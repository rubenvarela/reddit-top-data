{"kind": "Listing", "data": {"after": "t3_12kbglp", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_yqhxx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mimesis allows you toeasily generate detailed dummy datasets.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_12jorru", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 92, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 92, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/0HujrPfItzbK-xVcUfaTskdfDT2mtFezz4ZEQCZnbH8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681311398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/vdowhp07wgta1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/vdowhp07wgta1.png?auto=webp&amp;v=enabled&amp;s=945ba3c17594b5f18e16e95feebf9c07da2a8262", "width": 1864, "height": 2352}, "resolutions": [{"url": "https://preview.redd.it/vdowhp07wgta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1de560b22d1b59424fde93813523309c9c6a994f", "width": 108, "height": 136}, {"url": "https://preview.redd.it/vdowhp07wgta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29d0d3d9e9c35622693c7b92b0cd31c213695291", "width": 216, "height": 272}, {"url": "https://preview.redd.it/vdowhp07wgta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8443d21b10efac69c88b2b7a8c3d635619ec9f7c", "width": 320, "height": 403}, {"url": "https://preview.redd.it/vdowhp07wgta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efe245ac118cfa702fbc63c5543f976b8134cf6e", "width": 640, "height": 807}, {"url": "https://preview.redd.it/vdowhp07wgta1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a3f4a2a36d40e3fc15ed001bc8afa5e63015427", "width": 960, "height": 1211}, {"url": "https://preview.redd.it/vdowhp07wgta1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=429fc82a24e3539b771fecf02bdfd5d0f672bf4c", "width": 1080, "height": 1362}], "variants": {}, "id": "56AUYHxSl4omzIGYKyfLKYlY7OPf9zBKo_1y8707nWI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12jorru", "is_robot_indexable": true, "report_reasons": null, "author": "likid_geimfari", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12jorru/mimesis_allows_you_toeasily_generate_detailed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/vdowhp07wgta1.png", "subreddit_subscribers": 872033, "created_utc": 1681311398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Food for thought please?", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you like most about working in Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jtay0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 76, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 76, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681320904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Food for thought please?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12jtay0", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12jtay0/what_do_you_like_most_about_working_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12jtay0/what_do_you_like_most_about_working_in_data/", "subreddit_subscribers": 872033, "created_utc": 1681320904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So, I work for a very large company in their finance department. I recently got a new role on the data analytics team, and to my surprise, it seems like no one knows anything about data science, analytical methods, or best practices. \n\nA bit about myself, for the past 2 years, I've been teaching myself data science in order to get ahead. In this time, I've become really fluent in python, SQL, VBA, and general concepts such as ETL, wrangling...etc. I've also been able to use a lot of what I've learned in my current role. I'm by no means an expert, but I've been able to make some good progress at work with what I've done so far.\n\nBack to the new role. I had a couple of interviews with my new boss and director, and started describing the ETL process I do for email data. They had never heard of ETL. Beyond that, someone from their team reached out to me later and asked if I could help them find the name for a database in MS SQL. When I asked what type of data they were looking for they sent me a screenshot of the table with db name attached. It seemed as if they didn't understand the difference between a db, server, or table.\n\nI'm excited for the opportunity, but has anyone else been here?", "author_fullname": "t2_4emwju7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've found myself in a very unique situation at work. Has anyone else been here?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12k6j9x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681348028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I work for a very large company in their finance department. I recently got a new role on the data analytics team, and to my surprise, it seems like no one knows anything about data science, analytical methods, or best practices. &lt;/p&gt;\n\n&lt;p&gt;A bit about myself, for the past 2 years, I&amp;#39;ve been teaching myself data science in order to get ahead. In this time, I&amp;#39;ve become really fluent in python, SQL, VBA, and general concepts such as ETL, wrangling...etc. I&amp;#39;ve also been able to use a lot of what I&amp;#39;ve learned in my current role. I&amp;#39;m by no means an expert, but I&amp;#39;ve been able to make some good progress at work with what I&amp;#39;ve done so far.&lt;/p&gt;\n\n&lt;p&gt;Back to the new role. I had a couple of interviews with my new boss and director, and started describing the ETL process I do for email data. They had never heard of ETL. Beyond that, someone from their team reached out to me later and asked if I could help them find the name for a database in MS SQL. When I asked what type of data they were looking for they sent me a screenshot of the table with db name attached. It seemed as if they didn&amp;#39;t understand the difference between a db, server, or table.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m excited for the opportunity, but has anyone else been here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12k6j9x", "is_robot_indexable": true, "report_reasons": null, "author": "kkessler1023", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12k6j9x/ive_found_myself_in_a_very_unique_situation_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12k6j9x/ive_found_myself_in_a_very_unique_situation_at/", "subreddit_subscribers": 872033, "created_utc": 1681348028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Would like to introduce this tool to everyone. Have been testing with some beta users and see 10X increase in productivity. Currently it works well for less-complex DS tasks but we plan to expand more.\n\nHere what you can do with it all with natural language:\n\n1. Upload/Import data set csv, json, xls\n2. Do any processing task that you can think of\n3. Plot any plot that you can express in NLP and matplotlib can do :)\n4. Build simple model using scikit-learn\n\nLove to hear everyone feedbacks! Follow us here if you like to learn more [https://twitter.com/cnextdotio](https://twitter.com/cnextdotio)\n\nDocs: [https://docs.cnext.io/data-science-tools](https://docs.cnext.io/data-science-tools)\n\nApp: [apis.cnext.io](https://apis.cnext.io)\n\nhttps://preview.redd.it/lzktdauaykta1.png?width=873&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=16f2699204194527675e45531b8712c5f87ad6bd", "author_fullname": "t2_okfnia1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low-code Data Science Tool built on chatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 48, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lzktdauaykta1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/lzktdauaykta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1a5c7a2e3a498c928c74286ec1022650176e409"}, {"y": 174, "x": 216, "u": "https://preview.redd.it/lzktdauaykta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64fdf7e40a0dfe1cde77ce64062f868f4c2c4f87"}, {"y": 259, "x": 320, "u": "https://preview.redd.it/lzktdauaykta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1d528be3d18772ce799d366e50fdc4cc190ca78"}, {"y": 518, "x": 640, "u": "https://preview.redd.it/lzktdauaykta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de47389dd382213677cd067c4da66d6eabb6c87e"}], "s": {"y": 707, "x": 873, "u": "https://preview.redd.it/lzktdauaykta1.png?width=873&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=16f2699204194527675e45531b8712c5f87ad6bd"}, "id": "lzktdauaykta1"}}, "name": "t3_12kc5ls", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 48, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JDDq-pcrrSqsz7GEz0P5mUdLolERVxDSVAkq0fdYtPE.jpg", "edited": 1681362082.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1681360865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would like to introduce this tool to everyone. Have been testing with some beta users and see 10X increase in productivity. Currently it works well for less-complex DS tasks but we plan to expand more.&lt;/p&gt;\n\n&lt;p&gt;Here what you can do with it all with natural language:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Upload/Import data set csv, json, xls&lt;/li&gt;\n&lt;li&gt;Do any processing task that you can think of&lt;/li&gt;\n&lt;li&gt;Plot any plot that you can express in NLP and matplotlib can do :)&lt;/li&gt;\n&lt;li&gt;Build simple model using scikit-learn&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Love to hear everyone feedbacks! Follow us here if you like to learn more &lt;a href=\"https://twitter.com/cnextdotio\"&gt;https://twitter.com/cnextdotio&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Docs: &lt;a href=\"https://docs.cnext.io/data-science-tools\"&gt;https://docs.cnext.io/data-science-tools&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;App: &lt;a href=\"https://apis.cnext.io\"&gt;apis.cnext.io&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lzktdauaykta1.png?width=873&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=16f2699204194527675e45531b8712c5f87ad6bd\"&gt;https://preview.redd.it/lzktdauaykta1.png?width=873&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=16f2699204194527675e45531b8712c5f87ad6bd&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OBM7q-61ka5lkrprnjH6SpgJcEbNjU8Q46FW0LE-JWg.jpg?auto=webp&amp;v=enabled&amp;s=4d07eaa0db50c7c27f8c211c02755bcb7adbc83f", "width": 48, "height": 48}, "resolutions": [], "variants": {}, "id": "OlJRNvDzYa3NMm-BatyvTAOhVor4xM14A8xmLpBW4vI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kc5ls", "is_robot_indexable": true, "report_reasons": null, "author": "SomeProfessional", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kc5ls/lowcode_data_science_tool_built_on_chatgpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kc5ls/lowcode_data_science_tool_built_on_chatgpt/", "subreddit_subscribers": 872033, "created_utc": 1681360865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Loved this week's episode [Non-Response Bias](https://dataskeptic.com/blog/episodes/2023/non-response-bias) with Yajuan Si. DS is one of the best resources for data science info IMHO wondering what others think ?", "author_fullname": "t2_8c47ymou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data skeptic podcast, anyone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jxgdl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681330282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Loved this week&amp;#39;s episode &lt;a href=\"https://dataskeptic.com/blog/episodes/2023/non-response-bias\"&gt;Non-Response Bias&lt;/a&gt; with Yajuan Si. DS is one of the best resources for data science info IMHO wondering what others think ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HB3kelB6p3wDPkKU9TGPkxlF_cHc0QLquGtOzhJUSEk.jpg?auto=webp&amp;v=enabled&amp;s=48f3d59ecbbe5af2f72e17abe51453022fb4a818", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/HB3kelB6p3wDPkKU9TGPkxlF_cHc0QLquGtOzhJUSEk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20b14882d81c9408c8e2f0d78d9b117af6d42c8f", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/HB3kelB6p3wDPkKU9TGPkxlF_cHc0QLquGtOzhJUSEk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95b7bccedbef4d88ec5abf7f7a7bc2f40723b604", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/HB3kelB6p3wDPkKU9TGPkxlF_cHc0QLquGtOzhJUSEk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19bf5195ca59fd862db7d88d404973d2671f3478", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/HB3kelB6p3wDPkKU9TGPkxlF_cHc0QLquGtOzhJUSEk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8131048379b8c1e061cf325bcfad5d3643a0760", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/HB3kelB6p3wDPkKU9TGPkxlF_cHc0QLquGtOzhJUSEk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d501e954c878f024636c0a96366b242908518a7", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/HB3kelB6p3wDPkKU9TGPkxlF_cHc0QLquGtOzhJUSEk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e8df749079b500de17801b26b0ad3dd6f5391ee", "width": 1080, "height": 565}], "variants": {}, "id": "_wK6gZQ7TNgfZsYJv3DCWAOy0e7byHQjVzILP-M3fzs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12jxgdl", "is_robot_indexable": true, "report_reasons": null, "author": "Negative_Cell1272", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12jxgdl/data_skeptic_podcast_anyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12jxgdl/data_skeptic_podcast_anyone/", "subreddit_subscribers": 872033, "created_utc": 1681330282.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have incoming 1hr  technical interview for model development , the recruiter said they will provide me with a software and dummy data set , I should choose to code in SAS or python . When I asked the recruiter for more information , he did not reply .\nAs of now I am not sure on what to focus on my study , as connect with one current employee who told me \u00ab\u00a0to review statistics course \u00ab\u00a0 without telling me more .\nI am just lost on how to prepare .\nI did review EDA and model development in python but just scared of forgetting a specific library or not knowing a library they want me to use", "author_fullname": "t2_lhsetpwp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview for model development", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jmoi2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681306967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have incoming 1hr  technical interview for model development , the recruiter said they will provide me with a software and dummy data set , I should choose to code in SAS or python . When I asked the recruiter for more information , he did not reply .\nAs of now I am not sure on what to focus on my study , as connect with one current employee who told me \u00ab\u00a0to review statistics course \u00ab\u00a0 without telling me more .\nI am just lost on how to prepare .\nI did review EDA and model development in python but just scared of forgetting a specific library or not knowing a library they want me to use&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12jmoi2", "is_robot_indexable": true, "report_reasons": null, "author": "sQuant18", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12jmoi2/interview_for_model_development/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12jmoi2/interview_for_model_development/", "subreddit_subscribers": 872033, "created_utc": 1681306967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Long story short, I got hired as a consultant 5 months ago, but the project I was supposed to do was delayed several months. I have been doing some tasks (develop some scripts in python, NoSQL, nlp and a bit of ML), but I think I am wasting my time, since I am literally doing nothing and it is really frustrating.\n\nI have 3+ years of experience in this field, and I feel stuck. I do like doing online courses (I have done a lot from coursera, including specializations such as DL or NLP) but I am not motivated to do any of them right now (even though I want to learn about cloud and big data tools). \n\nThe company is trying to find new projects for me, I will give them that, but it is hard for me to spend time doing nothing and learning nothing either. At least my position is full remote, but I moved from my old company in order to face new projects and learn a lot, and it is not happening. The company is fine, I feel comfortable with almost everything but not with the zero workload.\n\nHave you ever been in this situation? I would consider moving to another company, but I don't like the idea of having in my CV a 5 month position honestly.", "author_fullname": "t2_2lc0syow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have been in this company for 5 months, and have done nothing relevant yet due to delays, what should I do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kjrc2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681380657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, I got hired as a consultant 5 months ago, but the project I was supposed to do was delayed several months. I have been doing some tasks (develop some scripts in python, NoSQL, nlp and a bit of ML), but I think I am wasting my time, since I am literally doing nothing and it is really frustrating.&lt;/p&gt;\n\n&lt;p&gt;I have 3+ years of experience in this field, and I feel stuck. I do like doing online courses (I have done a lot from coursera, including specializations such as DL or NLP) but I am not motivated to do any of them right now (even though I want to learn about cloud and big data tools). &lt;/p&gt;\n\n&lt;p&gt;The company is trying to find new projects for me, I will give them that, but it is hard for me to spend time doing nothing and learning nothing either. At least my position is full remote, but I moved from my old company in order to face new projects and learn a lot, and it is not happening. The company is fine, I feel comfortable with almost everything but not with the zero workload.&lt;/p&gt;\n\n&lt;p&gt;Have you ever been in this situation? I would consider moving to another company, but I don&amp;#39;t like the idea of having in my CV a 5 month position honestly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kjrc2", "is_robot_indexable": true, "report_reasons": null, "author": "Cassegrain07", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kjrc2/i_have_been_in_this_company_for_5_months_and_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kjrc2/i_have_been_in_this_company_for_5_months_and_have/", "subreddit_subscribers": 872033, "created_utc": 1681380657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am able to run a docker image with my m1 chip, and I'm able to import tensorflow locally on my m1 chip. \n\nWhat I can't do for the life of me is build and run a docker image that pip installs tensorflow (any version past 2.6.0, I have tried the unofficial wheel and it works, but my other dependencies require a higher version of tensorflow), while using my m1 chip. If anyone has any updated suggestions please let me know, as this issue seems to have quietened down since mid last year.", "author_fullname": "t2_cg1cyk8a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "M1 Chip, Tensorflow &amp; Docker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jmj2q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681306636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am able to run a docker image with my m1 chip, and I&amp;#39;m able to import tensorflow locally on my m1 chip. &lt;/p&gt;\n\n&lt;p&gt;What I can&amp;#39;t do for the life of me is build and run a docker image that pip installs tensorflow (any version past 2.6.0, I have tried the unofficial wheel and it works, but my other dependencies require a higher version of tensorflow), while using my m1 chip. If anyone has any updated suggestions please let me know, as this issue seems to have quietened down since mid last year.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12jmj2q", "is_robot_indexable": true, "report_reasons": null, "author": "plontface", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12jmj2q/m1_chip_tensorflow_docker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12jmj2q/m1_chip_tensorflow_docker/", "subreddit_subscribers": 872033, "created_utc": 1681306636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Good morning everyone, I am doing a data science project, and I am looking for recommendations/tips that can help me to carry it out. \n\nThe project is based on predicting monthly sales of a certain product. At the beginning of each month (around day 5-6), we are provided with an estimate of monthly sales. In addition, as the month progresses, more and more daily sales become visible, which allows us to better estimate the total monthly sales. The idea is to create a model that, for each day of the month based on the daily sales up to that day and the initial estimate, predicts the monthly sales value. Additionally, we also have information about the number of working days per month. \n\nAny recommendations for models/papers would be more than welcome.", "author_fullname": "t2_ott4s3e2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Project: Sales Forecasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kjcgo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681379636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good morning everyone, I am doing a data science project, and I am looking for recommendations/tips that can help me to carry it out. &lt;/p&gt;\n\n&lt;p&gt;The project is based on predicting monthly sales of a certain product. At the beginning of each month (around day 5-6), we are provided with an estimate of monthly sales. In addition, as the month progresses, more and more daily sales become visible, which allows us to better estimate the total monthly sales. The idea is to create a model that, for each day of the month based on the daily sales up to that day and the initial estimate, predicts the monthly sales value. Additionally, we also have information about the number of working days per month. &lt;/p&gt;\n\n&lt;p&gt;Any recommendations for models/papers would be more than welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kjcgo", "is_robot_indexable": true, "report_reasons": null, "author": "Common_Election_8646", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kjcgo/data_science_project_sales_forecasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kjcgo/data_science_project_sales_forecasting/", "subreddit_subscribers": 872033, "created_utc": 1681379636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All,\n\nI'm wondering if someone has the experience in moving dashboards and analysis from PBI to a real front end framework?\n\nReason I'm asking is that we started to see the limitations of PBI, especially on the performance site. \nDon't get me wrong the MS ekosystem is incredible but I do miss a lot of capability in end user interactions and real time simulation based on manual input. \n\nWe spent significantly amount of time tuning the dashboards so I'm quite confident that it is not a skillset issue.", "author_fullname": "t2_93oh8x44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PowerBi -&gt; JS/HTML/CSS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kfpzo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681369946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if someone has the experience in moving dashboards and analysis from PBI to a real front end framework?&lt;/p&gt;\n\n&lt;p&gt;Reason I&amp;#39;m asking is that we started to see the limitations of PBI, especially on the performance site. \nDon&amp;#39;t get me wrong the MS ekosystem is incredible but I do miss a lot of capability in end user interactions and real time simulation based on manual input. &lt;/p&gt;\n\n&lt;p&gt;We spent significantly amount of time tuning the dashboards so I&amp;#39;m quite confident that it is not a skillset issue.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kfpzo", "is_robot_indexable": true, "report_reasons": null, "author": "Kamil_1987", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kfpzo/powerbi_jshtmlcss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kfpzo/powerbi_jshtmlcss/", "subreddit_subscribers": 872033, "created_utc": 1681369946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've recently joined a new employer and have been somewhat shocked by the prevalent approach to managing data.\n\nBroadly speaking, people aren't using analytics/BI packages for reporting (even though they are available). Instead, there is a culture of making direct SQL queries against the database.\n\nNot only that, there is a culture of creating new tables to hold the results of a query rather than just building a view. These are usually added straight onto production. Rarely are they removed after use.\n\nMy gut feeling is that this is both extremely risky and a waste of resources. The rest of the organisation seems quite content to carry on in this manner. Who is right?", "author_fullname": "t2_135qqr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Company culture of creating tables directly on production to answer questions instead of using analytics/BI tools or views. Dangerous?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ju4op", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681323141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently joined a new employer and have been somewhat shocked by the prevalent approach to managing data.&lt;/p&gt;\n\n&lt;p&gt;Broadly speaking, people aren&amp;#39;t using analytics/BI packages for reporting (even though they are available). Instead, there is a culture of making direct SQL queries against the database.&lt;/p&gt;\n\n&lt;p&gt;Not only that, there is a culture of creating new tables to hold the results of a query rather than just building a view. These are usually added straight onto production. Rarely are they removed after use.&lt;/p&gt;\n\n&lt;p&gt;My gut feeling is that this is both extremely risky and a waste of resources. The rest of the organisation seems quite content to carry on in this manner. Who is right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ju4op", "is_robot_indexable": true, "report_reasons": null, "author": "forza_125", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ju4op/company_culture_of_creating_tables_directly_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ju4op/company_culture_of_creating_tables_directly_on/", "subreddit_subscribers": 872033, "created_utc": 1681323141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been a Data Scientist now for 2 years. I think I\u2019ve gotten better, but I\u2019m really not sure. Life feels really slow right now and I wonder if I\u2019m any better than where I started? Anyone else deal with this? I try to learn and absorb as much as I can but I feel like there\u2019s always something I don\u2019t know when I should. I went back and re-reviewed some old stats notes I took and realized I was having a hard time explaining and applying P-values\u2026I feel like I\u2019m on information overload at this point. Also I\u2019m not fresh out of school, I\u2019ve been in my current industry for 9 years now but this is my first DS job. How does everyone else deal with this?", "author_fullname": "t2_7xce854y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dealing with hardcore imposter syndrome in DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jordf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681311377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been a Data Scientist now for 2 years. I think I\u2019ve gotten better, but I\u2019m really not sure. Life feels really slow right now and I wonder if I\u2019m any better than where I started? Anyone else deal with this? I try to learn and absorb as much as I can but I feel like there\u2019s always something I don\u2019t know when I should. I went back and re-reviewed some old stats notes I took and realized I was having a hard time explaining and applying P-values\u2026I feel like I\u2019m on information overload at this point. Also I\u2019m not fresh out of school, I\u2019ve been in my current industry for 9 years now but this is my first DS job. How does everyone else deal with this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12jordf", "is_robot_indexable": true, "report_reasons": null, "author": "Professional-Humor-8", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12jordf/dealing_with_hardcore_imposter_syndrome_in_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12jordf/dealing_with_hardcore_imposter_syndrome_in_ds/", "subreddit_subscribers": 872033, "created_utc": 1681311377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_x3vk1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hear from today's real-world data leaders = episode 63 (Daniel Hulme founder of Satalia)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_12kk0m5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bHx6MGGYGs44L0rn8G7qZyVNOlSQjpJKU1zHW09HLIE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681381302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "podcasters.spotify.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://podcasters.spotify.com/pod/show/customerinsightleader/episodes/Episode-63---Daniel-Hulme-Satalia-e1sa7r7", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/K5WSuKshDcIYDOAEJ1dhjM2p-a8TI9pB8zCRtq7zkQ4.jpg?auto=webp&amp;v=enabled&amp;s=cae169dc86c09eee4a4ae4314280786fab102f9c", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/K5WSuKshDcIYDOAEJ1dhjM2p-a8TI9pB8zCRtq7zkQ4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd896b4d68f7063771f4ccdac61a9df4dddef55a", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/K5WSuKshDcIYDOAEJ1dhjM2p-a8TI9pB8zCRtq7zkQ4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=defe7d936a830122b7e94e927cd830f9559de781", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/K5WSuKshDcIYDOAEJ1dhjM2p-a8TI9pB8zCRtq7zkQ4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e60078a475e0369e46be33b37cd05346791259f8", "width": 320, "height": 320}], "variants": {}, "id": "lOmO3YIIHrYfnoN5Ytw44Gi7UDwTX5S2V--yq_mjt-Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kk0m5", "is_robot_indexable": true, "report_reasons": null, "author": "PaulLaughlin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kk0m5/hear_from_todays_realworld_data_leaders_episode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://podcasters.spotify.com/pod/show/customerinsightleader/episodes/Episode-63---Daniel-Hulme-Satalia-e1sa7r7", "subreddit_subscribers": 872033, "created_utc": 1681381302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI am working on a manufacturing data that is fairly new (only has 60 batches produced so far) dataset size is 60 observations of 150 variables and I am building a PLS model to predict the Final Product quantity in Kgs that meets minimum specifications. After removing intermediate product measurements, redundant variables, calculated variables to avoid Colinearity I am left with 60 observations of 110 variables. This PLS model has predictability only at 23% and more than 70% of the variables have huge variations in their data so far. My thoughts are this process data is too early and not sufficient to make a predictive PLS model but I would like to get some expert opinions on this situation. Can I assume adding more observations to this data helps the model? Is there any basic data health check I am missing for PLS modeling before I submit the outcomes to my manufacturing team? Thank you", "author_fullname": "t2_67a9iuah", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data size and health for PLS modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12katta", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681357720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am working on a manufacturing data that is fairly new (only has 60 batches produced so far) dataset size is 60 observations of 150 variables and I am building a PLS model to predict the Final Product quantity in Kgs that meets minimum specifications. After removing intermediate product measurements, redundant variables, calculated variables to avoid Colinearity I am left with 60 observations of 110 variables. This PLS model has predictability only at 23% and more than 70% of the variables have huge variations in their data so far. My thoughts are this process data is too early and not sufficient to make a predictive PLS model but I would like to get some expert opinions on this situation. Can I assume adding more observations to this data helps the model? Is there any basic data health check I am missing for PLS modeling before I submit the outcomes to my manufacturing team? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12katta", "is_robot_indexable": true, "report_reasons": null, "author": "Santhu1414Ind", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12katta/data_size_and_health_for_pls_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12katta/data_size_and_health_for_pls_modeling/", "subreddit_subscribers": 872033, "created_utc": 1681357720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work as an analyst for an established e-commerce FMCG. The work consists of dashboarding, SQL, commercial decision support. My work is fairly project based and I want to grow my skill set by completing some data science projects that add value to the business. \n\nI\u2019ve completed several intermediate level python courses and I\u2019m comfortable using pandas to explore data. With a background in economics and statistics I enjoy math. \n\nWhat sort of projects or tools would be a good starting point, I\u2019m thinking cluster analysis might be a good starting point? It would be great to get some feedback.", "author_fullname": "t2_et27hg3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data analyst to Data science - recommended projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12k4x6x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681344511.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as an analyst for an established e-commerce FMCG. The work consists of dashboarding, SQL, commercial decision support. My work is fairly project based and I want to grow my skill set by completing some data science projects that add value to the business. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve completed several intermediate level python courses and I\u2019m comfortable using pandas to explore data. With a background in economics and statistics I enjoy math. &lt;/p&gt;\n\n&lt;p&gt;What sort of projects or tools would be a good starting point, I\u2019m thinking cluster analysis might be a good starting point? It would be great to get some feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12k4x6x", "is_robot_indexable": true, "report_reasons": null, "author": "oats224466", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12k4x6x/data_analyst_to_data_science_recommended_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12k4x6x/data_analyst_to_data_science_recommended_projects/", "subreddit_subscribers": 872033, "created_utc": 1681344511.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey folks, we just published a new blog post about our in-house Metrics Layer for Experimentation. At DoorDash, we faced numerous challenges with our experimentation analysis platform, Curie, due to our ad-hoc approach to metrics. In our latest post, we delve into these challenges and share how a Metrics Layer helped standardize and scale our metrics for Experimentation. We also discuss the design and implementation of our data models, metrics authorship, metrics governance, and our highly scalable metrics computation engine, while documenting our key learnings.\n\nAs the trend of Metrics Layer adoption gains traction in the data space, we're thrilled to share a practical application of its value. We would love for you to give it a read and share your thoughts! [https://doordash.engineering/2023/04/12/using-metrics-layer-to-standardize-and-scale-experimentation-at-doordash/](https://doordash.engineering/2023/04/12/using-metrics-layer-to-standardize-and-scale-experimentation-at-doordash/)", "author_fullname": "t2_a12ijdpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Blog Post on how DoorDash used the metrics layer to scale and standardize Metrics for Experimentation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12k0cbg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681335593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, we just published a new blog post about our in-house Metrics Layer for Experimentation. At DoorDash, we faced numerous challenges with our experimentation analysis platform, Curie, due to our ad-hoc approach to metrics. In our latest post, we delve into these challenges and share how a Metrics Layer helped standardize and scale our metrics for Experimentation. We also discuss the design and implementation of our data models, metrics authorship, metrics governance, and our highly scalable metrics computation engine, while documenting our key learnings.&lt;/p&gt;\n\n&lt;p&gt;As the trend of Metrics Layer adoption gains traction in the data space, we&amp;#39;re thrilled to share a practical application of its value. We would love for you to give it a read and share your thoughts! &lt;a href=\"https://doordash.engineering/2023/04/12/using-metrics-layer-to-standardize-and-scale-experimentation-at-doordash/\"&gt;https://doordash.engineering/2023/04/12/using-metrics-layer-to-standardize-and-scale-experimentation-at-doordash/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12k0cbg", "is_robot_indexable": true, "report_reasons": null, "author": "Electrical-Apricot25", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12k0cbg/blog_post_on_how_doordash_used_the_metrics_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12k0cbg/blog_post_on_how_doordash_used_the_metrics_layer/", "subreddit_subscribers": 872033, "created_utc": 1681335593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nLets say I would like to create a system that can monitor the defect rate of our company products  (A,B,C). Right now we have a team that inspect the product weekly and find out if there is a defect or not. The problem is we sample few products out of the whole lot of products so the defect rate that we find in the sample needs to be used to estimate the true parameter of the population which would be the total defect ratio. \n\nI would like to make a separate model for each A B C product using Bayesian method to monitor the defect rate and how it is changing over time as inspection is being done\n\n1. What can be my prior distribution? Do I just use uniform beta distribution and use my inspection data to update it? \n\n2. What is the advantage of using bayesian method and not just use the average defect rate found during inspection?", "author_fullname": "t2_5uvrlw9s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bayesian Method for defect rate estimator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jwg9x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681328433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Lets say I would like to create a system that can monitor the defect rate of our company products  (A,B,C). Right now we have a team that inspect the product weekly and find out if there is a defect or not. The problem is we sample few products out of the whole lot of products so the defect rate that we find in the sample needs to be used to estimate the true parameter of the population which would be the total defect ratio. &lt;/p&gt;\n\n&lt;p&gt;I would like to make a separate model for each A B C product using Bayesian method to monitor the defect rate and how it is changing over time as inspection is being done&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What can be my prior distribution? Do I just use uniform beta distribution and use my inspection data to update it? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is the advantage of using bayesian method and not just use the average defect rate found during inspection?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12jwg9x", "is_robot_indexable": true, "report_reasons": null, "author": "Professional_Ball_58", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12jwg9x/bayesian_method_for_defect_rate_estimator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12jwg9x/bayesian_method_for_defect_rate_estimator/", "subreddit_subscribers": 872033, "created_utc": 1681328433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best tools for web scraping and analysis of natural language to populate a dataset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jte4d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_6rtdgxk5q", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "ArtificialInteligence", "selftext": "I have a large dataset (20k+ investor names, geographies and URLs), and I'd like to add columns for \"industry focus areas,\" \"geographic focus areas,\" \"typical ticket size,\" and other information available online. Preferably, the tool could find information about each investor outside of just their website (e.g. news articles, LinkedIn, etc.), and ideally across different languages. That being said, I'd be thrilled just to be able to populate columns with the key information on their websites.\n\nSo does anyone have any suggestions for an easy-to-configure web scraping tool that can populate a dataset like this? Any help is much appreciated!", "author_fullname": "t2_6rtdgxk5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best tools for web scraping and analysis of natural language to populate a dataset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/ArtificialInteligence", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jrxhv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "How-To", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681317687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ArtificialInteligence", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a large dataset (20k+ investor names, geographies and URLs), and I&amp;#39;d like to add columns for &amp;quot;industry focus areas,&amp;quot; &amp;quot;geographic focus areas,&amp;quot; &amp;quot;typical ticket size,&amp;quot; and other information available online. Preferably, the tool could find information about each investor outside of just their website (e.g. news articles, LinkedIn, etc.), and ideally across different languages. That being said, I&amp;#39;d be thrilled just to be able to populate columns with the key information on their websites.&lt;/p&gt;\n\n&lt;p&gt;So does anyone have any suggestions for an easy-to-configure web scraping tool that can populate a dataset like this? Any help is much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "top", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d85b3c74-99e7-11ed-a09d-5e4f494c55e8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_3crzr", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "12jrxhv", "is_robot_indexable": true, "report_reasons": null, "author": "adjectivenounnr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/ArtificialInteligence/comments/12jrxhv/what_are_the_best_tools_for_web_scraping_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/ArtificialInteligence/comments/12jrxhv/what_are_the_best_tools_for_web_scraping_and/", "subreddit_subscribers": 138150, "created_utc": 1681317687.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1681321150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ArtificialInteligence", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/ArtificialInteligence/comments/12jrxhv/what_are_the_best_tools_for_web_scraping_and/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12jte4d", "is_robot_indexable": true, "report_reasons": null, "author": "adjectivenounnr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12jrxhv", "author_flair_text_color": null, "permalink": "/r/datascience/comments/12jte4d/what_are_the_best_tools_for_web_scraping_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/ArtificialInteligence/comments/12jrxhv/what_are_the_best_tools_for_web_scraping_and/", "subreddit_subscribers": 872033, "created_utc": 1681321150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nI am an economist turned data scientist. I have worked on financial and economic models in the financial services industry for the past 15 years. I am looking to offer my services as a part time data science consultant. I want the flexibility of working on a variety of projects and not being tied down to one employer.\n\nI am trained in classical time series and econometric analysis and am self-taught in areas of machine learning, neural networks, etc. I have many years of experience building and maintaining live models that run in real time.\n\nCan anyone suggest ways that I might be able to find clients?\n\nThanks", "author_fullname": "t2_c9azn741", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I get clients as a Data Science Consultant?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jt76e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681320633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am an economist turned data scientist. I have worked on financial and economic models in the financial services industry for the past 15 years. I am looking to offer my services as a part time data science consultant. I want the flexibility of working on a variety of projects and not being tied down to one employer.&lt;/p&gt;\n\n&lt;p&gt;I am trained in classical time series and econometric analysis and am self-taught in areas of machine learning, neural networks, etc. I have many years of experience building and maintaining live models that run in real time.&lt;/p&gt;\n\n&lt;p&gt;Can anyone suggest ways that I might be able to find clients?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12jt76e", "is_robot_indexable": true, "report_reasons": null, "author": "ControlNo7276", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12jt76e/how_do_i_get_clients_as_a_data_science_consultant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12jt76e/how_do_i_get_clients_as_a_data_science_consultant/", "subreddit_subscribers": 872033, "created_utc": 1681320633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8vkq5mxj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for examples of companies that are doing a lot of citizen data science/ citizen automation or doing this really well\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jr74q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681316243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12jr74q", "is_robot_indexable": true, "report_reasons": null, "author": "No_Avocado_3335", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12jr74q/looking_for_examples_of_companies_that_are_doing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12jr74q/looking_for_examples_of_companies_that_are_doing/", "subreddit_subscribers": 872033, "created_utc": 1681316243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All,\n\nFor the past couple years I have been a researcher working primarily with Twitter data. Our team had access to the Twitter API using an academic license. Like many others, our license was revoked last week. Our team cannot afford an enterprise Twitter license, so I'm curious if there are any other options available to us to programmatically search Twitter--ideally using python.\n\nI would like to search for Tweets that contain specific URLs. Such as:\n\n&gt; https://www.vanityfair.com/hollywood/2018/02/parkland-students-crisis-actors-conspiracy-kimmel-colbert-trevor-noah\n\nWith the goal that I could obtain a count of the number of tweets that contain such a link.\n\nThank you for any help you can offer!", "author_fullname": "t2_5abvk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to programmatically search Twitter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jpivy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681312921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;For the past couple years I have been a researcher working primarily with Twitter data. Our team had access to the Twitter API using an academic license. Like many others, our license was revoked last week. Our team cannot afford an enterprise Twitter license, so I&amp;#39;m curious if there are any other options available to us to programmatically search Twitter--ideally using python.&lt;/p&gt;\n\n&lt;p&gt;I would like to search for Tweets that contain specific URLs. Such as:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;a href=\"https://www.vanityfair.com/hollywood/2018/02/parkland-students-crisis-actors-conspiracy-kimmel-colbert-trevor-noah\"&gt;https://www.vanityfair.com/hollywood/2018/02/parkland-students-crisis-actors-conspiracy-kimmel-colbert-trevor-noah&lt;/a&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;With the goal that I could obtain a count of the number of tweets that contain such a link.&lt;/p&gt;\n\n&lt;p&gt;Thank you for any help you can offer!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8_41Dir0ZbJEQpgk25rSUBBAEVPDSEAT2R4LlbRmtZI.jpg?auto=webp&amp;v=enabled&amp;s=56c00e04ab3ebb5c2599bdc85fa7868c32d8b554", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/8_41Dir0ZbJEQpgk25rSUBBAEVPDSEAT2R4LlbRmtZI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7449d8e4ada219a5d8e4a3a9c0c364bdcc433e7", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/8_41Dir0ZbJEQpgk25rSUBBAEVPDSEAT2R4LlbRmtZI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64c06a2dbb2cddd5d3b7fd86dde6e035d276aaaf", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/8_41Dir0ZbJEQpgk25rSUBBAEVPDSEAT2R4LlbRmtZI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2241848fd1dd3eb0980f2f851e541b1ffd19f311", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/8_41Dir0ZbJEQpgk25rSUBBAEVPDSEAT2R4LlbRmtZI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=393d727a05577b27af45f8916b77a87f533c0157", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/8_41Dir0ZbJEQpgk25rSUBBAEVPDSEAT2R4LlbRmtZI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd11b98804356eefd39de03de8c21f33b45c4cb3", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/8_41Dir0ZbJEQpgk25rSUBBAEVPDSEAT2R4LlbRmtZI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e13cc58b15003e6f88c31c72b44c82e99621dbbd", "width": 1080, "height": 607}], "variants": {}, "id": "x-I0qmTFbQeTGnXmIxkDN0XgkrAk5_F2kHTLWnMqd1o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12jpivy", "is_robot_indexable": true, "report_reasons": null, "author": "RamaAnattaDharma", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12jpivy/how_to_programmatically_search_twitter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12jpivy/how_to_programmatically_search_twitter/", "subreddit_subscribers": 872033, "created_utc": 1681312921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am working on a project for my probability and statistics class and I am a bit confused on how to continue. I am analysing a dataset of all premier league games from the 2010/11 season to the 2019/20 season. What I am trying to do is analyse the conversion rate (goals scored per game/shots taken per game) and create a distribution. I am not sure if I should use a normal distribution or a binomial distribution as the conversion rate is technically a proportion of success divided by trials. So far this what I have tried but I am not sure if I am going about this correctly.\n\nFirstly I tried using a normal distribution as when I divide the goals per game/shots taken per game I get continuous values, expect for some zeros which are the games where no goals were scored. However the data is not completely normal, so I artificially normalised by doing log(1+goals per game/shots taken per game). While it did not create a huge difference, the data is more normal now. Would I just create a normal distribution and find the mean and variance using the values given by the log transformation?\n\nThe other approach I took was using the binomial distribution as my population is large and it approximates the normal distribution. Firstly I used\n\nE(x)=mu=nP\n\nVar(x)=nP(1-P)\n\nBut I was not sure if this was correct because this would be a distribution of the number of successes, which is the goals scored. But that is not what I want to analyse, I want to analyse the conversion rate.\n\nSo instead I tried using the proportion random variable.\n\nP=X/n (where X is the number of successes, goals scored)\n\nmu=P\n\nVar(x)=(P(1-P))/n\n\nI would just like some advice on which approach is the best and makes the sense for what I am trying to do. Any help is appreciated and thanks in advance.", "author_fullname": "t2_1ynuq49y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to represent conversion rates?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jmna9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681306888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am working on a project for my probability and statistics class and I am a bit confused on how to continue. I am analysing a dataset of all premier league games from the 2010/11 season to the 2019/20 season. What I am trying to do is analyse the conversion rate (goals scored per game/shots taken per game) and create a distribution. I am not sure if I should use a normal distribution or a binomial distribution as the conversion rate is technically a proportion of success divided by trials. So far this what I have tried but I am not sure if I am going about this correctly.&lt;/p&gt;\n\n&lt;p&gt;Firstly I tried using a normal distribution as when I divide the goals per game/shots taken per game I get continuous values, expect for some zeros which are the games where no goals were scored. However the data is not completely normal, so I artificially normalised by doing log(1+goals per game/shots taken per game). While it did not create a huge difference, the data is more normal now. Would I just create a normal distribution and find the mean and variance using the values given by the log transformation?&lt;/p&gt;\n\n&lt;p&gt;The other approach I took was using the binomial distribution as my population is large and it approximates the normal distribution. Firstly I used&lt;/p&gt;\n\n&lt;p&gt;E(x)=mu=nP&lt;/p&gt;\n\n&lt;p&gt;Var(x)=nP(1-P)&lt;/p&gt;\n\n&lt;p&gt;But I was not sure if this was correct because this would be a distribution of the number of successes, which is the goals scored. But that is not what I want to analyse, I want to analyse the conversion rate.&lt;/p&gt;\n\n&lt;p&gt;So instead I tried using the proportion random variable.&lt;/p&gt;\n\n&lt;p&gt;P=X/n (where X is the number of successes, goals scored)&lt;/p&gt;\n\n&lt;p&gt;mu=P&lt;/p&gt;\n\n&lt;p&gt;Var(x)=(P(1-P))/n&lt;/p&gt;\n\n&lt;p&gt;I would just like some advice on which approach is the best and makes the sense for what I am trying to do. Any help is appreciated and thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12jmna9", "is_robot_indexable": true, "report_reasons": null, "author": "Rety03", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12jmna9/best_way_to_represent_conversion_rates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12jmna9/best_way_to_represent_conversion_rates/", "subreddit_subscribers": 872033, "created_utc": 1681306888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As of recently working on a project for forecasting. Before that I want to do some unsupervised learning on my dataset. If I have a dataset with many variables what Unsupervised method can I use to find those moving in the most similar of fashion together. Thanks.", "author_fullname": "t2_aws8tyj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unsupervised learning similarity analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12jlj6f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681304475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As of recently working on a project for forecasting. Before that I want to do some unsupervised learning on my dataset. If I have a dataset with many variables what Unsupervised method can I use to find those moving in the most similar of fashion together. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12jlj6f", "is_robot_indexable": true, "report_reasons": null, "author": "AnyJello605", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12jlj6f/unsupervised_learning_similarity_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12jlj6f/unsupervised_learning_similarity_analysis/", "subreddit_subscribers": 872033, "created_utc": 1681304475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4en3asns", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "r/gradadmissions on Reddit: UW MSDS vs UChicago MScA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kin3n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1681377817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "reddit.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/r/gradadmissions/comments/12khynx/uw_msds_vs_uchicago_msca/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kin3n", "is_robot_indexable": true, "report_reasons": null, "author": "Fit-Consequence4070", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kin3n/rgradadmissions_on_reddit_uw_msds_vs_uchicago_msca/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/gradadmissions/comments/12khynx/uw_msds_vs_uchicago_msca/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf", "subreddit_subscribers": 872033, "created_utc": 1681377817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anyone know any part time data science program (master/graduate level preferred) available out there? All I can find are full time programs\u2026\nI\u2019ve a mid level data analyst job but I really want to get into data science.\nTIA", "author_fullname": "t2_8s1y1k1s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Part time programs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kbglp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681359187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know any part time data science program (master/graduate level preferred) available out there? All I can find are full time programs\u2026\nI\u2019ve a mid level data analyst job but I really want to get into data science.\nTIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kbglp", "is_robot_indexable": true, "report_reasons": null, "author": "stephensplo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kbglp/part_time_programs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kbglp/part_time_programs/", "subreddit_subscribers": 872033, "created_utc": 1681359187.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}