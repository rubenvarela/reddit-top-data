{"kind": "Listing", "data": {"after": "t3_12afo94", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8v6mk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "COVID-19 data pipeline on AWS feat. Glue/PySpark, Docker, Great Expectations, Airflow, and Redshift, templated in CF/CDK, deployable via Github Actions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_12anr2k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 94, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 94, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BuxerbOZQ8bp-v8D4PAY2i18rpnPXbhZKvGZC3MzBpA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680535484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4qpi4llisora1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4qpi4llisora1.png?auto=webp&amp;v=enabled&amp;s=c238cb4d6ad3085913d8ca57fe1c8454c7560a49", "width": 2999, "height": 1879}, "resolutions": [{"url": "https://preview.redd.it/4qpi4llisora1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57e1f51cbcd1c5fdddb4ca0393bba2d6190c3a11", "width": 108, "height": 67}, {"url": "https://preview.redd.it/4qpi4llisora1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf4c1f52e4c1839854449c9de73b945f6a24a721", "width": 216, "height": 135}, {"url": "https://preview.redd.it/4qpi4llisora1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb6f9628dc35d1f82519602cff65ec9db5d9be4a", "width": 320, "height": 200}, {"url": "https://preview.redd.it/4qpi4llisora1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=71ad88d64e69170d4ad6b65d1bf0f339103f2082", "width": 640, "height": 400}, {"url": "https://preview.redd.it/4qpi4llisora1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c83db1d0e09a58dc397200876fc33bdaee0718e4", "width": 960, "height": 601}, {"url": "https://preview.redd.it/4qpi4llisora1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=039a2067db6dc0ab43a59e4ac4266ecfabac8c0c", "width": 1080, "height": 676}], "variants": {}, "id": "ipqQE0lb9pWDLD6MolmjOmGuaaIeU8jS-PJ20BcCN-0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "12anr2k", "is_robot_indexable": true, "report_reasons": null, "author": "smoochie100", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12anr2k/covid19_data_pipeline_on_aws_feat_gluepyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4qpi4llisora1.png", "subreddit_subscribers": 95679, "created_utc": 1680535484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After a few years and with the hype gone, it has become apparent that MLOps overlap more with Data Engineering than most people believed.\n\nI wrote my thoughts on the matter and the awesome people of the MLOps community were kind enough to host them on their blog as a guest post. You can find the post here:\n\n[https://mlops.community/mlops-is-mostly-data-engineering/](https://mlops.community/mlops-is-mostly-data-engineering/)", "author_fullname": "t2_fb1s1pke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MLOps is 98% Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12asp78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 95, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 95, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680545604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After a few years and with the hype gone, it has become apparent that MLOps overlap more with Data Engineering than most people believed.&lt;/p&gt;\n\n&lt;p&gt;I wrote my thoughts on the matter and the awesome people of the MLOps community were kind enough to host them on their blog as a guest post. You can find the post here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://mlops.community/mlops-is-mostly-data-engineering/\"&gt;https://mlops.community/mlops-is-mostly-data-engineering/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bVjWIf0rrdbCKPd_Xzn3W6W1rfXxA5DUGfQ4vOGB5OI.jpg?auto=webp&amp;v=enabled&amp;s=0d81c32dcfb93ea8d28ca754c33326a81e0c224e", "width": 700, "height": 467}, "resolutions": [{"url": "https://external-preview.redd.it/bVjWIf0rrdbCKPd_Xzn3W6W1rfXxA5DUGfQ4vOGB5OI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=744fe705c8924b38a5cb5812da49becb067c8ef7", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/bVjWIf0rrdbCKPd_Xzn3W6W1rfXxA5DUGfQ4vOGB5OI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ee10e129b5a63d0843b3853372afea177faaddd", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/bVjWIf0rrdbCKPd_Xzn3W6W1rfXxA5DUGfQ4vOGB5OI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=454128534ee7c02c4eb208d07b925cfb60adaa53", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/bVjWIf0rrdbCKPd_Xzn3W6W1rfXxA5DUGfQ4vOGB5OI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=322afdd685f97911331712d0c443345267967c7b", "width": 640, "height": 426}], "variants": {}, "id": "jLhsBd_EDLM0YfBqf4uOPydrZ4w5DXOH2lHMgyZ6lXw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12asp78", "is_robot_indexable": true, "report_reasons": null, "author": "cpardl", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12asp78/mlops_is_98_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12asp78/mlops_is_98_data_engineering/", "subreddit_subscribers": 95679, "created_utc": 1680545604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just read this and loved it (who doesn't like a bit of drama?)! I'm not to well versed, so I'd be interested in hearing what other people in the industry are thinking? Given the previous posts about costs of data teams etc, I think it's quite interesting.   \n\n\n[https://medium.com/@laurengreerbalik/customer-empathy-is-dead-10f412782b5e](https://medium.com/@laurengreerbalik/customer-empathy-is-dead-10f412782b5e)  \n\n\n*Airbyte is such a joke that Reddit* r/dataengineering *users \u201cMyDixonsCider\u201d (say that out loud) and \u201cThunderCuntAU\u201d seem to have done more due diligence on Airbyte than any venture capitalist willing to give tens of millions of dollars of other peoples\u2019 money to Airbyte\u2019s founders to make the twentieth-worst version of a data replication EL tool that exists on market.*  \n\n\n*I should be firing Fivetran potentially, when all we mostly use it for is Postgres and Salesforce replications, and I should look into Keboola (or similar) which can give me the same thing with better SLA adherence and better uptime for $10k a year and allows me to \u201ctransform and denormalize\u201d before dumping data into my Snowflake, which also will get rid of 25 dbt models and lower my Snowflake bills by a run rate of $30k this year.*", "author_fullname": "t2_opyjpm1x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The roast of the modern data stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12acdrk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 62, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680505464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just read this and loved it (who doesn&amp;#39;t like a bit of drama?)! I&amp;#39;m not to well versed, so I&amp;#39;d be interested in hearing what other people in the industry are thinking? Given the previous posts about costs of data teams etc, I think it&amp;#39;s quite interesting.   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@laurengreerbalik/customer-empathy-is-dead-10f412782b5e\"&gt;https://medium.com/@laurengreerbalik/customer-empathy-is-dead-10f412782b5e&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Airbyte is such a joke that Reddit&lt;/em&gt; &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; &lt;em&gt;users \u201cMyDixonsCider\u201d (say that out loud) and \u201cThunderCuntAU\u201d seem to have done more due diligence on Airbyte than any venture capitalist willing to give tens of millions of dollars of other peoples\u2019 money to Airbyte\u2019s founders to make the twentieth-worst version of a data replication EL tool that exists on market.&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I should be firing Fivetran potentially, when all we mostly use it for is Postgres and Salesforce replications, and I should look into Keboola (or similar) which can give me the same thing with better SLA adherence and better uptime for $10k a year and allows me to \u201ctransform and denormalize\u201d before dumping data into my Snowflake, which also will get rid of 25 dbt models and lower my Snowflake bills by a run rate of $30k this year.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Kb5csAa7A2R_K-bXN5tIdgtcw4DTzQtMir9cE-BmxOA.jpg?auto=webp&amp;v=enabled&amp;s=3fe186f30f581409007f9c13188249e177cf3876", "width": 667, "height": 668}, "resolutions": [{"url": "https://external-preview.redd.it/Kb5csAa7A2R_K-bXN5tIdgtcw4DTzQtMir9cE-BmxOA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08bdd8e2ad496235907f68c603d243bfc633a969", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/Kb5csAa7A2R_K-bXN5tIdgtcw4DTzQtMir9cE-BmxOA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24d6cd38cadb2dbac42ab8d364680c07a48031c7", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/Kb5csAa7A2R_K-bXN5tIdgtcw4DTzQtMir9cE-BmxOA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90e2b74056fa4bd92022da5298ed2caf28bee6e8", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/Kb5csAa7A2R_K-bXN5tIdgtcw4DTzQtMir9cE-BmxOA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f88ca9b8fa743c61259dcc016d02372733a1eeb5", "width": 640, "height": 640}], "variants": {}, "id": "Z57inWsHlf2DtghpGCHs36ZdZlpktVyZzo041Nbs5LA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12acdrk", "is_robot_indexable": true, "report_reasons": null, "author": "CalleKeboola", "discussion_type": null, "num_comments": 69, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12acdrk/the_roast_of_the_modern_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12acdrk/the_roast_of_the_modern_data_stack/", "subreddit_subscribers": 95679, "created_utc": 1680505464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_34twt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parquet: more than just \"Turbo CSV\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_12al33e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kDz2FtSxZfuo8nsWRVgJjHhzhpnkfAZv-HNu7_u9JnY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680529800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "csvbase.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://csvbase.com/blog/3", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qO6j-Oc50yisyKVVOCCfqO4EoVnf2OSvAwAr3zR07A8.jpg?auto=webp&amp;v=enabled&amp;s=eb063fe1d0f31434c427e80392457b4df5d3529b", "width": 800, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qO6j-Oc50yisyKVVOCCfqO4EoVnf2OSvAwAr3zR07A8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0dd3d76a43223524cdc72db650cefdf3b311d56", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/qO6j-Oc50yisyKVVOCCfqO4EoVnf2OSvAwAr3zR07A8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af1a87545730f3e2dfabab418431189de2c7da8d", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/qO6j-Oc50yisyKVVOCCfqO4EoVnf2OSvAwAr3zR07A8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95679e111fdd0a760ebb59daaef9d08ef54d6433", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/qO6j-Oc50yisyKVVOCCfqO4EoVnf2OSvAwAr3zR07A8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=130e5d87d9ae55aaa23c580a22dd1040d3e847a8", "width": 640, "height": 480}], "variants": {}, "id": "IfQge5tEzdN69CBwaua7mx3ljdv2t0UnAz-SSztYbHM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12al33e", "is_robot_indexable": true, "report_reasons": null, "author": "calp", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12al33e/parquet_more_than_just_turbo_csv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://csvbase.com/blog/3", "subreddit_subscribers": 95679, "created_utc": 1680529800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to put together a growth plan for myself and having a hard time coming up with where I want to be in 2-3 years. I\u2019m looking for examples of how you or you\u2019ve seen others grow as a DE. \n\nAbout myself: I really enjoyed DE-style work in order to run my small side hobbies before I ever got into the industry. I\u2019m E5 level at my current company and I\u2019ve always enjoyed enabling my team to better understand their products through core datasets with scalable offshoots of that.", "author_fullname": "t2_fo0y6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Growth plan ideas for senior data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ajqoz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680526849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to put together a growth plan for myself and having a hard time coming up with where I want to be in 2-3 years. I\u2019m looking for examples of how you or you\u2019ve seen others grow as a DE. &lt;/p&gt;\n\n&lt;p&gt;About myself: I really enjoyed DE-style work in order to run my small side hobbies before I ever got into the industry. I\u2019m E5 level at my current company and I\u2019ve always enjoyed enabling my team to better understand their products through core datasets with scalable offshoots of that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ajqoz", "is_robot_indexable": true, "report_reasons": null, "author": "sharpchicity", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ajqoz/growth_plan_ideas_for_senior_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ajqoz/growth_plan_ideas_for_senior_data_engineer/", "subreddit_subscribers": 95679, "created_utc": 1680526849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear community,\n\nI've developed an online tool that allows loading raw unstructured data from files (csv, xml, json, logs and others) into sql database (ClickHouse) in a normalized and structured way. I.e. it automatically parses data, flattens it (for json and xml), recognizes the type of columns, generates sql schema and imports structured data into the sql tables.   \nThe tool also provides SQL console in the UI that allows transforming data, subquerying loaded data to aggregate, filtering, sorting, etc.   \nFinally, user can share the ingested data via a standard db connector and explore all imported data in other data apps or BI, or download tables as csv, xml, json files. \n\nThe question is:\n\n1. Which niches would this solution be most useful for?\n2. Do you have any specific use cases where you could benefit from it?\n\nThanks for any comments. Also, if you believe that any features are missing from this type of product, I would greatly appreciate it if you could share your thoughts.", "author_fullname": "t2_1z5jdh5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data ingestion product questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ae9cx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680511691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear community,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve developed an online tool that allows loading raw unstructured data from files (csv, xml, json, logs and others) into sql database (ClickHouse) in a normalized and structured way. I.e. it automatically parses data, flattens it (for json and xml), recognizes the type of columns, generates sql schema and imports structured data into the sql tables.&lt;br/&gt;\nThe tool also provides SQL console in the UI that allows transforming data, subquerying loaded data to aggregate, filtering, sorting, etc.&lt;br/&gt;\nFinally, user can share the ingested data via a standard db connector and explore all imported data in other data apps or BI, or download tables as csv, xml, json files. &lt;/p&gt;\n\n&lt;p&gt;The question is:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Which niches would this solution be most useful for?&lt;/li&gt;\n&lt;li&gt;Do you have any specific use cases where you could benefit from it?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks for any comments. Also, if you believe that any features are missing from this type of product, I would greatly appreciate it if you could share your thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ae9cx", "is_robot_indexable": true, "report_reasons": null, "author": "Greg_Z_", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ae9cx/data_ingestion_product_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ae9cx/data_ingestion_product_questions/", "subreddit_subscribers": 95679, "created_utc": 1680511691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Preferably open source, preferably free, definitely hosted in-house, but anything that isn't too ridiculously expensive would be considered.\n\nThere's so many options, most of which either a) have zero documentation, not even system requirements, b) won't tell you what it costs until after a demo (that will inevitably be a waste of time with high pressure sales pitches), c) obscenely expensive (with subscription fees), or d) so complicated to set up as to be impossible (see a)).", "author_fullname": "t2_c8eislj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anybody recommend a document management system?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12a969n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680495488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Preferably open source, preferably free, definitely hosted in-house, but anything that isn&amp;#39;t too ridiculously expensive would be considered.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s so many options, most of which either a) have zero documentation, not even system requirements, b) won&amp;#39;t tell you what it costs until after a demo (that will inevitably be a waste of time with high pressure sales pitches), c) obscenely expensive (with subscription fees), or d) so complicated to set up as to be impossible (see a)).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12a969n", "is_robot_indexable": true, "report_reasons": null, "author": "DwaywelayTOP", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12a969n/can_anybody_recommend_a_document_management_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12a969n/can_anybody_recommend_a_document_management_system/", "subreddit_subscribers": 95679, "created_utc": 1680495488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started out doing a lot of data infrastructure work and python/airflow development during my career as a data engineer.\n\n\n\n\nHowever, I was transferred to a new team at the beginning of the year where I manage several ELT pipelines and a very large SQL codebase.  Most of my development nowadays is in SQL, and I haven't been doing much python or devops work compared to the past.\n\n\n\n\n\nHow can I get back to python/data infrastructure work?  The vast majority of data engineering jobs in my area are only SQL, and my company isn't hiring data infrastructure focused data engineers currently.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get a python/data infrastructure focused data engineering role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12awqmv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680553738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started out doing a lot of data infrastructure work and python/airflow development during my career as a data engineer.&lt;/p&gt;\n\n&lt;p&gt;However, I was transferred to a new team at the beginning of the year where I manage several ELT pipelines and a very large SQL codebase.  Most of my development nowadays is in SQL, and I haven&amp;#39;t been doing much python or devops work compared to the past.&lt;/p&gt;\n\n&lt;p&gt;How can I get back to python/data infrastructure work?  The vast majority of data engineering jobs in my area are only SQL, and my company isn&amp;#39;t hiring data infrastructure focused data engineers currently.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12awqmv", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12awqmv/how_to_get_a_pythondata_infrastructure_focused/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12awqmv/how_to_get_a_pythondata_infrastructure_focused/", "subreddit_subscribers": 95679, "created_utc": 1680553738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://sqlmesh.com/\n\nSQLMesh has native support for reading dbt projects. \n\nIt allows you to build safe incremental models with SQL. No Jinja required. Courtesy of SQLglot. \n\nComes bundled with DuckDB for testing. \n\nIt looks like a more pleasant experience. \n\nThoughts?", "author_fullname": "t2_74pfheof", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A dbt killer is born (SQLMesh)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12b6fgb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680575088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://sqlmesh.com/\"&gt;https://sqlmesh.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;SQLMesh has native support for reading dbt projects. &lt;/p&gt;\n\n&lt;p&gt;It allows you to build safe incremental models with SQL. No Jinja required. Courtesy of SQLglot. &lt;/p&gt;\n\n&lt;p&gt;Comes bundled with DuckDB for testing. &lt;/p&gt;\n\n&lt;p&gt;It looks like a more pleasant experience. &lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12b6fgb", "is_robot_indexable": true, "report_reasons": null, "author": "No_Equivalent5942", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12b6fgb/a_dbt_killer_is_born_sqlmesh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12b6fgb/a_dbt_killer_is_born_sqlmesh/", "subreddit_subscribers": 95679, "created_utc": 1680575088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I see Polars has bindings for Rust, Python, and NodeJS. Is there any interoperability between them?\n\nIf I have a Python or Rust backend serving data out to NodeJS frontend apps, is there any way of working natively in Polars (vs serializing/deserializing JSON back and forth)?\n\nLike a \u201cPolars API\u201d or something where backend and frontend are just taking Polars?\n\nOr, perhaps even if we still have to serialize/deserialize over HTTP, there would still be a benefit to having the backend and frontend working with the same data concepts.", "author_fullname": "t2_nz4bc66t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Polars in Python and NodeJS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12b578m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680572132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see Polars has bindings for Rust, Python, and NodeJS. Is there any interoperability between them?&lt;/p&gt;\n\n&lt;p&gt;If I have a Python or Rust backend serving data out to NodeJS frontend apps, is there any way of working natively in Polars (vs serializing/deserializing JSON back and forth)?&lt;/p&gt;\n\n&lt;p&gt;Like a \u201cPolars API\u201d or something where backend and frontend are just taking Polars?&lt;/p&gt;\n\n&lt;p&gt;Or, perhaps even if we still have to serialize/deserialize over HTTP, there would still be a benefit to having the backend and frontend working with the same data concepts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12b578m", "is_robot_indexable": true, "report_reasons": null, "author": "PlausibleNinja", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12b578m/polars_in_python_and_nodejs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12b578m/polars_in_python_and_nodejs/", "subreddit_subscribers": 95679, "created_utc": 1680572132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am working for 1 year now in a german company on data topics and managing projects for several data driven usecases as well as establishing data products in our company.\n\nI want to go with my team to a nice conference - as I have a strong Java/Software Engineering background - I am not very familiar with popular conferences data engineering / data in general.\n\nCan someone give me advice about nice conferences in Europe which are worth to visit?\n\nI would prefer a general, vendor agnostic conference.", "author_fullname": "t2_jky21", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Conferences 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12axbt2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680554913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am working for 1 year now in a german company on data topics and managing projects for several data driven usecases as well as establishing data products in our company.&lt;/p&gt;\n\n&lt;p&gt;I want to go with my team to a nice conference - as I have a strong Java/Software Engineering background - I am not very familiar with popular conferences data engineering / data in general.&lt;/p&gt;\n\n&lt;p&gt;Can someone give me advice about nice conferences in Europe which are worth to visit?&lt;/p&gt;\n\n&lt;p&gt;I would prefer a general, vendor agnostic conference.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12axbt2", "is_robot_indexable": true, "report_reasons": null, "author": "mikugo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12axbt2/data_engineering_conferences_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12axbt2/data_engineering_conferences_2023/", "subreddit_subscribers": 95679, "created_utc": 1680554913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\n&amp;#x200B;\n\nTLDR; we are doing a lot of forecasting on time series data and are currently using SQL databases for storing the data. We are wanting to switch over to time series databases like InfluxDB or AWS Timestream.\n\n&amp;#x200B;\n\nAny suggestions ? Do you have any experience with time series DBs? Is the switch worth it ?", "author_fullname": "t2_2i1av4aw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using time series databases ? InfluxDB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12aca4z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680505165.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;TLDR; we are doing a lot of forecasting on time series data and are currently using SQL databases for storing the data. We are wanting to switch over to time series databases like InfluxDB or AWS Timestream.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any suggestions ? Do you have any experience with time series DBs? Is the switch worth it ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12aca4z", "is_robot_indexable": true, "report_reasons": null, "author": "younggamech", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12aca4z/using_time_series_databases_influxdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12aca4z/using_time_series_databases_influxdb/", "subreddit_subscribers": 95679, "created_utc": 1680505165.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to migrate a Database with multiple schemas from SQL Server to Databricks Delta Lake. What is the equivalent of SQL Server's schema in databricks? In the unity catalog database or schema is the same and we put tables directly in the databricks database. Do I need to create multiple databases to account for each schema in SQL Server?", "author_fullname": "t2_c9y3v2w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Server to Databricks Delta Lake Unity Catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12abg1s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680502385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to migrate a Database with multiple schemas from SQL Server to Databricks Delta Lake. What is the equivalent of SQL Server&amp;#39;s schema in databricks? In the unity catalog database or schema is the same and we put tables directly in the databricks database. Do I need to create multiple databases to account for each schema in SQL Server?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12abg1s", "is_robot_indexable": true, "report_reasons": null, "author": "mdghouse1986", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12abg1s/sql_server_to_databricks_delta_lake_unity_catalog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12abg1s/sql_server_to_databricks_delta_lake_unity_catalog/", "subreddit_subscribers": 95679, "created_utc": 1680502385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Connection here is for postgresql and we are running a test for null values.  \n\n\nHere is the sample code for Airflow:  \n\n\n    from airflow import DAG\n    from airflow.operators.python_operator import PythonOperator\n    from datetime import datetime\n    import psycopg2\n    \n    def check_null_or_empty():\n        # Set up a connection to the PostgreSQL database\n        conn = psycopg2.connect(\n            host=\"your_host_name\",\n            database=\"your_database_name\",\n            user=\"your_username\",\n            password=\"your_password\"\n        )\n    \n        # Open a cursor to perform database operations\n        cur = conn.cursor()\n    \n        # Define the query to run\n        query = \"SELECT COUNT(*) FROM users WHERE column_name IS NULL OR column_name=''\"\n    \n        # Execute the query\n        cur.execute(query)\n    \n        # Fetch the results\n        result = cur.fetchone()[0]\n    \n        # Close the cursor and the connection\n        cur.close()\n        conn.close()\n    \n        # Raise an error if the result is not 0\n        if result != 0:\n            raise ValueError(f\"Data quality check failed. {result} rows have null or empty values in column_name.\")\n        else:\n            print(\"Data quality check passed. All rows have a value in column_name.\")\n    \n    # Define the DAG\n    dag = DAG('data_quality_dag', description='Data quality check for null or empty values in users.column_name',\n              schedule_interval='@daily', start_date=datetime(2023, 4, 1))\n    \n    # Define the task\n    check_null_or_empty_task = PythonOperator(task_id='check_null_or_empty', python_callable=check_null_or_empty, dag=dag)\n    \n    # Define the task order\n    check_null_or_empty_task\n\nNot lets take the example of GE:  \n\n\n    name: data_quality_check\n    \n    steps:\n      - name: check_null_or_empty\n        action:\n          module_name: great_expectations.dataset.sqlalchemy_dataset\n          class_name: SqlAlchemyDataset\n          datasource: your_postgresql_datasource\n          batch_kwargs:\n            table: users\n            schema: public\n          expectation_suite_name: data_quality_check\n          action_list_operator: OR\n          failing_expectation_results_in_triggered_actions: True\n          action_on_failure:\n            exit: True\n            message: \"Data quality check failed. {{ result['result'] }} rows have null or empty values in column_name.\"\n        expectations:\n          - expectation_type: not_null\n            kwargs:\n              column: column_name\n          - expectation_type: expect_column_values_to_not_be_null\n            kwargs:\n              column: column_name\n          - expectation_type: expect_column_values_to_not_be_empty\n            kwargs:\n              column: column_name\n    \n    datasources:\n      your_postgresql_datasource:\n        class_name: Datasource\n        module_name: great_expectations.datasource\n        credentials:\n          username: your_username\n          password: your_password\n        module_name: great_expectations.datasource\n        class_name: SqlAlchemyDatasource\n        data_asset_type:\n          module_name: great_expectations.dataset\n          class_name: SqlAlchemyDataset\n        credentials:\n          username: your_username\n          password: your_password\n        drivername: postgresql\n        host: your_host_name\n        port: 5432\n        database: your_database_name\n        schema: public", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Sample Code] : Data quality null check for Airflow vs GreatExpectations [GE]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12aao4m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680499971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Connection here is for postgresql and we are running a test for null values.  &lt;/p&gt;\n\n&lt;p&gt;Here is the sample code for Airflow:  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\nfrom datetime import datetime\nimport psycopg2\n\ndef check_null_or_empty():\n    # Set up a connection to the PostgreSQL database\n    conn = psycopg2.connect(\n        host=&amp;quot;your_host_name&amp;quot;,\n        database=&amp;quot;your_database_name&amp;quot;,\n        user=&amp;quot;your_username&amp;quot;,\n        password=&amp;quot;your_password&amp;quot;\n    )\n\n    # Open a cursor to perform database operations\n    cur = conn.cursor()\n\n    # Define the query to run\n    query = &amp;quot;SELECT COUNT(*) FROM users WHERE column_name IS NULL OR column_name=&amp;#39;&amp;#39;&amp;quot;\n\n    # Execute the query\n    cur.execute(query)\n\n    # Fetch the results\n    result = cur.fetchone()[0]\n\n    # Close the cursor and the connection\n    cur.close()\n    conn.close()\n\n    # Raise an error if the result is not 0\n    if result != 0:\n        raise ValueError(f&amp;quot;Data quality check failed. {result} rows have null or empty values in column_name.&amp;quot;)\n    else:\n        print(&amp;quot;Data quality check passed. All rows have a value in column_name.&amp;quot;)\n\n# Define the DAG\ndag = DAG(&amp;#39;data_quality_dag&amp;#39;, description=&amp;#39;Data quality check for null or empty values in users.column_name&amp;#39;,\n          schedule_interval=&amp;#39;@daily&amp;#39;, start_date=datetime(2023, 4, 1))\n\n# Define the task\ncheck_null_or_empty_task = PythonOperator(task_id=&amp;#39;check_null_or_empty&amp;#39;, python_callable=check_null_or_empty, dag=dag)\n\n# Define the task order\ncheck_null_or_empty_task\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Not lets take the example of GE:  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;name: data_quality_check\n\nsteps:\n  - name: check_null_or_empty\n    action:\n      module_name: great_expectations.dataset.sqlalchemy_dataset\n      class_name: SqlAlchemyDataset\n      datasource: your_postgresql_datasource\n      batch_kwargs:\n        table: users\n        schema: public\n      expectation_suite_name: data_quality_check\n      action_list_operator: OR\n      failing_expectation_results_in_triggered_actions: True\n      action_on_failure:\n        exit: True\n        message: &amp;quot;Data quality check failed. {{ result[&amp;#39;result&amp;#39;] }} rows have null or empty values in column_name.&amp;quot;\n    expectations:\n      - expectation_type: not_null\n        kwargs:\n          column: column_name\n      - expectation_type: expect_column_values_to_not_be_null\n        kwargs:\n          column: column_name\n      - expectation_type: expect_column_values_to_not_be_empty\n        kwargs:\n          column: column_name\n\ndatasources:\n  your_postgresql_datasource:\n    class_name: Datasource\n    module_name: great_expectations.datasource\n    credentials:\n      username: your_username\n      password: your_password\n    module_name: great_expectations.datasource\n    class_name: SqlAlchemyDatasource\n    data_asset_type:\n      module_name: great_expectations.dataset\n      class_name: SqlAlchemyDataset\n    credentials:\n      username: your_username\n      password: your_password\n    drivername: postgresql\n    host: your_host_name\n    port: 5432\n    database: your_database_name\n    schema: public\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12aao4m", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12aao4m/sample_code_data_quality_null_check_for_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12aao4m/sample_code_data_quality_null_check_for_airflow/", "subreddit_subscribers": 95679, "created_utc": 1680499971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently working as a controls engineering  (1yr) with a degree in industrial engineering, minor in data analysis. I\u2019m just curious if anyone has made a similar jump, how you did it, and how you would improve it if you did it again? Thanks for reading!", "author_fullname": "t2_zl24e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Controls Engineer Migration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12aajgp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680499580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently working as a controls engineering  (1yr) with a degree in industrial engineering, minor in data analysis. I\u2019m just curious if anyone has made a similar jump, how you did it, and how you would improve it if you did it again? Thanks for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12aajgp", "is_robot_indexable": true, "report_reasons": null, "author": "MrGreat_Value", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12aajgp/controls_engineer_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12aajgp/controls_engineer_migration/", "subreddit_subscribers": 95679, "created_utc": 1680499580.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys! First post here in this sub.  \n\n\nI'd like some advice in how to improve our Data Architeture in at our client. Currently I'm a intern at a a consulting firm in Brazil and we are exploring some options on how to improve our clients Architeture.  \n\n\nIr goes as follow:  \n\n\n1. We have a virtual machina which extracts data from SAP and store it at our Data Warehouse (SQL Server) in excract tables.  \n\n2. We consume this data at our ETL pipelines via Azure Data Factory, currently using Data Flow to perform transformations to  such as Joins, Filters... as much as the client requires.  \n\n3. The data is then stored at a temporary table in which we perform some validation and then stored again at our DW  with a view for that specific client/business process which is then made avalaible from the client to consult of feed into his/hers BI tool.  \n\n\nWe are trying to move away from Data Flow (2) into Databricks but are still figuring out the detalis of such a move and if it is a viable option at all. I've done some data transformation with databricks instead of Data Flow but mostly used Pandas instead of PySpark and as far as I've heard, the later is much more efficient at dealing with larger datasets.   \n\n\nTables extracted from SAP can have from 10k to 10kk rows, so I pretty sure any given process may need some exemptions according to data size.  \n\n\n  \nAny tips are appreciated!!", "author_fullname": "t2_4hycmkaa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help improving Data Architeture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12b08cb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680560914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys! First post here in this sub.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like some advice in how to improve our Data Architeture in at our client. Currently I&amp;#39;m a intern at a a consulting firm in Brazil and we are exploring some options on how to improve our clients Architeture.  &lt;/p&gt;\n\n&lt;p&gt;Ir goes as follow:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;We have a virtual machina which extracts data from SAP and store it at our Data Warehouse (SQL Server) in excract tables.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;We consume this data at our ETL pipelines via Azure Data Factory, currently using Data Flow to perform transformations to  such as Joins, Filters... as much as the client requires.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The data is then stored at a temporary table in which we perform some validation and then stored again at our DW  with a view for that specific client/business process which is then made avalaible from the client to consult of feed into his/hers BI tool.  &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We are trying to move away from Data Flow (2) into Databricks but are still figuring out the detalis of such a move and if it is a viable option at all. I&amp;#39;ve done some data transformation with databricks instead of Data Flow but mostly used Pandas instead of PySpark and as far as I&amp;#39;ve heard, the later is much more efficient at dealing with larger datasets.   &lt;/p&gt;\n\n&lt;p&gt;Tables extracted from SAP can have from 10k to 10kk rows, so I pretty sure any given process may need some exemptions according to data size.  &lt;/p&gt;\n\n&lt;p&gt;Any tips are appreciated!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12b08cb", "is_robot_indexable": true, "report_reasons": null, "author": "Lopokik", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12b08cb/help_improving_data_architeture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12b08cb/help_improving_data_architeture/", "subreddit_subscribers": 95679, "created_utc": 1680560914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "so the case is,\n\nI applied for an internship and those guys were offering  AWS course in which,\n\n interns get to be a part of\u00a0**live training on AWS**\u00a0and\u00a0**earn 5 AWS Accreditations**, given out directly by Amazon Web Services.  \nThe\u00a0**5 Accreditations**\u00a0include both\u00a0**technical and business** **modules**. The\u00a0**partial cost**\u00a0of the AWS Accreditations is\u00a0**borne by the organization in the form of a stipend**. And the\u00a0**remaining partial cost**\u00a0is taken up by the intern, which is\u00a0**59 USD**. \n\nThose five certificates are:\n\n \u2022\u00a0*AWS Business Professional Accreditation*  \n\u2022\u00a0*AWS Cloud Economics*  \n\u2022\u00a0*AWS Technical Professional*  \n\u2022\u00a0*AWS Training for Partners Foundation (Business)*  \n\u2022\u00a0*For the last accreditation, there is a choice between\u00a0\u00a02 electives, Machine Learning and Data Science. The candidate can choose which accreditation they would want to pursue.* \n\n\\--&gt; tho I know Learning cloud technologies is important and i am supposedly gonna get a high paying job but I dont know if this is the right choice to make as I have never paid for any online course and I believe I can learn everything for free but for this one I do need certificates to standout and also i wanted to use my parents money as less as possible. \n\n&amp;#x200B;\n\nI have AWS cloud practitioner level knowledge.", "author_fullname": "t2_ddd9jyym", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I enroll in this AWS cloud course? Guidance post!!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12av593", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680550511.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;so the case is,&lt;/p&gt;\n\n&lt;p&gt;I applied for an internship and those guys were offering  AWS course in which,&lt;/p&gt;\n\n&lt;p&gt;interns get to be a part of\u00a0&lt;strong&gt;live training on AWS&lt;/strong&gt;\u00a0and\u00a0&lt;strong&gt;earn 5 AWS Accreditations&lt;/strong&gt;, given out directly by Amazon Web Services.&lt;br/&gt;\nThe\u00a0&lt;strong&gt;5 Accreditations&lt;/strong&gt;\u00a0include both\u00a0&lt;strong&gt;technical and business&lt;/strong&gt; &lt;strong&gt;modules&lt;/strong&gt;. The\u00a0&lt;strong&gt;partial cost&lt;/strong&gt;\u00a0of the AWS Accreditations is\u00a0&lt;strong&gt;borne by the organization in the form of a stipend&lt;/strong&gt;. And the\u00a0&lt;strong&gt;remaining partial cost&lt;/strong&gt;\u00a0is taken up by the intern, which is\u00a0&lt;strong&gt;59 USD&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;Those five certificates are:&lt;/p&gt;\n\n&lt;p&gt;\u2022\u00a0&lt;em&gt;AWS Business Professional Accreditation&lt;/em&gt;&lt;br/&gt;\n\u2022\u00a0&lt;em&gt;AWS Cloud Economics&lt;/em&gt;&lt;br/&gt;\n\u2022\u00a0&lt;em&gt;AWS Technical Professional&lt;/em&gt;&lt;br/&gt;\n\u2022\u00a0&lt;em&gt;AWS Training for Partners Foundation (Business)&lt;/em&gt;&lt;br/&gt;\n\u2022\u00a0&lt;em&gt;For the last accreditation, there is a choice between\u00a0\u00a02 electives, Machine Learning and Data Science. The candidate can choose which accreditation they would want to pursue.&lt;/em&gt; &lt;/p&gt;\n\n&lt;p&gt;--&amp;gt; tho I know Learning cloud technologies is important and i am supposedly gonna get a high paying job but I dont know if this is the right choice to make as I have never paid for any online course and I believe I can learn everything for free but for this one I do need certificates to standout and also i wanted to use my parents money as less as possible. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have AWS cloud practitioner level knowledge.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12av593", "is_robot_indexable": true, "report_reasons": null, "author": "AaDI-TYA", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12av593/should_i_enroll_in_this_aws_cloud_course_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12av593/should_i_enroll_in_this_aws_cloud_course_guidance/", "subreddit_subscribers": 95679, "created_utc": 1680550511.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This post discusses about some key skills/technolgy that are used widely in the data engineering landscape. Your dream employment as a data engineer will be within reach with these skills.\n\n[https://blogs.sibyabin.tech/dataengineering/tech/hot-skills-for-dataengineers-in-2023/](https://blogs.sibyabin.tech/dataengineering/tech/hot-skills-for-dataengineers-in-2023/)\n\nhttps://preview.redd.it/di2d0h160qra1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c6c4c0f74bd53a48b98c101bd33ec4e9ab5bf492", "author_fullname": "t2_c4myu4hh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Top skills in 2023 that will help you land your dream data engineering job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"di2d0h160qra1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/di2d0h160qra1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5247a922299cdbe277e8351f7bfb8f0f5b7b2a1c"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/di2d0h160qra1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b86475c8a235afeab92510580356faf01392d74"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/di2d0h160qra1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e2fa2bab321aa1a6512d4485525b897d8b3accf"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/di2d0h160qra1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e977885e0fb5e1d2a411dd811ce674c91f4ed7b"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/di2d0h160qra1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab8a939055b3c6bc1a7b6a81861e9ee8b5cf4895"}], "s": {"y": 768, "x": 1024, "u": "https://preview.redd.it/di2d0h160qra1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c6c4c0f74bd53a48b98c101bd33ec4e9ab5bf492"}, "id": "di2d0h160qra1"}}, "name": "t3_12ausn7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZljpALCa3lpAajP_hvV-AJTMxUvlPOXpr_qYwVOdSKY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680549803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This post discusses about some key skills/technolgy that are used widely in the data engineering landscape. Your dream employment as a data engineer will be within reach with these skills.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blogs.sibyabin.tech/dataengineering/tech/hot-skills-for-dataengineers-in-2023/\"&gt;https://blogs.sibyabin.tech/dataengineering/tech/hot-skills-for-dataengineers-in-2023/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/di2d0h160qra1.jpg?width=1024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c6c4c0f74bd53a48b98c101bd33ec4e9ab5bf492\"&gt;https://preview.redd.it/di2d0h160qra1.jpg?width=1024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c6c4c0f74bd53a48b98c101bd33ec4e9ab5bf492&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12ausn7", "is_robot_indexable": true, "report_reasons": null, "author": "Satm2021", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12ausn7/top_skills_in_2023_that_will_help_you_land_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ausn7/top_skills_in_2023_that_will_help_you_land_your/", "subreddit_subscribers": 95679, "created_utc": 1680549803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "You get a SQL connection to a vendor created/managed backend that has zero documentation over function or a data dictionary. Tables have 100+ poorly named columns each, majority of which are filled with nulls. What are you gonna do?\n\nI\u2019ve repeatedly experienced this situation and beyond writing some simple python/sql in a notebook that profiles the seemingly useful columns, I\u2019m curious if there\u2019s a better approach. We have some off the shelf software that can do really impressive discovery/profiling but it\u2019s a bit of a pain to setup for every schema/database being looked at for the initial pass through", "author_fullname": "t2_ao7u40a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open Source Data Exploration tools/approach?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12aruh2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680544248.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680543916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You get a SQL connection to a vendor created/managed backend that has zero documentation over function or a data dictionary. Tables have 100+ poorly named columns each, majority of which are filled with nulls. What are you gonna do?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve repeatedly experienced this situation and beyond writing some simple python/sql in a notebook that profiles the seemingly useful columns, I\u2019m curious if there\u2019s a better approach. We have some off the shelf software that can do really impressive discovery/profiling but it\u2019s a bit of a pain to setup for every schema/database being looked at for the initial pass through&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12aruh2", "is_robot_indexable": true, "report_reasons": null, "author": "minormisgnomer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12aruh2/open_source_data_exploration_toolsapproach/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12aruh2/open_source_data_exploration_toolsapproach/", "subreddit_subscribers": 95679, "created_utc": 1680543916.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ui4m14ke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modelling for Data Architects - Points for further deep dive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 38, "top_awarded_type": null, "hide_score": false, "name": "t3_12arpt8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tPNMNuEBgh6pYXncq44fRfVRkBk2tWwkB9YXNIq3hfg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680543660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@anupmoncy/how-to-become-a-data-architect-data-modelling-8b3faac402f4", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?auto=webp&amp;v=enabled&amp;s=f45c3ccedc146666ff336f6994f5bff1da13ecfe", "width": 1200, "height": 330}, "resolutions": [{"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=79080e95e1ace9ddbd0e0919f4510c9dd9560ca1", "width": 108, "height": 29}, {"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b735e113429f6b3609db51088f4cc0dd86cc5fd", "width": 216, "height": 59}, {"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b3da1b26a9b0f6e81f361b7f09212c9b84894a4", "width": 320, "height": 88}, {"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=37bb518e875bf4f24de10e6ddfee8788f4b1ece5", "width": 640, "height": 176}, {"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4601c588b008d71d188c44b4865e2db615cbc578", "width": 960, "height": 264}, {"url": "https://external-preview.redd.it/43-inUTiXvHPaFWTNITf0l_bp7aFbKey_635B4pazM0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c6dd0d70f458a8856ced1edafa8ea5e381d3553", "width": 1080, "height": 297}], "variants": {}, "id": "BlpXO1H7BlpQkVRahLk9smqlyLwQbXRpyMKL-e8At8g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12arpt8", "is_robot_indexable": true, "report_reasons": null, "author": "Alarmed-Sock4915", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12arpt8/data_modelling_for_data_architects_points_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@anupmoncy/how-to-become-a-data-architect-data-modelling-8b3faac402f4", "subreddit_subscribers": 95679, "created_utc": 1680543660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://cumulativedata.com/power-of-functional-data-eng-p1-immutable-data/](https://cumulativedata.com/power-of-functional-data-eng-p1-immutable-data/)", "author_fullname": "t2_bkula0u9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benefits of Immutable Data. Any thoughts on this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12aq8w8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680540707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://cumulativedata.com/power-of-functional-data-eng-p1-immutable-data/\"&gt;https://cumulativedata.com/power-of-functional-data-eng-p1-immutable-data/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?auto=webp&amp;v=enabled&amp;s=aeb3e52e68df613846b3dfe1a916ded0959e2aa6", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b27adcca11ba5d8e17e3169c154c03cc23732cbd", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b1e53994de00b4c43a80aef4ddc597bae9eaacd5", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3364e732c4da3b29306ff7bab63eabb7e12eafec", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a26828dd753b4420f564053899cac6fdfecb8c62", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b270202407da347125290565be8b3bb5f91e44b2", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/9K4NDosRhAZ6KKgBiTz8P3MWmeZNtr8hSfhr8mE-2DE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9eb8184d3947b1157f9e7e266085b88464b397d6", "width": 1080, "height": 607}], "variants": {}, "id": "HheWTeOZ7IR2Kx2CJdqe14TRaZNukZFIIgAkbK15EXg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12aq8w8", "is_robot_indexable": true, "report_reasons": null, "author": "ganildata", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12aq8w8/benefits_of_immutable_data_any_thoughts_on_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12aq8w8/benefits_of_immutable_data_any_thoughts_on_this/", "subreddit_subscribers": 95679, "created_utc": 1680540707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Convert CSV Files into an Apache Iceberg table with Dremio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "name": "t3_12ao2yz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zJLYGk27_trmg3IH-_G6_WbU1yek7ofr3Env6Cnyrzg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680536183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dremio.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dremio.com/blog/how-to-convert-csv-files-into-an-apache-iceberg-table-with-dremio/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zxtJIagLDWZpguzI98Z8v1WVgeWXJPiJyJ0u1CfrlI0.jpg?auto=webp&amp;v=enabled&amp;s=d5d907b9a9975befd2ec14af693fffd7f02db06a", "width": 769, "height": 383}, "resolutions": [{"url": "https://external-preview.redd.it/zxtJIagLDWZpguzI98Z8v1WVgeWXJPiJyJ0u1CfrlI0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e5cd0de85bd15073379ab76d6bc47d255ca77a1", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/zxtJIagLDWZpguzI98Z8v1WVgeWXJPiJyJ0u1CfrlI0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=034aa77eea51b1d8efaf2bde8f41a37b7e29ccf8", "width": 216, "height": 107}, {"url": "https://external-preview.redd.it/zxtJIagLDWZpguzI98Z8v1WVgeWXJPiJyJ0u1CfrlI0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c8734975ae57b97cbf48ca73f29181ce08ce63f0", "width": 320, "height": 159}, {"url": "https://external-preview.redd.it/zxtJIagLDWZpguzI98Z8v1WVgeWXJPiJyJ0u1CfrlI0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81fc6c53c4f04461f00db53d2a6c84e9bdcdf64f", "width": 640, "height": 318}], "variants": {}, "id": "xNN4H40qu3ZhdZbvj47-RKZKZmtuObPJoFXNJ9YX5E0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12ao2yz", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ao2yz/how_to_convert_csv_files_into_an_apache_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dremio.com/blog/how-to-convert-csv-files-into-an-apache-iceberg-table-with-dremio/", "subreddit_subscribers": 95679, "created_utc": 1680536183.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uu592ayo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Druid, TiDB, ClickHouse, or Apache Doris? A Comparison of OLAP Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "name": "t3_12amyoq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/KY_eA60Pajpyh40hxXd4AdOyi0jRVD_ZuwSZxOmPjx8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680533813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hackernoon.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://hackernoon.com/apache-druid-tidb-clickhouse-or-apache-doris-a-comparison-of-olap-tools", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/99pDedvXWvN91zPtwZMHoHSINiRo67T40uxD4rP4GL4.jpg?auto=webp&amp;v=enabled&amp;s=9bb5b71e58f9e9a1308bdcebb9a30efe17c6df24", "width": 984, "height": 602}, "resolutions": [{"url": "https://external-preview.redd.it/99pDedvXWvN91zPtwZMHoHSINiRo67T40uxD4rP4GL4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e5c79dd10941c590c5e43dbaaedb86869c4bf4a", "width": 108, "height": 66}, {"url": "https://external-preview.redd.it/99pDedvXWvN91zPtwZMHoHSINiRo67T40uxD4rP4GL4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ee202e59d44b4d3099c5d4762ec74edf7fdc54b", "width": 216, "height": 132}, {"url": "https://external-preview.redd.it/99pDedvXWvN91zPtwZMHoHSINiRo67T40uxD4rP4GL4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98cfb0ecd556ca4b14bcd846e536cd0b5267f46b", "width": 320, "height": 195}, {"url": "https://external-preview.redd.it/99pDedvXWvN91zPtwZMHoHSINiRo67T40uxD4rP4GL4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ced54e027694fe731250129caed940e5b9d47393", "width": 640, "height": 391}, {"url": "https://external-preview.redd.it/99pDedvXWvN91zPtwZMHoHSINiRo67T40uxD4rP4GL4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d79115aa6e82a8c4ca4e228514717844e50bf5c", "width": 960, "height": 587}], "variants": {}, "id": "8jRxUhwcxfTMJ4WTUJ-E9gSvvoRG1BQ2OLWSVMMjKpE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12amyoq", "is_robot_indexable": true, "report_reasons": null, "author": "Any_Opportunity1234", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12amyoq/apache_druid_tidb_clickhouse_or_apache_doris_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://hackernoon.com/apache-druid-tidb-clickhouse-or-apache-doris-a-comparison-of-olap-tools", "subreddit_subscribers": 95679, "created_utc": 1680533813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey, is there any reason to use docker-compose if you can just make a playbook like this:\n\nall commands:\n\n[https://docs.ansible.com/ansible/latest/collections/community/docker/index.html#scenario-guide](https://docs.ansible.com/ansible/latest/collections/community/docker/index.html#scenario-guide)\n\nexample (scroll to bottom):\n\n[https://docs.ansible.com/ansible/latest/collections/community/docker/docker\\_container\\_exec\\_module.html#ansible-collections-community-docker-docker-container-exec-module](https://docs.ansible.com/ansible/latest/collections/community/docker/docker_container_exec_module.html#ansible-collections-community-docker-docker-container-exec-module)\n\nwith ansible you can call on any module, shell script, command line, and it will take care of it.\n\ncompose seems kind of limiting?  wondering if i'm missing something here.\n\nedit:\n\ni'm trying to understand what the benefit of creating a docker-compose.yml file is vs having an ansible playbook which pulls/builds and image, then creates however many containers i want.\n\nwhen i run compose, sometimes i get an issue with one container, and i have to shut down the entire pod vs just simply restarting a container or creating a new one to plug in with some kind of change.  (maybe this is due to my inexperience, but regardless i can't see what the use is vs ansible)\n\ngiven the down votes, people here seem to know some universal truth which i would like to be privy to.", "author_fullname": "t2_5qteskd9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ansible vs docker-compose", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ajf0v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680539442.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680526117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey, is there any reason to use docker-compose if you can just make a playbook like this:&lt;/p&gt;\n\n&lt;p&gt;all commands:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.ansible.com/ansible/latest/collections/community/docker/index.html#scenario-guide\"&gt;https://docs.ansible.com/ansible/latest/collections/community/docker/index.html#scenario-guide&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;example (scroll to bottom):&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.ansible.com/ansible/latest/collections/community/docker/docker_container_exec_module.html#ansible-collections-community-docker-docker-container-exec-module\"&gt;https://docs.ansible.com/ansible/latest/collections/community/docker/docker_container_exec_module.html#ansible-collections-community-docker-docker-container-exec-module&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;with ansible you can call on any module, shell script, command line, and it will take care of it.&lt;/p&gt;\n\n&lt;p&gt;compose seems kind of limiting?  wondering if i&amp;#39;m missing something here.&lt;/p&gt;\n\n&lt;p&gt;edit:&lt;/p&gt;\n\n&lt;p&gt;i&amp;#39;m trying to understand what the benefit of creating a docker-compose.yml file is vs having an ansible playbook which pulls/builds and image, then creates however many containers i want.&lt;/p&gt;\n\n&lt;p&gt;when i run compose, sometimes i get an issue with one container, and i have to shut down the entire pod vs just simply restarting a container or creating a new one to plug in with some kind of change.  (maybe this is due to my inexperience, but regardless i can&amp;#39;t see what the use is vs ansible)&lt;/p&gt;\n\n&lt;p&gt;given the down votes, people here seem to know some universal truth which i would like to be privy to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ajf0v", "is_robot_indexable": true, "report_reasons": null, "author": "iseestupid", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ajf0v/ansible_vs_dockercompose/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ajf0v/ansible_vs_dockercompose/", "subreddit_subscribers": 95679, "created_utc": 1680526117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://dev.to/memphis\\_dev/batch-processing-vs-stream-processing-why-batch-is-dying-and-streaming-takes-over-3dg8](https://dev.to/memphis_dev/batch-processing-vs-stream-processing-why-batch-is-dying-and-streaming-takes-over-3dg8)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Batch Processing vs Stream Processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12afo94", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680516565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://dev.to/memphis_dev/batch-processing-vs-stream-processing-why-batch-is-dying-and-streaming-takes-over-3dg8\"&gt;https://dev.to/memphis_dev/batch-processing-vs-stream-processing-why-batch-is-dying-and-streaming-takes-over-3dg8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3jyVPMhmOi0ULs46doDyMfY1nWu-rwNeCl97Qdity3U.jpg?auto=webp&amp;v=enabled&amp;s=c26eb9209007fec9a01b12f972de7d29da3b9649", "width": 1000, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/3jyVPMhmOi0ULs46doDyMfY1nWu-rwNeCl97Qdity3U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12f18f667423b5aeb381fe04cab9f3a1494ece9e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/3jyVPMhmOi0ULs46doDyMfY1nWu-rwNeCl97Qdity3U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4dba95685cd306ec58b41e072d68b971402f4409", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/3jyVPMhmOi0ULs46doDyMfY1nWu-rwNeCl97Qdity3U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bfdea54e8cfd846bde0df5d2452e9ebd6765eaa8", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/3jyVPMhmOi0ULs46doDyMfY1nWu-rwNeCl97Qdity3U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ee2a29e9aaecc548c9a630d5f273ce5e8ad2d76", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/3jyVPMhmOi0ULs46doDyMfY1nWu-rwNeCl97Qdity3U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f709675c841fac955ac9a22a160e3d77053dfbe9", "width": 960, "height": 480}], "variants": {}, "id": "z7WymFOQ5skMjTyghkdaNwKqo4_IMUPdurNewct71M8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12afo94", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12afo94/batch_processing_vs_stream_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12afo94/batch_processing_vs_stream_processing/", "subreddit_subscribers": 95679, "created_utc": 1680516565.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}