{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, let me preface this: **I understand this is a very general ask and therefore I can only expect very general responses.**\n\nI am most likely going to transition from my current data scientist role into a data analytics role because it aligns better with my interests and skillset. I know that generally speaking, the data scientist's salary is higher than that of the data analyst, but I also expect I will be able to leverage my experience to get a more senior role within data analytics that I am hoping will at least offset the difference.\n\nMy current role is an Associate-level Data Scientist, and my target role will be a Senior-level Data Analyst. Again, **I know there are a lot of variables at play here**, but in a very general sense, what do people think I should expect salary-wise? A slight decrease? Slight increase? Roughly the same?\n\nAny and all input is appreciated. Thanks all!", "author_fullname": "t2_ngcpuv32", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salary expectations moving from data science into data analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q8oaq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 143, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 143, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681788406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, let me preface this: &lt;strong&gt;I understand this is a very general ask and therefore I can only expect very general responses.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I am most likely going to transition from my current data scientist role into a data analytics role because it aligns better with my interests and skillset. I know that generally speaking, the data scientist&amp;#39;s salary is higher than that of the data analyst, but I also expect I will be able to leverage my experience to get a more senior role within data analytics that I am hoping will at least offset the difference.&lt;/p&gt;\n\n&lt;p&gt;My current role is an Associate-level Data Scientist, and my target role will be a Senior-level Data Analyst. Again, &lt;strong&gt;I know there are a lot of variables at play here&lt;/strong&gt;, but in a very general sense, what do people think I should expect salary-wise? A slight decrease? Slight increase? Roughly the same?&lt;/p&gt;\n\n&lt;p&gt;Any and all input is appreciated. Thanks all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q8oaq", "is_robot_indexable": true, "report_reasons": null, "author": "abnormal_oats", "discussion_type": null, "num_comments": 91, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q8oaq/salary_expectations_moving_from_data_science_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q8oaq/salary_expectations_moving_from_data_science_into/", "subreddit_subscribers": 875898, "created_utc": 1681788406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This particular project is for client-facing stakeholders. My team lead and I are tasked with automating several of their data-driven slides on Tableau that they currently manually produce not sure how or where.\n\nOne particular slide is a pie chart (yeah, I know) that splits the data into ~10 different segments or so, each with its % of market share.\n\nWe did so, and they complained that the numbers percentage points add up to 98%.\n\nWe explained that it's because of rounding, and if we included the decimal it would add up to 100%.\n\nThey started going on about how they present this to CFOs and they'll ask why it doesn't add up to 100% and it has to be perfect and etc.\n\nSo we offered to show the decimal, but nope, can't do that because it's \"hard to read.\"\n\nRemember how they produce those manually at the moment? They said, and I quote, \"sometimes I change a 3% to a 4% to make it work, because what's 1% more?\"\n\nI can kind of understand changing 20% to 21%, because that's only a 5% difference. But really, 3% to 4%? A whopping 33% difference?\n\nAnyway, I'm not about to tell them how to do their job, since I can barely do mine. Lord knows I have no idea how to automate this arbitrary number-fudging on Tableau, so I'll have to figure that one out (it has to be automated so that it adds up to 100% no matter what data ranges the user chooses). \n\nBut I just wonder, how hard is it to tell a CFO \"yeah, it doesn't add up to 100% because of rounding, but if we included the decimals it would\"?", "author_fullname": "t2_9g0ib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I was just asked to fudge the numbers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qzs1k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 93, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 93, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681843364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This particular project is for client-facing stakeholders. My team lead and I are tasked with automating several of their data-driven slides on Tableau that they currently manually produce not sure how or where.&lt;/p&gt;\n\n&lt;p&gt;One particular slide is a pie chart (yeah, I know) that splits the data into ~10 different segments or so, each with its % of market share.&lt;/p&gt;\n\n&lt;p&gt;We did so, and they complained that the numbers percentage points add up to 98%.&lt;/p&gt;\n\n&lt;p&gt;We explained that it&amp;#39;s because of rounding, and if we included the decimal it would add up to 100%.&lt;/p&gt;\n\n&lt;p&gt;They started going on about how they present this to CFOs and they&amp;#39;ll ask why it doesn&amp;#39;t add up to 100% and it has to be perfect and etc.&lt;/p&gt;\n\n&lt;p&gt;So we offered to show the decimal, but nope, can&amp;#39;t do that because it&amp;#39;s &amp;quot;hard to read.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Remember how they produce those manually at the moment? They said, and I quote, &amp;quot;sometimes I change a 3% to a 4% to make it work, because what&amp;#39;s 1% more?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I can kind of understand changing 20% to 21%, because that&amp;#39;s only a 5% difference. But really, 3% to 4%? A whopping 33% difference?&lt;/p&gt;\n\n&lt;p&gt;Anyway, I&amp;#39;m not about to tell them how to do their job, since I can barely do mine. Lord knows I have no idea how to automate this arbitrary number-fudging on Tableau, so I&amp;#39;ll have to figure that one out (it has to be automated so that it adds up to 100% no matter what data ranges the user chooses). &lt;/p&gt;\n\n&lt;p&gt;But I just wonder, how hard is it to tell a CFO &amp;quot;yeah, it doesn&amp;#39;t add up to 100% because of rounding, but if we included the decimals it would&amp;quot;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qzs1k", "is_robot_indexable": true, "report_reasons": null, "author": "Malarazz", "discussion_type": null, "num_comments": 73, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qzs1k/i_was_just_asked_to_fudge_the_numbers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qzs1k/i_was_just_asked_to_fudge_the_numbers/", "subreddit_subscribers": 875898, "created_utc": 1681843364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m fortunate to be with a company, and on a project, that does not go on hiring sprees, and due to its market niche rarely lays off data science folks. I\u2019m newish here, and thankfully have a straightforward role doing exploratory analysis and some people management, but I want to make myself less disposable. I meet deadlines, and get good feedback on my work, but I want to develop skills that will make me more valuable to management.\n\nWhat are you all doing to make your position more secure?", "author_fullname": "t2_7fs1p26vi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What skills make you less dispensable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qs1ib", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681832074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m fortunate to be with a company, and on a project, that does not go on hiring sprees, and due to its market niche rarely lays off data science folks. I\u2019m newish here, and thankfully have a straightforward role doing exploratory analysis and some people management, but I want to make myself less disposable. I meet deadlines, and get good feedback on my work, but I want to develop skills that will make me more valuable to management.&lt;/p&gt;\n\n&lt;p&gt;What are you all doing to make your position more secure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qs1ib", "is_robot_indexable": true, "report_reasons": null, "author": "Cannoli_Emma", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qs1ib/what_skills_make_you_less_dispensable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qs1ib/what_skills_make_you_less_dispensable/", "subreddit_subscribers": 875898, "created_utc": 1681832074.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am having a business problem, where we used to send some metrics Numbers each day, by putting them into excel sheet,  and send them to each stakeholders \n\nI have used Python to automate the numbers, and send the stakeholders daily mails using smtp lib.\n\nBut that doesn't  looks nice to present them to stakeholders like, CEO ,\n\nSo, I just wanna know, can we replicate this view using CSS/HTML or any other method,\n\nif yes, which method would work? I am data analyst So dont have any idea in css html or any other ,\n\n&amp;#x200B;\n\nhttps://preview.redd.it/yh9wlmk0xmua1.png?width=1073&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=245e3cb63690ed90500f7907803a01857d141144", "author_fullname": "t2_agvtvokn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replicating a sheet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"yh9wlmk0xmua1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 177, "x": 108, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ff7756410f3eff1a130b849b9733885d6cbbe71"}, {"y": 354, "x": 216, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a330aca0093670629bdfb7c2d8eea74925eb44e8"}, {"y": 525, "x": 320, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9cedccd7673911d2cb53e763715c91d52ef7a5b"}, {"y": 1050, "x": 640, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5278ca7cab7a0e72f6fce20abe0491ca5182860b"}, {"y": 1575, "x": 960, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd92b7bf8f9bf0b60daf7879c2010376c3209941"}], "s": {"y": 1761, "x": 1073, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=1073&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=245e3cb63690ed90500f7907803a01857d141144"}, "id": "yh9wlmk0xmua1"}}, "name": "t3_12ql37a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CIVfGZm5nguI7lUIpCWOZ9xw4WgLmAzBMvYI162AuBM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681820093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am having a business problem, where we used to send some metrics Numbers each day, by putting them into excel sheet,  and send them to each stakeholders &lt;/p&gt;\n\n&lt;p&gt;I have used Python to automate the numbers, and send the stakeholders daily mails using smtp lib.&lt;/p&gt;\n\n&lt;p&gt;But that doesn&amp;#39;t  looks nice to present them to stakeholders like, CEO ,&lt;/p&gt;\n\n&lt;p&gt;So, I just wanna know, can we replicate this view using CSS/HTML or any other method,&lt;/p&gt;\n\n&lt;p&gt;if yes, which method would work? I am data analyst So dont have any idea in css html or any other ,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yh9wlmk0xmua1.png?width=1073&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=245e3cb63690ed90500f7907803a01857d141144\"&gt;https://preview.redd.it/yh9wlmk0xmua1.png?width=1073&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=245e3cb63690ed90500f7907803a01857d141144&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ql37a", "is_robot_indexable": true, "report_reasons": null, "author": "chilly_tomato", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ql37a/replicating_a_sheet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ql37a/replicating_a_sheet/", "subreddit_subscribers": 875898, "created_utc": 1681820093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How do you guys deal with date time features ( like transaction time stamp) when training classifiers ? I extract hour, minute, weekday number, month and year as new features. Should I drop the date time column as I am not sure how a logistic regression model would treat it for example.", "author_fullname": "t2_9atv3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Date time features in tree based models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qtd9o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681833611.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you guys deal with date time features ( like transaction time stamp) when training classifiers ? I extract hour, minute, weekday number, month and year as new features. Should I drop the date time column as I am not sure how a logistic regression model would treat it for example.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qtd9o", "is_robot_indexable": true, "report_reasons": null, "author": "longgamma", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qtd9o/date_time_features_in_tree_based_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qtd9o/date_time_features_in_tree_based_models/", "subreddit_subscribers": 875898, "created_utc": 1681833611.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it normal that companies are not serious about hiring, take very long time and getting an offer is just not common\n\nI\u2019m not talking about job boards. Is it normal that you find a lot of positions that have not been posted yet, through perhaps word of mouth or recommendations, those companies constantly say you\u2019re perfect for this, will send you an offer shortly, then just don\u2019t? \n\nI have not quite experienced this in other fields. Maybe it takes too much to be in this field, and it\u2019s better to pursue something else? I never heard of so much playing around, or not knowing what they want?  ( career level: experienced)\n\nThis happened 3 times in the last month. Basically you\u2019re the chosen candidate, there are  no other candidates, let me just draft up the papers, then nothing or rejection. Also no questions in interviews or tests? They just reiterate your resume to you and how they know you\u2019d be a perfect fit", "author_fullname": "t2_6h5h5k7v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hiring practices particular to this field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qp3p8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681828525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it normal that companies are not serious about hiring, take very long time and getting an offer is just not common&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not talking about job boards. Is it normal that you find a lot of positions that have not been posted yet, through perhaps word of mouth or recommendations, those companies constantly say you\u2019re perfect for this, will send you an offer shortly, then just don\u2019t? &lt;/p&gt;\n\n&lt;p&gt;I have not quite experienced this in other fields. Maybe it takes too much to be in this field, and it\u2019s better to pursue something else? I never heard of so much playing around, or not knowing what they want?  ( career level: experienced)&lt;/p&gt;\n\n&lt;p&gt;This happened 3 times in the last month. Basically you\u2019re the chosen candidate, there are  no other candidates, let me just draft up the papers, then nothing or rejection. Also no questions in interviews or tests? They just reiterate your resume to you and how they know you\u2019d be a perfect fit&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qp3p8", "is_robot_indexable": true, "report_reasons": null, "author": "DerpyOwlofParadise", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qp3p8/hiring_practices_particular_to_this_field/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qp3p8/hiring_practices_particular_to_this_field/", "subreddit_subscribers": 875898, "created_utc": 1681828525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "From my understanding, ML algorithms can work best if seasonality or trends are removed to make the time series data stationary.\n\nIf I have multivariate time series data, I should ensure that its stationary before feeding the data into a model such as random forest. One question I have that is unanswered, when should I make the time series stationary? Before splitting into train and test? Additionally, if I wanted to resample hourly observations in my time series to get a daily average, would I perform the resampling after I split the data set into train and test, and after I make it stationary? \n\nI want to find what variables from my time series have the largest predictability or highest significance for predicting a value.", "author_fullname": "t2_atmge", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time Series Data Preparation - Random Forest Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12r773z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681857474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From my understanding, ML algorithms can work best if seasonality or trends are removed to make the time series data stationary.&lt;/p&gt;\n\n&lt;p&gt;If I have multivariate time series data, I should ensure that its stationary before feeding the data into a model such as random forest. One question I have that is unanswered, when should I make the time series stationary? Before splitting into train and test? Additionally, if I wanted to resample hourly observations in my time series to get a daily average, would I perform the resampling after I split the data set into train and test, and after I make it stationary? &lt;/p&gt;\n\n&lt;p&gt;I want to find what variables from my time series have the largest predictability or highest significance for predicting a value.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12r773z", "is_robot_indexable": true, "report_reasons": null, "author": "cdub4200", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12r773z/time_series_data_preparation_random_forest_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12r773z/time_series_data_preparation_random_forest_help/", "subreddit_subscribers": 875898, "created_utc": 1681857474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hi r/datascience\n\nI'm trying to design a method to evaluate the price of an asset given certain features. I have lots of data to work with, so the # of observations is not a real constraint.\n\nBased on my conceptual knowledge of the features, I expect most of them to have a linear/semi-linear relationship with the predicted value except for 2. For these 2 features, I expect the predicted value to have more of a clustering/radial relationship.\n\nI can understand how to model each of the two feature-types and their relationship to the predicted variable separately, but how could I ensure that the interaction between them is captured as well?", "author_fullname": "t2_v406kvhe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Applying Different Statistical Methods to Certain Areas of The Feature Space", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12r79j4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681857610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to design a method to evaluate the price of an asset given certain features. I have lots of data to work with, so the # of observations is not a real constraint.&lt;/p&gt;\n\n&lt;p&gt;Based on my conceptual knowledge of the features, I expect most of them to have a linear/semi-linear relationship with the predicted value except for 2. For these 2 features, I expect the predicted value to have more of a clustering/radial relationship.&lt;/p&gt;\n\n&lt;p&gt;I can understand how to model each of the two feature-types and their relationship to the predicted variable separately, but how could I ensure that the interaction between them is captured as well?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12r79j4", "is_robot_indexable": true, "report_reasons": null, "author": "ryan_s007", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12r79j4/applying_different_statistical_methods_to_certain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12r79j4/applying_different_statistical_methods_to_certain/", "subreddit_subscribers": 875898, "created_utc": 1681857610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How are customers with good credit scores and lenders who offer credit to those with lower scores. Let us say the lender uses a combination of risk based pricing and the use of different data in it\u2019s credit scoring model.", "author_fullname": "t2_jm8x8jsx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Credit Risk Analysis Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12ra25m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681863561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are customers with good credit scores and lenders who offer credit to those with lower scores. Let us say the lender uses a combination of risk based pricing and the use of different data in it\u2019s credit scoring model.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ra25m", "is_robot_indexable": true, "report_reasons": null, "author": "sydneysweeney69", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ra25m/credit_risk_analysis_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ra25m/credit_risk_analysis_question/", "subreddit_subscribers": 875898, "created_utc": 1681863561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Maybe my doubt is dumb, but how would you show on a table the variation between 0 and non-zero number? \n\nFor example: on 2021 I sold 0 cars and on 2022 I sold 4. To calculate the % change from on year to the other I would have to do (4/0)-1, wich is impossible to calculate. Should I just write something like \"increase\"? Or should I just put an * and explain the impossibility?", "author_fullname": "t2_7e27w7hg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to display the result of a division by 0?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12r95u8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681861600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe my doubt is dumb, but how would you show on a table the variation between 0 and non-zero number? &lt;/p&gt;\n\n&lt;p&gt;For example: on 2021 I sold 0 cars and on 2022 I sold 4. To calculate the % change from on year to the other I would have to do (4/0)-1, wich is impossible to calculate. Should I just write something like &amp;quot;increase&amp;quot;? Or should I just put an * and explain the impossibility?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12r95u8", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished-Wave356", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12r95u8/how_to_display_the_result_of_a_division_by_0/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12r95u8/how_to_display_the_result_of_a_division_by_0/", "subreddit_subscribers": 875898, "created_utc": 1681861600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m a masters student I just thought this would be a cool fun side project, and help the community at the same time. \n\nThe council have just put up bollards cutting the town I live in into two halves (increasing drive time in traffic from one half to the other from ~5 to ~30 minutes. \n\nDriving away people from using the towns high street and increasing emissions on school drops offs etc since you know have to drive around the town \n\nI wanted to make a heatmap showing the increase in drive time between a POI (the high street/ the school) and the surrounding area before and after the bollards. \n\nI looked in to using Google\u2019s distance matrix API but I can\u2019t get previous data from before the bollards were put up? \n\nAny thoughts or ways I can better show this increase in non essential travel.\n\n\n\n(I fully understand the scheme what they are trying to do to reduce emissions and grow cyclists/walkers but they haven\u2019t done it efficiently at all I want to show this. )\n\nAny helps much appreciated xD\n\nPreferably in R but I\u2019m comfortable in Python and visualisation systems like power BI", "author_fullname": "t2_9woatez4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drive time heatmap", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qwiea", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681837729.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681837510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a masters student I just thought this would be a cool fun side project, and help the community at the same time. &lt;/p&gt;\n\n&lt;p&gt;The council have just put up bollards cutting the town I live in into two halves (increasing drive time in traffic from one half to the other from ~5 to ~30 minutes. &lt;/p&gt;\n\n&lt;p&gt;Driving away people from using the towns high street and increasing emissions on school drops offs etc since you know have to drive around the town &lt;/p&gt;\n\n&lt;p&gt;I wanted to make a heatmap showing the increase in drive time between a POI (the high street/ the school) and the surrounding area before and after the bollards. &lt;/p&gt;\n\n&lt;p&gt;I looked in to using Google\u2019s distance matrix API but I can\u2019t get previous data from before the bollards were put up? &lt;/p&gt;\n\n&lt;p&gt;Any thoughts or ways I can better show this increase in non essential travel.&lt;/p&gt;\n\n&lt;p&gt;(I fully understand the scheme what they are trying to do to reduce emissions and grow cyclists/walkers but they haven\u2019t done it efficiently at all I want to show this. )&lt;/p&gt;\n\n&lt;p&gt;Any helps much appreciated xD&lt;/p&gt;\n\n&lt;p&gt;Preferably in R but I\u2019m comfortable in Python and visualisation systems like power BI&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qwiea", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Order6450", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qwiea/drive_time_heatmap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qwiea/drive_time_heatmap/", "subreddit_subscribers": 875898, "created_utc": 1681837510.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m trying to back track from survival function down to hazard function which upon dividing by the partial hazard should give the same baseline hazard for any 2 example subjects. Unfortunately predict_hazard function in CoxPHFitter is throwing an error (doesn\u2019t have the attribute apparently, which is v weird). And if I manually get to a hazard function from the cumulative hazard function (not super sure of the calculation), the step after dividing by partial hazard is not the same i.e., 2 different baseline hazards. Any help appreciated.", "author_fullname": "t2_u3vhf5lz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Facing inconsistencies while trying to reconstruct Cox PH predictions by lifelines package", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qltap", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681821775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to back track from survival function down to hazard function which upon dividing by the partial hazard should give the same baseline hazard for any 2 example subjects. Unfortunately predict_hazard function in CoxPHFitter is throwing an error (doesn\u2019t have the attribute apparently, which is v weird). And if I manually get to a hazard function from the cumulative hazard function (not super sure of the calculation), the step after dividing by partial hazard is not the same i.e., 2 different baseline hazards. Any help appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qltap", "is_robot_indexable": true, "report_reasons": null, "author": "thesaintyouneed", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qltap/facing_inconsistencies_while_trying_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qltap/facing_inconsistencies_while_trying_to/", "subreddit_subscribers": 875898, "created_utc": 1681821775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! I am currently writing a series of articles about the pre-processing steps for time series data.  \n\nIn the first article, I suggest the following order: \n\n1. Handle missing values \n2. Remove trend \n3. Remove seasonality \n4. Check for stationarity and make it stationary if necessary \n5. Normalize the data \n6. Remove outliers \n7. Smooth the data \n\nHowever, I know this order is not universal and can be changed depending on our data. Also, not all the steps are always required.  \n\nMy question is, which would be the \"standard\" order that you would suggest?  \n\nI leave the first part of these articles [here](https://mlpills.dev/time-series/clean-your-time-series-data-i/) and the second one [here](https://mlpills.dev/time-series/clean-your-time-series-data-ii/). The last two parts are written but not published yet :( \n\nI'd love to hear some feedback. :)\n\n Thanks!", "author_fullname": "t2_gvvf9r1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pre-processing order for time series data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qi9b4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681812524.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I am currently writing a series of articles about the pre-processing steps for time series data.  &lt;/p&gt;\n\n&lt;p&gt;In the first article, I suggest the following order: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Handle missing values &lt;/li&gt;\n&lt;li&gt;Remove trend &lt;/li&gt;\n&lt;li&gt;Remove seasonality &lt;/li&gt;\n&lt;li&gt;Check for stationarity and make it stationary if necessary &lt;/li&gt;\n&lt;li&gt;Normalize the data &lt;/li&gt;\n&lt;li&gt;Remove outliers &lt;/li&gt;\n&lt;li&gt;Smooth the data &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;However, I know this order is not universal and can be changed depending on our data. Also, not all the steps are always required.  &lt;/p&gt;\n\n&lt;p&gt;My question is, which would be the &amp;quot;standard&amp;quot; order that you would suggest?  &lt;/p&gt;\n\n&lt;p&gt;I leave the first part of these articles &lt;a href=\"https://mlpills.dev/time-series/clean-your-time-series-data-i/\"&gt;here&lt;/a&gt; and the second one &lt;a href=\"https://mlpills.dev/time-series/clean-your-time-series-data-ii/\"&gt;here&lt;/a&gt;. The last two parts are written but not published yet :( &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear some feedback. :)&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?auto=webp&amp;v=enabled&amp;s=2e987cc53a9606585b9baea3b9c3056362d77e3f", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b73276f3c7bed3898752484fca308aad5f66cc0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e2fa795d34a622e420f1f36e8388f25a2ac8789", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=358d8be8f2dd2edc85977a8aa927b07835df2b53", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b01d8de571f37cfff87ee9b58097cff988258d1", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0d9065265650f0e4234b339bc7f47411a7c790b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8de1b636fa63a6391629a2acd3898bee1f5f405", "width": 1080, "height": 607}], "variants": {}, "id": "z2mUwpw_935DsBDU4V1KJzNU_rF0PEhxMVMa8oVerhk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qi9b4", "is_robot_indexable": true, "report_reasons": null, "author": "daansan-ml", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qi9b4/preprocessing_order_for_time_series_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qi9b4/preprocessing_order_for_time_series_data/", "subreddit_subscribers": 875898, "created_utc": 1681812524.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hi! right now im looking to major in cs at georgia tech, and i'm not sure how much of a pipeline that leaves me out of undergrad. if i want to get in to data science out of undergrad, what might i need to do? does anyone have any experiences to share?\n\nim thinking of doing computational data analysis as a minor, infosystems and intelligence as \"subfocuses\" within my major, and i plan on joining some data science and ML bootcamps and clubs.... any other suggestions?\n\ni want to stick to a comp sci major, because i still want a good compsci foundation, just in case i dont end up enjoying ds. ", "author_fullname": "t2_5rc1mk09o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what might i need to get into data science as an undergrad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q7dbo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681785696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi! right now im looking to major in cs at georgia tech, and i&amp;#39;m not sure how much of a pipeline that leaves me out of undergrad. if i want to get in to data science out of undergrad, what might i need to do? does anyone have any experiences to share?&lt;/p&gt;\n\n&lt;p&gt;im thinking of doing computational data analysis as a minor, infosystems and intelligence as &amp;quot;subfocuses&amp;quot; within my major, and i plan on joining some data science and ML bootcamps and clubs.... any other suggestions?&lt;/p&gt;\n\n&lt;p&gt;i want to stick to a comp sci major, because i still want a good compsci foundation, just in case i dont end up enjoying ds. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q7dbo", "is_robot_indexable": true, "report_reasons": null, "author": "desperate_DS_student", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q7dbo/what_might_i_need_to_get_into_data_science_as_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q7dbo/what_might_i_need_to_get_into_data_science_as_an/", "subreddit_subscribers": 875898, "created_utc": 1681785696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hey r/datascience. \n\nI come from a business background and over the years have slowly made my way to data analysis and now moving to data science. However, one thing I noticed from other professionals that come from a computer science background is their more intricate knowledge of the tools and their interactions. Mid 2000's. after getting tired of Excel + VBA I started working with SQL. When programming languages became a necessity for my work, I learned Python (also some JavaScript, but that's not here nor there). after getting to the point I needed more number crunching and statistical approaches, I learned R. I don't consider myself an expert, but I at least understand the tools.... separately, at least. Now that I'm formally doing my masters, more than once I have been jumping from software to software, not to mention when doing collaborations (all my work so far was done by me and for me, only the insights and reports needed to be shared, so no one else ever worked on my codes), I have no idea on how to setup everything.   \n\nSo, I came here to ask: What is a good workflow and best practices to start with? Currently, most of my work is done either on PyCharm (for more complex coding), Jupiter (for EDA) and RStudio (for R). Regarding git and GitHub, I only ever used it through RStudio (other than the bash shell, of course). However, is there go-to approach where I can use the same tool for everything (or for most part of it)? I know how to do what I need, just not an efficient way to do it specially if I have to work with others.", "author_fullname": "t2_fna4qb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with workflow and best practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q9wxe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681791112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;I come from a business background and over the years have slowly made my way to data analysis and now moving to data science. However, one thing I noticed from other professionals that come from a computer science background is their more intricate knowledge of the tools and their interactions. Mid 2000&amp;#39;s. after getting tired of Excel + VBA I started working with SQL. When programming languages became a necessity for my work, I learned Python (also some JavaScript, but that&amp;#39;s not here nor there). after getting to the point I needed more number crunching and statistical approaches, I learned R. I don&amp;#39;t consider myself an expert, but I at least understand the tools.... separately, at least. Now that I&amp;#39;m formally doing my masters, more than once I have been jumping from software to software, not to mention when doing collaborations (all my work so far was done by me and for me, only the insights and reports needed to be shared, so no one else ever worked on my codes), I have no idea on how to setup everything.   &lt;/p&gt;\n\n&lt;p&gt;So, I came here to ask: What is a good workflow and best practices to start with? Currently, most of my work is done either on PyCharm (for more complex coding), Jupiter (for EDA) and RStudio (for R). Regarding git and GitHub, I only ever used it through RStudio (other than the bash shell, of course). However, is there go-to approach where I can use the same tool for everything (or for most part of it)? I know how to do what I need, just not an efficient way to do it specially if I have to work with others.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q9wxe", "is_robot_indexable": true, "report_reasons": null, "author": "rpcsanches", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q9wxe/help_with_workflow_and_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q9wxe/help_with_workflow_and_best_practices/", "subreddit_subscribers": 875898, "created_utc": 1681791112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in the middle of studying Economics outside the US (i.e. Brazil). I've studied Python, R and SQL for data science with more intensity since few months ago and increasing the study of statistics and math. I know that most data scientists are statisticians, mathematicians, etc. But I'm really interested in the field of data science. \n\nThen, I'm thinking of doing a master's degree in any field that will enhance my ability to become a data scientist and probably apply to a job in US in the future... \n\nWhat master's degree do I need to do after studying Economics, especially in my case (are there any senior economists that become a DS here to share their point of view?)? Should I start thinking about applying to any internship in data analysis to develop a good portfolio right now?\n\nAnyway, I'm open to suggestions. Tyvm :)", "author_fullname": "t2_e3lj119b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm a Economics Student", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q6gp8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681784565.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681783878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the middle of studying Economics outside the US (i.e. Brazil). I&amp;#39;ve studied Python, R and SQL for data science with more intensity since few months ago and increasing the study of statistics and math. I know that most data scientists are statisticians, mathematicians, etc. But I&amp;#39;m really interested in the field of data science. &lt;/p&gt;\n\n&lt;p&gt;Then, I&amp;#39;m thinking of doing a master&amp;#39;s degree in any field that will enhance my ability to become a data scientist and probably apply to a job in US in the future... &lt;/p&gt;\n\n&lt;p&gt;What master&amp;#39;s degree do I need to do after studying Economics, especially in my case (are there any senior economists that become a DS here to share their point of view?)? Should I start thinking about applying to any internship in data analysis to develop a good portfolio right now?&lt;/p&gt;\n\n&lt;p&gt;Anyway, I&amp;#39;m open to suggestions. Tyvm :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q6gp8", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic_Bite6696", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q6gp8/im_a_economics_student/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q6gp8/im_a_economics_student/", "subreddit_subscribers": 875898, "created_utc": 1681783878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "ClickHouse is one of the fastest SQL engines in the world. But installing and maintaining a Clickhouse server is not easy.\n\nNow, you can run complex SQL blazing fast with chDB which is an embedded Clickhouse engine in Python.\n\n# features\n\n* In-process SQL OLAP Engine, powered by ClickHouse\n* No need to install ClickHouse\n* Minimized data copy from C++ to Python with [python memoryview](https://docs.python.org/3/c-api/memoryview.html)\n* Input&amp;Output support Parquet, CSV, JSON, Arrow, ORC and [more](https://clickhouse.com/docs/en/interfaces/formats)\n\n# install\n```bash\npip install chdb\n```\n\n# examples\nRun any SQL in just one line\n```python\nimport chdb\nres = chdb.query('select * from file(\"data.parquet\", Parquet)', 'Dataframe')\nprint res\n```\n\n- PyPi: https://pypi.org/project/chdb/\n- GitHub: https://github.com/auxten/chdb\n\n&gt; Due to the size of the engine, the first SQL could be slow.", "author_fullname": "t2_5x6me", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Run SQL blazing fast with the embedded Clickhouse engine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qopcr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681827774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ClickHouse is one of the fastest SQL engines in the world. But installing and maintaining a Clickhouse server is not easy.&lt;/p&gt;\n\n&lt;p&gt;Now, you can run complex SQL blazing fast with chDB which is an embedded Clickhouse engine in Python.&lt;/p&gt;\n\n&lt;h1&gt;features&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;In-process SQL OLAP Engine, powered by ClickHouse&lt;/li&gt;\n&lt;li&gt;No need to install ClickHouse&lt;/li&gt;\n&lt;li&gt;Minimized data copy from C++ to Python with &lt;a href=\"https://docs.python.org/3/c-api/memoryview.html\"&gt;python memoryview&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Input&amp;amp;Output support Parquet, CSV, JSON, Arrow, ORC and &lt;a href=\"https://clickhouse.com/docs/en/interfaces/formats\"&gt;more&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;install&lt;/h1&gt;\n\n&lt;p&gt;&lt;code&gt;bash\npip install chdb\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;h1&gt;examples&lt;/h1&gt;\n\n&lt;p&gt;Run any SQL in just one line\n&lt;code&gt;python\nimport chdb\nres = chdb.query(&amp;#39;select * from file(&amp;quot;data.parquet&amp;quot;, Parquet)&amp;#39;, &amp;#39;Dataframe&amp;#39;)\nprint res\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;PyPi: &lt;a href=\"https://pypi.org/project/chdb/\"&gt;https://pypi.org/project/chdb/&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;GitHub: &lt;a href=\"https://github.com/auxten/chdb\"&gt;https://github.com/auxten/chdb&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Due to the size of the engine, the first SQL could be slow.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uQnwG5vj0W2B8UmXvnpbBF8bitWWN9ApOpjGDNFekLw.jpg?auto=webp&amp;v=enabled&amp;s=8cffb70177a255a5d273f49b07a192aae79dd5d1", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/uQnwG5vj0W2B8UmXvnpbBF8bitWWN9ApOpjGDNFekLw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00b81de315991e3643052ea46585a6ef9bd8c2d5", "width": 108, "height": 108}], "variants": {}, "id": "qsyApzksUdlxqY7z2ubJCNmhQilhXIOl25dSHcQQLB4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qopcr", "is_robot_indexable": true, "report_reasons": null, "author": "auxten", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qopcr/run_sql_blazing_fast_with_the_embedded_clickhouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qopcr/run_sql_blazing_fast_with_the_embedded_clickhouse/", "subreddit_subscribers": 875898, "created_utc": 1681827774.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have an HR screening interview for a data analyst role and wonder what questions will be asked. I know some common questions like tell me about yourself, what are you interested in this role? Why this company?Biggest accomplishment? Do you have any thoughts on other types of questions?", "author_fullname": "t2_8lzodaki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HR Screening Interview for half an hour", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qevdw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681803127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an HR screening interview for a data analyst role and wonder what questions will be asked. I know some common questions like tell me about yourself, what are you interested in this role? Why this company?Biggest accomplishment? Do you have any thoughts on other types of questions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qevdw", "is_robot_indexable": true, "report_reasons": null, "author": "Hidimbaa", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qevdw/hr_screening_interview_for_half_an_hour/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qevdw/hr_screening_interview_for_half_an_hour/", "subreddit_subscribers": 875898, "created_utc": 1681803127.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A data set including 700,000 pictures of industrial items with defects is given to you. The only thing you are aware of is that every image contains at least one obvious flaw. But you don't know where the flaw is or what kind of problem it is. Build a classifier that can distinguish between pieces that are OK and those that are defective. What would be your strategy?\n\n**Edit** : \nWhat would you say - if I would try to use an algorithm to try to match each image with one another, and transform an image via homography from one to another and try to find the difference between the images. Build an image which has all common features and then augment 80% of the images to remove all defects, but still have all variations of image perspectives. Would this be possible?", "author_fullname": "t2_30m20xwn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datascience Challenge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qij3w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.31, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681820860.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681813262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A data set including 700,000 pictures of industrial items with defects is given to you. The only thing you are aware of is that every image contains at least one obvious flaw. But you don&amp;#39;t know where the flaw is or what kind of problem it is. Build a classifier that can distinguish between pieces that are OK and those that are defective. What would be your strategy?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit&lt;/strong&gt; : \nWhat would you say - if I would try to use an algorithm to try to match each image with one another, and transform an image via homography from one to another and try to find the difference between the images. Build an image which has all common features and then augment 80% of the images to remove all defects, but still have all variations of image perspectives. Would this be possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qij3w", "is_robot_indexable": true, "report_reasons": null, "author": "_synaps_", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qij3w/datascience_challenge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qij3w/datascience_challenge/", "subreddit_subscribers": 875898, "created_utc": 1681813262.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}