{"kind": "Listing", "data": {"after": "t3_13175gr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello Homelab enthusiasts and Data Hoarders!\n\n45Drives here to talk about a new project that we are super excited about. We\u2019ve realized it\u2019s time to build a home lab-level storage server.\n\nWhy now? Over the years, enthusiasts repeatedly told us they wanted to get in on the action at home, but didn\u2019t have the funds to spend on servers aimed at the enterprise level. Also, many of us at 45Drives are homelab community members, and love computing as hobby in addition to a profession. They tell us they\u2019d love to have something at home. Our design team had a time slot, and we just thought it was time to take up this challenge.\n\nBut, when we sat down to design, we ended up with a bunch of questions that we couldn\u2019t answer on our own. We realized that we needed guidance from the community itself. Here we are asking you (with the kind permission of the moderators), to help guide the development of this product.\n\nBelow is a design brief outlining our ideas so far, none of which are written in stone. We will finish the post with a specific design question. Other questions will follow in future posts.\n\n&amp;#x200B;\n\n**Design brief:**  \n45Drives is known for building large and powerful data storage servers for the enterprise and B2B market. Our products are open-source and open-platform, built to last with upgradeability and the right to repair in mind. But our professional servers are overkill for most homelabs, like keeping an 18-wheeler in your driveway for personal use \u2013 they are simply too big and cost too much.\n\nWe also realize that there are many home NAS products on the market. They are practical and work as advertised. But they are built offshore to a price point. We believe they are adequate but underwhelming for the homelab world. By analogy, they are an economy car with a utility trailer.\n\nWe believe there is a space in between, that falls right in the enthusiast world. It is the computer storage equivalent of a heavy-duty pickup truck \u2013 big and strong, carrying some of the character of the 18-wheeler, but scaled appropriately for home labs, in size and price. That\u2019s what we are trying to  \ncreate.\n\nhttps://preview.redd.it/4ry53i77hfwa1.png?width=1944&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f4d8e2910f08398a65759d18afcecbadb82241bc\n\nThis server will need to meet a price point that makes sense for home, so there will be tradeoffs. It probably doesn\u2019t have a 64-core processor or a TB of RAM. Professional high-density products start at $7500; while off-shore-made, 4-drive systems might be $600 or so. We are thinking $2000 as a target price currently.\n\nWe want something physically well designed. This server will be hackable, easily serviceable, upgradeable, and retain the character of our enterprise servers. Running Linux/ ZFS, with the HoustonUI management layer (and the command line available for those who prefer it).\n\nConnectivity is the chokepoint for any capable storage server, so it\u2019s a critical design point. We are thinking of building around the assumption of single or dual 2.5Gb ports.\n\nThe electronics in a storage-only server are best optimized when they can saturate connectivity. Any more processing power or memory give no further return. This probably defines a base model.\n\nSome may be interested in convergence, running things like Plex or other media servers, NextCloud, video surveillance DVR, etc.\u00a0 That requires extra computing and memory, which could define higher performance models.\n\n&amp;#x200B;\n\nWe\u2019ve narrowed it down, but now we need your help to figure out what best meets the community\u2019s needs.\u00a0 So, here\u2019s our first question:\n\n**What physical form factor would you like to see? Should this be a 2U rackmount (to be installed in a rack or just sit on a shelf)? Is it a tower desktop? Any ideas for other interesting physical forms?** \n\nWe look forward to working together on this project. Thanks!", "author_fullname": "t2_hcrp0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "45Drives Needs Your Help Developing a Homelab Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 31, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4ry53i77hfwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 24, "x": 108, "u": "https://preview.redd.it/4ry53i77hfwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0653171c1734b0a9c4015b6214354ba75cd85d74"}, {"y": 48, "x": 216, "u": "https://preview.redd.it/4ry53i77hfwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e42a019f16cbfb18c8a6e4377016b31b69820ca"}, {"y": 71, "x": 320, "u": "https://preview.redd.it/4ry53i77hfwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=59c5f72a5e32f948a875242c4b06433b1b2e5647"}, {"y": 142, "x": 640, "u": "https://preview.redd.it/4ry53i77hfwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a02b8f75b142ac96d9632ef73acf8aadf2706fcb"}, {"y": 213, "x": 960, "u": "https://preview.redd.it/4ry53i77hfwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ef207e4b2b1c53b1b40a90cf7674a97cbe34be9"}, {"y": 240, "x": 1080, "u": "https://preview.redd.it/4ry53i77hfwa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2cc96fcc3953f46142d10a13337256b4a2f931d1"}], "s": {"y": 432, "x": 1944, "u": "https://preview.redd.it/4ry53i77hfwa1.png?width=1944&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f4d8e2910f08398a65759d18afcecbadb82241bc"}, "id": "4ry53i77hfwa1"}}, "name": "t3_130m860", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": "", "subreddit_type": "public", "ups": 262, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 262, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/wblYJdmVxodHZGyPrtcWh1mBt7HLULiIXhlSPG2RCE8.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682602183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Homelab enthusiasts and Data Hoarders!&lt;/p&gt;\n\n&lt;p&gt;45Drives here to talk about a new project that we are super excited about. We\u2019ve realized it\u2019s time to build a home lab-level storage server.&lt;/p&gt;\n\n&lt;p&gt;Why now? Over the years, enthusiasts repeatedly told us they wanted to get in on the action at home, but didn\u2019t have the funds to spend on servers aimed at the enterprise level. Also, many of us at 45Drives are homelab community members, and love computing as hobby in addition to a profession. They tell us they\u2019d love to have something at home. Our design team had a time slot, and we just thought it was time to take up this challenge.&lt;/p&gt;\n\n&lt;p&gt;But, when we sat down to design, we ended up with a bunch of questions that we couldn\u2019t answer on our own. We realized that we needed guidance from the community itself. Here we are asking you (with the kind permission of the moderators), to help guide the development of this product.&lt;/p&gt;\n\n&lt;p&gt;Below is a design brief outlining our ideas so far, none of which are written in stone. We will finish the post with a specific design question. Other questions will follow in future posts.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Design brief:&lt;/strong&gt;&lt;br/&gt;\n45Drives is known for building large and powerful data storage servers for the enterprise and B2B market. Our products are open-source and open-platform, built to last with upgradeability and the right to repair in mind. But our professional servers are overkill for most homelabs, like keeping an 18-wheeler in your driveway for personal use \u2013 they are simply too big and cost too much.&lt;/p&gt;\n\n&lt;p&gt;We also realize that there are many home NAS products on the market. They are practical and work as advertised. But they are built offshore to a price point. We believe they are adequate but underwhelming for the homelab world. By analogy, they are an economy car with a utility trailer.&lt;/p&gt;\n\n&lt;p&gt;We believe there is a space in between, that falls right in the enthusiast world. It is the computer storage equivalent of a heavy-duty pickup truck \u2013 big and strong, carrying some of the character of the 18-wheeler, but scaled appropriately for home labs, in size and price. That\u2019s what we are trying to&lt;br/&gt;\ncreate.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4ry53i77hfwa1.png?width=1944&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f4d8e2910f08398a65759d18afcecbadb82241bc\"&gt;https://preview.redd.it/4ry53i77hfwa1.png?width=1944&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f4d8e2910f08398a65759d18afcecbadb82241bc&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This server will need to meet a price point that makes sense for home, so there will be tradeoffs. It probably doesn\u2019t have a 64-core processor or a TB of RAM. Professional high-density products start at $7500; while off-shore-made, 4-drive systems might be $600 or so. We are thinking $2000 as a target price currently.&lt;/p&gt;\n\n&lt;p&gt;We want something physically well designed. This server will be hackable, easily serviceable, upgradeable, and retain the character of our enterprise servers. Running Linux/ ZFS, with the HoustonUI management layer (and the command line available for those who prefer it).&lt;/p&gt;\n\n&lt;p&gt;Connectivity is the chokepoint for any capable storage server, so it\u2019s a critical design point. We are thinking of building around the assumption of single or dual 2.5Gb ports.&lt;/p&gt;\n\n&lt;p&gt;The electronics in a storage-only server are best optimized when they can saturate connectivity. Any more processing power or memory give no further return. This probably defines a base model.&lt;/p&gt;\n\n&lt;p&gt;Some may be interested in convergence, running things like Plex or other media servers, NextCloud, video surveillance DVR, etc.\u00a0 That requires extra computing and memory, which could define higher performance models.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We\u2019ve narrowed it down, but now we need your help to figure out what best meets the community\u2019s needs.\u00a0 So, here\u2019s our first question:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What physical form factor would you like to see? Should this be a 2U rackmount (to be installed in a rack or just sit on a shelf)? Is it a tower desktop? Any ideas for other interesting physical forms?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;We look forward to working together on this project. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1PB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "130m860", "is_robot_indexable": true, "report_reasons": null, "author": "cmcgean45", "discussion_type": null, "num_comments": 233, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/130m860/45drives_needs_your_help_developing_a_homelab/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/130m860/45drives_needs_your_help_developing_a_homelab/", "subreddit_subscribers": 680082, "created_utc": 1682602183.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Has anyone saved this master piece?", "author_fullname": "t2_51p8x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Farscape 4K Remaster AI was recently uploaded to youtube. DMCA shut it down.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131f4mp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 109, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 109, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682649054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone saved this master piece?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "131f4mp", "is_robot_indexable": true, "report_reasons": null, "author": "fmjk45a", "discussion_type": null, "num_comments": 73, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/131f4mp/farscape_4k_remaster_ai_was_recently_uploaded_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/131f4mp/farscape_4k_remaster_ai_was_recently_uploaded_to/", "subreddit_subscribers": 680082, "created_utc": 1682649054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "San Francisco Board of Supervisors Unanimously Passes Resolution in Support of Digital Rights For Libraries | Internet Archive Blogs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1317bzq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_11rvc4", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Open_Access_tracking", "selftext": "", "author_fullname": "t2_2jdf6qz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "San Francisco Board of Supervisors Unanimously Passes Resolution in Support of Digital Rights For Libraries | Internet Archive Blogs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Open_Access_tracking", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1312mgy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "restricted", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "cb45153c-18b8-11e9-879a-0ed88a49fb8c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1682622385.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.archive.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.archive.org/2023/04/20/san-francisco-board-of-supervisors-unanimously-passes-resolution-in-support-of-digital-rights-for-libraries/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "OATP bot", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_qsver", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1312mgy", "is_robot_indexable": true, "report_reasons": null, "author": "Open_Access_tracking", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/Open_Access_tracking/comments/1312mgy/san_francisco_board_of_supervisors_unanimously/", "parent_whitelist_status": null, "stickied": false, "url": "https://blog.archive.org/2023/04/20/san-francisco-board-of-supervisors-unanimously-passes-resolution-in-support-of-digital-rights-for-libraries/", "subreddit_subscribers": 657, "created_utc": 1682622385.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1682630176.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.archive.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.archive.org/2023/04/20/san-francisco-board-of-supervisors-unanimously-passes-resolution-in-support-of-digital-rights-for-libraries/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1317bzq", "is_robot_indexable": true, "report_reasons": null, "author": "FruityWelsh", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1312mgy", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1317bzq/san_francisco_board_of_supervisors_unanimously/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.archive.org/2023/04/20/san-francisco-board-of-supervisors-unanimously-passes-resolution-in-support-of-digital-rights-for-libraries/", "subreddit_subscribers": 680082, "created_utc": 1682630176.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://changelog.com/podcast/537", "author_fullname": "t2_9vo91a1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Andy Klein from Backblaze talks about hard drive reliability at scale in The Changelog podcast", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130tla9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682611430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://changelog.com/podcast/537\"&gt;https://changelog.com/podcast/537&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/86KzRlkNqEZH6fasgiKcpPBJLC1ycMD9GClrwRX8SUU.jpg?auto=webp&amp;v=enabled&amp;s=3185d72095106b839e08b95f1125a8c1e219fed2", "width": 3000, "height": 1688}, "resolutions": [{"url": "https://external-preview.redd.it/86KzRlkNqEZH6fasgiKcpPBJLC1ycMD9GClrwRX8SUU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e3415a0f3ef43a5a49f034292015b280e6731b1", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/86KzRlkNqEZH6fasgiKcpPBJLC1ycMD9GClrwRX8SUU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c031f8ccbb4b92bdd667b320255f856fe2196b1f", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/86KzRlkNqEZH6fasgiKcpPBJLC1ycMD9GClrwRX8SUU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ddc359a7bd015eea18d2bfb80ced76a49b069ed", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/86KzRlkNqEZH6fasgiKcpPBJLC1ycMD9GClrwRX8SUU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a122fc2a9ae424532934bf121d5e2cf1b880db91", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/86KzRlkNqEZH6fasgiKcpPBJLC1ycMD9GClrwRX8SUU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9416f5487f95657b8b18fd6012fd7e3f999e9844", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/86KzRlkNqEZH6fasgiKcpPBJLC1ycMD9GClrwRX8SUU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4ca8723e78d931d13e60506b8733851c4af2e4e", "width": 1080, "height": 607}], "variants": {}, "id": "ASbLTzi2wodPQPSCEVm2nvTOcD47_aSnObO4LFAgOs4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "130tla9", "is_robot_indexable": true, "report_reasons": null, "author": "danlim93", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/130tla9/andy_klein_from_backblaze_talks_about_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/130tla9/andy_klein_from_backblaze_talks_about_hard_drive/", "subreddit_subscribers": 680082, "created_utc": 1682611430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an i5-9600k, 64gb of 3200mhz ddr4 and some various drives. 1tb Samsung 870 for boot, 1tb Samsung 970 nvme for cache and an 8TB WD-Red plus nas. I want to be able to run plex, a minecraft server and mass storage for the plex. What operating system should I use?", "author_fullname": "t2_14k9gl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best operating system for mass storage, plex and a minecraft server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13100ab", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682617860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an i5-9600k, 64gb of 3200mhz ddr4 and some various drives. 1tb Samsung 870 for boot, 1tb Samsung 970 nvme for cache and an 8TB WD-Red plus nas. I want to be able to run plex, a minecraft server and mass storage for the plex. What operating system should I use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13100ab", "is_robot_indexable": true, "report_reasons": null, "author": "DumbGrandsonPeptalk", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13100ab/best_operating_system_for_mass_storage_plex_and_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13100ab/best_operating_system_for_mass_storage_plex_and_a/", "subreddit_subscribers": 680082, "created_utc": 1682617860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'll be going with a 2TB 980 Pro otherwise", "author_fullname": "t2_9bci9al5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any 4TB M.2 SSD's that use TLC NAND or are they all QLC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131daak", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682643967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll be going with a 2TB 980 Pro otherwise&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "131daak", "is_robot_indexable": true, "report_reasons": null, "author": "CompleteMoron_203", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/131daak/are_there_any_4tb_m2_ssds_that_use_tlc_nand_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/131daak/are_there_any_4tb_m2_ssds_that_use_tlc_nand_or/", "subreddit_subscribers": 680082, "created_utc": 1682643967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My family has been using Marco Polo to share videos. I'd like to download the videos from the last year and copy them on to thumb drives I can give to family members. \n\nIt would be nice if there is a \"portable apps\" kind of program like google photos that would let me tag videos with people and location, etc, that would make searching through the videos easier.", "author_fullname": "t2_8looig91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Photos like software to manage videos on a USB thumb drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131asur", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682637499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My family has been using Marco Polo to share videos. I&amp;#39;d like to download the videos from the last year and copy them on to thumb drives I can give to family members. &lt;/p&gt;\n\n&lt;p&gt;It would be nice if there is a &amp;quot;portable apps&amp;quot; kind of program like google photos that would let me tag videos with people and location, etc, that would make searching through the videos easier.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "131asur", "is_robot_indexable": true, "report_reasons": null, "author": "RedbloodJarvey", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/131asur/google_photos_like_software_to_manage_videos_on_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/131asur/google_photos_like_software_to_manage_videos_on_a/", "subreddit_subscribers": 680082, "created_utc": 1682637499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a local (not online/web) software program that can be used to manage a large library of files?\n\nFor example, I have a massive e-book library.  It is messy.  But enormous.  They are all simply inside of a folder.  It works, but not always.  Sometimes it is hard to find a file that you want to find.\n\nIt would be great if I had a software solution that let me organize them with extra metadata - like Subject/Genre and A short description.\n\nAnother problem, all my medical research studies.  I don't want to rename the original filenames because I don't want to download duplicates.  If I keep the original filename, I can assure that I will never download the same study twice.  But I need to be able to sort through them and search when I want to read them or reference them.  How can I create a personal, offline database that allows me to add metadata, like a short description, personal notes, and a Proper Title to each file (without changing the original filename)?  There has to be a software solution for this that exists.\n\n**TL;DR**\n\n**There has to be some type of software program that allows you to create your own personal database for files (like thousands of PDFs) that lets you make it into a searchable library with the ability to add descriptions to each file, genre/subject, etc.  I'd like to keep the libraries separate too.  One for books.  One for medical studies.**\n\n**Things like Plex exist for giant video libraries.  What about books?  What about medical studies?**", "author_fullname": "t2_vr55ge7t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A better way to manage a giant library of files instead of Windows/Linux file manager?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13175s8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682630107.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682629925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a local (not online/web) software program that can be used to manage a large library of files?&lt;/p&gt;\n\n&lt;p&gt;For example, I have a massive e-book library.  It is messy.  But enormous.  They are all simply inside of a folder.  It works, but not always.  Sometimes it is hard to find a file that you want to find.&lt;/p&gt;\n\n&lt;p&gt;It would be great if I had a software solution that let me organize them with extra metadata - like Subject/Genre and A short description.&lt;/p&gt;\n\n&lt;p&gt;Another problem, all my medical research studies.  I don&amp;#39;t want to rename the original filenames because I don&amp;#39;t want to download duplicates.  If I keep the original filename, I can assure that I will never download the same study twice.  But I need to be able to sort through them and search when I want to read them or reference them.  How can I create a personal, offline database that allows me to add metadata, like a short description, personal notes, and a Proper Title to each file (without changing the original filename)?  There has to be a software solution for this that exists.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;There has to be some type of software program that allows you to create your own personal database for files (like thousands of PDFs) that lets you make it into a searchable library with the ability to add descriptions to each file, genre/subject, etc.  I&amp;#39;d like to keep the libraries separate too.  One for books.  One for medical studies.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Things like Plex exist for giant video libraries.  What about books?  What about medical studies?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13175s8", "is_robot_indexable": true, "report_reasons": null, "author": "GrandyRetroCandy", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13175s8/a_better_way_to_manage_a_giant_library_of_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13175s8/a_better_way_to_manage_a_giant_library_of_files/", "subreddit_subscribers": 680082, "created_utc": 1682629925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After becoming convinced a renewed MDD drive I received is actually an Exos X18 in disguise, I did a firmware update dry run and Seatools seems to agree with me.  Anyone else ever try un-white labelling their drive like this?  I've backed up all data so worst case scenario I have a bricked 14GB drive.  Thought I'd check here for any fellow mad scientists before I pull the trigger.  \n\n\n`SeaChest_Firmware_x64_windows.exe -d PD21 --fwdlDryRun --downloadFW .\\EvansBPExosX18SATA-STD-512E-SN04.LOD --noBanner`\n\n`\\\\.\\PhysicalDrive21 - OOS14000G - 000CCDBH - OOS1 - ATA`  \n`A firmware update is available for this device. FW File: .\\EvansBPExosX18SATA-STD-512E-SN04.LOD`", "author_fullname": "t2_5pk1lo3j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Update firmware for MDD OOS1400G to Exos X18", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1310us6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682619285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After becoming convinced a renewed MDD drive I received is actually an Exos X18 in disguise, I did a firmware update dry run and Seatools seems to agree with me.  Anyone else ever try un-white labelling their drive like this?  I&amp;#39;ve backed up all data so worst case scenario I have a bricked 14GB drive.  Thought I&amp;#39;d check here for any fellow mad scientists before I pull the trigger.  &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;SeaChest_Firmware_x64_windows.exe -d PD21 --fwdlDryRun --downloadFW .\\EvansBPExosX18SATA-STD-512E-SN04.LOD --noBanner&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\\\\.\\PhysicalDrive21 - OOS14000G - 000CCDBH - OOS1 - ATA&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;A firmware update is available for this device. FW File: .\\EvansBPExosX18SATA-STD-512E-SN04.LOD&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1310us6", "is_robot_indexable": true, "report_reasons": null, "author": "SupportExtra", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1310us6/update_firmware_for_mdd_oos1400g_to_exos_x18/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1310us6/update_firmware_for_mdd_oos1400g_to_exos_x18/", "subreddit_subscribers": 680082, "created_utc": 1682619285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I use this site a lot for some personal work going through old out of print books. It would otherwise cost me many thousands to buy them, as well taking up space. I'm devastated at the potential loss of this feature/site and so I'm wondering how I can back up some of the old scanned books on there. \n\nIs there an easy way of doing this? My current idea is to take screenshots of each page, or screen record it to video, while automating a page turn every 5 seconds or so. This is obviously pretty laborious but it would save me a fortune in actually buying them, plus many of the books aren't even available to buy anymore. \n\nBacking up the entire lot of scanned books would be ideal but I'm sure they have techniques to prevent this. \n\nIs there a better option?", "author_fullname": "t2_15doep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any way of backing up specific scanned books from Internet Archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130ke2y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682598142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use this site a lot for some personal work going through old out of print books. It would otherwise cost me many thousands to buy them, as well taking up space. I&amp;#39;m devastated at the potential loss of this feature/site and so I&amp;#39;m wondering how I can back up some of the old scanned books on there. &lt;/p&gt;\n\n&lt;p&gt;Is there an easy way of doing this? My current idea is to take screenshots of each page, or screen record it to video, while automating a page turn every 5 seconds or so. This is obviously pretty laborious but it would save me a fortune in actually buying them, plus many of the books aren&amp;#39;t even available to buy anymore. &lt;/p&gt;\n\n&lt;p&gt;Backing up the entire lot of scanned books would be ideal but I&amp;#39;m sure they have techniques to prevent this. &lt;/p&gt;\n\n&lt;p&gt;Is there a better option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "130ke2y", "is_robot_indexable": true, "report_reasons": null, "author": "Bfire7", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/130ke2y/is_there_any_way_of_backing_up_specific_scanned/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/130ke2y/is_there_any_way_of_backing_up_specific_scanned/", "subreddit_subscribers": 680082, "created_utc": 1682598142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all. Figured this would be the place to ask for this. See if anyone else has a clue what this program was.\n\nSo, there was this contact sheet/video thumbnail program I was using for a bit, then I reinstalled my OS, and was going about installing my usual programs, and realized I wanted to add that one again, but had no idea what it was called. So here's it's description:\n\nI believe it might've been a Windows program, and I used it through wine on Linux. It had a GUI, and it allowed drag and drop with video files, plus batch loaded files. On-top of that, the second you added files into it, it would begin the process of creating the contact sheets (typically creates them within the same folder). The location of the files you uploaded is on the left, with the settings and progress on the right.\n\nBest part is, the output (contact sheet afterwards) didn't have a little watermark or any such logo or reference to the program, unlike something like Video Thumbnail Maker.\n\nThis is a shot in the dark, but I've tried searching for this for a few days now, trying everything, and no single program I've come across is it. Trying my hand at all the experts in this sub to see if anyone came across this or knows of it.\n\nThank you!", "author_fullname": "t2_yirnb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to remember what THIS software is called, and what it's name is", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131ijzu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "eac073cc-b98a-11e2-84c9-12313d1841d1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "vhs", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682659490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all. Figured this would be the place to ask for this. See if anyone else has a clue what this program was.&lt;/p&gt;\n\n&lt;p&gt;So, there was this contact sheet/video thumbnail program I was using for a bit, then I reinstalled my OS, and was going about installing my usual programs, and realized I wanted to add that one again, but had no idea what it was called. So here&amp;#39;s it&amp;#39;s description:&lt;/p&gt;\n\n&lt;p&gt;I believe it might&amp;#39;ve been a Windows program, and I used it through wine on Linux. It had a GUI, and it allowed drag and drop with video files, plus batch loaded files. On-top of that, the second you added files into it, it would begin the process of creating the contact sheets (typically creates them within the same folder). The location of the files you uploaded is on the left, with the settings and progress on the right.&lt;/p&gt;\n\n&lt;p&gt;Best part is, the output (contact sheet afterwards) didn&amp;#39;t have a little watermark or any such logo or reference to the program, unlike something like Video Thumbnail Maker.&lt;/p&gt;\n\n&lt;p&gt;This is a shot in the dark, but I&amp;#39;ve tried searching for this for a few days now, trying everything, and no single program I&amp;#39;ve come across is it. Trying my hand at all the experts in this sub to see if anyone came across this or knows of it.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "VHS", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "131ijzu", "is_robot_indexable": true, "report_reasons": null, "author": "prodigalkal7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/131ijzu/trying_to_remember_what_this_software_is_called/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/131ijzu/trying_to_remember_what_this_software_is_called/", "subreddit_subscribers": 680082, "created_utc": 1682659490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Facebook displays a page's videos on a single screen that keeps adding thumbnail results as you scroll down. Because this page has so many videos, I haven't been able to reach the end of the video list (read: load thumbnails of all the page's videos) without something breaking.\n\nI tried using Youtube-DL and yt-dlp. They can download individual videos from Facebook, but they can't download all videos from a particular Facebook page.\n\nI also tried using JDownloader 2. LinkCrawler only found a handful of videos.\n\nSuggestions?", "author_fullname": "t2_ix7smrj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need to archive all of a Facebook page's public videos... but the page has 9,000+ videos and I can't even load all their thumbnails to grab their URLs. Suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131i2wj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682657978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Facebook displays a page&amp;#39;s videos on a single screen that keeps adding thumbnail results as you scroll down. Because this page has so many videos, I haven&amp;#39;t been able to reach the end of the video list (read: load thumbnails of all the page&amp;#39;s videos) without something breaking.&lt;/p&gt;\n\n&lt;p&gt;I tried using Youtube-DL and yt-dlp. They can download individual videos from Facebook, but they can&amp;#39;t download all videos from a particular Facebook page.&lt;/p&gt;\n\n&lt;p&gt;I also tried using JDownloader 2. LinkCrawler only found a handful of videos.&lt;/p&gt;\n\n&lt;p&gt;Suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "131i2wj", "is_robot_indexable": true, "report_reasons": null, "author": "SociopathicProTips", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/131i2wj/i_need_to_archive_all_of_a_facebook_pages_public/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/131i2wj/i_need_to_archive_all_of_a_facebook_pages_public/", "subreddit_subscribers": 680082, "created_utc": 1682657978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Early today \"The Roddenberry Archive\" released a bunch of explorable 3D models of the bridges from different iterations of Star Trek. I've only ever taken 3D models from video games, but these models are imbedded into the site, so I'm not even sure where I'd start. [https://roddenberry.x.io/2344-uss-enterprise-ncc-1701-c/](https://roddenberry.x.io/2344-uss-enterprise-ncc-1701-c/)\n\nYou're able to move around these environments, so they're not just panoramic images, it's just a bit fiddly to get the controls to come up.", "author_fullname": "t2_rax11", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any idea how to RIP the 3D models of the Star Trek bridges from this site?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131at1n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682637514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Early today &amp;quot;The Roddenberry Archive&amp;quot; released a bunch of explorable 3D models of the bridges from different iterations of Star Trek. I&amp;#39;ve only ever taken 3D models from video games, but these models are imbedded into the site, so I&amp;#39;m not even sure where I&amp;#39;d start. &lt;a href=\"https://roddenberry.x.io/2344-uss-enterprise-ncc-1701-c/\"&gt;https://roddenberry.x.io/2344-uss-enterprise-ncc-1701-c/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You&amp;#39;re able to move around these environments, so they&amp;#39;re not just panoramic images, it&amp;#39;s just a bit fiddly to get the controls to come up.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?auto=webp&amp;v=enabled&amp;s=496bc1673d5d4f599eeff3b494407bd810957592", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d9911065e88a1326beaa3e8851999933d1d4626", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe94783866fed13af2f13aa59c9bf539741bde2b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=68b37b42b2622e37a0925e32882bb4ab3c75902b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1bda51ade9ef7c9e8f3bba5f1bbcef48d61b2885", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=905a9a139e8f51fc09633a7c0eec265818285b78", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5358b683a5abaeeda37141ecbce8807b2a710333", "width": 1080, "height": 567}], "variants": {}, "id": "o68SdpvNOZ2SnNbQNs_v8GjPmMpUcMmVzv0KSaJDiUM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "131at1n", "is_robot_indexable": true, "report_reasons": null, "author": "Sparksighs", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/131at1n/any_idea_how_to_rip_the_3d_models_of_the_star/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/131at1n/any_idea_how_to_rip_the_3d_models_of_the_star/", "subreddit_subscribers": 680082, "created_utc": 1682637514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I read somewhere to download large google drive files without speed being throttled we can index a google drive.\n\nBut there is no tutorial on how to index a drive in google searches.\n\nCan anyone help\nI have a private shared drive with 80gb of single file even with idm every 10 mins links get broken and i had to renew the link in browset. Also google is throttling speeds to 100kbps only sometime as low as 11kbps.\n\nCan anyone help?", "author_fullname": "t2_fhyzfm8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Indexing Google Drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130lw4g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682601438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read somewhere to download large google drive files without speed being throttled we can index a google drive.&lt;/p&gt;\n\n&lt;p&gt;But there is no tutorial on how to index a drive in google searches.&lt;/p&gt;\n\n&lt;p&gt;Can anyone help\nI have a private shared drive with 80gb of single file even with idm every 10 mins links get broken and i had to renew the link in browset. Also google is throttling speeds to 100kbps only sometime as low as 11kbps.&lt;/p&gt;\n\n&lt;p&gt;Can anyone help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "130lw4g", "is_robot_indexable": true, "report_reasons": null, "author": "Kong_Don", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/130lw4g/indexing_google_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/130lw4g/indexing_google_drive/", "subreddit_subscribers": 680082, "created_utc": 1682601438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking at 8TB and higher HDD, to backup a lot of data in cold storage.  Is there anything I should be aware of, when looking at some of the enterprise models \u2014 particularly in terms of internal/external enclosures, or anything else I should know before dropping $200?", "author_fullname": "t2_uuh5r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you use an Enterprise HDD like Seagate EXOS for normal person cold storage? Looking to backup data on Macs. I also have a USB 3 to SATA 3 connector cable", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130h9iq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682591932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking at 8TB and higher HDD, to backup a lot of data in cold storage.  Is there anything I should be aware of, when looking at some of the enterprise models \u2014 particularly in terms of internal/external enclosures, or anything else I should know before dropping $200?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "130h9iq", "is_robot_indexable": true, "report_reasons": null, "author": "letourpowerscombine", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/130h9iq/can_you_use_an_enterprise_hdd_like_seagate_exos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/130h9iq/can_you_use_an_enterprise_hdd_like_seagate_exos/", "subreddit_subscribers": 680082, "created_utc": 1682591932.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m sure most people will shake their head at this, but I made a series of mistakes today regarding my phone, and my backup solution didn\u2019t save me. \n\nFirst, I bought a new iPhone, and transferred all the data to my new device. Then, after I had checked it was complete, I was in way too much of a hurry, and didn\u2019t check to make sure my 2FA apps worked on the new phone. (They didn\u2019t).\n\nOk no problem, on Google Authenticator, I just logged in and that restored the logins. However with the Microsoft Authenticator, that wasn\u2019t a option. \n\nAgain, though, I thought no issue, this is why I backup. I restored my old phone from a backup I made 24 hours earlier. To my surprise, the backup didn\u2019t restore the authentication 2FA accounts. Apparently it only works though icloud and somehow the local files aren\u2019t backed up even with complete iPhone backup. Go figure. \n\nSo now I\u2019m dealing with fixing this, for the most part I have backup codes or methods, but in one case I have contacted support. \n\nAgain, this is dumb, but I guess just a reminder to make sure you know what\u2019s actually included in your backup, and have a plan for 2FA access if the device breaks or is lost/erased, especially on a locked down device like a iPhone.", "author_fullname": "t2_8gr4mbih", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "iPhone 2FA backup fail.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131kv2q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682667460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m sure most people will shake their head at this, but I made a series of mistakes today regarding my phone, and my backup solution didn\u2019t save me. &lt;/p&gt;\n\n&lt;p&gt;First, I bought a new iPhone, and transferred all the data to my new device. Then, after I had checked it was complete, I was in way too much of a hurry, and didn\u2019t check to make sure my 2FA apps worked on the new phone. (They didn\u2019t).&lt;/p&gt;\n\n&lt;p&gt;Ok no problem, on Google Authenticator, I just logged in and that restored the logins. However with the Microsoft Authenticator, that wasn\u2019t a option. &lt;/p&gt;\n\n&lt;p&gt;Again, though, I thought no issue, this is why I backup. I restored my old phone from a backup I made 24 hours earlier. To my surprise, the backup didn\u2019t restore the authentication 2FA accounts. Apparently it only works though icloud and somehow the local files aren\u2019t backed up even with complete iPhone backup. Go figure. &lt;/p&gt;\n\n&lt;p&gt;So now I\u2019m dealing with fixing this, for the most part I have backup codes or methods, but in one case I have contacted support. &lt;/p&gt;\n\n&lt;p&gt;Again, this is dumb, but I guess just a reminder to make sure you know what\u2019s actually included in your backup, and have a plan for 2FA access if the device breaks or is lost/erased, especially on a locked down device like a iPhone.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "18TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "131kv2q", "is_robot_indexable": true, "report_reasons": null, "author": "mazdaowner6969", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/131kv2q/iphone_2fa_backup_fail/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/131kv2q/iphone_2fa_backup_fail/", "subreddit_subscribers": 680082, "created_utc": 1682667460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So HDDs are starting to go the way of the dodo, less and less devices come with them and experience tells me thats how it starts before a technology becomes obsolete, just like CDs.\n\nBut now I'm left wondering, if you Google around you'll find thousands of articles telling you SSDs in cold storage do not last, but to me that has been proven somewhat false, I've had a few SSDs unpowered for around a year without issues.\n\nSSDs have been around for more than 10 years now so there should be some actual experimental data around yet I cannot find any actual long term studies or people relating their experience, hence this post, what has been your experience? How long your data lasted? Under what conditions?", "author_fullname": "t2_lcjhu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSDs vs Time, what's your experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131irwi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682660197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So HDDs are starting to go the way of the dodo, less and less devices come with them and experience tells me thats how it starts before a technology becomes obsolete, just like CDs.&lt;/p&gt;\n\n&lt;p&gt;But now I&amp;#39;m left wondering, if you Google around you&amp;#39;ll find thousands of articles telling you SSDs in cold storage do not last, but to me that has been proven somewhat false, I&amp;#39;ve had a few SSDs unpowered for around a year without issues.&lt;/p&gt;\n\n&lt;p&gt;SSDs have been around for more than 10 years now so there should be some actual experimental data around yet I cannot find any actual long term studies or people relating their experience, hence this post, what has been your experience? How long your data lasted? Under what conditions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "131irwi", "is_robot_indexable": true, "report_reasons": null, "author": "otoko_no_hito", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/131irwi/ssds_vs_time_whats_your_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/131irwi/ssds_vs_time_whats_your_experience/", "subreddit_subscribers": 680082, "created_utc": 1682660197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Prices seem pretty good right now. If I wait should I expect sales in a month? Looking to update and exoand pc with some m.2.  \n\nSorry if wrong flair or not an appropriate question for the sub.", "author_fullname": "t2_6hel2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there normally memorial day sales for storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130vtpo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682614214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Prices seem pretty good right now. If I wait should I expect sales in a month? Looking to update and exoand pc with some m.2.  &lt;/p&gt;\n\n&lt;p&gt;Sorry if wrong flair or not an appropriate question for the sub.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "130vtpo", "is_robot_indexable": true, "report_reasons": null, "author": "Diabetesh", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/130vtpo/are_there_normally_memorial_day_sales_for_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/130vtpo/are_there_normally_memorial_day_sales_for_storage/", "subreddit_subscribers": 680082, "created_utc": 1682614214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there, does anyone know of these drives are smr or CMR drives? Have already purchased these and they are on the way so really hoping they are CMR. Can\u2019t find anything about them online one way or another. They are going into a server for 24/7 use including data archival and media streaming plus VMs and containers", "author_fullname": "t2_9r35st5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HGST HUC101212CSS600 1.2TB 10K SAS 2015 2.5\u201d smr or CMR?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130s4d3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682609810.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, does anyone know of these drives are smr or CMR drives? Have already purchased these and they are on the way so really hoping they are CMR. Can\u2019t find anything about them online one way or another. They are going into a server for 24/7 use including data archival and media streaming plus VMs and containers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "130s4d3", "is_robot_indexable": true, "report_reasons": null, "author": "whitebunnyflock", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/130s4d3/hgst_huc101212css600_12tb_10k_sas_2015_25_smr_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/130s4d3/hgst_huc101212css600_12tb_10k_sas_2015_25_smr_or/", "subreddit_subscribers": 680082, "created_utc": 1682609810.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Since the first release (in December 2021), SCrawler has been expanding and improving. I have implemented many of the user requests. I want to say thank you to everyone who uses my program, who likes it and who finds it useful. I really appreciate your kind words when you DM me. It makes my day :-)\n\nThe new release contains new sites: **YouTube, YouTube music, Mastodon, Pinterest** and **ThisVid**. It also contains many improvements and bug fixes.\n\n[https://github.com/AAndyProgram/SCrawler](https://github.com/AAndyProgram/SCrawler)\n\nThe program is completely free. I hope you will like it ;-)", "author_fullname": "t2_bfhlgnl4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SCrawler. Reddit, Twitter, Instagram, YouTube and any other sites downloader. New grand update.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_131m8h3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682672597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since the first release (in December 2021), SCrawler has been expanding and improving. I have implemented many of the user requests. I want to say thank you to everyone who uses my program, who likes it and who finds it useful. I really appreciate your kind words when you DM me. It makes my day :-)&lt;/p&gt;\n\n&lt;p&gt;The new release contains new sites: &lt;strong&gt;YouTube, YouTube music, Mastodon, Pinterest&lt;/strong&gt; and &lt;strong&gt;ThisVid&lt;/strong&gt;. It also contains many improvements and bug fixes.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/AAndyProgram/SCrawler\"&gt;https://github.com/AAndyProgram/SCrawler&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The program is completely free. I hope you will like it ;-)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/94HJHI8TvGTgmz8wWQbg_a-Nai34jS3HNnEMp9D0z74.jpg?auto=webp&amp;v=enabled&amp;s=7762203f5e277671722427ba8b8059db62a80ca6", "width": 1283, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/94HJHI8TvGTgmz8wWQbg_a-Nai34jS3HNnEMp9D0z74.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfd65c9e04800e8b1b9def6d61ba13455cf7836a", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/94HJHI8TvGTgmz8wWQbg_a-Nai34jS3HNnEMp9D0z74.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aecc109537c4353bb2aa96edfcd99aabea23614b", "width": 216, "height": 107}, {"url": "https://external-preview.redd.it/94HJHI8TvGTgmz8wWQbg_a-Nai34jS3HNnEMp9D0z74.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2de3fc7a72ad3e6c9e70b9aa1ad88d5fdd02a213", "width": 320, "height": 159}, {"url": "https://external-preview.redd.it/94HJHI8TvGTgmz8wWQbg_a-Nai34jS3HNnEMp9D0z74.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92ebb7d1e8d6b78d61545c05ce2cd18cca004443", "width": 640, "height": 319}, {"url": "https://external-preview.redd.it/94HJHI8TvGTgmz8wWQbg_a-Nai34jS3HNnEMp9D0z74.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55c3b20e58f54a3a864249853303c1c5f62bd4e5", "width": 960, "height": 478}, {"url": "https://external-preview.redd.it/94HJHI8TvGTgmz8wWQbg_a-Nai34jS3HNnEMp9D0z74.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4da6f9f905c18158e2ccbf373eda80877ad17760", "width": 1080, "height": 538}], "variants": {}, "id": "_pHtIQKoFHtVPlwEO3-8R5Db1nV-A5okGhAwJKRuSSk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "32TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "131m8h3", "is_robot_indexable": true, "report_reasons": null, "author": "AndyGay06", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/131m8h3/scrawler_reddit_twitter_instagram_youtube_and_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/131m8h3/scrawler_reddit_twitter_instagram_youtube_and_any/", "subreddit_subscribers": 680082, "created_utc": 1682672597.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm studying for calc bc right now and I heard the AP Daily Videos were a great resource. However, the horribly inefficient and crappy javascript just makes the user experience watching these videos super annoying.\n\nCan someone help me scrape and download the videos? I've tried finding an open directory, ytdl, and inspect element, but none of them have worked so far. Can someone help me out?", "author_fullname": "t2_42g5dplv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scraping AP Daily Videos from AP classroom", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131lfwk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682669651.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m studying for calc bc right now and I heard the AP Daily Videos were a great resource. However, the horribly inefficient and crappy javascript just makes the user experience watching these videos super annoying.&lt;/p&gt;\n\n&lt;p&gt;Can someone help me scrape and download the videos? I&amp;#39;ve tried finding an open directory, ytdl, and inspect element, but none of them have worked so far. Can someone help me out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "131lfwk", "is_robot_indexable": true, "report_reasons": null, "author": "-Trueman-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/131lfwk/scraping_ap_daily_videos_from_ap_classroom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/131lfwk/scraping_ap_daily_videos_from_ap_classroom/", "subreddit_subscribers": 680082, "created_utc": 1682669651.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hey there\n\nsince telegram allows to upload files that are under 2 gb in size i wondered if it is possible to upload a 4k mp4 and still be viewable without compressionso i tried that but when it is done uploading the only way to watch the video is to download the video and play it locallyis there a way for the video to still being viewable but without compression.\n\n&amp;#x200B;\n\nEDIT:  \ntried downloading the file and copying the link for it but the server responded with a 404 ", "author_fullname": "t2_sqj98exe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "telegram videos easily viewable", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131h1j0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682664067.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682654682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey there&lt;/p&gt;\n\n&lt;p&gt;since telegram allows to upload files that are under 2 gb in size i wondered if it is possible to upload a 4k mp4 and still be viewable without compressionso i tried that but when it is done uploading the only way to watch the video is to download the video and play it locallyis there a way for the video to still being viewable but without compression.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;br/&gt;\ntried downloading the file and copying the link for it but the server responded with a 404 &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "131h1j0", "is_robot_indexable": true, "report_reasons": null, "author": "kingoboom", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/131h1j0/telegram_videos_easily_viewable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/131h1j0/telegram_videos_easily_viewable/", "subreddit_subscribers": 680082, "created_utc": 1682654682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I am very new to this so I'm sorry if this is a dumb question. But I have to format my computer and I have around 750GB of anime that I need to move over to another drive or online. Is there a way for me to calculate how long it would take to transfer it all? If it will take more than a week I will just go scorched earth and not move anything over before formatting.  \n\n\nHDD:  Hitachi HUA722010CLA330 1TB, Internal Hard Drive  \n\n\nAll help is greatly appreciated.", "author_fullname": "t2_7aygqar2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hard Drive Switching", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131f5jl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682649118.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am very new to this so I&amp;#39;m sorry if this is a dumb question. But I have to format my computer and I have around 750GB of anime that I need to move over to another drive or online. Is there a way for me to calculate how long it would take to transfer it all? If it will take more than a week I will just go scorched earth and not move anything over before formatting.  &lt;/p&gt;\n\n&lt;p&gt;HDD:  Hitachi HUA722010CLA330 1TB, Internal Hard Drive  &lt;/p&gt;\n\n&lt;p&gt;All help is greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "131f5jl", "is_robot_indexable": true, "report_reasons": null, "author": "_TheOneTrueBean_", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/131f5jl/hard_drive_switching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/131f5jl/hard_drive_switching/", "subreddit_subscribers": 680082, "created_utc": 1682649118.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been looking for some drives to act as the backup copies for my WD Red Pro's which i got for a similar price a while back.. but i've really not paid attention to things..\n\nFrom what i've read the Exos are better than the Iron Wolf pro... but either way they both come with 5 years warranty..\n\ni picked up 2 x 16TB exos for \u00a3450.. so we're at \u00a314 per TB..\n\nThese drives are going to be sat in a microserver and powered up once a week to have thr weeks worth of \"acquisitions\" written to them.. total power on time will be about 7 hours a week.\n\nHave a gotten at least an acceptable deal at this price for these drives?", "author_fullname": "t2_4cfky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Exos 16tb - \u00a3225.. was this a good deal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131920j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682633525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been looking for some drives to act as the backup copies for my WD Red Pro&amp;#39;s which i got for a similar price a while back.. but i&amp;#39;ve really not paid attention to things..&lt;/p&gt;\n\n&lt;p&gt;From what i&amp;#39;ve read the Exos are better than the Iron Wolf pro... but either way they both come with 5 years warranty..&lt;/p&gt;\n\n&lt;p&gt;i picked up 2 x 16TB exos for \u00a3450.. so we&amp;#39;re at \u00a314 per TB..&lt;/p&gt;\n\n&lt;p&gt;These drives are going to be sat in a microserver and powered up once a week to have thr weeks worth of &amp;quot;acquisitions&amp;quot; written to them.. total power on time will be about 7 hours a week.&lt;/p&gt;\n\n&lt;p&gt;Have a gotten at least an acceptable deal at this price for these drives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "42 TB (Usable)", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "131920j", "is_robot_indexable": true, "report_reasons": null, "author": "d4nm3d", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/131920j/seagate_exos_16tb_225_was_this_a_good_deal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/131920j/seagate_exos_16tb_225_was_this_a_good_deal/", "subreddit_subscribers": 680082, "created_utc": 1682633525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There are various 3D environments displayed on this site that I am trying to back up. WebGL appears to be in use and I assume I can get a .glb out of it, but so far I have had no luck locating them. \n\nDo any of you know how to get models/textures out of webgl? There are various pages on the site with 3D environments (which are initialized by the \"Enable Navigation\" button, not current available in Firefox):\n\nhttps://roddenberry.x.io/2370-uss-enterprise-ncc-1701-d/", "author_fullname": "t2_4soct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download 3D models/textures from WebGL site?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13175gr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682629910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are various 3D environments displayed on this site that I am trying to back up. WebGL appears to be in use and I assume I can get a .glb out of it, but so far I have had no luck locating them. &lt;/p&gt;\n\n&lt;p&gt;Do any of you know how to get models/textures out of webgl? There are various pages on the site with 3D environments (which are initialized by the &amp;quot;Enable Navigation&amp;quot; button, not current available in Firefox):&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://roddenberry.x.io/2370-uss-enterprise-ncc-1701-d/\"&gt;https://roddenberry.x.io/2370-uss-enterprise-ncc-1701-d/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?auto=webp&amp;v=enabled&amp;s=496bc1673d5d4f599eeff3b494407bd810957592", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d9911065e88a1326beaa3e8851999933d1d4626", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe94783866fed13af2f13aa59c9bf539741bde2b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=68b37b42b2622e37a0925e32882bb4ab3c75902b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1bda51ade9ef7c9e8f3bba5f1bbcef48d61b2885", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=905a9a139e8f51fc09633a7c0eec265818285b78", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/lNVAondnD_4iGCsxpS_E4ayX5-fWriXVesTKnefxddA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5358b683a5abaeeda37141ecbce8807b2a710333", "width": 1080, "height": 567}], "variants": {}, "id": "o68SdpvNOZ2SnNbQNs_v8GjPmMpUcMmVzv0KSaJDiUM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13175gr", "is_robot_indexable": true, "report_reasons": null, "author": "SillyNonsense", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13175gr/how_to_download_3d_modelstextures_from_webgl_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13175gr/how_to_download_3d_modelstextures_from_webgl_site/", "subreddit_subscribers": 680082, "created_utc": 1682629910.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}