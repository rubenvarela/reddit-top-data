{"kind": "Listing", "data": {"after": "t3_131d4ex", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[Previous post](https://www.reddit.com/r/datascience/comments/12xd1h0/comment/jht1lwq/?context=3)\n\nBasically, I interviewed with a company and a month later they sent me a take-home exam (and also their real datasets so I most certainly was used for free labor). It's been a month since I sent them my work and they just now invited me for yet another interview, this time technical, where I'll also explain the take-home exam. Most people in the previous thread told me to give up on this company, but I don't have any other job offers. Can I leverage the long waiting time to tell them that they either give me a job offer with what I've shown so far or I walk? I don't see the point in giving yet another interview, even the role is up for discussion. I'm not sure if they're interviewing other candidates, I wasn't applying for an open role. ", "author_fullname": "t2_w0if7iet", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Update: Company that sent me their real datasets is now asking for another interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130fj8b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 141, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 141, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682588452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/datascience/comments/12xd1h0/comment/jht1lwq/?context=3\"&gt;Previous post&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Basically, I interviewed with a company and a month later they sent me a take-home exam (and also their real datasets so I most certainly was used for free labor). It&amp;#39;s been a month since I sent them my work and they just now invited me for yet another interview, this time technical, where I&amp;#39;ll also explain the take-home exam. Most people in the previous thread told me to give up on this company, but I don&amp;#39;t have any other job offers. Can I leverage the long waiting time to tell them that they either give me a job offer with what I&amp;#39;ve shown so far or I walk? I don&amp;#39;t see the point in giving yet another interview, even the role is up for discussion. I&amp;#39;m not sure if they&amp;#39;re interviewing other candidates, I wasn&amp;#39;t applying for an open role. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "130fj8b", "is_robot_indexable": true, "report_reasons": null, "author": "Direct_Pie_9059", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/130fj8b/update_company_that_sent_me_their_real_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/130fj8b/update_company_that_sent_me_their_real_datasets/", "subreddit_subscribers": 883290, "created_utc": 1682588452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Have you ever interviewed candidates that acted so poorly on an interpersonal level that you had to cut the interview short? If so, how have you handled the situation?", "author_fullname": "t2_l79yml7q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interviews with dick candidates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1311zdz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 136, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 136, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682621271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you ever interviewed candidates that acted so poorly on an interpersonal level that you had to cut the interview short? If so, how have you handled the situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1311zdz", "is_robot_indexable": true, "report_reasons": null, "author": "Academic_Baker_9233", "discussion_type": null, "num_comments": 69, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1311zdz/interviews_with_dick_candidates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1311zdz/interviews_with_dick_candidates/", "subreddit_subscribers": 883290, "created_utc": 1682621271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey data legends,\n\nI've just started to learn a bit of Python and it's got me going down the rabbit hole of possible business applications for data analysis/science in this small/medium business (B2B with typically only a couple of transactions per customer each year).  What's currently done is very basic stuff in excel and no machine learning etc. (I have no background in data science other than basic knowledge but I feel there is a lot of potential)\n\nI've managed to automate a PDF report that has some basic stuff using Plotly and Pandas and am wondering where I should focus my efforts next.\n\nWhat are the general low hanging fruits that I should try and start out with for a business that has very little maturity on this front?\n\nChat GPT has come back with some suggestions like: Customer segmentation, Churn analysis, sales forecasting, website optimisation, recommendation engines, predictive CLV.  \n\nAny help or insights would be appreciated pointing me in the right direction.  Thanks", "author_fullname": "t2_amcbd0hb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low hanging fruit projects for business with non-mature data science/analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130hqft", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682592785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey data legends,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve just started to learn a bit of Python and it&amp;#39;s got me going down the rabbit hole of possible business applications for data analysis/science in this small/medium business (B2B with typically only a couple of transactions per customer each year).  What&amp;#39;s currently done is very basic stuff in excel and no machine learning etc. (I have no background in data science other than basic knowledge but I feel there is a lot of potential)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve managed to automate a PDF report that has some basic stuff using Plotly and Pandas and am wondering where I should focus my efforts next.&lt;/p&gt;\n\n&lt;p&gt;What are the general low hanging fruits that I should try and start out with for a business that has very little maturity on this front?&lt;/p&gt;\n\n&lt;p&gt;Chat GPT has come back with some suggestions like: Customer segmentation, Churn analysis, sales forecasting, website optimisation, recommendation engines, predictive CLV.  &lt;/p&gt;\n\n&lt;p&gt;Any help or insights would be appreciated pointing me in the right direction.  Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "130hqft", "is_robot_indexable": true, "report_reasons": null, "author": "BobzzYourUncle", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/130hqft/low_hanging_fruit_projects_for_business_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/130hqft/low_hanging_fruit_projects_for_business_with/", "subreddit_subscribers": 883290, "created_utc": 1682592785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When I was in high school, my algebra 2 schools were weak because I slacked off in Algebra 1 and the highest math course I took was a combo course of algebra 1 and 2 my senior year.\n\nEDIT: I'm actually doing my Masters in Data Science and highest math I took was Calculus 1 in college. I'm just curious if any other Redditors struggled with math.", "author_fullname": "t2_2avd4wfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Were any of you DS bad at math at some point?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1315m8l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682629181.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682627420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I was in high school, my algebra 2 schools were weak because I slacked off in Algebra 1 and the highest math course I took was a combo course of algebra 1 and 2 my senior year.&lt;/p&gt;\n\n&lt;p&gt;EDIT: I&amp;#39;m actually doing my Masters in Data Science and highest math I took was Calculus 1 in college. I&amp;#39;m just curious if any other Redditors struggled with math.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1315m8l", "is_robot_indexable": true, "report_reasons": null, "author": "Javilism", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1315m8l/were_any_of_you_ds_bad_at_math_at_some_point/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1315m8l/were_any_of_you_ds_bad_at_math_at_some_point/", "subreddit_subscribers": 883290, "created_utc": 1682627420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I just published a comprehensive guide on using NumPy, Pandas, and Matplotlib in Python for data science. If you're looking to level up your data analysis, manipulation, and visualization skills, this post is for you! I'd love to hear your feedback and any suggestions you might have. Check it out here: [https://danielbuilescu.com/blogs/learn-python/python-for-data-science-unlocking-the-power-of-numpy-pandas-and-matplotlib](https://danielbuilescu.com/blogs/learn-python/python-for-data-science-unlocking-the-power-of-numpy-pandas-and-matplotlib)", "author_fullname": "t2_o8z8csoh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udc68\u200d\ud83d\udcbb Python for Data Science: Unlocking the Power of NumPy, Pandas, and Matplotlib", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130c821", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682577332.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I just published a comprehensive guide on using NumPy, Pandas, and Matplotlib in Python for data science. If you&amp;#39;re looking to level up your data analysis, manipulation, and visualization skills, this post is for you! I&amp;#39;d love to hear your feedback and any suggestions you might have. Check it out here: &lt;a href=\"https://danielbuilescu.com/blogs/learn-python/python-for-data-science-unlocking-the-power-of-numpy-pandas-and-matplotlib\"&gt;https://danielbuilescu.com/blogs/learn-python/python-for-data-science-unlocking-the-power-of-numpy-pandas-and-matplotlib&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-vIgBZlXESj1qHyf0tdvPCKSv2plPL7RJb2K5Rm7qrk.jpg?auto=webp&amp;v=enabled&amp;s=eddcbb401b64a42ed568ee4f8e58182ae1deb700", "width": 1024, "height": 576}, "resolutions": [{"url": "https://external-preview.redd.it/-vIgBZlXESj1qHyf0tdvPCKSv2plPL7RJb2K5Rm7qrk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c12fa2eec9d0278824cdab45da8d922b7f8f237", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/-vIgBZlXESj1qHyf0tdvPCKSv2plPL7RJb2K5Rm7qrk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78007d993af35a4151ee090120101f019af28fb2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/-vIgBZlXESj1qHyf0tdvPCKSv2plPL7RJb2K5Rm7qrk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=634effbf820dfde16fe24a937c3dc69121c72bef", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/-vIgBZlXESj1qHyf0tdvPCKSv2plPL7RJb2K5Rm7qrk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f6878e3d4e192883661e8a919b6aed9b758547d", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/-vIgBZlXESj1qHyf0tdvPCKSv2plPL7RJb2K5Rm7qrk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28f41cece940838163d4e3beab4b2bcca54cdcc5", "width": 960, "height": 540}], "variants": {}, "id": "1BL1eSz3X_Bm0DPvey4vd-qCRXBy5r5j5FWhAk5p87M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "130c821", "is_robot_indexable": true, "report_reasons": null, "author": "Which-Cycle3051", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/130c821/python_for_data_science_unlocking_the_power_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/130c821/python_for_data_science_unlocking_the_power_of/", "subreddit_subscribers": 883290, "created_utc": 1682577332.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've seen in the programming humor sub that experienced SWEs have recruiters constantly messaging them for roles. Does this happen with data science too and if so at what level?", "author_fullname": "t2_mkdw0oz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At what experience level do recruiters reach out", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130z4ni", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682617128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen in the programming humor sub that experienced SWEs have recruiters constantly messaging them for roles. Does this happen with data science too and if so at what level?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "130z4ni", "is_robot_indexable": true, "report_reasons": null, "author": "send_math_equations", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/130z4ni/at_what_experience_level_do_recruiters_reach_out/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/130z4ni/at_what_experience_level_do_recruiters_reach_out/", "subreddit_subscribers": 883290, "created_utc": 1682617128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_5y5y24cy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hey, what is wrong with me? I sent many applications, and lately, I am getting a bunch of no'es, even for entry positions. Not even getting a chance for an interview. Is there something wrong with it? I have a hided bunch of identifying information.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_131bl0x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7erjq-uYKkqltMVO1L6X9ToKrDx1A2NcZhbfWtkXAhk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682639467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/oy5cmuehliwa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/oy5cmuehliwa1.png?auto=webp&amp;v=enabled&amp;s=1f0c766919f648071f84049a1685047fda08e4c6", "width": 1123, "height": 1580}, "resolutions": [{"url": "https://preview.redd.it/oy5cmuehliwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=126a57cd1474e5f8e9d558db4fccbcd91deb2b51", "width": 108, "height": 151}, {"url": "https://preview.redd.it/oy5cmuehliwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=272a284d77279b98b94fce73fba45d9e74b5ecb1", "width": 216, "height": 303}, {"url": "https://preview.redd.it/oy5cmuehliwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=85aa7b1e51b88f691a3b882b79ca8e0ce67f7d96", "width": 320, "height": 450}, {"url": "https://preview.redd.it/oy5cmuehliwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ae8f4dfb0f2ed2199f5f4fd404a8542aa07837f", "width": 640, "height": 900}, {"url": "https://preview.redd.it/oy5cmuehliwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b5ba1c94bfc127d29dcdbdfd59fe7b0121f6319", "width": 960, "height": 1350}, {"url": "https://preview.redd.it/oy5cmuehliwa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2fe5cc8a2d38d016d908c556340dbad4ccca39a5", "width": 1080, "height": 1519}], "variants": {}, "id": "PeZkRMDbCHTwwaxzG38aaIFR8EmSGC_VMtgHqntSUsQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "131bl0x", "is_robot_indexable": true, "report_reasons": null, "author": "Parazic", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/131bl0x/hey_what_is_wrong_with_me_i_sent_many/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/oy5cmuehliwa1.png", "subreddit_subscribers": 883290, "created_utc": 1682639467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I volunteered at a middle school career fair to discuss my job as a data scientist and created this neat poster. FYI it was way way overkill and most kids didn't read the through much of it. Next year I'll try to reduce the text and incorporate more games / activities. \n\nhttps://preview.redd.it/pnze9c42tgwa1.png?width=2304&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f1faed07e646caa16a56eb5b00839198f51816f8", "author_fullname": "t2_6hvdm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Poster I created for a middle school career fair", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"pnze9c42tgwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 162, "x": 108, "u": "https://preview.redd.it/pnze9c42tgwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=56436100f67b467d23e5afe872863ffa3c814042"}, {"y": 324, "x": 216, "u": "https://preview.redd.it/pnze9c42tgwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f173bebed98ea86ea0bc01f38e442dd9fecdf3e8"}, {"y": 480, "x": 320, "u": "https://preview.redd.it/pnze9c42tgwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95cf79ac4dc76f107800b500e11f338fbf9d8668"}, {"y": 960, "x": 640, "u": "https://preview.redd.it/pnze9c42tgwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=777d23f978ad3f359d14863acb78cdf5cc009096"}, {"y": 1440, "x": 960, "u": "https://preview.redd.it/pnze9c42tgwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=866b37a9b98d5611962794b4a020fdf5cb1f7a71"}, {"y": 1620, "x": 1080, "u": "https://preview.redd.it/pnze9c42tgwa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7d434d9b97b58217093cb60043ef88207fe4796"}], "s": {"y": 3456, "x": 2304, "u": "https://preview.redd.it/pnze9c42tgwa1.png?width=2304&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f1faed07e646caa16a56eb5b00839198f51816f8"}, "id": "pnze9c42tgwa1"}}, "name": "t3_13105ot", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XfVPKB5bCClu8xJGpsDhdorivewk7LwcbpFQckKDodU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682618054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I volunteered at a middle school career fair to discuss my job as a data scientist and created this neat poster. FYI it was way way overkill and most kids didn&amp;#39;t read the through much of it. Next year I&amp;#39;ll try to reduce the text and incorporate more games / activities. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pnze9c42tgwa1.png?width=2304&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f1faed07e646caa16a56eb5b00839198f51816f8\"&gt;https://preview.redd.it/pnze9c42tgwa1.png?width=2304&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f1faed07e646caa16a56eb5b00839198f51816f8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13105ot", "is_robot_indexable": true, "report_reasons": null, "author": "hipstahs", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13105ot/poster_i_created_for_a_middle_school_career_fair/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13105ot/poster_i_created_for_a_middle_school_career_fair/", "subreddit_subscribers": 883290, "created_utc": 1682618054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_3xnau4cx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Blog] What is data profiling?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 95, "top_awarded_type": null, "hide_score": false, "name": "t3_130rrma", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/lbuo8g_XYpLxzss2nTCWeq5d1o0s5Ur7okJtR1JvwL8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682609497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "greatexpectations.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://greatexpectations.io/blog/what-is-data-profiling", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QzCFFHyO3P4mKv-lAT0OPjmAHjo-syNkFBo5XINOzzA.jpg?auto=webp&amp;v=enabled&amp;s=478ff82196dc2d5c08e0e2b1292645b89aa7e765", "width": 1283, "height": 879}, "resolutions": [{"url": "https://external-preview.redd.it/QzCFFHyO3P4mKv-lAT0OPjmAHjo-syNkFBo5XINOzzA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e4b121a74009aa153184bee58fcd9fbf6d25cbf", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/QzCFFHyO3P4mKv-lAT0OPjmAHjo-syNkFBo5XINOzzA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=79f149d5ddcc1f6498057a915dc6deeb39ac764c", "width": 216, "height": 147}, {"url": "https://external-preview.redd.it/QzCFFHyO3P4mKv-lAT0OPjmAHjo-syNkFBo5XINOzzA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66f512efe91aa6b70088207aa205b65097d3192c", "width": 320, "height": 219}, {"url": "https://external-preview.redd.it/QzCFFHyO3P4mKv-lAT0OPjmAHjo-syNkFBo5XINOzzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ebae9673c60a857a8dcbf352abab4ed3ca9bf1e8", "width": 640, "height": 438}, {"url": "https://external-preview.redd.it/QzCFFHyO3P4mKv-lAT0OPjmAHjo-syNkFBo5XINOzzA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c1f8d1b0550c08c806ac8768c72c036bf75d4fa", "width": 960, "height": 657}, {"url": "https://external-preview.redd.it/QzCFFHyO3P4mKv-lAT0OPjmAHjo-syNkFBo5XINOzzA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b1ab29bc6c9fbe4cb45716bee7b7763563e1dcc1", "width": 1080, "height": 739}], "variants": {}, "id": "zFFdiW1ZD1OMCqzYT7L-pdQo1l5aeUIM-LWZp_-9Vzw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "130rrma", "is_robot_indexable": true, "report_reasons": null, "author": "superconductiveKyle", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/130rrma/blog_what_is_data_profiling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://greatexpectations.io/blog/what-is-data-profiling", "subreddit_subscribers": 883290, "created_utc": 1682609497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hi everyone,\n\nI'm excited to share my new course \"GCP Professional **Cloud** **Database** Practice Exams\". This course will prepare you for the Google Cloud **Cloud Database** Certification exam.\n\nI'm offering free coupons for a limited time to the members of this forum. You can enjoy the promotion code by following the link that I provide below:\n\nhttps://www.udemy.com/course/gcp-professional-cloud-database-engineer-certification-exams/?couponCode=D1E95566B8CB56DC5AC4\n\nThank you for your time, and I look forward to seeing you in the course.\n\nBest regards", "author_fullname": "t2_5mszqi6z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP Professional Cloud Database Practice Exams - Get it for free!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130hpbh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682592728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m excited to share my new course &amp;quot;GCP Professional &lt;strong&gt;Cloud&lt;/strong&gt; &lt;strong&gt;Database&lt;/strong&gt; Practice Exams&amp;quot;. This course will prepare you for the Google Cloud &lt;strong&gt;Cloud Database&lt;/strong&gt; Certification exam.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m offering free coupons for a limited time to the members of this forum. You can enjoy the promotion code by following the link that I provide below:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.udemy.com/course/gcp-professional-cloud-database-engineer-certification-exams/?couponCode=D1E95566B8CB56DC5AC4\"&gt;https://www.udemy.com/course/gcp-professional-cloud-database-engineer-certification-exams/?couponCode=D1E95566B8CB56DC5AC4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time, and I look forward to seeing you in the course.&lt;/p&gt;\n\n&lt;p&gt;Best regards&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5DwLO8KtxDJhjZftUTdwoPy7eP2vVSjfSO3ms_30aTE.jpg?auto=webp&amp;v=enabled&amp;s=42a0c9602f14fe2bed464b305186ed2596762565", "width": 480, "height": 270}, "resolutions": [{"url": "https://external-preview.redd.it/5DwLO8KtxDJhjZftUTdwoPy7eP2vVSjfSO3ms_30aTE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d167d8090cfc595969338eed6a0ff77fed82442", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/5DwLO8KtxDJhjZftUTdwoPy7eP2vVSjfSO3ms_30aTE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c273c5b6768fcafa295273f6647adf2828999c39", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/5DwLO8KtxDJhjZftUTdwoPy7eP2vVSjfSO3ms_30aTE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec8a7af19a78b60c3cbc16cad47e87043fec715e", "width": 320, "height": 180}], "variants": {}, "id": "vUX_7XvQF5uijYDxLYXand2CddA3v-Zu58VvrGzEtIg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "130hpbh", "is_robot_indexable": true, "report_reasons": null, "author": "Entire-Work34", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/130hpbh/gcp_professional_cloud_database_practice_exams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/130hpbh/gcp_professional_cloud_database_practice_exams/", "subreddit_subscribers": 883290, "created_utc": 1682592728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips on processing 10M+ records locally with python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1312hry", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_lyf92k", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I was given a test task that definitely wants to test my skills in data processing optimization. I have some `.csv` data and need to run several transformations and count statistics on it. \n\nIf I just do stuff with plain pandas on `.csv` files it will be ineffective. Any good tips? I have few ideas like converting `.csv` to parquet or `avro`. I never practiced pySpark or Dask though, are they good tools for local machine (I know that Spark works on clusters)? Would appreciate any advice or personal experience.   \n\n\nThe data itself is small and in `.csv` but the task specifically mentions to code with the thought that it could contain tens of millions records eventually.", "author_fullname": "t2_lyf92k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips on processing 10M+ records locally with python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1312gxj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682622124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I was given a test task that definitely wants to test my skills in data processing optimization. I have some &lt;code&gt;.csv&lt;/code&gt; data and need to run several transformations and count statistics on it. &lt;/p&gt;\n\n&lt;p&gt;If I just do stuff with plain pandas on &lt;code&gt;.csv&lt;/code&gt; files it will be ineffective. Any good tips? I have few ideas like converting &lt;code&gt;.csv&lt;/code&gt; to parquet or &lt;code&gt;avro&lt;/code&gt;. I never practiced pySpark or Dask though, are they good tools for local machine (I know that Spark works on clusters)? Would appreciate any advice or personal experience.   &lt;/p&gt;\n\n&lt;p&gt;The data itself is small and in &lt;code&gt;.csv&lt;/code&gt; but the task specifically mentions to code with the thought that it could contain tens of millions records eventually.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1312gxj", "is_robot_indexable": true, "report_reasons": null, "author": "chelicerae-aureus", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1312gxj/tips_on_processing_10m_records_locally_with_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1312gxj/tips_on_processing_10m_records_locally_with_python/", "subreddit_subscribers": 102943, "created_utc": 1682622124.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1682622163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/dataengineering/comments/1312gxj/tips_on_processing_10m_records_locally_with_python/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1312hry", "is_robot_indexable": true, "report_reasons": null, "author": "chelicerae-aureus", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1312gxj", "author_flair_text_color": null, "permalink": "/r/datascience/comments/1312hry/tips_on_processing_10m_records_locally_with_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/dataengineering/comments/1312gxj/tips_on_processing_10m_records_locally_with_python/", "subreddit_subscribers": 883290, "created_utc": 1682622163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently in the last semester of my undergraduate program, and I've been learning about Data Science and Machine Learning a lot these days. I've completed a couple of courses from Coursera (Supervised and Unsupervised Learning) and Udemy (DS and ML Bootcamp- Jose P.). I also got the opportunity to do a remote DS Internship.  \nMy problem at hand is how should I put those skills to use since I don't have a job related to the field yet. I want to post everything I do related to DS and ML on my GitHub. Where should I start? with respect to building a portfolio that attracts hirers.", "author_fullname": "t2_3ihaa088", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS and ML Portfolio.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131c302", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682640743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in the last semester of my undergraduate program, and I&amp;#39;ve been learning about Data Science and Machine Learning a lot these days. I&amp;#39;ve completed a couple of courses from Coursera (Supervised and Unsupervised Learning) and Udemy (DS and ML Bootcamp- Jose P.). I also got the opportunity to do a remote DS Internship.&lt;br/&gt;\nMy problem at hand is how should I put those skills to use since I don&amp;#39;t have a job related to the field yet. I want to post everything I do related to DS and ML on my GitHub. Where should I start? with respect to building a portfolio that attracts hirers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "131c302", "is_robot_indexable": true, "report_reasons": null, "author": "Shwifty_MO", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/131c302/ds_and_ml_portfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/131c302/ds_and_ml_portfolio/", "subreddit_subscribers": 883290, "created_utc": 1682640743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have weekly sales data for a restaurant, with 113 observations, and every year in January, sales drop significantly and then recover after two or four weeks. I applied a SARIMA model with auto-arima in R, but when I evaluate my model, I realize that the residuals are not constant and not normally distributed. Box-Cox Transformation was already used, lamba was 1.99 but it did not improve the model.\n\nUpon reviewing a time series text, I learned that I need to create a dummy variable. I looked at the observations where the pattern breaks in January and classified them as \"1\", with the others as zero. I estimated my model again and it resulted in a SARIMA with rgex, but when I reviewed the residuals, I still have extremely high residuals in those periods. Residuals used to be -10000, now they are mostly -5000, so they were reduced. Do you have any suggestions? What types of interventions exist? I placed \"1\" for the first few weeks of January, then \"0\" when I see that sales have reached their normal level.\n\nTo test for stationarity, I used the Augmented Dickey-Fuller test and found that the data was not stationary. Therefore, I differenced the time series and checked for stationarity again using the ADF test.\n\nNext, I decomposed the time series into its seasonal, trend, and residual components and plotted the results. I then fit a SARIMA model using auto.arima and checked its diagnostic tests for accuracy. Additionally, I  performed a Box-Ljung test to check for autocorrelation in the residuals and a Jarque-Bera test for normality. Box-Ljung was fine, but Jarque-Bera was not.\n\nI then added a dummy variable for intervention analysis to account for outliers or extreme values in the data. I fit a second SARIMA model using the dummy variable and checked its diagnostic tests for accuracy. However, yI found that the variance was still high, and upon further investigation, I found that the highest residuals corresponded to the same period that I alreadt included in the dummy variable for intervention. What else could I do? any suggestion? thanks!", "author_fullname": "t2_440m0av6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to apply intervention analysis to my time series?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1316e2u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682628678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have weekly sales data for a restaurant, with 113 observations, and every year in January, sales drop significantly and then recover after two or four weeks. I applied a SARIMA model with auto-arima in R, but when I evaluate my model, I realize that the residuals are not constant and not normally distributed. Box-Cox Transformation was already used, lamba was 1.99 but it did not improve the model.&lt;/p&gt;\n\n&lt;p&gt;Upon reviewing a time series text, I learned that I need to create a dummy variable. I looked at the observations where the pattern breaks in January and classified them as &amp;quot;1&amp;quot;, with the others as zero. I estimated my model again and it resulted in a SARIMA with rgex, but when I reviewed the residuals, I still have extremely high residuals in those periods. Residuals used to be -10000, now they are mostly -5000, so they were reduced. Do you have any suggestions? What types of interventions exist? I placed &amp;quot;1&amp;quot; for the first few weeks of January, then &amp;quot;0&amp;quot; when I see that sales have reached their normal level.&lt;/p&gt;\n\n&lt;p&gt;To test for stationarity, I used the Augmented Dickey-Fuller test and found that the data was not stationary. Therefore, I differenced the time series and checked for stationarity again using the ADF test.&lt;/p&gt;\n\n&lt;p&gt;Next, I decomposed the time series into its seasonal, trend, and residual components and plotted the results. I then fit a SARIMA model using auto.arima and checked its diagnostic tests for accuracy. Additionally, I  performed a Box-Ljung test to check for autocorrelation in the residuals and a Jarque-Bera test for normality. Box-Ljung was fine, but Jarque-Bera was not.&lt;/p&gt;\n\n&lt;p&gt;I then added a dummy variable for intervention analysis to account for outliers or extreme values in the data. I fit a second SARIMA model using the dummy variable and checked its diagnostic tests for accuracy. However, yI found that the variance was still high, and upon further investigation, I found that the highest residuals corresponded to the same period that I alreadt included in the dummy variable for intervention. What else could I do? any suggestion? thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1316e2u", "is_robot_indexable": true, "report_reasons": null, "author": "sircapital97", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1316e2u/how_to_apply_intervention_analysis_to_my_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1316e2u/how_to_apply_intervention_analysis_to_my_time/", "subreddit_subscribers": 883290, "created_utc": 1682628678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently working on a project that involves analyzing a dataset with lots of different variables, and I'm hoping to find a software that can help me identify correlations between them. The data looks akin to movie rating/ movie stats database where I want to figure out what movie would a person like depending on previous ratings. I would also like it to be something I can use as API from programming language that is more universal (unlike R for example) so I can build upon it more easily.\n\nThanks for help!", "author_fullname": "t2_lyhdhzbm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a software that can automatically find correlations between different types of data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13134ku", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682623273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working on a project that involves analyzing a dataset with lots of different variables, and I&amp;#39;m hoping to find a software that can help me identify correlations between them. The data looks akin to movie rating/ movie stats database where I want to figure out what movie would a person like depending on previous ratings. I would also like it to be something I can use as API from programming language that is more universal (unlike R for example) so I can build upon it more easily.&lt;/p&gt;\n\n&lt;p&gt;Thanks for help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13134ku", "is_robot_indexable": true, "report_reasons": null, "author": "TopPaleontologist185", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13134ku/looking_for_a_software_that_can_automatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13134ku/looking_for_a_software_that_can_automatically/", "subreddit_subscribers": 883290, "created_utc": 1682623273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Been in data science, modeling, and analytics for ~10 years total. I\u2019d like to advance in terms of gaining leadership experience with hopes of having my own team in the next few years. I have always wanted to be in a mentoring role. I\u2019d like to do some reading on the subject, but don\u2019t really know where to start. Or if anyone has any conference or course recommendations.", "author_fullname": "t2_gkzxk97m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some resources specific to leadership within data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13131tm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682623139.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been in data science, modeling, and analytics for ~10 years total. I\u2019d like to advance in terms of gaining leadership experience with hopes of having my own team in the next few years. I have always wanted to be in a mentoring role. I\u2019d like to do some reading on the subject, but don\u2019t really know where to start. Or if anyone has any conference or course recommendations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13131tm", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Stock950", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13131tm/what_are_some_resources_specific_to_leadership/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13131tm/what_are_some_resources_specific_to_leadership/", "subreddit_subscribers": 883290, "created_utc": 1682623139.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I want to use GridsearchCV for hyperparametertuning, but in my code  there are several parts that I want to try different parameters for. I  first want to use SMOTE for oversampling, and there the parameters would  be the k-nearest neighbours (either 3, 5 or 7), and sampling\\_strategy  which will be either 0.1, 0.15, or 0.2. Then when I use LDA (latent  Dirichlet allocation) I want to set the topic count to either 5, 10 or  15. And then I want to use a multinomial na\u00efve bayes classifier, and  either do the classification with only the descriptions as predictor,  the descriptions and the publisher, or descriptions, publisher,  pagecount, and title.  \n\nCan I do all of this is the same GridSearchCV algorithm? Cause so far I have only found examples where they use one classifier and then use GridsearchCV to try different parameters for that single model.", "author_fullname": "t2_2uua33bh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using GridsearchCV for several parts of code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131279p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682621659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to use GridsearchCV for hyperparametertuning, but in my code  there are several parts that I want to try different parameters for. I  first want to use SMOTE for oversampling, and there the parameters would  be the k-nearest neighbours (either 3, 5 or 7), and sampling_strategy  which will be either 0.1, 0.15, or 0.2. Then when I use LDA (latent  Dirichlet allocation) I want to set the topic count to either 5, 10 or  15. And then I want to use a multinomial na\u00efve bayes classifier, and  either do the classification with only the descriptions as predictor,  the descriptions and the publisher, or descriptions, publisher,  pagecount, and title.  &lt;/p&gt;\n\n&lt;p&gt;Can I do all of this is the same GridSearchCV algorithm? Cause so far I have only found examples where they use one classifier and then use GridsearchCV to try different parameters for that single model.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "131279p", "is_robot_indexable": true, "report_reasons": null, "author": "Romcom1398", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/131279p/using_gridsearchcv_for_several_parts_of_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/131279p/using_gridsearchcv_for_several_parts_of_code/", "subreddit_subscribers": 883290, "created_utc": 1682621659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I've been a data engineer for about 2 years now and am currently getting a masters in data analytics.\n\nI use snowflake sql, python, and aws in my current role.\n\nIn my coursework for my class we go over network science (doesn't even seem related to the field except in niche roles it seems?), ML, data visualization, cloud, sas, and spark to name a few tools.\n\nA few questions- is there any difference between data analyst/ data scientist/ ML engineer / MLops roles? Or are they pretty much synonymous and more company dependent? I'm more interested in getting into data prep, model training and model deployment as opposed to visualization. Is there a specific role I should be targeting that would fit my interests? From some research it seems like I should be targeting data science roles? Not sure if It would be too much of a jump in terms of lack of experience to jump into the role as my professional experience with modeling is only part time teaching kids ML and an internship where I did some computer vision stuff.\n\nWhat's the day to day look like in the role? Is most of your work spend on the data prep/ model training/ model deployment?\n\nWhere can I go to learn about industry standards about model creation and deployment? If there's one thing I've learned from undergrad, school did not prepare me well for that and I don't expect grad school to be different.", "author_fullname": "t2_7170e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What steps should I take to transition my data engineering career to a data analyst/ML engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130u52o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682613264.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682612454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;ve been a data engineer for about 2 years now and am currently getting a masters in data analytics.&lt;/p&gt;\n\n&lt;p&gt;I use snowflake sql, python, and aws in my current role.&lt;/p&gt;\n\n&lt;p&gt;In my coursework for my class we go over network science (doesn&amp;#39;t even seem related to the field except in niche roles it seems?), ML, data visualization, cloud, sas, and spark to name a few tools.&lt;/p&gt;\n\n&lt;p&gt;A few questions- is there any difference between data analyst/ data scientist/ ML engineer / MLops roles? Or are they pretty much synonymous and more company dependent? I&amp;#39;m more interested in getting into data prep, model training and model deployment as opposed to visualization. Is there a specific role I should be targeting that would fit my interests? From some research it seems like I should be targeting data science roles? Not sure if It would be too much of a jump in terms of lack of experience to jump into the role as my professional experience with modeling is only part time teaching kids ML and an internship where I did some computer vision stuff.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the day to day look like in the role? Is most of your work spend on the data prep/ model training/ model deployment?&lt;/p&gt;\n\n&lt;p&gt;Where can I go to learn about industry standards about model creation and deployment? If there&amp;#39;s one thing I&amp;#39;ve learned from undergrad, school did not prepare me well for that and I don&amp;#39;t expect grad school to be different.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "130u52o", "is_robot_indexable": true, "report_reasons": null, "author": "wcb98", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/130u52o/what_steps_should_i_take_to_transition_my_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/130u52o/what_steps_should_i_take_to_transition_my_data/", "subreddit_subscribers": 883290, "created_utc": 1682612454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am going into my third year of a maths degree and wanted some advice on which modules would be most useful for a data science career. If you believe they are all essential, then which ones are the hardest to self-study?\n\nI can **choose 2 from the following:**\n\n&amp;#x200B;\n\n* **Frequentist and Bayesian Inference**\n   * Builds on previous studies of classical (frequentist) inference and introduces  Bayesian inference\n   * Topics such as sufficiency, estimating equations, likelihood ratio tests and best-unbiased estimators are explored in detail.\n   * Will also use statistical packages\n   * I imagine this would be useful as a product analyst running experiments\n\n&amp;#x200B;\n\n* **Optimisation**\n   * Centred around classical optimization problems such as linear programming and nonlinear regression problems arising in a myriad of areas including operations research, computational data science, and financial mathematics, among many others\n   * Could be useful for understanding machine learning algorithms - things like gradient descent.\n   * Known for being an easier module\n\n&amp;#x200B;\n\n* **Time Series Analysis**\n   * concepts of stationary and non-stationary time series;\n   * philosophy of model building in the context of time series analysis;\n   * simple time series models and their properties;\n   * the model identification process;\n   * estimation of parameters;\n   * assessing the goodness of fit;\n   * methods for forecasting;\n   * use of a statistical package\n\n&amp;#x200B;\n\n* **Stochastic Models**\n   * probably the least practical module, but I did enjoy studying Markov chains...\n   * Builds on previous studies of discrete-time Markov chains.\n   * homogeneous Poisson processes and their elementary properties;\n   * birth-and-death processes - forward and backward equations, extinction probability;\n   * epidemic processes - chain-binomial models, parameter estimation, deterministic and stochastic general epidemic, threshold behaviour, carrier-borne epidemics;\n   * queueing processes - equilibrium behaviour of single server queues;\n   * queues with priorities;\n   * component reliability and replacement schemes;\n   * system reliability;\n   * Stochastic differential equations and Ito's lemma.", "author_fullname": "t2_i4soxrm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which modules would you recommend for an aspiring data scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130q332", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682615599.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682607874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am going into my third year of a maths degree and wanted some advice on which modules would be most useful for a data science career. If you believe they are all essential, then which ones are the hardest to self-study?&lt;/p&gt;\n\n&lt;p&gt;I can &lt;strong&gt;choose 2 from the following:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Frequentist and Bayesian Inference&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Builds on previous studies of classical (frequentist) inference and introduces  Bayesian inference&lt;/li&gt;\n&lt;li&gt;Topics such as sufficiency, estimating equations, likelihood ratio tests and best-unbiased estimators are explored in detail.&lt;/li&gt;\n&lt;li&gt;Will also use statistical packages&lt;/li&gt;\n&lt;li&gt;I imagine this would be useful as a product analyst running experiments&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Optimisation&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Centred around classical optimization problems such as linear programming and nonlinear regression problems arising in a myriad of areas including operations research, computational data science, and financial mathematics, among many others&lt;/li&gt;\n&lt;li&gt;Could be useful for understanding machine learning algorithms - things like gradient descent.&lt;/li&gt;\n&lt;li&gt;Known for being an easier module&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Time Series Analysis&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;concepts of stationary and non-stationary time series;&lt;/li&gt;\n&lt;li&gt;philosophy of model building in the context of time series analysis;&lt;/li&gt;\n&lt;li&gt;simple time series models and their properties;&lt;/li&gt;\n&lt;li&gt;the model identification process;&lt;/li&gt;\n&lt;li&gt;estimation of parameters;&lt;/li&gt;\n&lt;li&gt;assessing the goodness of fit;&lt;/li&gt;\n&lt;li&gt;methods for forecasting;&lt;/li&gt;\n&lt;li&gt;use of a statistical package&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Stochastic Models&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;probably the least practical module, but I did enjoy studying Markov chains...&lt;/li&gt;\n&lt;li&gt;Builds on previous studies of discrete-time Markov chains.&lt;/li&gt;\n&lt;li&gt;homogeneous Poisson processes and their elementary properties;&lt;/li&gt;\n&lt;li&gt;birth-and-death processes - forward and backward equations, extinction probability;&lt;/li&gt;\n&lt;li&gt;epidemic processes - chain-binomial models, parameter estimation, deterministic and stochastic general epidemic, threshold behaviour, carrier-borne epidemics;&lt;/li&gt;\n&lt;li&gt;queueing processes - equilibrium behaviour of single server queues;&lt;/li&gt;\n&lt;li&gt;queues with priorities;&lt;/li&gt;\n&lt;li&gt;component reliability and replacement schemes;&lt;/li&gt;\n&lt;li&gt;system reliability;&lt;/li&gt;\n&lt;li&gt;Stochastic differential equations and Ito&amp;#39;s lemma.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "130q332", "is_robot_indexable": true, "report_reasons": null, "author": "poorname", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/130q332/which_modules_would_you_recommend_for_an_aspiring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/130q332/which_modules_would_you_recommend_for_an_aspiring/", "subreddit_subscribers": 883290, "created_utc": 1682607874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I need to predict end of quarter customer retention by the end of each week. Ideally I would train separate models on weekly historic data but that would be too much to handle so I'm thinking of training on end of month data and feed the weekly data to the model for predictions. That way I'll have 3 models instead of ~13 models/quarter. \n\nBut the training data has same customer population multiple times. For example two rows of the data (only predictors) would be like: \n\n| ID  | Age | Total Spending  | Month Seq |\n|-----|-----|-----------------|-----------|\n| 007 | 45  | 150             | 1         |   \n| 007 | 45  | 220             | 2         |   \n\nMy understanding is that panel data breaks the assumption that each row is an independent record but how bad would it be if it's broken?", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How bad a idea is it to use panel data for traditional predictive model training?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130j9h4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682595620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to predict end of quarter customer retention by the end of each week. Ideally I would train separate models on weekly historic data but that would be too much to handle so I&amp;#39;m thinking of training on end of month data and feed the weekly data to the model for predictions. That way I&amp;#39;ll have 3 models instead of ~13 models/quarter. &lt;/p&gt;\n\n&lt;p&gt;But the training data has same customer population multiple times. For example two rows of the data (only predictors) would be like: &lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;ID&lt;/th&gt;\n&lt;th&gt;Age&lt;/th&gt;\n&lt;th&gt;Total Spending&lt;/th&gt;\n&lt;th&gt;Month Seq&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;007&lt;/td&gt;\n&lt;td&gt;45&lt;/td&gt;\n&lt;td&gt;150&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;007&lt;/td&gt;\n&lt;td&gt;45&lt;/td&gt;\n&lt;td&gt;220&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;My understanding is that panel data breaks the assumption that each row is an independent record but how bad would it be if it&amp;#39;s broken?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "130j9h4", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/130j9h4/how_bad_a_idea_is_it_to_use_panel_data_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/130j9h4/how_bad_a_idea_is_it_to_use_panel_data_for/", "subreddit_subscribers": 883290, "created_utc": 1682595620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Heh guys, I've gotten an offer for a bachelor's degree in Data Science in the UK and I have around three months before I begin the course. \nI'd like to know the ideal learning path for a novice learner like myself to get a head start in this ever-growing field.\n\nThis is the course modules for my studies:\nhttps://www.sheffield.ac.uk/undergraduate/courses/2024/data-science-bsc", "author_fullname": "t2_7qe2y8bt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I get a good start before starting my university?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_130fn1i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682588730.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heh guys, I&amp;#39;ve gotten an offer for a bachelor&amp;#39;s degree in Data Science in the UK and I have around three months before I begin the course. \nI&amp;#39;d like to know the ideal learning path for a novice learner like myself to get a head start in this ever-growing field.&lt;/p&gt;\n\n&lt;p&gt;This is the course modules for my studies:\n&lt;a href=\"https://www.sheffield.ac.uk/undergraduate/courses/2024/data-science-bsc\"&gt;https://www.sheffield.ac.uk/undergraduate/courses/2024/data-science-bsc&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-qPQl5cbX58IW2h_OYgPWVBAit-zqocJP8jxAR1twcM.jpg?auto=webp&amp;v=enabled&amp;s=03135d9b1f2bdfb63b398535443a73f6412ee459", "width": 1504, "height": 846}, "resolutions": [{"url": "https://external-preview.redd.it/-qPQl5cbX58IW2h_OYgPWVBAit-zqocJP8jxAR1twcM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=99c0d748e9c0e99a1d11f311ab74c66be5bb4156", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/-qPQl5cbX58IW2h_OYgPWVBAit-zqocJP8jxAR1twcM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f8740f3f8bcd1b8c5799ae054d45032c26c2d37a", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/-qPQl5cbX58IW2h_OYgPWVBAit-zqocJP8jxAR1twcM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b40e5d90cba597cdf8bfc1fbbdeb5d1d01bf9034", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/-qPQl5cbX58IW2h_OYgPWVBAit-zqocJP8jxAR1twcM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec199cd803de63a51c5d3d6828bb17cfbce0f6c4", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/-qPQl5cbX58IW2h_OYgPWVBAit-zqocJP8jxAR1twcM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3944484d9f90502ee21b545c2793e014403ac309", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/-qPQl5cbX58IW2h_OYgPWVBAit-zqocJP8jxAR1twcM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1273e095814177720daa98d95d02c66fd70b1fc", "width": 1080, "height": 607}], "variants": {}, "id": "zXHx_XogqVLgdGjZ476PJxAzNrP9q7qYgCs1h_yz75w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "130fn1i", "is_robot_indexable": true, "report_reasons": null, "author": "sheefuzai", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/130fn1i/how_can_i_get_a_good_start_before_starting_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/130fn1i/how_can_i_get_a_good_start_before_starting_my/", "subreddit_subscribers": 883290, "created_utc": 1682588730.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR: Know R + Tidyverse, want to get better at Python + numpy/pandas (or arrow is that better?) + PyData Stack. How?  \n\n\nI'm mainly an R + SQL coder. It gets me through a lot of things... definitely better for visualizations and tidyverse allows for a lot of quick/dirty things to be done adhoc. I have used Python in the past but it always felt cludgy and I never really forced myself to get to where I have near effortless mastery of it.   \n\n\nI'm increasingly, doing XAI and causal inference, and will be productionizing some models in the near future. R works but the packages available seem slow (evtree+GRF vs GOSDT+EconML+CausalML). As such I'm looking towards Python. Also, everyone except for my manager mainly uses Python now. They all know R so it's not a problem but I'm also trying to NOT be the odd man out. \n\nAny tips/tricks for getting good at Python for DS tasks? Should I cram leetcode/hackerrank questions? Maybe push myself to do a few public facing projects on github?", "author_fullname": "t2_9zr0in21s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to get better at Python and the PyData stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_131gnf1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682653506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: Know R + Tidyverse, want to get better at Python + numpy/pandas (or arrow is that better?) + PyData Stack. How?  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m mainly an R + SQL coder. It gets me through a lot of things... definitely better for visualizations and tidyverse allows for a lot of quick/dirty things to be done adhoc. I have used Python in the past but it always felt cludgy and I never really forced myself to get to where I have near effortless mastery of it.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m increasingly, doing XAI and causal inference, and will be productionizing some models in the near future. R works but the packages available seem slow (evtree+GRF vs GOSDT+EconML+CausalML). As such I&amp;#39;m looking towards Python. Also, everyone except for my manager mainly uses Python now. They all know R so it&amp;#39;s not a problem but I&amp;#39;m also trying to NOT be the odd man out. &lt;/p&gt;\n\n&lt;p&gt;Any tips/tricks for getting good at Python for DS tasks? Should I cram leetcode/hackerrank questions? Maybe push myself to do a few public facing projects on github?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "131gnf1", "is_robot_indexable": true, "report_reasons": null, "author": "ramblinginternetgeek", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/131gnf1/looking_to_get_better_at_python_and_the_pydata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/131gnf1/looking_to_get_better_at_python_and_the_pydata/", "subreddit_subscribers": 883290, "created_utc": 1682653506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I applied to NEU MSDS program sometime in the first week of April. I know there are people still waiting from dec to hear back. Have decisions in the previous years been given in mid-late may as well? (Asking if I should keep hope)", "author_fullname": "t2_pwd61hqc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NEU MSDS Decision delay", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_131fxjh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682651360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I applied to NEU MSDS program sometime in the first week of April. I know there are people still waiting from dec to hear back. Have decisions in the previous years been given in mid-late may as well? (Asking if I should keep hope)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "131fxjh", "is_robot_indexable": true, "report_reasons": null, "author": "Sherlock-1899", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/131fxjh/neu_msds_decision_delay/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/131fxjh/neu_msds_decision_delay/", "subreddit_subscribers": 883290, "created_utc": 1682651360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi! I'm trying to start on this case study project for my portfolio the dataset I have had 16 different csv files I'm trying to combine these into one csv file in order to analyze data is this not the correct approach seems as if all \"solutions\" aren't working. Any insight would be greatly appreciated this is my first project! TIA", "author_fullname": "t2_5ljrjtkja", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "case study dataset issues", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131en56", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682647708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m trying to start on this case study project for my portfolio the dataset I have had 16 different csv files I&amp;#39;m trying to combine these into one csv file in order to analyze data is this not the correct approach seems as if all &amp;quot;solutions&amp;quot; aren&amp;#39;t working. Any insight would be greatly appreciated this is my first project! TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "131en56", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious-Tea1886", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/131en56/case_study_dataset_issues/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/131en56/case_study_dataset_issues/", "subreddit_subscribers": 883290, "created_utc": 1682647708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are your experiences using some tool or system to track issues and tasks related to data projects. I\u2019m coming across small projects (maybe 1-3 weeks) but there\u2019s lots of stakeholders who provide data inputs, or want particular outputs, or other teams need to do subtasks and such. So I\u2019m looking for something to just have a common url that people can view and add info to. \n\nI\u2019ve used jira in the past but it gets expensive with lots of users, especially infrequent users who might only want to see a single project in a year. \n\nI\u2019ve used GitLab and GitHub issues pretty effectively but non-devs seem to have a tough time accessing and working on items. \n\nMy org uses ServiceNow but it seems more like just a ticketing system than a collaboration tool. And the UI is really unpleasant looking and difficult to navigate. \n\nAny particular tools that are lightweight and easy for diverse stakeholder groups to connect to and use without a lot of cost and training.", "author_fullname": "t2_6r40s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good issue tracker for data projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131dbqo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682644082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your experiences using some tool or system to track issues and tasks related to data projects. I\u2019m coming across small projects (maybe 1-3 weeks) but there\u2019s lots of stakeholders who provide data inputs, or want particular outputs, or other teams need to do subtasks and such. So I\u2019m looking for something to just have a common url that people can view and add info to. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve used jira in the past but it gets expensive with lots of users, especially infrequent users who might only want to see a single project in a year. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve used GitLab and GitHub issues pretty effectively but non-devs seem to have a tough time accessing and working on items. &lt;/p&gt;\n\n&lt;p&gt;My org uses ServiceNow but it seems more like just a ticketing system than a collaboration tool. And the UI is really unpleasant looking and difficult to navigate. &lt;/p&gt;\n\n&lt;p&gt;Any particular tools that are lightweight and easy for diverse stakeholder groups to connect to and use without a lot of cost and training.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "131dbqo", "is_robot_indexable": true, "report_reasons": null, "author": "prepend", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/131dbqo/good_issue_tracker_for_data_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/131dbqo/good_issue_tracker_for_data_projects/", "subreddit_subscribers": 883290, "created_utc": 1682644082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have experience with SQL queries / DOMO/ and a bit of Tableau, and use SQL everyday at my current job as an operations analyst.My college background is business, and I have experience in sales operations. \n\nFor those working as an analyst / data analyst what is a good next step I can take to stand out and improve my skills, or is there a certificate which may help me? \n\nI know there are a lot out there, Coursera, Google analytics, etc.\n\nAny advice is appreciated.", "author_fullname": "t2_4dnjg2o7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Courses/ skills to advance career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_131d4ex", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682643544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have experience with SQL queries / DOMO/ and a bit of Tableau, and use SQL everyday at my current job as an operations analyst.My college background is business, and I have experience in sales operations. &lt;/p&gt;\n\n&lt;p&gt;For those working as an analyst / data analyst what is a good next step I can take to stand out and improve my skills, or is there a certificate which may help me? &lt;/p&gt;\n\n&lt;p&gt;I know there are a lot out there, Coursera, Google analytics, etc.&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "131d4ex", "is_robot_indexable": true, "report_reasons": null, "author": "Dex1155115115", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/131d4ex/courses_skills_to_advance_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/131d4ex/courses_skills_to_advance_career/", "subreddit_subscribers": 883290, "created_utc": 1682643544.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}