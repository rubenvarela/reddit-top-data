{"kind": "Listing", "data": {"after": "t3_12x55ng", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I applied for a DS position at a company a while ago and interviewed with them, after which they gave me a take-home exam. It was a project where I had to use company data, and I completed it within the given one-week deadline. However, it's been almost a month now, and I haven't heard anything back from them. I suppose I'm not hearing back from them ever, but I want to know if this was legal for them to do. I had to build machine learning models using their client data, it wasn't exactly easy work. Worth mentioning that while I applied and interviewed for DS, the recruiter said the project was for a DA position. Classic bait-and-switch, but I still did the exam since the job market is bad. I addressed this when I sent the finished result back to them (asked for clarification on the position and said I was out if it's not DS).", "author_fullname": "t2_w0if7iet", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Company gave me their real datasets for take-home exam + bait and switch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xd1h0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 253, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 253, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682337190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I applied for a DS position at a company a while ago and interviewed with them, after which they gave me a take-home exam. It was a project where I had to use company data, and I completed it within the given one-week deadline. However, it&amp;#39;s been almost a month now, and I haven&amp;#39;t heard anything back from them. I suppose I&amp;#39;m not hearing back from them ever, but I want to know if this was legal for them to do. I had to build machine learning models using their client data, it wasn&amp;#39;t exactly easy work. Worth mentioning that while I applied and interviewed for DS, the recruiter said the project was for a DA position. Classic bait-and-switch, but I still did the exam since the job market is bad. I addressed this when I sent the finished result back to them (asked for clarification on the position and said I was out if it&amp;#39;s not DS).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xd1h0", "is_robot_indexable": true, "report_reasons": null, "author": "Direct_Pie_9059", "discussion_type": null, "num_comments": 91, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xd1h0/company_gave_me_their_real_datasets_for_takehome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xd1h0/company_gave_me_their_real_datasets_for_takehome/", "subreddit_subscribers": 880180, "created_utc": 1682337190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_n6gdbs8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recently I've been thinking a lot about what I do that makes me happy. What better way to understand that than to do sentiment analysis on 20 years of gmail history! Labels are the main things I've worked on in the last twenty years.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_12xbyeo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 121, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 121, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Scrut_DPaSZev7ety8giccZuW2eu4cWfOa1TDUTw-vY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682334588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ao35zmctetva1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ao35zmctetva1.png?auto=webp&amp;v=enabled&amp;s=c11c5ca28a5c9f4f0012d6ec056f90c9eceea70a", "width": 2560, "height": 1340}, "resolutions": [{"url": "https://preview.redd.it/ao35zmctetva1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=291fb9fb61437209a28c584419468c151df454f2", "width": 108, "height": 56}, {"url": "https://preview.redd.it/ao35zmctetva1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b55e1a796e08b6626dd8cc19121e55b10f49d82c", "width": 216, "height": 113}, {"url": "https://preview.redd.it/ao35zmctetva1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d01c776805ed267855acb93ff02f67434da497c1", "width": 320, "height": 167}, {"url": "https://preview.redd.it/ao35zmctetva1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34c600ab48dbf82606c09bb70caba0f6b78e18bb", "width": 640, "height": 335}, {"url": "https://preview.redd.it/ao35zmctetva1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8cd556ba948b613d50f9c80c3599503a97532000", "width": 960, "height": 502}, {"url": "https://preview.redd.it/ao35zmctetva1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=61369a7d828fa681bd2121051364429ae0f2d643", "width": 1080, "height": 565}], "variants": {}, "id": "UvBuB8spDOpalEpSmjvDmOWY6RksopEVgs0zdiV0mss"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xbyeo", "is_robot_indexable": true, "report_reasons": null, "author": "EvilCorpGame", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xbyeo/recently_ive_been_thinking_a_lot_about_what_i_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ao35zmctetva1.png", "subreddit_subscribers": 880180, "created_utc": 1682334588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Floundering in the sea of knowledge atm.\n\nSend inspiration please.", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When did data science start \"clicking\" for you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xhmfi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682346487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Floundering in the sea of knowledge atm.&lt;/p&gt;\n\n&lt;p&gt;Send inspiration please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xhmfi", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xhmfi/when_did_data_science_start_clicking_for_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xhmfi/when_did_data_science_start_clicking_for_you/", "subreddit_subscribers": 880180, "created_utc": 1682346487.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m a beginner at data analysis and I\u2019ve been given a task, sort of a test to see what I can come up with by utilizing available data and the power of the internet. So here\u2019s what I need to do:\n\nThe company is in manufacturing, and I was tasked with looking at delivery turnaround times for a specific client on a month to month basis for the last 12 months. And I was told simply and vaguely to present my findings and \u201cany insight I can gain from it.\u201d\n\nSo, I thought about presenting it as a line chart to show the trends for this specific client. AND I also thought about showing that data along side the trends for ALL clients, to compare this client against.\n\nMy questions are:\n\n1. is there any other suggested ways to gain insights, based on the data description above?\n2. what would be good ways to present this data? I feel like just making a line chart seems to high school. I feel like there might be better ways to visualize and present this data.", "author_fullname": "t2_c10zsd9n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am looking for help on how to use specific data to gain insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12x9grn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682327500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a beginner at data analysis and I\u2019ve been given a task, sort of a test to see what I can come up with by utilizing available data and the power of the internet. So here\u2019s what I need to do:&lt;/p&gt;\n\n&lt;p&gt;The company is in manufacturing, and I was tasked with looking at delivery turnaround times for a specific client on a month to month basis for the last 12 months. And I was told simply and vaguely to present my findings and \u201cany insight I can gain from it.\u201d&lt;/p&gt;\n\n&lt;p&gt;So, I thought about presenting it as a line chart to show the trends for this specific client. AND I also thought about showing that data along side the trends for ALL clients, to compare this client against.&lt;/p&gt;\n\n&lt;p&gt;My questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;is there any other suggested ways to gain insights, based on the data description above?&lt;/li&gt;\n&lt;li&gt;what would be good ways to present this data? I feel like just making a line chart seems to high school. I feel like there might be better ways to visualize and present this data.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12x9grn", "is_robot_indexable": true, "report_reasons": null, "author": "EmoryCadet", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12x9grn/i_am_looking_for_help_on_how_to_use_specific_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12x9grn/i_am_looking_for_help_on_how_to_use_specific_data/", "subreddit_subscribers": 880180, "created_utc": 1682327500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 24 Apr, 2023 - 01 May, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12x2df1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682308886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12x2df1", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 24, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12x2df1/weekly_entering_transitioning_thread_24_apr_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/12x2df1/weekly_entering_transitioning_thread_24_apr_2023/", "subreddit_subscribers": 880180, "created_utc": 1682308886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Business Problem**: Company has an existing client base. They are looking to expand usage of a specific service within their existing client base. Industry average is 40% usage, while company client usage is closer to 5%. The company wants to identify existing customers who are likely to use the service.\n\n&amp;#x200B;\n\n**Data Science Setup:** This is a Positive-Unlabeled problem since there are current clients that are Positive (using the service) and clients that are Unlabeled  (unknown if they would use the service). There are no negative cases since we don't know if clients who currently aren't using the service would or not.\n\n&amp;#x200B;\n\n**My Proposed Solution:** Cluster clients who use the service in order group specific segments of population together. Then use One-Class SVM to set a boundary in the feature-space. Normally, SVM tries to maximize the distance between classes, but in One-Class SVM, the goal is to draw the tightest boundary around the data. Then, the Unlabeled data (clients not currently using the service) would be mapped into the space and any within the boundary would be good candidates to use the service. This approach is ideal since the modeling technique only requires the positive class (hence the \"One-Class\")\n\n&amp;#x200B;\n\n**Alternate Proposed Solution:** Mark customers who use the service as True and customers who don't as False. Train an XGBoost model on data set. False-Positives (Customers who were marked as \"Use the Service\" by the model but who actually don't) are the new prospects for using the service.\n\n&amp;#x200B;\n\n**What I Need Help With:**  I am trying to explain why the output metrics (Accuracy, F1-Score, etc.) are not valid in this scenario. It is not a traditional classification since we do not have any negative-class records (don't need the service, not just currently don't use it). This is especially true since for every 1 positive record, we know we are missing 7 (based on industry average-- 40% vs our 5% usage). People are hung up on the results (Accuracy of 93%!!!1!!). \n\nI do not believe that the metrics are valid and I don't think that the model will provide real-world results. \n\nAm I wrong? How can I explain this?", "author_fullname": "t2_4df9q790", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Problems with Using XGBoost with Positive-Only Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xu0je", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682365726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Business Problem&lt;/strong&gt;: Company has an existing client base. They are looking to expand usage of a specific service within their existing client base. Industry average is 40% usage, while company client usage is closer to 5%. The company wants to identify existing customers who are likely to use the service.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data Science Setup:&lt;/strong&gt; This is a Positive-Unlabeled problem since there are current clients that are Positive (using the service) and clients that are Unlabeled  (unknown if they would use the service). There are no negative cases since we don&amp;#39;t know if clients who currently aren&amp;#39;t using the service would or not.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My Proposed Solution:&lt;/strong&gt; Cluster clients who use the service in order group specific segments of population together. Then use One-Class SVM to set a boundary in the feature-space. Normally, SVM tries to maximize the distance between classes, but in One-Class SVM, the goal is to draw the tightest boundary around the data. Then, the Unlabeled data (clients not currently using the service) would be mapped into the space and any within the boundary would be good candidates to use the service. This approach is ideal since the modeling technique only requires the positive class (hence the &amp;quot;One-Class&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Alternate Proposed Solution:&lt;/strong&gt; Mark customers who use the service as True and customers who don&amp;#39;t as False. Train an XGBoost model on data set. False-Positives (Customers who were marked as &amp;quot;Use the Service&amp;quot; by the model but who actually don&amp;#39;t) are the new prospects for using the service.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I Need Help With:&lt;/strong&gt;  I am trying to explain why the output metrics (Accuracy, F1-Score, etc.) are not valid in this scenario. It is not a traditional classification since we do not have any negative-class records (don&amp;#39;t need the service, not just currently don&amp;#39;t use it). This is especially true since for every 1 positive record, we know we are missing 7 (based on industry average-- 40% vs our 5% usage). People are hung up on the results (Accuracy of 93%!!!1!!). &lt;/p&gt;\n\n&lt;p&gt;I do not believe that the metrics are valid and I don&amp;#39;t think that the model will provide real-world results. &lt;/p&gt;\n\n&lt;p&gt;Am I wrong? How can I explain this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xu0je", "is_robot_indexable": true, "report_reasons": null, "author": "adrift_burrito", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xu0je/problems_with_using_xgboost_with_positiveonly_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xu0je/problems_with_using_xgboost_with_positiveonly_data/", "subreddit_subscribers": 880180, "created_utc": 1682365726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys,\n\nRecently I was interviewing for a data analyst position. To give you a brief BG, I have around 1.5 years of experience as a data analyst.\n\nDuring the interview they asked me \"what is the biggest blunder you made and what did you learn from it?\"\n\nNow this is loaded. \n\nDo you give a honest answer, or do you give a fake one? \n\nI... Didn't have a huge blunder so I kind of made one up, where I said I messed up in A/B testing of a model and that had a big impact on resources and yada yada.\n\nI feel the answer I gave was the reason why I was not chosen for the position.\n\nSo do you guys give them a straight no, that you have not made any blunders or do you make stuff up? And if you have made blunders, then do you tone it down or is there a specific way that you present these blunders? \n\nAny response would be appreciated.", "author_fullname": "t2_jo4irqsu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a strategy to answer this question in an interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12y2nxh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682383605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;Recently I was interviewing for a data analyst position. To give you a brief BG, I have around 1.5 years of experience as a data analyst.&lt;/p&gt;\n\n&lt;p&gt;During the interview they asked me &amp;quot;what is the biggest blunder you made and what did you learn from it?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Now this is loaded. &lt;/p&gt;\n\n&lt;p&gt;Do you give a honest answer, or do you give a fake one? &lt;/p&gt;\n\n&lt;p&gt;I... Didn&amp;#39;t have a huge blunder so I kind of made one up, where I said I messed up in A/B testing of a model and that had a big impact on resources and yada yada.&lt;/p&gt;\n\n&lt;p&gt;I feel the answer I gave was the reason why I was not chosen for the position.&lt;/p&gt;\n\n&lt;p&gt;So do you guys give them a straight no, that you have not made any blunders or do you make stuff up? And if you have made blunders, then do you tone it down or is there a specific way that you present these blunders? &lt;/p&gt;\n\n&lt;p&gt;Any response would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12y2nxh", "is_robot_indexable": true, "report_reasons": null, "author": "thanderrine", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12y2nxh/is_there_a_strategy_to_answer_this_question_in_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12y2nxh/is_there_a_strategy_to_answer_this_question_in_an/", "subreddit_subscribers": 880180, "created_utc": 1682383605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My friend [Donny Flynn](https://www.linkedin.com/in/donny-flynn-578149a4/) has been using dbt for a couple years, and tomorrow he'll be hosting a free, live workshop on how to make the most of Macros and Jinja in dbt\n\nNote: This is not a dbt sponsored event, and we are not selling you any SaaS! If you wanna learn about Macros and Jinja, that's what you'll learn. There's no surprise \"now buy this thing!\" at the end of the workshop \ud83e\udd23  \nHere's what Donny will cover:  \n\\- How to best leverage dbt macros and Jinja  \n\\- Live demo of coding macros... Donny demonstrates how to to calculate rolling averages!  \n\\- How to put this all into practice in your organizations (hint: document all the things)\n\nIf this interests you at all, sign up [here](https://www.operationalanalytics.club/events/jinja-ninja-get-your-black-belt-in-dbt-macros-w-donny-flynn)!", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advanced use Cases for dbt's Jinja and Macros", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xxq0a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682372802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My friend &lt;a href=\"https://www.linkedin.com/in/donny-flynn-578149a4/\"&gt;Donny Flynn&lt;/a&gt; has been using dbt for a couple years, and tomorrow he&amp;#39;ll be hosting a free, live workshop on how to make the most of Macros and Jinja in dbt&lt;/p&gt;\n\n&lt;p&gt;Note: This is not a dbt sponsored event, and we are not selling you any SaaS! If you wanna learn about Macros and Jinja, that&amp;#39;s what you&amp;#39;ll learn. There&amp;#39;s no surprise &amp;quot;now buy this thing!&amp;quot; at the end of the workshop \ud83e\udd23&lt;br/&gt;\nHere&amp;#39;s what Donny will cover:&lt;br/&gt;\n- How to best leverage dbt macros and Jinja&lt;br/&gt;\n- Live demo of coding macros... Donny demonstrates how to to calculate rolling averages!&lt;br/&gt;\n- How to put this all into practice in your organizations (hint: document all the things)&lt;/p&gt;\n\n&lt;p&gt;If this interests you at all, sign up &lt;a href=\"https://www.operationalanalytics.club/events/jinja-ninja-get-your-black-belt-in-dbt-macros-w-donny-flynn\"&gt;here&lt;/a&gt;!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xxq0a", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xxq0a/advanced_use_cases_for_dbts_jinja_and_macros/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xxq0a/advanced_use_cases_for_dbts_jinja_and_macros/", "subreddit_subscribers": 880180, "created_utc": 1682372802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m a econ phd student currently interning full time on a time series forecasting team due to funding issues. The team said they could provide me data for a thesis so that seemed cool.\n\nThe problem is my manager is obsessed with minimising the MAPE of a consumption forecasting model. It\u2019s somehow a never ending problem, where I\u2019m continuously adding new x variables/aggregating from different levels of the data/using different training lengths/forecasting prices separately and deflating/trying every possible time series model under the sun and choosing combinations of all different models based on random statistics\u2026 all for these 0.1% improvements in MAPE. He also then wanted to use old MAPE - new MAPE / new MAPE to show how much the models have improved to his boss (I managed to convince him we should at least use old MAPE as the denominator\u2026).\n\nAny tips on how to wrap up a seemingly endless project? He never seems satisfied with the model. Note that the forecasts are literally of aggregate US consumption and have nothing to do with internal business data. I was originally told we were going to try to incorporate internal data but my manager seems to think that\u2019s a bad idea and not worth trying. \n\nOverall I never even really get time to work on thesis or even get tasks that would help me learn about the data available.", "author_fullname": "t2_b027350z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manager obsessed with minimising MAPEs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xqtvc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682359063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a econ phd student currently interning full time on a time series forecasting team due to funding issues. The team said they could provide me data for a thesis so that seemed cool.&lt;/p&gt;\n\n&lt;p&gt;The problem is my manager is obsessed with minimising the MAPE of a consumption forecasting model. It\u2019s somehow a never ending problem, where I\u2019m continuously adding new x variables/aggregating from different levels of the data/using different training lengths/forecasting prices separately and deflating/trying every possible time series model under the sun and choosing combinations of all different models based on random statistics\u2026 all for these 0.1% improvements in MAPE. He also then wanted to use old MAPE - new MAPE / new MAPE to show how much the models have improved to his boss (I managed to convince him we should at least use old MAPE as the denominator\u2026).&lt;/p&gt;\n\n&lt;p&gt;Any tips on how to wrap up a seemingly endless project? He never seems satisfied with the model. Note that the forecasts are literally of aggregate US consumption and have nothing to do with internal business data. I was originally told we were going to try to incorporate internal data but my manager seems to think that\u2019s a bad idea and not worth trying. &lt;/p&gt;\n\n&lt;p&gt;Overall I never even really get time to work on thesis or even get tasks that would help me learn about the data available.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xqtvc", "is_robot_indexable": true, "report_reasons": null, "author": "archiepomchi", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xqtvc/manager_obsessed_with_minimising_mapes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xqtvc/manager_obsessed_with_minimising_mapes/", "subreddit_subscribers": 880180, "created_utc": 1682359063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello guys, i'm a fresh data science masters degree graduate, as an international student in the UK, i found difficulties to find an internship or a job after my graduation due to two reasons: my visa status and the lack of experience.\n\nit's fair i guess, i need to do more but the problem is due to my visa status i find it hard to even get unpaid internships, not sure what i'm doing wrong and i could really use some helpful advice from people who faced the same issue\n\nthank's in advance", "author_fullname": "t2_55642ldz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "some advice to proceed in the data field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xqtjs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682359045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, i&amp;#39;m a fresh data science masters degree graduate, as an international student in the UK, i found difficulties to find an internship or a job after my graduation due to two reasons: my visa status and the lack of experience.&lt;/p&gt;\n\n&lt;p&gt;it&amp;#39;s fair i guess, i need to do more but the problem is due to my visa status i find it hard to even get unpaid internships, not sure what i&amp;#39;m doing wrong and i could really use some helpful advice from people who faced the same issue&lt;/p&gt;\n\n&lt;p&gt;thank&amp;#39;s in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xqtjs", "is_robot_indexable": true, "report_reasons": null, "author": "ARA-GOD", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xqtjs/some_advice_to_proceed_in_the_data_field/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xqtjs/some_advice_to_proceed_in_the_data_field/", "subreddit_subscribers": 880180, "created_utc": 1682359045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_jix1wo4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Transformer Encoder Demystified: An Easy-to-Understand Explanation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_12xow6w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"267\" height=\"200\" src=\"https://www.youtube.com/embed/73gTEub2e3I?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The Transformer Encoder Demystified: An Easy-to-Understand Explanation\"&gt;&lt;/iframe&gt;", "width": 267, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "The Transformer Encoder Demystified: An Easy-to-Understand Explanation", "type": "video", "thumbnail_width": 480, "height": 200, "width": 267, "html": "&lt;iframe width=\"267\" height=\"200\" src=\"https://www.youtube.com/embed/73gTEub2e3I?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The Transformer Encoder Demystified: An Easy-to-Understand Explanation\"&gt;&lt;/iframe&gt;", "author_name": "Sachin Kalsi", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/73gTEub2e3I/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ml-simplified"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"267\" height=\"200\" src=\"https://www.youtube.com/embed/73gTEub2e3I?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The Transformer Encoder Demystified: An Easy-to-Understand Explanation\"&gt;&lt;/iframe&gt;", "width": 267, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/12xow6w", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TvpxC2PDVgW9bYmRM4JN6AemeijeJ0276RCFeDXWVis.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682355078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/73gTEub2e3I", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5FqN7QBnFEiExIp0-qFKvwQTp9VYl33Vn5Ibk6JVRIY.jpg?auto=webp&amp;v=enabled&amp;s=e7aa51c79396bdc437868fba9684b40b458778bb", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/5FqN7QBnFEiExIp0-qFKvwQTp9VYl33Vn5Ibk6JVRIY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b8593d99d26b04ccde20aeb832b7aee01a150db", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/5FqN7QBnFEiExIp0-qFKvwQTp9VYl33Vn5Ibk6JVRIY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7bb4d2d218b3982f0bd0cfd3ef432c55aa16ff6b", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/5FqN7QBnFEiExIp0-qFKvwQTp9VYl33Vn5Ibk6JVRIY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=139ca920abc0444a9dfd60a1052cdffba2216f93", "width": 320, "height": 240}], "variants": {}, "id": "QMXQ3cM9VYt10pqZV1kmLTLP686D3nYNGVUDqjSW9pY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xow6w", "is_robot_indexable": true, "report_reasons": null, "author": "kalsi_sachin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xow6w/the_transformer_encoder_demystified_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/73gTEub2e3I", "subreddit_subscribers": 880180, "created_utc": 1682355078.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "The Transformer Encoder Demystified: An Easy-to-Understand Explanation", "type": "video", "thumbnail_width": 480, "height": 200, "width": 267, "html": "&lt;iframe width=\"267\" height=\"200\" src=\"https://www.youtube.com/embed/73gTEub2e3I?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The Transformer Encoder Demystified: An Easy-to-Understand Explanation\"&gt;&lt;/iframe&gt;", "author_name": "Sachin Kalsi", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/73gTEub2e3I/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ml-simplified"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I just put up a new [dataset](https://www.kaggle.com/datasets/hrokrin/us-core-samples) and attached [notebook](https://www.kaggle.com/datasets/hrokrin/us-core-samples/code) on the US Geological Survey Core Sample Catalog.\n\nMost of the charts are in plotly but there is one using folium and couple using my favorite torture device, matplotlib. It also uses a waterfall chart. Finally, at the end there are some additional ideas for charts that should be fairly easy to generate.\n\nI'd love feedback.\n\nHowever, if you're too busy answering burning questions like:\n\n* Why does the ***US***GS have a couple of core samples from Canada and Austrailia, it's not like we're going to invade -- or *are* we?\n* Why were 64 wells drilled in the Pacific?\n* What is the easternmost test well drilled in the US?\n\nwell, I'd understand. But I am serious about feedback for either.\n\nThanks", "author_fullname": "t2_3k6hhf49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Holes drilled into the earth for fun and profit -- but mostly profit.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xnm1a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682352435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just put up a new &lt;a href=\"https://www.kaggle.com/datasets/hrokrin/us-core-samples\"&gt;dataset&lt;/a&gt; and attached &lt;a href=\"https://www.kaggle.com/datasets/hrokrin/us-core-samples/code\"&gt;notebook&lt;/a&gt; on the US Geological Survey Core Sample Catalog.&lt;/p&gt;\n\n&lt;p&gt;Most of the charts are in plotly but there is one using folium and couple using my favorite torture device, matplotlib. It also uses a waterfall chart. Finally, at the end there are some additional ideas for charts that should be fairly easy to generate.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love feedback.&lt;/p&gt;\n\n&lt;p&gt;However, if you&amp;#39;re too busy answering burning questions like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Why does the &lt;strong&gt;&lt;em&gt;US&lt;/em&gt;&lt;/strong&gt;GS have a couple of core samples from Canada and Austrailia, it&amp;#39;s not like we&amp;#39;re going to invade -- or &lt;em&gt;are&lt;/em&gt; we?&lt;/li&gt;\n&lt;li&gt;Why were 64 wells drilled in the Pacific?&lt;/li&gt;\n&lt;li&gt;What is the easternmost test well drilled in the US?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;well, I&amp;#39;d understand. But I am serious about feedback for either.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Q5JFiEN4AztmAC915_I63QEoLO4c0jxnnigux6Wvjic.jpg?auto=webp&amp;v=enabled&amp;s=641d3f009e9b1e69a425c39e5ebd6e6466ba3acc", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/Q5JFiEN4AztmAC915_I63QEoLO4c0jxnnigux6Wvjic.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f52e82ff3aceb3f2c2dfdb6290fd89a5cc29993", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/Q5JFiEN4AztmAC915_I63QEoLO4c0jxnnigux6Wvjic.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33e52b328d62cc0fae759c23e6caeb90994ebbe9", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/Q5JFiEN4AztmAC915_I63QEoLO4c0jxnnigux6Wvjic.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ccad364193288fee101ef97115cf398a46750f5a", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/Q5JFiEN4AztmAC915_I63QEoLO4c0jxnnigux6Wvjic.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49dff66bd438d3dc09467d5996719fc0d80ce7a3", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/Q5JFiEN4AztmAC915_I63QEoLO4c0jxnnigux6Wvjic.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=894a2b2a900cebc0acb7d22844fe0aadecaf17f0", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/Q5JFiEN4AztmAC915_I63QEoLO4c0jxnnigux6Wvjic.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ca1aa2b6a0a311dd1f40d9764ab147bb2abb816", "width": 1080, "height": 1080}], "variants": {}, "id": "peCUDADp8j1_OaoqJDosFZAAEOnqScgsH-i0xqhTR0I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xnm1a", "is_robot_indexable": true, "report_reasons": null, "author": "hrokrin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xnm1a/holes_drilled_into_the_earth_for_fun_and_profit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xnm1a/holes_drilled_into_the_earth_for_fun_and_profit/", "subreddit_subscribers": 880180, "created_utc": 1682352435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hi all! title basically says it all, im looking for some fun teambuilding games to do for teams that work in data science. preferably for free :)", "author_fullname": "t2_4mr4l4g8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "looking for online and free teambuilding games for data science teams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xnl8w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682352388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi all! title basically says it all, im looking for some fun teambuilding games to do for teams that work in data science. preferably for free :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xnl8w", "is_robot_indexable": true, "report_reasons": null, "author": "8mw8", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xnl8w/looking_for_online_and_free_teambuilding_games/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xnl8w/looking_for_online_and_free_teambuilding_games/", "subreddit_subscribers": 880180, "created_utc": 1682352388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI want to do object detection on road defect with Classes like wet pothole, dry pothole, and alligator cracks, etc, for each defect I also want to measure the severity. \n\nHow should I go about the task?", "author_fullname": "t2_46r5np3v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Object detection road defects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xbnyh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682333871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I want to do object detection on road defect with Classes like wet pothole, dry pothole, and alligator cracks, etc, for each defect I also want to measure the severity. &lt;/p&gt;\n\n&lt;p&gt;How should I go about the task?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xbnyh", "is_robot_indexable": true, "report_reasons": null, "author": "Logical_Ad6811", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xbnyh/object_detection_road_defects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xbnyh/object_detection_road_defects/", "subreddit_subscribers": 880180, "created_utc": 1682333871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I'm looking for a new laptop, and I'm very interested in the 2022 Zephhyrus G14. The problem is it has an AMD GPU, and also I strongly prefer using Windows, and from what I can find, making a Radeon GPU get along with Pytorch is a bit tricky. Dual booting Ubuntu and using ROCm seems like an option. But I was wondering what your experience with such workflows and a 6700s or a 6800s is? As sad as it seems, waiting for and buying a (probably more expensive) NVIDIA-based machine seems like a more logical approach :(", "author_fullname": "t2_l2ega", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AMD GPU for pytorch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xaat9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682330007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m looking for a new laptop, and I&amp;#39;m very interested in the 2022 Zephhyrus G14. The problem is it has an AMD GPU, and also I strongly prefer using Windows, and from what I can find, making a Radeon GPU get along with Pytorch is a bit tricky. Dual booting Ubuntu and using ROCm seems like an option. But I was wondering what your experience with such workflows and a 6700s or a 6800s is? As sad as it seems, waiting for and buying a (probably more expensive) NVIDIA-based machine seems like a more logical approach :(&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xaat9", "is_robot_indexable": true, "report_reasons": null, "author": "klaafas", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xaat9/amd_gpu_for_pytorch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xaat9/amd_gpu_for_pytorch/", "subreddit_subscribers": 880180, "created_utc": 1682330007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I previously asked r/cscareerquestions if years spent in a postdoc count towards seniority in an industrial role in the context of SWE or MLE. The answer was a resounding \"no\".\n\nI'm currently working as a Data Scienstist in a quasi-academic role for a government research institute. It's nice, but the pay is not great. I'd like to apply for a more senior position following the completion of my contract. Are postdocs widely regarded as work experience in DS?\n\nI am just looking for a second opinion, because while I love my job there's an incentive from my superviser to inflate the value of my transferrable skills to encourage me to renew my contract.", "author_fullname": "t2_2kg2yb8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Work experience from academia", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xa0y0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682329206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I previously asked &lt;a href=\"/r/cscareerquestions\"&gt;r/cscareerquestions&lt;/a&gt; if years spent in a postdoc count towards seniority in an industrial role in the context of SWE or MLE. The answer was a resounding &amp;quot;no&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working as a Data Scienstist in a quasi-academic role for a government research institute. It&amp;#39;s nice, but the pay is not great. I&amp;#39;d like to apply for a more senior position following the completion of my contract. Are postdocs widely regarded as work experience in DS?&lt;/p&gt;\n\n&lt;p&gt;I am just looking for a second opinion, because while I love my job there&amp;#39;s an incentive from my superviser to inflate the value of my transferrable skills to encourage me to renew my contract.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xa0y0", "is_robot_indexable": true, "report_reasons": null, "author": "magical_mykhaylo", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xa0y0/work_experience_from_academia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xa0y0/work_experience_from_academia/", "subreddit_subscribers": 880180, "created_utc": 1682329206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Give me advise : Stock price return prediction using deep learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12y2lky", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_9x4x53qyp", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "learnmachinelearning", "selftext": "Hi, I\u2019m now trying to train the NN model to predict stock price return. However, the performance is terrible. Does anyone know how efficiently I can improve this step by step?? I'm working on one data science competition, \"Numerai Signals\"\n\n## Dataset description\n\n* 3000 stocks\n* 4 years\n* Use the Adj Close column only\n* Daily stock price data\n* train data: 2017-2022\n* test data: 2022-2023\n* Targets are provided by the competition host, Targets are future return in 20 days\n* Each target is available only on Friday every week. \n* The range of the target is from zero to 1, [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0] they are ranking of return on each week\n\n\n## Task\n\n* forecast future 20 days' return rank for each stock  \n* Method : Not extract features manually, like technical indicators.\n* I want to use raw data as much as possible Use Neural Network, (CNN, FCN, LSTM, Transformer....) \n* model input is one stock sequence, past 90 days\n* I don't want to use technical indicators, like RSI, MACD, or BB because \n* I want to use Neural Networks to extract beneficial features automatically, not manually\n\n## What I did\n\n* Preprocessing by removing trend factor, with moving average\n* ADF test to confirm if the data has stationarity, then apply normalization using `StandardScaler()`\n* Already tried conventional machine learning methods, like regression tree\n* Tried LSTM, FCN, Transformer, CNN\n* Tried to test various hyperparameter conditions\n* Self-supervised learning, I tried to make a new approach based on my experience\n\n## The Issue\n\n* Worse performance compared to a simple Regression Tree with famous technical indicators\n* For now, I can say that NN is not good at time series data. The decision Tree is still working well even on technical indicators. NN model doesn\u2019t works well for raw price data without feature extraction by hand. I think NN cannot beat decision trees. Is this correct?", "author_fullname": "t2_9x4x53qyp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Give me advise : Stock price return prediction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/learnmachinelearning", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xtn22", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682383412.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682364948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnmachinelearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019m now trying to train the NN model to predict stock price return. However, the performance is terrible. Does anyone know how efficiently I can improve this step by step?? I&amp;#39;m working on one data science competition, &amp;quot;Numerai Signals&amp;quot;&lt;/p&gt;\n\n&lt;h2&gt;Dataset description&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;3000 stocks&lt;/li&gt;\n&lt;li&gt;4 years&lt;/li&gt;\n&lt;li&gt;Use the Adj Close column only&lt;/li&gt;\n&lt;li&gt;Daily stock price data&lt;/li&gt;\n&lt;li&gt;train data: 2017-2022&lt;/li&gt;\n&lt;li&gt;test data: 2022-2023&lt;/li&gt;\n&lt;li&gt;Targets are provided by the competition host, Targets are future return in 20 days&lt;/li&gt;\n&lt;li&gt;Each target is available only on Friday every week. &lt;/li&gt;\n&lt;li&gt;The range of the target is from zero to 1, [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0] they are ranking of return on each week&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Task&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;forecast future 20 days&amp;#39; return rank for each stock&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Method : Not extract features manually, like technical indicators.&lt;/li&gt;\n&lt;li&gt;I want to use raw data as much as possible Use Neural Network, (CNN, FCN, LSTM, Transformer....) &lt;/li&gt;\n&lt;li&gt;model input is one stock sequence, past 90 days&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t want to use technical indicators, like RSI, MACD, or BB because &lt;/li&gt;\n&lt;li&gt;I want to use Neural Networks to extract beneficial features automatically, not manually&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;What I did&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Preprocessing by removing trend factor, with moving average&lt;/li&gt;\n&lt;li&gt;ADF test to confirm if the data has stationarity, then apply normalization using &lt;code&gt;StandardScaler()&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Already tried conventional machine learning methods, like regression tree&lt;/li&gt;\n&lt;li&gt;Tried LSTM, FCN, Transformer, CNN&lt;/li&gt;\n&lt;li&gt;Tried to test various hyperparameter conditions&lt;/li&gt;\n&lt;li&gt;Self-supervised learning, I tried to make a new approach based on my experience&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;The Issue&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Worse performance compared to a simple Regression Tree with famous technical indicators&lt;/li&gt;\n&lt;li&gt;For now, I can say that NN is not good at time series data. The decision Tree is still working well even on technical indicators. NN model doesn\u2019t works well for raw price data without feature extraction by hand. I think NN cannot beat decision trees. Is this correct?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_3cqa1", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xtn22", "is_robot_indexable": true, "report_reasons": null, "author": "Common-Ad-1772", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/learnmachinelearning/comments/12xtn22/give_me_advise_stock_price_return_prediction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/learnmachinelearning/comments/12xtn22/give_me_advise_stock_price_return_prediction/", "subreddit_subscribers": 294655, "created_utc": 1682364948.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1682383470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnmachinelearning", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/learnmachinelearning/comments/12xtn22/give_me_advise_stock_price_return_prediction/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12y2lky", "is_robot_indexable": true, "report_reasons": null, "author": "Common-Ad-1772", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12xtn22", "author_flair_text_color": null, "permalink": "/r/datascience/comments/12y2lky/give_me_advise_stock_price_return_prediction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/learnmachinelearning/comments/12xtn22/give_me_advise_stock_price_return_prediction/", "subreddit_subscribers": 880180, "created_utc": 1682383470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there! \n\nCanadian here. I am relatively new to the world of data science in a professional sense, having transitioned form a career in actuarial science in the last year. I\u2019m my spare time, I\u2019ve been taking verified courses on data science to be able to improve my skill set in my day to day work. The business I work for is going through a large overhaul with respect to data management and how we use data in our day to day .. \n\nI am at this point now where I am questioning for myself, what is next? What sort of education should I pursue to really put me ahead of the game and help to manage this analytics journey that we\u2019re now on. \n\nThe next step for me will be enrolling in a more rigours course like the Data Science certificate that is offered by UWaterloo. After that, who knows.. \n\nI am hoping that someone has some insight on designations and education that would set me on the right path. Currently, I\u2019ve been researching the CDS (chartered data scientist), CAP (certified analytics professional), SDS/PDS designations from DASCA as well as the open CDS program. \n\nI also would like to possible look at doing a course based masters program related to data science or related field.\n\nAny information or recommendations on what pathway I should take would be greatly appreciated.\n\nCheers!", "author_fullname": "t2_4bw73j46", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preferred designations in Data Science and Analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12y1sgu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682381695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there! &lt;/p&gt;\n\n&lt;p&gt;Canadian here. I am relatively new to the world of data science in a professional sense, having transitioned form a career in actuarial science in the last year. I\u2019m my spare time, I\u2019ve been taking verified courses on data science to be able to improve my skill set in my day to day work. The business I work for is going through a large overhaul with respect to data management and how we use data in our day to day .. &lt;/p&gt;\n\n&lt;p&gt;I am at this point now where I am questioning for myself, what is next? What sort of education should I pursue to really put me ahead of the game and help to manage this analytics journey that we\u2019re now on. &lt;/p&gt;\n\n&lt;p&gt;The next step for me will be enrolling in a more rigours course like the Data Science certificate that is offered by UWaterloo. After that, who knows.. &lt;/p&gt;\n\n&lt;p&gt;I am hoping that someone has some insight on designations and education that would set me on the right path. Currently, I\u2019ve been researching the CDS (chartered data scientist), CAP (certified analytics professional), SDS/PDS designations from DASCA as well as the open CDS program. &lt;/p&gt;\n\n&lt;p&gt;I also would like to possible look at doing a course based masters program related to data science or related field.&lt;/p&gt;\n\n&lt;p&gt;Any information or recommendations on what pathway I should take would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12y1sgu", "is_robot_indexable": true, "report_reasons": null, "author": "gsgagahu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12y1sgu/preferred_designations_in_data_science_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12y1sgu/preferred_designations_in_data_science_and/", "subreddit_subscribers": 880180, "created_utc": 1682381695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My company is setting up a tool that will allow us to sell products with customized configurations. The customer will be able to select the product\u2019s physical attributes as they please, such as height, width, length, color, attachments, etc. We want to be able to create a price for each of these customizations on the fly. I have 2 years worth of sales order data for various non-custom products along with info about the product\u2019s physical attributes. I\u2019m thinking I could use a multiple regression model on this historical data to find a model that predicts the price of a custom product based on the product category and the physical attributes. For example Price = b0 + b1*Height + b2*Width + b3*Length + b4*Category_Dummy + b5*Color_Dummy + b6*Attachment_Count.\nDoes this seem like a good use case for multiple regression? Would I need to include a time variable or would it be fine with just having product attributes as inputs?", "author_fullname": "t2_hyamjn58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Product Price Prediction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12y0plj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682379382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is setting up a tool that will allow us to sell products with customized configurations. The customer will be able to select the product\u2019s physical attributes as they please, such as height, width, length, color, attachments, etc. We want to be able to create a price for each of these customizations on the fly. I have 2 years worth of sales order data for various non-custom products along with info about the product\u2019s physical attributes. I\u2019m thinking I could use a multiple regression model on this historical data to find a model that predicts the price of a custom product based on the product category and the physical attributes. For example Price = b0 + b1&lt;em&gt;Height + b2&lt;/em&gt;Width + b3&lt;em&gt;Length + b4&lt;/em&gt;Category_Dummy + b5&lt;em&gt;Color_Dummy + b6&lt;/em&gt;Attachment_Count.\nDoes this seem like a good use case for multiple regression? Would I need to include a time variable or would it be fine with just having product attributes as inputs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12y0plj", "is_robot_indexable": true, "report_reasons": null, "author": "ggmmz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12y0plj/product_price_prediction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12y0plj/product_price_prediction/", "subreddit_subscribers": 880180, "created_utc": 1682379382.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all!\n\nSo, my area if the states was home to a lot of WWII era factories, to the point where I'm pretty sure someone discovered mines a while back and they're doing controlled detonations of old mines and stuff... \n\nAnyways, coincidentally, my area seems to have a lot of people developing brain tumors.. someone got the press involved a while back, but of course it was written off as merely coincidental (I guess it could be).\n\nMy question - I used to work in health care, and I know cms keeps a lot of data. Does anyone know if I can find the instances of brain surgery over time by area? \n\nI'd be super curious to know if there is a correlation at all..\n\nMaybe this isn't the right forum, but having been in health care, I don't trust everyone is doing everything they could with the data..\n\nMaybe someone has already done this, not sure though", "author_fullname": "t2_15urwebm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Diagnosis data by area?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xzt4z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682377208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all!&lt;/p&gt;\n\n&lt;p&gt;So, my area if the states was home to a lot of WWII era factories, to the point where I&amp;#39;m pretty sure someone discovered mines a while back and they&amp;#39;re doing controlled detonations of old mines and stuff... &lt;/p&gt;\n\n&lt;p&gt;Anyways, coincidentally, my area seems to have a lot of people developing brain tumors.. someone got the press involved a while back, but of course it was written off as merely coincidental (I guess it could be).&lt;/p&gt;\n\n&lt;p&gt;My question - I used to work in health care, and I know cms keeps a lot of data. Does anyone know if I can find the instances of brain surgery over time by area? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d be super curious to know if there is a correlation at all..&lt;/p&gt;\n\n&lt;p&gt;Maybe this isn&amp;#39;t the right forum, but having been in health care, I don&amp;#39;t trust everyone is doing everything they could with the data..&lt;/p&gt;\n\n&lt;p&gt;Maybe someone has already done this, not sure though&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xzt4z", "is_robot_indexable": true, "report_reasons": null, "author": "Humanoid_Earthling", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xzt4z/diagnosis_data_by_area/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xzt4z/diagnosis_data_by_area/", "subreddit_subscribers": 880180, "created_utc": 1682377208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Podcast about the power of Large Language Models (LLMs) for the future of AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xvjpm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_erazjrbo", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "u_UBIAI", "selftext": " \n\nAs AI continues to shape the future of businesses, it is essential to understand the potential of LLMs in driving growth for enterprises. We are thrilled to announce our participation in a new podcast series with u/Graphable, where we'll be covering the power of Large Language Models (LLMs) for the future of AI. \n\nCheck out our introductory article \"LLMs for Enterprises: A Comprehensive Guide to Navigating the New AI Frontier\" to learn more.\n\nStay ahead of the curve and join us on this journey as we explore the exciting world of LLMs. \n\nTune in to the podcast series now, learn more here : [https://www.graphable.ai/blog/large-language-models-llms/](https://www.graphable.ai/blog/large-language-models-llms/) \n\n\\#LLMs #AI #largelanguagemodels #analytics #machinelearning #NLP #NLU #Graphable #UBIAI #ChatGPT #Neo4j #GraphAware #democratizingAI #dataanalytics #emergingtech #societalimpact #regulatorylandscape #usecases #incontextlearning #law #naturallanguage #contextualunderstanding #fine-tuning #transformative #businessinnovation #competitiveadvantage #differentiation #strategicdecisionmaking #success", "author_fullname": "t2_32tnavmg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Podcast about the power of Large Language Models (LLMs) for the future of AI", "link_flair_richtext": [], "subreddit_name_prefixed": "u/UBIAI", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xvbi2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "user", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682368228.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.UBIAI", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As AI continues to shape the future of businesses, it is essential to understand the potential of LLMs in driving growth for enterprises. We are thrilled to announce our participation in a new podcast series with &lt;a href=\"/u/Graphable\"&gt;u/Graphable&lt;/a&gt;, where we&amp;#39;ll be covering the power of Large Language Models (LLMs) for the future of AI. &lt;/p&gt;\n\n&lt;p&gt;Check out our introductory article &amp;quot;LLMs for Enterprises: A Comprehensive Guide to Navigating the New AI Frontier&amp;quot; to learn more.&lt;/p&gt;\n\n&lt;p&gt;Stay ahead of the curve and join us on this journey as we explore the exciting world of LLMs. &lt;/p&gt;\n\n&lt;p&gt;Tune in to the podcast series now, learn more here : &lt;a href=\"https://www.graphable.ai/blog/large-language-models-llms/\"&gt;https://www.graphable.ai/blog/large-language-models-llms/&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;#LLMs #AI #largelanguagemodels #analytics #machinelearning #NLP #NLU #Graphable #UBIAI #ChatGPT #Neo4j #GraphAware #democratizingAI #dataanalytics #emergingtech #societalimpact #regulatorylandscape #usecases #incontextlearning #law #naturallanguage #contextualunderstanding #fine-tuning #transformative #businessinnovation #competitiveadvantage #differentiation #strategicdecisionmaking #success&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "qa", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?auto=webp&amp;v=enabled&amp;s=daabae4754b6503567c3b7c4422dabe25b43f14f", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=601e1474964395a6b5953b20d171f7711e1e8492", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=621ca063839dca33c5c8e946d7a616ec19f30380", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47df19db91e843cea280e6962ea894302857a6fb", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33904a1f89f313e27652c3bd359f556ed02d4579", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2ad32d237fac48b4aa26d8c5840a80c5ac82755", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=649c563e8f04838c52a961b600c4e45386824717", "width": 1080, "height": 565}], "variants": {}, "id": "lmQbWmnrpaYNmyH4-rGJBRvhkOHK9vzJ8o9dL8DRJGY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2lnnxo", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xvbi2", "is_robot_indexable": true, "report_reasons": null, "author": "UBIAI", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/u_UBIAI/comments/12xvbi2/podcast_about_the_power_of_large_language_models/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/u_UBIAI/comments/12xvbi2/podcast_about_the_power_of_large_language_models/", "subreddit_subscribers": 0, "created_utc": 1682368228.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1682368637.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.UBIAI", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/user/UBIAI/comments/12xvbi2/podcast_about_the_power_of_large_language_models/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?auto=webp&amp;v=enabled&amp;s=daabae4754b6503567c3b7c4422dabe25b43f14f", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=601e1474964395a6b5953b20d171f7711e1e8492", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=621ca063839dca33c5c8e946d7a616ec19f30380", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47df19db91e843cea280e6962ea894302857a6fb", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33904a1f89f313e27652c3bd359f556ed02d4579", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2ad32d237fac48b4aa26d8c5840a80c5ac82755", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/xV2irmFgRc8_CX8NwdTh_YV7ebla6fzyMs9T7G1qhmE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=649c563e8f04838c52a961b600c4e45386824717", "width": 1080, "height": 565}], "variants": {}, "id": "lmQbWmnrpaYNmyH4-rGJBRvhkOHK9vzJ8o9dL8DRJGY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xvjpm", "is_robot_indexable": true, "report_reasons": null, "author": "Lilith-Smol", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12xvbi2", "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xvjpm/podcast_about_the_power_of_large_language_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/user/UBIAI/comments/12xvbi2/podcast_about_the_power_of_large_language_models/", "subreddit_subscribers": 880180, "created_utc": 1682368637.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm not an analyst, but I still want to improve my general data literacy. I'm bad at dealing with visual data (charts, maps, diagrams), whenever I see a piece of visual data my mind shuts down, I don't understand what information they convey, how its elements correspond with one another and such and so on. In other words, I'm a terribly data illiterate person. Are there any crash courses or books that could help in my case? Should I learn basic statistics or something of the sort?", "author_fullname": "t2_e7ef294o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A question from layman. Where can I learn to read and understand visual data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xphti", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682356308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not an analyst, but I still want to improve my general data literacy. I&amp;#39;m bad at dealing with visual data (charts, maps, diagrams), whenever I see a piece of visual data my mind shuts down, I don&amp;#39;t understand what information they convey, how its elements correspond with one another and such and so on. In other words, I&amp;#39;m a terribly data illiterate person. Are there any crash courses or books that could help in my case? Should I learn basic statistics or something of the sort?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xphti", "is_robot_indexable": true, "report_reasons": null, "author": "fyj7itjd", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xphti/a_question_from_layman_where_can_i_learn_to_read/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xphti/a_question_from_layman_where_can_i_learn_to_read/", "subreddit_subscribers": 880180, "created_utc": 1682356308.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently working as a first-year data engineer at a very large U.S. corporation and primarily program and build pipelines in Python. I have my MS in Data Science and I\u2019m not sure how much longer I can handle the strict hierarchy and oversight that is a constant among these large corps and wanted to ask any of you what I should focus my skills on if I were to leave and try to jump salary/total comp along with a better position. Any help at all would be greatly valued! Thanks!", "author_fullname": "t2_95shon5w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rookie Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xj7ar", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682348352.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working as a first-year data engineer at a very large U.S. corporation and primarily program and build pipelines in Python. I have my MS in Data Science and I\u2019m not sure how much longer I can handle the strict hierarchy and oversight that is a constant among these large corps and wanted to ask any of you what I should focus my skills on if I were to leave and try to jump salary/total comp along with a better position. Any help at all would be greatly valued! Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12xj7ar", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished_Leg3480", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12xj7ar/rookie_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12xj7ar/rookie_advice/", "subreddit_subscribers": 880180, "created_utc": 1682348352.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi! Been wanting to start doing my portfolio. I'm a masters student in DS, just almost starting my journey. I've had business Intelligence and analytics, data visualization courses. Idk where to start doing my portfolio. \n\nWhere can I have a discord for DS students? Also, where can I have a buddy/accountability partner for this? \n\nAlso, been gearing my career towards climate, environment, computational analysis, policy, development. I wanna know it there's a niche skills for this? Thanks.", "author_fullname": "t2_9yqklxvv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Buddies? Mentor?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12x71l3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682320497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! Been wanting to start doing my portfolio. I&amp;#39;m a masters student in DS, just almost starting my journey. I&amp;#39;ve had business Intelligence and analytics, data visualization courses. Idk where to start doing my portfolio. &lt;/p&gt;\n\n&lt;p&gt;Where can I have a discord for DS students? Also, where can I have a buddy/accountability partner for this? &lt;/p&gt;\n\n&lt;p&gt;Also, been gearing my career towards climate, environment, computational analysis, policy, development. I wanna know it there&amp;#39;s a niche skills for this? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12x71l3", "is_robot_indexable": true, "report_reasons": null, "author": "thursdayhaziran", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12x71l3/buddies_mentor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12x71l3/buddies_mentor/", "subreddit_subscribers": 880180, "created_utc": 1682320497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How can I pass text data to CNN for Text classification? How should I turn my data so it can be used in CNN?", "author_fullname": "t2_1bmmkdkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are ways to uses text data as input for CNN binary classification?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12x55ng", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682315700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can I pass text data to CNN for Text classification? How should I turn my data so it can be used in CNN?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12x55ng", "is_robot_indexable": true, "report_reasons": null, "author": "The_artist_999", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12x55ng/what_are_ways_to_uses_text_data_as_input_for_cnn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12x55ng/what_are_ways_to_uses_text_data_as_input_for_cnn/", "subreddit_subscribers": 880180, "created_utc": 1682315700.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}