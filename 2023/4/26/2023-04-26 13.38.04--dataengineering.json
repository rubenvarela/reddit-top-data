{"kind": "Listing", "data": {"after": "t3_12ze0m5", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently work with a colleague who I swear to fucking god has the worst practices ever.  The stuff they do should be considered war crimes (in the data world, of course).\n\nThe person in question has never done CI/CD before and has been copying and pasting blocks of code into the next environment when they want to \"promote\" a change.  Naturally, this has left environments being massively out of sync.  \n\nSince then, we've implemented CI/CD to move database meta data and schemas between environments.  It's consistent, it works, it's better than copying and pasting.  The person in question, however, always rejects the idea of CI/CD with the following talking point:\n\nThem: \"We can't guarantee consistency between environments\"\n\nMe: \"We can because that's sorted through CI/CD\"\n\nThem: \"Yeah, but when I want to make emergency changes to production, it won't align\"\n\nMe: \"But why are we making changes in production directly? They'll get erased next time we release because they don't exist in the previous environments.  For us to be consistent, we have to be in the mindset of working through environments\"\n\nThem: \"I don't want to have to go through every single environment to make a single change\"\n\nThey will then continue to argue forever.  For some strange reason, this happens a lot and I feel like I'm going insane because I feel like it shouldn't be up for debate.  I feel like the person I'm arguing with wants to patch everything, I want to do everything correctly.  They want to apply ad hoc fixes as and when they feel like it, I want to be consistent so when something breaks we can test it at a lower level before releasing it. \n\nI'm 100% ready to be wrong.  Do people regularly makes production only changes?  Am I misunderstanding the whole point of CI/CD? How do you guys facilitate emergency changes with CI/CD?\n\nThank you.", "author_fullname": "t2_anttcncw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should production changes be handled? Rant/debate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yj6uv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682428694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work with a colleague who I swear to fucking god has the worst practices ever.  The stuff they do should be considered war crimes (in the data world, of course).&lt;/p&gt;\n\n&lt;p&gt;The person in question has never done CI/CD before and has been copying and pasting blocks of code into the next environment when they want to &amp;quot;promote&amp;quot; a change.  Naturally, this has left environments being massively out of sync.  &lt;/p&gt;\n\n&lt;p&gt;Since then, we&amp;#39;ve implemented CI/CD to move database meta data and schemas between environments.  It&amp;#39;s consistent, it works, it&amp;#39;s better than copying and pasting.  The person in question, however, always rejects the idea of CI/CD with the following talking point:&lt;/p&gt;\n\n&lt;p&gt;Them: &amp;quot;We can&amp;#39;t guarantee consistency between environments&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Me: &amp;quot;We can because that&amp;#39;s sorted through CI/CD&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Them: &amp;quot;Yeah, but when I want to make emergency changes to production, it won&amp;#39;t align&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Me: &amp;quot;But why are we making changes in production directly? They&amp;#39;ll get erased next time we release because they don&amp;#39;t exist in the previous environments.  For us to be consistent, we have to be in the mindset of working through environments&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Them: &amp;quot;I don&amp;#39;t want to have to go through every single environment to make a single change&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;They will then continue to argue forever.  For some strange reason, this happens a lot and I feel like I&amp;#39;m going insane because I feel like it shouldn&amp;#39;t be up for debate.  I feel like the person I&amp;#39;m arguing with wants to patch everything, I want to do everything correctly.  They want to apply ad hoc fixes as and when they feel like it, I want to be consistent so when something breaks we can test it at a lower level before releasing it. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m 100% ready to be wrong.  Do people regularly makes production only changes?  Am I misunderstanding the whole point of CI/CD? How do you guys facilitate emergency changes with CI/CD?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yj6uv", "is_robot_indexable": true, "report_reasons": null, "author": "average_ukpf_user", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yj6uv/how_should_production_changes_be_handled/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yj6uv/how_should_production_changes_be_handled/", "subreddit_subscribers": 102639, "created_utc": 1682428694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, my organization has been using O365 with the power platform for a minute now. We've got some real MVPs on our team who are treating SharePoint like a database for their power apps (\"front-end\") and power bi reports with power automate work around. But, here's the kicker - the company doesn't want to invest in a proper database like SQL server or full Datavers. \n\nPersonally, I think this is a recipe for disaster. I mean, SharePoint is great and all, but using it as a \"database\" just doesn't seem sustainable. What are your thoughts? Should we continue to use SharePoint or should we explore other options? Let me know in the comments below.", "author_fullname": "t2_8bvav827h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hey guys, so I work for an organization and we're thinking about using SharePoint as a \"database.\" Do you guys have any tips or recommendations on how to make this work? We're kind of new to SharePoint so any advice would be greatly appreciated! Thanks in advance.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yw1ul", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682456731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, my organization has been using O365 with the power platform for a minute now. We&amp;#39;ve got some real MVPs on our team who are treating SharePoint like a database for their power apps (&amp;quot;front-end&amp;quot;) and power bi reports with power automate work around. But, here&amp;#39;s the kicker - the company doesn&amp;#39;t want to invest in a proper database like SQL server or full Datavers. &lt;/p&gt;\n\n&lt;p&gt;Personally, I think this is a recipe for disaster. I mean, SharePoint is great and all, but using it as a &amp;quot;database&amp;quot; just doesn&amp;#39;t seem sustainable. What are your thoughts? Should we continue to use SharePoint or should we explore other options? Let me know in the comments below.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yw1ul", "is_robot_indexable": true, "report_reasons": null, "author": "CassiusBlackwood", "discussion_type": null, "num_comments": 76, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yw1ul/hey_guys_so_i_work_for_an_organization_and_were/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yw1ul/hey_guys_so_i_work_for_an_organization_and_were/", "subreddit_subscribers": 102639, "created_utc": 1682456731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're looking at stuff like Synapse/trino/presto for the engine but for now we're just loading raw json + converting to parquet.\n\nIt's time series data so it partitions nicely along an hourly cadence. This creates files that are about 100Mb. We are about to expand by quite a lot (acquisition) so we think this will ~5x soon enough. \n\nFrom those raw json (500Mb) files we can convert to parquet for the query layer but unsure of how big we ought to go here. We can leave as is and rely on parquets/compression efficiency or compact several hours into a single file. \n\nDon't have a lot of know-how for this so we appreciate any tips. Also, we know a simple set up with a DB might do for this volume of data but the chosen paradigm for the company is data lake + query engine, and our department is just the first to build it out. Thanks.", "author_fullname": "t2_ut20i32q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How big are your data lake raw files? Parquet files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yknp3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682432040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re looking at stuff like Synapse/trino/presto for the engine but for now we&amp;#39;re just loading raw json + converting to parquet.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s time series data so it partitions nicely along an hourly cadence. This creates files that are about 100Mb. We are about to expand by quite a lot (acquisition) so we think this will ~5x soon enough. &lt;/p&gt;\n\n&lt;p&gt;From those raw json (500Mb) files we can convert to parquet for the query layer but unsure of how big we ought to go here. We can leave as is and rely on parquets/compression efficiency or compact several hours into a single file. &lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t have a lot of know-how for this so we appreciate any tips. Also, we know a simple set up with a DB might do for this volume of data but the chosen paradigm for the company is data lake + query engine, and our department is just the first to build it out. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yknp3", "is_robot_indexable": true, "report_reasons": null, "author": "alex_o_h", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yknp3/how_big_are_your_data_lake_raw_files_parquet_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yknp3/how_big_are_your_data_lake_raw_files_parquet_files/", "subreddit_subscribers": 102639, "created_utc": 1682432040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Essentially title. Is it left up to the data architects? Principal/staff engineers?", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who sets the pipeline/warehouse strategy and roadmap in your organization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z1s36", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682470743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Essentially title. Is it left up to the data architects? Principal/staff engineers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12z1s36", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12z1s36/who_sets_the_pipelinewarehouse_strategy_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12z1s36/who_sets_the_pipelinewarehouse_strategy_and/", "subreddit_subscribers": 102639, "created_utc": 1682470743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "From PLC/sensor level  all the way up to reporting and visuals, what tools do you guys use?\n\nMy company uses the following:\n\n* Kepware\n* SQL\n* Power BI\n\nThat's it. Nothing else. I'm being tasked with helping on all kinds of Industry 4.0 initiatives but it seems like everything is already hitting its cap and we've barely gotten started.\n\nKepware VM is at max capacity which should hopefully be as easy as migrating to a more powerful VM. SQL gateways for Power BI, Power Apps, Flows, etc. seems to be failing. No one can give me a root cause and I don't have access myself. Power BI refreshes get slower and slower by the day.\n\nLuckily, I think we will be getting OSI PI soon which should do wonders. \n\nHas anyone else experienced this and if so what did your manufacturing stack look like. How did it eventually improve....please tell me it eventually improved.", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone work in the Industry 4.0 space? More specifically in manufacturing? What does your data stack look like?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yw3x2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682456852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From PLC/sensor level  all the way up to reporting and visuals, what tools do you guys use?&lt;/p&gt;\n\n&lt;p&gt;My company uses the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Kepware&lt;/li&gt;\n&lt;li&gt;SQL&lt;/li&gt;\n&lt;li&gt;Power BI&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;That&amp;#39;s it. Nothing else. I&amp;#39;m being tasked with helping on all kinds of Industry 4.0 initiatives but it seems like everything is already hitting its cap and we&amp;#39;ve barely gotten started.&lt;/p&gt;\n\n&lt;p&gt;Kepware VM is at max capacity which should hopefully be as easy as migrating to a more powerful VM. SQL gateways for Power BI, Power Apps, Flows, etc. seems to be failing. No one can give me a root cause and I don&amp;#39;t have access myself. Power BI refreshes get slower and slower by the day.&lt;/p&gt;\n\n&lt;p&gt;Luckily, I think we will be getting OSI PI soon which should do wonders. &lt;/p&gt;\n\n&lt;p&gt;Has anyone else experienced this and if so what did your manufacturing stack look like. How did it eventually improve....please tell me it eventually improved.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yw3x2", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yw3x2/anyone_work_in_the_industry_40_space_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yw3x2/anyone_work_in_the_industry_40_space_more/", "subreddit_subscribers": 102639, "created_utc": 1682456852.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are thinking of adopting snowpipe to ingest data from Kafka to Snowflake (currently using Fivetran). Would be happy for some homes reviews.", "author_fullname": "t2_19dlf55q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are you using Snowpipe? What\u2019s its pros and cons?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ytogu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682451730.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are thinking of adopting snowpipe to ingest data from Kafka to Snowflake (currently using Fivetran). Would be happy for some homes reviews.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ytogu", "is_robot_indexable": true, "report_reasons": null, "author": "themo_legrange", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ytogu/are_you_using_snowpipe_whats_its_pros_and_cons/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ytogu/are_you_using_snowpipe_whats_its_pros_and_cons/", "subreddit_subscribers": 102639, "created_utc": 1682451730.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What skills would you consider soft skills as a DE?\nThere are some obvious ones like;\n- Communication\n- Stakeholder management\n- Writing (mails, documentation, guidelines)\n- Listening to client requests\n- Peer reviews \n\nBut what about some less obvious, would you consider them to be closer to soft skills or hard skills ones like;\n- Making a proper code review (so that others can review easier)\n- Giving proper code review feedback\n- Improving productivity\n\nOr would you say there is an extra list of skills between soft and hard skills?\n\nWhat are your struggles with these types of skills?", "author_fullname": "t2_1jkhpl2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Soft skills aimed at DE's", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yw8c8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682457116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What skills would you consider soft skills as a DE?\nThere are some obvious ones like;\n- Communication\n- Stakeholder management\n- Writing (mails, documentation, guidelines)\n- Listening to client requests\n- Peer reviews &lt;/p&gt;\n\n&lt;p&gt;But what about some less obvious, would you consider them to be closer to soft skills or hard skills ones like;\n- Making a proper code review (so that others can review easier)\n- Giving proper code review feedback\n- Improving productivity&lt;/p&gt;\n\n&lt;p&gt;Or would you say there is an extra list of skills between soft and hard skills?&lt;/p&gt;\n\n&lt;p&gt;What are your struggles with these types of skills?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yw8c8", "is_robot_indexable": true, "report_reasons": null, "author": "Luxi36", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yw8c8/soft_skills_aimed_at_des/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yw8c8/soft_skills_aimed_at_des/", "subreddit_subscribers": 102639, "created_utc": 1682457116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have all seen the layoff announcements from various MDS vendors.  This week, I found out my main customer success contact at one vendor is no longer there.   I know vendors lurk here on reddit.  Can anybody share the inside scoop and what we should anticipate next?  What's the vibe?", "author_fullname": "t2_7yk2o6hxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Inside scoop from Data Engineering vendors?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z7jn7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682486823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have all seen the layoff announcements from various MDS vendors.  This week, I found out my main customer success contact at one vendor is no longer there.   I know vendors lurk here on reddit.  Can anybody share the inside scoop and what we should anticipate next?  What&amp;#39;s the vibe?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12z7jn7", "is_robot_indexable": true, "report_reasons": null, "author": "grahamdietz", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12z7jn7/inside_scoop_from_data_engineering_vendors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12z7jn7/inside_scoop_from_data_engineering_vendors/", "subreddit_subscribers": 102639, "created_utc": 1682486823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am learning Aws glue but it's very expensive, so  I need a way that I can test it on local first.", "author_fullname": "t2_8szkmsobv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Can I test AWS glue jobs on local?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z8375", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682488509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am learning Aws glue but it&amp;#39;s very expensive, so  I need a way that I can test it on local first.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12z8375", "is_robot_indexable": true, "report_reasons": null, "author": "neutronajs", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12z8375/how_can_i_test_aws_glue_jobs_on_local/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12z8375/how_can_i_test_aws_glue_jobs_on_local/", "subreddit_subscribers": 102639, "created_utc": 1682488509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Question:\n\nWhen you\u2019re building the databricks architecture utilizing the medallion model,\nWhere are your bronze, silver, gold tier delta files sitting?\n\nCurrently we have bronze tier data in AZDL Gen 2 , loading those files into a databricks DF, doing transformations, then creating delta files into a silver layer in AZDL gen 2.  \n\nWould it make more sense to not have the delta files in AZDL but in the databricks file system? \n\nOR would it make sense to load the silver files into the databricks file system then copy them into the AZDL. \n\nDatabricks is relatively new to me but we are starting to shift away from synapse", "author_fullname": "t2_uf4ne7uq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yw8co", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682457116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Question:&lt;/p&gt;\n\n&lt;p&gt;When you\u2019re building the databricks architecture utilizing the medallion model,\nWhere are your bronze, silver, gold tier delta files sitting?&lt;/p&gt;\n\n&lt;p&gt;Currently we have bronze tier data in AZDL Gen 2 , loading those files into a databricks DF, doing transformations, then creating delta files into a silver layer in AZDL gen 2.  &lt;/p&gt;\n\n&lt;p&gt;Would it make more sense to not have the delta files in AZDL but in the databricks file system? &lt;/p&gt;\n\n&lt;p&gt;OR would it make sense to load the silver files into the databricks file system then copy them into the AZDL. &lt;/p&gt;\n\n&lt;p&gt;Databricks is relatively new to me but we are starting to shift away from synapse&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yw8co", "is_robot_indexable": true, "report_reasons": null, "author": "NipsAhoy2", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yw8co/databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yw8co/databricks/", "subreddit_subscribers": 102639, "created_utc": 1682457116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently interviewed for a role and the hiring manager mentioned there would be system-design interview questions. I have traditionally been more of an analytically focused DE (close to an analytics engineer role) and have little experience with system design questions. Does anyone have advice on where I should start for interview prep? Is going through Grokking the System Design Interview enough? Does anyone have any experience ramping up on this topic within 3 weeks? For context, I am still early in my career, so this would likely be a junior-level role since I have less than 3 YOE.", "author_fullname": "t2_6wqif47u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Prep Advice - System Design - Where to start?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yk9r6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682431175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently interviewed for a role and the hiring manager mentioned there would be system-design interview questions. I have traditionally been more of an analytically focused DE (close to an analytics engineer role) and have little experience with system design questions. Does anyone have advice on where I should start for interview prep? Is going through Grokking the System Design Interview enough? Does anyone have any experience ramping up on this topic within 3 weeks? For context, I am still early in my career, so this would likely be a junior-level role since I have less than 3 YOE.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12yk9r6", "is_robot_indexable": true, "report_reasons": null, "author": "tagavor_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yk9r6/interview_prep_advice_system_design_where_to_start/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yk9r6/interview_prep_advice_system_design_where_to_start/", "subreddit_subscribers": 102639, "created_utc": 1682431175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone,\n\nIn one of my projects I\u2019m using python to connect to a SFTP server and use SSH keys to authenticate myself. All of a sudden the client SFTP server started showing errors and wasn\u2019t accepting SSH Keys. \u201cPAM Authentication\u201d shows up. \n\nThe SFTP is managed by another vendor and they identified that this is due to their SSH being backdated. While they\u2019re fixing that, they gave me password for PAM Authentication. I can log in using CLI. \n\nI just don\u2019t understand how to use this password with python/paramiko. I feel this password is definitely different than the username and password combo for the server. \n\nIs there anyone who wrote some python scripts for connection using PAM password?\n\nThanks!", "author_fullname": "t2_dv4ply58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Ingestion from SFTP Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yxwtg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682460874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;In one of my projects I\u2019m using python to connect to a SFTP server and use SSH keys to authenticate myself. All of a sudden the client SFTP server started showing errors and wasn\u2019t accepting SSH Keys. \u201cPAM Authentication\u201d shows up. &lt;/p&gt;\n\n&lt;p&gt;The SFTP is managed by another vendor and they identified that this is due to their SSH being backdated. While they\u2019re fixing that, they gave me password for PAM Authentication. I can log in using CLI. &lt;/p&gt;\n\n&lt;p&gt;I just don\u2019t understand how to use this password with python/paramiko. I feel this password is definitely different than the username and password combo for the server. &lt;/p&gt;\n\n&lt;p&gt;Is there anyone who wrote some python scripts for connection using PAM password?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yxwtg", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous_Apple_420", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yxwtg/data_ingestion_from_sftp_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yxwtg/data_ingestion_from_sftp_server/", "subreddit_subscribers": 102639, "created_utc": 1682460874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently in a position where I do a lot of the data modeling for report purposes. It's at a new company for me but in an industry I know well so I'm pretty familiar with the data I'm working with. My experience is mostly in analytics though with only the last year or so being more engineer focused so I'm still learning a lot.  \n\n\nI feel like I spend an inordinate amount of time just trying to unravel all our data models so that I can trace something from source system through to business report. I do this because we have a lot of data integrity questions that come up and to help me better understand the process. We have layers and layers of built in logic even for the most straightforward measures. \n\nI think what I'm seeing, on top of the data integrity concerns, as well as consistent integration breakdowns, speaks to a poorly designed warehouse but I don't feel like I have enough, except my experience, to go off of. I know it's not like anything I've dealt with in my past though. What questions do I need to be asking, or what else can I be looking at to help me better understand where our issues are? Any ideas or thoughts that can help point me in the right direction are appreciated!", "author_fullname": "t2_2q171de9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm spending a lot of time unraveling data models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yt7e4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682450727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in a position where I do a lot of the data modeling for report purposes. It&amp;#39;s at a new company for me but in an industry I know well so I&amp;#39;m pretty familiar with the data I&amp;#39;m working with. My experience is mostly in analytics though with only the last year or so being more engineer focused so I&amp;#39;m still learning a lot.  &lt;/p&gt;\n\n&lt;p&gt;I feel like I spend an inordinate amount of time just trying to unravel all our data models so that I can trace something from source system through to business report. I do this because we have a lot of data integrity questions that come up and to help me better understand the process. We have layers and layers of built in logic even for the most straightforward measures. &lt;/p&gt;\n\n&lt;p&gt;I think what I&amp;#39;m seeing, on top of the data integrity concerns, as well as consistent integration breakdowns, speaks to a poorly designed warehouse but I don&amp;#39;t feel like I have enough, except my experience, to go off of. I know it&amp;#39;s not like anything I&amp;#39;ve dealt with in my past though. What questions do I need to be asking, or what else can I be looking at to help me better understand where our issues are? Any ideas or thoughts that can help point me in the right direction are appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12yt7e4", "is_robot_indexable": true, "report_reasons": null, "author": "lahma_mama", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yt7e4/im_spending_a_lot_of_time_unraveling_data_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yt7e4/im_spending_a_lot_of_time_unraveling_data_models/", "subreddit_subscribers": 102639, "created_utc": 1682450727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a bunch of sites across the country collecting data.\n\nEach piece of equipment has a battery and a .txt file recording the battery level every minute, appending the record to the site .txt file. So, a file that is growing one record every minute.\n\nThe equipment is managed by an external company, so i don't have control to change the way the .txt add records.\n\nMy team want to write this data to a database (BigQuery) and i can't think of an efficient way to do this other than searching and deleting all the records for the site and re-writing them to the database. As each file may contains 200k records and doing a query to write only new records will, i guess, be slow.\n\nAny suggestions or am patterns i could use? And suggestions would be awesome. Thanks :-)", "author_fullname": "t2_qd6ssd6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's an efficient write to DB a file that's continuously being appended to?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yjk8d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682429548.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bunch of sites across the country collecting data.&lt;/p&gt;\n\n&lt;p&gt;Each piece of equipment has a battery and a .txt file recording the battery level every minute, appending the record to the site .txt file. So, a file that is growing one record every minute.&lt;/p&gt;\n\n&lt;p&gt;The equipment is managed by an external company, so i don&amp;#39;t have control to change the way the .txt add records.&lt;/p&gt;\n\n&lt;p&gt;My team want to write this data to a database (BigQuery) and i can&amp;#39;t think of an efficient way to do this other than searching and deleting all the records for the site and re-writing them to the database. As each file may contains 200k records and doing a query to write only new records will, i guess, be slow.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or am patterns i could use? And suggestions would be awesome. Thanks :-)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12yjk8d", "is_robot_indexable": true, "report_reasons": null, "author": "Careful-Doughnut-59", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yjk8d/whats_an_efficient_write_to_db_a_file_thats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yjk8d/whats_an_efficient_write_to_db_a_file_thats/", "subreddit_subscribers": 102639, "created_utc": 1682429548.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nI'm the sole 'data' person at a small company where my role spans a bucket load of titles, I know there are many in a similar position out there... As such any chance I can get to offload any work/mental capacity to a managed/streamlined platform I'm usually all for it.\n\nThe company has a bunch of legacy/niche industry software that require custom pipelines to be put together. Now I'm sure something like airflow would fill the shoes and there some, but I just can't justify the management nor the costs of a managed service for this.\n\nSurely there has to be something between, like scheduled lambdas with monitoring/alerting/validation rolled in?\n\nI've so far in my spare time cobbled together a series of scripts and a rudimentary frontend to streamline and achieve the above, but was hoping for something pre-existing I could drop in...\n\n\nReally to sum it up, my wishlist is basically bring code, aka serverless function style but have the monitoring ease of something like airflow or prefect.\n\nThanks for any comments or thoughts", "author_fullname": "t2_kjuqv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What exists on the spectrum between a cron job and airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12zfj4u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682510943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m the sole &amp;#39;data&amp;#39; person at a small company where my role spans a bucket load of titles, I know there are many in a similar position out there... As such any chance I can get to offload any work/mental capacity to a managed/streamlined platform I&amp;#39;m usually all for it.&lt;/p&gt;\n\n&lt;p&gt;The company has a bunch of legacy/niche industry software that require custom pipelines to be put together. Now I&amp;#39;m sure something like airflow would fill the shoes and there some, but I just can&amp;#39;t justify the management nor the costs of a managed service for this.&lt;/p&gt;\n\n&lt;p&gt;Surely there has to be something between, like scheduled lambdas with monitoring/alerting/validation rolled in?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve so far in my spare time cobbled together a series of scripts and a rudimentary frontend to streamline and achieve the above, but was hoping for something pre-existing I could drop in...&lt;/p&gt;\n\n&lt;p&gt;Really to sum it up, my wishlist is basically bring code, aka serverless function style but have the monitoring ease of something like airflow or prefect.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any comments or thoughts&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12zfj4u", "is_robot_indexable": true, "report_reasons": null, "author": "kmsherrin", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zfj4u/what_exists_on_the_spectrum_between_a_cron_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12zfj4u/what_exists_on_the_spectrum_between_a_cron_job/", "subreddit_subscribers": 102639, "created_utc": 1682510943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got offered to take a second job by a colleague and I'll be doing it on my own free time. However the job is more of a BI role (doing analysis and data visualization). I also have access to tons of learning materials in my current company and may take some certifications when I want. \n\nSo basically I am torn on what to do between the two on my free time. Looking for advice from wiser people here. Thank you.\n\nTake second job = more money\n\nPrioritize learning = more DE knowledge", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Take a second job or study more", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z7u43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682487727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got offered to take a second job by a colleague and I&amp;#39;ll be doing it on my own free time. However the job is more of a BI role (doing analysis and data visualization). I also have access to tons of learning materials in my current company and may take some certifications when I want. &lt;/p&gt;\n\n&lt;p&gt;So basically I am torn on what to do between the two on my free time. Looking for advice from wiser people here. Thank you.&lt;/p&gt;\n\n&lt;p&gt;Take second job = more money&lt;/p&gt;\n\n&lt;p&gt;Prioritize learning = more DE knowledge&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12z7u43", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12z7u43/take_a_second_job_or_study_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12z7u43/take_a_second_job_or_study_more/", "subreddit_subscribers": 102639, "created_utc": 1682487727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I was tasked to build a CICD pipeline for Synapse. I want to be able to deploy from Dev to different environment. I found the Sqlpackage, where it extract the schema of a workspace and publish it to a destination workspace. I'm not sure but I think it is not the right approach since it is not parametrizable and throwing error when deploying external views. So far it worked only with tables.\nAny idea how can I build it? Thank you in advance", "author_fullname": "t2_pp0zirow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD for Synapse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ysvyg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682450021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I was tasked to build a CICD pipeline for Synapse. I want to be able to deploy from Dev to different environment. I found the Sqlpackage, where it extract the schema of a workspace and publish it to a destination workspace. I&amp;#39;m not sure but I think it is not the right approach since it is not parametrizable and throwing error when deploying external views. So far it worked only with tables.\nAny idea how can I build it? Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ysvyg", "is_robot_indexable": true, "report_reasons": null, "author": "These_Rip_9327", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ysvyg/cicd_for_synapse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ysvyg/cicd_for_synapse/", "subreddit_subscribers": 102639, "created_utc": 1682450021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3yleu7rp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Business Value of Metadata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_12you5a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/EHES8eKB3vtBgsdAesjBcGWniy51TpSivgMmve21LL8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682441175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/alvin-ai/the-business-value-of-metadata-efa46f78a6da", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?auto=webp&amp;v=enabled&amp;s=52a7f0a1a29f6fcbed6044190f4419d8c7db6ea9", "width": 1200, "height": 692}, "resolutions": [{"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1fae95481cfa84bed915d1d20480d4fb030c472", "width": 108, "height": 62}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=50b80bbe9a84be94b24656c94868a1bd76babac1", "width": 216, "height": 124}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02375c4beeb71f2bc69588ec37b949cf2937ea4e", "width": 320, "height": 184}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=355acf7fd8c020eee63b5a36e58fc66588eb49b4", "width": 640, "height": 369}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=884a6f268b31cb73bf1f290b1da30f8d16c416e5", "width": 960, "height": 553}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d1f8f55607a0a4e8a56baf818ded87cc76159e5", "width": 1080, "height": 622}], "variants": {}, "id": "Mhev0XFTT0iV1DglMqIEg298usdpo1bM03JWxEvDc9A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12you5a", "is_robot_indexable": true, "report_reasons": null, "author": "gabsferreiradev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12you5a/the_business_value_of_metadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/alvin-ai/the-business-value-of-metadata-efa46f78a6da", "subreddit_subscribers": 102639, "created_utc": 1682441175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, \nI have started a new role recently where I am at a large legacy manufacturing company that is trying to get into analytics (lol). I was hired to do data engineering but it seems like most of what i will be doing to start off is working on getting their data policies in order. They have been using SAP for 30 years and are trying to modernize somewhat.  Currently at their plants they have analytics on site that are running based on production data and from my view those are all fine. However in their administration building is where they need a shitload of work. Basically they have always had web devs or SAP devs and never really had anyone in admin who was a DBA or trained in that regard. From just my first month i have a few things that I know need to change and was wondering if anyone had advice.\n\n1. Every project was made as its own database. Is there a way to quickly go back and put all of these projects into one database but under different schemas? To put it in perspective one of their sql servers has 55 databases.\n\n2. How do you get people to buy into data governance as a policy when it really hasnt been enforced before? Right now everyone has access to everything and its kind of a wild west. \n\n3. They currently have a few people who are very good at getting data out of SAP BW for queries. However this creates problems because the data analytics people arent really SAP trained and the data gets lost in translation over time, not to mention the bottleneck of always having to ask one of the couple people who understand SAP BW. Does anyone have experience in creating an analytics database in a third party program off of an SAP ERP system? There is really no getting rid of SAP in any capacity when its been used this long.", "author_fullname": "t2_6ra3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for new role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yl02m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682432808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, \nI have started a new role recently where I am at a large legacy manufacturing company that is trying to get into analytics (lol). I was hired to do data engineering but it seems like most of what i will be doing to start off is working on getting their data policies in order. They have been using SAP for 30 years and are trying to modernize somewhat.  Currently at their plants they have analytics on site that are running based on production data and from my view those are all fine. However in their administration building is where they need a shitload of work. Basically they have always had web devs or SAP devs and never really had anyone in admin who was a DBA or trained in that regard. From just my first month i have a few things that I know need to change and was wondering if anyone had advice.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Every project was made as its own database. Is there a way to quickly go back and put all of these projects into one database but under different schemas? To put it in perspective one of their sql servers has 55 databases.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do you get people to buy into data governance as a policy when it really hasnt been enforced before? Right now everyone has access to everything and its kind of a wild west. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;They currently have a few people who are very good at getting data out of SAP BW for queries. However this creates problems because the data analytics people arent really SAP trained and the data gets lost in translation over time, not to mention the bottleneck of always having to ask one of the couple people who understand SAP BW. Does anyone have experience in creating an analytics database in a third party program off of an SAP ERP system? There is really no getting rid of SAP in any capacity when its been used this long.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yl02m", "is_robot_indexable": true, "report_reasons": null, "author": "deemerritt", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yl02m/advice_for_new_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yl02m/advice_for_new_role/", "subreddit_subscribers": 102639, "created_utc": 1682432808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI don\u2019t *think* this is possible, and have asked on the dbt Slack but got no response so wanted to check here.\n\ndbt can connect to Databricks and can connect to DuckDB.\n\nDuckDB can connect to DeltaLake (via Arrow).\n\nIs it possible to leverage dbt for my transformation pipelines with my data stored in S3 using delta-rs in Python, with DuckDB as my compute engine?\n\nIf anyone has done it, is there a guide I can follow, or some basic pointers to get up and running?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt with Delta Lake &amp; DuckDB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12zf0bu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682509635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t &lt;em&gt;think&lt;/em&gt; this is possible, and have asked on the dbt Slack but got no response so wanted to check here.&lt;/p&gt;\n\n&lt;p&gt;dbt can connect to Databricks and can connect to DuckDB.&lt;/p&gt;\n\n&lt;p&gt;DuckDB can connect to DeltaLake (via Arrow).&lt;/p&gt;\n\n&lt;p&gt;Is it possible to leverage dbt for my transformation pipelines with my data stored in S3 using delta-rs in Python, with DuckDB as my compute engine?&lt;/p&gt;\n\n&lt;p&gt;If anyone has done it, is there a guide I can follow, or some basic pointers to get up and running?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12zf0bu", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zf0bu/dbt_with_delta_lake_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12zf0bu/dbt_with_delta_lake_duckdb/", "subreddit_subscribers": 102639, "created_utc": 1682509635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got assigned to a new project which uses AWS stack and noticed that they are only using Glue to call stored procedures or run queries in external database. From what I know, Glue is just spark on the backend so by not using spark they are not using Glue to its full capabilities. So my question is, is this an acceptable way of using Glue?", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue not fully utilized?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yrhwz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682446925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got assigned to a new project which uses AWS stack and noticed that they are only using Glue to call stored procedures or run queries in external database. From what I know, Glue is just spark on the backend so by not using spark they are not using Glue to its full capabilities. So my question is, is this an acceptable way of using Glue?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12yrhwz", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yrhwz/aws_glue_not_fully_utilized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yrhwz/aws_glue_not_fully_utilized/", "subreddit_subscribers": 102639, "created_utc": 1682446925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/vr2c6dyv68wa1.png?width=1142&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6f17111ba9082c24ddba8279138ded3d2f8833c8", "author_fullname": "t2_thbyp5gl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do any of you do modeling with pymc3 or Bayesian moderation analysis? I need a data science player to import my research results and visualize the moderation effect for me (here are some useful links: https://www.pymc.io/projects/docs/en/v3/pymc-examples/examples/case_studies/moderation)... Thanks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": true, "media_metadata": {"vr2c6dyv68wa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 57, "x": 108, "u": "https://preview.redd.it/vr2c6dyv68wa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ff95a5cd738185b4d036f73ea6d9c131279f98b"}, {"y": 114, "x": 216, "u": "https://preview.redd.it/vr2c6dyv68wa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c63b626433657022db458bbac67eb44ee037290"}, {"y": 169, "x": 320, "u": "https://preview.redd.it/vr2c6dyv68wa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5f51331d98c0c408c8383693e86b8d949f9dd81"}, {"y": 339, "x": 640, "u": "https://preview.redd.it/vr2c6dyv68wa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c24d437877d801ec22129277d3ed8e26fa9258d5"}, {"y": 508, "x": 960, "u": "https://preview.redd.it/vr2c6dyv68wa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=420d764d2c6a16a57fde48bdc8ef7e12f54887ec"}, {"y": 572, "x": 1080, "u": "https://preview.redd.it/vr2c6dyv68wa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ca5a7c6e0dcddfb2bdeb5752f2cf987089803f1"}], "s": {"y": 605, "x": 1142, "u": "https://preview.redd.it/vr2c6dyv68wa1.png?width=1142&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6f17111ba9082c24ddba8279138ded3d2f8833c8"}, "id": "vr2c6dyv68wa1"}}, "name": "t3_12zglme", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/McTYimTFEMLHSaGHq6yDcC7y0tNnE8j26Rcywnp5MHc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682513521.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vr2c6dyv68wa1.png?width=1142&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6f17111ba9082c24ddba8279138ded3d2f8833c8\"&gt;https://preview.redd.it/vr2c6dyv68wa1.png?width=1142&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6f17111ba9082c24ddba8279138ded3d2f8833c8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12zglme", "is_robot_indexable": true, "report_reasons": null, "author": "Best-Tour-2952", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zglme/do_any_of_you_do_modeling_with_pymc3_or_bayesian/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12zglme/do_any_of_you_do_modeling_with_pymc3_or_bayesian/", "subreddit_subscribers": 102639, "created_utc": 1682513521.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to share the Terraform tutorial **(Infrastructure As Code for Cloud)**, cheat sheet, and usage scenarios that I created as a notebook for myself. This repo covers Terraform with **(How-To) HANDS-On LABs and AWS SAMPLEs** (comprehensive, but simple):\n\n* Resources, Data Sources, Variables, Meta Arguments, Provisioners, Dynamic Blocks, Modules, Workspaces, Templates, Remote State.\n* Provisioning AWS Components (EC2, Lambda, ECS, EKS, API Gateway, ELB, CodePipeline, CodeBuild, etc.), use cases, and details. Possible usage scenarios are aimed to update over time.\n\n**Tutorial Link:** [**https://github.com/omerbsezer/Fast-Terraform**](https://github.com/omerbsezer/Fast-Terraform)\n\n**Extra Kubernetes-Tutorial Link:** [**https://github.com/omerbsezer/Fast-Kubernetes**](https://github.com/omerbsezer/Fast-Kubernetes)\n\n**Quick Look (How-To): Terraform Hands-on LABs**\n\nThese LABs focus on Terraform features, and help to learn Terraform:\n\n* [LAB-00: Installing Terraform, AWS Configuration with Terraform](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB00-Terraform-Install-AWS-Configuration.md)\n* [LAB-01: Terraform Docker =&gt; Pull Docker Image, Create Docker Container on Local Machine](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB01-Terraform-Docker-Without-Cloud.md)\n* [LAB-02: Resources =&gt; Provision Basic EC2 (Ubuntu 22.04)](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB02-Resources-Basic-EC2.md)\n* [LAB-03: Variables, Locals, Output =&gt; Provision EC2s](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB03-Variables-Locals-Output-EC2.md)\n* [LAB-04: Meta Arguments (Count, For\\_Each, Map) =&gt; Provision IAM Users, Groups, Policies, Attachment Policy-User](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB04-Meta-Arguments-IAM-User-Group-Policy.md)\n* [LAB-05: Dynamic Blocks =&gt; Provision Security Groups, EC2, VPC](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB05-Dynamic-Blocks-Security-Groups-EC2.md)\n* [LAB-06: Data Sources with Depends\\_on =&gt; Provision EC2](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB06-Data-Sources-EC2.md)\n* [LAB-07: Provisioners (file, remote-exec), Null Resources (local-exec) =&gt; Provision Key-Pair, SSH Connection](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB07-Provisioners-Null-Resources.md)\n* [LAB-08: Modules =&gt; Provision EC2](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB08-Modules-EC2.md)\n* [LAB-09: Workspaces =&gt; Provision EC2 with Different tfvars Files](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB09-Workspaces-EC2.md)\n* [LAB-10: Templates =&gt; Provision IAM User, User Access Key, Policy](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB10-Templates-User-Policy.md)\n* [LAB-11: Backend - Remote States =&gt; Provision EC2 and Save State File on S3](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB11-Backend-Remote-State.md)\n* [Terraform Cheatsheet](https://github.com/omerbsezer/Fast-Terraform/blob/main/Terraform-Cheatsheet.md)\n\n**Quick Look (How-To): AWS Terraform Hands-on Samples**\n\nThese samples focus on how to create and use AWS components (EC2, EBS, EFS, IAM Roles, IAM Policies, Key-Pairs, VPC with Network Components, Lambda, ECR, ECS with Fargate, EKS with Managed Nodes, ASG, ELB, API Gateway, S3, CloudFront, CodeCommit, CodePipeline, CodeBuild, CodeDeploy) with Terraform:\n\n* [SAMPLE-01: Provisioning EC2s (Windows 2019 Server, Ubuntu 20.04) on VPC (Subnet), Creating Key-Pair, Connecting Ubuntu using SSH, and Connecting Windows Using RDP](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE01-EC2-VPC-Ubuntu-Win-SSH-RDP.md)\n* [SAMPLE-02: Provisioning Lambda Function, API Gateway and Reaching HTML Page in Python Code From Browser](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE02-Lambda-API-Gateway-Python.md)\n* [SAMPLE-03: EBS (Elastic Block Storage: HDD, SDD) and EFS (Elastic File System: NFS) Configuration with EC2s (Ubuntu and Windows Instances)](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE03-EC2-EBS-EFS.md)\n* [SAMPLE-04: Provisioning ECR (Elastic Container Repository), Pushing Image to ECR, Provisioning ECS (Elastic Container Service), VPC (Virtual Private Cloud), ELB (Elastic Load Balancer), ECS Tasks and Service on Fargate Cluster](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE04-ECR-ECS-ELB-VPC-ECS-Service.md)\n* [SAMPLE-05: Provisioning ECR, Lambda Function and API Gateway to run Flask App Container on Lambda](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE05-Lambda-Container-ApiGateway-FlaskApp.md)\n* [SAMPLE-06: Provisioning EKS (Elastic Kubernetes Service) with Managed Nodes using Blueprint and Modules](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE06-EKS-ManagedNodes-Blueprint.md)\n* [SAMPLE-07: CI/CD on AWS =&gt; Provisioning CodeCommit and CodePipeline, Triggering CodeBuild and CodeDeploy, Running on Lambda Container](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE07-CodeCommit-Pipeline-Build-Deploy-Lambda.md)\n* [SAMPLE-08: Provisioning S3 and CloudFront to serve Static Web Site](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE08-S3-CloudFront-Static-WebSite.md)\n\n**Table of Contents**\n\n* [Motivation](https://github.com/omerbsezer/Fast-Terraform#motivation)\n* [What is Terraform?](https://github.com/omerbsezer/Fast-Terraform#what_is_terraform)\n* [How Terraform Works?](https://github.com/omerbsezer/Fast-Terraform#how_terrafom_works)\n* [Terraform File Components](https://github.com/omerbsezer/Fast-Terraform#terrafom_file_components)\n   * [Providers](https://github.com/omerbsezer/Fast-Terraform#providers)\n   * [Resources](https://github.com/omerbsezer/Fast-Terraform#resources)\n   * [Variables (tfvar)](https://github.com/omerbsezer/Fast-Terraform#variables)\n   * [Values (Locals, Outputs)](https://github.com/omerbsezer/Fast-Terraform#values)\n   * [Meta Arguments](https://github.com/omerbsezer/Fast-Terraform#meta_arguments)\n   * [Dynamic Blocks](https://github.com/omerbsezer/Fast-Terraform#dynamic_blocks)\n   * [Data Sources](https://github.com/omerbsezer/Fast-Terraform#datasources)\n   * [Provisioners (file, remote\\_exec, local\\_exec), Null Resource](https://github.com/omerbsezer/Fast-Terraform#provisioners)\n   * [Modules](https://github.com/omerbsezer/Fast-Terraform#modules)\n   * [Workspaces](https://github.com/omerbsezer/Fast-Terraform#workspaces)\n   * [Templates](https://github.com/omerbsezer/Fast-Terraform#templates)\n   * [Backends and Remote States](https://github.com/omerbsezer/Fast-Terraform#backends_remote_states)\n* [Terraform Best Practices](https://github.com/omerbsezer/Fast-Terraform#best_practice)\n* [AWS Terraform Hands-on Samples](https://github.com/omerbsezer/Fast-Terraform#samples)\n   * [SAMPLE-01: EC2s (Windows 2019 Server, Ubuntu 20.04), VPC, Key-Pairs for SSH, RDP connections](https://github.com/omerbsezer/Fast-Terraform#ec2_vpc_key_pair_ssh_rdp)\n   * [SAMPLE-02: Provisioning Lambda Function, API Gateway and Reaching HTML Page in Python Code From Browsers](https://github.com/omerbsezer/Fast-Terraform#lambda_apigateway_python)\n   * [SAMPLE-03: EBS (Elastic Block Storage: HDD, SDD) and EFS (Elastic File System: NFS) Configuration with EC2s (Ubuntu and Windows Instances)](https://github.com/omerbsezer/Fast-Terraform#ebs_efs_ec2)\n   * [SAMPLE-04: Provisioning ECR (Elastic Container Repository), Pushing Image to ECR, Provisioning ECS (Elastic Container Service), VPC (Virtual Private Cloud), ELB (Elastic Load Balancer), ECS Tasks and Service on Fargate Cluster](https://github.com/omerbsezer/Fast-Terraform#ecr_ecs_elb_vpc_ecs_service_fargate)\n   * [SAMPLE-05: Provisioning ECR, Lambda Function and API Gateway to run Flask App Container on Lambda](https://github.com/omerbsezer/Fast-Terraform#ecr_lambda_apigateway_container)\n   * [SAMPLE-06: Provisioning EKS (Elastic Kubernetes Service) with Managed Nodes using Blueprint and Modules](https://github.com/omerbsezer/Fast-Terraform#eks_managednodes_blueprint)\n   * [SAMPLE-07: CI/CD on AWS =&gt; Provisioning CodeCommit and CodePipeline, Triggering CodeBuild and CodeDeploy, Running on Lambda Container](https://github.com/omerbsezer/Fast-Terraform#ci_cd)\n   * [SAMPLE-08: Provisioning S3 and CloudFront to serve Static Web Site](https://github.com/omerbsezer/Fast-Terraform#s3_cloudfront)\n* [Details](https://github.com/omerbsezer/Fast-Terraform#details)\n* [Terraform Cheatsheet](https://github.com/omerbsezer/Fast-Terraform#cheatsheet)\n* [Other Useful Resources Related Terraform](https://github.com/omerbsezer/Fast-Terraform#resource)\n* [References](https://github.com/omerbsezer/Fast-Terraform#references)", "author_fullname": "t2_muiope", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fast-Terraform: Terraform Tutorial, How-To: Hands-on LABs, and AWS Hands-on Sample Usage Scenarios (Infrastructure As Code)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12zfwq0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682511860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to share the Terraform tutorial &lt;strong&gt;(Infrastructure As Code for Cloud)&lt;/strong&gt;, cheat sheet, and usage scenarios that I created as a notebook for myself. This repo covers Terraform with &lt;strong&gt;(How-To) HANDS-On LABs and AWS SAMPLEs&lt;/strong&gt; (comprehensive, but simple):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Resources, Data Sources, Variables, Meta Arguments, Provisioners, Dynamic Blocks, Modules, Workspaces, Templates, Remote State.&lt;/li&gt;\n&lt;li&gt;Provisioning AWS Components (EC2, Lambda, ECS, EKS, API Gateway, ELB, CodePipeline, CodeBuild, etc.), use cases, and details. Possible usage scenarios are aimed to update over time.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Tutorial Link:&lt;/strong&gt; &lt;a href=\"https://github.com/omerbsezer/Fast-Terraform\"&gt;&lt;strong&gt;https://github.com/omerbsezer/Fast-Terraform&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Extra Kubernetes-Tutorial Link:&lt;/strong&gt; &lt;a href=\"https://github.com/omerbsezer/Fast-Kubernetes\"&gt;&lt;strong&gt;https://github.com/omerbsezer/Fast-Kubernetes&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Quick Look (How-To): Terraform Hands-on LABs&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;These LABs focus on Terraform features, and help to learn Terraform:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB00-Terraform-Install-AWS-Configuration.md\"&gt;LAB-00: Installing Terraform, AWS Configuration with Terraform&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB01-Terraform-Docker-Without-Cloud.md\"&gt;LAB-01: Terraform Docker =&amp;gt; Pull Docker Image, Create Docker Container on Local Machine&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB02-Resources-Basic-EC2.md\"&gt;LAB-02: Resources =&amp;gt; Provision Basic EC2 (Ubuntu 22.04)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB03-Variables-Locals-Output-EC2.md\"&gt;LAB-03: Variables, Locals, Output =&amp;gt; Provision EC2s&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB04-Meta-Arguments-IAM-User-Group-Policy.md\"&gt;LAB-04: Meta Arguments (Count, For_Each, Map) =&amp;gt; Provision IAM Users, Groups, Policies, Attachment Policy-User&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB05-Dynamic-Blocks-Security-Groups-EC2.md\"&gt;LAB-05: Dynamic Blocks =&amp;gt; Provision Security Groups, EC2, VPC&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB06-Data-Sources-EC2.md\"&gt;LAB-06: Data Sources with Depends_on =&amp;gt; Provision EC2&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB07-Provisioners-Null-Resources.md\"&gt;LAB-07: Provisioners (file, remote-exec), Null Resources (local-exec) =&amp;gt; Provision Key-Pair, SSH Connection&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB08-Modules-EC2.md\"&gt;LAB-08: Modules =&amp;gt; Provision EC2&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB09-Workspaces-EC2.md\"&gt;LAB-09: Workspaces =&amp;gt; Provision EC2 with Different tfvars Files&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB10-Templates-User-Policy.md\"&gt;LAB-10: Templates =&amp;gt; Provision IAM User, User Access Key, Policy&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB11-Backend-Remote-State.md\"&gt;LAB-11: Backend - Remote States =&amp;gt; Provision EC2 and Save State File on S3&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/Terraform-Cheatsheet.md\"&gt;Terraform Cheatsheet&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Quick Look (How-To): AWS Terraform Hands-on Samples&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;These samples focus on how to create and use AWS components (EC2, EBS, EFS, IAM Roles, IAM Policies, Key-Pairs, VPC with Network Components, Lambda, ECR, ECS with Fargate, EKS with Managed Nodes, ASG, ELB, API Gateway, S3, CloudFront, CodeCommit, CodePipeline, CodeBuild, CodeDeploy) with Terraform:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE01-EC2-VPC-Ubuntu-Win-SSH-RDP.md\"&gt;SAMPLE-01: Provisioning EC2s (Windows 2019 Server, Ubuntu 20.04) on VPC (Subnet), Creating Key-Pair, Connecting Ubuntu using SSH, and Connecting Windows Using RDP&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE02-Lambda-API-Gateway-Python.md\"&gt;SAMPLE-02: Provisioning Lambda Function, API Gateway and Reaching HTML Page in Python Code From Browser&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE03-EC2-EBS-EFS.md\"&gt;SAMPLE-03: EBS (Elastic Block Storage: HDD, SDD) and EFS (Elastic File System: NFS) Configuration with EC2s (Ubuntu and Windows Instances)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE04-ECR-ECS-ELB-VPC-ECS-Service.md\"&gt;SAMPLE-04: Provisioning ECR (Elastic Container Repository), Pushing Image to ECR, Provisioning ECS (Elastic Container Service), VPC (Virtual Private Cloud), ELB (Elastic Load Balancer), ECS Tasks and Service on Fargate Cluster&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE05-Lambda-Container-ApiGateway-FlaskApp.md\"&gt;SAMPLE-05: Provisioning ECR, Lambda Function and API Gateway to run Flask App Container on Lambda&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE06-EKS-ManagedNodes-Blueprint.md\"&gt;SAMPLE-06: Provisioning EKS (Elastic Kubernetes Service) with Managed Nodes using Blueprint and Modules&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE07-CodeCommit-Pipeline-Build-Deploy-Lambda.md\"&gt;SAMPLE-07: CI/CD on AWS =&amp;gt; Provisioning CodeCommit and CodePipeline, Triggering CodeBuild and CodeDeploy, Running on Lambda Container&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE08-S3-CloudFront-Static-WebSite.md\"&gt;SAMPLE-08: Provisioning S3 and CloudFront to serve Static Web Site&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#motivation\"&gt;Motivation&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#what_is_terraform\"&gt;What is Terraform?&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#how_terrafom_works\"&gt;How Terraform Works?&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#terrafom_file_components\"&gt;Terraform File Components&lt;/a&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#providers\"&gt;Providers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#resources\"&gt;Resources&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#variables\"&gt;Variables (tfvar)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#values\"&gt;Values (Locals, Outputs)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#meta_arguments\"&gt;Meta Arguments&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#dynamic_blocks\"&gt;Dynamic Blocks&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#datasources\"&gt;Data Sources&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#provisioners\"&gt;Provisioners (file, remote_exec, local_exec), Null Resource&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#modules\"&gt;Modules&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#workspaces\"&gt;Workspaces&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#templates\"&gt;Templates&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#backends_remote_states\"&gt;Backends and Remote States&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#best_practice\"&gt;Terraform Best Practices&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#samples\"&gt;AWS Terraform Hands-on Samples&lt;/a&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#ec2_vpc_key_pair_ssh_rdp\"&gt;SAMPLE-01: EC2s (Windows 2019 Server, Ubuntu 20.04), VPC, Key-Pairs for SSH, RDP connections&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#lambda_apigateway_python\"&gt;SAMPLE-02: Provisioning Lambda Function, API Gateway and Reaching HTML Page in Python Code From Browsers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#ebs_efs_ec2\"&gt;SAMPLE-03: EBS (Elastic Block Storage: HDD, SDD) and EFS (Elastic File System: NFS) Configuration with EC2s (Ubuntu and Windows Instances)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#ecr_ecs_elb_vpc_ecs_service_fargate\"&gt;SAMPLE-04: Provisioning ECR (Elastic Container Repository), Pushing Image to ECR, Provisioning ECS (Elastic Container Service), VPC (Virtual Private Cloud), ELB (Elastic Load Balancer), ECS Tasks and Service on Fargate Cluster&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#ecr_lambda_apigateway_container\"&gt;SAMPLE-05: Provisioning ECR, Lambda Function and API Gateway to run Flask App Container on Lambda&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#eks_managednodes_blueprint\"&gt;SAMPLE-06: Provisioning EKS (Elastic Kubernetes Service) with Managed Nodes using Blueprint and Modules&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#ci_cd\"&gt;SAMPLE-07: CI/CD on AWS =&amp;gt; Provisioning CodeCommit and CodePipeline, Triggering CodeBuild and CodeDeploy, Running on Lambda Container&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#s3_cloudfront\"&gt;SAMPLE-08: Provisioning S3 and CloudFront to serve Static Web Site&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#details\"&gt;Details&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#cheatsheet\"&gt;Terraform Cheatsheet&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#resource\"&gt;Other Useful Resources Related Terraform&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#references\"&gt;References&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?auto=webp&amp;v=enabled&amp;s=aff26802866c8cce610984e0b23824759b5e96d9", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=155564a5e52eb1b21bd0c1f37bada689f46741a1", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e786a876c9e7662b513d04d0ccf664e8f6da45d8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f4ddd263c3406b748c18985efa7fab7a9c4f154", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=978ae3396e5dabfe24da9c5417a8c7809e727957", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76ff4eaee9dee400851b777417f062428646a90c", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea5a448c788a5c53455f942fc541d7f026aba6d9", "width": 1080, "height": 540}], "variants": {}, "id": "_glqqYG7gBRy19Ov4gqUzroMtXxsOzvirCtVjW58RnI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "12zfwq0", "is_robot_indexable": true, "report_reasons": null, "author": "obsezer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zfwq0/fastterraform_terraform_tutorial_howto_handson/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12zfwq0/fastterraform_terraform_tutorial_howto_handson/", "subreddit_subscribers": 102639, "created_utc": 1682511860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The latest [Thoughtworks Tech Radar](https://www.thoughtworks.com/radar) is out. Some highlights in the data space:\n\n## \ud83d\udfe2 Adopt\n\n* [DVC](HTTPs://dvc.org)\n\n## \ud83d\udc4d\ud83c\udffb Trial\n\n* [Apache Hudi](https://hudi.apache.org/)\n* [DuckDB](https://duckdb.org/)\n* [Soda Core](https://www.soda.io/core)\n* [dbt-unit-testing](https://github.com/EqualExperts/dbt-unit-testing)\n* [Lakehouse Architecture](https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf)\n\n## \ud83d\udc40 Assess\n\n* [Neon](https://neon.tech/)\n* [dbt-expectations](https://github.com/calogica/dbt-expectations/tree/0.8.2/)\n\n## \ud83d\udfe0 Hold\n\n* [Denodo](https://www.denodo.com/en)\n\n---\n\nDid anything else catch your eye from the radar? Any thoughts on the assessments of the above tools? \n\nFor me, it was seeing Denodo listed. I've not used it, but it's fairly unusual for tools &amp; platforms to move to Hold (often the entries, or 'blips' as they're called, just don't get listed next time), so seems they had a pretty bad time with Denodo, even saying: \n\n&gt; we recommend that you do not use Denodo as a primary data transformation tool and use tools like Spark or SQL (with dbt) for your data transformations instead.", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data-eng related highlights from the latest Thoughtworks Tech Radar", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ze7uy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682507544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The latest &lt;a href=\"https://www.thoughtworks.com/radar\"&gt;Thoughtworks Tech Radar&lt;/a&gt; is out. Some highlights in the data space:&lt;/p&gt;\n\n&lt;h2&gt;\ud83d\udfe2 Adopt&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"HTTPs://dvc.org\"&gt;DVC&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;\ud83d\udc4d\ud83c\udffb Trial&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://hudi.apache.org/\"&gt;Apache Hudi&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://duckdb.org/\"&gt;DuckDB&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.soda.io/core\"&gt;Soda Core&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/EqualExperts/dbt-unit-testing\"&gt;dbt-unit-testing&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf\"&gt;Lakehouse Architecture&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;\ud83d\udc40 Assess&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://neon.tech/\"&gt;Neon&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/calogica/dbt-expectations/tree/0.8.2/\"&gt;dbt-expectations&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;\ud83d\udfe0 Hold&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.denodo.com/en\"&gt;Denodo&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Did anything else catch your eye from the radar? Any thoughts on the assessments of the above tools? &lt;/p&gt;\n\n&lt;p&gt;For me, it was seeing Denodo listed. I&amp;#39;ve not used it, but it&amp;#39;s fairly unusual for tools &amp;amp; platforms to move to Hold (often the entries, or &amp;#39;blips&amp;#39; as they&amp;#39;re called, just don&amp;#39;t get listed next time), so seems they had a pretty bad time with Denodo, even saying: &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;we recommend that you do not use Denodo as a primary data transformation tool and use tools like Spark or SQL (with dbt) for your data transformations instead.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?auto=webp&amp;v=enabled&amp;s=811182d29905a1e1e9403c451cf55bb6e8f6f368", "width": 1600, "height": 837}, "resolutions": [{"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64ff67d5c54e2223029ebe80e5afbea47bedd2d7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f125b62c2d28fe65a11ab525349a719a7a9e0d06", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=492e504d582234f81d47fd498965c4311a0947ad", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54ad7c054ee7bdf6bb0dea7fad5a7821a18da98e", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1b9965c5698e7f4220c164dcfe0fa5ea058a274", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=689783f11d2d3dfda79b30353949a6c5d0c30306", "width": 1080, "height": 564}], "variants": {}, "id": "qKpvdmTr2prhwnfo9Lt4Bu8EUjs0RuFpA_BAZYOqGlQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ze7uy", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ze7uy/dataeng_related_highlights_from_the_latest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ze7uy/dataeng_related_highlights_from_the_latest/", "subreddit_subscribers": 102639, "created_utc": 1682507544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi DEs of Reddit,\n\nI\u2019m about to start a new project which requires me to download daily a large file from a public website (~30Gb) and land this file into AWS S3. I\u2019m trying to brainstorm the most efficient solution and I was wondering if anybody had an experience downloading large files like this? \n\nAnything in particular I should be aware of/consider ? \n\nThank you!", "author_fullname": "t2_a3m6qw38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading large files from public websites - Brainstorm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ze0m5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682507000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi DEs of Reddit,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m about to start a new project which requires me to download daily a large file from a public website (~30Gb) and land this file into AWS S3. I\u2019m trying to brainstorm the most efficient solution and I was wondering if anybody had an experience downloading large files like this? &lt;/p&gt;\n\n&lt;p&gt;Anything in particular I should be aware of/consider ? &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ze0m5", "is_robot_indexable": true, "report_reasons": null, "author": "sk808mafia", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ze0m5/downloading_large_files_from_public_websites/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ze0m5/downloading_large_files_from_public_websites/", "subreddit_subscribers": 102639, "created_utc": 1682507000.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}