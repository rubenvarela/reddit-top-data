{"kind": "Listing", "data": {"after": "t3_12yr637", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " **If all those out-of-work data scientists and software engineers banded together, what problem could actually be solved with their skills? Let's ignore the profit motive, since they're not getting paid right now anyway (I'm being tongue-in-cheek). No stealing and selling data, just literally applying tech skills to solve issues. Put another way, we've spent all this time and energy (and money) learning these advanced technical skills. If we spent our efforts on actually creating things that have direct utility to the world instead of enriching executives, what specifically could be achieved?**", "author_fullname": "t2_1vrrxpqh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ignoring the profit motive for a moment (bear with me), what real-life problems could all the out-of-work DS and SWE solve with their skills?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yzdsi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 171, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 171, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682464481.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;If all those out-of-work data scientists and software engineers banded together, what problem could actually be solved with their skills? Let&amp;#39;s ignore the profit motive, since they&amp;#39;re not getting paid right now anyway (I&amp;#39;m being tongue-in-cheek). No stealing and selling data, just literally applying tech skills to solve issues. Put another way, we&amp;#39;ve spent all this time and energy (and money) learning these advanced technical skills. If we spent our efforts on actually creating things that have direct utility to the world instead of enriching executives, what specifically could be achieved?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12yzdsi", "is_robot_indexable": true, "report_reasons": null, "author": "TehSausBaus", "discussion_type": null, "num_comments": 94, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12yzdsi/ignoring_the_profit_motive_for_a_moment_bear_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12yzdsi/ignoring_the_profit_motive_for_a_moment_bear_with/", "subreddit_subscribers": 881673, "created_utc": 1682464481.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_17nocwms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "We have trained own text2gif model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"145d71kzb4wa1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/145d71kzb4wa1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=80adc93714e2eb6312e2e5010e4c10877aa1b70d"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/145d71kzb4wa1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=06dedf67489ca6e5516810f906853d45f21a7799"}], "s": {"y": 256, "gif": "https://i.redd.it/145d71kzb4wa1.gif", "mp4": "https://preview.redd.it/145d71kzb4wa1.gif?format=mp4&amp;v=enabled&amp;s=fae87a73ec3c6d349365a3f8cbe7b995ee68af45", "x": 256}, "id": "145d71kzb4wa1"}, "6my5tng1c4wa1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 116, "x": 108, "u": "https://preview.redd.it/6my5tng1c4wa1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=0f96f47486c55cd6105048645a77660ef8c74ce1"}, {"y": 232, "x": 216, "u": "https://preview.redd.it/6my5tng1c4wa1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=ffb50b0d21ffadb73936d623e5515677d5ce71dd"}], "s": {"y": 276, "gif": "https://i.redd.it/6my5tng1c4wa1.gif", "mp4": "https://preview.redd.it/6my5tng1c4wa1.gif?format=mp4&amp;v=enabled&amp;s=05f886b1332a4a852087ec658155dfdf65911c33", "x": 256}, "id": "6my5tng1c4wa1"}, "c1aeg02zb4wa1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 116, "x": 108, "u": "https://preview.redd.it/c1aeg02zb4wa1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=f837f24b4a1d0a885f47752bc9e88951365c392a"}, {"y": 232, "x": 216, "u": "https://preview.redd.it/c1aeg02zb4wa1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=d16372e1b3629fc2f1cca6b7ccf473c2c26a6f59"}], "s": {"y": 276, "gif": "https://i.redd.it/c1aeg02zb4wa1.gif", "mp4": "https://preview.redd.it/c1aeg02zb4wa1.gif?format=mp4&amp;v=enabled&amp;s=f11137c956b9d86b345d9f8c88d79dab67fc00c1", "x": 256}, "id": "c1aeg02zb4wa1"}, "ff6a2l01c4wa1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 116, "x": 108, "u": "https://preview.redd.it/ff6a2l01c4wa1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=ec133265c98f5a38f08be86332815e140c6dec5f"}, {"y": 232, "x": 216, "u": "https://preview.redd.it/ff6a2l01c4wa1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=17a229d6b8c3e74ae5b4ab8e6b91f87437a2c5b2"}], "s": {"y": 276, "gif": "https://i.redd.it/ff6a2l01c4wa1.gif", "mp4": "https://preview.redd.it/ff6a2l01c4wa1.gif?format=mp4&amp;v=enabled&amp;s=442a21d769efbf71a16b3a91be1d7c6a9ba5250c", "x": 256}, "id": "ff6a2l01c4wa1"}}, "name": "t3_12z0b5p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 145, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "c1aeg02zb4wa1", "id": 267802864}, {"media_id": "145d71kzb4wa1", "id": 267802865}, {"media_id": "ff6a2l01c4wa1", "id": 267802866}, {"media_id": "6my5tng1c4wa1", "id": 267802867}]}, "link_flair_text": "Projects", "can_mod_post": false, "score": 145, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/m2eAXRveIY95FqC3EldacXJedUV62kgmOYpAieB7MEM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682466817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/12z0b5p", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "12z0b5p", "is_robot_indexable": true, "report_reasons": null, "author": "sokolegg", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12z0b5p/we_have_trained_own_text2gif_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/12z0b5p", "subreddit_subscribers": 881673, "created_utc": 1682466817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is the grind of getting jobs on upwork, fiverr etc really worth it?", "author_fullname": "t2_7qvort5t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone managed to successfully freelance as a DS or DA?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z2poa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 66, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 66, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682473266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is the grind of getting jobs on upwork, fiverr etc really worth it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12z2poa", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial_Space9001", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12z2poa/has_anyone_managed_to_successfully_freelance_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12z2poa/has_anyone_managed_to_successfully_freelance_as_a/", "subreddit_subscribers": 881673, "created_utc": 1682473266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently studying this at university and it\u2019s kicking my ass. Have heard it has some applications in DS, so had wanted to know how much of these concepts are used in the day to day.", "author_fullname": "t2_7qvort5t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you have ever used Stochastic Processes in your Data Science role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ys3xv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682448291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently studying this at university and it\u2019s kicking my ass. Have heard it has some applications in DS, so had wanted to know how much of these concepts are used in the day to day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ys3xv", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial_Space9001", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ys3xv/have_you_have_ever_used_stochastic_processes_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ys3xv/have_you_have_ever_used_stochastic_processes_in/", "subreddit_subscribers": 881673, "created_utc": 1682448291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Would greatly appreciate anyone who can share their journey to getting a real DS role (coming from a DS role by title but doing ba work)\n- what skills did you work on the most\n- how long did you have to work before getting the DS role you want\n- how to put your work experience in your resume/ LinkedIn profile - will it hurt you if you have a formal DS job title but do not have the actual professional experience (may have learned from master\u2019s program but don\u2019t have any opportunity to apply them at work) \n- tips on developing project portfolio and finding time to do them on the side\n- how to pick DS specialization to focus your learning on\n\nTIA!\n\nEdit: I apologize. I realize now that maybe my post should have been on the weekly entering and transitioning thread", "author_fullname": "t2_owayirrd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interested to hear success stories of those who have made it to real DS roles coming from a DS role but only by title", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z0pfv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682470917.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682467827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would greatly appreciate anyone who can share their journey to getting a real DS role (coming from a DS role by title but doing ba work)\n- what skills did you work on the most\n- how long did you have to work before getting the DS role you want\n- how to put your work experience in your resume/ LinkedIn profile - will it hurt you if you have a formal DS job title but do not have the actual professional experience (may have learned from master\u2019s program but don\u2019t have any opportunity to apply them at work) \n- tips on developing project portfolio and finding time to do them on the side\n- how to pick DS specialization to focus your learning on&lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n\n&lt;p&gt;Edit: I apologize. I realize now that maybe my post should have been on the weekly entering and transitioning thread&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12z0pfv", "is_robot_indexable": true, "report_reasons": null, "author": "wintergreenboba", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12z0pfv/interested_to_hear_success_stories_of_those_who/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12z0pfv/interested_to_hear_success_stories_of_those_who/", "subreddit_subscribers": 881673, "created_utc": 1682467827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a dataset which is about 90TB. I can run impala or sparksql queries against it but they're very slow. I created a sub-aggregate which runs way faster, but it can't handle every use case so I would have to make several sub-aggregates which means I have to maintain them all. I would rather not to that. Any thoughts?", "author_fullname": "t2_kcl3tfwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle querying huge datasets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yvj5n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682455631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset which is about 90TB. I can run impala or sparksql queries against it but they&amp;#39;re very slow. I created a sub-aggregate which runs way faster, but it can&amp;#39;t handle every use case so I would have to make several sub-aggregates which means I have to maintain them all. I would rather not to that. Any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12yvj5n", "is_robot_indexable": true, "report_reasons": null, "author": "NewEcho2940", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12yvj5n/how_do_you_handle_querying_huge_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12yvj5n/how_do_you_handle_querying_huge_datasets/", "subreddit_subscribers": 881673, "created_utc": 1682455631.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m 27, have an undergraduate degree in Biology from a well known R1 (grad 2019), and a Master\u2019s degree in Human Physiology from Western Central Eastern state school that was 40k of uselessness (grad 2022). During my graduate degree I taught myself programming fundamentals and forced some intro CS classes into my coursework. I graduated June 2022 and 550+ applications later I landed a role in customer support at a biotech company. I\u2019m hesitant to share the role title because it\u2019s kind of niche and I feel I would be doxxing myself but lets call it data scientist.\n\nEven though I went to uni straight out of HS and got my degree from a reputable school, I consider myself a late bloomer and did not have the \u201cmathematical maturity\u201d to take or appreciate the technical courses available to me during undergrad, and the courses in my masters program unfortunately were not up to snuff.\n\nMy current role has a technical title but has very little technical work and very little mentorship, but it pays relatively well (Remote, 80k USD, MCOL). Another bit of useful info, I just proposed to my girlfriend and we are planning on getting married this Fall, and we want to start growing our clan with children, and we plan for me to be the sole source of income. \n\nThe crux of my question is: how do I fill in the gaps of my knowledge from being self taught (CS fundamentals, mathematics/statistics underpinning DS work) and progress in my career (in DS/SWE) to provide for my coming family, while being our sole source of income.\n\nAny advice is much appreciated.", "author_fullname": "t2_1nhqot00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to upskill while starting a family?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z1xqz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682471150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m 27, have an undergraduate degree in Biology from a well known R1 (grad 2019), and a Master\u2019s degree in Human Physiology from Western Central Eastern state school that was 40k of uselessness (grad 2022). During my graduate degree I taught myself programming fundamentals and forced some intro CS classes into my coursework. I graduated June 2022 and 550+ applications later I landed a role in customer support at a biotech company. I\u2019m hesitant to share the role title because it\u2019s kind of niche and I feel I would be doxxing myself but lets call it data scientist.&lt;/p&gt;\n\n&lt;p&gt;Even though I went to uni straight out of HS and got my degree from a reputable school, I consider myself a late bloomer and did not have the \u201cmathematical maturity\u201d to take or appreciate the technical courses available to me during undergrad, and the courses in my masters program unfortunately were not up to snuff.&lt;/p&gt;\n\n&lt;p&gt;My current role has a technical title but has very little technical work and very little mentorship, but it pays relatively well (Remote, 80k USD, MCOL). Another bit of useful info, I just proposed to my girlfriend and we are planning on getting married this Fall, and we want to start growing our clan with children, and we plan for me to be the sole source of income. &lt;/p&gt;\n\n&lt;p&gt;The crux of my question is: how do I fill in the gaps of my knowledge from being self taught (CS fundamentals, mathematics/statistics underpinning DS work) and progress in my career (in DS/SWE) to provide for my coming family, while being our sole source of income.&lt;/p&gt;\n\n&lt;p&gt;Any advice is much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12z1xqz", "is_robot_indexable": true, "report_reasons": null, "author": "AngryDuckling1", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12z1xqz/how_to_upskill_while_starting_a_family/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12z1xqz/how_to_upskill_while_starting_a_family/", "subreddit_subscribers": 881673, "created_utc": 1682471150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Was having a conversation with a colleague about the breadth of libraries available in our work which made us both wonder: What are some tools that are missing from the data science ecosystem?", "author_fullname": "t2_2kmip1ue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some data science tools that don\u2019t exist that you would pay for?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12zr6qw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682530250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was having a conversation with a colleague about the breadth of libraries available in our work which made us both wonder: What are some tools that are missing from the data science ecosystem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12zr6qw", "is_robot_indexable": true, "report_reasons": null, "author": "KeyVisual", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12zr6qw/what_are_some_data_science_tools_that_dont_exist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12zr6qw/what_are_some_data_science_tools_that_dont_exist/", "subreddit_subscribers": 881673, "created_utc": 1682530250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a full stack data scientist who used to build end to end ML solutions in python only. \n\nI have joined a new company and the entire backend is built on golang. All of the support by the site reliability engineering team is given to golang projects only. \n\nI feel like i am left alone, struggling to integrate my machine learning and deep learning projects with the rest of the backend services. \n\nI am struggling a lot and this has affected my annual increment very badly. \n\nI am not even getting time to pick up new things to learn. My whole world life balance has taken a hit. \n\nI am not even getting time to learn golang. Everything is moving away so fast. Feeling helpless. I never imagined that python would become outdated so quickly.", "author_fullname": "t2_869m5ow7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling left out as everyone at my job uses golang", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12zq9mv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682528282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a full stack data scientist who used to build end to end ML solutions in python only. &lt;/p&gt;\n\n&lt;p&gt;I have joined a new company and the entire backend is built on golang. All of the support by the site reliability engineering team is given to golang projects only. &lt;/p&gt;\n\n&lt;p&gt;I feel like i am left alone, struggling to integrate my machine learning and deep learning projects with the rest of the backend services. &lt;/p&gt;\n\n&lt;p&gt;I am struggling a lot and this has affected my annual increment very badly. &lt;/p&gt;\n\n&lt;p&gt;I am not even getting time to pick up new things to learn. My whole world life balance has taken a hit. &lt;/p&gt;\n\n&lt;p&gt;I am not even getting time to learn golang. Everything is moving away so fast. Feeling helpless. I never imagined that python would become outdated so quickly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12zq9mv", "is_robot_indexable": true, "report_reasons": null, "author": "Jaded_Click9591", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12zq9mv/feeling_left_out_as_everyone_at_my_job_uses_golang/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12zq9mv/feeling_left_out_as_everyone_at_my_job_uses_golang/", "subreddit_subscribers": 881673, "created_utc": 1682528282.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in the process of creating a customer segmentation with the hope of clustering by customer behavior, rather than engagement. Because of this, I was going to use more binary variables than continuous variables, which has led me to use K-Prototypes. \n\nI'm curious if you've done this, what issues if any did you have? Someone told me that using more binary variables can make it difficult to cluster, but I've yet to find anything online that supports this. Of course, the only true way to know is to try it, but I thought if someone hear had any advice/experience with this, I could be prepared for it ahead of time.", "author_fullname": "t2_cdcqcaia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you've used K-Prototypes clustering method, what issues (if any) did you have?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12zj4ja", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682518995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the process of creating a customer segmentation with the hope of clustering by customer behavior, rather than engagement. Because of this, I was going to use more binary variables than continuous variables, which has led me to use K-Prototypes. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious if you&amp;#39;ve done this, what issues if any did you have? Someone told me that using more binary variables can make it difficult to cluster, but I&amp;#39;ve yet to find anything online that supports this. Of course, the only true way to know is to try it, but I thought if someone hear had any advice/experience with this, I could be prepared for it ahead of time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12zj4ja", "is_robot_indexable": true, "report_reasons": null, "author": "InjuryNeat7483", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12zj4ja/if_youve_used_kprototypes_clustering_method_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12zj4ja/if_youve_used_kprototypes_clustering_method_what/", "subreddit_subscribers": 881673, "created_utc": 1682518995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Prety much the title, Are you Data Analyst? MlE?  Or what sub branch Do u work in? Thanks", "author_fullname": "t2_usmthp9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Data Science Sub branch do you work in?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z5n3u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682481340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Prety much the title, Are you Data Analyst? MlE?  Or what sub branch Do u work in? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12z5n3u", "is_robot_indexable": true, "report_reasons": null, "author": "1st_human", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12z5n3u/which_data_science_sub_branch_do_you_work_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12z5n3u/which_data_science_sub_branch_do_you_work_in/", "subreddit_subscribers": 881673, "created_utc": 1682481340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking for clever solutions from seniors and leaders out there.\n\nWhat processes/templates/tools do you have in place to reduce the iterative churn in your analyses and projects? We spend far too much time doing high-lift/low-return exploratory analysis with six time-strapped decision-makers involved because we haven't been able to cut through the noise and get to the actual question we're solving for. The ambiguity inevitably drifts down to the analyst team, who know the least of anyone about the goals but have to make something out of nothing. Not a good setup.\n\nAny tips from the vets on herding cats, getting to the point and getting to done when it comes to data needed, analysis needed, outcome desired (i.e. project management)? What's worked well? Any books or resources?", "author_fullname": "t2_5oxw05u1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analysis Planning and Communication", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ywi8j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682457715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for clever solutions from seniors and leaders out there.&lt;/p&gt;\n\n&lt;p&gt;What processes/templates/tools do you have in place to reduce the iterative churn in your analyses and projects? We spend far too much time doing high-lift/low-return exploratory analysis with six time-strapped decision-makers involved because we haven&amp;#39;t been able to cut through the noise and get to the actual question we&amp;#39;re solving for. The ambiguity inevitably drifts down to the analyst team, who know the least of anyone about the goals but have to make something out of nothing. Not a good setup.&lt;/p&gt;\n\n&lt;p&gt;Any tips from the vets on herding cats, getting to the point and getting to done when it comes to data needed, analysis needed, outcome desired (i.e. project management)? What&amp;#39;s worked well? Any books or resources?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ywi8j", "is_robot_indexable": true, "report_reasons": null, "author": "r4intr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ywi8j/analysis_planning_and_communication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ywi8j/analysis_planning_and_communication/", "subreddit_subscribers": 881673, "created_utc": 1682457715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Full disclosure - I\u2019m an analytics guy so good with understanding and framing data but not super knowledgeable in ML work.\n\n\nI have a large number of variables related to user actions and application functionality for a consumer facing software. I am looking for a solution to detect anomalies in these metrics on a daily basis.\n\n\nThe anomaly detection needs to be \u201cintelligent\u201d enough to look both the individual metric\u2019s historical trends as well as how all other semi-correlated metrics are moving that day.\n\n\nWhat I would basically like to create is a tool that will identify metrics that have moved in an unexpected way in the past day to help identify potential issues quickly.\n\n-\tMany of these metrics are highly volatile so setting intuitive boundaries (e.g. alert if metric increases by 5%) is too crude and will create way too many false positives.\n-\tThere are 100+ total metrics to track and each will need to be tracked \u201coverall\u201d as well as broken out by certain attributes(for example, we would want to track a metric overall as well as by device type, by user\u2019s country, etc\u2026). \n-\tThe data is all stored in Snowflake and the metrics are compiled using logic in SQL. \n\n\nAny guidance that the group can provide on approaches, tools, 3rd party solutions, or algorithms that may help would be greatly appreciated!!!", "author_fullname": "t2_s0ppa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ML options for real-time anomaly detection across a large set of volatile metrics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ytnyk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682451700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Full disclosure - I\u2019m an analytics guy so good with understanding and framing data but not super knowledgeable in ML work.&lt;/p&gt;\n\n&lt;p&gt;I have a large number of variables related to user actions and application functionality for a consumer facing software. I am looking for a solution to detect anomalies in these metrics on a daily basis.&lt;/p&gt;\n\n&lt;p&gt;The anomaly detection needs to be \u201cintelligent\u201d enough to look both the individual metric\u2019s historical trends as well as how all other semi-correlated metrics are moving that day.&lt;/p&gt;\n\n&lt;p&gt;What I would basically like to create is a tool that will identify metrics that have moved in an unexpected way in the past day to help identify potential issues quickly.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;  Many of these metrics are highly volatile so setting intuitive boundaries (e.g. alert if metric increases by 5%) is too crude and will create way too many false positives.&lt;/li&gt;\n&lt;li&gt;  There are 100+ total metrics to track and each will need to be tracked \u201coverall\u201d as well as broken out by certain attributes(for example, we would want to track a metric overall as well as by device type, by user\u2019s country, etc\u2026). &lt;/li&gt;\n&lt;li&gt;  The data is all stored in Snowflake and the metrics are compiled using logic in SQL. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any guidance that the group can provide on approaches, tools, 3rd party solutions, or algorithms that may help would be greatly appreciated!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ytnyk", "is_robot_indexable": true, "report_reasons": null, "author": "Junglejim1020", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ytnyk/ml_options_for_realtime_anomaly_detection_across/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ytnyk/ml_options_for_realtime_anomaly_detection_across/", "subreddit_subscribers": 881673, "created_utc": 1682451700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Rant time\u2026\n\nI work at a major financial company doing data science. I\u2019ve been in a data science role for 2 years. Prior to that, in the same company, I worked as a data analyst for 5 years. In the first 5 years, I got a Masters in statistics from a local university (it\u2019s not Harvard but not some BS online program). I was honestly doing more data science work in my analyst position, I made 3 very impactful models that change how the company works, I was just young. It was so hard to get hired for this data science position, I basically had to find one where it was a pure analyst position. \n\nEvery time I look for roles internally, I get passed for external candidates. When I look at these external candidates, many of them had a different undergrad than stats or DS, they even work in a different career for a bit, then go back to school or do some online program and then pass me up.\n\nI\u2019m just looking to use my quantitative chops more. I\u2019ve been applying for internal DS, analyst, and risk management positions. I just want to use my quant skills, I like to actually learn mathematics and verify assumptions of these models, and I find no one else does. All of my colleagues just took some random self paced online class and are deploying models to production, and I\u2019m cleaning everyone\u2019s data.\n\nEdit: 3 weeks ago, I talked w a hiring manager about a risk position. Everything went great, she said she\u2019d set up an interview with me in the next week. A week goes by, nothing. I email - no response. Now the position is filled. Thanks for the consideration!!!!", "author_fullname": "t2_3rafs7wl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internal Hiring Struggles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12zftbe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682511631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Rant time\u2026&lt;/p&gt;\n\n&lt;p&gt;I work at a major financial company doing data science. I\u2019ve been in a data science role for 2 years. Prior to that, in the same company, I worked as a data analyst for 5 years. In the first 5 years, I got a Masters in statistics from a local university (it\u2019s not Harvard but not some BS online program). I was honestly doing more data science work in my analyst position, I made 3 very impactful models that change how the company works, I was just young. It was so hard to get hired for this data science position, I basically had to find one where it was a pure analyst position. &lt;/p&gt;\n\n&lt;p&gt;Every time I look for roles internally, I get passed for external candidates. When I look at these external candidates, many of them had a different undergrad than stats or DS, they even work in a different career for a bit, then go back to school or do some online program and then pass me up.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m just looking to use my quantitative chops more. I\u2019ve been applying for internal DS, analyst, and risk management positions. I just want to use my quant skills, I like to actually learn mathematics and verify assumptions of these models, and I find no one else does. All of my colleagues just took some random self paced online class and are deploying models to production, and I\u2019m cleaning everyone\u2019s data.&lt;/p&gt;\n\n&lt;p&gt;Edit: 3 weeks ago, I talked w a hiring manager about a risk position. Everything went great, she said she\u2019d set up an interview with me in the next week. A week goes by, nothing. I email - no response. Now the position is filled. Thanks for the consideration!!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12zftbe", "is_robot_indexable": true, "report_reasons": null, "author": "Active-Bag9261", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12zftbe/internal_hiring_struggles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12zftbe/internal_hiring_struggles/", "subreddit_subscribers": 881673, "created_utc": 1682511631.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/h4gnqvx857wa1.png?width=1142&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=43376fc2a3c3dfab90d0e40978a5b0d4758a763d", "author_fullname": "t2_thbyp5gl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do any of you do modeling with pymc3 or Bayesian moderation analysis? I need a data science player to import my research results and visualize the moderation effect for me (here are some useful links: https://www.pymc.io/projects/docs/en/v3/pymc-examples/examples/case_studies/moderation)... Thanks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": false, "media_metadata": {"h4gnqvx857wa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 57, "x": 108, "u": "https://preview.redd.it/h4gnqvx857wa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1bd4b9ec4e0f89c2d111aa7f543d7778a9e210ab"}, {"y": 114, "x": 216, "u": "https://preview.redd.it/h4gnqvx857wa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=541086597ecfd34b6669f074c66e99f59c4c3ac7"}, {"y": 169, "x": 320, "u": "https://preview.redd.it/h4gnqvx857wa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ff8cd88864f4e58669d538a1537802cc1bf33c5"}, {"y": 339, "x": 640, "u": "https://preview.redd.it/h4gnqvx857wa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8214c579acf1004e46b353a6752aafcddda161ad"}, {"y": 508, "x": 960, "u": "https://preview.redd.it/h4gnqvx857wa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30416444c2196e49b6dacbcdeed61a8a7c41dde6"}, {"y": 572, "x": 1080, "u": "https://preview.redd.it/h4gnqvx857wa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6f8a40cb1c54ed7cb8654b30f49d79a29ca5d80"}], "s": {"y": 605, "x": 1142, "u": "https://preview.redd.it/h4gnqvx857wa1.png?width=1142&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=43376fc2a3c3dfab90d0e40978a5b0d4758a763d"}, "id": "h4gnqvx857wa1"}}, "name": "t3_12zc7ic", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/mlT5Td0-o8YgQ2KiPmHJ_ZoTPegO8KAiVT7FBcXmC14.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682501741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/h4gnqvx857wa1.png?width=1142&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=43376fc2a3c3dfab90d0e40978a5b0d4758a763d\"&gt;https://preview.redd.it/h4gnqvx857wa1.png?width=1142&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=43376fc2a3c3dfab90d0e40978a5b0d4758a763d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12zc7ic", "is_robot_indexable": true, "report_reasons": null, "author": "Best-Tour-2952", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12zc7ic/do_any_of_you_do_modeling_with_pymc3_or_bayesian/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12zc7ic/do_any_of_you_do_modeling_with_pymc3_or_bayesian/", "subreddit_subscribers": 881673, "created_utc": 1682501741.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_v8n3a1nm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streamlit in 5 minutes Tutorial", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_12zs28d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/o6ez9gvxLOk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Streamlit in 5 minutes Tutorial\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Streamlit in 5 minutes Tutorial", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/o6ez9gvxLOk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Streamlit in 5 minutes Tutorial\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/o6ez9gvxLOk/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/o6ez9gvxLOk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Streamlit in 5 minutes Tutorial\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/12zs28d", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/R6M00l2UUhLEal_UL7UCLZKoS6iqBj9qzEiNUGlQoEA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682532182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/o6ez9gvxLOk", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iy3LUsoRrw9G7plpvxfKuQb8WifELhnyKeKqDqwBhz0.jpg?auto=webp&amp;v=enabled&amp;s=e0cebcfe8e4600b7a3ca06ad21fefaf83f1a3052", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/iy3LUsoRrw9G7plpvxfKuQb8WifELhnyKeKqDqwBhz0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eeefab21f18af324aa3580556c8904caa28ff9bb", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/iy3LUsoRrw9G7plpvxfKuQb8WifELhnyKeKqDqwBhz0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cacc2a8b11e170d8e4f7ef056a8b2a33096d4f11", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/iy3LUsoRrw9G7plpvxfKuQb8WifELhnyKeKqDqwBhz0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38938c360b6a0cf3481db8d1f5bf20c9601deb3c", "width": 320, "height": 240}], "variants": {}, "id": "HtPQ8kKaX85XzvIsdvMj8C_uQX19bqs72MqBU0y1bsw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12zs28d", "is_robot_indexable": true, "report_reasons": null, "author": "fancypigollo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12zs28d/streamlit_in_5_minutes_tutorial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/o6ez9gvxLOk", "subreddit_subscribers": 881673, "created_utc": 1682532182.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Streamlit in 5 minutes Tutorial", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/o6ez9gvxLOk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Streamlit in 5 minutes Tutorial\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/o6ez9gvxLOk/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This question is mainly for Senior/Staff+ Data scientists that work in a non-academic setting:\n\nAs a data scientist in training, I would like to develop a \"map\" I can follow to make sure I'm progressing in terms of my learning in data science.\n\nTherefore, I thought I would create a Leveling system that I can measure myself against to see where I'm at (naturally, from easiest to master to hardest to master). This leveling system should be created for:\n\n* Someone in the industry in a non academic setting, and \n\n* Correlated to what you'd expect from someone with n years of experience\n\nAnd for scope reasons, lets just limit it the projects that ML models are being used for in the real world.\n\nFor example:\n\n* Level 1: Fluent in Propensity to Purchase, Customer Retention, Supply chain/Revenue Optimization - tasks that use classic Classification &amp; Regression models\n\n* Level 2: Fluent in Anomaly/Fraud detection - highly imbalanced datasets\n\n* Level 3: Fluent in Time series prediction, Anomaly detection within a time series\n\n* Level 4: Recommendation systems (Netflix, Amazon)\n\n* Level 5: Network Analysis (Facebook)\n\n* Level 6: Active/Transfer Learning\n\n* Level ?: Real time detection\n\n* Level ?: Image/NLP classification\n\n* ...\n\nSome of these may be incorrect or out of order - please fix and add to your heart's desire. \n\n**Bonus points** if you can list out some resources to help me achieve fluency for each of the levels.", "author_fullname": "t2_g0ajn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's a good Leveling system to follow for Data Scientists that are starting out?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12zrika", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682530965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This question is mainly for Senior/Staff+ Data scientists that work in a non-academic setting:&lt;/p&gt;\n\n&lt;p&gt;As a data scientist in training, I would like to develop a &amp;quot;map&amp;quot; I can follow to make sure I&amp;#39;m progressing in terms of my learning in data science.&lt;/p&gt;\n\n&lt;p&gt;Therefore, I thought I would create a Leveling system that I can measure myself against to see where I&amp;#39;m at (naturally, from easiest to master to hardest to master). This leveling system should be created for:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Someone in the industry in a non academic setting, and &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Correlated to what you&amp;#39;d expect from someone with n years of experience&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And for scope reasons, lets just limit it the projects that ML models are being used for in the real world.&lt;/p&gt;\n\n&lt;p&gt;For example:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Level 1: Fluent in Propensity to Purchase, Customer Retention, Supply chain/Revenue Optimization - tasks that use classic Classification &amp;amp; Regression models&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Level 2: Fluent in Anomaly/Fraud detection - highly imbalanced datasets&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Level 3: Fluent in Time series prediction, Anomaly detection within a time series&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Level 4: Recommendation systems (Netflix, Amazon)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Level 5: Network Analysis (Facebook)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Level 6: Active/Transfer Learning&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Level ?: Real time detection&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Level ?: Image/NLP classification&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;...&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Some of these may be incorrect or out of order - please fix and add to your heart&amp;#39;s desire. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Bonus points&lt;/strong&gt; if you can list out some resources to help me achieve fluency for each of the levels.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12zrika", "is_robot_indexable": true, "report_reasons": null, "author": "Katsuuu100", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12zrika/whats_a_good_leveling_system_to_follow_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12zrika/whats_a_good_leveling_system_to_follow_for_data/", "subreddit_subscribers": 881673, "created_utc": 1682530965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI have now had 2 years experience working on data analysis at a local authority. I am interested in the transition to data science and would like to know if I am on the right track and what roles I could realistically expect to land.\n\nI am currently enrolled on a Level 4 Data Analyst apprenticeship which covers Power BI and R plus a bit of SQL and Python for analysis. It has mainly covered producing visuals using ggplot2 and I will cover regression and machine learning in the next part of the course.\n\nAs well as this as I am on the Data Camp Data Scientist Professional track in R which I am doing as an extra circular activity to supplement my apprenticeship. I hope to become certified shortly after summer and then plan to redo the track in Python.\n\nWithin my role I have used R for visualisation and am experienced in Power BI for dashboard creation and DAX. This is on top of routine data cleaning and analysis in Excel and some GIS.\n\nI also hold a first class integrated masters in environmental science.\n\nI am aware I will likely need to go for a junior role seeing as I am not experienced in data science specifically? Would be good to have an idea of associated salaries  too. I am currently paid in the early 30s salary wise ( I am outside London plus public sector) and I would like at least 40k next year seeing as this is below what the senior analyst pay is in my organisation.\n\nThank you for any advice :) Hoping to start applying for roles early next year.", "author_fullname": "t2_mdk3eav8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from data analyst to data scientist, UK based, am I on the right track, possible roles, salary expectations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12zr323", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682530031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have now had 2 years experience working on data analysis at a local authority. I am interested in the transition to data science and would like to know if I am on the right track and what roles I could realistically expect to land.&lt;/p&gt;\n\n&lt;p&gt;I am currently enrolled on a Level 4 Data Analyst apprenticeship which covers Power BI and R plus a bit of SQL and Python for analysis. It has mainly covered producing visuals using ggplot2 and I will cover regression and machine learning in the next part of the course.&lt;/p&gt;\n\n&lt;p&gt;As well as this as I am on the Data Camp Data Scientist Professional track in R which I am doing as an extra circular activity to supplement my apprenticeship. I hope to become certified shortly after summer and then plan to redo the track in Python.&lt;/p&gt;\n\n&lt;p&gt;Within my role I have used R for visualisation and am experienced in Power BI for dashboard creation and DAX. This is on top of routine data cleaning and analysis in Excel and some GIS.&lt;/p&gt;\n\n&lt;p&gt;I also hold a first class integrated masters in environmental science.&lt;/p&gt;\n\n&lt;p&gt;I am aware I will likely need to go for a junior role seeing as I am not experienced in data science specifically? Would be good to have an idea of associated salaries  too. I am currently paid in the early 30s salary wise ( I am outside London plus public sector) and I would like at least 40k next year seeing as this is below what the senior analyst pay is in my organisation.&lt;/p&gt;\n\n&lt;p&gt;Thank you for any advice :) Hoping to start applying for roles early next year.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12zr323", "is_robot_indexable": true, "report_reasons": null, "author": "SeekedSwan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12zr323/transitioning_from_data_analyst_to_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12zr323/transitioning_from_data_analyst_to_data_scientist/", "subreddit_subscribers": 881673, "created_utc": 1682530031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in the process of developing a ML model that will rank individuals based on their likelihood to complete an action. The ultimately goal of this model is to reduce the amount of people we advertise to, as a cost saving measure.\n\nAs we develop the model, we are creating evaluation plots like a lift plot and a calibration plot. We also look at standard evaluation metrics like precision, recall, etc.\n\nI'm tasked with ideating an evaluation procedure for after we complete the model, to get a better sense of its business value. My stakeholders are hesitant (rightfully so) to simply apply the model's insights to their campaigns without a test. \n\nIn the past I've seen people do the following:\n\n* Create a decile plot and get the average response value post campaign. The x-axis here is binned probabilities (i.e. 0-.1, .1-.2, etc.). The expectation here is that as the bin values increase so should the average response value (response is a binary variable so the average would represent the % of folks who responded). This is kinda similar to a calibration plot imo.\n* Take a marketing campaign that's about to go live and random assign people to groups. One group is random selection of campaign members (emulates a control), another is a low probability bin and another is a high probability bin. The two probability bins emulate a treatment, but there isn't a treatment applied.\n\nThe internet talks about lift, cumulative gains plots, etc. I can include those, but I see those as evaluation tools for data scientist and an interpretable plot for stakeholders, but there must be another formal procedure to do this.\n\nI wanted to see how others evaluate model performance for their organization. Experience in marketing campaigns is a plus.", "author_fullname": "t2_a071r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Evaluating an ML model on a live marketing campaign", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12zoh0r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682526106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the process of developing a ML model that will rank individuals based on their likelihood to complete an action. The ultimately goal of this model is to reduce the amount of people we advertise to, as a cost saving measure.&lt;/p&gt;\n\n&lt;p&gt;As we develop the model, we are creating evaluation plots like a lift plot and a calibration plot. We also look at standard evaluation metrics like precision, recall, etc.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m tasked with ideating an evaluation procedure for after we complete the model, to get a better sense of its business value. My stakeholders are hesitant (rightfully so) to simply apply the model&amp;#39;s insights to their campaigns without a test. &lt;/p&gt;\n\n&lt;p&gt;In the past I&amp;#39;ve seen people do the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Create a decile plot and get the average response value post campaign. The x-axis here is binned probabilities (i.e. 0-.1, .1-.2, etc.). The expectation here is that as the bin values increase so should the average response value (response is a binary variable so the average would represent the % of folks who responded). This is kinda similar to a calibration plot imo.&lt;/li&gt;\n&lt;li&gt;Take a marketing campaign that&amp;#39;s about to go live and random assign people to groups. One group is random selection of campaign members (emulates a control), another is a low probability bin and another is a high probability bin. The two probability bins emulate a treatment, but there isn&amp;#39;t a treatment applied.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The internet talks about lift, cumulative gains plots, etc. I can include those, but I see those as evaluation tools for data scientist and an interpretable plot for stakeholders, but there must be another formal procedure to do this.&lt;/p&gt;\n\n&lt;p&gt;I wanted to see how others evaluate model performance for their organization. Experience in marketing campaigns is a plus.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12zoh0r", "is_robot_indexable": true, "report_reasons": null, "author": "IAteQuarters", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12zoh0r/evaluating_an_ml_model_on_a_live_marketing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12zoh0r/evaluating_an_ml_model_on_a_live_marketing/", "subreddit_subscribers": 881673, "created_utc": 1682526106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All,\n\nI have prepared a survey for my master thesis regarding learning on Kaggle. It would be great if you can fill it out! It takes no more than 5 minutes and completly anonymous.\n\nhttps://www.surveyhero.com/c/kaggle\n\nThanks", "author_fullname": "t2_g9krl7fx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Survey for Research", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12zoap1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682525951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I have prepared a survey for my master thesis regarding learning on Kaggle. It would be great if you can fill it out! It takes no more than 5 minutes and completly anonymous.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.surveyhero.com/c/kaggle\"&gt;https://www.surveyhero.com/c/kaggle&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12zoap1", "is_robot_indexable": true, "report_reasons": null, "author": "WranglerInevitable70", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12zoap1/survey_for_research/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12zoap1/survey_for_research/", "subreddit_subscribers": 881673, "created_utc": 1682525951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a personal project that I've shared a couple times before on other subreddits (working title is SoundMap). It's essentially a visual representation of the relationships between musical artists and the various projects they're in. This started as a small fun side thing with friends and grew into an obsession, like many of my other hobbies. However, it's grown to the point where the browser simply can't handle all the data and it's near impossible to work on.\n\n&amp;#x200B;\n\nI started this project in 2016-2017, in an online-based data visualization platform called Kumu - at the time it checked all the boxes for what I wanted to do and let me quickly add connections between elements, add basic color coordination, etc. As I mentioned before, this network of connections has grown to over 10,000 elements and has taken on somewhat of a... life of its own. I am trying to export the data out of here and turn it into something more user-friendly and responsive, but I am running into some roadblocks. Mainly the export options are pretty limited:\n\n1. I can export the entire project as a JSON file, but my knowledge and experience with these isn't great. This seems like the best way to go, but that's where I'm stuck.\n2. I can export the data into an Excel workbook, which includes two sheets: one listing elements, and one listing connections. I can work with this, but I just know by going this route I'm going to be putting in hours of extra work. \n\nAny thoughts or ideas?", "author_fullname": "t2_6a0rat1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone here good with Kumu/JSON files? Help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12zkk9i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682522203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a personal project that I&amp;#39;ve shared a couple times before on other subreddits (working title is SoundMap). It&amp;#39;s essentially a visual representation of the relationships between musical artists and the various projects they&amp;#39;re in. This started as a small fun side thing with friends and grew into an obsession, like many of my other hobbies. However, it&amp;#39;s grown to the point where the browser simply can&amp;#39;t handle all the data and it&amp;#39;s near impossible to work on.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I started this project in 2016-2017, in an online-based data visualization platform called Kumu - at the time it checked all the boxes for what I wanted to do and let me quickly add connections between elements, add basic color coordination, etc. As I mentioned before, this network of connections has grown to over 10,000 elements and has taken on somewhat of a... life of its own. I am trying to export the data out of here and turn it into something more user-friendly and responsive, but I am running into some roadblocks. Mainly the export options are pretty limited:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I can export the entire project as a JSON file, but my knowledge and experience with these isn&amp;#39;t great. This seems like the best way to go, but that&amp;#39;s where I&amp;#39;m stuck.&lt;/li&gt;\n&lt;li&gt;I can export the data into an Excel workbook, which includes two sheets: one listing elements, and one listing connections. I can work with this, but I just know by going this route I&amp;#39;m going to be putting in hours of extra work. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any thoughts or ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12zkk9i", "is_robot_indexable": true, "report_reasons": null, "author": "st_nebula", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12zkk9i/anyone_here_good_with_kumujson_files_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12zkk9i/anyone_here_good_with_kumujson_files_help/", "subreddit_subscribers": 881673, "created_utc": 1682522203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Newbie question, but I really couldn't find answers on google.\n\nI was given a table with \\[Title, Views\\] for storing articles and times being read.\n\nI was asked to rank them into 10 ranks based on views so they can present it to management for easier presentation.\n\nMy boss already told me not to use quantile method, since the method tries to split the groups evenly. I tried k-means cluster on this 1d-data, the clusters honestly looks fine, but my boss is looking for more 'statistical method'.\n\nSo I plotted the histogram and KDE, and observed it looks like a exponential / skewed normal / gamma function.\n\nSo after fitting my data to any one of those distributions, Is it okay / make sense for me to use CDF and get the probability value to rank my items into 10 ranks? (Example. 0.9 - 1.0 = rank 10, 0.8 - 0.9 rank 9)\n\nI looked up exponential / gamma distribution on  wiki, it seems they were made to model different kind of behavior. Also I have doubt using CDF to rank my items as I don't see it being mentioned anywhere.\n\nAny input or directions would be appreciated.", "author_fullname": "t2_9cxk59r4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I use CDF to rank values after fitting them into a distribution?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12zim58", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682517877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Newbie question, but I really couldn&amp;#39;t find answers on google.&lt;/p&gt;\n\n&lt;p&gt;I was given a table with [Title, Views] for storing articles and times being read.&lt;/p&gt;\n\n&lt;p&gt;I was asked to rank them into 10 ranks based on views so they can present it to management for easier presentation.&lt;/p&gt;\n\n&lt;p&gt;My boss already told me not to use quantile method, since the method tries to split the groups evenly. I tried k-means cluster on this 1d-data, the clusters honestly looks fine, but my boss is looking for more &amp;#39;statistical method&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;So I plotted the histogram and KDE, and observed it looks like a exponential / skewed normal / gamma function.&lt;/p&gt;\n\n&lt;p&gt;So after fitting my data to any one of those distributions, Is it okay / make sense for me to use CDF and get the probability value to rank my items into 10 ranks? (Example. 0.9 - 1.0 = rank 10, 0.8 - 0.9 rank 9)&lt;/p&gt;\n\n&lt;p&gt;I looked up exponential / gamma distribution on  wiki, it seems they were made to model different kind of behavior. Also I have doubt using CDF to rank my items as I don&amp;#39;t see it being mentioned anywhere.&lt;/p&gt;\n\n&lt;p&gt;Any input or directions would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12zim58", "is_robot_indexable": true, "report_reasons": null, "author": "MobileOk3170", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12zim58/can_i_use_cdf_to_rank_values_after_fitting_them/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12zim58/can_i_use_cdf_to_rank_values_after_fitting_them/", "subreddit_subscribers": 881673, "created_utc": 1682517877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I had this niche business idea and i was thinking about make a comparison of the usernames following some niche interest accounts worldwide and compare them with the accounts who follow famous people from my country (argentina), even i talked with a friend of mine who know programming and started to invest a little bit of money, but after that i checked that verified usernames have a limitation to see the accounts following him if the account its verified. So im totally disappointed, i have put so much effort in this.", "author_fullname": "t2_il80wn86", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any way to have all the usernames following a IG verified account?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z2fwv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682472525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had this niche business idea and i was thinking about make a comparison of the usernames following some niche interest accounts worldwide and compare them with the accounts who follow famous people from my country (argentina), even i talked with a friend of mine who know programming and started to invest a little bit of money, but after that i checked that verified usernames have a limitation to see the accounts following him if the account its verified. So im totally disappointed, i have put so much effort in this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12z2fwv", "is_robot_indexable": true, "report_reasons": null, "author": "Weak_Sandwich_6384", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12z2fwv/is_there_any_way_to_have_all_the_usernames/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12z2fwv/is_there_any_way_to_have_all_the_usernames/", "subreddit_subscribers": 881673, "created_utc": 1682472525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Getting my PhD soon in DS, specifically knowledge graphs and language models. Is there anyone who can share their transition from a PhD to a product manager?", "author_fullname": "t2_89joir5i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From a PhD in data science/AI to a product manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yyzbg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682463493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Getting my PhD soon in DS, specifically knowledge graphs and language models. Is there anyone who can share their transition from a PhD to a product manager?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12yyzbg", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering-Mistake42", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12yyzbg/from_a_phd_in_data_scienceai_to_a_product_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12yyzbg/from_a_phd_in_data_scienceai_to_a_product_manager/", "subreddit_subscribers": 881673, "created_utc": 1682463493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've built a recipe which includes `step_log` , `step_center` and `step_scale` processing steps that are performed on both IV and DV. This recipe is combined in a worflow with a grid\\_search, 5-fold CV and glmnet model. I'd like to get the MAE for this model on every fold **in original DV units**. Is there a way to accomplish this?\n\nMy understanding of recipes is that for each k-fold the SD and mean are calculated from the training split and applied for scaling. How would i go about accessing these values and inverse\\_transforming my predicted values within fold? Or is there a better way to do this?\n\nOn a more general note, its a little frustrating that there isn't a native `inverse_transform` method for tidymodel scaling steps, but oh well. Or maybe I'm just ignorant to one that does exist!", "author_fullname": "t2_lntkl9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "R Tidymodel inverse_scaling steps and MAE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yr637", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682446219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve built a recipe which includes &lt;code&gt;step_log&lt;/code&gt; , &lt;code&gt;step_center&lt;/code&gt; and &lt;code&gt;step_scale&lt;/code&gt; processing steps that are performed on both IV and DV. This recipe is combined in a worflow with a grid_search, 5-fold CV and glmnet model. I&amp;#39;d like to get the MAE for this model on every fold &lt;strong&gt;in original DV units&lt;/strong&gt;. Is there a way to accomplish this?&lt;/p&gt;\n\n&lt;p&gt;My understanding of recipes is that for each k-fold the SD and mean are calculated from the training split and applied for scaling. How would i go about accessing these values and inverse_transforming my predicted values within fold? Or is there a better way to do this?&lt;/p&gt;\n\n&lt;p&gt;On a more general note, its a little frustrating that there isn&amp;#39;t a native &lt;code&gt;inverse_transform&lt;/code&gt; method for tidymodel scaling steps, but oh well. Or maybe I&amp;#39;m just ignorant to one that does exist!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12yr637", "is_robot_indexable": true, "report_reasons": null, "author": "ParlyWhites", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12yr637/r_tidymodel_inverse_scaling_steps_and_mae/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12yr637/r_tidymodel_inverse_scaling_steps_and_mae/", "subreddit_subscribers": 881673, "created_utc": 1682446219.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}