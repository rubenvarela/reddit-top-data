{"kind": "Listing", "data": {"after": "t3_12yy0tq", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, my organization has been using O365 with the power platform for a minute now. We've got some real MVPs on our team who are treating SharePoint like a database for their power apps (\"front-end\") and power bi reports with power automate work around. But, here's the kicker - the company doesn't want to invest in a proper database like SQL server or full Datavers. \n\nPersonally, I think this is a recipe for disaster. I mean, SharePoint is great and all, but using it as a \"database\" just doesn't seem sustainable. What are your thoughts? Should we continue to use SharePoint or should we explore other options? Let me know in the comments below.", "author_fullname": "t2_8bvav827h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hey guys, so I work for an organization and we're thinking about using SharePoint as a \"database.\" Do you guys have any tips or recommendations on how to make this work? We're kind of new to SharePoint so any advice would be greatly appreciated! Thanks in advance.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yw1ul", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682456731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, my organization has been using O365 with the power platform for a minute now. We&amp;#39;ve got some real MVPs on our team who are treating SharePoint like a database for their power apps (&amp;quot;front-end&amp;quot;) and power bi reports with power automate work around. But, here&amp;#39;s the kicker - the company doesn&amp;#39;t want to invest in a proper database like SQL server or full Datavers. &lt;/p&gt;\n\n&lt;p&gt;Personally, I think this is a recipe for disaster. I mean, SharePoint is great and all, but using it as a &amp;quot;database&amp;quot; just doesn&amp;#39;t seem sustainable. What are your thoughts? Should we continue to use SharePoint or should we explore other options? Let me know in the comments below.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yw1ul", "is_robot_indexable": true, "report_reasons": null, "author": "CassiusBlackwood", "discussion_type": null, "num_comments": 80, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yw1ul/hey_guys_so_i_work_for_an_organization_and_were/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yw1ul/hey_guys_so_i_work_for_an_organization_and_were/", "subreddit_subscribers": 102654, "created_utc": 1682456731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Essentially title. Is it left up to the data architects? Principal/staff engineers?", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who sets the pipeline/warehouse strategy and roadmap in your organization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z1s36", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682470743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Essentially title. Is it left up to the data architects? Principal/staff engineers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12z1s36", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12z1s36/who_sets_the_pipelinewarehouse_strategy_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12z1s36/who_sets_the_pipelinewarehouse_strategy_and/", "subreddit_subscribers": 102654, "created_utc": 1682470743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're looking at stuff like Synapse/trino/presto for the engine but for now we're just loading raw json + converting to parquet.\n\nIt's time series data so it partitions nicely along an hourly cadence. This creates files that are about 100Mb. We are about to expand by quite a lot (acquisition) so we think this will ~5x soon enough. \n\nFrom those raw json (500Mb) files we can convert to parquet for the query layer but unsure of how big we ought to go here. We can leave as is and rely on parquets/compression efficiency or compact several hours into a single file. \n\nDon't have a lot of know-how for this so we appreciate any tips. Also, we know a simple set up with a DB might do for this volume of data but the chosen paradigm for the company is data lake + query engine, and our department is just the first to build it out. Thanks.", "author_fullname": "t2_ut20i32q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How big are your data lake raw files? Parquet files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yknp3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682432040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re looking at stuff like Synapse/trino/presto for the engine but for now we&amp;#39;re just loading raw json + converting to parquet.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s time series data so it partitions nicely along an hourly cadence. This creates files that are about 100Mb. We are about to expand by quite a lot (acquisition) so we think this will ~5x soon enough. &lt;/p&gt;\n\n&lt;p&gt;From those raw json (500Mb) files we can convert to parquet for the query layer but unsure of how big we ought to go here. We can leave as is and rely on parquets/compression efficiency or compact several hours into a single file. &lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t have a lot of know-how for this so we appreciate any tips. Also, we know a simple set up with a DB might do for this volume of data but the chosen paradigm for the company is data lake + query engine, and our department is just the first to build it out. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yknp3", "is_robot_indexable": true, "report_reasons": null, "author": "alex_o_h", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yknp3/how_big_are_your_data_lake_raw_files_parquet_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yknp3/how_big_are_your_data_lake_raw_files_parquet_files/", "subreddit_subscribers": 102654, "created_utc": 1682432040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9v8cn0yzu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PSA: Learn Vendor Agnostic Technologies!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_12zhvtk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lqr4PfL8LjDhaihBKoDMu1ZaMztPOpeumQsrGReasNY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682516342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/bdjqa87ue8wa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/bdjqa87ue8wa1.png?auto=webp&amp;v=enabled&amp;s=ff5b8a5cef6602a33220fb057c9d62360a8021b4", "width": 978, "height": 1302}, "resolutions": [{"url": "https://preview.redd.it/bdjqa87ue8wa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2cd80b7e0905d4a76359afba109b7dd0d660cb3f", "width": 108, "height": 143}, {"url": "https://preview.redd.it/bdjqa87ue8wa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb945495b099eead8965755b5c0597297ba48675", "width": 216, "height": 287}, {"url": "https://preview.redd.it/bdjqa87ue8wa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c54dd00ee87da2cb99afe6c74d0ec2c7f1ff70af", "width": 320, "height": 426}, {"url": "https://preview.redd.it/bdjqa87ue8wa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bac0d1ba5f0f6b5f0e881aa3c2af6bb0c5883e8a", "width": 640, "height": 852}, {"url": "https://preview.redd.it/bdjqa87ue8wa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d02565ff969943cc6a17a7e46f5eef620fa89706", "width": 960, "height": 1278}], "variants": {}, "id": "Xiff3duE8muyQSlxKxBCka9qSyXJfKYwhy3LN1-LgDc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "12zhvtk", "is_robot_indexable": true, "report_reasons": null, "author": "smashmaps", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zhvtk/psa_learn_vendor_agnostic_technologies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/bdjqa87ue8wa1.png", "subreddit_subscribers": 102654, "created_utc": 1682516342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "From PLC/sensor level  all the way up to reporting and visuals, what tools do you guys use?\n\nMy company uses the following:\n\n* Kepware\n* SQL\n* Power BI\n\nThat's it. Nothing else. I'm being tasked with helping on all kinds of Industry 4.0 initiatives but it seems like everything is already hitting its cap and we've barely gotten started.\n\nKepware VM is at max capacity which should hopefully be as easy as migrating to a more powerful VM. SQL gateways for Power BI, Power Apps, Flows, etc. seems to be failing. No one can give me a root cause and I don't have access myself. Power BI refreshes get slower and slower by the day.\n\nLuckily, I think we will be getting OSI PI soon which should do wonders. \n\nHas anyone else experienced this and if so what did your manufacturing stack look like. How did it eventually improve....please tell me it eventually improved.", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone work in the Industry 4.0 space? More specifically in manufacturing? What does your data stack look like?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yw3x2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682456852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From PLC/sensor level  all the way up to reporting and visuals, what tools do you guys use?&lt;/p&gt;\n\n&lt;p&gt;My company uses the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Kepware&lt;/li&gt;\n&lt;li&gt;SQL&lt;/li&gt;\n&lt;li&gt;Power BI&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;That&amp;#39;s it. Nothing else. I&amp;#39;m being tasked with helping on all kinds of Industry 4.0 initiatives but it seems like everything is already hitting its cap and we&amp;#39;ve barely gotten started.&lt;/p&gt;\n\n&lt;p&gt;Kepware VM is at max capacity which should hopefully be as easy as migrating to a more powerful VM. SQL gateways for Power BI, Power Apps, Flows, etc. seems to be failing. No one can give me a root cause and I don&amp;#39;t have access myself. Power BI refreshes get slower and slower by the day.&lt;/p&gt;\n\n&lt;p&gt;Luckily, I think we will be getting OSI PI soon which should do wonders. &lt;/p&gt;\n\n&lt;p&gt;Has anyone else experienced this and if so what did your manufacturing stack look like. How did it eventually improve....please tell me it eventually improved.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yw3x2", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yw3x2/anyone_work_in_the_industry_40_space_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yw3x2/anyone_work_in_the_industry_40_space_more/", "subreddit_subscribers": 102654, "created_utc": 1682456852.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are thinking of adopting snowpipe to ingest data from Kafka to Snowflake (currently using Fivetran). Would be happy for some homes reviews.", "author_fullname": "t2_19dlf55q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are you using Snowpipe? What\u2019s its pros and cons?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ytogu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682451730.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are thinking of adopting snowpipe to ingest data from Kafka to Snowflake (currently using Fivetran). Would be happy for some homes reviews.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ytogu", "is_robot_indexable": true, "report_reasons": null, "author": "themo_legrange", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ytogu/are_you_using_snowpipe_whats_its_pros_and_cons/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ytogu/are_you_using_snowpipe_whats_its_pros_and_cons/", "subreddit_subscribers": 102654, "created_utc": 1682451730.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What skills would you consider soft skills as a DE?\nThere are some obvious ones like;\n- Communication\n- Stakeholder management\n- Writing (mails, documentation, guidelines)\n- Listening to client requests\n- Peer reviews \n\nBut what about some less obvious, would you consider them to be closer to soft skills or hard skills ones like;\n- Making a proper code review (so that others can review easier)\n- Giving proper code review feedback\n- Improving productivity\n\nOr would you say there is an extra list of skills between soft and hard skills?\n\nWhat are your struggles with these types of skills?", "author_fullname": "t2_1jkhpl2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Soft skills aimed at DE's", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yw8c8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682457116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What skills would you consider soft skills as a DE?\nThere are some obvious ones like;\n- Communication\n- Stakeholder management\n- Writing (mails, documentation, guidelines)\n- Listening to client requests\n- Peer reviews &lt;/p&gt;\n\n&lt;p&gt;But what about some less obvious, would you consider them to be closer to soft skills or hard skills ones like;\n- Making a proper code review (so that others can review easier)\n- Giving proper code review feedback\n- Improving productivity&lt;/p&gt;\n\n&lt;p&gt;Or would you say there is an extra list of skills between soft and hard skills?&lt;/p&gt;\n\n&lt;p&gt;What are your struggles with these types of skills?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yw8c8", "is_robot_indexable": true, "report_reasons": null, "author": "Luxi36", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yw8c8/soft_skills_aimed_at_des/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yw8c8/soft_skills_aimed_at_des/", "subreddit_subscribers": 102654, "created_utc": 1682457116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have all seen the layoff announcements from various MDS vendors.  This week, I found out my main customer success contact at one vendor is no longer there.   I know vendors lurk here on reddit.  Can anybody share the inside scoop and what we should anticipate next?  What's the vibe?", "author_fullname": "t2_7yk2o6hxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Inside scoop from Data Engineering vendors?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z7jn7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682486823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have all seen the layoff announcements from various MDS vendors.  This week, I found out my main customer success contact at one vendor is no longer there.   I know vendors lurk here on reddit.  Can anybody share the inside scoop and what we should anticipate next?  What&amp;#39;s the vibe?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12z7jn7", "is_robot_indexable": true, "report_reasons": null, "author": "grahamdietz", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12z7jn7/inside_scoop_from_data_engineering_vendors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12z7jn7/inside_scoop_from_data_engineering_vendors/", "subreddit_subscribers": 102654, "created_utc": 1682486823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Question:\n\nWhen you\u2019re building the databricks architecture utilizing the medallion model,\nWhere are your bronze, silver, gold tier delta files sitting?\n\nCurrently we have bronze tier data in AZDL Gen 2 , loading those files into a databricks DF, doing transformations, then creating delta files into a silver layer in AZDL gen 2.  \n\nWould it make more sense to not have the delta files in AZDL but in the databricks file system? \n\nOR would it make sense to load the silver files into the databricks file system then copy them into the AZDL. \n\nDatabricks is relatively new to me but we are starting to shift away from synapse", "author_fullname": "t2_uf4ne7uq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yw8co", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682457116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Question:&lt;/p&gt;\n\n&lt;p&gt;When you\u2019re building the databricks architecture utilizing the medallion model,\nWhere are your bronze, silver, gold tier delta files sitting?&lt;/p&gt;\n\n&lt;p&gt;Currently we have bronze tier data in AZDL Gen 2 , loading those files into a databricks DF, doing transformations, then creating delta files into a silver layer in AZDL gen 2.  &lt;/p&gt;\n\n&lt;p&gt;Would it make more sense to not have the delta files in AZDL but in the databricks file system? &lt;/p&gt;\n\n&lt;p&gt;OR would it make sense to load the silver files into the databricks file system then copy them into the AZDL. &lt;/p&gt;\n\n&lt;p&gt;Databricks is relatively new to me but we are starting to shift away from synapse&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yw8co", "is_robot_indexable": true, "report_reasons": null, "author": "NipsAhoy2", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yw8co/databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yw8co/databricks/", "subreddit_subscribers": 102654, "created_utc": 1682457116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nI'm the sole 'data' person at a small company where my role spans a bucket load of titles, I know there are many in a similar position out there... As such any chance I can get to offload any work/mental capacity to a managed/streamlined platform I'm usually all for it.\n\nThe company has a bunch of legacy/niche industry software that require custom pipelines to be put together. Now I'm sure something like airflow would fill the shoes and there some, but I just can't justify the management nor the costs of a managed service for this.\n\nSurely there has to be something between, like scheduled lambdas with monitoring/alerting/validation rolled in?\n\nI've so far in my spare time cobbled together a series of scripts and a rudimentary frontend to streamline and achieve the above, but was hoping for something pre-existing I could drop in...\n\n\nReally to sum it up, my wishlist is basically bring code, aka serverless function style but have the monitoring ease of something like airflow or prefect.\n\nThanks for any comments or thoughts", "author_fullname": "t2_kjuqv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What exists on the spectrum between a cron job and airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12zfj4u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682510943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m the sole &amp;#39;data&amp;#39; person at a small company where my role spans a bucket load of titles, I know there are many in a similar position out there... As such any chance I can get to offload any work/mental capacity to a managed/streamlined platform I&amp;#39;m usually all for it.&lt;/p&gt;\n\n&lt;p&gt;The company has a bunch of legacy/niche industry software that require custom pipelines to be put together. Now I&amp;#39;m sure something like airflow would fill the shoes and there some, but I just can&amp;#39;t justify the management nor the costs of a managed service for this.&lt;/p&gt;\n\n&lt;p&gt;Surely there has to be something between, like scheduled lambdas with monitoring/alerting/validation rolled in?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve so far in my spare time cobbled together a series of scripts and a rudimentary frontend to streamline and achieve the above, but was hoping for something pre-existing I could drop in...&lt;/p&gt;\n\n&lt;p&gt;Really to sum it up, my wishlist is basically bring code, aka serverless function style but have the monitoring ease of something like airflow or prefect.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any comments or thoughts&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12zfj4u", "is_robot_indexable": true, "report_reasons": null, "author": "kmsherrin", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zfj4u/what_exists_on_the_spectrum_between_a_cron_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12zfj4u/what_exists_on_the_spectrum_between_a_cron_job/", "subreddit_subscribers": 102654, "created_utc": 1682510943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone,\n\nIn one of my projects I\u2019m using python to connect to a SFTP server and use SSH keys to authenticate myself. All of a sudden the client SFTP server started showing errors and wasn\u2019t accepting SSH Keys. \u201cPAM Authentication\u201d shows up. \n\nThe SFTP is managed by another vendor and they identified that this is due to their SSH being backdated. While they\u2019re fixing that, they gave me password for PAM Authentication. I can log in using CLI. \n\nI just don\u2019t understand how to use this password with python/paramiko. I feel this password is definitely different than the username and password combo for the server. \n\nIs there anyone who wrote some python scripts for connection using PAM password?\n\nThanks!", "author_fullname": "t2_dv4ply58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Ingestion from SFTP Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yxwtg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682460874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;In one of my projects I\u2019m using python to connect to a SFTP server and use SSH keys to authenticate myself. All of a sudden the client SFTP server started showing errors and wasn\u2019t accepting SSH Keys. \u201cPAM Authentication\u201d shows up. &lt;/p&gt;\n\n&lt;p&gt;The SFTP is managed by another vendor and they identified that this is due to their SSH being backdated. While they\u2019re fixing that, they gave me password for PAM Authentication. I can log in using CLI. &lt;/p&gt;\n\n&lt;p&gt;I just don\u2019t understand how to use this password with python/paramiko. I feel this password is definitely different than the username and password combo for the server. &lt;/p&gt;\n\n&lt;p&gt;Is there anyone who wrote some python scripts for connection using PAM password?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yxwtg", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous_Apple_420", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yxwtg/data_ingestion_from_sftp_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yxwtg/data_ingestion_from_sftp_server/", "subreddit_subscribers": 102654, "created_utc": 1682460874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a company that has used sql server as the majority. We have made the move to cloud in the recent years and also have onboarded a data library with Starburst which is backed by Trino. I recently learned about DBT and thought it was an amazing tool to allow for documentation and more clarity on where our data is coming from with the built in DAG. However, every time i introduced it to an analyst or engineer they are all clutching onto their tsql and stored procedures. I know change is difficult but has anyone else made this transition at their company and how did you win them over?", "author_fullname": "t2_eww42", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to convince analysts/de to use DBT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12zh3pv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682514641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a company that has used sql server as the majority. We have made the move to cloud in the recent years and also have onboarded a data library with Starburst which is backed by Trino. I recently learned about DBT and thought it was an amazing tool to allow for documentation and more clarity on where our data is coming from with the built in DAG. However, every time i introduced it to an analyst or engineer they are all clutching onto their tsql and stored procedures. I know change is difficult but has anyone else made this transition at their company and how did you win them over?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12zh3pv", "is_robot_indexable": true, "report_reasons": null, "author": "Annaphasia", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zh3pv/how_to_convince_analystsde_to_use_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12zh3pv/how_to_convince_analystsde_to_use_dbt/", "subreddit_subscribers": 102654, "created_utc": 1682514641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The latest [Thoughtworks Tech Radar](https://www.thoughtworks.com/radar) is out. Some highlights in the data space:\n\n## \ud83d\udfe2 Adopt\n\n* [DVC](HTTPs://dvc.org)\n\n## \ud83d\udc4d\ud83c\udffb Trial\n\n* [Apache Hudi](https://hudi.apache.org/)\n* [DuckDB](https://duckdb.org/)\n* [Soda Core](https://www.soda.io/core)\n* [dbt-unit-testing](https://github.com/EqualExperts/dbt-unit-testing)\n* [Lakehouse Architecture](https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf)\n\n## \ud83d\udc40 Assess\n\n* [Neon](https://neon.tech/)\n* [dbt-expectations](https://github.com/calogica/dbt-expectations/tree/0.8.2/)\n\n## \ud83d\udfe0 Hold\n\n* [Denodo](https://www.denodo.com/en)\n\n---\n\nDid anything else catch your eye from the radar? Any thoughts on the assessments of the above tools? \n\nFor me, it was seeing Denodo listed. I've not used it, but it's fairly unusual for tools &amp; platforms to move to Hold (often the entries, or 'blips' as they're called, just don't get listed next time), so seems they had a pretty bad time with Denodo, even saying: \n\n&gt; we recommend that you do not use Denodo as a primary data transformation tool and use tools like Spark or SQL (with dbt) for your data transformations instead.", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data-eng related highlights from the latest Thoughtworks Tech Radar", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ze7uy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682507544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The latest &lt;a href=\"https://www.thoughtworks.com/radar\"&gt;Thoughtworks Tech Radar&lt;/a&gt; is out. Some highlights in the data space:&lt;/p&gt;\n\n&lt;h2&gt;\ud83d\udfe2 Adopt&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"HTTPs://dvc.org\"&gt;DVC&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;\ud83d\udc4d\ud83c\udffb Trial&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://hudi.apache.org/\"&gt;Apache Hudi&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://duckdb.org/\"&gt;DuckDB&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.soda.io/core\"&gt;Soda Core&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/EqualExperts/dbt-unit-testing\"&gt;dbt-unit-testing&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf\"&gt;Lakehouse Architecture&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;\ud83d\udc40 Assess&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://neon.tech/\"&gt;Neon&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/calogica/dbt-expectations/tree/0.8.2/\"&gt;dbt-expectations&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;\ud83d\udfe0 Hold&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.denodo.com/en\"&gt;Denodo&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Did anything else catch your eye from the radar? Any thoughts on the assessments of the above tools? &lt;/p&gt;\n\n&lt;p&gt;For me, it was seeing Denodo listed. I&amp;#39;ve not used it, but it&amp;#39;s fairly unusual for tools &amp;amp; platforms to move to Hold (often the entries, or &amp;#39;blips&amp;#39; as they&amp;#39;re called, just don&amp;#39;t get listed next time), so seems they had a pretty bad time with Denodo, even saying: &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;we recommend that you do not use Denodo as a primary data transformation tool and use tools like Spark or SQL (with dbt) for your data transformations instead.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?auto=webp&amp;v=enabled&amp;s=811182d29905a1e1e9403c451cf55bb6e8f6f368", "width": 1600, "height": 837}, "resolutions": [{"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64ff67d5c54e2223029ebe80e5afbea47bedd2d7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f125b62c2d28fe65a11ab525349a719a7a9e0d06", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=492e504d582234f81d47fd498965c4311a0947ad", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54ad7c054ee7bdf6bb0dea7fad5a7821a18da98e", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1b9965c5698e7f4220c164dcfe0fa5ea058a274", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=689783f11d2d3dfda79b30353949a6c5d0c30306", "width": 1080, "height": 564}], "variants": {}, "id": "qKpvdmTr2prhwnfo9Lt4Bu8EUjs0RuFpA_BAZYOqGlQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ze7uy", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ze7uy/dataeng_related_highlights_from_the_latest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ze7uy/dataeng_related_highlights_from_the_latest/", "subreddit_subscribers": 102654, "created_utc": 1682507544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently in a position where I do a lot of the data modeling for report purposes. It's at a new company for me but in an industry I know well so I'm pretty familiar with the data I'm working with. My experience is mostly in analytics though with only the last year or so being more engineer focused so I'm still learning a lot.  \n\n\nI feel like I spend an inordinate amount of time just trying to unravel all our data models so that I can trace something from source system through to business report. I do this because we have a lot of data integrity questions that come up and to help me better understand the process. We have layers and layers of built in logic even for the most straightforward measures. \n\nI think what I'm seeing, on top of the data integrity concerns, as well as consistent integration breakdowns, speaks to a poorly designed warehouse but I don't feel like I have enough, except my experience, to go off of. I know it's not like anything I've dealt with in my past though. What questions do I need to be asking, or what else can I be looking at to help me better understand where our issues are? Any ideas or thoughts that can help point me in the right direction are appreciated!", "author_fullname": "t2_2q171de9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm spending a lot of time unraveling data models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yt7e4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682450727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in a position where I do a lot of the data modeling for report purposes. It&amp;#39;s at a new company for me but in an industry I know well so I&amp;#39;m pretty familiar with the data I&amp;#39;m working with. My experience is mostly in analytics though with only the last year or so being more engineer focused so I&amp;#39;m still learning a lot.  &lt;/p&gt;\n\n&lt;p&gt;I feel like I spend an inordinate amount of time just trying to unravel all our data models so that I can trace something from source system through to business report. I do this because we have a lot of data integrity questions that come up and to help me better understand the process. We have layers and layers of built in logic even for the most straightforward measures. &lt;/p&gt;\n\n&lt;p&gt;I think what I&amp;#39;m seeing, on top of the data integrity concerns, as well as consistent integration breakdowns, speaks to a poorly designed warehouse but I don&amp;#39;t feel like I have enough, except my experience, to go off of. I know it&amp;#39;s not like anything I&amp;#39;ve dealt with in my past though. What questions do I need to be asking, or what else can I be looking at to help me better understand where our issues are? Any ideas or thoughts that can help point me in the right direction are appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12yt7e4", "is_robot_indexable": true, "report_reasons": null, "author": "lahma_mama", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yt7e4/im_spending_a_lot_of_time_unraveling_data_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yt7e4/im_spending_a_lot_of_time_unraveling_data_models/", "subreddit_subscribers": 102654, "created_utc": 1682450727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI don\u2019t *think* this is possible, and have asked on the dbt Slack but got no response so wanted to check here.\n\ndbt can connect to Databricks and can connect to DuckDB.\n\nDuckDB can connect to DeltaLake (via Arrow).\n\nIs it possible to leverage dbt for my transformation pipelines with my data stored in S3 using delta-rs in Python, with DuckDB as my compute engine?\n\nIf anyone has done it, is there a guide I can follow, or some basic pointers to get up and running?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt with Delta Lake &amp; DuckDB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12zf0bu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682509635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t &lt;em&gt;think&lt;/em&gt; this is possible, and have asked on the dbt Slack but got no response so wanted to check here.&lt;/p&gt;\n\n&lt;p&gt;dbt can connect to Databricks and can connect to DuckDB.&lt;/p&gt;\n\n&lt;p&gt;DuckDB can connect to DeltaLake (via Arrow).&lt;/p&gt;\n\n&lt;p&gt;Is it possible to leverage dbt for my transformation pipelines with my data stored in S3 using delta-rs in Python, with DuckDB as my compute engine?&lt;/p&gt;\n\n&lt;p&gt;If anyone has done it, is there a guide I can follow, or some basic pointers to get up and running?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12zf0bu", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zf0bu/dbt_with_delta_lake_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12zf0bu/dbt_with_delta_lake_duckdb/", "subreddit_subscribers": 102654, "created_utc": 1682509635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got offered to take a second job by a colleague and I'll be doing it on my own free time. However the job is more of a BI role (doing analysis and data visualization). I also have access to tons of learning materials in my current company and may take some certifications when I want. \n\nSo basically I am torn on what to do between the two on my free time. Looking for advice from wiser people here. Thank you.\n\nTake second job = more money\n\nPrioritize learning = more DE knowledge", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Take a second job or study more", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z7u43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682487727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got offered to take a second job by a colleague and I&amp;#39;ll be doing it on my own free time. However the job is more of a BI role (doing analysis and data visualization). I also have access to tons of learning materials in my current company and may take some certifications when I want. &lt;/p&gt;\n\n&lt;p&gt;So basically I am torn on what to do between the two on my free time. Looking for advice from wiser people here. Thank you.&lt;/p&gt;\n\n&lt;p&gt;Take second job = more money&lt;/p&gt;\n\n&lt;p&gt;Prioritize learning = more DE knowledge&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12z7u43", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12z7u43/take_a_second_job_or_study_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12z7u43/take_a_second_job_or_study_more/", "subreddit_subscribers": 102654, "created_utc": 1682487727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I was tasked to build a CICD pipeline for Synapse. I want to be able to deploy from Dev to different environment. I found the Sqlpackage, where it extract the schema of a workspace and publish it to a destination workspace. I'm not sure but I think it is not the right approach since it is not parametrizable and throwing error when deploying external views. So far it worked only with tables.\nAny idea how can I build it? Thank you in advance", "author_fullname": "t2_pp0zirow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD for Synapse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ysvyg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682450021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I was tasked to build a CICD pipeline for Synapse. I want to be able to deploy from Dev to different environment. I found the Sqlpackage, where it extract the schema of a workspace and publish it to a destination workspace. I&amp;#39;m not sure but I think it is not the right approach since it is not parametrizable and throwing error when deploying external views. So far it worked only with tables.\nAny idea how can I build it? Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ysvyg", "is_robot_indexable": true, "report_reasons": null, "author": "These_Rip_9327", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ysvyg/cicd_for_synapse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ysvyg/cicd_for_synapse/", "subreddit_subscribers": 102654, "created_utc": 1682450021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3yleu7rp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Business Value of Metadata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_12you5a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/EHES8eKB3vtBgsdAesjBcGWniy51TpSivgMmve21LL8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682441175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/alvin-ai/the-business-value-of-metadata-efa46f78a6da", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?auto=webp&amp;v=enabled&amp;s=52a7f0a1a29f6fcbed6044190f4419d8c7db6ea9", "width": 1200, "height": 692}, "resolutions": [{"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1fae95481cfa84bed915d1d20480d4fb030c472", "width": 108, "height": 62}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=50b80bbe9a84be94b24656c94868a1bd76babac1", "width": 216, "height": 124}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02375c4beeb71f2bc69588ec37b949cf2937ea4e", "width": 320, "height": 184}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=355acf7fd8c020eee63b5a36e58fc66588eb49b4", "width": 640, "height": 369}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=884a6f268b31cb73bf1f290b1da30f8d16c416e5", "width": 960, "height": 553}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d1f8f55607a0a4e8a56baf818ded87cc76159e5", "width": 1080, "height": 622}], "variants": {}, "id": "Mhev0XFTT0iV1DglMqIEg298usdpo1bM03JWxEvDc9A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12you5a", "is_robot_indexable": true, "report_reasons": null, "author": "gabsferreiradev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12you5a/the_business_value_of_metadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/alvin-ai/the-business-value-of-metadata-efa46f78a6da", "subreddit_subscribers": 102654, "created_utc": 1682441175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, \nI have started a new role recently where I am at a large legacy manufacturing company that is trying to get into analytics (lol). I was hired to do data engineering but it seems like most of what i will be doing to start off is working on getting their data policies in order. They have been using SAP for 30 years and are trying to modernize somewhat.  Currently at their plants they have analytics on site that are running based on production data and from my view those are all fine. However in their administration building is where they need a shitload of work. Basically they have always had web devs or SAP devs and never really had anyone in admin who was a DBA or trained in that regard. From just my first month i have a few things that I know need to change and was wondering if anyone had advice.\n\n1. Every project was made as its own database. Is there a way to quickly go back and put all of these projects into one database but under different schemas? To put it in perspective one of their sql servers has 55 databases.\n\n2. How do you get people to buy into data governance as a policy when it really hasnt been enforced before? Right now everyone has access to everything and its kind of a wild west. \n\n3. They currently have a few people who are very good at getting data out of SAP BW for queries. However this creates problems because the data analytics people arent really SAP trained and the data gets lost in translation over time, not to mention the bottleneck of always having to ask one of the couple people who understand SAP BW. Does anyone have experience in creating an analytics database in a third party program off of an SAP ERP system? There is really no getting rid of SAP in any capacity when its been used this long.", "author_fullname": "t2_6ra3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for new role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yl02m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682432808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, \nI have started a new role recently where I am at a large legacy manufacturing company that is trying to get into analytics (lol). I was hired to do data engineering but it seems like most of what i will be doing to start off is working on getting their data policies in order. They have been using SAP for 30 years and are trying to modernize somewhat.  Currently at their plants they have analytics on site that are running based on production data and from my view those are all fine. However in their administration building is where they need a shitload of work. Basically they have always had web devs or SAP devs and never really had anyone in admin who was a DBA or trained in that regard. From just my first month i have a few things that I know need to change and was wondering if anyone had advice.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Every project was made as its own database. Is there a way to quickly go back and put all of these projects into one database but under different schemas? To put it in perspective one of their sql servers has 55 databases.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do you get people to buy into data governance as a policy when it really hasnt been enforced before? Right now everyone has access to everything and its kind of a wild west. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;They currently have a few people who are very good at getting data out of SAP BW for queries. However this creates problems because the data analytics people arent really SAP trained and the data gets lost in translation over time, not to mention the bottleneck of always having to ask one of the couple people who understand SAP BW. Does anyone have experience in creating an analytics database in a third party program off of an SAP ERP system? There is really no getting rid of SAP in any capacity when its been used this long.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yl02m", "is_robot_indexable": true, "report_reasons": null, "author": "deemerritt", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yl02m/advice_for_new_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yl02m/advice_for_new_role/", "subreddit_subscribers": 102654, "created_utc": 1682432808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi DEs of Reddit,\n\nI\u2019m about to start a new project which requires me to download daily a large file from a public website (~30Gb) and land this file into AWS S3. I\u2019m trying to brainstorm the most efficient solution and I was wondering if anybody had an experience downloading large files like this? \n\nAnything in particular I should be aware of/consider ? \n\nThank you!", "author_fullname": "t2_a3m6qw38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading large files from public websites - Brainstorm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ze0m5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682507000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi DEs of Reddit,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m about to start a new project which requires me to download daily a large file from a public website (~30Gb) and land this file into AWS S3. I\u2019m trying to brainstorm the most efficient solution and I was wondering if anybody had an experience downloading large files like this? &lt;/p&gt;\n\n&lt;p&gt;Anything in particular I should be aware of/consider ? &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ze0m5", "is_robot_indexable": true, "report_reasons": null, "author": "sk808mafia", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ze0m5/downloading_large_files_from_public_websites/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ze0m5/downloading_large_files_from_public_websites/", "subreddit_subscribers": 102654, "created_utc": 1682507000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got assigned to a new project which uses AWS stack and noticed that they are only using Glue to call stored procedures or run queries in external database. From what I know, Glue is just spark on the backend so by not using spark they are not using Glue to its full capabilities. So my question is, is this an acceptable way of using Glue?", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue not fully utilized?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yrhwz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682446925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got assigned to a new project which uses AWS stack and noticed that they are only using Glue to call stored procedures or run queries in external database. From what I know, Glue is just spark on the backend so by not using spark they are not using Glue to its full capabilities. So my question is, is this an acceptable way of using Glue?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12yrhwz", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yrhwz/aws_glue_not_fully_utilized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yrhwz/aws_glue_not_fully_utilized/", "subreddit_subscribers": 102654, "created_utc": 1682446925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to share the Terraform tutorial **(Infrastructure As Code for Cloud)**, cheat sheet, and usage scenarios that I created as a notebook for myself. This repo covers Terraform with **(How-To) HANDS-On LABs and AWS SAMPLEs** (comprehensive, but simple):\n\n* Resources, Data Sources, Variables, Meta Arguments, Provisioners, Dynamic Blocks, Modules, Workspaces, Templates, Remote State.\n* Provisioning AWS Components (EC2, Lambda, ECS, EKS, API Gateway, ELB, CodePipeline, CodeBuild, etc.), use cases, and details. Possible usage scenarios are aimed to update over time.\n\n**Tutorial Link:** [**https://github.com/omerbsezer/Fast-Terraform**](https://github.com/omerbsezer/Fast-Terraform)\n\n**Extra Kubernetes-Tutorial Link:** [**https://github.com/omerbsezer/Fast-Kubernetes**](https://github.com/omerbsezer/Fast-Kubernetes)\n\n**Quick Look (How-To): Terraform Hands-on LABs**\n\nThese LABs focus on Terraform features, and help to learn Terraform:\n\n* [LAB-00: Installing Terraform, AWS Configuration with Terraform](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB00-Terraform-Install-AWS-Configuration.md)\n* [LAB-01: Terraform Docker =&gt; Pull Docker Image, Create Docker Container on Local Machine](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB01-Terraform-Docker-Without-Cloud.md)\n* [LAB-02: Resources =&gt; Provision Basic EC2 (Ubuntu 22.04)](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB02-Resources-Basic-EC2.md)\n* [LAB-03: Variables, Locals, Output =&gt; Provision EC2s](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB03-Variables-Locals-Output-EC2.md)\n* [LAB-04: Meta Arguments (Count, For\\_Each, Map) =&gt; Provision IAM Users, Groups, Policies, Attachment Policy-User](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB04-Meta-Arguments-IAM-User-Group-Policy.md)\n* [LAB-05: Dynamic Blocks =&gt; Provision Security Groups, EC2, VPC](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB05-Dynamic-Blocks-Security-Groups-EC2.md)\n* [LAB-06: Data Sources with Depends\\_on =&gt; Provision EC2](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB06-Data-Sources-EC2.md)\n* [LAB-07: Provisioners (file, remote-exec), Null Resources (local-exec) =&gt; Provision Key-Pair, SSH Connection](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB07-Provisioners-Null-Resources.md)\n* [LAB-08: Modules =&gt; Provision EC2](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB08-Modules-EC2.md)\n* [LAB-09: Workspaces =&gt; Provision EC2 with Different tfvars Files](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB09-Workspaces-EC2.md)\n* [LAB-10: Templates =&gt; Provision IAM User, User Access Key, Policy](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB10-Templates-User-Policy.md)\n* [LAB-11: Backend - Remote States =&gt; Provision EC2 and Save State File on S3](https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB11-Backend-Remote-State.md)\n* [Terraform Cheatsheet](https://github.com/omerbsezer/Fast-Terraform/blob/main/Terraform-Cheatsheet.md)\n\n**Quick Look (How-To): AWS Terraform Hands-on Samples**\n\nThese samples focus on how to create and use AWS components (EC2, EBS, EFS, IAM Roles, IAM Policies, Key-Pairs, VPC with Network Components, Lambda, ECR, ECS with Fargate, EKS with Managed Nodes, ASG, ELB, API Gateway, S3, CloudFront, CodeCommit, CodePipeline, CodeBuild, CodeDeploy) with Terraform:\n\n* [SAMPLE-01: Provisioning EC2s (Windows 2019 Server, Ubuntu 20.04) on VPC (Subnet), Creating Key-Pair, Connecting Ubuntu using SSH, and Connecting Windows Using RDP](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE01-EC2-VPC-Ubuntu-Win-SSH-RDP.md)\n* [SAMPLE-02: Provisioning Lambda Function, API Gateway and Reaching HTML Page in Python Code From Browser](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE02-Lambda-API-Gateway-Python.md)\n* [SAMPLE-03: EBS (Elastic Block Storage: HDD, SDD) and EFS (Elastic File System: NFS) Configuration with EC2s (Ubuntu and Windows Instances)](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE03-EC2-EBS-EFS.md)\n* [SAMPLE-04: Provisioning ECR (Elastic Container Repository), Pushing Image to ECR, Provisioning ECS (Elastic Container Service), VPC (Virtual Private Cloud), ELB (Elastic Load Balancer), ECS Tasks and Service on Fargate Cluster](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE04-ECR-ECS-ELB-VPC-ECS-Service.md)\n* [SAMPLE-05: Provisioning ECR, Lambda Function and API Gateway to run Flask App Container on Lambda](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE05-Lambda-Container-ApiGateway-FlaskApp.md)\n* [SAMPLE-06: Provisioning EKS (Elastic Kubernetes Service) with Managed Nodes using Blueprint and Modules](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE06-EKS-ManagedNodes-Blueprint.md)\n* [SAMPLE-07: CI/CD on AWS =&gt; Provisioning CodeCommit and CodePipeline, Triggering CodeBuild and CodeDeploy, Running on Lambda Container](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE07-CodeCommit-Pipeline-Build-Deploy-Lambda.md)\n* [SAMPLE-08: Provisioning S3 and CloudFront to serve Static Web Site](https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE08-S3-CloudFront-Static-WebSite.md)\n\n**Table of Contents**\n\n* [Motivation](https://github.com/omerbsezer/Fast-Terraform#motivation)\n* [What is Terraform?](https://github.com/omerbsezer/Fast-Terraform#what_is_terraform)\n* [How Terraform Works?](https://github.com/omerbsezer/Fast-Terraform#how_terrafom_works)\n* [Terraform File Components](https://github.com/omerbsezer/Fast-Terraform#terrafom_file_components)\n   * [Providers](https://github.com/omerbsezer/Fast-Terraform#providers)\n   * [Resources](https://github.com/omerbsezer/Fast-Terraform#resources)\n   * [Variables (tfvar)](https://github.com/omerbsezer/Fast-Terraform#variables)\n   * [Values (Locals, Outputs)](https://github.com/omerbsezer/Fast-Terraform#values)\n   * [Meta Arguments](https://github.com/omerbsezer/Fast-Terraform#meta_arguments)\n   * [Dynamic Blocks](https://github.com/omerbsezer/Fast-Terraform#dynamic_blocks)\n   * [Data Sources](https://github.com/omerbsezer/Fast-Terraform#datasources)\n   * [Provisioners (file, remote\\_exec, local\\_exec), Null Resource](https://github.com/omerbsezer/Fast-Terraform#provisioners)\n   * [Modules](https://github.com/omerbsezer/Fast-Terraform#modules)\n   * [Workspaces](https://github.com/omerbsezer/Fast-Terraform#workspaces)\n   * [Templates](https://github.com/omerbsezer/Fast-Terraform#templates)\n   * [Backends and Remote States](https://github.com/omerbsezer/Fast-Terraform#backends_remote_states)\n* [Terraform Best Practices](https://github.com/omerbsezer/Fast-Terraform#best_practice)\n* [AWS Terraform Hands-on Samples](https://github.com/omerbsezer/Fast-Terraform#samples)\n   * [SAMPLE-01: EC2s (Windows 2019 Server, Ubuntu 20.04), VPC, Key-Pairs for SSH, RDP connections](https://github.com/omerbsezer/Fast-Terraform#ec2_vpc_key_pair_ssh_rdp)\n   * [SAMPLE-02: Provisioning Lambda Function, API Gateway and Reaching HTML Page in Python Code From Browsers](https://github.com/omerbsezer/Fast-Terraform#lambda_apigateway_python)\n   * [SAMPLE-03: EBS (Elastic Block Storage: HDD, SDD) and EFS (Elastic File System: NFS) Configuration with EC2s (Ubuntu and Windows Instances)](https://github.com/omerbsezer/Fast-Terraform#ebs_efs_ec2)\n   * [SAMPLE-04: Provisioning ECR (Elastic Container Repository), Pushing Image to ECR, Provisioning ECS (Elastic Container Service), VPC (Virtual Private Cloud), ELB (Elastic Load Balancer), ECS Tasks and Service on Fargate Cluster](https://github.com/omerbsezer/Fast-Terraform#ecr_ecs_elb_vpc_ecs_service_fargate)\n   * [SAMPLE-05: Provisioning ECR, Lambda Function and API Gateway to run Flask App Container on Lambda](https://github.com/omerbsezer/Fast-Terraform#ecr_lambda_apigateway_container)\n   * [SAMPLE-06: Provisioning EKS (Elastic Kubernetes Service) with Managed Nodes using Blueprint and Modules](https://github.com/omerbsezer/Fast-Terraform#eks_managednodes_blueprint)\n   * [SAMPLE-07: CI/CD on AWS =&gt; Provisioning CodeCommit and CodePipeline, Triggering CodeBuild and CodeDeploy, Running on Lambda Container](https://github.com/omerbsezer/Fast-Terraform#ci_cd)\n   * [SAMPLE-08: Provisioning S3 and CloudFront to serve Static Web Site](https://github.com/omerbsezer/Fast-Terraform#s3_cloudfront)\n* [Details](https://github.com/omerbsezer/Fast-Terraform#details)\n* [Terraform Cheatsheet](https://github.com/omerbsezer/Fast-Terraform#cheatsheet)\n* [Other Useful Resources Related Terraform](https://github.com/omerbsezer/Fast-Terraform#resource)\n* [References](https://github.com/omerbsezer/Fast-Terraform#references)", "author_fullname": "t2_muiope", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fast-Terraform: Terraform Tutorial, How-To: Hands-on LABs, and AWS Hands-on Sample Usage Scenarios (Infrastructure As Code)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12zfwq0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682511860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to share the Terraform tutorial &lt;strong&gt;(Infrastructure As Code for Cloud)&lt;/strong&gt;, cheat sheet, and usage scenarios that I created as a notebook for myself. This repo covers Terraform with &lt;strong&gt;(How-To) HANDS-On LABs and AWS SAMPLEs&lt;/strong&gt; (comprehensive, but simple):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Resources, Data Sources, Variables, Meta Arguments, Provisioners, Dynamic Blocks, Modules, Workspaces, Templates, Remote State.&lt;/li&gt;\n&lt;li&gt;Provisioning AWS Components (EC2, Lambda, ECS, EKS, API Gateway, ELB, CodePipeline, CodeBuild, etc.), use cases, and details. Possible usage scenarios are aimed to update over time.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Tutorial Link:&lt;/strong&gt; &lt;a href=\"https://github.com/omerbsezer/Fast-Terraform\"&gt;&lt;strong&gt;https://github.com/omerbsezer/Fast-Terraform&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Extra Kubernetes-Tutorial Link:&lt;/strong&gt; &lt;a href=\"https://github.com/omerbsezer/Fast-Kubernetes\"&gt;&lt;strong&gt;https://github.com/omerbsezer/Fast-Kubernetes&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Quick Look (How-To): Terraform Hands-on LABs&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;These LABs focus on Terraform features, and help to learn Terraform:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB00-Terraform-Install-AWS-Configuration.md\"&gt;LAB-00: Installing Terraform, AWS Configuration with Terraform&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB01-Terraform-Docker-Without-Cloud.md\"&gt;LAB-01: Terraform Docker =&amp;gt; Pull Docker Image, Create Docker Container on Local Machine&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB02-Resources-Basic-EC2.md\"&gt;LAB-02: Resources =&amp;gt; Provision Basic EC2 (Ubuntu 22.04)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB03-Variables-Locals-Output-EC2.md\"&gt;LAB-03: Variables, Locals, Output =&amp;gt; Provision EC2s&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB04-Meta-Arguments-IAM-User-Group-Policy.md\"&gt;LAB-04: Meta Arguments (Count, For_Each, Map) =&amp;gt; Provision IAM Users, Groups, Policies, Attachment Policy-User&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB05-Dynamic-Blocks-Security-Groups-EC2.md\"&gt;LAB-05: Dynamic Blocks =&amp;gt; Provision Security Groups, EC2, VPC&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB06-Data-Sources-EC2.md\"&gt;LAB-06: Data Sources with Depends_on =&amp;gt; Provision EC2&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB07-Provisioners-Null-Resources.md\"&gt;LAB-07: Provisioners (file, remote-exec), Null Resources (local-exec) =&amp;gt; Provision Key-Pair, SSH Connection&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB08-Modules-EC2.md\"&gt;LAB-08: Modules =&amp;gt; Provision EC2&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB09-Workspaces-EC2.md\"&gt;LAB-09: Workspaces =&amp;gt; Provision EC2 with Different tfvars Files&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB10-Templates-User-Policy.md\"&gt;LAB-10: Templates =&amp;gt; Provision IAM User, User Access Key, Policy&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/LAB11-Backend-Remote-State.md\"&gt;LAB-11: Backend - Remote States =&amp;gt; Provision EC2 and Save State File on S3&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/Terraform-Cheatsheet.md\"&gt;Terraform Cheatsheet&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Quick Look (How-To): AWS Terraform Hands-on Samples&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;These samples focus on how to create and use AWS components (EC2, EBS, EFS, IAM Roles, IAM Policies, Key-Pairs, VPC with Network Components, Lambda, ECR, ECS with Fargate, EKS with Managed Nodes, ASG, ELB, API Gateway, S3, CloudFront, CodeCommit, CodePipeline, CodeBuild, CodeDeploy) with Terraform:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE01-EC2-VPC-Ubuntu-Win-SSH-RDP.md\"&gt;SAMPLE-01: Provisioning EC2s (Windows 2019 Server, Ubuntu 20.04) on VPC (Subnet), Creating Key-Pair, Connecting Ubuntu using SSH, and Connecting Windows Using RDP&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE02-Lambda-API-Gateway-Python.md\"&gt;SAMPLE-02: Provisioning Lambda Function, API Gateway and Reaching HTML Page in Python Code From Browser&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE03-EC2-EBS-EFS.md\"&gt;SAMPLE-03: EBS (Elastic Block Storage: HDD, SDD) and EFS (Elastic File System: NFS) Configuration with EC2s (Ubuntu and Windows Instances)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE04-ECR-ECS-ELB-VPC-ECS-Service.md\"&gt;SAMPLE-04: Provisioning ECR (Elastic Container Repository), Pushing Image to ECR, Provisioning ECS (Elastic Container Service), VPC (Virtual Private Cloud), ELB (Elastic Load Balancer), ECS Tasks and Service on Fargate Cluster&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE05-Lambda-Container-ApiGateway-FlaskApp.md\"&gt;SAMPLE-05: Provisioning ECR, Lambda Function and API Gateway to run Flask App Container on Lambda&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE06-EKS-ManagedNodes-Blueprint.md\"&gt;SAMPLE-06: Provisioning EKS (Elastic Kubernetes Service) with Managed Nodes using Blueprint and Modules&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE07-CodeCommit-Pipeline-Build-Deploy-Lambda.md\"&gt;SAMPLE-07: CI/CD on AWS =&amp;gt; Provisioning CodeCommit and CodePipeline, Triggering CodeBuild and CodeDeploy, Running on Lambda Container&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform/blob/main/SAMPLE08-S3-CloudFront-Static-WebSite.md\"&gt;SAMPLE-08: Provisioning S3 and CloudFront to serve Static Web Site&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#motivation\"&gt;Motivation&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#what_is_terraform\"&gt;What is Terraform?&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#how_terrafom_works\"&gt;How Terraform Works?&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#terrafom_file_components\"&gt;Terraform File Components&lt;/a&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#providers\"&gt;Providers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#resources\"&gt;Resources&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#variables\"&gt;Variables (tfvar)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#values\"&gt;Values (Locals, Outputs)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#meta_arguments\"&gt;Meta Arguments&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#dynamic_blocks\"&gt;Dynamic Blocks&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#datasources\"&gt;Data Sources&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#provisioners\"&gt;Provisioners (file, remote_exec, local_exec), Null Resource&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#modules\"&gt;Modules&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#workspaces\"&gt;Workspaces&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#templates\"&gt;Templates&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#backends_remote_states\"&gt;Backends and Remote States&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#best_practice\"&gt;Terraform Best Practices&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#samples\"&gt;AWS Terraform Hands-on Samples&lt;/a&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#ec2_vpc_key_pair_ssh_rdp\"&gt;SAMPLE-01: EC2s (Windows 2019 Server, Ubuntu 20.04), VPC, Key-Pairs for SSH, RDP connections&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#lambda_apigateway_python\"&gt;SAMPLE-02: Provisioning Lambda Function, API Gateway and Reaching HTML Page in Python Code From Browsers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#ebs_efs_ec2\"&gt;SAMPLE-03: EBS (Elastic Block Storage: HDD, SDD) and EFS (Elastic File System: NFS) Configuration with EC2s (Ubuntu and Windows Instances)&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#ecr_ecs_elb_vpc_ecs_service_fargate\"&gt;SAMPLE-04: Provisioning ECR (Elastic Container Repository), Pushing Image to ECR, Provisioning ECS (Elastic Container Service), VPC (Virtual Private Cloud), ELB (Elastic Load Balancer), ECS Tasks and Service on Fargate Cluster&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#ecr_lambda_apigateway_container\"&gt;SAMPLE-05: Provisioning ECR, Lambda Function and API Gateway to run Flask App Container on Lambda&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#eks_managednodes_blueprint\"&gt;SAMPLE-06: Provisioning EKS (Elastic Kubernetes Service) with Managed Nodes using Blueprint and Modules&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#ci_cd\"&gt;SAMPLE-07: CI/CD on AWS =&amp;gt; Provisioning CodeCommit and CodePipeline, Triggering CodeBuild and CodeDeploy, Running on Lambda Container&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#s3_cloudfront\"&gt;SAMPLE-08: Provisioning S3 and CloudFront to serve Static Web Site&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#details\"&gt;Details&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#cheatsheet\"&gt;Terraform Cheatsheet&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#resource\"&gt;Other Useful Resources Related Terraform&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/omerbsezer/Fast-Terraform#references\"&gt;References&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?auto=webp&amp;v=enabled&amp;s=aff26802866c8cce610984e0b23824759b5e96d9", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=155564a5e52eb1b21bd0c1f37bada689f46741a1", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e786a876c9e7662b513d04d0ccf664e8f6da45d8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f4ddd263c3406b748c18985efa7fab7a9c4f154", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=978ae3396e5dabfe24da9c5417a8c7809e727957", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76ff4eaee9dee400851b777417f062428646a90c", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/AOccRH0R74eV4U6EfVBZFJoiCZGuxwPgLgjDZQgUiyo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea5a448c788a5c53455f942fc541d7f026aba6d9", "width": 1080, "height": 540}], "variants": {}, "id": "_glqqYG7gBRy19Ov4gqUzroMtXxsOzvirCtVjW58RnI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "12zfwq0", "is_robot_indexable": true, "report_reasons": null, "author": "obsezer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zfwq0/fastterraform_terraform_tutorial_howto_handson/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12zfwq0/fastterraform_terraform_tutorial_howto_handson/", "subreddit_subscribers": 102654, "created_utc": 1682511860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is working on modernizing our stack, but we still rely on a great number of legacy systems and processes. I'm in the initial stages of putting together a POC for an orchestrater to manage the mess of DBMS and ETL platforms we've accumulated, and everything I've read about Dagster sounds great. Unfortunately, it doesn't seem to natively support Oracle/SQL Server, or some of our other legacy systems. \n\nI know that with Airflow, you can write your own hooks and operarors to interface with APIs or use existing python packages or bash commands. Is this sort of thing possible with dagster as well? I haven't seen anything talking about that kind of customization. The docs give a broad overview of how to write code for assets, but I'm still not clear on whether I could create an asset class to access Oracle using SQLAlchemy, for example. \n\nI see a lot of examples that interface with airbyte and dbt, which I think could be used as Middleware for this purpose, but I'd prefer to keep things as simple and self-contained as possible.\n\nAny thoughts or experience would be greatly appreciated.", "author_fullname": "t2_3boovm3w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Custom assets in dagster?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12zdezw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682505307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is working on modernizing our stack, but we still rely on a great number of legacy systems and processes. I&amp;#39;m in the initial stages of putting together a POC for an orchestrater to manage the mess of DBMS and ETL platforms we&amp;#39;ve accumulated, and everything I&amp;#39;ve read about Dagster sounds great. Unfortunately, it doesn&amp;#39;t seem to natively support Oracle/SQL Server, or some of our other legacy systems. &lt;/p&gt;\n\n&lt;p&gt;I know that with Airflow, you can write your own hooks and operarors to interface with APIs or use existing python packages or bash commands. Is this sort of thing possible with dagster as well? I haven&amp;#39;t seen anything talking about that kind of customization. The docs give a broad overview of how to write code for assets, but I&amp;#39;m still not clear on whether I could create an asset class to access Oracle using SQLAlchemy, for example. &lt;/p&gt;\n\n&lt;p&gt;I see a lot of examples that interface with airbyte and dbt, which I think could be used as Middleware for this purpose, but I&amp;#39;d prefer to keep things as simple and self-contained as possible.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts or experience would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12zdezw", "is_robot_indexable": true, "report_reasons": null, "author": "myrstica", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zdezw/custom_assets_in_dagster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12zdezw/custom_assets_in_dagster/", "subreddit_subscribers": 102654, "created_utc": 1682505307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a biotech company that's embarking on a new effort to build a decentralized data mesh with an associated data catalog. Previously, my team was responsible for data engineering at one of our sites, and we'll continue to support building out data engineering projects for all scientists at the site, but now integrating with the data mesh.\n\nI know that the big benefit of a data mesh architecture is that a company is able to decentralize your data architecture and give each group the power to own their own data infrastructure, shared centrally; I see the benefit here. *However*, none of the groups my team supports are very technical, and in practice, my team will build out and maintain all infrastructure. Since we have one group (my team) responsible for building and maintaining infrastructure relating to multiple groups, I *feel* as though it makes more sense to centralize the data infrastructure my team is working on and simply separate data from different groups logically (i.e. S3 keys/Redshift schemas).\n\nBut I'm definitely looking for opinions here. What do you think would work best?", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it ever a good idea to centralize a data lake/warehouse in a data mesh architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12zbybz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682500900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a biotech company that&amp;#39;s embarking on a new effort to build a decentralized data mesh with an associated data catalog. Previously, my team was responsible for data engineering at one of our sites, and we&amp;#39;ll continue to support building out data engineering projects for all scientists at the site, but now integrating with the data mesh.&lt;/p&gt;\n\n&lt;p&gt;I know that the big benefit of a data mesh architecture is that a company is able to decentralize your data architecture and give each group the power to own their own data infrastructure, shared centrally; I see the benefit here. &lt;em&gt;However&lt;/em&gt;, none of the groups my team supports are very technical, and in practice, my team will build out and maintain all infrastructure. Since we have one group (my team) responsible for building and maintaining infrastructure relating to multiple groups, I &lt;em&gt;feel&lt;/em&gt; as though it makes more sense to centralize the data infrastructure my team is working on and simply separate data from different groups logically (i.e. S3 keys/Redshift schemas).&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m definitely looking for opinions here. What do you think would work best?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12zbybz", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zbybz/is_it_ever_a_good_idea_to_centralize_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12zbybz/is_it_ever_a_good_idea_to_centralize_a_data/", "subreddit_subscribers": 102654, "created_utc": 1682500900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all!\n\nI'm new to iceberg but a pretty decent DE.  Right now my company is paying a fortune for a splunk implementation and I'm thinking I can replace it pretty quickly and just do a cost per query in Athena with proper partitioning and bucketing.\n\nHowever since the logs are currently just simple zipped json files, I am going to be doing some large transformations to get everything in an optimized fashion and want to 'measure twice cut once' so to speak.\n\nI know the perks of Avro and Iceberg are schema evolution, but I honestly can't see that happening at most once every couple of years so I'm not seeing a benefit. My naivete with Iceberg makes me think the main power of that would be for the time travel, but again, logs are immutable so not much of a perk.\n\nIf I do proper partitioning, will parquet take me to where I want it or should I be looking at something more modern?\n\nThanks!", "author_fullname": "t2_bu6ed", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iceberg on Cloudtrail Logs with Athena", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yy0tq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682461148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m new to iceberg but a pretty decent DE.  Right now my company is paying a fortune for a splunk implementation and I&amp;#39;m thinking I can replace it pretty quickly and just do a cost per query in Athena with proper partitioning and bucketing.&lt;/p&gt;\n\n&lt;p&gt;However since the logs are currently just simple zipped json files, I am going to be doing some large transformations to get everything in an optimized fashion and want to &amp;#39;measure twice cut once&amp;#39; so to speak.&lt;/p&gt;\n\n&lt;p&gt;I know the perks of Avro and Iceberg are schema evolution, but I honestly can&amp;#39;t see that happening at most once every couple of years so I&amp;#39;m not seeing a benefit. My naivete with Iceberg makes me think the main power of that would be for the time travel, but again, logs are immutable so not much of a perk.&lt;/p&gt;\n\n&lt;p&gt;If I do proper partitioning, will parquet take me to where I want it or should I be looking at something more modern?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yy0tq", "is_robot_indexable": true, "report_reasons": null, "author": "pankswork", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yy0tq/iceberg_on_cloudtrail_logs_with_athena/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yy0tq/iceberg_on_cloudtrail_logs_with_athena/", "subreddit_subscribers": 102654, "created_utc": 1682461148.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}