{"kind": "Listing", "data": {"after": "t3_12zbybz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently work with a colleague who I swear to fucking god has the worst practices ever.  The stuff they do should be considered war crimes (in the data world, of course).\n\nThe person in question has never done CI/CD before and has been copying and pasting blocks of code into the next environment when they want to \"promote\" a change.  Naturally, this has left environments being massively out of sync.  \n\nSince then, we've implemented CI/CD to move database meta data and schemas between environments.  It's consistent, it works, it's better than copying and pasting.  The person in question, however, always rejects the idea of CI/CD with the following talking point:\n\nThem: \"We can't guarantee consistency between environments\"\n\nMe: \"We can because that's sorted through CI/CD\"\n\nThem: \"Yeah, but when I want to make emergency changes to production, it won't align\"\n\nMe: \"But why are we making changes in production directly? They'll get erased next time we release because they don't exist in the previous environments.  For us to be consistent, we have to be in the mindset of working through environments\"\n\nThem: \"I don't want to have to go through every single environment to make a single change\"\n\nThey will then continue to argue forever.  For some strange reason, this happens a lot and I feel like I'm going insane because I feel like it shouldn't be up for debate.  I feel like the person I'm arguing with wants to patch everything, I want to do everything correctly.  They want to apply ad hoc fixes as and when they feel like it, I want to be consistent so when something breaks we can test it at a lower level before releasing it. \n\nI'm 100% ready to be wrong.  Do people regularly makes production only changes?  Am I misunderstanding the whole point of CI/CD? How do you guys facilitate emergency changes with CI/CD?\n\nThank you.", "author_fullname": "t2_anttcncw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should production changes be handled? Rant/debate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yj6uv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682428694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work with a colleague who I swear to fucking god has the worst practices ever.  The stuff they do should be considered war crimes (in the data world, of course).&lt;/p&gt;\n\n&lt;p&gt;The person in question has never done CI/CD before and has been copying and pasting blocks of code into the next environment when they want to &amp;quot;promote&amp;quot; a change.  Naturally, this has left environments being massively out of sync.  &lt;/p&gt;\n\n&lt;p&gt;Since then, we&amp;#39;ve implemented CI/CD to move database meta data and schemas between environments.  It&amp;#39;s consistent, it works, it&amp;#39;s better than copying and pasting.  The person in question, however, always rejects the idea of CI/CD with the following talking point:&lt;/p&gt;\n\n&lt;p&gt;Them: &amp;quot;We can&amp;#39;t guarantee consistency between environments&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Me: &amp;quot;We can because that&amp;#39;s sorted through CI/CD&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Them: &amp;quot;Yeah, but when I want to make emergency changes to production, it won&amp;#39;t align&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Me: &amp;quot;But why are we making changes in production directly? They&amp;#39;ll get erased next time we release because they don&amp;#39;t exist in the previous environments.  For us to be consistent, we have to be in the mindset of working through environments&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Them: &amp;quot;I don&amp;#39;t want to have to go through every single environment to make a single change&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;They will then continue to argue forever.  For some strange reason, this happens a lot and I feel like I&amp;#39;m going insane because I feel like it shouldn&amp;#39;t be up for debate.  I feel like the person I&amp;#39;m arguing with wants to patch everything, I want to do everything correctly.  They want to apply ad hoc fixes as and when they feel like it, I want to be consistent so when something breaks we can test it at a lower level before releasing it. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m 100% ready to be wrong.  Do people regularly makes production only changes?  Am I misunderstanding the whole point of CI/CD? How do you guys facilitate emergency changes with CI/CD?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yj6uv", "is_robot_indexable": true, "report_reasons": null, "author": "average_ukpf_user", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yj6uv/how_should_production_changes_be_handled/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yj6uv/how_should_production_changes_be_handled/", "subreddit_subscribers": 102631, "created_utc": 1682428694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, my organization has been using O365 with the power platform for a minute now. We've got some real MVPs on our team who are treating SharePoint like a database for their power apps (\"front-end\") and power bi reports with power automate work around. But, here's the kicker - the company doesn't want to invest in a proper database like SQL server or full Datavers. \n\nPersonally, I think this is a recipe for disaster. I mean, SharePoint is great and all, but using it as a \"database\" just doesn't seem sustainable. What are your thoughts? Should we continue to use SharePoint or should we explore other options? Let me know in the comments below.", "author_fullname": "t2_8bvav827h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hey guys, so I work for an organization and we're thinking about using SharePoint as a \"database.\" Do you guys have any tips or recommendations on how to make this work? We're kind of new to SharePoint so any advice would be greatly appreciated! Thanks in advance.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yw1ul", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682456731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, my organization has been using O365 with the power platform for a minute now. We&amp;#39;ve got some real MVPs on our team who are treating SharePoint like a database for their power apps (&amp;quot;front-end&amp;quot;) and power bi reports with power automate work around. But, here&amp;#39;s the kicker - the company doesn&amp;#39;t want to invest in a proper database like SQL server or full Datavers. &lt;/p&gt;\n\n&lt;p&gt;Personally, I think this is a recipe for disaster. I mean, SharePoint is great and all, but using it as a &amp;quot;database&amp;quot; just doesn&amp;#39;t seem sustainable. What are your thoughts? Should we continue to use SharePoint or should we explore other options? Let me know in the comments below.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yw1ul", "is_robot_indexable": true, "report_reasons": null, "author": "CassiusBlackwood", "discussion_type": null, "num_comments": 75, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yw1ul/hey_guys_so_i_work_for_an_organization_and_were/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yw1ul/hey_guys_so_i_work_for_an_organization_and_were/", "subreddit_subscribers": 102631, "created_utc": 1682456731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're looking at stuff like Synapse/trino/presto for the engine but for now we're just loading raw json + converting to parquet.\n\nIt's time series data so it partitions nicely along an hourly cadence. This creates files that are about 100Mb. We are about to expand by quite a lot (acquisition) so we think this will ~5x soon enough. \n\nFrom those raw json (500Mb) files we can convert to parquet for the query layer but unsure of how big we ought to go here. We can leave as is and rely on parquets/compression efficiency or compact several hours into a single file. \n\nDon't have a lot of know-how for this so we appreciate any tips. Also, we know a simple set up with a DB might do for this volume of data but the chosen paradigm for the company is data lake + query engine, and our department is just the first to build it out. Thanks.", "author_fullname": "t2_ut20i32q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How big are your data lake raw files? Parquet files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yknp3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682432040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re looking at stuff like Synapse/trino/presto for the engine but for now we&amp;#39;re just loading raw json + converting to parquet.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s time series data so it partitions nicely along an hourly cadence. This creates files that are about 100Mb. We are about to expand by quite a lot (acquisition) so we think this will ~5x soon enough. &lt;/p&gt;\n\n&lt;p&gt;From those raw json (500Mb) files we can convert to parquet for the query layer but unsure of how big we ought to go here. We can leave as is and rely on parquets/compression efficiency or compact several hours into a single file. &lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t have a lot of know-how for this so we appreciate any tips. Also, we know a simple set up with a DB might do for this volume of data but the chosen paradigm for the company is data lake + query engine, and our department is just the first to build it out. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yknp3", "is_robot_indexable": true, "report_reasons": null, "author": "alex_o_h", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yknp3/how_big_are_your_data_lake_raw_files_parquet_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yknp3/how_big_are_your_data_lake_raw_files_parquet_files/", "subreddit_subscribers": 102631, "created_utc": 1682432040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Essentially title. Is it left up to the data architects? Principal/staff engineers?", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who sets the pipeline/warehouse strategy and roadmap in your organization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z1s36", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682470743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Essentially title. Is it left up to the data architects? Principal/staff engineers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12z1s36", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12z1s36/who_sets_the_pipelinewarehouse_strategy_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12z1s36/who_sets_the_pipelinewarehouse_strategy_and/", "subreddit_subscribers": 102631, "created_utc": 1682470743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "From PLC/sensor level  all the way up to reporting and visuals, what tools do you guys use?\n\nMy company uses the following:\n\n* Kepware\n* SQL\n* Power BI\n\nThat's it. Nothing else. I'm being tasked with helping on all kinds of Industry 4.0 initiatives but it seems like everything is already hitting its cap and we've barely gotten started.\n\nKepware VM is at max capacity which should hopefully be as easy as migrating to a more powerful VM. SQL gateways for Power BI, Power Apps, Flows, etc. seems to be failing. No one can give me a root cause and I don't have access myself. Power BI refreshes get slower and slower by the day.\n\nLuckily, I think we will be getting OSI PI soon which should do wonders. \n\nHas anyone else experienced this and if so what did your manufacturing stack look like. How did it eventually improve....please tell me it eventually improved.", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone work in the Industry 4.0 space? More specifically in manufacturing? What does your data stack look like?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yw3x2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682456852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From PLC/sensor level  all the way up to reporting and visuals, what tools do you guys use?&lt;/p&gt;\n\n&lt;p&gt;My company uses the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Kepware&lt;/li&gt;\n&lt;li&gt;SQL&lt;/li&gt;\n&lt;li&gt;Power BI&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;That&amp;#39;s it. Nothing else. I&amp;#39;m being tasked with helping on all kinds of Industry 4.0 initiatives but it seems like everything is already hitting its cap and we&amp;#39;ve barely gotten started.&lt;/p&gt;\n\n&lt;p&gt;Kepware VM is at max capacity which should hopefully be as easy as migrating to a more powerful VM. SQL gateways for Power BI, Power Apps, Flows, etc. seems to be failing. No one can give me a root cause and I don&amp;#39;t have access myself. Power BI refreshes get slower and slower by the day.&lt;/p&gt;\n\n&lt;p&gt;Luckily, I think we will be getting OSI PI soon which should do wonders. &lt;/p&gt;\n\n&lt;p&gt;Has anyone else experienced this and if so what did your manufacturing stack look like. How did it eventually improve....please tell me it eventually improved.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yw3x2", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yw3x2/anyone_work_in_the_industry_40_space_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yw3x2/anyone_work_in_the_industry_40_space_more/", "subreddit_subscribers": 102631, "created_utc": 1682456852.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What skills would you consider soft skills as a DE?\nThere are some obvious ones like;\n- Communication\n- Stakeholder management\n- Writing (mails, documentation, guidelines)\n- Listening to client requests\n- Peer reviews \n\nBut what about some less obvious, would you consider them to be closer to soft skills or hard skills ones like;\n- Making a proper code review (so that others can review easier)\n- Giving proper code review feedback\n- Improving productivity\n\nOr would you say there is an extra list of skills between soft and hard skills?\n\nWhat are your struggles with these types of skills?", "author_fullname": "t2_1jkhpl2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Soft skills aimed at DE's", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yw8c8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682457116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What skills would you consider soft skills as a DE?\nThere are some obvious ones like;\n- Communication\n- Stakeholder management\n- Writing (mails, documentation, guidelines)\n- Listening to client requests\n- Peer reviews &lt;/p&gt;\n\n&lt;p&gt;But what about some less obvious, would you consider them to be closer to soft skills or hard skills ones like;\n- Making a proper code review (so that others can review easier)\n- Giving proper code review feedback\n- Improving productivity&lt;/p&gt;\n\n&lt;p&gt;Or would you say there is an extra list of skills between soft and hard skills?&lt;/p&gt;\n\n&lt;p&gt;What are your struggles with these types of skills?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yw8c8", "is_robot_indexable": true, "report_reasons": null, "author": "Luxi36", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yw8c8/soft_skills_aimed_at_des/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yw8c8/soft_skills_aimed_at_des/", "subreddit_subscribers": 102631, "created_utc": 1682457116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are thinking of adopting snowpipe to ingest data from Kafka to Snowflake (currently using Fivetran). Would be happy for some homes reviews.", "author_fullname": "t2_19dlf55q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are you using Snowpipe? What\u2019s its pros and cons?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ytogu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682451730.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are thinking of adopting snowpipe to ingest data from Kafka to Snowflake (currently using Fivetran). Would be happy for some homes reviews.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ytogu", "is_robot_indexable": true, "report_reasons": null, "author": "themo_legrange", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ytogu/are_you_using_snowpipe_whats_its_pros_and_cons/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ytogu/are_you_using_snowpipe_whats_its_pros_and_cons/", "subreddit_subscribers": 102631, "created_utc": 1682451730.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have all seen the layoff announcements from various MDS vendors.  This week, I found out my main customer success contact at one vendor is no longer there.   I know vendors lurk here on reddit.  Can anybody share the inside scoop and what we should anticipate next?  What's the vibe?", "author_fullname": "t2_7yk2o6hxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Inside scoop from Data Engineering vendors?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z7jn7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682486823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have all seen the layoff announcements from various MDS vendors.  This week, I found out my main customer success contact at one vendor is no longer there.   I know vendors lurk here on reddit.  Can anybody share the inside scoop and what we should anticipate next?  What&amp;#39;s the vibe?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12z7jn7", "is_robot_indexable": true, "report_reasons": null, "author": "grahamdietz", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12z7jn7/inside_scoop_from_data_engineering_vendors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12z7jn7/inside_scoop_from_data_engineering_vendors/", "subreddit_subscribers": 102631, "created_utc": 1682486823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Question:\n\nWhen you\u2019re building the databricks architecture utilizing the medallion model,\nWhere are your bronze, silver, gold tier delta files sitting?\n\nCurrently we have bronze tier data in AZDL Gen 2 , loading those files into a databricks DF, doing transformations, then creating delta files into a silver layer in AZDL gen 2.  \n\nWould it make more sense to not have the delta files in AZDL but in the databricks file system? \n\nOR would it make sense to load the silver files into the databricks file system then copy them into the AZDL. \n\nDatabricks is relatively new to me but we are starting to shift away from synapse", "author_fullname": "t2_uf4ne7uq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yw8co", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682457116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Question:&lt;/p&gt;\n\n&lt;p&gt;When you\u2019re building the databricks architecture utilizing the medallion model,\nWhere are your bronze, silver, gold tier delta files sitting?&lt;/p&gt;\n\n&lt;p&gt;Currently we have bronze tier data in AZDL Gen 2 , loading those files into a databricks DF, doing transformations, then creating delta files into a silver layer in AZDL gen 2.  &lt;/p&gt;\n\n&lt;p&gt;Would it make more sense to not have the delta files in AZDL but in the databricks file system? &lt;/p&gt;\n\n&lt;p&gt;OR would it make sense to load the silver files into the databricks file system then copy them into the AZDL. &lt;/p&gt;\n\n&lt;p&gt;Databricks is relatively new to me but we are starting to shift away from synapse&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yw8co", "is_robot_indexable": true, "report_reasons": null, "author": "NipsAhoy2", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yw8co/databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yw8co/databricks/", "subreddit_subscribers": 102631, "created_utc": 1682457116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently interviewed for a role and the hiring manager mentioned there would be system-design interview questions. I have traditionally been more of an analytically focused DE (close to an analytics engineer role) and have little experience with system design questions. Does anyone have advice on where I should start for interview prep? Is going through Grokking the System Design Interview enough? Does anyone have any experience ramping up on this topic within 3 weeks? For context, I am still early in my career, so this would likely be a junior-level role since I have less than 3 YOE.", "author_fullname": "t2_6wqif47u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Prep Advice - System Design - Where to start?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yk9r6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682431175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently interviewed for a role and the hiring manager mentioned there would be system-design interview questions. I have traditionally been more of an analytically focused DE (close to an analytics engineer role) and have little experience with system design questions. Does anyone have advice on where I should start for interview prep? Is going through Grokking the System Design Interview enough? Does anyone have any experience ramping up on this topic within 3 weeks? For context, I am still early in my career, so this would likely be a junior-level role since I have less than 3 YOE.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12yk9r6", "is_robot_indexable": true, "report_reasons": null, "author": "tagavor_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yk9r6/interview_prep_advice_system_design_where_to_start/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yk9r6/interview_prep_advice_system_design_where_to_start/", "subreddit_subscribers": 102631, "created_utc": 1682431175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am learning Aws glue but it's very expensive, so  I need a way that I can test it on local first.", "author_fullname": "t2_8szkmsobv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Can I test AWS glue jobs on local?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z8375", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682488509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am learning Aws glue but it&amp;#39;s very expensive, so  I need a way that I can test it on local first.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12z8375", "is_robot_indexable": true, "report_reasons": null, "author": "neutronajs", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12z8375/how_can_i_test_aws_glue_jobs_on_local/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12z8375/how_can_i_test_aws_glue_jobs_on_local/", "subreddit_subscribers": 102631, "created_utc": 1682488509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone,\n\nIn one of my projects I\u2019m using python to connect to a SFTP server and use SSH keys to authenticate myself. All of a sudden the client SFTP server started showing errors and wasn\u2019t accepting SSH Keys. \u201cPAM Authentication\u201d shows up. \n\nThe SFTP is managed by another vendor and they identified that this is due to their SSH being backdated. While they\u2019re fixing that, they gave me password for PAM Authentication. I can log in using CLI. \n\nI just don\u2019t understand how to use this password with python/paramiko. I feel this password is definitely different than the username and password combo for the server. \n\nIs there anyone who wrote some python scripts for connection using PAM password?\n\nThanks!", "author_fullname": "t2_dv4ply58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Ingestion from SFTP Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yxwtg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682460874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;In one of my projects I\u2019m using python to connect to a SFTP server and use SSH keys to authenticate myself. All of a sudden the client SFTP server started showing errors and wasn\u2019t accepting SSH Keys. \u201cPAM Authentication\u201d shows up. &lt;/p&gt;\n\n&lt;p&gt;The SFTP is managed by another vendor and they identified that this is due to their SSH being backdated. While they\u2019re fixing that, they gave me password for PAM Authentication. I can log in using CLI. &lt;/p&gt;\n\n&lt;p&gt;I just don\u2019t understand how to use this password with python/paramiko. I feel this password is definitely different than the username and password combo for the server. &lt;/p&gt;\n\n&lt;p&gt;Is there anyone who wrote some python scripts for connection using PAM password?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yxwtg", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous_Apple_420", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yxwtg/data_ingestion_from_sftp_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yxwtg/data_ingestion_from_sftp_server/", "subreddit_subscribers": 102631, "created_utc": 1682460874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently in a position where I do a lot of the data modeling for report purposes. It's at a new company for me but in an industry I know well so I'm pretty familiar with the data I'm working with. My experience is mostly in analytics though with only the last year or so being more engineer focused so I'm still learning a lot.  \n\n\nI feel like I spend an inordinate amount of time just trying to unravel all our data models so that I can trace something from source system through to business report. I do this because we have a lot of data integrity questions that come up and to help me better understand the process. We have layers and layers of built in logic even for the most straightforward measures. \n\nI think what I'm seeing, on top of the data integrity concerns, as well as consistent integration breakdowns, speaks to a poorly designed warehouse but I don't feel like I have enough, except my experience, to go off of. I know it's not like anything I've dealt with in my past though. What questions do I need to be asking, or what else can I be looking at to help me better understand where our issues are? Any ideas or thoughts that can help point me in the right direction are appreciated!", "author_fullname": "t2_2q171de9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm spending a lot of time unraveling data models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yt7e4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682450727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in a position where I do a lot of the data modeling for report purposes. It&amp;#39;s at a new company for me but in an industry I know well so I&amp;#39;m pretty familiar with the data I&amp;#39;m working with. My experience is mostly in analytics though with only the last year or so being more engineer focused so I&amp;#39;m still learning a lot.  &lt;/p&gt;\n\n&lt;p&gt;I feel like I spend an inordinate amount of time just trying to unravel all our data models so that I can trace something from source system through to business report. I do this because we have a lot of data integrity questions that come up and to help me better understand the process. We have layers and layers of built in logic even for the most straightforward measures. &lt;/p&gt;\n\n&lt;p&gt;I think what I&amp;#39;m seeing, on top of the data integrity concerns, as well as consistent integration breakdowns, speaks to a poorly designed warehouse but I don&amp;#39;t feel like I have enough, except my experience, to go off of. I know it&amp;#39;s not like anything I&amp;#39;ve dealt with in my past though. What questions do I need to be asking, or what else can I be looking at to help me better understand where our issues are? Any ideas or thoughts that can help point me in the right direction are appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12yt7e4", "is_robot_indexable": true, "report_reasons": null, "author": "lahma_mama", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yt7e4/im_spending_a_lot_of_time_unraveling_data_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yt7e4/im_spending_a_lot_of_time_unraveling_data_models/", "subreddit_subscribers": 102631, "created_utc": 1682450727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a bunch of sites across the country collecting data.\n\nEach piece of equipment has a battery and a .txt file recording the battery level every minute, appending the record to the site .txt file. So, a file that is growing one record every minute.\n\nThe equipment is managed by an external company, so i don't have control to change the way the .txt add records.\n\nMy team want to write this data to a database (BigQuery) and i can't think of an efficient way to do this other than searching and deleting all the records for the site and re-writing them to the database. As each file may contains 200k records and doing a query to write only new records will, i guess, be slow.\n\nAny suggestions or am patterns i could use? And suggestions would be awesome. Thanks :-)", "author_fullname": "t2_qd6ssd6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's an efficient write to DB a file that's continuously being appended to?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yjk8d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682429548.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bunch of sites across the country collecting data.&lt;/p&gt;\n\n&lt;p&gt;Each piece of equipment has a battery and a .txt file recording the battery level every minute, appending the record to the site .txt file. So, a file that is growing one record every minute.&lt;/p&gt;\n\n&lt;p&gt;The equipment is managed by an external company, so i don&amp;#39;t have control to change the way the .txt add records.&lt;/p&gt;\n\n&lt;p&gt;My team want to write this data to a database (BigQuery) and i can&amp;#39;t think of an efficient way to do this other than searching and deleting all the records for the site and re-writing them to the database. As each file may contains 200k records and doing a query to write only new records will, i guess, be slow.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or am patterns i could use? And suggestions would be awesome. Thanks :-)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12yjk8d", "is_robot_indexable": true, "report_reasons": null, "author": "Careful-Doughnut-59", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yjk8d/whats_an_efficient_write_to_db_a_file_thats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yjk8d/whats_an_efficient_write_to_db_a_file_thats/", "subreddit_subscribers": 102631, "created_utc": 1682429548.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got offered to take a second job by a colleague and I'll be doing it on my own free time. However the job is more of a BI role (doing analysis and data visualization). I also have access to tons of learning materials in my current company and may take some certifications when I want. \n\nSo basically I am torn on what to do between the two on my free time. Looking for advice from wiser people here. Thank you.\n\nTake second job = more money\n\nPrioritize learning = more DE knowledge", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Take a second job or study more", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12z7u43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682487727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got offered to take a second job by a colleague and I&amp;#39;ll be doing it on my own free time. However the job is more of a BI role (doing analysis and data visualization). I also have access to tons of learning materials in my current company and may take some certifications when I want. &lt;/p&gt;\n\n&lt;p&gt;So basically I am torn on what to do between the two on my free time. Looking for advice from wiser people here. Thank you.&lt;/p&gt;\n\n&lt;p&gt;Take second job = more money&lt;/p&gt;\n\n&lt;p&gt;Prioritize learning = more DE knowledge&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12z7u43", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12z7u43/take_a_second_job_or_study_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12z7u43/take_a_second_job_or_study_more/", "subreddit_subscribers": 102631, "created_utc": 1682487727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I was tasked to build a CICD pipeline for Synapse. I want to be able to deploy from Dev to different environment. I found the Sqlpackage, where it extract the schema of a workspace and publish it to a destination workspace. I'm not sure but I think it is not the right approach since it is not parametrizable and throwing error when deploying external views. So far it worked only with tables.\nAny idea how can I build it? Thank you in advance", "author_fullname": "t2_pp0zirow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD for Synapse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ysvyg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682450021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I was tasked to build a CICD pipeline for Synapse. I want to be able to deploy from Dev to different environment. I found the Sqlpackage, where it extract the schema of a workspace and publish it to a destination workspace. I&amp;#39;m not sure but I think it is not the right approach since it is not parametrizable and throwing error when deploying external views. So far it worked only with tables.\nAny idea how can I build it? Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ysvyg", "is_robot_indexable": true, "report_reasons": null, "author": "These_Rip_9327", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ysvyg/cicd_for_synapse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ysvyg/cicd_for_synapse/", "subreddit_subscribers": 102631, "created_utc": 1682450021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3yleu7rp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Business Value of Metadata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_12you5a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/EHES8eKB3vtBgsdAesjBcGWniy51TpSivgMmve21LL8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682441175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/alvin-ai/the-business-value-of-metadata-efa46f78a6da", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?auto=webp&amp;v=enabled&amp;s=52a7f0a1a29f6fcbed6044190f4419d8c7db6ea9", "width": 1200, "height": 692}, "resolutions": [{"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1fae95481cfa84bed915d1d20480d4fb030c472", "width": 108, "height": 62}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=50b80bbe9a84be94b24656c94868a1bd76babac1", "width": 216, "height": 124}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02375c4beeb71f2bc69588ec37b949cf2937ea4e", "width": 320, "height": 184}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=355acf7fd8c020eee63b5a36e58fc66588eb49b4", "width": 640, "height": 369}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=884a6f268b31cb73bf1f290b1da30f8d16c416e5", "width": 960, "height": 553}, {"url": "https://external-preview.redd.it/gsDwIaxoZmwWR2kIqWLqJ87JJ3rA5zy-WAoF82Jz-wU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d1f8f55607a0a4e8a56baf818ded87cc76159e5", "width": 1080, "height": 622}], "variants": {}, "id": "Mhev0XFTT0iV1DglMqIEg298usdpo1bM03JWxEvDc9A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12you5a", "is_robot_indexable": true, "report_reasons": null, "author": "gabsferreiradev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12you5a/the_business_value_of_metadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/alvin-ai/the-business-value-of-metadata-efa46f78a6da", "subreddit_subscribers": 102631, "created_utc": 1682441175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, \nI have started a new role recently where I am at a large legacy manufacturing company that is trying to get into analytics (lol). I was hired to do data engineering but it seems like most of what i will be doing to start off is working on getting their data policies in order. They have been using SAP for 30 years and are trying to modernize somewhat.  Currently at their plants they have analytics on site that are running based on production data and from my view those are all fine. However in their administration building is where they need a shitload of work. Basically they have always had web devs or SAP devs and never really had anyone in admin who was a DBA or trained in that regard. From just my first month i have a few things that I know need to change and was wondering if anyone had advice.\n\n1. Every project was made as its own database. Is there a way to quickly go back and put all of these projects into one database but under different schemas? To put it in perspective one of their sql servers has 55 databases.\n\n2. How do you get people to buy into data governance as a policy when it really hasnt been enforced before? Right now everyone has access to everything and its kind of a wild west. \n\n3. They currently have a few people who are very good at getting data out of SAP BW for queries. However this creates problems because the data analytics people arent really SAP trained and the data gets lost in translation over time, not to mention the bottleneck of always having to ask one of the couple people who understand SAP BW. Does anyone have experience in creating an analytics database in a third party program off of an SAP ERP system? There is really no getting rid of SAP in any capacity when its been used this long.", "author_fullname": "t2_6ra3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for new role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yl02m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682432808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, \nI have started a new role recently where I am at a large legacy manufacturing company that is trying to get into analytics (lol). I was hired to do data engineering but it seems like most of what i will be doing to start off is working on getting their data policies in order. They have been using SAP for 30 years and are trying to modernize somewhat.  Currently at their plants they have analytics on site that are running based on production data and from my view those are all fine. However in their administration building is where they need a shitload of work. Basically they have always had web devs or SAP devs and never really had anyone in admin who was a DBA or trained in that regard. From just my first month i have a few things that I know need to change and was wondering if anyone had advice.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Every project was made as its own database. Is there a way to quickly go back and put all of these projects into one database but under different schemas? To put it in perspective one of their sql servers has 55 databases.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do you get people to buy into data governance as a policy when it really hasnt been enforced before? Right now everyone has access to everything and its kind of a wild west. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;They currently have a few people who are very good at getting data out of SAP BW for queries. However this creates problems because the data analytics people arent really SAP trained and the data gets lost in translation over time, not to mention the bottleneck of always having to ask one of the couple people who understand SAP BW. Does anyone have experience in creating an analytics database in a third party program off of an SAP ERP system? There is really no getting rid of SAP in any capacity when its been used this long.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12yl02m", "is_robot_indexable": true, "report_reasons": null, "author": "deemerritt", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yl02m/advice_for_new_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yl02m/advice_for_new_role/", "subreddit_subscribers": 102631, "created_utc": 1682432808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Morning guys,\n\nI\u2019m not very knowledgeable on CS and needed all of your opinions/expertise:\n\nI have a grad course or two that requires a windows OS. I only have a MacBook (M2 max) and a windows PC (AMD/GTX3070).\n\nI don\u2019t want to purchase a windows laptop just for this course. Is remoting into my home desktop a terrible idea? What are the setbacks? \n\n(I\u2019ve heard internet speed could be a bottle neck. But honestly, what speed would I want for this? I\u2019m looking for specifics so I can be the most prepared for this)", "author_fullname": "t2_3pqlnc5y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RDP MacBook to Windows PC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yhkpc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682424757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Morning guys,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not very knowledgeable on CS and needed all of your opinions/expertise:&lt;/p&gt;\n\n&lt;p&gt;I have a grad course or two that requires a windows OS. I only have a MacBook (M2 max) and a windows PC (AMD/GTX3070).&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t want to purchase a windows laptop just for this course. Is remoting into my home desktop a terrible idea? What are the setbacks? &lt;/p&gt;\n\n&lt;p&gt;(I\u2019ve heard internet speed could be a bottle neck. But honestly, what speed would I want for this? I\u2019m looking for specifics so I can be the most prepared for this)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12yhkpc", "is_robot_indexable": true, "report_reasons": null, "author": "RealTrashyC", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yhkpc/rdp_macbook_to_windows_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yhkpc/rdp_macbook_to_windows_pc/", "subreddit_subscribers": 102631, "created_utc": 1682424757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got assigned to a new project which uses AWS stack and noticed that they are only using Glue to call stored procedures or run queries in external database. From what I know, Glue is just spark on the backend so by not using spark they are not using Glue to its full capabilities. So my question is, is this an acceptable way of using Glue?", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue not fully utilized?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12yrhwz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682446925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got assigned to a new project which uses AWS stack and noticed that they are only using Glue to call stored procedures or run queries in external database. From what I know, Glue is just spark on the backend so by not using spark they are not using Glue to its full capabilities. So my question is, is this an acceptable way of using Glue?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12yrhwz", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12yrhwz/aws_glue_not_fully_utilized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12yrhwz/aws_glue_not_fully_utilized/", "subreddit_subscribers": 102631, "created_utc": 1682446925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI don\u2019t *think* this is possible, and have asked on the dbt Slack but got no response so wanted to check here.\n\ndbt can connect to Databricks and can connect to DuckDB.\n\nDuckDB can connect to DeltaLake (via Arrow).\n\nIs it possible to leverage dbt for my transformation pipelines with my data stored in S3 using delta-rs in Python, with DuckDB as my compute engine?\n\nIf anyone has done it, is there a guide I can follow, or some basic pointers to get up and running?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt with Delta Lake &amp; DuckDB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12zf0bu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682509635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t &lt;em&gt;think&lt;/em&gt; this is possible, and have asked on the dbt Slack but got no response so wanted to check here.&lt;/p&gt;\n\n&lt;p&gt;dbt can connect to Databricks and can connect to DuckDB.&lt;/p&gt;\n\n&lt;p&gt;DuckDB can connect to DeltaLake (via Arrow).&lt;/p&gt;\n\n&lt;p&gt;Is it possible to leverage dbt for my transformation pipelines with my data stored in S3 using delta-rs in Python, with DuckDB as my compute engine?&lt;/p&gt;\n\n&lt;p&gt;If anyone has done it, is there a guide I can follow, or some basic pointers to get up and running?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12zf0bu", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zf0bu/dbt_with_delta_lake_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12zf0bu/dbt_with_delta_lake_duckdb/", "subreddit_subscribers": 102631, "created_utc": 1682509635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The latest [Thoughtworks Tech Radar](https://www.thoughtworks.com/radar) is out. Some highlights in the data space:\n\n## \ud83d\udfe2 Adopt\n\n* [DVC](HTTPs://dvc.org)\n\n## \ud83d\udc4d\ud83c\udffb Trial\n\n* [Apache Hudi](https://hudi.apache.org/)\n* [DuckDB](https://duckdb.org/)\n* [Soda Core](https://www.soda.io/core)\n* [dbt-unit-testing](https://github.com/EqualExperts/dbt-unit-testing)\n* [Lakehouse Architecture](https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf)\n\n## \ud83d\udc40 Assess\n\n* [Neon](https://neon.tech/)\n* [dbt-expectations](https://github.com/calogica/dbt-expectations/tree/0.8.2/)\n\n## \ud83d\udfe0 Hold\n\n* [Denodo](https://www.denodo.com/en)\n\n---\n\nDid anything else catch your eye from the radar? Any thoughts on the assessments of the above tools? \n\nFor me, it was seeing Denodo listed. I've not used it, but it's fairly unusual for tools &amp; platforms to move to Hold (often the entries, or 'blips' as they're called, just don't get listed next time), so seems they had a pretty bad time with Denodo, even saying: \n\n&gt; we recommend that you do not use Denodo as a primary data transformation tool and use tools like Spark or SQL (with dbt) for your data transformations instead.", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data-eng related highlights from the latest Thoughtworks Tech Radar", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12ze7uy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682507544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The latest &lt;a href=\"https://www.thoughtworks.com/radar\"&gt;Thoughtworks Tech Radar&lt;/a&gt; is out. Some highlights in the data space:&lt;/p&gt;\n\n&lt;h2&gt;\ud83d\udfe2 Adopt&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"HTTPs://dvc.org\"&gt;DVC&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;\ud83d\udc4d\ud83c\udffb Trial&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://hudi.apache.org/\"&gt;Apache Hudi&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://duckdb.org/\"&gt;DuckDB&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.soda.io/core\"&gt;Soda Core&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/EqualExperts/dbt-unit-testing\"&gt;dbt-unit-testing&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf\"&gt;Lakehouse Architecture&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;\ud83d\udc40 Assess&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://neon.tech/\"&gt;Neon&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/calogica/dbt-expectations/tree/0.8.2/\"&gt;dbt-expectations&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;\ud83d\udfe0 Hold&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.denodo.com/en\"&gt;Denodo&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Did anything else catch your eye from the radar? Any thoughts on the assessments of the above tools? &lt;/p&gt;\n\n&lt;p&gt;For me, it was seeing Denodo listed. I&amp;#39;ve not used it, but it&amp;#39;s fairly unusual for tools &amp;amp; platforms to move to Hold (often the entries, or &amp;#39;blips&amp;#39; as they&amp;#39;re called, just don&amp;#39;t get listed next time), so seems they had a pretty bad time with Denodo, even saying: &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;we recommend that you do not use Denodo as a primary data transformation tool and use tools like Spark or SQL (with dbt) for your data transformations instead.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?auto=webp&amp;v=enabled&amp;s=811182d29905a1e1e9403c451cf55bb6e8f6f368", "width": 1600, "height": 837}, "resolutions": [{"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64ff67d5c54e2223029ebe80e5afbea47bedd2d7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f125b62c2d28fe65a11ab525349a719a7a9e0d06", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=492e504d582234f81d47fd498965c4311a0947ad", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54ad7c054ee7bdf6bb0dea7fad5a7821a18da98e", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1b9965c5698e7f4220c164dcfe0fa5ea058a274", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/a4ecY2hwS5qxufqQSZnrTLtKQZRHDTcLN-CJfOWGyco.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=689783f11d2d3dfda79b30353949a6c5d0c30306", "width": 1080, "height": 564}], "variants": {}, "id": "qKpvdmTr2prhwnfo9Lt4Bu8EUjs0RuFpA_BAZYOqGlQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ze7uy", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ze7uy/dataeng_related_highlights_from_the_latest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ze7uy/dataeng_related_highlights_from_the_latest/", "subreddit_subscribers": 102631, "created_utc": 1682507544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi DEs of Reddit,\n\nI\u2019m about to start a new project which requires me to download daily a large file from a public website (~30Gb) and land this file into AWS S3. I\u2019m trying to brainstorm the most efficient solution and I was wondering if anybody had an experience downloading large files like this? \n\nAnything in particular I should be aware of/consider ? \n\nThank you!", "author_fullname": "t2_a3m6qw38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading large files from public websites - Brainstorm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12ze0m5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682507000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi DEs of Reddit,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m about to start a new project which requires me to download daily a large file from a public website (~30Gb) and land this file into AWS S3. I\u2019m trying to brainstorm the most efficient solution and I was wondering if anybody had an experience downloading large files like this? &lt;/p&gt;\n\n&lt;p&gt;Anything in particular I should be aware of/consider ? &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ze0m5", "is_robot_indexable": true, "report_reasons": null, "author": "sk808mafia", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ze0m5/downloading_large_files_from_public_websites/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ze0m5/downloading_large_files_from_public_websites/", "subreddit_subscribers": 102631, "created_utc": 1682507000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is working on modernizing our stack, but we still rely on a great number of legacy systems and processes. I'm in the initial stages of putting together a POC for an orchestrater to manage the mess of DBMS and ETL platforms we've accumulated, and everything I've read about Dagster sounds great. Unfortunately, it doesn't seem to natively support Oracle/SQL Server, or some of our other legacy systems. \n\nI know that with Airflow, you can write your own hooks and operarors to interface with APIs or use existing python packages or bash commands. Is this sort of thing possible with dagster as well? I haven't seen anything talking about that kind of customization. The docs give a broad overview of how to write code for assets, but I'm still not clear on whether I could create an asset class to access Oracle using SQLAlchemy, for example. \n\nI see a lot of examples that interface with airbyte and dbt, which I think could be used as Middleware for this purpose, but I'd prefer to keep things as simple and self-contained as possible.\n\nAny thoughts or experience would be greatly appreciated.", "author_fullname": "t2_3boovm3w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Custom assets in dagster?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12zdezw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682505307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is working on modernizing our stack, but we still rely on a great number of legacy systems and processes. I&amp;#39;m in the initial stages of putting together a POC for an orchestrater to manage the mess of DBMS and ETL platforms we&amp;#39;ve accumulated, and everything I&amp;#39;ve read about Dagster sounds great. Unfortunately, it doesn&amp;#39;t seem to natively support Oracle/SQL Server, or some of our other legacy systems. &lt;/p&gt;\n\n&lt;p&gt;I know that with Airflow, you can write your own hooks and operarors to interface with APIs or use existing python packages or bash commands. Is this sort of thing possible with dagster as well? I haven&amp;#39;t seen anything talking about that kind of customization. The docs give a broad overview of how to write code for assets, but I&amp;#39;m still not clear on whether I could create an asset class to access Oracle using SQLAlchemy, for example. &lt;/p&gt;\n\n&lt;p&gt;I see a lot of examples that interface with airbyte and dbt, which I think could be used as Middleware for this purpose, but I&amp;#39;d prefer to keep things as simple and self-contained as possible.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts or experience would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12zdezw", "is_robot_indexable": true, "report_reasons": null, "author": "myrstica", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zdezw/custom_assets_in_dagster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12zdezw/custom_assets_in_dagster/", "subreddit_subscribers": 102631, "created_utc": 1682505307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a biotech company that's embarking on a new effort to build a decentralized data mesh with an associated data catalog. Previously, my team was responsible for data engineering at one of our sites, and we'll continue to support building out data engineering projects for all scientists at the site, but now integrating with the data mesh.\n\nI know that the big benefit of a data mesh architecture is that a company is able to decentralize your data architecture and give each group the power to own their own data infrastructure, shared centrally; I see the benefit here. *However*, none of the groups my team supports are very technical, and in practice, my team will build out and maintain all infrastructure. Since we have one group (my team) responsible for building and maintaining infrastructure relating to multiple groups, I *feel* as though it makes more sense to centralize the data infrastructure my team is working on and simply separate data from different groups logically (i.e. S3 keys/Redshift schemas).\n\nBut I'm definitely looking for opinions here. What do you think would work best?", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it ever a good idea to centralize a data lake/warehouse in a data mesh architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12zbybz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682500900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a biotech company that&amp;#39;s embarking on a new effort to build a decentralized data mesh with an associated data catalog. Previously, my team was responsible for data engineering at one of our sites, and we&amp;#39;ll continue to support building out data engineering projects for all scientists at the site, but now integrating with the data mesh.&lt;/p&gt;\n\n&lt;p&gt;I know that the big benefit of a data mesh architecture is that a company is able to decentralize your data architecture and give each group the power to own their own data infrastructure, shared centrally; I see the benefit here. &lt;em&gt;However&lt;/em&gt;, none of the groups my team supports are very technical, and in practice, my team will build out and maintain all infrastructure. Since we have one group (my team) responsible for building and maintaining infrastructure relating to multiple groups, I &lt;em&gt;feel&lt;/em&gt; as though it makes more sense to centralize the data infrastructure my team is working on and simply separate data from different groups logically (i.e. S3 keys/Redshift schemas).&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m definitely looking for opinions here. What do you think would work best?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12zbybz", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12zbybz/is_it_ever_a_good_idea_to_centralize_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12zbybz/is_it_ever_a_good_idea_to_centralize_a_data/", "subreddit_subscribers": 102631, "created_utc": 1682500900.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}