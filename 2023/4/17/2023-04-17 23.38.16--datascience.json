{"kind": "Listing", "data": {"after": "t3_12pnlhr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When a dataset has 27 features, how to start visualizing. Should i start from scratch or use correlation and see the relation or any other?", "author_fullname": "t2_jx6tumem", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to work on visualization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pa2uy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681725083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When a dataset has 27 features, how to start visualizing. Should i start from scratch or use correlation and see the relation or any other?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pa2uy", "is_robot_indexable": true, "report_reasons": null, "author": "DrummerSea4593", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pa2uy/how_to_work_on_visualization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pa2uy/how_to_work_on_visualization/", "subreddit_subscribers": 875120, "created_utc": 1681725083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I received an offer for Optum's DS&amp;E TDP full-time program. I've seen mixed reviews about it on Reddit and was curious if anyone has feedback on the program? The market is pretty bad right now so I've accepted the offer, but I want to make sure I can make the most of it and build a solid foundation for my career in the future. I'm interested in DS in the healthcare and medical industry, which is what appealed to me about Optum in the first place and just wanna make sure I'm doing the right thing to get my foot in the door :) Any feedback would be much appreciated, or, if anyone has more experience and started out with a lower tier company, that would be great to hear about too!", "author_fullname": "t2_9dz2je2p8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optum TDP Data Science and Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ovrv7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681692877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I received an offer for Optum&amp;#39;s DS&amp;amp;E TDP full-time program. I&amp;#39;ve seen mixed reviews about it on Reddit and was curious if anyone has feedback on the program? The market is pretty bad right now so I&amp;#39;ve accepted the offer, but I want to make sure I can make the most of it and build a solid foundation for my career in the future. I&amp;#39;m interested in DS in the healthcare and medical industry, which is what appealed to me about Optum in the first place and just wanna make sure I&amp;#39;m doing the right thing to get my foot in the door :) Any feedback would be much appreciated, or, if anyone has more experience and started out with a lower tier company, that would be great to hear about too!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ovrv7", "is_robot_indexable": true, "report_reasons": null, "author": "Most-Hovercraft-9580", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ovrv7/optum_tdp_data_science_and_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ovrv7/optum_tdp_data_science_and_engineering/", "subreddit_subscribers": 875120, "created_utc": 1681692877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Apologies for a 2nd post here, but just trying to learn more about A/B testing and experimentation\n\nWhat is the \"harm\" in collecting more data or letting your experiment run longer\n\nFor example, let's assume we determine that we can reach sample size within a week for our primary metric CTR. But we need 3 weeks to measure retention, and so we determine that we must run this experiment for at least 3 weeks\n\nWhat is the harm in running the experiment for 4 weeks? or 5 weeks? Are there pros/cons to this?\n\nApologies for a dumb question again.", "author_fullname": "t2_133emd5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pros/cons of collecting more data in an A/B Test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12p7rxo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681719360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies for a 2nd post here, but just trying to learn more about A/B testing and experimentation&lt;/p&gt;\n\n&lt;p&gt;What is the &amp;quot;harm&amp;quot; in collecting more data or letting your experiment run longer&lt;/p&gt;\n\n&lt;p&gt;For example, let&amp;#39;s assume we determine that we can reach sample size within a week for our primary metric CTR. But we need 3 weeks to measure retention, and so we determine that we must run this experiment for at least 3 weeks&lt;/p&gt;\n\n&lt;p&gt;What is the harm in running the experiment for 4 weeks? or 5 weeks? Are there pros/cons to this?&lt;/p&gt;\n\n&lt;p&gt;Apologies for a dumb question again.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12p7rxo", "is_robot_indexable": true, "report_reasons": null, "author": "vatom14", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12p7rxo/proscons_of_collecting_more_data_in_an_ab_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12p7rxo/proscons_of_collecting_more_data_in_an_ab_test/", "subreddit_subscribers": 875120, "created_utc": 1681719360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I bought \"Practical Statistics for Data Scientists second edition\" and I believe it is fake. I was wondering if anyone has experienced this, or can help me confirm whether it is fake.\n\nThe pages are a light yellow instead of white, and the printing quality of the light grey (numbers in the code, and certain plots) is not good, other than this though, the book looks great. Is this the case with any copies you guys/gals have?\n\nIm not complaining too much though, it was $7 and for that price, it's a great bargain. \n\nThank you", "author_fullname": "t2_vdnydt7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "O REILLY fake textbooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12p8mez", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681721456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought &amp;quot;Practical Statistics for Data Scientists second edition&amp;quot; and I believe it is fake. I was wondering if anyone has experienced this, or can help me confirm whether it is fake.&lt;/p&gt;\n\n&lt;p&gt;The pages are a light yellow instead of white, and the printing quality of the light grey (numbers in the code, and certain plots) is not good, other than this though, the book looks great. Is this the case with any copies you guys/gals have?&lt;/p&gt;\n\n&lt;p&gt;Im not complaining too much though, it was $7 and for that price, it&amp;#39;s a great bargain. &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12p8mez", "is_robot_indexable": true, "report_reasons": null, "author": "ajplant", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12p8mez/o_reilly_fake_textbooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12p8mez/o_reilly_fake_textbooks/", "subreddit_subscribers": 875120, "created_utc": 1681721456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m going to start my first internship soon and I\u2019m going to be the only data scientist there, mainly working with sequential data.\n\nHas anyone tips when it comes to being the only data person?\n\nEdit: forgot to mention that it\u2019s a medtech startup", "author_fullname": "t2_6q7a2p0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tips about being the only data scientist in a startup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pc67k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681761655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681730090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m going to start my first internship soon and I\u2019m going to be the only data scientist there, mainly working with sequential data.&lt;/p&gt;\n\n&lt;p&gt;Has anyone tips when it comes to being the only data person?&lt;/p&gt;\n\n&lt;p&gt;Edit: forgot to mention that it\u2019s a medtech startup&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pc67k", "is_robot_indexable": true, "report_reasons": null, "author": "jeffrey_56", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pc67k/any_tips_about_being_the_only_data_scientist_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pc67k/any_tips_about_being_the_only_data_scientist_in_a/", "subreddit_subscribers": 875120, "created_utc": 1681730090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Fitter:  \n [cokelaer/fitter: Fit data to many distributions (github.com)](https://github.com/cokelaer/fitter)", "author_fullname": "t2_3op9qx89", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I recently discovered the python package 'fitter', which is a really nifty package for fitting various data distributions. Has anyone discovered any other cool packages that the field would find useful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ppj7g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681751794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fitter:&lt;br/&gt;\n &lt;a href=\"https://github.com/cokelaer/fitter\"&gt;cokelaer/fitter: Fit data to many distributions (github.com)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ppj7g", "is_robot_indexable": true, "report_reasons": null, "author": "LatterConcentrate6", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ppj7g/i_recently_discovered_the_python_package_fitter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ppj7g/i_recently_discovered_the_python_package_fitter/", "subreddit_subscribers": 875120, "created_utc": 1681751794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey r/datascience!   \nI found [this ancient thread](https://www.reddit.com/r/datascience/comments/bx59cv/tool_for_integrating_sql_jupyter_seamlessly/) about Jupyter Notebooks and SQL queries.   \nI\u2019m wondering if:\n\n1. Are people here still running SQL from within the notebook?\n2. What best practices/tips do you have?\n3. What are the main use cases?\n\nI usually use it to connect to multiple sources, store the queries within the notebook, and then put the notebooks into version control. I also found pandas way slower from running a duckdb + jupysql when possible.", "author_fullname": "t2_sy01bb7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best practices around Jupyter and SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ptgo1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681759204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;!&lt;br/&gt;\nI found &lt;a href=\"https://www.reddit.com/r/datascience/comments/bx59cv/tool_for_integrating_sql_jupyter_seamlessly/\"&gt;this ancient thread&lt;/a&gt; about Jupyter Notebooks and SQL queries.&lt;br/&gt;\nI\u2019m wondering if:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Are people here still running SQL from within the notebook?&lt;/li&gt;\n&lt;li&gt;What best practices/tips do you have?&lt;/li&gt;\n&lt;li&gt;What are the main use cases?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I usually use it to connect to multiple sources, store the queries within the notebook, and then put the notebooks into version control. I also found pandas way slower from running a duckdb + jupysql when possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ptgo1", "is_robot_indexable": true, "report_reasons": null, "author": "idomic", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ptgo1/what_are_the_best_practices_around_jupyter_and_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ptgo1/what_are_the_best_practices_around_jupyter_and_sql/", "subreddit_subscribers": 875120, "created_utc": 1681759204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm training an xgboost model in R using the caret package. I added class weights to the train control because my binary outcome is very skewed. However, the model with weights has an AUROC of 0.49, whereas the model without the weights has an AUROC of 0.88. I have other models too including logistic regression, random forest, etc, and their AUROC increased after implementing the weights. So why does it decrease it so much for XGBoost, is it because XGB already gives bigger weight to wrongly predicted observations in previous iterations?", "author_fullname": "t2_ing7dag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about class weights in xgboost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12poilz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681749797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m training an xgboost model in R using the caret package. I added class weights to the train control because my binary outcome is very skewed. However, the model with weights has an AUROC of 0.49, whereas the model without the weights has an AUROC of 0.88. I have other models too including logistic regression, random forest, etc, and their AUROC increased after implementing the weights. So why does it decrease it so much for XGBoost, is it because XGB already gives bigger weight to wrongly predicted observations in previous iterations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12poilz", "is_robot_indexable": true, "report_reasons": null, "author": "Goliof", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12poilz/question_about_class_weights_in_xgboost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12poilz/question_about_class_weights_in_xgboost/", "subreddit_subscribers": 875120, "created_utc": 1681749797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'm trying to do a project which links customer value to there NPS score.\nIt's for a retail company with a focus on credit options, we don't have a CLV metric due to the credit reasons.\nI have tried to find a correlation between total amount spent in the previous 90 days from survey, churn, probability to shop in the next 10 days and average order freq.\nThe hightest was total spent with a correlation of 0.15.\n\nNot sure where to take this. Any advice?", "author_fullname": "t2_7427v7db", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pcywk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681731880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m trying to do a project which links customer value to there NPS score.\nIt&amp;#39;s for a retail company with a focus on credit options, we don&amp;#39;t have a CLV metric due to the credit reasons.\nI have tried to find a correlation between total amount spent in the previous 90 days from survey, churn, probability to shop in the next 10 days and average order freq.\nThe hightest was total spent with a correlation of 0.15.&lt;/p&gt;\n\n&lt;p&gt;Not sure where to take this. Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pcywk", "is_robot_indexable": true, "report_reasons": null, "author": "Grovesy158", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pcywk/project_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pcywk/project_help/", "subreddit_subscribers": 875120, "created_utc": 1681731880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi friends, I\u2019m working on a uni project where I have I have to attribute multiple factors (e.g. promotions, inventory levels, store closures, etc.) to a retail sales increase / decrease for a particular week. So like I want to say like \u201cgood weather was responsible for driving sales this week.\u201d\n\nWhat\u2019s the best type of causal model / lib to use in this case? I\u2019m thinking of using something like DoWhy, but not sure if there\u2019s other causal frameworks out there that could be more relevant? \n\nThanks!", "author_fullname": "t2_1blas9up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Retail Sales Attribution Models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pw7za", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681764497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends, I\u2019m working on a uni project where I have I have to attribute multiple factors (e.g. promotions, inventory levels, store closures, etc.) to a retail sales increase / decrease for a particular week. So like I want to say like \u201cgood weather was responsible for driving sales this week.\u201d&lt;/p&gt;\n\n&lt;p&gt;What\u2019s the best type of causal model / lib to use in this case? I\u2019m thinking of using something like DoWhy, but not sure if there\u2019s other causal frameworks out there that could be more relevant? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pw7za", "is_robot_indexable": true, "report_reasons": null, "author": "chocolate_bear95", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pw7za/retail_sales_attribution_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pw7za/retail_sales_attribution_models/", "subreddit_subscribers": 875120, "created_utc": 1681764497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear all, for my final thesis, I am doing market research into the German data verification market. I made a short list of 18 questions concerning the market and would like to ask everyone to participate to help me finish my bachelor's degree. I'm happy to share the research's results upon request. \n\nAnyone working in the FinTech, Flex work or healthcare industry  and people that are familiar with the data verification market or active in data science have a valuable opinion in this questionnaire.  \n \nfind the link to questionnaire here: https://form.jotform.com/230624379916362 \n\nKind regards,\nJaydey Braams", "author_fullname": "t2_6kr8y1qc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Market research", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ph0tv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681740080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear all, for my final thesis, I am doing market research into the German data verification market. I made a short list of 18 questions concerning the market and would like to ask everyone to participate to help me finish my bachelor&amp;#39;s degree. I&amp;#39;m happy to share the research&amp;#39;s results upon request. &lt;/p&gt;\n\n&lt;p&gt;Anyone working in the FinTech, Flex work or healthcare industry  and people that are familiar with the data verification market or active in data science have a valuable opinion in this questionnaire.  &lt;/p&gt;\n\n&lt;p&gt;find the link to questionnaire here: &lt;a href=\"https://form.jotform.com/230624379916362\"&gt;https://form.jotform.com/230624379916362&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Kind regards,\nJaydey Braams&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ph0tv", "is_robot_indexable": true, "report_reasons": null, "author": "ogjd020", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ph0tv/market_research/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ph0tv/market_research/", "subreddit_subscribers": 875120, "created_utc": 1681740080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello!  \nSoftware engineer making the move to data science. I'm proficient in Python but not much on data skills and stack.  \nWhere should I start?  \n\n\nI heard that ydata-profiling is the must use tool but I'm still figuring out how to leverage it.  \n\n\nThank you in advance!", "author_fullname": "t2_76hc2h27", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm new to data science. Where to start?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12q0o1i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681772533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;br/&gt;\nSoftware engineer making the move to data science. I&amp;#39;m proficient in Python but not much on data skills and stack.&lt;br/&gt;\nWhere should I start?  &lt;/p&gt;\n\n&lt;p&gt;I heard that ydata-profiling is the must use tool but I&amp;#39;m still figuring out how to leverage it.  &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q0o1i", "is_robot_indexable": true, "report_reasons": null, "author": "PhilosopherNo2974", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q0o1i/im_new_to_data_science_where_to_start/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q0o1i/im_new_to_data_science_where_to_start/", "subreddit_subscribers": 875120, "created_utc": 1681772533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I can\u2019t find any information online on the process/timeline for a data scientist role. Was hoping someone would share their experience?", "author_fullname": "t2_5akq1mi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone interviewed with P&amp;G for a data science role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12q07sb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681771696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can\u2019t find any information online on the process/timeline for a data scientist role. Was hoping someone would share their experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q07sb", "is_robot_indexable": true, "report_reasons": null, "author": "Dapper-Economy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q07sb/has_anyone_interviewed_with_pg_for_a_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q07sb/has_anyone_interviewed_with_pg_for_a_data_science/", "subreddit_subscribers": 875120, "created_utc": 1681771696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does it happen that you will be at Kubecon Europe 2023? We will be at **booth P15**, ready to talk about AI/ML, MLOps, open-source ML, Kubeflow, and more. There are a bunch of demos Ubuntu prepared and a fun keynote on secure MLOps. [Read more](https://medium.com/@andreeamihaelamunteanu/open-source-mlops-at-kubecon-with-ubuntu-870d06742b4f) and meet us there!", "author_fullname": "t2_3z4miuvs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kubecon Europe 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12pzypd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681771222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does it happen that you will be at Kubecon Europe 2023? We will be at &lt;strong&gt;booth P15&lt;/strong&gt;, ready to talk about AI/ML, MLOps, open-source ML, Kubeflow, and more. There are a bunch of demos Ubuntu prepared and a fun keynote on secure MLOps. &lt;a href=\"https://medium.com/@andreeamihaelamunteanu/open-source-mlops-at-kubecon-with-ubuntu-870d06742b4f\"&gt;Read more&lt;/a&gt; and meet us there!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?auto=webp&amp;v=enabled&amp;s=77fa09475f5677298ce0f781605f8b30e3872c28", "width": 720, "height": 376}, "resolutions": [{"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df046630b5228d489c6666882cd309e9a7db6bad", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=951a9937f2949b1944ec19a4be60f600d93bf424", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4928ff7617de6e675af1ca549a2751852e323de4", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd34f0217fe410444e028ce9b2b455e5962469a7", "width": 640, "height": 334}], "variants": {}, "id": "nXaAxnhnc4JIZNk3qgMyfIBphHx3dRXGnYjGSFZKG2I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pzypd", "is_robot_indexable": true, "report_reasons": null, "author": "andreea-mun", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pzypd/kubecon_europe_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pzypd/kubecon_europe_2023/", "subreddit_subscribers": 875120, "created_utc": 1681771222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, \nI want to create a ml model in order to predict anomaly of my material. \nThe issue is that i have more than one node on my dataset (almost 2500 nodes and 3 millions logs) and m having troubles finding the right model to forecast. (my data is timestamp) timestamp + the value of load cpu at each time. The models depend on the node. Same model can work on a node and not be good for others. And ofc i can't train 2500 models manually. \nPls can anyone help me out with this?\nM still a beginner in the field (intern).", "author_fullname": "t2_9fzprsh0s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AiOps issue machine learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pvt7z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681764728.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681763741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, \nI want to create a ml model in order to predict anomaly of my material. \nThe issue is that i have more than one node on my dataset (almost 2500 nodes and 3 millions logs) and m having troubles finding the right model to forecast. (my data is timestamp) timestamp + the value of load cpu at each time. The models depend on the node. Same model can work on a node and not be good for others. And ofc i can&amp;#39;t train 2500 models manually. \nPls can anyone help me out with this?\nM still a beginner in the field (intern).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pvt7z", "is_robot_indexable": true, "report_reasons": null, "author": "Bearsalim", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pvt7z/aiops_issue_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pvt7z/aiops_issue_machine_learning/", "subreddit_subscribers": 875120, "created_utc": 1681763741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently doing a Data Science coop at a mid level Fortune 500 company.\n\nI did a summer internship as a sophomore last year, and have been cooping during the following Fall and Spring semesters.\n\nI will be doing another summer internship as a Junior, and by the end of it I will know if I have a full time offer or not.\n\n&amp;#x200B;\n\nMy question is this:\n\nIf I do get a full time offer, should I continue cooping for my remaining year of school (i.e. 12 credit hours + part time work), or take that time to focus on studying and enjoying my last year of college? My full time offer would still stand if I decide not to continue coop.\n\nThe coop is paid, in case you were wondering.\n\n&amp;#x200B;\n\n**tl;dr**\n\n**I can get more work experience before graduation, or be lazy and relax for my last year, what do I do?**", "author_fullname": "t2_32ft64py", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Continue Coop, or Focus on Studies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pqivp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681754453.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681753698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently doing a Data Science coop at a mid level Fortune 500 company.&lt;/p&gt;\n\n&lt;p&gt;I did a summer internship as a sophomore last year, and have been cooping during the following Fall and Spring semesters.&lt;/p&gt;\n\n&lt;p&gt;I will be doing another summer internship as a Junior, and by the end of it I will know if I have a full time offer or not.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question is this:&lt;/p&gt;\n\n&lt;p&gt;If I do get a full time offer, should I continue cooping for my remaining year of school (i.e. 12 credit hours + part time work), or take that time to focus on studying and enjoying my last year of college? My full time offer would still stand if I decide not to continue coop.&lt;/p&gt;\n\n&lt;p&gt;The coop is paid, in case you were wondering.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I can get more work experience before graduation, or be lazy and relax for my last year, what do I do?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pqivp", "is_robot_indexable": true, "report_reasons": null, "author": "daltonpain", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pqivp/continue_coop_or_focus_on_studies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pqivp/continue_coop_or_focus_on_studies/", "subreddit_subscribers": 875120, "created_utc": 1681753698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm thinking about a work problem and not sure if I am making a dumb mistake.\n\nLet's assume we are designing some A/B test, calculate the same sample size required and etc. Let's say sample size required for experiment is 100 users. Let's say the company get 1k users per day.\n\nWhat is the absolute minimum number of days required for the experiment? Can we not technically run the experiment in a day? \n\nOf course we would want to run it for maybe a week at least to capture any variation maybe throughout the week or something - but is the absolute minimum just 1 day or am i oversimplifying?", "author_fullname": "t2_133emd5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Minimum duration of an experiment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12p54le", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681712951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m thinking about a work problem and not sure if I am making a dumb mistake.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s assume we are designing some A/B test, calculate the same sample size required and etc. Let&amp;#39;s say sample size required for experiment is 100 users. Let&amp;#39;s say the company get 1k users per day.&lt;/p&gt;\n\n&lt;p&gt;What is the absolute minimum number of days required for the experiment? Can we not technically run the experiment in a day? &lt;/p&gt;\n\n&lt;p&gt;Of course we would want to run it for maybe a week at least to capture any variation maybe throughout the week or something - but is the absolute minimum just 1 day or am i oversimplifying?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12p54le", "is_robot_indexable": true, "report_reasons": null, "author": "vatom14", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12p54le/minimum_duration_of_an_experiment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12p54le/minimum_duration_of_an_experiment/", "subreddit_subscribers": 875120, "created_utc": 1681712951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 17 Apr, 2023 - 24 Apr, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12p185o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681704087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12p185o", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12p185o/weekly_entering_transitioning_thread_17_apr_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/12p185o/weekly_entering_transitioning_thread_17_apr_2023/", "subreddit_subscribers": 875120, "created_utc": 1681704087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, \n\nI am looking for data concerning car crash tests for a machine learning project. It should contain physical 3d information about the crash tests and scores or sensory measurements of the crash result. Ideally, all crashes are indentical with only the car being changed. (Or at least distinct labels for crash test type)\n\nThanks a lot!", "author_fullname": "t2_nh5hq8wn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crash Test Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12pzfuy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681770256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;I am looking for data concerning car crash tests for a machine learning project. It should contain physical 3d information about the crash tests and scores or sensory measurements of the crash result. Ideally, all crashes are indentical with only the car being changed. (Or at least distinct labels for crash test type)&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pzfuy", "is_robot_indexable": true, "report_reasons": null, "author": "just_another_ai_guy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pzfuy/crash_test_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pzfuy/crash_test_data/", "subreddit_subscribers": 875120, "created_utc": 1681770256.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easy to Use Text Annotation Tool | Upload documents, start annotating, and create advanced NLP model in a few hours.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_12ps49p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_q9v3kbiq", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Pzv8FB5ZBU2PuFtg7UErZJE_cmIcHWC1TWB3kje4rJI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "deeplearning", "selftext": "Check out this new article about how few-shot learning is automating document labeling! \ud83e\udd16\ud83d\udcdd \n\nManual document labeling can be time-consuming and prone to errors, but recent advancements in machine learning, specifically few-shot learning, are changing the game. \n\nFew-shot learning is a machine learning technique that allows models to learn a specific task with just a few labeled examples. By providing concatenated training examples of the task at hand and asking the model to predict the output of a target text, the model can be fine-tuned to perform the task accurately.\n\nDiscover how this technology is revolutionizing the data labeling space and making document processing more efficient \ud83d\udcbb\ud83d\udd0d read the full article here :  https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling", "author_fullname": "t2_q9v3kbiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easy to Use Text Annotation Tool | Upload documents, start annotating, and create advanced NLP model in a few hours.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/deeplearning", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_12ps3bv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1681756553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ubiai.tools", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Check out this new article about how few-shot learning is automating document labeling! \ud83e\udd16\ud83d\udcdd &lt;/p&gt;\n\n&lt;p&gt;Manual document labeling can be time-consuming and prone to errors, but recent advancements in machine learning, specifically few-shot learning, are changing the game. &lt;/p&gt;\n\n&lt;p&gt;Few-shot learning is a machine learning technique that allows models to learn a specific task with just a few labeled examples. By providing concatenated training examples of the task at hand and asking the model to predict the output of a target text, the model can be fine-tuned to perform the task accurately.&lt;/p&gt;\n\n&lt;p&gt;Discover how this technology is revolutionizing the data labeling space and making document processing more efficient \ud83d\udcbb\ud83d\udd0d read the full article here :  &lt;a href=\"https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling\"&gt;https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?auto=webp&amp;v=enabled&amp;s=8589973933b8a3d98f94770efc6b03fc0bf51d9d", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08f5bda42462327fe951a5c9830a966264d78738", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2deb84eb43c25f5feea0e7ddc596ae839f806c22", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d26bf86ae373d50e6c92bea40edbc5ef4f8fa2b2", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91e8fdb39b0ecc15eee3b51c79d6b072ed337b57", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d9bb0c74ca7b008ca2d474ed86f7dc180ed0a98", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=636277a8dfc8f20e73200643c91121e4f74c5f02", "width": 1080, "height": 564}], "variants": {}, "id": "fTeOd0VyYPSKz6U0rOsuA68u5NR6-meqB9jGZ-AMOzw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2t5eh", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ps3bv", "is_robot_indexable": true, "report_reasons": null, "author": "Harvy_thomson87", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/deeplearning/comments/12ps3bv/easy_to_use_text_annotation_tool_upload_documents/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling", "subreddit_subscribers": 93174, "created_utc": 1681756553.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1681756602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ubiai.tools", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?auto=webp&amp;v=enabled&amp;s=8589973933b8a3d98f94770efc6b03fc0bf51d9d", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08f5bda42462327fe951a5c9830a966264d78738", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2deb84eb43c25f5feea0e7ddc596ae839f806c22", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d26bf86ae373d50e6c92bea40edbc5ef4f8fa2b2", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91e8fdb39b0ecc15eee3b51c79d6b072ed337b57", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d9bb0c74ca7b008ca2d474ed86f7dc180ed0a98", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=636277a8dfc8f20e73200643c91121e4f74c5f02", "width": 1080, "height": 564}], "variants": {}, "id": "fTeOd0VyYPSKz6U0rOsuA68u5NR6-meqB9jGZ-AMOzw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ps49p", "is_robot_indexable": true, "report_reasons": null, "author": "Harvy_thomson87", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12ps3bv", "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ps49p/easy_to_use_text_annotation_tool_upload_documents/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling", "subreddit_subscribers": 875120, "created_utc": 1681756602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am building an NLP project from reddit data where age and gender are very helpful indicators of what I am trying to classify. Many submissions have this type sequence \"I (M35)\" and etc but not necessarily this. I've thought of searching for the M(age), F(age) pattern and in case there are multiple in a submission to get the one nearest. Do you think it will work? Is there something better I haven't thought of? Also the majority of the rows will be NaN? Is it worth it?", "author_fullname": "t2_jnkopc1j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would I extract op's gender and age?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pgfob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681738968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am building an NLP project from reddit data where age and gender are very helpful indicators of what I am trying to classify. Many submissions have this type sequence &amp;quot;I (M35)&amp;quot; and etc but not necessarily this. I&amp;#39;ve thought of searching for the M(age), F(age) pattern and in case there are multiple in a submission to get the one nearest. Do you think it will work? Is there something better I haven&amp;#39;t thought of? Also the majority of the rows will be NaN? Is it worth it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pgfob", "is_robot_indexable": true, "report_reasons": null, "author": "Brilliant_Intern1588", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pgfob/how_would_i_extract_ops_gender_and_age/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pgfob/how_would_i_extract_ops_gender_and_age/", "subreddit_subscribers": 875120, "created_utc": 1681738968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Say I have a computation subroutine (e.g., generating a report, computing a crew schedule given some inputs) developed in the notebook form. Now I want it to be callable or integrated by other systems. \nWhat are the tools you have used, or workflows to achieve such tasks. \n\nFor example, I know I can definitely rewrite the solution and expose it as a service by flask, fastapi etc. But do you have some other unconventional ways to do that?", "author_fullname": "t2_uqaki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tools do you use to make your developed DS solutions integrable", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12owr2d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681694888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say I have a computation subroutine (e.g., generating a report, computing a crew schedule given some inputs) developed in the notebook form. Now I want it to be callable or integrated by other systems. \nWhat are the tools you have used, or workflows to achieve such tasks. &lt;/p&gt;\n\n&lt;p&gt;For example, I know I can definitely rewrite the solution and expose it as a service by flask, fastapi etc. But do you have some other unconventional ways to do that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12owr2d", "is_robot_indexable": true, "report_reasons": null, "author": "dayeye2006", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12owr2d/what_tools_do_you_use_to_make_your_developed_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12owr2d/what_tools_do_you_use_to_make_your_developed_ds/", "subreddit_subscribers": 875120, "created_utc": 1681694888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently studying data science at a university and was wondering what criteria to look for in a company to apply for an intership", "author_fullname": "t2_29ek7oq0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tips for finding a great company for an internship during pursuing a bachelors degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ptxvh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681760148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently studying data science at a university and was wondering what criteria to look for in a company to apply for an intership&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ptxvh", "is_robot_indexable": true, "report_reasons": null, "author": "zyanaera", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ptxvh/any_tips_for_finding_a_great_company_for_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ptxvh/any_tips_for_finding_a_great_company_for_an/", "subreddit_subscribers": 875120, "created_utc": 1681760148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all,\n\nI am interviewing at a job as Data Literacy Consultant at a branch of a major Non-profit. Role would be for 20 hours per week. I have no experience in data and this would be my first consultancy job. Based in the Netherlands.\n\nI have no idea of hourly rates for consultancy and would appreciate some guidance on this. Bearing in mind also that it is my first gig, I have no data experience and I woukd be working for a non-profit. What should I ask for per hour?", "author_fullname": "t2_9q4mq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommended hourly rates for a 1st time Data Literacy Consultant?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pbqtq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681729466.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681729114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I am interviewing at a job as Data Literacy Consultant at a branch of a major Non-profit. Role would be for 20 hours per week. I have no experience in data and this would be my first consultancy job. Based in the Netherlands.&lt;/p&gt;\n\n&lt;p&gt;I have no idea of hourly rates for consultancy and would appreciate some guidance on this. Bearing in mind also that it is my first gig, I have no data experience and I woukd be working for a non-profit. What should I ask for per hour?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pbqtq", "is_robot_indexable": true, "report_reasons": null, "author": "Commodore-Metal", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pbqtq/recommended_hourly_rates_for_a_1st_time_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pbqtq/recommended_hourly_rates_for_a_1st_time_data/", "subreddit_subscribers": 875120, "created_utc": 1681729114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_bec2hd8k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Jupyter not working!! Added streamlit and created a new environment, now when i open the pynb file it shows Error and theres an update at top about update. Idk how to fix this. Pls help??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"f45k2cihzgua1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/f45k2cihzgua1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d2617a1dca1d3b60f3722a426aca907c72f7d7c"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/f45k2cihzgua1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e523a042f9f592fc8274e6c99f26766aa8c45477"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/f45k2cihzgua1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9840f478eae38807665249e514d9dbecfd4f4a51"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/f45k2cihzgua1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=753dacd39a46c758be749df24b5f1db411669c69"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/f45k2cihzgua1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a5700ba24c581982e52631fb9e1e008d8832f9b4"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/f45k2cihzgua1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=40cd0c140695d6b35bf1e46a2e4d23c6b03fca1a"}], "s": {"y": 3024, "x": 4032, "u": "https://preview.redd.it/f45k2cihzgua1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=4ef3a76d644537d28eec8544c1c4957821100a0a"}, "id": "f45k2cihzgua1"}, "tgb44jihzgua1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/tgb44jihzgua1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fbf17f1d3526817ef1d47f95839f4cc14406014"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/tgb44jihzgua1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a41ebb0efdbc5ba697ccfbe54dcb449866f7b93"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/tgb44jihzgua1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67d1fef6974eb7f73e2e507a816cd4c98f558a0e"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/tgb44jihzgua1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dac7b1e4b5780300f9f6b39454e748b5429727f8"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/tgb44jihzgua1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7e1775dd893646a59c1e37fd2d2f3ef9528de0c"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/tgb44jihzgua1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91fb2042f0914d8969e6a8a3d72b419a17ce08ac"}], "s": {"y": 3024, "x": 4032, "u": "https://preview.redd.it/tgb44jihzgua1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e750583e24adffe25cbcdc4607b65561045d8369"}, "id": "tgb44jihzgua1"}}, "name": "t3_12pnlhr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "f45k2cihzgua1", "id": 264653373}, {"media_id": "tgb44jihzgua1", "id": 264653374}]}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yEAZEZ0hrdSgMdIikTMnWHYfhOUEzSxeXeRtgO6bNeI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681748260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/12pnlhr", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "12pnlhr", "is_robot_indexable": true, "report_reasons": null, "author": "PrudentFly8507", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pnlhr/jupyter_not_working_added_streamlit_and_created_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/12pnlhr", "subreddit_subscribers": 875120, "created_utc": 1681748260.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}