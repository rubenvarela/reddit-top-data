{"kind": "Listing", "data": {"after": "t3_12djy0h", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working as a junior engineer for 9 months now at a consultancy, and I have to say, it's been a real struggle. Up to now, I've worked on 3 projects and I've struggled on each one. I struggle with the expectation that my company has for me to deliver. I understand I need to deliver, but it feels like I'm stuck in a vicious circle.\n\nAll of the cloud stuff, sql, and pipelines are new to me. Each project has lasted 2 or 3 months and by the time I'm comfortable and started to deliver, the project is over. In my spare time, I do plenty of tutorials to get myself up to speed, but it seems like all the personal work I do is not relevant to the project work that I'm doing because it's s so specific. Majority of the time I'm depending on my fellow engineers to help me out. I can honestly say, that I've only completed a handful of tickets by myself and I feel ashamed of it. They expect me to deliver when I simply don't know. I honestly feel like a burden on every team that I'm on.\n\nToday I had a 1-1 with my manager and he said that people on my previous project complained about my lack of contribution and how they weren't able to bill for their work because they were helping me. This was a shock because none of my colleagues expressed this to me while I was there.\n\nMy manager decided to do a 'PIP' (Performance Improvement Plan) to get me to improve. I've told my manager that I need to be on a project that is 6 months to a year-long but he keeps saying there isn't one. I feel kinda sad that he's put me on an informal disciplinary thing. He kept on saying that it was nothing, but I know it will be used against me if I don't improve. \n\nI feel like I'm alone and don't know what to do. Am I just kidding myself that I'm an engineer?", "author_fullname": "t2_81mnb4wb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shall I accept that I'm a useless engineer and look somewhere else or is this feeling part of the journey?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12e0lti", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680820742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working as a junior engineer for 9 months now at a consultancy, and I have to say, it&amp;#39;s been a real struggle. Up to now, I&amp;#39;ve worked on 3 projects and I&amp;#39;ve struggled on each one. I struggle with the expectation that my company has for me to deliver. I understand I need to deliver, but it feels like I&amp;#39;m stuck in a vicious circle.&lt;/p&gt;\n\n&lt;p&gt;All of the cloud stuff, sql, and pipelines are new to me. Each project has lasted 2 or 3 months and by the time I&amp;#39;m comfortable and started to deliver, the project is over. In my spare time, I do plenty of tutorials to get myself up to speed, but it seems like all the personal work I do is not relevant to the project work that I&amp;#39;m doing because it&amp;#39;s s so specific. Majority of the time I&amp;#39;m depending on my fellow engineers to help me out. I can honestly say, that I&amp;#39;ve only completed a handful of tickets by myself and I feel ashamed of it. They expect me to deliver when I simply don&amp;#39;t know. I honestly feel like a burden on every team that I&amp;#39;m on.&lt;/p&gt;\n\n&lt;p&gt;Today I had a 1-1 with my manager and he said that people on my previous project complained about my lack of contribution and how they weren&amp;#39;t able to bill for their work because they were helping me. This was a shock because none of my colleagues expressed this to me while I was there.&lt;/p&gt;\n\n&lt;p&gt;My manager decided to do a &amp;#39;PIP&amp;#39; (Performance Improvement Plan) to get me to improve. I&amp;#39;ve told my manager that I need to be on a project that is 6 months to a year-long but he keeps saying there isn&amp;#39;t one. I feel kinda sad that he&amp;#39;s put me on an informal disciplinary thing. He kept on saying that it was nothing, but I know it will be used against me if I don&amp;#39;t improve. &lt;/p&gt;\n\n&lt;p&gt;I feel like I&amp;#39;m alone and don&amp;#39;t know what to do. Am I just kidding myself that I&amp;#39;m an engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12e0lti", "is_robot_indexable": true, "report_reasons": null, "author": "Taurusamazing92", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12e0lti/shall_i_accept_that_im_a_useless_engineer_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12e0lti/shall_i_accept_that_im_a_useless_engineer_and/", "subreddit_subscribers": 96514, "created_utc": 1680820742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently a data engineer at a unicorn tech company, and I started applying a couple of months ago to see if I could get a job offer in this economy.  I have 5 years of experience, and before my current job, I was a data engineer at a smaller tech company and a non-tech company in the fortune 500.\n\n\n\n\n\n\nI only applied to about 20-25 jobs in the past couple of months, since there really isn't that many job openings in my area.  Which is strange since I live in one of the big cities for tech jobs.  LinkedIn in my area is the same promoted jobs, so there appears to be more jobs available than there really are.\n\n\n\n\nOut of about 25 applications, I got one interview at a very small tech startup with a decent amount of funding.  I did really well in the recruiter and programming rounds, but I couldn't get a final round interview since there is a lot of competition for jobs.\n\n\n\n\nIt seems that even smaller tech companies and startups don't really care if you worked at a big tech company for several years and if you interviewed well, since there are so many engineers on the job market.", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineers, what has been your experience applying for jobs in this economy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dii09", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680783746.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680783508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a data engineer at a unicorn tech company, and I started applying a couple of months ago to see if I could get a job offer in this economy.  I have 5 years of experience, and before my current job, I was a data engineer at a smaller tech company and a non-tech company in the fortune 500.&lt;/p&gt;\n\n&lt;p&gt;I only applied to about 20-25 jobs in the past couple of months, since there really isn&amp;#39;t that many job openings in my area.  Which is strange since I live in one of the big cities for tech jobs.  LinkedIn in my area is the same promoted jobs, so there appears to be more jobs available than there really are.&lt;/p&gt;\n\n&lt;p&gt;Out of about 25 applications, I got one interview at a very small tech startup with a decent amount of funding.  I did really well in the recruiter and programming rounds, but I couldn&amp;#39;t get a final round interview since there is a lot of competition for jobs.&lt;/p&gt;\n\n&lt;p&gt;It seems that even smaller tech companies and startups don&amp;#39;t really care if you worked at a big tech company for several years and if you interviewed well, since there are so many engineers on the job market.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12dii09", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12dii09/data_engineers_what_has_been_your_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12dii09/data_engineers_what_has_been_your_experience/", "subreddit_subscribers": 96514, "created_utc": 1680783508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're already accustomed to hearing people say \"this is how YOU should use chatGPT\", but I rarely see people say \"This is how I use chat gpt.\"  \n\n\nIf you've got first hand experience using chat GPT to add legitimate value as a data engineer, I'd love to hear about it!", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How has ChatGPT helped you in your DE job? First hand experience only, plz.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dwoe3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680812476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re already accustomed to hearing people say &amp;quot;this is how YOU should use chatGPT&amp;quot;, but I rarely see people say &amp;quot;This is how I use chat gpt.&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve got first hand experience using chat GPT to add legitimate value as a data engineer, I&amp;#39;d love to hear about it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12dwoe3", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 84, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12dwoe3/how_has_chatgpt_helped_you_in_your_de_job_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12dwoe3/how_has_chatgpt_helped_you_in_your_de_job_first/", "subreddit_subscribers": 96514, "created_utc": 1680812476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying to gauge the viability of running Python/Go/Dask data lake transformations (raw data in many files -&gt; cleaned data in many parquet files). \n\n- Spark might intro a lot of overhead and complexity\n- We don't want to buy into Databricks\n- We're running on K8s with a solid platform team for support\n- Right now, Python scripts + Fivetran drop raw data files into data lake\n- First goal is to transform these raw files into silver and gold parquet-based tables in the data lake\n- After gold, teams are allowed to load into a DWH, query directly with some BI tool, etc but that's not the focus right now.\n\nWe know our infra will change over the next couple of years as this data operation gets going so writing simple, low cost scripts in languages that we're handy with would be great.\n\nMy worry in this case is performance. Can these languages/frameworks work well when needing to transform ~50GBs of data spread across many (hourly partitioned probably) files and transform them into the silver and gold. \n\nAny experience with something like this? Thanks.", "author_fullname": "t2_ut20i32q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any teams building data lakes without Spark? And specifically with vanilla Python/Go or with something like Dask?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dps2u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680798898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to gauge the viability of running Python/Go/Dask data lake transformations (raw data in many files -&amp;gt; cleaned data in many parquet files). &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Spark might intro a lot of overhead and complexity&lt;/li&gt;\n&lt;li&gt;We don&amp;#39;t want to buy into Databricks&lt;/li&gt;\n&lt;li&gt;We&amp;#39;re running on K8s with a solid platform team for support&lt;/li&gt;\n&lt;li&gt;Right now, Python scripts + Fivetran drop raw data files into data lake&lt;/li&gt;\n&lt;li&gt;First goal is to transform these raw files into silver and gold parquet-based tables in the data lake&lt;/li&gt;\n&lt;li&gt;After gold, teams are allowed to load into a DWH, query directly with some BI tool, etc but that&amp;#39;s not the focus right now.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We know our infra will change over the next couple of years as this data operation gets going so writing simple, low cost scripts in languages that we&amp;#39;re handy with would be great.&lt;/p&gt;\n\n&lt;p&gt;My worry in this case is performance. Can these languages/frameworks work well when needing to transform ~50GBs of data spread across many (hourly partitioned probably) files and transform them into the silver and gold. &lt;/p&gt;\n\n&lt;p&gt;Any experience with something like this? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12dps2u", "is_robot_indexable": true, "report_reasons": null, "author": "alex_o_h", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12dps2u/any_teams_building_data_lakes_without_spark_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12dps2u/any_teams_building_data_lakes_without_spark_and/", "subreddit_subscribers": 96514, "created_utc": 1680798898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI have seen a lot of posts regarding the use cases of Docker but not really any on how it actually works on a functional level. Many mention that it is great for dependency issues (one version of Python required for one process vs another) but how does Docker actually solve for this?", "author_fullname": "t2_jr18wyyz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker - Magic or Hype?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dteg3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680814420.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680806003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I have seen a lot of posts regarding the use cases of Docker but not really any on how it actually works on a functional level. Many mention that it is great for dependency issues (one version of Python required for one process vs another) but how does Docker actually solve for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12dteg3", "is_robot_indexable": true, "report_reasons": null, "author": "Fintechie__", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12dteg3/docker_magic_or_hype/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12dteg3/docker_magic_or_hype/", "subreddit_subscribers": 96514, "created_utc": 1680806003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I haven\u2019t done too many technical interviews for DE (&lt;20). Normally I get questions that i can do pretty easily. Things like: modeling, \u201chow would you build this pipeline?\u201d, basic SQL/Python, cloud services/data warehousing. \n\nToday I got put into a live coding interview unexpectedly, and was asked to get data from an API and do some transformations against it. The solution involved using requests library and doing some json loading/parsing. For the transformation it involved using the pivot function in python.\n\nI was completely caught off guard, as I haven\u2019t done the above in a while and my mind sort of blanked. \n\nIs this something that I should have known how to do easily?", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would you be able to do this on the spot during an interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12e589j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680831292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I haven\u2019t done too many technical interviews for DE (&amp;lt;20). Normally I get questions that i can do pretty easily. Things like: modeling, \u201chow would you build this pipeline?\u201d, basic SQL/Python, cloud services/data warehousing. &lt;/p&gt;\n\n&lt;p&gt;Today I got put into a live coding interview unexpectedly, and was asked to get data from an API and do some transformations against it. The solution involved using requests library and doing some json loading/parsing. For the transformation it involved using the pivot function in python.&lt;/p&gt;\n\n&lt;p&gt;I was completely caught off guard, as I haven\u2019t done the above in a while and my mind sort of blanked. &lt;/p&gt;\n\n&lt;p&gt;Is this something that I should have known how to do easily?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12e589j", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12e589j/would_you_be_able_to_do_this_on_the_spot_during/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12e589j/would_you_be_able_to_do_this_on_the_spot_during/", "subreddit_subscribers": 96514, "created_utc": 1680831292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you are writing complex SQLs it is most likely the systems aren\u2019t designed well and you are working on a bad data model.", "author_fullname": "t2_ui4m14ke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Here is a controversial statement", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12e8vxo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680839695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you are writing complex SQLs it is most likely the systems aren\u2019t designed well and you are working on a bad data model.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12e8vxo", "is_robot_indexable": true, "report_reasons": null, "author": "Alarmed-Sock4915", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12e8vxo/here_is_a_controversial_statement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12e8vxo/here_is_a_controversial_statement/", "subreddit_subscribers": 96514, "created_utc": 1680839695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since joining a Bay Area tech company, I have realized the grind to keep up with all the new tools in software engineering is alot. I am 35 and realizing it takes too much time commitment to keep up after work. Even as a data engineering manager, I am expected to know all the new skills and tools. What other roles align to a data engineering background? Product roles for data platforms? I like working with the business.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Change?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12e6iqp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680834164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since joining a Bay Area tech company, I have realized the grind to keep up with all the new tools in software engineering is alot. I am 35 and realizing it takes too much time commitment to keep up after work. Even as a data engineering manager, I am expected to know all the new skills and tools. What other roles align to a data engineering background? Product roles for data platforms? I like working with the business.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12e6iqp", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12e6iqp/career_change/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12e6iqp/career_change/", "subreddit_subscribers": 96514, "created_utc": 1680834164.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In AWS Glue (PySpark) I'm reading a 29GB CSV file from S3 then repartitioning to 204 partitions and finally writing out to S3. The Spark log for the FileScanRDD stage shows that a single executor is processing the entire 29GB and spilling a huge amount of data. To me this seems like Spark is using a  single executor to first read the entire CSV. I was under the impression that a  splittable format such as CSV could be read in chunks by each executor rather than going into a single executor. Is the only way to avoid the single-executor read to break up the input CSV into smaller files before reading? Also, why are  the 101GB disk and 40GB memory spill larger than the input size of 29GB? I'm  generally just trying to understand how the data transfer is happening  with respect to executors/partitions.\n\n&amp;#x200B;\n\n[FileScan Executor Metrics](https://preview.redd.it/s8gseh4mjasa1.png?width=1871&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fdb7fe4668506e2ece55a36057df3cd0208960b0)\n\n&amp;#x200B;\n\n[FileScan DAG](https://preview.redd.it/nung0qcojasa1.png?width=565&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=70ed7073d4608c93117de8fb4767a3cb9f57fe2b)\n\n&amp;#x200B;\n\n    import sys\n    from awsglue.transforms import *\n    from awsglue.utils import getResolvedOptions\n    from pyspark.context import SparkContext, SparkConf\n    from awsglue.context import GlueContext\n    from awsglue.job import Job\n    import time\n    from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n    \n    sc = SparkContext()\n    glueContext = GlueContext(sc)\n    spark = glueContext.spark_session\n    \n    \n    df = spark.read.format('csv').option('header',True)\\\n                                .option('multiline',True)\\\n                                .option(\"escape\", \"\\\"\")\\\n                                .option(\"delimiter\", \",\")\\\n                                .load(f's3://bucket/folder')\n    \n    df = df.repartition(numPartitions=204)\n    \n    \n    db = 'athena-db-name'\n    path = 's3://target_bucket/target_folder'\n    table = 'target_table_name'\n    folder = table.replace('_','-')\n    target_path = path + folder\n    \n    \n    df.write.saveAsTable(f\"`{db}`.{table}\", format='parquet', mode='overwrite', path=target_path)", "author_fullname": "t2_1evp2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark (AWS Glue) spill when reading large CSV file", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 20, "top_awarded_type": null, "hide_score": false, "media_metadata": {"nung0qcojasa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 132, "x": 108, "u": "https://preview.redd.it/nung0qcojasa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca92d05ca7ae22413fedb452ca6bdef04f34997d"}, {"y": 265, "x": 216, "u": "https://preview.redd.it/nung0qcojasa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de956270a3400fa6e6283e50d500906975001db1"}, {"y": 393, "x": 320, "u": "https://preview.redd.it/nung0qcojasa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8859cfb230ddf501ddf0044fd189fad47589abe"}], "s": {"y": 695, "x": 565, "u": "https://preview.redd.it/nung0qcojasa1.png?width=565&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=70ed7073d4608c93117de8fb4767a3cb9f57fe2b"}, "id": "nung0qcojasa1"}, "s8gseh4mjasa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 16, "x": 108, "u": "https://preview.redd.it/s8gseh4mjasa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a7e753437a67bae601dd2e16fece2b648cc0f2ff"}, {"y": 32, "x": 216, "u": "https://preview.redd.it/s8gseh4mjasa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bda3090b9168e845d89555e379289c18be255c63"}, {"y": 47, "x": 320, "u": "https://preview.redd.it/s8gseh4mjasa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc98e1e06dea0ec99d3ec622e4217d074cf3959b"}, {"y": 95, "x": 640, "u": "https://preview.redd.it/s8gseh4mjasa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d70bfc4858eca2a3bf43c275b01c1762a6150d1"}, {"y": 142, "x": 960, "u": "https://preview.redd.it/s8gseh4mjasa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3bc6879429dfbb8293c22095bc630b1b7988daba"}, {"y": 160, "x": 1080, "u": "https://preview.redd.it/s8gseh4mjasa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=481f83db3e97408cfb64fcf36606cd5770a9fea7"}], "s": {"y": 278, "x": 1871, "u": "https://preview.redd.it/s8gseh4mjasa1.png?width=1871&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fdb7fe4668506e2ece55a36057df3cd0208960b0"}, "id": "s8gseh4mjasa1"}}, "name": "t3_12dpot8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ffkA9zEVfvOCOc37wATyi335c6BIwRvXsujeDYMRxL4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680798718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In AWS Glue (PySpark) I&amp;#39;m reading a 29GB CSV file from S3 then repartitioning to 204 partitions and finally writing out to S3. The Spark log for the FileScanRDD stage shows that a single executor is processing the entire 29GB and spilling a huge amount of data. To me this seems like Spark is using a  single executor to first read the entire CSV. I was under the impression that a  splittable format such as CSV could be read in chunks by each executor rather than going into a single executor. Is the only way to avoid the single-executor read to break up the input CSV into smaller files before reading? Also, why are  the 101GB disk and 40GB memory spill larger than the input size of 29GB? I&amp;#39;m  generally just trying to understand how the data transfer is happening  with respect to executors/partitions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/s8gseh4mjasa1.png?width=1871&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=fdb7fe4668506e2ece55a36057df3cd0208960b0\"&gt;FileScan Executor Metrics&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nung0qcojasa1.png?width=565&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=70ed7073d4608c93117de8fb4767a3cb9f57fe2b\"&gt;FileScan DAG&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext, SparkConf\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nimport time\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType\n\nsc = SparkContext()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\n\n\ndf = spark.read.format(&amp;#39;csv&amp;#39;).option(&amp;#39;header&amp;#39;,True)\\\n                            .option(&amp;#39;multiline&amp;#39;,True)\\\n                            .option(&amp;quot;escape&amp;quot;, &amp;quot;\\&amp;quot;&amp;quot;)\\\n                            .option(&amp;quot;delimiter&amp;quot;, &amp;quot;,&amp;quot;)\\\n                            .load(f&amp;#39;s3://bucket/folder&amp;#39;)\n\ndf = df.repartition(numPartitions=204)\n\n\ndb = &amp;#39;athena-db-name&amp;#39;\npath = &amp;#39;s3://target_bucket/target_folder&amp;#39;\ntable = &amp;#39;target_table_name&amp;#39;\nfolder = table.replace(&amp;#39;_&amp;#39;,&amp;#39;-&amp;#39;)\ntarget_path = path + folder\n\n\ndf.write.saveAsTable(f&amp;quot;`{db}`.{table}&amp;quot;, format=&amp;#39;parquet&amp;#39;, mode=&amp;#39;overwrite&amp;#39;, path=target_path)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12dpot8", "is_robot_indexable": true, "report_reasons": null, "author": "LaminatedMisanthropy", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12dpot8/pyspark_aws_glue_spill_when_reading_large_csv_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12dpot8/pyspark_aws_glue_spill_when_reading_large_csv_file/", "subreddit_subscribers": 96514, "created_utc": 1680798718.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake vs Redshift: a comprehensive guide on choosing your cloud data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_12dkst1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": "transparent", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/E7S3Y4PGDYtRiG7Qx7vB_-NFu3PcyJ9ljzm69C6Ws3A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680788599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/snowflake-vs-redshift", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uPK2BpY6nPGO0-wl1JTUYBE81zabtWqEZJJC2o5GgQc.jpg?auto=webp&amp;v=enabled&amp;s=47a86384027e35d5146c9faa79795835d7a8d550", "width": 1800, "height": 946}, "resolutions": [{"url": "https://external-preview.redd.it/uPK2BpY6nPGO0-wl1JTUYBE81zabtWqEZJJC2o5GgQc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=789e3825d5a199333c23ac750d8dd304cc73a331", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/uPK2BpY6nPGO0-wl1JTUYBE81zabtWqEZJJC2o5GgQc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=978c798f81ef9e752dee778def8ecb74e3ce938f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/uPK2BpY6nPGO0-wl1JTUYBE81zabtWqEZJJC2o5GgQc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6e45f6c05585fce3fb85f409d71d7e1e156c645", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/uPK2BpY6nPGO0-wl1JTUYBE81zabtWqEZJJC2o5GgQc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e3f92c8c124d0017104970b7f52c32604059077", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/uPK2BpY6nPGO0-wl1JTUYBE81zabtWqEZJJC2o5GgQc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2dcfe0591ca1ac1a3859ed799e9a0336c4bca90b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/uPK2BpY6nPGO0-wl1JTUYBE81zabtWqEZJJC2o5GgQc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=026bcd859fd79edaf025c8df1554c501a2585eac", "width": 1080, "height": 567}], "variants": {}, "id": "FcKPoXUUPVO80Peja_IMgPPk998zQAeEIgojWPAIXeE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12dkst1", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12dkst1/snowflake_vs_redshift_a_comprehensive_guide_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/snowflake-vs-redshift", "subreddit_subscribers": 96514, "created_utc": 1680788599.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious to hear how others test data pipelines that spread across multiple tools.\n\n\\- Do you create dev and staging environments for each layer?\n\n\\- Do you run the whole pipeline during development?\n\n\\- Do you write unit, integration, or end-to-end tests?\n\n\\- Do you review data differences across the pipeline?\n\nI wrote an [article](https://www.datafold.com/blog/testing-data-pipelines) discussing some challenges to testing each layer: storage, integration, orchestration, transformation, BI, activation\u2026\n\nOne of my takes is that data teams will keep moving most of the complex transformation logic to the transformation layer (notably dbt):\n\n\\- ELT pipelines move transformation out from the integration layer\n\n\\- the metrics layer moves transformations out of the BI layer\n\n\\- the activation layer already advocates for transforming data with dbt\n\nIf raw data enters the transformation layer and ready-to-be-consumed data exits, can you test end-to-end pipelines from the transformation layer?", "author_fullname": "t2_975og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing the modern data stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12djkq1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680786231.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680785962.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious to hear how others test data pipelines that spread across multiple tools.&lt;/p&gt;\n\n&lt;p&gt;- Do you create dev and staging environments for each layer?&lt;/p&gt;\n\n&lt;p&gt;- Do you run the whole pipeline during development?&lt;/p&gt;\n\n&lt;p&gt;- Do you write unit, integration, or end-to-end tests?&lt;/p&gt;\n\n&lt;p&gt;- Do you review data differences across the pipeline?&lt;/p&gt;\n\n&lt;p&gt;I wrote an &lt;a href=\"https://www.datafold.com/blog/testing-data-pipelines\"&gt;article&lt;/a&gt; discussing some challenges to testing each layer: storage, integration, orchestration, transformation, BI, activation\u2026&lt;/p&gt;\n\n&lt;p&gt;One of my takes is that data teams will keep moving most of the complex transformation logic to the transformation layer (notably dbt):&lt;/p&gt;\n\n&lt;p&gt;- ELT pipelines move transformation out from the integration layer&lt;/p&gt;\n\n&lt;p&gt;- the metrics layer moves transformations out of the BI layer&lt;/p&gt;\n\n&lt;p&gt;- the activation layer already advocates for transforming data with dbt&lt;/p&gt;\n\n&lt;p&gt;If raw data enters the transformation layer and ready-to-be-consumed data exits, can you test end-to-end pipelines from the transformation layer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/boPF5YrwqrSsEyxakvag8-TAY5TVtcpAShR-eAk1uzY.jpg?auto=webp&amp;v=enabled&amp;s=629e981b19b1f5a09b7eca4029116bb93f9ffc34", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/boPF5YrwqrSsEyxakvag8-TAY5TVtcpAShR-eAk1uzY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c1b1fa08a10ecc2430d2298bcabf0718ae941de", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/boPF5YrwqrSsEyxakvag8-TAY5TVtcpAShR-eAk1uzY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9afafbfd738711eb984df3e8bd957b4413cddb98", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/boPF5YrwqrSsEyxakvag8-TAY5TVtcpAShR-eAk1uzY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9cb4920d04a54371115a4c625830dde9b2bf377", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/boPF5YrwqrSsEyxakvag8-TAY5TVtcpAShR-eAk1uzY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=935d9a143280253de2d05b9ac7c3a169e0bf0ed8", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/boPF5YrwqrSsEyxakvag8-TAY5TVtcpAShR-eAk1uzY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44dbe71446119d6bb4ced5e7b697ac68e35f1337", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/boPF5YrwqrSsEyxakvag8-TAY5TVtcpAShR-eAk1uzY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=41cf4c548a336e53bb91e25656580d6cf778f934", "width": 1080, "height": 607}], "variants": {}, "id": "EpOJBL6tEGJlfDwVwF5pZQ7zInpkiLXsFmo98IemLk4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12djkq1", "is_robot_indexable": true, "report_reasons": null, "author": "arimbr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12djkq1/testing_the_modern_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12djkq1/testing_the_modern_data_stack/", "subreddit_subscribers": 96514, "created_utc": 1680785962.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nMy task is to test Azure Data Pipelines.\n\n***My question is HOW?***\n\nCan you provide some resources?\n\nFor someone with experience, how would a test case look like? (give some examples please)\n\nContext:\n\nI recently joined a new project as QA Automation. In the initial phase of the project the pipeline will just copy data from a on-premise database into Azure Data Lake. Later, transformations and business rules will be added to the pipeline\n\nI have 0 experience with data pipelines and Azure Data Lake. I have experience with API testing, microservices, mobile (android and ios), end-to-end starting with creating testdata in backend and testing it in the UI.\n\nTools I've been using so far: Java, RestAssured, Cucumber, Appium (for mobile), a little bit of Gatling for performance, and of course Git, BitBucket, Jenkins, Azure Repo and Azure DevOps Pipelines.\n\nI am a bit stressed because I have to come up with a presentation proposing some tools for testing the Azure Data Pipelines (the internet suggested dbt or Great Expectations). How can I come up with pros and cons to each tool if I haven't worked with them yet? :)\n\nThank you!", "author_fullname": "t2_12t1ny", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing Azure Data Pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dg9oy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680778182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;My task is to test Azure Data Pipelines.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;My question is HOW?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Can you provide some resources?&lt;/p&gt;\n\n&lt;p&gt;For someone with experience, how would a test case look like? (give some examples please)&lt;/p&gt;\n\n&lt;p&gt;Context:&lt;/p&gt;\n\n&lt;p&gt;I recently joined a new project as QA Automation. In the initial phase of the project the pipeline will just copy data from a on-premise database into Azure Data Lake. Later, transformations and business rules will be added to the pipeline&lt;/p&gt;\n\n&lt;p&gt;I have 0 experience with data pipelines and Azure Data Lake. I have experience with API testing, microservices, mobile (android and ios), end-to-end starting with creating testdata in backend and testing it in the UI.&lt;/p&gt;\n\n&lt;p&gt;Tools I&amp;#39;ve been using so far: Java, RestAssured, Cucumber, Appium (for mobile), a little bit of Gatling for performance, and of course Git, BitBucket, Jenkins, Azure Repo and Azure DevOps Pipelines.&lt;/p&gt;\n\n&lt;p&gt;I am a bit stressed because I have to come up with a presentation proposing some tools for testing the Azure Data Pipelines (the internet suggested dbt or Great Expectations). How can I come up with pros and cons to each tool if I haven&amp;#39;t worked with them yet? :)&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12dg9oy", "is_robot_indexable": true, "report_reasons": null, "author": "intranca", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12dg9oy/testing_azure_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12dg9oy/testing_azure_data_pipelines/", "subreddit_subscribers": 96514, "created_utc": 1680778182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, i have a production airflow orchestrating 4 clusters on pre 2.0 version. Our scheduler is dying constantly and no one knows why.\n\nWe have over 500k entries in x-com table, and probably as much in other tables, so our db has probably never been cleaned. I belive that to be slowing us, among other things, but senior engineer in charge of my team said its not the case ( guy is known for not caring too much). \n\nAny expert here to confirm or deny this? We have a ton of other bad practices, but this would be the quickest to clean up for sure.", "author_fullname": "t2_4smbd7xs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow meta-db cleaning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12df018", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680774766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, i have a production airflow orchestrating 4 clusters on pre 2.0 version. Our scheduler is dying constantly and no one knows why.&lt;/p&gt;\n\n&lt;p&gt;We have over 500k entries in x-com table, and probably as much in other tables, so our db has probably never been cleaned. I belive that to be slowing us, among other things, but senior engineer in charge of my team said its not the case ( guy is known for not caring too much). &lt;/p&gt;\n\n&lt;p&gt;Any expert here to confirm or deny this? We have a ton of other bad practices, but this would be the quickest to clean up for sure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12df018", "is_robot_indexable": true, "report_reasons": null, "author": "Sneakyfrog112", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12df018/airflow_metadb_cleaning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12df018/airflow_metadb_cleaning/", "subreddit_subscribers": 96514, "created_utc": 1680774766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering, \n\nI been tasked with setting up a new environment for my teams processing. We have quite a few restrictions which makes it hard to narrow in on a good plan for our use case.\n\nCurrently my team uses on-prem SAS that can no longer handle the load and the discussions with IT seem to indicate that we will never get a new server so we need to piggyback off an existing environment used by other teams, that is basically locked down (no internet) windows VMs (64GB 8 cores can maybe get bigger) on the cloud with databricks connected to them.\n\nthe environment limitations / processing details:\n\n* Must be python, dont have permission to use another language except maybe sql\n* Solution that is available on PYPI repository only and will be installing it offline with anaconda. \n* cant install external executables\n* We do mostly small batch processing jobs usually small &lt;10GB but occasionally some large 100-200GB batch processing. \n* We need to output as csvs.\n\nSo far I am weighing between the following options and am happy to hear other thoughts and opinions:\n\n* Spark, (can use local spark for small jobs and use databricks for any large jobs) \n* Pandas (I worry it will die with the larger datasets)\n* Polars (I havent used this before but heard it is a better replacement for pandas)\n* Dask (I assume it will eliminate the problems of pandas?)\n\nI would like to see something with pipe lining options, maybe a local dagster?\n\n&amp;#x200B;\n\nAnyway thanks for reading this far, I hope someone has some suggestions, right now I am thinking that I am fucked with all the limitations put on me.", "author_fullname": "t2_3x579bn9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with deciding data-eng stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12e43ql", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680828737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;, &lt;/p&gt;\n\n&lt;p&gt;I been tasked with setting up a new environment for my teams processing. We have quite a few restrictions which makes it hard to narrow in on a good plan for our use case.&lt;/p&gt;\n\n&lt;p&gt;Currently my team uses on-prem SAS that can no longer handle the load and the discussions with IT seem to indicate that we will never get a new server so we need to piggyback off an existing environment used by other teams, that is basically locked down (no internet) windows VMs (64GB 8 cores can maybe get bigger) on the cloud with databricks connected to them.&lt;/p&gt;\n\n&lt;p&gt;the environment limitations / processing details:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Must be python, dont have permission to use another language except maybe sql&lt;/li&gt;\n&lt;li&gt;Solution that is available on PYPI repository only and will be installing it offline with anaconda. &lt;/li&gt;\n&lt;li&gt;cant install external executables&lt;/li&gt;\n&lt;li&gt;We do mostly small batch processing jobs usually small &amp;lt;10GB but occasionally some large 100-200GB batch processing. &lt;/li&gt;\n&lt;li&gt;We need to output as csvs.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So far I am weighing between the following options and am happy to hear other thoughts and opinions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Spark, (can use local spark for small jobs and use databricks for any large jobs) &lt;/li&gt;\n&lt;li&gt;Pandas (I worry it will die with the larger datasets)&lt;/li&gt;\n&lt;li&gt;Polars (I havent used this before but heard it is a better replacement for pandas)&lt;/li&gt;\n&lt;li&gt;Dask (I assume it will eliminate the problems of pandas?)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I would like to see something with pipe lining options, maybe a local dagster?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Anyway thanks for reading this far, I hope someone has some suggestions, right now I am thinking that I am fucked with all the limitations put on me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12e43ql", "is_robot_indexable": true, "report_reasons": null, "author": "Mclovine_aus", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12e43ql/help_with_deciding_dataeng_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12e43ql/help_with_deciding_dataeng_stack/", "subreddit_subscribers": 96514, "created_utc": 1680828737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI am working on designing the architecture of a web app that is going to ask a bunch of input parameters from the user and perform joins, filters and aggregations on BigQuery.\n\nMy first idea was to have a flask app for the web part. Request comes in from the user, flask runs the function that pulls data from BQ and we process the data locally.\n\nHowever, this does not seem to be very performant. I would like to avoid having to read/write large tables into BigQuery so I am looking for a SQL-based solution. \n\nI am already using dbt for other projects but I am wondering if it really suits this use-case. \n\nI did stumble upon dbt server that would be able to run dbt operations in response to API Requests, but don't know how it would scale.\n\nAny thoughts ?", "author_fullname": "t2_kqzh0kz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data processing and web app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dl8qj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680789584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am working on designing the architecture of a web app that is going to ask a bunch of input parameters from the user and perform joins, filters and aggregations on BigQuery.&lt;/p&gt;\n\n&lt;p&gt;My first idea was to have a flask app for the web part. Request comes in from the user, flask runs the function that pulls data from BQ and we process the data locally.&lt;/p&gt;\n\n&lt;p&gt;However, this does not seem to be very performant. I would like to avoid having to read/write large tables into BigQuery so I am looking for a SQL-based solution. &lt;/p&gt;\n\n&lt;p&gt;I am already using dbt for other projects but I am wondering if it really suits this use-case. &lt;/p&gt;\n\n&lt;p&gt;I did stumble upon dbt server that would be able to run dbt operations in response to API Requests, but don&amp;#39;t know how it would scale.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12dl8qj", "is_robot_indexable": true, "report_reasons": null, "author": "JamieA28", "discussion_type": null, "num_comments": 6, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12dl8qj/data_processing_and_web_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12dl8qj/data_processing_and_web_app/", "subreddit_subscribers": 96514, "created_utc": 1680789584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "title says it all", "author_fullname": "t2_vm5kbtxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is dbt + athena/presto a viable stack? how do you orchestrate creation and maintenance of your athena/presto tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12ee6bw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680855655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title says it all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ee6bw", "is_robot_indexable": true, "report_reasons": null, "author": "srevolve", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ee6bw/is_dbt_athenapresto_a_viable_stack_how_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ee6bw/is_dbt_athenapresto_a_viable_stack_how_do_you/", "subreddit_subscribers": 96514, "created_utc": 1680855655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys. Hope you are all doing well. I am on my way to switch to DE from BI engineer position. Is there any option to find a mentor here, with whom I can have a call for once a couple weeks for example  and discuss my progress and maybe get some learning exercises? \nI already know some python, Linux, tableau, sql, GCS.\n\nThank you", "author_fullname": "t2_6zhipiyk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for data engineering mentorship", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12e9jt7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680841290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys. Hope you are all doing well. I am on my way to switch to DE from BI engineer position. Is there any option to find a mentor here, with whom I can have a call for once a couple weeks for example  and discuss my progress and maybe get some learning exercises? \nI already know some python, Linux, tableau, sql, GCS.&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12e9jt7", "is_robot_indexable": true, "report_reasons": null, "author": "Euphoric-Worker-8516", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12e9jt7/looking_for_data_engineering_mentorship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12e9jt7/looking_for_data_engineering_mentorship/", "subreddit_subscribers": 96514, "created_utc": 1680841290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The title says everything.Just find Apache Airflow fascinating but I cannot run it locally. Any idea where I can experiment it on the cloud? Almost every other post in this sub is on Airflow/Dagster.   \n\n\nFor example - We have replit to experiment on Python or other programming languages, so is there a similar infra for Airflow/Dagster?", "author_fullname": "t2_6hp3gp78", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I experiment with Apache Airflow without running it locally?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ecrzm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680850948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The title says everything.Just find Apache Airflow fascinating but I cannot run it locally. Any idea where I can experiment it on the cloud? Almost every other post in this sub is on Airflow/Dagster.   &lt;/p&gt;\n\n&lt;p&gt;For example - We have replit to experiment on Python or other programming languages, so is there a similar infra for Airflow/Dagster?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ecrzm", "is_robot_indexable": true, "report_reasons": null, "author": "rohetoric", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ecrzm/where_can_i_experiment_with_apache_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ecrzm/where_can_i_experiment_with_apache_airflow/", "subreddit_subscribers": 96514, "created_utc": 1680850948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have to tokenize some sensitive columns in my data warehouse. However, the tokenization needs to be format preserving so that business users can still carry our analysis without any issues. Are there any standard format preserving tokenization algorithm that I can use out of box or should I write my own custom tokenization algorithm?", "author_fullname": "t2_virernyk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any standard format preserving tokenization algorithm that we can use out of box?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dnhpn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680794354.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have to tokenize some sensitive columns in my data warehouse. However, the tokenization needs to be format preserving so that business users can still carry our analysis without any issues. Are there any standard format preserving tokenization algorithm that I can use out of box or should I write my own custom tokenization algorithm?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12dnhpn", "is_robot_indexable": true, "report_reasons": null, "author": "Hitoxi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12dnhpn/are_there_any_standard_format_preserving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12dnhpn/are_there_any_standard_format_preserving/", "subreddit_subscribers": 96514, "created_utc": 1680794354.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Google BigQuery documentation discourages single row inserts (commonly needed in applications), since BigQuery is supposed to be used for bulk updates. ([Source](https://cloud.google.com/bigquery/docs/best-practices-performance-patterns#dml_statements_that_update_or_insert_single_rows)).\n\nFrom the documentation, they suggest that you instead can use Cloud SQL with federated queries, which [enables BigQuery to query data from the Cloud SQL database.](https://cloud.google.com/bigquery/docs/cloud-sql-federated-queries). However, the data ends up being stored in a traditional database, like MySQL, instead of BigQuery and loses thereby some features (I would imagine ???).\n\nAs an alternative, I thought about using redis as a \"man-in-the-middle\" to batch analytics data from the application (or multiple applications when deployed in a cluster), and then insert those every X minutes (as a load job, or is stream better???) into BigQuery.\nI can't seem to find many sources that mention such an approach, and I was wondering why not? Are there disadvantages that I'm not aware of which makes Cloud SQL a better choice in this situation?", "author_fullname": "t2_n726hnv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using redis to batch data from various sources and then bulk insert into BigQuery, is this common?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dh2ht", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680780174.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Google BigQuery documentation discourages single row inserts (commonly needed in applications), since BigQuery is supposed to be used for bulk updates. (&lt;a href=\"https://cloud.google.com/bigquery/docs/best-practices-performance-patterns#dml_statements_that_update_or_insert_single_rows\"&gt;Source&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;From the documentation, they suggest that you instead can use Cloud SQL with federated queries, which &lt;a href=\"https://cloud.google.com/bigquery/docs/cloud-sql-federated-queries\"&gt;enables BigQuery to query data from the Cloud SQL database.&lt;/a&gt;. However, the data ends up being stored in a traditional database, like MySQL, instead of BigQuery and loses thereby some features (I would imagine ???).&lt;/p&gt;\n\n&lt;p&gt;As an alternative, I thought about using redis as a &amp;quot;man-in-the-middle&amp;quot; to batch analytics data from the application (or multiple applications when deployed in a cluster), and then insert those every X minutes (as a load job, or is stream better???) into BigQuery.\nI can&amp;#39;t seem to find many sources that mention such an approach, and I was wondering why not? Are there disadvantages that I&amp;#39;m not aware of which makes Cloud SQL a better choice in this situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?auto=webp&amp;v=enabled&amp;s=20d96e49b41bb7bd00ff56b8e9ed66dc6ed60231", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cefbc38d0f527d52311150f3e2a5ee0cd4294045", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=23a8451c1ff5cb4b86d4b12437a301825fbdeb9f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ac4fd116586a05dcece0cf47055879bc2ac44aa", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=467e1aba873015b34b1a4e2b7b44a79b2ab7343c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f90c3f55c5ad89d8d04390c2907361929ba9d300", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/cmUpHS82A2NmQUetG5xkM6py3mx8MKKYEYyam7WGO4M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2c9d97288732e216db7689a964c326a90bdbe29", "width": 1080, "height": 567}], "variants": {}, "id": "DsiOIzUSicS_9zIKwMDQbNT2LOE1o29sSYs49HAmO_k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12dh2ht", "is_robot_indexable": true, "report_reasons": null, "author": "Fit-Swordfish-5533", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12dh2ht/using_redis_to_batch_data_from_various_sources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12dh2ht/using_redis_to_batch_data_from_various_sources/", "subreddit_subscribers": 96514, "created_utc": 1680780174.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a codesignal test due in 2 weeks for a senior data engineer position. Has anyone taken one before and remembers what kind of questions they got? I feel like if I desensitized myself and not freakout about the question I can do really well \ud83d\ude02", "author_fullname": "t2_1p47iyvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Codesignal test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ecp7g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680850710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a codesignal test due in 2 weeks for a senior data engineer position. Has anyone taken one before and remembers what kind of questions they got? I feel like if I desensitized myself and not freakout about the question I can do really well \ud83d\ude02&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12ecp7g", "is_robot_indexable": true, "report_reasons": null, "author": "rhymeswithloop92", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ecp7g/codesignal_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ecp7g/codesignal_test/", "subreddit_subscribers": 96514, "created_utc": 1680850710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, a junior here and would appreciate your help. I came across this binary encoding  v.s. textual encoding concept in the book \"Designing Data-Intensive App\". It talks about how binary encoding can save more space than textual JSON encoding. My questions are: \n\n1. Since everything is stored as 0/1, wouldn't textual JSON encoding actually stores as binary as well? \n\n2. How could binary encoding actually saves space? Assuming we have this JSON {\"userName\": \"Martin\"}. \n\n* If we do binary encoding, we'd need to store (a) #of fields in this object, (b) field type and length, in this case, string as field type and length = 8. (c) the string userName itself in binary, (d) value type and length, in this case, string as value type and length = 6, and (e) the string Martin itselt in binary.  \n* However, if we do textual JSON encoding, won't we need to do (a)-(e) just like above too? So how would binary encoding actually save space?\n\n&amp;#x200B;\n\nThanks all for your help.", "author_fullname": "t2_szomhuik", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Binary Encoding &amp; Textual Encoding", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12e65p3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680833367.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, a junior here and would appreciate your help. I came across this binary encoding  v.s. textual encoding concept in the book &amp;quot;Designing Data-Intensive App&amp;quot;. It talks about how binary encoding can save more space than textual JSON encoding. My questions are: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Since everything is stored as 0/1, wouldn&amp;#39;t textual JSON encoding actually stores as binary as well? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How could binary encoding actually saves space? Assuming we have this JSON {&amp;quot;userName&amp;quot;: &amp;quot;Martin&amp;quot;}. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;If we do binary encoding, we&amp;#39;d need to store (a) #of fields in this object, (b) field type and length, in this case, string as field type and length = 8. (c) the string userName itself in binary, (d) value type and length, in this case, string as value type and length = 6, and (e) the string Martin itselt in binary.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;However, if we do textual JSON encoding, won&amp;#39;t we need to do (a)-(e) just like above too? So how would binary encoding actually save space?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks all for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12e65p3", "is_robot_indexable": true, "report_reasons": null, "author": "TendMyOwnGarden", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12e65p3/binary_encoding_textual_encoding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12e65p3/binary_encoding_textual_encoding/", "subreddit_subscribers": 96514, "created_utc": 1680833367.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there anyway to set file sizes on write to 128mb without using coalesce() or repartition()?\n\nBtw, I\u2019m also interested in answers that use glue syntax aswell as pyspark.", "author_fullname": "t2_5fmit0v9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark, Glue and Small/Big files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dot4u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680796980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there anyway to set file sizes on write to 128mb without using coalesce() or repartition()?&lt;/p&gt;\n\n&lt;p&gt;Btw, I\u2019m also interested in answers that use glue syntax aswell as pyspark.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12dot4u", "is_robot_indexable": true, "report_reasons": null, "author": "gabbom_XCII", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12dot4u/spark_glue_and_smallbig_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12dot4u/spark_glue_and_smallbig_files/", "subreddit_subscribers": 96514, "created_utc": 1680796980.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, colorfulskull here. I'm a 3y swe, now moving into a de path in a mid-size startup. So, I've been working with several data scientists and analysts who love using Jupyter notebooks. I mean, I get it \u2013 they're great for prototyping, and it's so fast and easy to get results. But as someone who prefers working in a proper IDE and dev environment, I'm finding it hard when we move towards production. It's like going from smooth sailing to navigating a minefield!\n\nSo, I'm reaching out to the r/dataengineering ecosystem for guidance. What are some best practices you've found for working with notebooks, especially when moving towards production? Someone recommended me projects like nbdev, but not sure if that is the right path the follow. How do you strike a balance between the flexibility of notebooks and the structure of a traditional development environment?  Want to make sure I'm not taking the wrong steps, what are some blogs/individuals/newsletters that I should follow?\n\nI dumped all the questions I have in one post, hope it's not a bother. I'd love to hear your thoughts and experiences \ud83d\ude04\ud83d\ude80\ud83d\udcda", "author_fullname": "t2_43r4n5ss", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "tough time with notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dn7ej", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680793767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, colorfulskull here. I&amp;#39;m a 3y swe, now moving into a de path in a mid-size startup. So, I&amp;#39;ve been working with several data scientists and analysts who love using Jupyter notebooks. I mean, I get it \u2013 they&amp;#39;re great for prototyping, and it&amp;#39;s so fast and easy to get results. But as someone who prefers working in a proper IDE and dev environment, I&amp;#39;m finding it hard when we move towards production. It&amp;#39;s like going from smooth sailing to navigating a minefield!&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m reaching out to the &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; ecosystem for guidance. What are some best practices you&amp;#39;ve found for working with notebooks, especially when moving towards production? Someone recommended me projects like nbdev, but not sure if that is the right path the follow. How do you strike a balance between the flexibility of notebooks and the structure of a traditional development environment?  Want to make sure I&amp;#39;m not taking the wrong steps, what are some blogs/individuals/newsletters that I should follow?&lt;/p&gt;\n\n&lt;p&gt;I dumped all the questions I have in one post, hope it&amp;#39;s not a bother. I&amp;#39;d love to hear your thoughts and experiences \ud83d\ude04\ud83d\ude80\ud83d\udcda&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12dn7ej", "is_robot_indexable": true, "report_reasons": null, "author": "colorfulskull", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12dn7ej/tough_time_with_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12dn7ej/tough_time_with_notebooks/", "subreddit_subscribers": 96514, "created_utc": 1680793767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ay1q1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Arrow String improvements in Pandas/Dask DataFrames", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "name": "t3_12djy0h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6uwjML35z-FxsE_pRboam-GDwq291V8TrPtVWQof1WA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680786747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/coiled-hq/pyarrow-strings-in-dask-dataframes-55a0c4871586", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ze7rRKl1l71HThxnJOHJpIfrgdSKrEysX-TeVWvy3aU.jpg?auto=webp&amp;v=enabled&amp;s=6859023178db536f94b55bb63382a7a09109032b", "width": 792, "height": 490}, "resolutions": [{"url": "https://external-preview.redd.it/Ze7rRKl1l71HThxnJOHJpIfrgdSKrEysX-TeVWvy3aU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9618b07d38c42c9b44e92644148b22822523cd9e", "width": 108, "height": 66}, {"url": "https://external-preview.redd.it/Ze7rRKl1l71HThxnJOHJpIfrgdSKrEysX-TeVWvy3aU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e340c81948a4fba6552f26b728af8711788bc35", "width": 216, "height": 133}, {"url": "https://external-preview.redd.it/Ze7rRKl1l71HThxnJOHJpIfrgdSKrEysX-TeVWvy3aU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ac1c66e5bf7be22194afbe2e088a490ce2f46dd", "width": 320, "height": 197}, {"url": "https://external-preview.redd.it/Ze7rRKl1l71HThxnJOHJpIfrgdSKrEysX-TeVWvy3aU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d4cd149bae3ae18eb7da5790f10a0c5f43a190ed", "width": 640, "height": 395}], "variants": {}, "id": "V5FocKkZS3WgTL0zjz6iujrafykJdPf8Om_OTahpOug"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "12djy0h", "is_robot_indexable": true, "report_reasons": null, "author": "mrocklin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12djy0h/arrow_string_improvements_in_pandasdask_dataframes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/coiled-hq/pyarrow-strings-in-dask-dataframes-55a0c4871586", "subreddit_subscribers": 96514, "created_utc": 1680786747.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}