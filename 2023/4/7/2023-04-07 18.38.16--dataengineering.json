{"kind": "Listing", "data": {"after": "t3_12eg82n", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hf9ddayj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineers processing data access requests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "name": "t3_12ekdv2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 102, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 102, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/PwQFpnI6ohAOk8a2oHExRt5VPPNiNCh0lB3wSKRXgPM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680872041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/fvhpekkylgsa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/fvhpekkylgsa1.png?auto=webp&amp;v=enabled&amp;s=3d488123b490adb09b02b89bf0062491807eb3a7", "width": 1566, "height": 1096}, "resolutions": [{"url": "https://preview.redd.it/fvhpekkylgsa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e723ffde2298b53be5040ca50cd3fa857d8cddd6", "width": 108, "height": 75}, {"url": "https://preview.redd.it/fvhpekkylgsa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dad4b60ee7905425f32c05d87fc14462894faa9b", "width": 216, "height": 151}, {"url": "https://preview.redd.it/fvhpekkylgsa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4acec0efae2a9d17c5d774ba1e561901f29f158e", "width": 320, "height": 223}, {"url": "https://preview.redd.it/fvhpekkylgsa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2933de1a74c8bd7130551f9d2351a29612fe36d", "width": 640, "height": 447}, {"url": "https://preview.redd.it/fvhpekkylgsa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c972504627d1b0844729ccf54b5b5183bcc45c04", "width": 960, "height": 671}, {"url": "https://preview.redd.it/fvhpekkylgsa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba3a61733592d6c7ee91b71476a7fd4e9fb8c9aa", "width": 1080, "height": 755}], "variants": {}, "id": "DY6enitmFwWz8hoYEQaE_nDciegvG14Wmu3A3m0BEUU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "12ekdv2", "is_robot_indexable": true, "report_reasons": null, "author": "Bart_Vee", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ekdv2/data_engineers_processing_data_access_requests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/fvhpekkylgsa1.png", "subreddit_subscribers": 96630, "created_utc": 1680872041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working as a junior engineer for 9 months now at a consultancy, and I have to say, it's been a real struggle. Up to now, I've worked on 3 projects and I've struggled on each one. I struggle with the expectation that my company has for me to deliver. I understand I need to deliver, but it feels like I'm stuck in a vicious circle.\n\nAll of the cloud stuff, sql, and pipelines are new to me. Each project has lasted 2 or 3 months and by the time I'm comfortable and started to deliver, the project is over. In my spare time, I do plenty of tutorials to get myself up to speed, but it seems like all the personal work I do is not relevant to the project work that I'm doing because it's s so specific. Majority of the time I'm depending on my fellow engineers to help me out. I can honestly say, that I've only completed a handful of tickets by myself and I feel ashamed of it. They expect me to deliver when I simply don't know. I honestly feel like a burden on every team that I'm on.\n\nToday I had a 1-1 with my manager and he said that people on my previous project complained about my lack of contribution and how they weren't able to bill for their work because they were helping me. This was a shock because none of my colleagues expressed this to me while I was there.\n\nMy manager decided to do a 'PIP' (Performance Improvement Plan) to get me to improve. I've told my manager that I need to be on a project that is 6 months to a year-long but he keeps saying there isn't one. I feel kinda sad that he's put me on an informal disciplinary thing. He kept on saying that it was nothing, but I know it will be used against me if I don't improve. \n\nI feel like I'm alone and don't know what to do. Am I just kidding myself that I'm an engineer?", "author_fullname": "t2_81mnb4wb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shall I accept that I'm a useless engineer and look somewhere else or is this feeling part of the journey?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12e0lti", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680820742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working as a junior engineer for 9 months now at a consultancy, and I have to say, it&amp;#39;s been a real struggle. Up to now, I&amp;#39;ve worked on 3 projects and I&amp;#39;ve struggled on each one. I struggle with the expectation that my company has for me to deliver. I understand I need to deliver, but it feels like I&amp;#39;m stuck in a vicious circle.&lt;/p&gt;\n\n&lt;p&gt;All of the cloud stuff, sql, and pipelines are new to me. Each project has lasted 2 or 3 months and by the time I&amp;#39;m comfortable and started to deliver, the project is over. In my spare time, I do plenty of tutorials to get myself up to speed, but it seems like all the personal work I do is not relevant to the project work that I&amp;#39;m doing because it&amp;#39;s s so specific. Majority of the time I&amp;#39;m depending on my fellow engineers to help me out. I can honestly say, that I&amp;#39;ve only completed a handful of tickets by myself and I feel ashamed of it. They expect me to deliver when I simply don&amp;#39;t know. I honestly feel like a burden on every team that I&amp;#39;m on.&lt;/p&gt;\n\n&lt;p&gt;Today I had a 1-1 with my manager and he said that people on my previous project complained about my lack of contribution and how they weren&amp;#39;t able to bill for their work because they were helping me. This was a shock because none of my colleagues expressed this to me while I was there.&lt;/p&gt;\n\n&lt;p&gt;My manager decided to do a &amp;#39;PIP&amp;#39; (Performance Improvement Plan) to get me to improve. I&amp;#39;ve told my manager that I need to be on a project that is 6 months to a year-long but he keeps saying there isn&amp;#39;t one. I feel kinda sad that he&amp;#39;s put me on an informal disciplinary thing. He kept on saying that it was nothing, but I know it will be used against me if I don&amp;#39;t improve. &lt;/p&gt;\n\n&lt;p&gt;I feel like I&amp;#39;m alone and don&amp;#39;t know what to do. Am I just kidding myself that I&amp;#39;m an engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12e0lti", "is_robot_indexable": true, "report_reasons": null, "author": "Taurusamazing92", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12e0lti/shall_i_accept_that_im_a_useless_engineer_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12e0lti/shall_i_accept_that_im_a_useless_engineer_and/", "subreddit_subscribers": 96630, "created_utc": 1680820742.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're already accustomed to hearing people say \"this is how YOU should use chatGPT\", but I rarely see people say \"This is how I use chat gpt.\"  \n\n\nIf you've got first hand experience using chat GPT to add legitimate value as a data engineer, I'd love to hear about it!", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How has ChatGPT helped you in your DE job? First hand experience only, plz.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dwoe3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680812476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re already accustomed to hearing people say &amp;quot;this is how YOU should use chatGPT&amp;quot;, but I rarely see people say &amp;quot;This is how I use chat gpt.&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve got first hand experience using chat GPT to add legitimate value as a data engineer, I&amp;#39;d love to hear about it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12dwoe3", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 113, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12dwoe3/how_has_chatgpt_helped_you_in_your_de_job_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12dwoe3/how_has_chatgpt_helped_you_in_your_de_job_first/", "subreddit_subscribers": 96630, "created_utc": 1680812476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI have seen a lot of posts regarding the use cases of Docker but not really any on how it actually works on a functional level. Many mention that it is great for dependency issues (one version of Python required for one process vs another) but how does Docker actually solve for this?", "author_fullname": "t2_jr18wyyz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker - Magic or Hype?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dteg3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680814420.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680806003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I have seen a lot of posts regarding the use cases of Docker but not really any on how it actually works on a functional level. Many mention that it is great for dependency issues (one version of Python required for one process vs another) but how does Docker actually solve for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12dteg3", "is_robot_indexable": true, "report_reasons": null, "author": "Fintechie__", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12dteg3/docker_magic_or_hype/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12dteg3/docker_magic_or_hype/", "subreddit_subscribers": 96630, "created_utc": 1680806003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I haven\u2019t done too many technical interviews for DE (&lt;20). Normally I get questions that i can do pretty easily. Things like: modeling, \u201chow would you build this pipeline?\u201d, basic SQL/Python, cloud services/data warehousing. \n\nToday I got put into a live coding interview unexpectedly, and was asked to get data from an API and do some transformations against it. The solution involved using requests library and doing some json loading/parsing. For the transformation it involved using the pivot function in python.\n\nI was completely caught off guard, as I haven\u2019t done the above in a while and my mind sort of blanked. \n\nIs this something that I should have known how to do easily?", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would you be able to do this on the spot during an interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12e589j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680831292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I haven\u2019t done too many technical interviews for DE (&amp;lt;20). Normally I get questions that i can do pretty easily. Things like: modeling, \u201chow would you build this pipeline?\u201d, basic SQL/Python, cloud services/data warehousing. &lt;/p&gt;\n\n&lt;p&gt;Today I got put into a live coding interview unexpectedly, and was asked to get data from an API and do some transformations against it. The solution involved using requests library and doing some json loading/parsing. For the transformation it involved using the pivot function in python.&lt;/p&gt;\n\n&lt;p&gt;I was completely caught off guard, as I haven\u2019t done the above in a while and my mind sort of blanked. &lt;/p&gt;\n\n&lt;p&gt;Is this something that I should have known how to do easily?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12e589j", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12e589j/would_you_be_able_to_do_this_on_the_spot_during/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12e589j/would_you_be_able_to_do_this_on_the_spot_during/", "subreddit_subscribers": 96630, "created_utc": 1680831292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The title says everything.Just find Apache Airflow fascinating but I cannot run it locally. Any idea where I can experiment it on the cloud? Almost every other post in this sub is on Airflow/Dagster.   \n\n\nFor example - We have replit to experiment on Python or other programming languages, so is there a similar infra for Airflow/Dagster?", "author_fullname": "t2_6hp3gp78", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I experiment with Apache Airflow without running it locally?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ecrzm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680850948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The title says everything.Just find Apache Airflow fascinating but I cannot run it locally. Any idea where I can experiment it on the cloud? Almost every other post in this sub is on Airflow/Dagster.   &lt;/p&gt;\n\n&lt;p&gt;For example - We have replit to experiment on Python or other programming languages, so is there a similar infra for Airflow/Dagster?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ecrzm", "is_robot_indexable": true, "report_reasons": null, "author": "rohetoric", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ecrzm/where_can_i_experiment_with_apache_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ecrzm/where_can_i_experiment_with_apache_airflow/", "subreddit_subscribers": 96630, "created_utc": 1680850948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since joining a Bay Area tech company, I have realized the grind to keep up with all the new tools in software engineering is alot. I am 35 and realizing it takes too much time commitment to keep up after work. Even as a data engineering manager, I am expected to know all the new skills and tools. What other roles align to a data engineering background? Product roles for data platforms? I like working with the business.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Change?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12e6iqp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680834164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since joining a Bay Area tech company, I have realized the grind to keep up with all the new tools in software engineering is alot. I am 35 and realizing it takes too much time commitment to keep up after work. Even as a data engineering manager, I am expected to know all the new skills and tools. What other roles align to a data engineering background? Product roles for data platforms? I like working with the business.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12e6iqp", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12e6iqp/career_change/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12e6iqp/career_change/", "subreddit_subscribers": 96630, "created_utc": 1680834164.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm just an average (perhaps below average) data engineer. I have read many posts in this subreddit daily (other sources also) and have seen many visions from you guys. I want to contribute something, but have nothing to share. So I share this article (I have just read that minutes ago):  \n[https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c](https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c)  \nAt first I was mind-blown, and thought of creating a repo built on top ChatGPT to extract, transform data. My dream collapsed right afterwards, after knowing the existence of AWS Aurora.[https://aws.amazon.com/about-aws/whats-new/2022/11/amazon-aurora-zero-etl-integration-redshift/](https://aws.amazon.com/about-aws/whats-new/2022/11/amazon-aurora-zero-etl-integration-redshift/)  \nHowever, i'm still get excited due to this. If the data is relatively simply structured, this would be extremely handy. Otherwise, ETL/ELT pipelines are still needed. Other pros and cons of zero-ETL are also mentioned in the above towardsdatascience article.  \nWhat are your thoughts about this?", "author_fullname": "t2_4exoz3kf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The future of less ETL-data-pipeline building", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12eg4ty", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680862065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m just an average (perhaps below average) data engineer. I have read many posts in this subreddit daily (other sources also) and have seen many visions from you guys. I want to contribute something, but have nothing to share. So I share this article (I have just read that minutes ago):&lt;br/&gt;\n&lt;a href=\"https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c\"&gt;https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&lt;/a&gt;&lt;br/&gt;\nAt first I was mind-blown, and thought of creating a repo built on top ChatGPT to extract, transform data. My dream collapsed right afterwards, after knowing the existence of AWS Aurora.&lt;a href=\"https://aws.amazon.com/about-aws/whats-new/2022/11/amazon-aurora-zero-etl-integration-redshift/\"&gt;https://aws.amazon.com/about-aws/whats-new/2022/11/amazon-aurora-zero-etl-integration-redshift/&lt;/a&gt;&lt;br/&gt;\nHowever, i&amp;#39;m still get excited due to this. If the data is relatively simply structured, this would be extremely handy. Otherwise, ETL/ELT pipelines are still needed. Other pros and cons of zero-ETL are also mentioned in the above towardsdatascience article.&lt;br/&gt;\nWhat are your thoughts about this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xSB-VRAG8K0EqeEJx3raBuXgYpw50BJqz4xHJE_81c8.jpg?auto=webp&amp;v=enabled&amp;s=ec51b72c1edf8ba4f8dc0eb8bbd0887c5a10bbdd", "width": 1200, "height": 543}, "resolutions": [{"url": "https://external-preview.redd.it/xSB-VRAG8K0EqeEJx3raBuXgYpw50BJqz4xHJE_81c8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1e8c9fd48223781443d8c46be48ab920179e2b7", "width": 108, "height": 48}, {"url": "https://external-preview.redd.it/xSB-VRAG8K0EqeEJx3raBuXgYpw50BJqz4xHJE_81c8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=382e0f4f2c49bf8cf0e3b3aa4d813e621e21cb1b", "width": 216, "height": 97}, {"url": "https://external-preview.redd.it/xSB-VRAG8K0EqeEJx3raBuXgYpw50BJqz4xHJE_81c8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ddedb3f7dfc408418a63076bae0756ac336c924", "width": 320, "height": 144}, {"url": "https://external-preview.redd.it/xSB-VRAG8K0EqeEJx3raBuXgYpw50BJqz4xHJE_81c8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e8423f80288e2ce8684080fb040aba5768a2f39", "width": 640, "height": 289}, {"url": "https://external-preview.redd.it/xSB-VRAG8K0EqeEJx3raBuXgYpw50BJqz4xHJE_81c8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db543297d3c099db0127a0b2f21eaec818bce132", "width": 960, "height": 434}, {"url": "https://external-preview.redd.it/xSB-VRAG8K0EqeEJx3raBuXgYpw50BJqz4xHJE_81c8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3176ee720d2a0710d0cbc971054c316ad001141", "width": 1080, "height": 488}], "variants": {}, "id": "NUV7jTZprOTDG09SohaAm32t7mHuSpgMRI6ybLu37-E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12eg4ty", "is_robot_indexable": true, "report_reasons": null, "author": "duohd", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12eg4ty/the_future_of_less_etldatapipeline_building/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12eg4ty/the_future_of_less_etldatapipeline_building/", "subreddit_subscribers": 96630, "created_utc": 1680862065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering, \n\nI been tasked with setting up a new environment for my teams processing. We have quite a few restrictions which makes it hard to narrow in on a good plan for our use case.\n\nCurrently my team uses on-prem SAS that can no longer handle the load and the discussions with IT seem to indicate that we will never get a new server so we need to piggyback off an existing environment used by other teams, that is basically locked down (no internet) windows VMs (64GB 8 cores can maybe get bigger) on the cloud with databricks connected to them.\n\nthe environment limitations / processing details:\n\n* Must be python, dont have permission to use another language except maybe sql\n* Solution that is available on PYPI repository only and will be installing it offline with anaconda. \n* cant install external executables\n* We do mostly small batch processing jobs usually small &lt;10GB but occasionally some large 100-200GB batch processing. \n* We need to output as csvs.\n\nSo far I am weighing between the following options and am happy to hear other thoughts and opinions:\n\n* Spark, (can use local spark for small jobs and use databricks for any large jobs) \n* Pandas (I worry it will die with the larger datasets)\n* Polars (I havent used this before but heard it is a better replacement for pandas)\n* Dask (I assume it will eliminate the problems of pandas?)\n\nI would like to see something with pipe lining options, maybe a local dagster?\n\n&amp;#x200B;\n\nAnyway thanks for reading this far, I hope someone has some suggestions, right now I am thinking that I am fucked with all the limitations put on me.", "author_fullname": "t2_3x579bn9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with deciding data-eng stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12e43ql", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680828737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;, &lt;/p&gt;\n\n&lt;p&gt;I been tasked with setting up a new environment for my teams processing. We have quite a few restrictions which makes it hard to narrow in on a good plan for our use case.&lt;/p&gt;\n\n&lt;p&gt;Currently my team uses on-prem SAS that can no longer handle the load and the discussions with IT seem to indicate that we will never get a new server so we need to piggyback off an existing environment used by other teams, that is basically locked down (no internet) windows VMs (64GB 8 cores can maybe get bigger) on the cloud with databricks connected to them.&lt;/p&gt;\n\n&lt;p&gt;the environment limitations / processing details:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Must be python, dont have permission to use another language except maybe sql&lt;/li&gt;\n&lt;li&gt;Solution that is available on PYPI repository only and will be installing it offline with anaconda. &lt;/li&gt;\n&lt;li&gt;cant install external executables&lt;/li&gt;\n&lt;li&gt;We do mostly small batch processing jobs usually small &amp;lt;10GB but occasionally some large 100-200GB batch processing. &lt;/li&gt;\n&lt;li&gt;We need to output as csvs.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So far I am weighing between the following options and am happy to hear other thoughts and opinions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Spark, (can use local spark for small jobs and use databricks for any large jobs) &lt;/li&gt;\n&lt;li&gt;Pandas (I worry it will die with the larger datasets)&lt;/li&gt;\n&lt;li&gt;Polars (I havent used this before but heard it is a better replacement for pandas)&lt;/li&gt;\n&lt;li&gt;Dask (I assume it will eliminate the problems of pandas?)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I would like to see something with pipe lining options, maybe a local dagster?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Anyway thanks for reading this far, I hope someone has some suggestions, right now I am thinking that I am fucked with all the limitations put on me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12e43ql", "is_robot_indexable": true, "report_reasons": null, "author": "Mclovine_aus", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12e43ql/help_with_deciding_dataeng_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12e43ql/help_with_deciding_dataeng_stack/", "subreddit_subscribers": 96630, "created_utc": 1680828737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "title says it all", "author_fullname": "t2_vm5kbtxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is dbt + athena/presto a viable stack? how do you orchestrate creation and maintenance of your athena/presto tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ee6bw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680855655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title says it all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ee6bw", "is_robot_indexable": true, "report_reasons": null, "author": "srevolve", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ee6bw/is_dbt_athenapresto_a_viable_stack_how_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ee6bw/is_dbt_athenapresto_a_viable_stack_how_do_you/", "subreddit_subscribers": 96630, "created_utc": 1680855655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got large file, about 20GB as a parquet and 300GB as an unsorted csv. I'd like to sort by a field and save it as a single csv file. I'm using an ml.r5.12xlarge sagemaker instance to read the parquet to a dataframe, sort, coalesce to a single partition, and save as csv. I thought I might hit problems when I coalesced, but it's actually choking during the sort. I've tried it filtering the dataset to a quarter of the size, but it still chokes.\n\nSuggestions?", "author_fullname": "t2_6fylz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I sort a massive (300 GB) csv with Spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12er9ut", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680885771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got large file, about 20GB as a parquet and 300GB as an unsorted csv. I&amp;#39;d like to sort by a field and save it as a single csv file. I&amp;#39;m using an ml.r5.12xlarge sagemaker instance to read the parquet to a dataframe, sort, coalesce to a single partition, and save as csv. I thought I might hit problems when I coalesced, but it&amp;#39;s actually choking during the sort. I&amp;#39;ve tried it filtering the dataset to a quarter of the size, but it still chokes.&lt;/p&gt;\n\n&lt;p&gt;Suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12er9ut", "is_robot_indexable": true, "report_reasons": null, "author": "Nooooope", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12er9ut/how_do_i_sort_a_massive_300_gb_csv_with_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12er9ut/how_do_i_sort_a_massive_300_gb_csv_with_spark/", "subreddit_subscribers": 96630, "created_utc": 1680885771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_txvugrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What I Don't Want To See In The Data World In 5 Years", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 61, "top_awarded_type": null, "hide_score": false, "name": "t3_12el758", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9_HjsHTlAulDskKkZGvs_BmLnOsisdmtkTax-6ZqajA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680873784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "seattledataguy.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://seattledataguy.substack.com/p/what-i-dont-want-to-see-in-the-data", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/R-x1Ur-J9SX_VG7MbOlf1rIFTHwH6_OP5n7jTD2Iu_0.jpg?auto=webp&amp;v=enabled&amp;s=a6131fd83abd457f466d76cc4cfb5c2cbdcb8757", "width": 1200, "height": 530}, "resolutions": [{"url": "https://external-preview.redd.it/R-x1Ur-J9SX_VG7MbOlf1rIFTHwH6_OP5n7jTD2Iu_0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a405b03b1770f1ed5165c561229970ed093f6ab6", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/R-x1Ur-J9SX_VG7MbOlf1rIFTHwH6_OP5n7jTD2Iu_0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0de727292d78f7c60a0b11a9371f6d7e43037c6b", "width": 216, "height": 95}, {"url": "https://external-preview.redd.it/R-x1Ur-J9SX_VG7MbOlf1rIFTHwH6_OP5n7jTD2Iu_0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f3280f08c8675e6c2e2443ac8c9ee0635a28776", "width": 320, "height": 141}, {"url": "https://external-preview.redd.it/R-x1Ur-J9SX_VG7MbOlf1rIFTHwH6_OP5n7jTD2Iu_0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a59a467376400f564838cdcab402c593a327bf6e", "width": 640, "height": 282}, {"url": "https://external-preview.redd.it/R-x1Ur-J9SX_VG7MbOlf1rIFTHwH6_OP5n7jTD2Iu_0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b4a9a8ffb25ae89a2d7142f3204946bcd630b26", "width": 960, "height": 424}, {"url": "https://external-preview.redd.it/R-x1Ur-J9SX_VG7MbOlf1rIFTHwH6_OP5n7jTD2Iu_0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3891ef64193dd18a9f484a17b1b0ce7bbc27bf26", "width": 1080, "height": 477}], "variants": {}, "id": "uA_trWBusPbOF2d9apwPVAwzE_UX45bICkDcvh2Z0Vc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Company", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12el758", "is_robot_indexable": true, "report_reasons": null, "author": "prequel_co", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12el758/what_i_dont_want_to_see_in_the_data_world_in_5/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://seattledataguy.substack.com/p/what-i-dont-want-to-see-in-the-data", "subreddit_subscribers": 96630, "created_utc": 1680873784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1jkhpl2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to run dynamic Github Action workflows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_12ejuno", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/FZ-EQeupBO47ozfZ4Yhsp-mzoSYWcEYoFigcz_6ap38.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680870879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/p/35692957ef94", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vGEmG2mmaakKcxnXDQY3ZlcJrqrVPcNl_RptOf4OtC0.jpg?auto=webp&amp;v=enabled&amp;s=eef5caba0c98e8021ccceef2330b82bb0c4606f5", "width": 1200, "height": 750}, "resolutions": [{"url": "https://external-preview.redd.it/vGEmG2mmaakKcxnXDQY3ZlcJrqrVPcNl_RptOf4OtC0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a850d3475130a02050eaace31f251748b905d792", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/vGEmG2mmaakKcxnXDQY3ZlcJrqrVPcNl_RptOf4OtC0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adef17c44871e980d9b4e4473cdd9d8ef5f4a484", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/vGEmG2mmaakKcxnXDQY3ZlcJrqrVPcNl_RptOf4OtC0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b74f8c19297e4c723220debde72294891846b15b", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/vGEmG2mmaakKcxnXDQY3ZlcJrqrVPcNl_RptOf4OtC0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd5f85dd858cd8d54a191d6499ade97cfa1dac48", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/vGEmG2mmaakKcxnXDQY3ZlcJrqrVPcNl_RptOf4OtC0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=242170b34d9b9b44c47ac539d4498063edcfd29e", "width": 960, "height": 600}, {"url": "https://external-preview.redd.it/vGEmG2mmaakKcxnXDQY3ZlcJrqrVPcNl_RptOf4OtC0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=770b2e3cc0ccc9d1a5c21f271a323605672be27d", "width": 1080, "height": 675}], "variants": {}, "id": "corEyKiyBN7xmaYdlI-4JDM9ATZVUIIp5xW9IRgtJB8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12ejuno", "is_robot_indexable": true, "report_reasons": null, "author": "Luxi36", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ejuno/how_to_run_dynamic_github_action_workflows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/p/35692957ef94", "subreddit_subscribers": 96630, "created_utc": 1680870879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've 10 numerical and large datasets where each has 3 generic categories. Each row contains unique data. The end row of each dataset contains the labels for each category. The category is not distinct thus other row may refer to any of the 3 categories.\n\ne.g. Dataset A\n\n&amp;#x200B;\n\n|Date|Value|Category|\n|:-|:-|:-|\n|1/1/2010|1.11111|Alpha|\n|2/1/2010|2.11111|Beta|\n|3/1/2010|2.00009|Alpha|\n|4/1/2010|0.00000|Charlie|\n\nBut the 10 datasets have different volume of data. E.g.  dataset A may have 10K rows, dataset B around 100K, Dataset C 1 million, etc.\n\nI couldn't process all the data as its too large.\n\nWhat would be the best way to sample each dataset? I'd like the sample containing a fair representative of the 3 categories.", "author_fullname": "t2_3z6gqvrh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to represent large categorical data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12egjxl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680863159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve 10 numerical and large datasets where each has 3 generic categories. Each row contains unique data. The end row of each dataset contains the labels for each category. The category is not distinct thus other row may refer to any of the 3 categories.&lt;/p&gt;\n\n&lt;p&gt;e.g. Dataset A&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Date&lt;/th&gt;\n&lt;th align=\"left\"&gt;Value&lt;/th&gt;\n&lt;th align=\"left\"&gt;Category&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1/1/2010&lt;/td&gt;\n&lt;td align=\"left\"&gt;1.11111&lt;/td&gt;\n&lt;td align=\"left\"&gt;Alpha&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2/1/2010&lt;/td&gt;\n&lt;td align=\"left\"&gt;2.11111&lt;/td&gt;\n&lt;td align=\"left\"&gt;Beta&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3/1/2010&lt;/td&gt;\n&lt;td align=\"left\"&gt;2.00009&lt;/td&gt;\n&lt;td align=\"left\"&gt;Alpha&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;4/1/2010&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.00000&lt;/td&gt;\n&lt;td align=\"left\"&gt;Charlie&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;But the 10 datasets have different volume of data. E.g.  dataset A may have 10K rows, dataset B around 100K, Dataset C 1 million, etc.&lt;/p&gt;\n\n&lt;p&gt;I couldn&amp;#39;t process all the data as its too large.&lt;/p&gt;\n\n&lt;p&gt;What would be the best way to sample each dataset? I&amp;#39;d like the sample containing a fair representative of the 3 categories.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12egjxl", "is_robot_indexable": true, "report_reasons": null, "author": "runnersgo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12egjxl/how_to_represent_large_categorical_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12egjxl/how_to_represent_large_categorical_data/", "subreddit_subscribers": 96630, "created_utc": 1680863159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nHello guys,\nCan anyone point me to a place where I can learn how to extract specie row-data with row level security from SQL Db to storage container  using data factory ?", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Row level security in ADF", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12ergr0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680886138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,\nCan anyone point me to a place where I can learn how to extract specie row-data with row level security from SQL Db to storage container  using data factory ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ergr0", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ergr0/row_level_security_in_adf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ergr0/row_level_security_in_adf/", "subreddit_subscribers": 96630, "created_utc": 1680886138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Good day, I am a data engineer and have been asked to be a part of panel for interviewing director level candidates. They will oversee the data engineering and devsecops teams. The candidate will be given a technical prompt and they will be required to discuss a recent project they led. This is the first time I will be interviewing a senior level candidate. What questions can I ask the candidate for a meaningful assessment and experience for all of us?", "author_fullname": "t2_77mz0n8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions to ask a leadership candidate as a DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12erf91", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680886057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good day, I am a data engineer and have been asked to be a part of panel for interviewing director level candidates. They will oversee the data engineering and devsecops teams. The candidate will be given a technical prompt and they will be required to discuss a recent project they led. This is the first time I will be interviewing a senior level candidate. What questions can I ask the candidate for a meaningful assessment and experience for all of us?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12erf91", "is_robot_indexable": true, "report_reasons": null, "author": "Programmer_Virtual", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12erf91/questions_to_ask_a_leadership_candidate_as_a_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12erf91/questions_to_ask_a_leadership_candidate_as_a_de/", "subreddit_subscribers": 96630, "created_utc": 1680886057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've created a solution based on these articles:\n\n* Theory: [https://www.redhat.com/en/blog/why-spark-ceph-part-1-3](https://www.redhat.com/en/blog/why-spark-ceph-part-1-3)\n* Implementation: [https://radanalytics.io/examples/ceph-source-example](https://radanalytics.io/examples/ceph-source-example)\n\nIt has been a messy journey, but so far it seems like I've gotten to the last step - I can query txt, csv and other files, but I'm still struggling querying the actual sqlite3 file on Ceph.\n\nHas anyone done anything similar in this regard to give some general tips and tricks, best practices and so on?\n\n*Note: This is more of a generic discussion thread, but if you'd like to help me the error I'm facing, I have a post on Stackoverflow:* [*https://stackoverflow.com/questions/75959520/querying-an-sqlite3-file-on-ceph-via-s3a-using-pyspark-requirement-failed-the*](https://stackoverflow.com/questions/75959520/querying-an-sqlite3-file-on-ceph-via-s3a-using-pyspark-requirement-failed-the)", "author_fullname": "t2_sy57joj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Spark to query Sqlite3 files stored on Ceph", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12erdiz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680885968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve created a solution based on these articles:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Theory: &lt;a href=\"https://www.redhat.com/en/blog/why-spark-ceph-part-1-3\"&gt;https://www.redhat.com/en/blog/why-spark-ceph-part-1-3&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Implementation: &lt;a href=\"https://radanalytics.io/examples/ceph-source-example\"&gt;https://radanalytics.io/examples/ceph-source-example&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;It has been a messy journey, but so far it seems like I&amp;#39;ve gotten to the last step - I can query txt, csv and other files, but I&amp;#39;m still struggling querying the actual sqlite3 file on Ceph.&lt;/p&gt;\n\n&lt;p&gt;Has anyone done anything similar in this regard to give some general tips and tricks, best practices and so on?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Note: This is more of a generic discussion thread, but if you&amp;#39;d like to help me the error I&amp;#39;m facing, I have a post on Stackoverflow:&lt;/em&gt; &lt;a href=\"https://stackoverflow.com/questions/75959520/querying-an-sqlite3-file-on-ceph-via-s3a-using-pyspark-requirement-failed-the\"&gt;&lt;em&gt;https://stackoverflow.com/questions/75959520/querying-an-sqlite3-file-on-ceph-via-s3a-using-pyspark-requirement-failed-the&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aJKUjlRZOQ5zCI_oiLgRfvnrBPEJ42leZbocgCpUCNY.jpg?auto=webp&amp;v=enabled&amp;s=05c8470dbdcfd7cd0dfd7e4527cdd4602cc774cf", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/aJKUjlRZOQ5zCI_oiLgRfvnrBPEJ42leZbocgCpUCNY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2137cbf420f60b1525ac7e09bfa9a8a3f4c22186", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/aJKUjlRZOQ5zCI_oiLgRfvnrBPEJ42leZbocgCpUCNY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd4a05a9750b0dc811783b83485cb4dafaea0f80", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/aJKUjlRZOQ5zCI_oiLgRfvnrBPEJ42leZbocgCpUCNY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=107428a18928923d74b2c4855e3a7b4667e6edf7", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/aJKUjlRZOQ5zCI_oiLgRfvnrBPEJ42leZbocgCpUCNY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db5cd310b5df37671aadef3563fb49bca6fe0a3d", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/aJKUjlRZOQ5zCI_oiLgRfvnrBPEJ42leZbocgCpUCNY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=676043fceccc799c8bc827d7c767343abad586c9", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/aJKUjlRZOQ5zCI_oiLgRfvnrBPEJ42leZbocgCpUCNY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=804865a5b207b480f68a1161cf196cd208f881d6", "width": 1080, "height": 567}], "variants": {}, "id": "rpz7XRvvl4-yX8tMXzyfnMqpwkzXT4I2njPuoYdvEls"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12erdiz", "is_robot_indexable": true, "report_reasons": null, "author": "pioneeringwork", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12erdiz/using_spark_to_query_sqlite3_files_stored_on_ceph/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12erdiz/using_spark_to_query_sqlite3_files_stored_on_ceph/", "subreddit_subscribers": 96630, "created_utc": 1680885968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all - does using Delta Sharing cost anything as a Databricks customer? I would want to know the answer for multiple use cases (DBX-to-DBX internal, DBX-to-DBX external or another organization but same VPC, and DBX-to-DBX external different VPC or CSP altogether).   \n\n\nThanks so much.", "author_fullname": "t2_4oqqusfb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Sharing Cost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12epuyd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680883088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all - does using Delta Sharing cost anything as a Databricks customer? I would want to know the answer for multiple use cases (DBX-to-DBX internal, DBX-to-DBX external or another organization but same VPC, and DBX-to-DBX external different VPC or CSP altogether).   &lt;/p&gt;\n\n&lt;p&gt;Thanks so much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12epuyd", "is_robot_indexable": true, "report_reasons": null, "author": "Foreign_Magician_429", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12epuyd/delta_sharing_cost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12epuyd/delta_sharing_cost/", "subreddit_subscribers": 96630, "created_utc": 1680883088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey r/dataengineering! I've been contributing to an open-source project in the data lineage domain, and I'd really like to know more about the challenges you face in your day-to-day work.\n\nSo, let's discuss! What do you find most troublesome about data lineage? Are you struggling with tracking data dependencies, compliance, testing, or maybe something else entirely?", "author_fullname": "t2_i0qyphvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fellow Data Engineers, Share Your Data Lineage Struggles!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ep3pl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680881592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;! I&amp;#39;ve been contributing to an open-source project in the data lineage domain, and I&amp;#39;d really like to know more about the challenges you face in your day-to-day work.&lt;/p&gt;\n\n&lt;p&gt;So, let&amp;#39;s discuss! What do you find most troublesome about data lineage? Are you struggling with tracking data dependencies, compliance, testing, or maybe something else entirely?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ep3pl", "is_robot_indexable": true, "report_reasons": null, "author": "ProfessionalHorse707", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ep3pl/fellow_data_engineers_share_your_data_lineage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ep3pl/fellow_data_engineers_share_your_data_lineage/", "subreddit_subscribers": 96630, "created_utc": 1680881592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data scientist within a small data science team. We're currently in the midst of a transition to cloud, but due to regulatory mess we cannot actually switch within the next three years. We're kind of an oddball out of the bunch, as the other IT teams focus in making microservices for the organization and don't care much about what we do. 90% of the organization is not IT, so it's not like they hand us the best tools.\n\nMeanwhile, we kind of need a robust development environment that data scientists can use to make more 'production-ready' products. Right now, DEs kind of have to make major adjustments to fit everything in docker containers and have to deal with the issue of debugging things in different environments than it was developed in (Windows Server 2019 vs Linux in the container). Also there's an issue where if someone is running a model (let's say XGB) it literally freezes the session of other colleagues logged into the remote desktop session (yikes!). \n\nWhat's currently a 'good' practice in terms of setting up a development environment? I've looked into Hyper-V or something like Proxmox  and starting up a simple CLI debian per project and using remote explorer and/or dev containers using VSCode. It's a major requirement to have RBAC (Role based access control) per project. If it's indeed not a crazy solution, how would it work so that a DBA can quickly give access to tables for that project in that environment?", "author_fullname": "t2_607hu6ywi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On premise development environment for data scientists. Best practices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12eozr9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680881394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data scientist within a small data science team. We&amp;#39;re currently in the midst of a transition to cloud, but due to regulatory mess we cannot actually switch within the next three years. We&amp;#39;re kind of an oddball out of the bunch, as the other IT teams focus in making microservices for the organization and don&amp;#39;t care much about what we do. 90% of the organization is not IT, so it&amp;#39;s not like they hand us the best tools.&lt;/p&gt;\n\n&lt;p&gt;Meanwhile, we kind of need a robust development environment that data scientists can use to make more &amp;#39;production-ready&amp;#39; products. Right now, DEs kind of have to make major adjustments to fit everything in docker containers and have to deal with the issue of debugging things in different environments than it was developed in (Windows Server 2019 vs Linux in the container). Also there&amp;#39;s an issue where if someone is running a model (let&amp;#39;s say XGB) it literally freezes the session of other colleagues logged into the remote desktop session (yikes!). &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s currently a &amp;#39;good&amp;#39; practice in terms of setting up a development environment? I&amp;#39;ve looked into Hyper-V or something like Proxmox  and starting up a simple CLI debian per project and using remote explorer and/or dev containers using VSCode. It&amp;#39;s a major requirement to have RBAC (Role based access control) per project. If it&amp;#39;s indeed not a crazy solution, how would it work so that a DBA can quickly give access to tables for that project in that environment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12eozr9", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial_Score757", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12eozr9/on_premise_development_environment_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12eozr9/on_premise_development_environment_for_data/", "subreddit_subscribers": 96630, "created_utc": 1680881394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wanted to try out `pyarrow`'s `S3FileSystem` by converting a `boto3` snippet to read gzipped jsonline files (a dump from DynamoDB). Compared to the original, the `pyarrow` one is terribly slow *well before data starts reading JSON into memory*.\n\nThe snippet core logic is this:\n\n```python\nfrom pyarrow import fs\ns3 = fs.S3FileSystem()\n\nfrom mymodule import yield_as_json\n\nmyfile = \"bucket/path/to/dump.json.gz\"\n\nwith s3.open_input_stream(myfile) as stream:\n    data = list(yield_as_json(stream))\n```\n\nWhat's inside `yield_as_json` does not really matter - I believe it works, because the second snippet (below) works. My suspicion is that `pyarrow` reads the whole data in memory, decompresses it and then starts iterating over lines.\n\nBy comparison, the `boto3` snippet is:\n\n```python\nimport boto3\nimport gzip\n\nfrom mymodule import yield_as_json\n\ns3 = boto3.session.Session(**session_kwargs).client(\"s3\")\n\nbucket = \"bucket\"\nkey = \"path/to/dump.json.gz\"\nstream = s3.get_object(Bucket=bucket, Key=key).get(\"Body\")\n\nwith gzip.open(stream, \"rb\") as zipped:\n    data = list(yield_as_json(zipped))\n```\n\nDoes anyone know what's happening, or how I could improve the code?", "author_fullname": "t2_329zuj1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "pyarrow S3FS: reading zipped files is slow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12eoc5a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "245217ea-ac9d-11eb-a81a-0e03519a5d4b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680880088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanted to try out &lt;code&gt;pyarrow&lt;/code&gt;&amp;#39;s &lt;code&gt;S3FileSystem&lt;/code&gt; by converting a &lt;code&gt;boto3&lt;/code&gt; snippet to read gzipped jsonline files (a dump from DynamoDB). Compared to the original, the &lt;code&gt;pyarrow&lt;/code&gt; one is terribly slow &lt;em&gt;well before data starts reading JSON into memory&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;The snippet core logic is this:&lt;/p&gt;\n\n&lt;p&gt;```python\nfrom pyarrow import fs\ns3 = fs.S3FileSystem()&lt;/p&gt;\n\n&lt;p&gt;from mymodule import yield_as_json&lt;/p&gt;\n\n&lt;p&gt;myfile = &amp;quot;bucket/path/to/dump.json.gz&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;with s3.open_input_stream(myfile) as stream:\n    data = list(yield_as_json(stream))\n```&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s inside &lt;code&gt;yield_as_json&lt;/code&gt; does not really matter - I believe it works, because the second snippet (below) works. My suspicion is that &lt;code&gt;pyarrow&lt;/code&gt; reads the whole data in memory, decompresses it and then starts iterating over lines.&lt;/p&gt;\n\n&lt;p&gt;By comparison, the &lt;code&gt;boto3&lt;/code&gt; snippet is:&lt;/p&gt;\n\n&lt;p&gt;```python\nimport boto3\nimport gzip&lt;/p&gt;\n\n&lt;p&gt;from mymodule import yield_as_json&lt;/p&gt;\n\n&lt;p&gt;s3 = boto3.session.Session(**session_kwargs).client(&amp;quot;s3&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;bucket = &amp;quot;bucket&amp;quot;\nkey = &amp;quot;path/to/dump.json.gz&amp;quot;\nstream = s3.get_object(Bucket=bucket, Key=key).get(&amp;quot;Body&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;with gzip.open(stream, &amp;quot;rb&amp;quot;) as zipped:\n    data = list(yield_as_json(zipped))\n```&lt;/p&gt;\n\n&lt;p&gt;Does anyone know what&amp;#39;s happening, or how I could improve the code?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12eoc5a", "is_robot_indexable": true, "report_reasons": null, "author": "BaggiPonte", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12eoc5a/pyarrow_s3fs_reading_zipped_files_is_slow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12eoc5a/pyarrow_s3fs_reading_zipped_files_is_slow/", "subreddit_subscribers": 96630, "created_utc": 1680880088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys,\n\nI have a heroku app, which runs an api server, and I wanted to run also an airflow server on the same heroku app, meaning that I want a dag to run daily.\n\nI have the following structure, the repo contains an airflow folder which is set as path for AIRFLOW\\_HOME. The folder contains a dags folder where i have the script.\n\nNow my question would be what commands should the Procfile contains?\n\nCause at the moment it contains: web: gunicorn -w 4 -k uvicorn.workers.UvicornWorker api.main:app &amp;&amp; cd airflow\\_folder &amp;&amp; airflow webserver -p 8080 &amp;&amp; airflow schedule.\n\nThe first command before &amp;&amp; is to start the api server, and the others are to run the airflow server. Not sure if that's the best, or if i should do it in a different way. The thing is on my heroku logs there's no error / complain, but the airflow dag doesn't run either and I am not sure what I am doing wrong and how I should make it work as expected.", "author_fullname": "t2_b4ypm8ew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Integrate airflow in my github app running on heroku", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12eo3z0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680879663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I have a heroku app, which runs an api server, and I wanted to run also an airflow server on the same heroku app, meaning that I want a dag to run daily.&lt;/p&gt;\n\n&lt;p&gt;I have the following structure, the repo contains an airflow folder which is set as path for AIRFLOW_HOME. The folder contains a dags folder where i have the script.&lt;/p&gt;\n\n&lt;p&gt;Now my question would be what commands should the Procfile contains?&lt;/p&gt;\n\n&lt;p&gt;Cause at the moment it contains: web: gunicorn -w 4 -k uvicorn.workers.UvicornWorker api.main:app &amp;amp;&amp;amp; cd airflow_folder &amp;amp;&amp;amp; airflow webserver -p 8080 &amp;amp;&amp;amp; airflow schedule.&lt;/p&gt;\n\n&lt;p&gt;The first command before &amp;amp;&amp;amp; is to start the api server, and the others are to run the airflow server. Not sure if that&amp;#39;s the best, or if i should do it in a different way. The thing is on my heroku logs there&amp;#39;s no error / complain, but the airflow dag doesn&amp;#39;t run either and I am not sure what I am doing wrong and how I should make it work as expected.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12eo3z0", "is_robot_indexable": true, "report_reasons": null, "author": "Koxinfster", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12eo3z0/integrate_airflow_in_my_github_app_running_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12eo3z0/integrate_airflow_in_my_github_app_running_on/", "subreddit_subscribers": 96630, "created_utc": 1680879663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We used to use traditional syntax in all our Airflow dags, however, some of the tasks would be much easier to write with the TaskFlow API but on the other hand that would mean mixing two different styles. \n\nWhat is your view on this? Would you go with easier path to develop (mixing both syntax) or cleaner (use exactly one flavor)?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Combining TaskFlow API and Traditional syntax in Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12emkq6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680876642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We used to use traditional syntax in all our Airflow dags, however, some of the tasks would be much easier to write with the TaskFlow API but on the other hand that would mean mixing two different styles. &lt;/p&gt;\n\n&lt;p&gt;What is your view on this? Would you go with easier path to develop (mixing both syntax) or cleaner (use exactly one flavor)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12emkq6", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12emkq6/combining_taskflow_api_and_traditional_syntax_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12emkq6/combining_taskflow_api_and_traditional_syntax_in/", "subreddit_subscribers": 96630, "created_utc": 1680876642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello  \nI am working at consulting company as BI developer (mainly PowerBI but also a Qliksense), however recently I have been roll off from the project due to project freeze and now siting on a bench. I've been told that I'll be having an interview next week Tue/Wed on data engineering role with AWS. My cloud \"stack\" is Azure - AZ-900, DP-900, PL-300. I used a little bit of Azure Data Studio and Synapse. Thats pretty much it. I know SQL to the extend I can freely make a view myself with some transformations or to answer some business question but never been \"deeper\" and I am afraid not that I'll not land in that position - it is guaranteed, but that I'll make fool of myself. I know core concepts of DE, but never really used the tools na AWS itself.   \n\n\nAny protips for me? What to prepare if we're talking about bare minimum, to not make a fool out of myself?", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "help me in not making fool of myself", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ekb6i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680871879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello&lt;br/&gt;\nI am working at consulting company as BI developer (mainly PowerBI but also a Qliksense), however recently I have been roll off from the project due to project freeze and now siting on a bench. I&amp;#39;ve been told that I&amp;#39;ll be having an interview next week Tue/Wed on data engineering role with AWS. My cloud &amp;quot;stack&amp;quot; is Azure - AZ-900, DP-900, PL-300. I used a little bit of Azure Data Studio and Synapse. Thats pretty much it. I know SQL to the extend I can freely make a view myself with some transformations or to answer some business question but never been &amp;quot;deeper&amp;quot; and I am afraid not that I&amp;#39;ll not land in that position - it is guaranteed, but that I&amp;#39;ll make fool of myself. I know core concepts of DE, but never really used the tools na AWS itself.   &lt;/p&gt;\n\n&lt;p&gt;Any protips for me? What to prepare if we&amp;#39;re talking about bare minimum, to not make a fool out of myself?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ekb6i", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ekb6i/help_me_in_not_making_fool_of_myself/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ekb6i/help_me_in_not_making_fool_of_myself/", "subreddit_subscribers": 96630, "created_utc": 1680871879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone!\n\nI've been searching for a while an installer for SpectX (the log analytics tool). Since the company was bought by Dynatrace, it has become impossible to find it online.\n\nI was wondering if anyone has an installer, or even an installed version from which we can extract the specx.jar.\n\nI happen to have a license for it, but no way to use it.", "author_fullname": "t2_8q939c1mp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SpectX", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12eg82n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680862305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been searching for a while an installer for SpectX (the log analytics tool). Since the company was bought by Dynatrace, it has become impossible to find it online.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone has an installer, or even an installed version from which we can extract the specx.jar.&lt;/p&gt;\n\n&lt;p&gt;I happen to have a license for it, but no way to use it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12eg82n", "is_robot_indexable": true, "report_reasons": null, "author": "AdditionalDLL", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12eg82n/spectx/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12eg82n/spectx/", "subreddit_subscribers": 96630, "created_utc": 1680862305.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}