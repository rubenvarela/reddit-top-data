{"kind": "Listing", "data": {"after": "t3_12dqjha", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI find it hard to decide what to learn. Like I have been working on a project, in the night I learn something about LLMs, then the next day I explore Topic Modelling, the next day I try some Pyspark coding in Azure Databricks, then I decide to study the maths behind Gaussian Mixture Models and then I decide I should explore PyTorch and so on\n\nFor AI/Data Science professionals, how do you prioritize as the things we need to learn seems just.....\n\nENDLESS", "author_fullname": "t2_8pphmf41t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science is so vast, how to prioritize what to learn?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ekysa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 69, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680873290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I find it hard to decide what to learn. Like I have been working on a project, in the night I learn something about LLMs, then the next day I explore Topic Modelling, the next day I try some Pyspark coding in Azure Databricks, then I decide to study the maths behind Gaussian Mixture Models and then I decide I should explore PyTorch and so on&lt;/p&gt;\n\n&lt;p&gt;For AI/Data Science professionals, how do you prioritize as the things we need to learn seems just.....&lt;/p&gt;\n\n&lt;p&gt;ENDLESS&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ekysa", "is_robot_indexable": true, "report_reasons": null, "author": "NickRay1234", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ekysa/data_science_is_so_vast_how_to_prioritize_what_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ekysa/data_science_is_so_vast_how_to_prioritize_what_to/", "subreddit_subscribers": 869029, "created_utc": 1680873290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_gj8rt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving estimators (agnostic) vs ARMA-ARCH-like philosophy (arbitrary) on example of Student's t-distributions for economical data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 106, "top_awarded_type": null, "hide_score": false, "name": "t3_12ednms", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aOp5GxUkW51V_HM3hwzpk-_t3UbVFWKYRdCRtfHtyWo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680853925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/jw5b4i304fsa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/jw5b4i304fsa1.png?auto=webp&amp;v=enabled&amp;s=552232c2a39e50e911e8209fc3127dade1941360", "width": 2127, "height": 1625}, "resolutions": [{"url": "https://preview.redd.it/jw5b4i304fsa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7a41d4e423ef3c0e19de7f00ed02dac539f2ecb", "width": 108, "height": 82}, {"url": "https://preview.redd.it/jw5b4i304fsa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f662a311f1d770fca857f5787fe0542b55aa90f", "width": 216, "height": 165}, {"url": "https://preview.redd.it/jw5b4i304fsa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3df04a03ace1d5c8f7a2db86bca2c2e5095db115", "width": 320, "height": 244}, {"url": "https://preview.redd.it/jw5b4i304fsa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=988251d989db849d5a4ce278483fbf92c775c289", "width": 640, "height": 488}, {"url": "https://preview.redd.it/jw5b4i304fsa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdbe4a2a59b0730de7ad35a73c0f83f0906ef251", "width": 960, "height": 733}, {"url": "https://preview.redd.it/jw5b4i304fsa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2274960b3b0dd9e40e948e3423303ee7b75a1a82", "width": 1080, "height": 825}], "variants": {}, "id": "U3iXumCJAdToRNi7FK6lU4kBvWYQbXy4woxr2dy52tA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ednms", "is_robot_indexable": true, "report_reasons": null, "author": "jarekduda", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ednms/moving_estimators_agnostic_vs_armaarchlike/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/jw5b4i304fsa1.png", "subreddit_subscribers": 869029, "created_utc": 1680853925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello there,\n\nI am currently finishing my master's program in Digitalization / CS, having a background in Business and Economics. Basically what my program prepares me for is to be the \"bridge\" between classic IT and business people. That means we learn some soft skills and knowledge, but also work with R, Python and some simple NN. Nonetheless, I would like to dive deeper into the topic of data science and data analysis and am quite open minded. The goal is to use my skills for a job in this area. Does not have to be super techy, but I would like to have some solid knowledge of my field.\n\nWhat are good approaches to arrive at such a level? Which courses/certificates make sense? What do employers care about/look at? Can I just start with my knowledge as, e.g., a data analyst and \"learn on the job\"? I guess with the current market situation it might not be that hard, I am from Europe.\n\nThank you! :)", "author_fullname": "t2_171gs3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get more Data Science \"proficient\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12eex4c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680858201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there,&lt;/p&gt;\n\n&lt;p&gt;I am currently finishing my master&amp;#39;s program in Digitalization / CS, having a background in Business and Economics. Basically what my program prepares me for is to be the &amp;quot;bridge&amp;quot; between classic IT and business people. That means we learn some soft skills and knowledge, but also work with R, Python and some simple NN. Nonetheless, I would like to dive deeper into the topic of data science and data analysis and am quite open minded. The goal is to use my skills for a job in this area. Does not have to be super techy, but I would like to have some solid knowledge of my field.&lt;/p&gt;\n\n&lt;p&gt;What are good approaches to arrive at such a level? Which courses/certificates make sense? What do employers care about/look at? Can I just start with my knowledge as, e.g., a data analyst and &amp;quot;learn on the job&amp;quot;? I guess with the current market situation it might not be that hard, I am from Europe.&lt;/p&gt;\n\n&lt;p&gt;Thank you! :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12eex4c", "is_robot_indexable": true, "report_reasons": null, "author": "obeseelk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12eex4c/how_to_get_more_data_science_proficient/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12eex4c/how_to_get_more_data_science_proficient/", "subreddit_subscribers": 869029, "created_utc": 1680858201.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Good Evening,\n\nI am a mathematics and science high school teacher, and I just completed a data science bootcamp from SMU. I am wondering if joining professional data science organizations would be a value, and if so, which organizations would be the best one to join. I live in Fort Worth, TX.  \n\n\nI am choosing from among these:\n\n[https://www.datascienceassn.org/](https://www.datascienceassn.org/)\n\n[https://adasci.org/](https://adasci.org/)\n\n[https://www.informs.org/](https://www.informs.org/)\n\n[https://www.asist.org/](https://www.asist.org/)\n\nMany of them require dues and they come with courses to further my skills. If you have any recommendations about these, it would be helpful for me.", "author_fullname": "t2_8pawae23u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Professional Organizations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12e7drd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680836106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good Evening,&lt;/p&gt;\n\n&lt;p&gt;I am a mathematics and science high school teacher, and I just completed a data science bootcamp from SMU. I am wondering if joining professional data science organizations would be a value, and if so, which organizations would be the best one to join. I live in Fort Worth, TX.  &lt;/p&gt;\n\n&lt;p&gt;I am choosing from among these:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datascienceassn.org/\"&gt;https://www.datascienceassn.org/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://adasci.org/\"&gt;https://adasci.org/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.informs.org/\"&gt;https://www.informs.org/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.asist.org/\"&gt;https://www.asist.org/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Many of them require dues and they come with courses to further my skills. If you have any recommendations about these, it would be helpful for me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12e7drd", "is_robot_indexable": true, "report_reasons": null, "author": "sajid1760", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12e7drd/data_science_professional_organizations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12e7drd/data_science_professional_organizations/", "subreddit_subscribers": 869029, "created_utc": 1680836106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm wondering what I can do to be ahead of my peers. I know the market is \"saturated\" with a lot of hype in the data science field. But what are things you wish you knew? For example, paying attention in class or taking a course online... \n\nThere's so much out there nowadays, but knowing all of it isn't necessary.\n\n I am putting more time into Math, SQL, and Python. Any recommendations you can give me would be cool.", "author_fullname": "t2_vngkp0a1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What recommendations would you give to an undergraduate or things you would've done differently while in school?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dx054", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680813132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m wondering what I can do to be ahead of my peers. I know the market is &amp;quot;saturated&amp;quot; with a lot of hype in the data science field. But what are things you wish you knew? For example, paying attention in class or taking a course online... &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s so much out there nowadays, but knowing all of it isn&amp;#39;t necessary.&lt;/p&gt;\n\n&lt;p&gt;I am putting more time into Math, SQL, and Python. Any recommendations you can give me would be cool.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12dx054", "is_robot_indexable": true, "report_reasons": null, "author": "kaxziss", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12dx054/what_recommendations_would_you_give_to_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12dx054/what_recommendations_would_you_give_to_an/", "subreddit_subscribers": 869029, "created_utc": 1680813132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'm a recent college grad. Majored in biology, no experience or anything with computers/data/math engineering etc. I was considering getting a masters in business analytics to get my foot in the door into this world and then hopefully work as a data scientist at some point. I'm very lost and don't really know how to move forward in my career... anyone willing to private message me or just chat here will be greatly appreciated! Thanks in advance.", "author_fullname": "t2_85e1b61je", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wanting to get into Data Science/Analytics but with a Bio background", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12epdb9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680882117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m a recent college grad. Majored in biology, no experience or anything with computers/data/math engineering etc. I was considering getting a masters in business analytics to get my foot in the door into this world and then hopefully work as a data scientist at some point. I&amp;#39;m very lost and don&amp;#39;t really know how to move forward in my career... anyone willing to private message me or just chat here will be greatly appreciated! Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12epdb9", "is_robot_indexable": true, "report_reasons": null, "author": "QueenArtichoke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12epdb9/wanting_to_get_into_data_scienceanalytics_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12epdb9/wanting_to_get_into_data_scienceanalytics_but/", "subreddit_subscribers": 869029, "created_utc": 1680882117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm trying to switch company for the first time with 2 yoe. I interviewed at a marketing analytics company for DS role this Monday and Tuesday, a total of 3 rounds and after these rounds the HR said \"they'll get back to me asap as some feedbacks are pending\". I asked for a timeframe or maybe an ETA to which I was told the same thing \"as soon as possible\".\n\nSince this is my first time, i wanted to know what is the appropriate period to maybe reach out to the recruiter maybe an update? Also does this mean that they are interviewing other potential candidates and keeping me on hold? How can I play this the right way?", "author_fullname": "t2_2xjdvpun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question to DS recruiters.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12egkek", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680863194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to switch company for the first time with 2 yoe. I interviewed at a marketing analytics company for DS role this Monday and Tuesday, a total of 3 rounds and after these rounds the HR said &amp;quot;they&amp;#39;ll get back to me asap as some feedbacks are pending&amp;quot;. I asked for a timeframe or maybe an ETA to which I was told the same thing &amp;quot;as soon as possible&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Since this is my first time, i wanted to know what is the appropriate period to maybe reach out to the recruiter maybe an update? Also does this mean that they are interviewing other potential candidates and keeping me on hold? How can I play this the right way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12egkek", "is_robot_indexable": true, "report_reasons": null, "author": "deepcontractor", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12egkek/question_to_ds_recruiters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12egkek/question_to_ds_recruiters/", "subreddit_subscribers": 869029, "created_utc": 1680863194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm having trouble visualizing datasets with correlations that are non-spherical like the famous moons example. In my own time, I've played around with KNN and DBSCAN and it feels like KNN outperforms. Researching further, it looks like DBSCAN is especially good with image and geographical data. Does anyone else have any more examples they could share?", "author_fullname": "t2_45bgy9c3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some real life use cases where DBSCAN outperforms KNN?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dsiom", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680804271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m having trouble visualizing datasets with correlations that are non-spherical like the famous moons example. In my own time, I&amp;#39;ve played around with KNN and DBSCAN and it feels like KNN outperforms. Researching further, it looks like DBSCAN is especially good with image and geographical data. Does anyone else have any more examples they could share?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12dsiom", "is_robot_indexable": true, "report_reasons": null, "author": "EasternStuff5015", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12dsiom/what_are_some_real_life_use_cases_where_dbscan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12dsiom/what_are_some_real_life_use_cases_where_dbscan/", "subreddit_subscribers": 869029, "created_utc": 1680804271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vuozxz2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing Workflow orchestrators: Why I'm fascinated by Metaflow and Flyte and will stop using Airflow. Compares prefect, dagster, luigi, and others as well.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": true, "name": "t3_12eptjp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7O2Raqq31tVgokW1i_9qxmlOv59uD82kjm35PDTk6ug.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680883010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dsdaily.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://dsdaily.substack.com/p/workflow-orchestrators-metaflow-kedro", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/B7967E5kGkGqxs4Lda43PVqY-eNs7YQ6ZZ3CzhQUvlU.jpg?auto=webp&amp;v=enabled&amp;s=a6a802bb2d7efde54ff0ef2559e66e363bf49a5a", "width": 1018, "height": 598}, "resolutions": [{"url": "https://external-preview.redd.it/B7967E5kGkGqxs4Lda43PVqY-eNs7YQ6ZZ3CzhQUvlU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a90eb229993f8276fb3f03b5a2de1277134e270", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/B7967E5kGkGqxs4Lda43PVqY-eNs7YQ6ZZ3CzhQUvlU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7481dd837331da965c18dc15b5976422a51163e", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/B7967E5kGkGqxs4Lda43PVqY-eNs7YQ6ZZ3CzhQUvlU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe6d2538e603e9ff23432a09fc2833ac7a295d1b", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/B7967E5kGkGqxs4Lda43PVqY-eNs7YQ6ZZ3CzhQUvlU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9afb7d19e43b264aa71a446da5da02ffb669588a", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/B7967E5kGkGqxs4Lda43PVqY-eNs7YQ6ZZ3CzhQUvlU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0c11dd6aa271307b19698104a9c2ca7db2cc184", "width": 960, "height": 563}], "variants": {}, "id": "k_OJwzSNhRaOxxkROZWgnREqC7dSqVJTRM4y-8YAGys"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12eptjp", "is_robot_indexable": true, "report_reasons": null, "author": "RAFisherman", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12eptjp/comparing_workflow_orchestrators_why_im/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dsdaily.substack.com/p/workflow-orchestrators-metaflow-kedro", "subreddit_subscribers": 869029, "created_utc": 1680883010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone I am very new at data science, currently I am interning at a cab aggregator company in India, my task is\n - to automate the process of data collection from a group in telegram where various cab drivers post ride for outstations, and at the same time customers or brokers who have customers that are looking for outstation rides are also posting their demands (they have no particular format and we don't want to constraint them with it). \n- We have to take that random sequence of text posted by drivers and extract fields such as source, destination, type of car, their contact details etc. and store it in a structured manner. \n- this structured data is then required to be pushed onto our application. \n\nSo problem statement is-\n-automating the task of collection and storing of message data so that it can be fed directly to a DL model\n-Identify what language the driver is conversing in, as there are lot of different regional language and they may be conversing in marathi while using English alphabets\n-Identifying important data points in the message \n- Once identified and stored messages in structured format everything should be loaded on the app \n\n\nWould really appreciate any ideas and open source resources to help me solve this task.", "author_fullname": "t2_c43vnolo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help on meaningful data capture from telegram messages", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12epa34", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680881940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone I am very new at data science, currently I am interning at a cab aggregator company in India, my task is\n - to automate the process of data collection from a group in telegram where various cab drivers post ride for outstations, and at the same time customers or brokers who have customers that are looking for outstation rides are also posting their demands (they have no particular format and we don&amp;#39;t want to constraint them with it). \n- We have to take that random sequence of text posted by drivers and extract fields such as source, destination, type of car, their contact details etc. and store it in a structured manner. \n- this structured data is then required to be pushed onto our application. &lt;/p&gt;\n\n&lt;p&gt;So problem statement is-\n-automating the task of collection and storing of message data so that it can be fed directly to a DL model\n-Identify what language the driver is conversing in, as there are lot of different regional language and they may be conversing in marathi while using English alphabets\n-Identifying important data points in the message \n- Once identified and stored messages in structured format everything should be loaded on the app &lt;/p&gt;\n\n&lt;p&gt;Would really appreciate any ideas and open source resources to help me solve this task.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12epa34", "is_robot_indexable": true, "report_reasons": null, "author": "Asce_119", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12epa34/help_on_meaningful_data_capture_from_telegram/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12epa34/help_on_meaningful_data_capture_from_telegram/", "subreddit_subscribers": 869029, "created_utc": 1680881940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello there! I am a master's student of medical laboratory sciences hoping to get my PhD in bioinformatics or computational biology, and I recently participated in the Datacamp 'Everyone Can Learn Python Scholarship'.\n\nI tried to tackle the two challenges from the point of view of someone who wants their colleagues to have the best possible understanding of the problem, giving them insights and information without overwhelming them with statistics. This is also why I chose Plotly as my only tool for analysis so as not to make the graphs and code complicated for the reader (i.e., my fictional colleague).\n\nI would appreciate any criticisms or opinions you guys have and I would like to know what you think I should've done differently. Also, if you think that the workspace deserves it, I would seriously appreciate an upvote.  \nThank you.\n\nHere's the link to the entry:  \nhttps://app.datacamp.com/workspace/w/a869ebe5-d49f-4e4c-a00a-192b74c03e8f", "author_fullname": "t2_8evqbb7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datacamp 'Everyone Can Learn Python Scholarship' entry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12ep9v1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680881926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there! I am a master&amp;#39;s student of medical laboratory sciences hoping to get my PhD in bioinformatics or computational biology, and I recently participated in the Datacamp &amp;#39;Everyone Can Learn Python Scholarship&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;I tried to tackle the two challenges from the point of view of someone who wants their colleagues to have the best possible understanding of the problem, giving them insights and information without overwhelming them with statistics. This is also why I chose Plotly as my only tool for analysis so as not to make the graphs and code complicated for the reader (i.e., my fictional colleague).&lt;/p&gt;\n\n&lt;p&gt;I would appreciate any criticisms or opinions you guys have and I would like to know what you think I should&amp;#39;ve done differently. Also, if you think that the workspace deserves it, I would seriously appreciate an upvote.&lt;br/&gt;\nThank you.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the link to the entry:&lt;br/&gt;\n&lt;a href=\"https://app.datacamp.com/workspace/w/a869ebe5-d49f-4e4c-a00a-192b74c03e8f\"&gt;https://app.datacamp.com/workspace/w/a869ebe5-d49f-4e4c-a00a-192b74c03e8f&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?auto=webp&amp;v=enabled&amp;s=6200d7e1b6a8bdc05dcef79f485481bdc5fe4388", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f0de0f56f86bea05a370682c3f06ae5ea19cc4d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d8a8c80178ebf9125398b37b9a53a5ddb77eed7", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38137b22f12a844be1b7c455448cc55a12e63a3b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=182675253b24e5f6db8d18d1e3a4beccdbd9e1ed", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=190032e55865b8f952cf46c3b897d7de48d6d7dc", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/zZwb0qbP2fjw_gJGFWasrVdF8LHMCpabmmgPgQoKuFc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91d125c283ae7077c91a702e86233747214c9675", "width": 1080, "height": 567}], "variants": {}, "id": "UZeNBRQYqCTTuggCdhICWS1x95WjUfJ3Zsib1mgPnXI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ep9v1", "is_robot_indexable": true, "report_reasons": null, "author": "No_Tumbleweed_153", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ep9v1/datacamp_everyone_can_learn_python_scholarship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ep9v1/datacamp_everyone_can_learn_python_scholarship/", "subreddit_subscribers": 869029, "created_utc": 1680881926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m a process engineer that has been dabbling in DS / ML over the past 6 months. I have a decent foundation in Pandas, SKLearn, Seaborn, etc. can build out data visualizations, classifications, and models and for data generated from DOE. But for commercial data, it is extremely difficult. \n\nI\u2019ve tried applying some of this to operating plant datasets but it is extremely hard due to the data rarely being collected at steady state, unknown time lag between the change in a process variable and the resultant label, and generally being very high dimensions of data. \n\nWe have a lab that collects data from DOE and can generate very strong models, but for actual operating data in a commercial plant, it is challenging to even see correlations in the data. \n\nDoes anybody have experience working with chemical process engineering data and have any advice for how to make good use of the data?", "author_fullname": "t2_a9c3d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Chemical Process Data / Data Science Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12eopju", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680880828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a process engineer that has been dabbling in DS / ML over the past 6 months. I have a decent foundation in Pandas, SKLearn, Seaborn, etc. can build out data visualizations, classifications, and models and for data generated from DOE. But for commercial data, it is extremely difficult. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried applying some of this to operating plant datasets but it is extremely hard due to the data rarely being collected at steady state, unknown time lag between the change in a process variable and the resultant label, and generally being very high dimensions of data. &lt;/p&gt;\n\n&lt;p&gt;We have a lab that collects data from DOE and can generate very strong models, but for actual operating data in a commercial plant, it is challenging to even see correlations in the data. &lt;/p&gt;\n\n&lt;p&gt;Does anybody have experience working with chemical process engineering data and have any advice for how to make good use of the data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12eopju", "is_robot_indexable": true, "report_reasons": null, "author": "STFUandLOVE", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12eopju/chemical_process_data_data_science_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12eopju/chemical_process_data_data_science_advice/", "subreddit_subscribers": 869029, "created_utc": 1680880828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI tried searching for a roadmap and ended up designing my own, but honestly, I don't know if I'm being too overambitious or just a complete noob about it!\n\n**Some background:** BSc in Econ, Postgraduate in Financial Econ, so stats/finance concepts are not new to me. I work in the pension funds industry but want to switch to a fintech job. I know some R but haven't practised in years.\n\nI would like some advice on this \"roadmap\", feels like it's too short and also that I might not be prioritizing the right stuff! I also can't decide where to start the data analysis journey, on either 2a or 2b!! Thank you all for your help!\n\nhttps://preview.redd.it/amg5evlyahsa1.png?width=2010&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f5e34a90b1c7d56d23bcce6b3f1ee32c1c27aa49\n\nAll in all a 3+ years plan (as I have a day job) if you add in projects along the way to keep practising (and practising!), which I'm fine sticking to.\n\nNote: I'm not expecting you to open all the links!", "author_fullname": "t2_72vcncwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science in Finance | help roadmap", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 55, "top_awarded_type": null, "hide_score": true, "media_metadata": {"amg5evlyahsa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 43, "x": 108, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3af2320e022d1ebe78226f1df69813498b0a351d"}, {"y": 86, "x": 216, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1b3469e3c9a8a6a73c0b62dd9c7665c0cc26ae0"}, {"y": 127, "x": 320, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a838767c26aab2ca3ce1534a275ae772e4c2e7ff"}, {"y": 255, "x": 640, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4dc3dda9e46db8c627f64083bb318937376dfc1"}, {"y": 382, "x": 960, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f07bb2dd4ced5317434210d1e50f4bf56b082bb2"}, {"y": 430, "x": 1080, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc2824a86161e38aacb43296bed01c79ac18f908"}], "s": {"y": 801, "x": 2010, "u": "https://preview.redd.it/amg5evlyahsa1.png?width=2010&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f5e34a90b1c7d56d23bcce6b3f1ee32c1c27aa49"}, "id": "amg5evlyahsa1"}}, "name": "t3_12eol6t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rU105M8zzcPSw_luY7D8kL4ingBzo8AHvZ7ODrm4oCM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680880596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tried searching for a roadmap and ended up designing my own, but honestly, I don&amp;#39;t know if I&amp;#39;m being too overambitious or just a complete noob about it!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Some background:&lt;/strong&gt; BSc in Econ, Postgraduate in Financial Econ, so stats/finance concepts are not new to me. I work in the pension funds industry but want to switch to a fintech job. I know some R but haven&amp;#39;t practised in years.&lt;/p&gt;\n\n&lt;p&gt;I would like some advice on this &amp;quot;roadmap&amp;quot;, feels like it&amp;#39;s too short and also that I might not be prioritizing the right stuff! I also can&amp;#39;t decide where to start the data analysis journey, on either 2a or 2b!! Thank you all for your help!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/amg5evlyahsa1.png?width=2010&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f5e34a90b1c7d56d23bcce6b3f1ee32c1c27aa49\"&gt;https://preview.redd.it/amg5evlyahsa1.png?width=2010&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f5e34a90b1c7d56d23bcce6b3f1ee32c1c27aa49&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;All in all a 3+ years plan (as I have a day job) if you add in projects along the way to keep practising (and practising!), which I&amp;#39;m fine sticking to.&lt;/p&gt;\n\n&lt;p&gt;Note: I&amp;#39;m not expecting you to open all the links!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12eol6t", "is_robot_indexable": true, "report_reasons": null, "author": "badsaying", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12eol6t/data_science_in_finance_help_roadmap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12eol6t/data_science_in_finance_help_roadmap/", "subreddit_subscribers": 869029, "created_utc": 1680880596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I wanted to share a Python library I recently came across called TextScribe. This library offers a streamlined and efficient way to read and write data to CSV, JSON, and TXT files, making data processing faster and more convenient.\n\nSome of the key features of the TextScribe library include:\n\n* Writing data to CSV, TXT, and JSON files with custom labels\n* Extracting data from CSV and TXT files based on specific labels\n* Searching a JSON file for all occurrences of a specified label and returning the corresponding values\n\nI've found this library to be really helpful in my own data processing projects, and I think it could be a great tool for anyone working with these types of files.\n\nIf you're interested, you can check out the library on PyPI here: [**https://pypi.org/project/textscribe/**](https://pypi.org/project/textscribe/)\n\n**Here is the GitHub** [**https://github.com/huntert1004/textscribe**](https://github.com/huntert1004/textscribe)\n\nWaidAI LLC Official Website [https://waidai.co/index.html](https://waidai.co/index.html)\n\nAnd if you have any questions or feedback, feel free to share in the comments below. Thanks!", "author_fullname": "t2_kdovct2j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TextScribe - A Python Library for Efficient Data Processing of CSV, JSON, and TXT Files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12eo0d9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680879486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I wanted to share a Python library I recently came across called TextScribe. This library offers a streamlined and efficient way to read and write data to CSV, JSON, and TXT files, making data processing faster and more convenient.&lt;/p&gt;\n\n&lt;p&gt;Some of the key features of the TextScribe library include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Writing data to CSV, TXT, and JSON files with custom labels&lt;/li&gt;\n&lt;li&gt;Extracting data from CSV and TXT files based on specific labels&lt;/li&gt;\n&lt;li&gt;Searching a JSON file for all occurrences of a specified label and returning the corresponding values&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve found this library to be really helpful in my own data processing projects, and I think it could be a great tool for anyone working with these types of files.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested, you can check out the library on PyPI here: &lt;a href=\"https://pypi.org/project/textscribe/\"&gt;&lt;strong&gt;https://pypi.org/project/textscribe/&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here is the GitHub&lt;/strong&gt; &lt;a href=\"https://github.com/huntert1004/textscribe\"&gt;&lt;strong&gt;https://github.com/huntert1004/textscribe&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;WaidAI LLC Official Website &lt;a href=\"https://waidai.co/index.html\"&gt;https://waidai.co/index.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And if you have any questions or feedback, feel free to share in the comments below. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?auto=webp&amp;v=enabled&amp;s=f0cc8dce4c4d114433073f7ec64bf299623fcef9", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b8865fd719f17e774b2178948603d0c4bfb2673", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7f78455787f3622b85aa8394a3ee4b6f14e35c1", "width": 216, "height": 216}], "variants": {}, "id": "IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12eo0d9", "is_robot_indexable": true, "report_reasons": null, "author": "waidai_the_real_one", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12eo0d9/textscribe_a_python_library_for_efficient_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12eo0d9/textscribe_a_python_library_for_efficient_data/", "subreddit_subscribers": 869029, "created_utc": 1680879486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do my analysis lacks depth?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ejtrx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_8jstn73fy", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "learnpython", "selftext": "This is my first project using python and i was introduced to it since i started learning on datacamp, even the app took me sometime to do it, and i still think it's very amateur, can i have your review?\nN.B not looking for upvotes i already have plenty\n\n\n\nhttps://app.datacamp.com/workspace/w/f885974b-5e59-4465-b2a1-4377297b0e50", "author_fullname": "t2_8jstn73fy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do my analysis lacks depth?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/learnpython", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12btmv3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680636459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnpython", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my first project using python and i was introduced to it since i started learning on datacamp, even the app took me sometime to do it, and i still think it&amp;#39;s very amateur, can i have your review?\nN.B not looking for upvotes i already have plenty&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://app.datacamp.com/workspace/w/f885974b-5e59-4465-b2a1-4377297b0e50\"&gt;https://app.datacamp.com/workspace/w/f885974b-5e59-4465-b2a1-4377297b0e50&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?auto=webp&amp;v=enabled&amp;s=a1bbdb19248ca69b9c3fae09ed92998da10ae548", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9eb4602c442e6f90c1c5f8b609e6c6db1696a2fd", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19c04f01fd6388b64cbc4fae93c1697f88baf238", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fce7dc037a027f5738914fa1191b3a211094e895", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12cf7f4d607429e424966df85cd9e41e4acf56e9", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f297ed18be97367a352a06e4e5c1596f135d0bc", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eddd729c1dbbf4b92afb950d00532e4d13eaf8a7", "width": 1080, "height": 567}], "variants": {}, "id": "8w2P8WuVE2a1VEWKd2llLi8LCgBVsQc6gcW5I5ysexA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8ot", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12btmv3", "is_robot_indexable": true, "report_reasons": null, "author": "Zono198", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/learnpython/comments/12btmv3/do_my_analysis_lacks_depth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/learnpython/comments/12btmv3/do_my_analysis_lacks_depth/", "subreddit_subscribers": 701050, "created_utc": 1680636459.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1680870825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnpython", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/learnpython/comments/12btmv3/do_my_analysis_lacks_depth/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?auto=webp&amp;v=enabled&amp;s=a1bbdb19248ca69b9c3fae09ed92998da10ae548", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9eb4602c442e6f90c1c5f8b609e6c6db1696a2fd", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19c04f01fd6388b64cbc4fae93c1697f88baf238", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fce7dc037a027f5738914fa1191b3a211094e895", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12cf7f4d607429e424966df85cd9e41e4acf56e9", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f297ed18be97367a352a06e4e5c1596f135d0bc", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/bMkPx1z31GOp1-V7iiA8uOkblfYAJV64nnEJoc91vFI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eddd729c1dbbf4b92afb950d00532e4d13eaf8a7", "width": 1080, "height": 567}], "variants": {}, "id": "8w2P8WuVE2a1VEWKd2llLi8LCgBVsQc6gcW5I5ysexA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ejtrx", "is_robot_indexable": true, "report_reasons": null, "author": "Zono198", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12btmv3", "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ejtrx/do_my_analysis_lacks_depth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/learnpython/comments/12btmv3/do_my_analysis_lacks_depth/", "subreddit_subscribers": 869029, "created_utc": 1680870825.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a 5 years experience in SaaS environment as Tech Engineer Supp and Marketing Operations. I got laid off and would like to change career to DA/DS and in process of taking BS Degree in WGU but I am hesitant to continue due to the quality concern. \n\nDo you have any recommendations for online school that have quality curriculum for BS in DA/DS? Or WGU is enough and just support with other resources like data camp?\n\nI am also in military family that\u2019s why I need something I can bring anywhere. Appreciate the insight!", "author_fullname": "t2_12oxot", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advise for BS Degree school", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ejqye", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680870659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 5 years experience in SaaS environment as Tech Engineer Supp and Marketing Operations. I got laid off and would like to change career to DA/DS and in process of taking BS Degree in WGU but I am hesitant to continue due to the quality concern. &lt;/p&gt;\n\n&lt;p&gt;Do you have any recommendations for online school that have quality curriculum for BS in DA/DS? Or WGU is enough and just support with other resources like data camp?&lt;/p&gt;\n\n&lt;p&gt;I am also in military family that\u2019s why I need something I can bring anywhere. Appreciate the insight!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ejqye", "is_robot_indexable": true, "report_reasons": null, "author": "cloudedmind00", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ejqye/seeking_advise_for_bs_degree_school/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ejqye/seeking_advise_for_bs_degree_school/", "subreddit_subscribers": 869029, "created_utc": 1680870659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all! I am currently working as a data scientist and have around two years of experience. I am working from home since the job started and I live in a tier 2 city.\nWorking from home does have some advantages for example rent is saved, family support, more time for hobbies etc.\nBut at the same time I'm not able to network, and work on my growth. I just end up doing the assigned work in job and thats it.\nI still prefer Wfh. But just wanted to understand how can i focus more on growth from the perspective of future in data science, I want to make it big\ud83d\ude05.\nI will be highly thankful if you guys can suggest some tips around How can I grow as a data scientist working from home.  \n\nThank you!", "author_fullname": "t2_9v4zx4k9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can i work on my growth.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ejnp9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680870466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! I am currently working as a data scientist and have around two years of experience. I am working from home since the job started and I live in a tier 2 city.\nWorking from home does have some advantages for example rent is saved, family support, more time for hobbies etc.\nBut at the same time I&amp;#39;m not able to network, and work on my growth. I just end up doing the assigned work in job and thats it.\nI still prefer Wfh. But just wanted to understand how can i focus more on growth from the perspective of future in data science, I want to make it big\ud83d\ude05.\nI will be highly thankful if you guys can suggest some tips around How can I grow as a data scientist working from home.  &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ejnp9", "is_robot_indexable": true, "report_reasons": null, "author": "LetterheadFar5316", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ejnp9/how_can_i_work_on_my_growth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ejnp9/how_can_i_work_on_my_growth/", "subreddit_subscribers": 869029, "created_utc": 1680870466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Coming more from a modeling background, I was wondering if there is a difference between the ICC of an ANOVA framework and a multilevel model, and if so, what is the difference? I am aware that the two approaches differ in that the ANOVA uses the sums of squares and the multilevel approach uses the variance components of the random effects. But does this difference affect practice, or will the results be the same?", "author_fullname": "t2_pfyictop", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ICC: ANOVA vs multilevel framework", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12efrzg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680861108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Coming more from a modeling background, I was wondering if there is a difference between the ICC of an ANOVA framework and a multilevel model, and if so, what is the difference? I am aware that the two approaches differ in that the ANOVA uses the sums of squares and the multilevel approach uses the variance components of the random effects. But does this difference affect practice, or will the results be the same?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12efrzg", "is_robot_indexable": true, "report_reasons": null, "author": "Lazy_Inevitable_9274", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12efrzg/icc_anova_vs_multilevel_framework/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12efrzg/icc_anova_vs_multilevel_framework/", "subreddit_subscribers": 869029, "created_utc": 1680861108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a terrible time committing basic functions to memory and often times find myself googling something as basic as instantiating an X-by-Y dataframe despite doing repeatedly. Here's [this](https://pandas-dataframe-generator.glitch.me) if anyone else is as lazy as I am.\n\nTell me I'm not alone?", "author_fullname": "t2_8qld5k9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a simple webpage for generating Pandas dataframes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dz6xy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680817669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a terrible time committing basic functions to memory and often times find myself googling something as basic as instantiating an X-by-Y dataframe despite doing repeatedly. Here&amp;#39;s &lt;a href=\"https://pandas-dataframe-generator.glitch.me\"&gt;this&lt;/a&gt; if anyone else is as lazy as I am.&lt;/p&gt;\n\n&lt;p&gt;Tell me I&amp;#39;m not alone?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12dz6xy", "is_robot_indexable": true, "report_reasons": null, "author": "additional_pyl0ns", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12dz6xy/i_made_a_simple_webpage_for_generating_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12dz6xy/i_made_a_simple_webpage_for_generating_pandas/", "subreddit_subscribers": 869029, "created_utc": 1680817669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So in SF, Order and Order Products are two separate tables, and when we use it for analysis, we pull both tables, and join them.\n\nin ERP, transaction and transaction lines are also separate tables, and we join them when we need to use them.\n\nSo my question is if i do transformation and then sending them to the Data Warehouse, should i still transform them separately? the Kimball book suggests joining the Transaction and Transaction Line inside the data warehouse as one big table. but this is from a 2007 article...\n\nwhat's the best way now in 2023? or db is Snowflake.\n\nforgot to add our setup. We use Fivetran to bring over SF and ERP data into Snowflake warehouse (without any changes), and then plan to use DBT to do some transformation (getting rid of a lot of useless columns, and customizations) and then bring it back into snowflake as Final table for endpoint analysts to use. My question is regarding the DBT steps.", "author_fullname": "t2_cooe1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about Data Warehouse for ERP/CRM data (Specifically Transaction Data)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dv3un", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680810319.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680809378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So in SF, Order and Order Products are two separate tables, and when we use it for analysis, we pull both tables, and join them.&lt;/p&gt;\n\n&lt;p&gt;in ERP, transaction and transaction lines are also separate tables, and we join them when we need to use them.&lt;/p&gt;\n\n&lt;p&gt;So my question is if i do transformation and then sending them to the Data Warehouse, should i still transform them separately? the Kimball book suggests joining the Transaction and Transaction Line inside the data warehouse as one big table. but this is from a 2007 article...&lt;/p&gt;\n\n&lt;p&gt;what&amp;#39;s the best way now in 2023? or db is Snowflake.&lt;/p&gt;\n\n&lt;p&gt;forgot to add our setup. We use Fivetran to bring over SF and ERP data into Snowflake warehouse (without any changes), and then plan to use DBT to do some transformation (getting rid of a lot of useless columns, and customizations) and then bring it back into snowflake as Final table for endpoint analysts to use. My question is regarding the DBT steps.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12dv3un", "is_robot_indexable": true, "report_reasons": null, "author": "tyw214", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12dv3un/question_about_data_warehouse_for_erpcrm_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12dv3un/question_about_data_warehouse_for_erpcrm_data/", "subreddit_subscribers": 869029, "created_utc": 1680809378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am thrilled to announce to all of you who are looking for real-world project to show in portfolio, i am hosting a 2 months local chapter in Omdena \"Developing a forest fire detection system in Algeria using satellite imagery and machine learning\", beginners and experts are all welcome to join \n\nhttps://omdena.com/projects/developing-a-forest-fire-detection-and-monitoring-system-for-algeria/", "author_fullname": "t2_3n9hivan", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "real-world AI project looking for collaborators(beginners or experts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dtb34", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680805826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thrilled to announce to all of you who are looking for real-world project to show in portfolio, i am hosting a 2 months local chapter in Omdena &amp;quot;Developing a forest fire detection system in Algeria using satellite imagery and machine learning&amp;quot;, beginners and experts are all welcome to join &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://omdena.com/projects/developing-a-forest-fire-detection-and-monitoring-system-for-algeria/\"&gt;https://omdena.com/projects/developing-a-forest-fire-detection-and-monitoring-system-for-algeria/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zGfIM0Ozo1Bxy5vziT62CCYvKY749u7qMPGqoTZBGhg.jpg?auto=webp&amp;v=enabled&amp;s=24340473ae28813dadf53122fa03f75c4f4a5c5a", "width": 2560, "height": 1700}, "resolutions": [{"url": "https://external-preview.redd.it/zGfIM0Ozo1Bxy5vziT62CCYvKY749u7qMPGqoTZBGhg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d3f824d145b1cdd427774d56402167c17b31de3", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/zGfIM0Ozo1Bxy5vziT62CCYvKY749u7qMPGqoTZBGhg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36185c9f84bb07da964ab5a2d86b3926f44937b7", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/zGfIM0Ozo1Bxy5vziT62CCYvKY749u7qMPGqoTZBGhg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d10b096d171aec406e37626ec3a4ec6afc86fcdb", "width": 320, "height": 212}, {"url": "https://external-preview.redd.it/zGfIM0Ozo1Bxy5vziT62CCYvKY749u7qMPGqoTZBGhg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=716af971639fc440785b1e3fcde3c0fb57c94c2c", "width": 640, "height": 425}, {"url": "https://external-preview.redd.it/zGfIM0Ozo1Bxy5vziT62CCYvKY749u7qMPGqoTZBGhg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=16e3f9e6a5cc56f4d6b63946bbfce771741c9b33", "width": 960, "height": 637}, {"url": "https://external-preview.redd.it/zGfIM0Ozo1Bxy5vziT62CCYvKY749u7qMPGqoTZBGhg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f80eb88d1243f4a82171a0a7c3e3383810c04fd", "width": 1080, "height": 717}], "variants": {}, "id": "971COXhfyQiSUBEjaXtCVhdLOMGXNKteAFNJ15t_Dvo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12dtb34", "is_robot_indexable": true, "report_reasons": null, "author": "how_why123", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12dtb34/realworld_ai_project_looking_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12dtb34/realworld_ai_project_looking_for/", "subreddit_subscribers": 869029, "created_utc": 1680805826.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've 10 numerical and large datasets where each has 3 generic categories. Each row contains unique data. The end row of each dataset contains the labels for each category. The category is not distinct thus other row may refer to any of the 3 categories.\n\ne.g.\n\n&amp;#x200B;\n\n|Date|Value|Category|\n|:-|:-|:-|\n|1/1/2010|1.11111|Alpha|\n|2/1/2010|2.11111|Beta|\n|3/1/2010|2.00009|Alpha|\n|4/1/2010|0.00000|Charlie|\n\nBut the 10 datasets have different volume of data. E.g.  dataset A may have 10K rows, dataset B around 100K, Dataset C 1 million, etc.\n\nI couldn't process all the data as its too large.\n\nWhat would be the best way to sample each dataset? I'd like the sample containing a fair representative of the 3 categories.", "author_fullname": "t2_3z6gqvrh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to represent large categorical data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12eggr2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680863173.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680862933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve 10 numerical and large datasets where each has 3 generic categories. Each row contains unique data. The end row of each dataset contains the labels for each category. The category is not distinct thus other row may refer to any of the 3 categories.&lt;/p&gt;\n\n&lt;p&gt;e.g.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Date&lt;/th&gt;\n&lt;th align=\"left\"&gt;Value&lt;/th&gt;\n&lt;th align=\"left\"&gt;Category&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1/1/2010&lt;/td&gt;\n&lt;td align=\"left\"&gt;1.11111&lt;/td&gt;\n&lt;td align=\"left\"&gt;Alpha&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2/1/2010&lt;/td&gt;\n&lt;td align=\"left\"&gt;2.11111&lt;/td&gt;\n&lt;td align=\"left\"&gt;Beta&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3/1/2010&lt;/td&gt;\n&lt;td align=\"left\"&gt;2.00009&lt;/td&gt;\n&lt;td align=\"left\"&gt;Alpha&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;4/1/2010&lt;/td&gt;\n&lt;td align=\"left\"&gt;0.00000&lt;/td&gt;\n&lt;td align=\"left\"&gt;Charlie&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;But the 10 datasets have different volume of data. E.g.  dataset A may have 10K rows, dataset B around 100K, Dataset C 1 million, etc.&lt;/p&gt;\n\n&lt;p&gt;I couldn&amp;#39;t process all the data as its too large.&lt;/p&gt;\n\n&lt;p&gt;What would be the best way to sample each dataset? I&amp;#39;d like the sample containing a fair representative of the 3 categories.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12eggr2", "is_robot_indexable": true, "report_reasons": null, "author": "runnersgo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12eggr2/how_to_represent_large_categorical_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12eggr2/how_to_represent_large_categorical_data/", "subreddit_subscribers": 869029, "created_utc": 1680862933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "High school mathematics and it's application.", "author_fullname": "t2_4hu9d8ja", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High School Mathematics: The Foundation of AI and ML", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_12e7vd8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8N2ERRT8yjVHbAFXiSoElWqHB1OGyiGSJ1AKoAME_bk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680837218.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "link.medium.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;High school mathematics and it&amp;#39;s application.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://link.medium.com/AncPASteNyb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HSuUuOkRJBRSqWIp1qMInIG8tnXqYoYrg7ijPT69D6k.jpg?auto=webp&amp;v=enabled&amp;s=096114634f34df30fca65b8d8d6a198257e7c757", "width": 300, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/HSuUuOkRJBRSqWIp1qMInIG8tnXqYoYrg7ijPT69D6k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5118a1f42b98e7c39b9d3773b6df811dda4b4493", "width": 108, "height": 162}, {"url": "https://external-preview.redd.it/HSuUuOkRJBRSqWIp1qMInIG8tnXqYoYrg7ijPT69D6k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1903c197af4bb6cc0f2d9347c914dcfdd7b7d074", "width": 216, "height": 324}], "variants": {}, "id": "CCrcUCoKEp9hDDcp72OKSL2-jL3Q3kO5gzz2tXE5t0g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12e7vd8", "is_robot_indexable": true, "report_reasons": null, "author": "Confident_Western", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12e7vd8/high_school_mathematics_the_foundation_of_ai_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://link.medium.com/AncPASteNyb", "subreddit_subscribers": 869029, "created_utc": 1680837218.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi Redditors,\nI have been facing problem predicting user Day 1 churn for a mobile app and game separately.\n\nI could achieve max F1 score of 0.68, but using aggregated user features. I used XGBoost. But the insights/feature importance  are not actionable.\n\nPlease suggest if I should change my target variable that is D1 retention/churn, or should I use sequential features and LSTM like architecture?\n\nIf any suggestions for papers would be appreciated a well.", "author_fullname": "t2_440ofawxp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Research Papers Suggestions for Churn Prediction in Mobile App/Games", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ec8y0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680849137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Redditors,\nI have been facing problem predicting user Day 1 churn for a mobile app and game separately.&lt;/p&gt;\n\n&lt;p&gt;I could achieve max F1 score of 0.68, but using aggregated user features. I used XGBoost. But the insights/feature importance  are not actionable.&lt;/p&gt;\n\n&lt;p&gt;Please suggest if I should change my target variable that is D1 retention/churn, or should I use sequential features and LSTM like architecture?&lt;/p&gt;\n\n&lt;p&gt;If any suggestions for papers would be appreciated a well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ec8y0", "is_robot_indexable": true, "report_reasons": null, "author": "tushar8sk", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ec8y0/research_papers_suggestions_for_churn_prediction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ec8y0/research_papers_suggestions_for_churn_prediction/", "subreddit_subscribers": 869029, "created_utc": 1680849137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Are you a data whiz, language expert, or someone who is interested in pushing the boundaries of large language models? We\u2019re looking to revolutionize the way we understand and interact with financial data and want to have a little fun by launching a challenge with a chance to win $1000.\n\nWe are doing something like this on our GPInvestBot Twitter, but think we can make it even more interesting by engaging with others.\n\nMost liked headline/tweet created automatically summarizing macroeconomic and financial time series data wins. More details here: https://www.globalpredictions.com/posts/unlocking-insights-in-time-series-data-the-generative-ai-challenge", "author_fullname": "t2_p9otw1al", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to push the boundaries? New challenge to turn macro data into interesting insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dqjha", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680800420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are you a data whiz, language expert, or someone who is interested in pushing the boundaries of large language models? We\u2019re looking to revolutionize the way we understand and interact with financial data and want to have a little fun by launching a challenge with a chance to win $1000.&lt;/p&gt;\n\n&lt;p&gt;We are doing something like this on our GPInvestBot Twitter, but think we can make it even more interesting by engaging with others.&lt;/p&gt;\n\n&lt;p&gt;Most liked headline/tweet created automatically summarizing macroeconomic and financial time series data wins. More details here: &lt;a href=\"https://www.globalpredictions.com/posts/unlocking-insights-in-time-series-data-the-generative-ai-challenge\"&gt;https://www.globalpredictions.com/posts/unlocking-insights-in-time-series-data-the-generative-ai-challenge&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7AuEb9DaOBM5SbScEjNQg-AzfC9e52u2PO2WN7GkotY.jpg?auto=webp&amp;v=enabled&amp;s=0fba279202c7fd132a1b2474de83d7459578e681", "width": 1910, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/7AuEb9DaOBM5SbScEjNQg-AzfC9e52u2PO2WN7GkotY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfc5e4751d806349c96a3bc6a2fd69c835382a49", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7AuEb9DaOBM5SbScEjNQg-AzfC9e52u2PO2WN7GkotY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20e12f6970ed8eb7015de7a14f060737ef0f42e7", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/7AuEb9DaOBM5SbScEjNQg-AzfC9e52u2PO2WN7GkotY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e0ef79987d80b02b2438ad474238253cdbf667f", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/7AuEb9DaOBM5SbScEjNQg-AzfC9e52u2PO2WN7GkotY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=368cd28d8fa82501c9782f47d6191e246a9754d6", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/7AuEb9DaOBM5SbScEjNQg-AzfC9e52u2PO2WN7GkotY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1a437ec26ce30a0cac93c282a033b5d25231d25", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/7AuEb9DaOBM5SbScEjNQg-AzfC9e52u2PO2WN7GkotY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1ae250158e104c18068aafec508feefe5472d56", "width": 1080, "height": 565}], "variants": {}, "id": "m6ZIV4lMAqK8horuOkbW85X4N-4BOMbbhvGxVqlIZkU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12dqjha", "is_robot_indexable": true, "report_reasons": null, "author": "BenGlobalPredictions", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12dqjha/looking_to_push_the_boundaries_new_challenge_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12dqjha/looking_to_push_the_boundaries_new_challenge_to/", "subreddit_subscribers": 869029, "created_utc": 1680800420.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}