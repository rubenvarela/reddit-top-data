{"kind": "Listing", "data": {"after": "t3_133rf3z", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_84cmf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "iMessage Exporter 1.4.0: Cliff Aster adds support for iOS Backup parsing and deleted message recovery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_133ahkj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 255, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 255, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/EuMq_5nztYH4H0z6uxGn-rTm5_SoDSoLqNUFoDJOHB4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682812432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/ReagentX/imessage-exporter/#", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uxMe5AJ2c9vF2Sl5W71IV5hS6SkeG1mA6ZQmbSnRwmA.jpg?auto=webp&amp;v=enabled&amp;s=2e2dbc179641dfe12a651024a6d9e65d87eaec54", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/uxMe5AJ2c9vF2Sl5W71IV5hS6SkeG1mA6ZQmbSnRwmA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0a7705bf8a8d87880f3ef221360fc23fb20bd42", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/uxMe5AJ2c9vF2Sl5W71IV5hS6SkeG1mA6ZQmbSnRwmA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec24f51a1642a4a3f74cda5c00ef186d5896362b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/uxMe5AJ2c9vF2Sl5W71IV5hS6SkeG1mA6ZQmbSnRwmA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa47bd8a1169bb34b10146cb7e4c2f71f87eafc9", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/uxMe5AJ2c9vF2Sl5W71IV5hS6SkeG1mA6ZQmbSnRwmA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d3e5228e20f97f05089f5e7e72c2978d6e5d3de6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/uxMe5AJ2c9vF2Sl5W71IV5hS6SkeG1mA6ZQmbSnRwmA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ab22cdc56e497bab2aef116952144dd112b14b1", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/uxMe5AJ2c9vF2Sl5W71IV5hS6SkeG1mA6ZQmbSnRwmA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7b0ed81033be4d1dd6425de1e6c82ce89bc56b3", "width": 1080, "height": 540}], "variants": {}, "id": "4K8FJDLv_P0yHg15I-0un1wa7xJsp-23L5KsOpZkBRo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133ahkj", "is_robot_indexable": true, "report_reasons": null, "author": "ReagentX", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133ahkj/imessage_exporter_140_cliff_aster_adds_support/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/ReagentX/imessage-exporter/#", "subreddit_subscribers": 680312, "created_utc": 1682812432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_l1ud2si", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How it started vs how it\u2019s going. $40 PC I spontaneously picked up and turned into my first server compared to my new build today. Not sure how much longer I can resist the urge to make a financial oopsie and fill up all those new drive bays.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_133dw35", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 20, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2Fcrcm6Q0%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2Fcrcm6Q0&amp;image=https%3A%2F%2Fi.imgur.com%2FV0yG7Vq.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"840\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "height": 840}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "imgur.com", "oembed": {"provider_url": "http://imgur.com", "description": "Discover the magic of the internet at Imgur, a community powered entertainment destination. Lift your spirits with funny jokes, trending memes, entertaining gifs, inspiring stories, viral videos, and so much more from users.", "title": "Imgur", "url": "https://imgur.com/a/crcm6Q0", "type": "rich", "thumbnail_width": 600, "height": 840, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2Fcrcm6Q0%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2Fcrcm6Q0&amp;image=https%3A%2F%2Fi.imgur.com%2FV0yG7Vq.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"840\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "Imgur", "thumbnail_url": "https://i.imgur.com/V0yG7Vq.jpg?fb", "thumbnail_height": 315}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2Fcrcm6Q0%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2Fcrcm6Q0&amp;image=https%3A%2F%2Fi.imgur.com%2FV0yG7Vq.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"840\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/133dw35", "height": 840}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/yEBF6fwO6xsbD9Dh5Uf8XzNe8Lwmbpz6r2NrYalMEgU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682822686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://imgur.com/a/crcm6Q0/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7-DTGEYuVrKKAsto9w57mqBqs3ki7ZGnLHJmPUWFVZ8.jpg?auto=webp&amp;v=enabled&amp;s=2ea657b6a5caa85a7eff96c89d5ed6f4baa3fee2", "width": 1500, "height": 2000}, "resolutions": [{"url": "https://external-preview.redd.it/7-DTGEYuVrKKAsto9w57mqBqs3ki7ZGnLHJmPUWFVZ8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04950bb522eece86a765cf15d4e1b5ae0a5ba966", "width": 108, "height": 144}, {"url": "https://external-preview.redd.it/7-DTGEYuVrKKAsto9w57mqBqs3ki7ZGnLHJmPUWFVZ8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9dcebf2aa5062cebdc911e144160ab093b2be99", "width": 216, "height": 288}, {"url": "https://external-preview.redd.it/7-DTGEYuVrKKAsto9w57mqBqs3ki7ZGnLHJmPUWFVZ8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b33d1785fa457f87137a435d7b3a7a66d55a6da", "width": 320, "height": 426}, {"url": "https://external-preview.redd.it/7-DTGEYuVrKKAsto9w57mqBqs3ki7ZGnLHJmPUWFVZ8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae74b8644f5da1dc75256c02fc9d191a591731fd", "width": 640, "height": 853}, {"url": "https://external-preview.redd.it/7-DTGEYuVrKKAsto9w57mqBqs3ki7ZGnLHJmPUWFVZ8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7c3426067c59e925d023605bb8406ea9c6e70ff", "width": 960, "height": 1280}, {"url": "https://external-preview.redd.it/7-DTGEYuVrKKAsto9w57mqBqs3ki7ZGnLHJmPUWFVZ8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28ebf6bd95a6399c297ee87b2cbd819110f83c6b", "width": 1080, "height": 1440}], "variants": {}, "id": "qmXHFu_ljCoiLzvjeVNH2NNMU_NLPrAqNR2Rxp-gTD4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133dw35", "is_robot_indexable": true, "report_reasons": null, "author": "purpan-", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133dw35/how_it_started_vs_how_its_going_40_pc_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://imgur.com/a/crcm6Q0/", "subreddit_subscribers": 680312, "created_utc": 1682822686.0, "num_crossposts": 0, "media": {"type": "imgur.com", "oembed": {"provider_url": "http://imgur.com", "description": "Discover the magic of the internet at Imgur, a community powered entertainment destination. Lift your spirits with funny jokes, trending memes, entertaining gifs, inspiring stories, viral videos, and so much more from users.", "title": "Imgur", "url": "https://imgur.com/a/crcm6Q0", "type": "rich", "thumbnail_width": 600, "height": 840, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2Fcrcm6Q0%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2Fcrcm6Q0&amp;image=https%3A%2F%2Fi.imgur.com%2FV0yG7Vq.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"840\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "Imgur", "thumbnail_url": "https://i.imgur.com/V0yG7Vq.jpg?fb", "thumbnail_height": 315}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Kind of off topic maybe, but where do you guys buy used hard drives, flash drives, sd cards, etc? I've been working on a pet project involving compaction for awhile and its getting expensive to keep ordering off of mercari and the like when i burn out another drive. The project isn't stable enough to justify using new just yet.", "author_fullname": "t2_3x3jc7gd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you guys buy used hard drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133d11a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682820016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Kind of off topic maybe, but where do you guys buy used hard drives, flash drives, sd cards, etc? I&amp;#39;ve been working on a pet project involving compaction for awhile and its getting expensive to keep ordering off of mercari and the like when i burn out another drive. The project isn&amp;#39;t stable enough to justify using new just yet.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133d11a", "is_robot_indexable": true, "report_reasons": null, "author": "NimbleNavigator19", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133d11a/where_do_you_guys_buy_used_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133d11a/where_do_you_guys_buy_used_hard_drives/", "subreddit_subscribers": 680312, "created_utc": 1682820016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Attention data hoarders! Are you tired of losing your Reddit chats when switching accounts or deleting them altogether? Fear not, because there's now a tool to help you liberate your Reddit chats. Introducing Rexit - the Reddit Brexit tool that exports your Reddit chats into a variety of open formats, such as CSV, JSON, and TXT.\n\nUsing Rexit is simple. Just specify the formats you want to export to using the --formats option, and enter your Reddit username and password when prompted. Rexit will then save your chats to the current directory. If an image was sent in the chat, the filename will be displayed as the message content, prefixed with FILE.\n\nHere's an example usage of Rexit:\n\n    $ rexit --formats csv,json,txt\n    &gt; Your Reddit Username: &lt;USERNAME&gt;\n    &gt; Your Reddit Password: &lt;PASSWORD&gt;\n    \n\n&amp;#x200B;\n\nRexit can be installed via the files provided in the releases page of the GitHub repository, via Cargo homebrew, or build from source. \n\n**To install via Cargo, simply run:**\n\n    $ cargo install rexit\n\n**using homebrew:**\n\n    $ brew tap mpult/mpult \n    $ brew install rexit\n\n**from source:**\n\nyou probably know what you're doing (or I hope so). Use the instructions in the [Readme](https://github.com/MPult/Rexit)\n\nAll contributions are welcome. For documentation on contributing and technical information, run cargo doc --open in your terminal. \n\nRexit is licensed under the GNU General Public License, Version 3.\n\n&amp;#x200B;\n\nIf you have any questions ask me! or checkout the [GitHub](https://github.com/MPult/Rexit).\n\nSay goodbye to lost Reddit chats and hello to data hoarding with Rexit!", "author_fullname": "t2_vkc3rydr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rexit v1.0.0 - Export your Reddit chats!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133xxqy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682876064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Attention data hoarders! Are you tired of losing your Reddit chats when switching accounts or deleting them altogether? Fear not, because there&amp;#39;s now a tool to help you liberate your Reddit chats. Introducing Rexit - the Reddit Brexit tool that exports your Reddit chats into a variety of open formats, such as CSV, JSON, and TXT.&lt;/p&gt;\n\n&lt;p&gt;Using Rexit is simple. Just specify the formats you want to export to using the --formats option, and enter your Reddit username and password when prompted. Rexit will then save your chats to the current directory. If an image was sent in the chat, the filename will be displayed as the message content, prefixed with FILE.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s an example usage of Rexit:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;$ rexit --formats csv,json,txt\n&amp;gt; Your Reddit Username: &amp;lt;USERNAME&amp;gt;\n&amp;gt; Your Reddit Password: &amp;lt;PASSWORD&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Rexit can be installed via the files provided in the releases page of the GitHub repository, via Cargo homebrew, or build from source. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;To install via Cargo, simply run:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;$ cargo install rexit\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;using homebrew:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;$ brew tap mpult/mpult \n$ brew install rexit\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;from source:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;you probably know what you&amp;#39;re doing (or I hope so). Use the instructions in the &lt;a href=\"https://github.com/MPult/Rexit\"&gt;Readme&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;All contributions are welcome. For documentation on contributing and technical information, run cargo doc --open in your terminal. &lt;/p&gt;\n\n&lt;p&gt;Rexit is licensed under the GNU General Public License, Version 3.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you have any questions ask me! or checkout the &lt;a href=\"https://github.com/MPult/Rexit\"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Say goodbye to lost Reddit chats and hello to data hoarding with Rexit!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ebjx888g0-LbUrtgh6akhlpIS3ulTMEF5bHkrmHQ2K8.jpg?auto=webp&amp;v=enabled&amp;s=a0e2b097c867f011513addd7de362f08508754ac", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Ebjx888g0-LbUrtgh6akhlpIS3ulTMEF5bHkrmHQ2K8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=248774bdf2dc93dc7587ca947f30b9e444e11e04", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Ebjx888g0-LbUrtgh6akhlpIS3ulTMEF5bHkrmHQ2K8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=486afa539c8a283241a4c5d834c02c0d0eb500c4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Ebjx888g0-LbUrtgh6akhlpIS3ulTMEF5bHkrmHQ2K8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e058e0ca10273340656fe025d5028bbcc3352ad", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Ebjx888g0-LbUrtgh6akhlpIS3ulTMEF5bHkrmHQ2K8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73069070f2259cc033ee9d054555e002ec45f9f8", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Ebjx888g0-LbUrtgh6akhlpIS3ulTMEF5bHkrmHQ2K8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54fa41b4525a2fef147e7347aaea95b09aa79bea", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Ebjx888g0-LbUrtgh6akhlpIS3ulTMEF5bHkrmHQ2K8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db848978440634a5ed0c2a746cb86c63b298cea3", "width": 1080, "height": 540}], "variants": {}, "id": "aZWW6ru-XU5GJmzn86c4duCXetEp84WK3Zc77bF_eD8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133xxqy", "is_robot_indexable": true, "report_reasons": null, "author": "New-Yak-3548", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133xxqy/rexit_v100_export_your_reddit_chats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133xxqy/rexit_v100_export_your_reddit_chats/", "subreddit_subscribers": 680312, "created_utc": 1682876064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking at scanners for my printed photos instead of paying for one of the digitizing companies. I'm only doing prints, no negatives or other types. What should I look for in the specs and features? The 3 I'm looking at so far are the Epson Perfection V39, Plustek ephoto Z300, and Canon CanoScan Lide 400.\n\n&amp;#x200B;\n\nThanks", "author_fullname": "t2_hahbwvw5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to look for in a photo scanner?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13386zh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682806149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking at scanners for my printed photos instead of paying for one of the digitizing companies. I&amp;#39;m only doing prints, no negatives or other types. What should I look for in the specs and features? The 3 I&amp;#39;m looking at so far are the Epson Perfection V39, Plustek ephoto Z300, and Canon CanoScan Lide 400.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13386zh", "is_robot_indexable": true, "report_reasons": null, "author": "DogsAreCool89", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13386zh/what_to_look_for_in_a_photo_scanner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13386zh/what_to_look_for_in_a_photo_scanner/", "subreddit_subscribers": 680312, "created_utc": 1682806149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_d3wk5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Is this a SAS or SATA disk?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"s9z0j10xm1xa1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/s9z0j10xm1xa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6f3d975ac95638575db67abc21be5cfd0867e5a"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/s9z0j10xm1xa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a51e4185bb96829b9390c7979924d460a2e662ec"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/s9z0j10xm1xa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=68884add6731e345ca9dc3aa54c902d3777fb262"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/s9z0j10xm1xa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1d1463edb95da942a7ee36baa449cb63284e0e4"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/s9z0j10xm1xa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57642afc659704f3c887c1b649a38d2c35714a78"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/s9z0j10xm1xa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33ad5d5972fc4214c2747d0f0160219d9c4fa69f"}], "s": {"y": 2778, "x": 1284, "u": "https://preview.redd.it/s9z0j10xm1xa1.jpg?width=1284&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6c0756550f839c69728f589c5741ccd0c7b13cfb"}, "id": "s9z0j10xm1xa1"}, "plck010xm1xa1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/plck010xm1xa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d877484872ac23daa439d4860b50668282da38c"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/plck010xm1xa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8db0a57f84ffbfe47e2d6d6c2417cc4c4a0ecb59"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/plck010xm1xa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b411e9be93297a661f358c3ef8c5a19511d4648"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/plck010xm1xa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af519d99db5b707336b290d4c6478d0a4b56c084"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/plck010xm1xa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=485b7caf2a6250248e71258cd6e5dfb3b86591db"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/plck010xm1xa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ded5440880d24626c7ac89c5abc2abb41d04690d"}], "s": {"y": 2778, "x": 1284, "u": "https://preview.redd.it/plck010xm1xa1.jpg?width=1284&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=924fd64dc466d33f6de5a879d97ea2f898374182"}, "id": "plck010xm1xa1"}, "d3w1i10xm1xa1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/d3w1i10xm1xa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=903b2ebcf64cf5c7a13757974962cb7fbbe8ee83"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/d3w1i10xm1xa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=41decc5079cbc5a77f5cab91e805b07742acdafa"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/d3w1i10xm1xa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6f4d16165156ca7b618fe35540faad0ca2ffadc"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/d3w1i10xm1xa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8224fd8916fcefd7b0c074977ccb56c27efd36f5"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/d3w1i10xm1xa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca3d4eccb7863308fcd92ef5826828a4369f741f"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/d3w1i10xm1xa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6eab3dbf6968fec0bd0d5f6f5e104d933ef5d5e6"}], "s": {"y": 2778, "x": 1284, "u": "https://preview.redd.it/d3w1i10xm1xa1.jpg?width=1284&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=dc67971d2a892d4242d39151ec986d84ac2fc3ff"}, "id": "d3w1i10xm1xa1"}}, "name": "t3_133vgvs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "ups": 15, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "Is says SAS in the title but SATA in the description. ", "media_id": "d3w1i10xm1xa1", "id": 269575437}, {"media_id": "plck010xm1xa1", "id": 269575438}, {"media_id": "s9z0j10xm1xa1", "id": 269575439}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hI-XRq7SsmuAIwskBVy7t_h-GrVL7THNni3ioyTvqfg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682869972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/133vgvs", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133vgvs", "is_robot_indexable": true, "report_reasons": null, "author": "bullerwins", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133vgvs/is_this_a_sas_or_sata_disk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/133vgvs", "subreddit_subscribers": 680312, "created_utc": 1682869972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently purchased an external Seagate One Touch Hub 8TB which contains a Seagate Barracuda ST8000DM004, an SMR disk. My intentions were to download torrents directly then keep it running 24/7 to seed, however I've realized this is not the ideal workload for an SMR disk due to slow writing speeds.\n\nI've been trying to read a lot and I've found different answers about the reading speeds as well, some say the writing speeds are fine, others say they're not so great. Would torrenting to a internal CMR drive, then transfer the content to the SMR to let it continously seed many torrents bottleneck me or cause me any problems?", "author_fullname": "t2_z8kgu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Issues with seeding 24/7 from an external SMR disk?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1339tvo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682810600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently purchased an external Seagate One Touch Hub 8TB which contains a Seagate Barracuda ST8000DM004, an SMR disk. My intentions were to download torrents directly then keep it running 24/7 to seed, however I&amp;#39;ve realized this is not the ideal workload for an SMR disk due to slow writing speeds.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been trying to read a lot and I&amp;#39;ve found different answers about the reading speeds as well, some say the writing speeds are fine, others say they&amp;#39;re not so great. Would torrenting to a internal CMR drive, then transfer the content to the SMR to let it continously seed many torrents bottleneck me or cause me any problems?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1339tvo", "is_robot_indexable": true, "report_reasons": null, "author": "smokepasta", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1339tvo/issues_with_seeding_247_from_an_external_smr_disk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1339tvo/issues_with_seeding_247_from_an_external_smr_disk/", "subreddit_subscribers": 680312, "created_utc": 1682810600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there, new to this sub, so please be gentle with me.\n\n&amp;#x200B;\n\nCurrent setup: Xpenology NAS with 4 3TB drives in RAID5\n\nLooking to purchase 2 22TB drives with the plan of buying another 2 in the future.\n\nUnsure of the best way to set it up, so that I can add the 2 additional drives later without having to move the data around too much.\n\nAlso unsure even if I bought all 4 at once, if I should run them in RAID5 or not.\n\n&amp;#x200B;\n\nAny help would be much appreciated, I am not tied to Xpenology for the OS.\n\n&amp;#x200B;\n\nEdit: Thinking I will actually end up using TrueNAS Core", "author_fullname": "t2_io7qy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Planning...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133q8vx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682861499.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682860881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, new to this sub, so please be gentle with me.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Current setup: Xpenology NAS with 4 3TB drives in RAID5&lt;/p&gt;\n\n&lt;p&gt;Looking to purchase 2 22TB drives with the plan of buying another 2 in the future.&lt;/p&gt;\n\n&lt;p&gt;Unsure of the best way to set it up, so that I can add the 2 additional drives later without having to move the data around too much.&lt;/p&gt;\n\n&lt;p&gt;Also unsure even if I bought all 4 at once, if I should run them in RAID5 or not.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any help would be much appreciated, I am not tied to Xpenology for the OS.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: Thinking I will actually end up using TrueNAS Core&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "12TB (9TB Usable)", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133q8vx", "is_robot_indexable": true, "report_reasons": null, "author": "Connerzzz6", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/133q8vx/planning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133q8vx/planning/", "subreddit_subscribers": 680312, "created_utc": 1682860881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Whether 'tis nobler to convert my archived files into gzip tarballs or just leave them as-is. I mostly collect FLAC, MP3, JPG, PDF, and EPUB files. I've tried compressing some of them, but the size reduction is insignificant. Any (dis)advantages if I bother archiving them?", "author_fullname": "t2_im7u2xpy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To compress or not to compress, that is the question.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133qe0e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682861025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Whether &amp;#39;tis nobler to convert my archived files into gzip tarballs or just leave them as-is. I mostly collect FLAC, MP3, JPG, PDF, and EPUB files. I&amp;#39;ve tried compressing some of them, but the size reduction is insignificant. Any (dis)advantages if I bother archiving them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "500GB (noob)", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133qe0e", "is_robot_indexable": true, "report_reasons": null, "author": "HaveOurBaskets", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/133qe0e/to_compress_or_not_to_compress_that_is_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133qe0e/to_compress_or_not_to_compress_that_is_the/", "subreddit_subscribers": 680312, "created_utc": 1682861025.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't expect help, as I don't see many AP fans here, so consider this a chronicling.\n\n&amp;#x200B;\n\nTL;DR\n\nUsing Amazon Photos as a photo \\*access &amp; tagging\\* service (not backup, just for access) is good and you can argue me in the comments if you think otherwise. BUT it doesn't offer multi-user access to a central repository and that sucks, since Amazon has multi-user access to prime, books, movies, and purchased content.\n\n&amp;#x200B;\n\nMy spouse recently presented me with the classic user problem \"Where's my stuff?\".\n\n&amp;#x200B;\n\nNow, despite having meticulously organized a OneDrive for cloud access of our local data repository that includes a well-organized but not overly-deep folder structure that I designed specifically based on their recommendations, the sheer volume of photos, video, and other documents that we produce makes search a bit of a challenge, especially when Google Photos as the default has gotten so good at AI-tagging of images that searching \"Flower\" finds plants and \"Flour\" finds baking supplies. \n\n&amp;#x200B;\n\nSo I get it.\n\n&amp;#x200B;\n\nRemembering the near-date of a picture and searching through EXIF-named, data tagged items in a OneDrive is not as easy as just typing in \"cat\" and getting cats. \n\n&amp;#x200B;\n\nSo that leaves me with 2 problems...\n\n\\-1- How do I provide not only a stable backup solution of all our joint photos taken from their phone, my phone, our shared DSLR camera, and all other one-off upload/backup requests we get from family, who know us as the go-to backup dump for data? &lt;&lt;&lt;&lt;&lt; Easy, solved. 3-2-1. Local, Offsite, Encrypted, done.\n\n\\-2- How Do I let my spouse search \"cat\" on their phone and get pictures of our cat. &lt;&lt;&lt; Messier, that one.\n\n&amp;#x200B;\n\nThe default here is going to be Google Photos or iCloud, as most users are going to be on Android or Apple, but I don't love that. I've got problems with both companies as companies and on top of that we already have Pixel phones that are doing *some* photo backups to Google Photos, so we can't use iCloud and using Google Photos would require me untangling the 50k+ photos in the repository that already have a lot of overlap, as well as downloading both accounts' photos to a central repository on my backup server for offsite backups, and it all just gets quite complicated quite quickly.\n\nSo fine, something that is NOT google Photos, is NOT iCloud, searches with AI photo tagging, and has a good user interface.\n\nMy gut said OneDrive - have you tried OneDrive's AI photo search feature? It was raved about as the greatest thing since sliced bread in several articles in 2018..... I assume they fired that engineering team because it's simply non-existent. There is SOME photo tagging with auto-generated tags, but they're random and non-syncing with the Windows file metadata so even manually tagged photos don't show up in search. Complete trash. Literally useless for the one reason I switched. Guess that's my lesson to test a service before hinging everything on it.\n\nSo now I'm on to the next in line on non-self-hosted AI-tagging platforms with neat-o UX - Amazon Photos.\n\n&amp;#x200B;\n\n1) Does it respect my privacy? -- No, absolutely not\n\n2) Do I feel like my photos are in a safe, long term storage environment? -- Again, no. I expect this service to die within the next 2 years\n\n3) Can my spouse now do AI-tagged searches of photos on their phone via a sleek auto-organizing interface? -- Yes!! Mission Accomplished.\n\n&amp;#x200B;\n\nThe only drawback so far - and this is a big one - despite us having 2 separate Amazon accounts linked to the same prime subscription which allows for purchased-content sharing, there is basically no way to both look at the Amazon Photo repository on our individual devices without logging into the same account. The bummer there is that the login syncs between Amazon shopping and Amazon Photos, so I can't stay logged into my shopping account without losing access to view all the photos.\n\nThis sucks and, ultimately, will cause me to abandon the app if it's not fixed before I can find a new service to fill the need, maybe Flickr cloud hosting? (or buck up the money for a self-hosted OpenVPN and the time to build out LibrePhotos).\n\n&amp;#x200B;\n\nI'm open to opinions on this, just know that \\*I know\\* this is not a long-term backup. This is sheerly for the sake of cloud access + AI tagging without me needing to build a local LibrePhotos + OpenVPN solution on my apartment wifi. All off-site backups &amp; multiple copies are settled here.", "author_fullname": "t2_3hqf1pst", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Amazon Photos Multi-User Access", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133bf06", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682815128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t expect help, as I don&amp;#39;t see many AP fans here, so consider this a chronicling.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;TL;DR&lt;/p&gt;\n\n&lt;p&gt;Using Amazon Photos as a photo *access &amp;amp; tagging* service (not backup, just for access) is good and you can argue me in the comments if you think otherwise. BUT it doesn&amp;#39;t offer multi-user access to a central repository and that sucks, since Amazon has multi-user access to prime, books, movies, and purchased content.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My spouse recently presented me with the classic user problem &amp;quot;Where&amp;#39;s my stuff?&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now, despite having meticulously organized a OneDrive for cloud access of our local data repository that includes a well-organized but not overly-deep folder structure that I designed specifically based on their recommendations, the sheer volume of photos, video, and other documents that we produce makes search a bit of a challenge, especially when Google Photos as the default has gotten so good at AI-tagging of images that searching &amp;quot;Flower&amp;quot; finds plants and &amp;quot;Flour&amp;quot; finds baking supplies. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So I get it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Remembering the near-date of a picture and searching through EXIF-named, data tagged items in a OneDrive is not as easy as just typing in &amp;quot;cat&amp;quot; and getting cats. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So that leaves me with 2 problems...&lt;/p&gt;\n\n&lt;p&gt;-1- How do I provide not only a stable backup solution of all our joint photos taken from their phone, my phone, our shared DSLR camera, and all other one-off upload/backup requests we get from family, who know us as the go-to backup dump for data? &amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; Easy, solved. 3-2-1. Local, Offsite, Encrypted, done.&lt;/p&gt;\n\n&lt;p&gt;-2- How Do I let my spouse search &amp;quot;cat&amp;quot; on their phone and get pictures of our cat. &amp;lt;&amp;lt;&amp;lt; Messier, that one.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The default here is going to be Google Photos or iCloud, as most users are going to be on Android or Apple, but I don&amp;#39;t love that. I&amp;#39;ve got problems with both companies as companies and on top of that we already have Pixel phones that are doing &lt;em&gt;some&lt;/em&gt; photo backups to Google Photos, so we can&amp;#39;t use iCloud and using Google Photos would require me untangling the 50k+ photos in the repository that already have a lot of overlap, as well as downloading both accounts&amp;#39; photos to a central repository on my backup server for offsite backups, and it all just gets quite complicated quite quickly.&lt;/p&gt;\n\n&lt;p&gt;So fine, something that is NOT google Photos, is NOT iCloud, searches with AI photo tagging, and has a good user interface.&lt;/p&gt;\n\n&lt;p&gt;My gut said OneDrive - have you tried OneDrive&amp;#39;s AI photo search feature? It was raved about as the greatest thing since sliced bread in several articles in 2018..... I assume they fired that engineering team because it&amp;#39;s simply non-existent. There is SOME photo tagging with auto-generated tags, but they&amp;#39;re random and non-syncing with the Windows file metadata so even manually tagged photos don&amp;#39;t show up in search. Complete trash. Literally useless for the one reason I switched. Guess that&amp;#39;s my lesson to test a service before hinging everything on it.&lt;/p&gt;\n\n&lt;p&gt;So now I&amp;#39;m on to the next in line on non-self-hosted AI-tagging platforms with neat-o UX - Amazon Photos.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;1) Does it respect my privacy? -- No, absolutely not&lt;/p&gt;\n\n&lt;p&gt;2) Do I feel like my photos are in a safe, long term storage environment? -- Again, no. I expect this service to die within the next 2 years&lt;/p&gt;\n\n&lt;p&gt;3) Can my spouse now do AI-tagged searches of photos on their phone via a sleek auto-organizing interface? -- Yes!! Mission Accomplished.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The only drawback so far - and this is a big one - despite us having 2 separate Amazon accounts linked to the same prime subscription which allows for purchased-content sharing, there is basically no way to both look at the Amazon Photo repository on our individual devices without logging into the same account. The bummer there is that the login syncs between Amazon shopping and Amazon Photos, so I can&amp;#39;t stay logged into my shopping account without losing access to view all the photos.&lt;/p&gt;\n\n&lt;p&gt;This sucks and, ultimately, will cause me to abandon the app if it&amp;#39;s not fixed before I can find a new service to fill the need, maybe Flickr cloud hosting? (or buck up the money for a self-hosted OpenVPN and the time to build out LibrePhotos).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m open to opinions on this, just know that *I know* this is not a long-term backup. This is sheerly for the sake of cloud access + AI tagging without me needing to build a local LibrePhotos + OpenVPN solution on my apartment wifi. All off-site backups &amp;amp; multiple copies are settled here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "133bf06", "is_robot_indexable": true, "report_reasons": null, "author": "FireWithBoxingGloves", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133bf06/amazon_photos_multiuser_access/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133bf06/amazon_photos_multiuser_access/", "subreddit_subscribers": 680312, "created_utc": 1682815128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So yeah, I have accumulated a bunch of external HDDs, been a while since I counted them but theres at least over 15 of them. Some are 3.5 inch, some 2.5.\n\nCouple years ago I built 2 racks for them from wood, which didnt turn out particularly well, but worked for a while until I got even more of them and now they dont fit and instead of trying to upgrade my shitty attempt I would rather start from scratch.\n\nSo do you guys have any ideas, experience with stacking external HDDs in some sort of a rack? Something kinda like a CD/DVD rack or shelve would be neat, but the dimensions are going to be way off of course even if you try to modify it. So at the moment I am wondering if theres something similar, a narrow self-standing shelf with a ton of levels in it which height could be easily adjusted as intended or by doing a bit of modifications to it? Atm the drives are just laying on the table and on a couple of normal shelves which looks ugly and takes way more space than they actually need. I would also like to keep the drives vertically.\n\nAnd I am just after a rack/shelve, I am not going to start building some nas server with them or anything like that as I want to be able transport them easily in a bag if and when needed. A big metal box isn't very ideal for that, which is why I also upgraded to a smaller ITX case from a regular one.", "author_fullname": "t2_jkzbd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DIY rack ideas for a bunch of usb HDDs of different sizes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133ls4r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682850957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So yeah, I have accumulated a bunch of external HDDs, been a while since I counted them but theres at least over 15 of them. Some are 3.5 inch, some 2.5.&lt;/p&gt;\n\n&lt;p&gt;Couple years ago I built 2 racks for them from wood, which didnt turn out particularly well, but worked for a while until I got even more of them and now they dont fit and instead of trying to upgrade my shitty attempt I would rather start from scratch.&lt;/p&gt;\n\n&lt;p&gt;So do you guys have any ideas, experience with stacking external HDDs in some sort of a rack? Something kinda like a CD/DVD rack or shelve would be neat, but the dimensions are going to be way off of course even if you try to modify it. So at the moment I am wondering if theres something similar, a narrow self-standing shelf with a ton of levels in it which height could be easily adjusted as intended or by doing a bit of modifications to it? Atm the drives are just laying on the table and on a couple of normal shelves which looks ugly and takes way more space than they actually need. I would also like to keep the drives vertically.&lt;/p&gt;\n\n&lt;p&gt;And I am just after a rack/shelve, I am not going to start building some nas server with them or anything like that as I want to be able transport them easily in a bag if and when needed. A big metal box isn&amp;#39;t very ideal for that, which is why I also upgraded to a smaller ITX case from a regular one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133ls4r", "is_robot_indexable": true, "report_reasons": null, "author": "kasetti", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133ls4r/diy_rack_ideas_for_a_bunch_of_usb_hdds_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133ls4r/diy_rack_ideas_for_a_bunch_of_usb_hdds_of/", "subreddit_subscribers": 680312, "created_utc": 1682850957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi!  \n\n\nI have Macrium reflect and I have a Win10 image file. I am used to restoring it on new devices as a faster alternative to installing Win10 and downloading all the updates from scratch.  \n\n\nI also have a 4x hotswap bay for 2,5\" SSDs. Can I select multiple target drives in Macrium when restoring an image? I know it would take longer to restore, of course, I just want to leave it to restore instead of having to re-select it after every drive.  \n\n\nThanks!", "author_fullname": "t2_69e78j78", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quick newbie question: with Macrium, can you select multiple target drives at the same time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_133yoyd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682877934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!  &lt;/p&gt;\n\n&lt;p&gt;I have Macrium reflect and I have a Win10 image file. I am used to restoring it on new devices as a faster alternative to installing Win10 and downloading all the updates from scratch.  &lt;/p&gt;\n\n&lt;p&gt;I also have a 4x hotswap bay for 2,5&amp;quot; SSDs. Can I select multiple target drives in Macrium when restoring an image? I know it would take longer to restore, of course, I just want to leave it to restore instead of having to re-select it after every drive.  &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133yoyd", "is_robot_indexable": true, "report_reasons": null, "author": "real_smoky", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133yoyd/quick_newbie_question_with_macrium_can_you_select/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133yoyd/quick_newbie_question_with_macrium_can_you_select/", "subreddit_subscribers": 680312, "created_utc": 1682877934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I am picking up a 8 TB WD - easystore external hard drive tomorrow. I will be backing up all of the movies, TV shows and sports games I have stored on my other external hard drive (5 TB Seagate 3.5). \n\nI just got the Seagate one last week, but after poking around on here, I realized that relying on that one drive (as well as it being Seagate) was just asking for something to go wrong. So another $150 or so to prevent me from having to re-burn all of my discs back onto my computer is well worth it. \n\nHowever, I skipped some steps with the Seagate drive (I just plugged it in and started dragging files over). I want to make sure I take all of the steps to make my new WD drive work properly.\n\nAny tips or advice you can offer will be greatly appreciated. \n\nPS: Between the 5TB Seagate drive and the 8TB WD one, which one is a better option to host all of my Plex files (if there is a difference at all)?", "author_fullname": "t2_af98i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner's guide to formatting a new external hard drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133st6g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682863397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am picking up a 8 TB WD - easystore external hard drive tomorrow. I will be backing up all of the movies, TV shows and sports games I have stored on my other external hard drive (5 TB Seagate 3.5). &lt;/p&gt;\n\n&lt;p&gt;I just got the Seagate one last week, but after poking around on here, I realized that relying on that one drive (as well as it being Seagate) was just asking for something to go wrong. So another $150 or so to prevent me from having to re-burn all of my discs back onto my computer is well worth it. &lt;/p&gt;\n\n&lt;p&gt;However, I skipped some steps with the Seagate drive (I just plugged it in and started dragging files over). I want to make sure I take all of the steps to make my new WD drive work properly.&lt;/p&gt;\n\n&lt;p&gt;Any tips or advice you can offer will be greatly appreciated. &lt;/p&gt;\n\n&lt;p&gt;PS: Between the 5TB Seagate drive and the 8TB WD one, which one is a better option to host all of my Plex files (if there is a difference at all)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133st6g", "is_robot_indexable": true, "report_reasons": null, "author": "btgio", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133st6g/beginners_guide_to_formatting_a_new_external_hard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133st6g/beginners_guide_to_formatting_a_new_external_hard/", "subreddit_subscribers": 680312, "created_utc": 1682863397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What kind of setup do you guys have in terms of a big storage array on a server rack? Right now, I have a large chassis with a ton of drive bays, but it's not going to be sustainable as I keep increasing my storage. I'm wondering what the most scalable setup is for a huge amount of storage.", "author_fullname": "t2_imj4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Server rack setup with storage array?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133nr16", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682857272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What kind of setup do you guys have in terms of a big storage array on a server rack? Right now, I have a large chassis with a ton of drive bays, but it&amp;#39;s not going to be sustainable as I keep increasing my storage. I&amp;#39;m wondering what the most scalable setup is for a huge amount of storage.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133nr16", "is_robot_indexable": true, "report_reasons": null, "author": "Grandfather-Paradox", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133nr16/server_rack_setup_with_storage_array/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133nr16/server_rack_setup_with_storage_array/", "subreddit_subscribers": 680312, "created_utc": 1682857272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone. Long time reader, first time poster.\n\nA couple years ago, I successfully archived 35K bookmarks (\u22481TB) with Archivebox 0.4.1\n\nBack in January, I installed docker version of Archivebox 0.6.2 in a brand new linux machine, and managed to save another 7K new bookmarks in a single run.\n\nI'm decided to finally merge those two instances, and run it again via docker-compose, to complete my bookmarks collection.\n\nI came across this link, explaining how to merge archives, but I don't fully understand it.\n\nhttps://github.com/ArchiveBox/ArchiveBox/wiki/Upgrading-or-Merging-Archives\n\nI don't know what to do with the original data folder containing 35K bookmarks. I guess I can move the content of \"archive\" folder to it's new location, but the rest of the files (*index.html, index.sqlite3, archivebox.conf and index_old.json*) not really sure where to put them.\n\nCan any of you guys help me out and guide me along every step of the process?", "author_fullname": "t2_j5hu3307", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archivebox - trying to hoard 112K bookmarks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133mexo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682853014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. Long time reader, first time poster.&lt;/p&gt;\n\n&lt;p&gt;A couple years ago, I successfully archived 35K bookmarks (\u22481TB) with Archivebox 0.4.1&lt;/p&gt;\n\n&lt;p&gt;Back in January, I installed docker version of Archivebox 0.6.2 in a brand new linux machine, and managed to save another 7K new bookmarks in a single run.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m decided to finally merge those two instances, and run it again via docker-compose, to complete my bookmarks collection.&lt;/p&gt;\n\n&lt;p&gt;I came across this link, explaining how to merge archives, but I don&amp;#39;t fully understand it.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ArchiveBox/ArchiveBox/wiki/Upgrading-or-Merging-Archives\"&gt;https://github.com/ArchiveBox/ArchiveBox/wiki/Upgrading-or-Merging-Archives&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know what to do with the original data folder containing 35K bookmarks. I guess I can move the content of &amp;quot;archive&amp;quot; folder to it&amp;#39;s new location, but the rest of the files (&lt;em&gt;index.html, index.sqlite3, archivebox.conf and index_old.json&lt;/em&gt;) not really sure where to put them.&lt;/p&gt;\n\n&lt;p&gt;Can any of you guys help me out and guide me along every step of the process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aLOzvQh3di5n5iViBK4zfGXUzzYsfeDSG2Op4ocLsMA.jpg?auto=webp&amp;v=enabled&amp;s=27f4cb6929d778d2c560f14a591c9c09ef4c09c1", "width": 1280, "height": 681}, "resolutions": [{"url": "https://external-preview.redd.it/aLOzvQh3di5n5iViBK4zfGXUzzYsfeDSG2Op4ocLsMA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2efb39cef2f9a7e380e4c189885c075044f63a3e", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/aLOzvQh3di5n5iViBK4zfGXUzzYsfeDSG2Op4ocLsMA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=648c4c7f0f4b684bec9559a0122731661a020933", "width": 216, "height": 114}, {"url": "https://external-preview.redd.it/aLOzvQh3di5n5iViBK4zfGXUzzYsfeDSG2Op4ocLsMA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac818f88887a2b59a4b3350aa7074327372ce5cd", "width": 320, "height": 170}, {"url": "https://external-preview.redd.it/aLOzvQh3di5n5iViBK4zfGXUzzYsfeDSG2Op4ocLsMA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2885cf0550f8753c014ab4e44c973d7a434c8a19", "width": 640, "height": 340}, {"url": "https://external-preview.redd.it/aLOzvQh3di5n5iViBK4zfGXUzzYsfeDSG2Op4ocLsMA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46c3e878c4be081c04ee7e68cd31ac6c25562f2f", "width": 960, "height": 510}, {"url": "https://external-preview.redd.it/aLOzvQh3di5n5iViBK4zfGXUzzYsfeDSG2Op4ocLsMA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=576d38cd62272bb5163ca7a9ffe2474ecbcfdf46", "width": 1080, "height": 574}], "variants": {}, "id": "-z9vjhMaxpt-_StJBYK3ZTqIebyvFPjVGKerpNepLGM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133mexo", "is_robot_indexable": true, "report_reasons": null, "author": "marywang2022", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133mexo/archivebox_trying_to_hoard_112k_bookmarks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133mexo/archivebox_trying_to_hoard_112k_bookmarks/", "subreddit_subscribers": 680312, "created_utc": 1682853014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, My best friend accidentally deleted both chats on telegram and it has almost 4 years of memories saved on it. I opened telegram on edge and before it subsequently loaded, I noticed that it still had our messages a few weeks ago. I then removed the internet connection so that it won't fully load and still have those cached messages. I was wondering if it's possible to extract those messages from Edge's cache? If so, how? These messages mean a lot to me and I guess it serves a core memory for me. I would really be grateful if you can help me save these messages. Thank you", "author_fullname": "t2_hjabt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Saving cached telegram messages from Edge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133aclo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682812047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, My best friend accidentally deleted both chats on telegram and it has almost 4 years of memories saved on it. I opened telegram on edge and before it subsequently loaded, I noticed that it still had our messages a few weeks ago. I then removed the internet connection so that it won&amp;#39;t fully load and still have those cached messages. I was wondering if it&amp;#39;s possible to extract those messages from Edge&amp;#39;s cache? If so, how? These messages mean a lot to me and I guess it serves a core memory for me. I would really be grateful if you can help me save these messages. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133aclo", "is_robot_indexable": true, "report_reasons": null, "author": "McJakey", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133aclo/saving_cached_telegram_messages_from_edge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133aclo/saving_cached_telegram_messages_from_edge/", "subreddit_subscribers": 680312, "created_utc": 1682812047.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have my entire collection ripped to ISO. I am now using DVD FAB on an old WIN 7 laptop to convert these into x264 files for easy streaming\n\n&amp;#x200B;\n\nLooking for a good program for my WIN 10 PC that will do the same thing only faster possibly", "author_fullname": "t2_viuwzrr1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best free program to convert my ISO collection into individual video files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1336vco", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682802751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have my entire collection ripped to ISO. I am now using DVD FAB on an old WIN 7 laptop to convert these into x264 files for easy streaming&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Looking for a good program for my WIN 10 PC that will do the same thing only faster possibly&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1336vco", "is_robot_indexable": true, "report_reasons": null, "author": "Rotisseriejedi", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1336vco/best_free_program_to_convert_my_iso_collection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1336vco/best_free_program_to_convert_my_iso_collection/", "subreddit_subscribers": 680312, "created_utc": 1682802751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_9tlfztgu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crucial P3 Plus 4TB M.2 PCIe Gen4 NVMe Internal SSD - \u00a3192.99", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_133z94s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1682879333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "amazon.co.uk", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.amazon.co.uk/Crucial-Plus-PCIe-Gen4-Internal/dp/B0B25M8FXX/ref=sr_1_5?crid=1GP7DDJ3GTOZY&amp;keywords=crucial%2Bp3&amp;qid=1682879265&amp;refinements=p_n_feature_seven_browse-bin%3A56158693031&amp;rnid=56157908031&amp;s=computers&amp;sprefix=Crucia%2Caps%2C122&amp;sr=1-5&amp;th=1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "133z94s", "is_robot_indexable": true, "report_reasons": null, "author": "Striking_Sea_7469", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133z94s/crucial_p3_plus_4tb_m2_pcie_gen4_nvme_internal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.amazon.co.uk/Crucial-Plus-PCIe-Gen4-Internal/dp/B0B25M8FXX/ref=sr_1_5?crid=1GP7DDJ3GTOZY&amp;keywords=crucial%2Bp3&amp;qid=1682879265&amp;refinements=p_n_feature_seven_browse-bin%3A56158693031&amp;rnid=56157908031&amp;s=computers&amp;sprefix=Crucia%2Caps%2C122&amp;sr=1-5&amp;th=1", "subreddit_subscribers": 680312, "created_utc": 1682879333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey I didn't see anything after a cursory google search, but do any of you know of a bot/integration that I could use to ping my discord server when, for example, the price of the 14TB WDs hit a specific price target at BBY?", "author_fullname": "t2_71ot7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discord Bot to Track Prices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133xeo8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682874708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey I didn&amp;#39;t see anything after a cursory google search, but do any of you know of a bot/integration that I could use to ping my discord server when, for example, the price of the 14TB WDs hit a specific price target at BBY?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133xeo8", "is_robot_indexable": true, "report_reasons": null, "author": "firefall", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133xeo8/discord_bot_to_track_prices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133xeo8/discord_bot_to_track_prices/", "subreddit_subscribers": 680312, "created_utc": 1682874708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a windows app (preferably open source) with a GUI that makes it possible to queue up large file copies so that they're copied sequentially? In windows explorer, when I initiate a few copies they happy simultaneously which is slow to perform on spinning disks. I'm looking for something that will let me create a queue of simple file copies.\n\nQuicksync kinda does this but it's cumbersome to set up for just one copy, this isn't for regular backups.", "author_fullname": "t2_3kkzr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows app to queue sequential copying of large files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133w7r3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682871764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a windows app (preferably open source) with a GUI that makes it possible to queue up large file copies so that they&amp;#39;re copied sequentially? In windows explorer, when I initiate a few copies they happy simultaneously which is slow to perform on spinning disks. I&amp;#39;m looking for something that will let me create a queue of simple file copies.&lt;/p&gt;\n\n&lt;p&gt;Quicksync kinda does this but it&amp;#39;s cumbersome to set up for just one copy, this isn&amp;#39;t for regular backups.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133w7r3", "is_robot_indexable": true, "report_reasons": null, "author": "kwirky88", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133w7r3/windows_app_to_queue_sequential_copying_of_large/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133w7r3/windows_app_to_queue_sequential_copying_of_large/", "subreddit_subscribers": 680312, "created_utc": 1682871764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Good evening Hoarders,  \n\n\nunfortunately my Nas broke and I still have an older 4 Bay Raidsonic ICY BOX IB-RD3640SU3 case here.   \nMy question is, which raid type can I use with this case?    \nI have 4 hard drives: 2x 18 TB and 2x 6 TB.  \nI would like to show the 2x 18TB as one volume and the 2x 6TB as a separate volume.   \nI don't need a backup as the data is faces elsewhere. I'm just wondering how can I do that with this case?   \n\n\nThanks for the Help :)\n\nLinks\n\n[Official Product info](https://icybox.de/en/product.php?id=308)  \n[Official Manual](https://raidsonic-static-content.s3.eu-central-1.amazonaws.com/IcyBox/Files/Manual_IB-3640_series_web_e.pdf)", "author_fullname": "t2_972z5xxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Raid Type should / can i use ? New ICY BOX IB-RD3640SU3 and 4 HD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133v7vi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682869374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good evening Hoarders,  &lt;/p&gt;\n\n&lt;p&gt;unfortunately my Nas broke and I still have an older 4 Bay Raidsonic ICY BOX IB-RD3640SU3 case here.&lt;br/&gt;\nMy question is, which raid type can I use with this case?&lt;br/&gt;\nI have 4 hard drives: 2x 18 TB and 2x 6 TB.&lt;br/&gt;\nI would like to show the 2x 18TB as one volume and the 2x 6TB as a separate volume.&lt;br/&gt;\nI don&amp;#39;t need a backup as the data is faces elsewhere. I&amp;#39;m just wondering how can I do that with this case?   &lt;/p&gt;\n\n&lt;p&gt;Thanks for the Help :)&lt;/p&gt;\n\n&lt;p&gt;Links&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://icybox.de/en/product.php?id=308\"&gt;Official Product info&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://raidsonic-static-content.s3.eu-central-1.amazonaws.com/IcyBox/Files/Manual_IB-3640_series_web_e.pdf\"&gt;Official Manual&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uoFGqOhUlcq8GnDN_pN2r5aXC0SQxvZvzpu-KU2MD4M.jpg?auto=webp&amp;v=enabled&amp;s=2a4ebee9bc83967d124e67ee2a9564b9f606dfe3", "width": 1920, "height": 650}, "resolutions": [{"url": "https://external-preview.redd.it/uoFGqOhUlcq8GnDN_pN2r5aXC0SQxvZvzpu-KU2MD4M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1d55096e3c1e58591eb1a87606d7d3fcd22882f0", "width": 108, "height": 36}, {"url": "https://external-preview.redd.it/uoFGqOhUlcq8GnDN_pN2r5aXC0SQxvZvzpu-KU2MD4M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=62f5bb01d23cc78249e01524a46177241f116b19", "width": 216, "height": 73}, {"url": "https://external-preview.redd.it/uoFGqOhUlcq8GnDN_pN2r5aXC0SQxvZvzpu-KU2MD4M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d1c772bcd13449d57a074a716d81e2bd92bba90", "width": 320, "height": 108}, {"url": "https://external-preview.redd.it/uoFGqOhUlcq8GnDN_pN2r5aXC0SQxvZvzpu-KU2MD4M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6697bd35ff1e11e67a4159b39158929904f101b", "width": 640, "height": 216}, {"url": "https://external-preview.redd.it/uoFGqOhUlcq8GnDN_pN2r5aXC0SQxvZvzpu-KU2MD4M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba612738821615f8acff4082737ab8ac12c82214", "width": 960, "height": 325}, {"url": "https://external-preview.redd.it/uoFGqOhUlcq8GnDN_pN2r5aXC0SQxvZvzpu-KU2MD4M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7178773ea58520b819fa2801f82bb63950e63cb7", "width": 1080, "height": 365}], "variants": {}, "id": "dUD9rrrmmXaicHwPrtfRKnhSejLXRY5VKKUtjLWI03c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133v7vi", "is_robot_indexable": true, "report_reasons": null, "author": "SuspiciousChemistry9", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133v7vi/which_raid_type_should_can_i_use_new_icy_box/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133v7vi/which_raid_type_should_can_i_use_new_icy_box/", "subreddit_subscribers": 680312, "created_utc": 1682869374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Its clear, that most of you have encrypted data. But the ISP can see, that you download/upload terrabytes 24/7. \n\nI mean\n\nIs the chance there, that someone can get suspicous? And is it possible that different countrys have different rules to check the activity? (I mean like in germany. I am also interested about the rules in germany)", "author_fullname": "t2_oq2e3f8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Was your internet providor suspicous about the activity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133nka2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682856707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Its clear, that most of you have encrypted data. But the ISP can see, that you download/upload terrabytes 24/7. &lt;/p&gt;\n\n&lt;p&gt;I mean&lt;/p&gt;\n\n&lt;p&gt;Is the chance there, that someone can get suspicous? And is it possible that different countrys have different rules to check the activity? (I mean like in germany. I am also interested about the rules in germany)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133nka2", "is_robot_indexable": true, "report_reasons": null, "author": "Sorita_", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133nka2/was_your_internet_providor_suspicous_about_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133nka2/was_your_internet_providor_suspicous_about_the/", "subreddit_subscribers": 680312, "created_utc": 1682856707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I can already copy the files manually with SMB but if my comp goes to sleep the copying stops. I want the NAS to take care of of the copying of several terabytes of Data without having to keep my computer awake.\n\nIs this even possible?", "author_fullname": "t2_v1x12bzc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Synology package is used for unattended backups of specific files and directories from a 18 TB USB external HDD to my new Synology NAS.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133a9fx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682811801.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can already copy the files manually with SMB but if my comp goes to sleep the copying stops. I want the NAS to take care of of the copying of several terabytes of Data without having to keep my computer awake.&lt;/p&gt;\n\n&lt;p&gt;Is this even possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133a9fx", "is_robot_indexable": true, "report_reasons": null, "author": "IllicitHypocrisy", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133a9fx/what_synology_package_is_used_for_unattended/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133a9fx/what_synology_package_is_used_for_unattended/", "subreddit_subscribers": 680312, "created_utc": 1682811801.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I already asked Newmaxx. Waiting for a reply. \n\nI've bought 2 enclosures, one with the ASM2362 bridge chip and the other with the rtl9210b. Couldn't get either to work with my 2 ssds. The crucial p3 plus 4tb was alright with the realtek chip on a 5gb/s port, but I didn't trust it to put my data on, given blue screens and other issues on other Ports. After flashing the firmware, it didn't even work. \n\nIt's in my pc now, and the silicon power 512gb PCIe 3.0 with dram it replaced didn't show up on either enclosure. I like the form factor, but nvme to USB isn't working on ryzen. Works fine on a 12 year old intel board, though. Will a sata iii ssd work? I'm calling it nvme because of the form factor. I know it's incorrect. \n\nI have plenty of Hdd enclosures and docks. Can I assume that a Transcend MTS830S 4 TB will have no detection problems? What's the heat like on sata nvmes? And since commercial drives like the SanDisk extreme v2 and wd my passport use the ASM2362, should I assume they won't work with my pc?\n\nFinally, how bad would a Samsung qvo 8tb drive be for my needs? Because 4tb drives cost half as much, I saw no need for it. I also heard it's really slow when you exit the cache. But Gigabyte's crappy motherboard has forced me to use sata, as I have no nvme Ports left and USB to nvme is a non starter.", "author_fullname": "t2_gti8t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will sata iii 2280 \"nvme\" ssd work on ryzen motherboard?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_133yvjv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682878387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I already asked Newmaxx. Waiting for a reply. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve bought 2 enclosures, one with the ASM2362 bridge chip and the other with the rtl9210b. Couldn&amp;#39;t get either to work with my 2 ssds. The crucial p3 plus 4tb was alright with the realtek chip on a 5gb/s port, but I didn&amp;#39;t trust it to put my data on, given blue screens and other issues on other Ports. After flashing the firmware, it didn&amp;#39;t even work. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s in my pc now, and the silicon power 512gb PCIe 3.0 with dram it replaced didn&amp;#39;t show up on either enclosure. I like the form factor, but nvme to USB isn&amp;#39;t working on ryzen. Works fine on a 12 year old intel board, though. Will a sata iii ssd work? I&amp;#39;m calling it nvme because of the form factor. I know it&amp;#39;s incorrect. &lt;/p&gt;\n\n&lt;p&gt;I have plenty of Hdd enclosures and docks. Can I assume that a Transcend MTS830S 4 TB will have no detection problems? What&amp;#39;s the heat like on sata nvmes? And since commercial drives like the SanDisk extreme v2 and wd my passport use the ASM2362, should I assume they won&amp;#39;t work with my pc?&lt;/p&gt;\n\n&lt;p&gt;Finally, how bad would a Samsung qvo 8tb drive be for my needs? Because 4tb drives cost half as much, I saw no need for it. I also heard it&amp;#39;s really slow when you exit the cache. But Gigabyte&amp;#39;s crappy motherboard has forced me to use sata, as I have no nvme Ports left and USB to nvme is a non starter.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133yvjv", "is_robot_indexable": true, "report_reasons": null, "author": "wgolding", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133yvjv/will_sata_iii_2280_nvme_ssd_work_on_ryzen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133yvjv/will_sata_iii_2280_nvme_ssd_work_on_ryzen/", "subreddit_subscribers": 680312, "created_utc": 1682878387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have watched two or three videos and I know how to going through the website code. The problem is when I find the source website for the PDF it takes it back to a file on \"[documentservices.adobe.com](https://documentservices.adobe.com)\" and then tells me I don't have access to it. \n\nWhat are my options? Thanks!", "author_fullname": "t2_gmwxl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to rip PDF's from a protected website?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133rf3z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682862056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have watched two or three videos and I know how to going through the website code. The problem is when I find the source website for the PDF it takes it back to a file on &amp;quot;&lt;a href=\"https://documentservices.adobe.com\"&gt;documentservices.adobe.com&lt;/a&gt;&amp;quot; and then tells me I don&amp;#39;t have access to it. &lt;/p&gt;\n\n&lt;p&gt;What are my options? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "133rf3z", "is_robot_indexable": true, "report_reasons": null, "author": "Foot-Note", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/133rf3z/how_to_rip_pdfs_from_a_protected_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/133rf3z/how_to_rip_pdfs_from_a_protected_website/", "subreddit_subscribers": 680312, "created_utc": 1682862056.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}