{"kind": "Listing", "data": {"after": "t3_132z6xc", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "That was the sentiment I\u2019ve heard a lot in the past couple years. Thoughts?", "author_fullname": "t2_5412hsg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there still a consensus that undergrad degrees in data science are a scam?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133919y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 191, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 191, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682808416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;That was the sentiment I\u2019ve heard a lot in the past couple years. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "133919y", "is_robot_indexable": true, "report_reasons": null, "author": "Voldemort57", "discussion_type": null, "num_comments": 176, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/133919y/is_there_still_a_consensus_that_undergrad_degrees/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/133919y/is_there_still_a_consensus_that_undergrad_degrees/", "subreddit_subscribers": 885673, "created_utc": 1682808416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Throughout my career, I have always occupied roles which closely resembled what people seem to be talking about when they talk about \u201cdata science\u201d. However, I was never formally trained in data science, or even machine learning, as a subject. As a result of my engineering degree, I had been taught mathematical modelling (i.e. how to translate problems from word-based descriptions into formal mathematical problems which can then be tackled analytically), as well as the concept of iterative development (i.e. how to start with a ridiculously simple solution to something and then add complexity to it progressively to make the solution better and better). I then did a master\u2019s in applied statistics, which taught me probability theory at a deeper level than I could\u2019ve ever imagined, and picked up the ability to code through successive jobs.\n\nI say all this because I am now at a level of seniority in my career where I now have to hire data scientists, i.e. hire the very person I used to be. And the experience has been\u2026 well\u2026 underwhelming would be to put it kindly. There are serious skill deficits among the data scientists I have interviewed, among those whom I converse with in sister companies, and sadly even among those who I have ended up hiring. (If you are wondering why I would hire someone whose skills aren\u2019t that great, please realise that: 1. It can take time for this deficit to become apparent, 2. The person can still be useful in terms of taking simpler and more annoying work off others, 3. What actually happens during a hiring process is that you are told by your superiors that \u201cwe need a data scientist\u201d and are allotted a budget for that specific role, and if you don\u2019t fill it you get yelled at).\n\nHere are the most serious problems I have observed among data scientists I have met and interacted with:\n\n1. Only ever reaching for their \u201cbag of tricks\u201d\n\nAs the old saying goes: if all you have is a hammer, everything looks like a nail. Pretty much all the data scientists I have met in my time seem to have a mental catalogue of well-known algorithms (K-nearest neighbours, Bayesian networks, logistic regression, etc.), and refer to this catalogue of algorithms in the same way an alchemist from the Middle Ages would refer to a book of alchemical recipes. They\u2019re not quite sure which recipes will work or why, but they know some of them work some of the time. So they try to pattern-match the current situation to previous situations they\u2019ve encountered, and try to remember which recipe seemed to work then.\n\nThe idea of **not** doing this, of **not** reaching for one of their pre-cooked algorithmic ready meals, of stopping and examining the problem in detail from its foundations and maybe even coming up with their own method of solving it (yes, from scratch!), seems to fill them with the uttermost horror. And the idea that a problem might even have an **analytic** solution, if you just think about it a bit, is simply too much for many of them to bear (one who I currently work with calls such an approach \u201cpseudoscience\u201d). \n\nI suspect this propensity for crowbarring pre-memorized algorithms into unsuitable situations has two underlying causes: (a) A lack of practice at mathematical modelling (which is a different skill from data science), and (b) A lack of comfort with probability and statistics. I\u2019ve had data scientists stare at me, dumbfounded, when I tell them the correlation coefficient only measures straight-line relationships, and will be useless for nonlinear (e.g. U-shaped) relationships. I\u2019ve had a data scientist tell me with confidence that the correct way to calculate the probability of A and B happening is always, under all circumstances, to multiply the probability of A by the probability of B. When I pointed out that this obviously wasn\u2019t true if A and B were tightly correlated and that they might be missing something important (I was trying to see if they were aware of the concept of conditional probability), they had a kind of meltdown and started questioning whether all of probability theory was wrong.\n\nTo those who say, \u201cBut data scientists are trained to use the algorithms that they\u2019re taught, not the weird stuff you\u2019re talking about\u201d, I say I\u2019m afraid that just isn\u2019t good enough. Your job is to extract meaning from data. That is the task you are being hired for. If you are flummoxed by basic probability theory, or are uncomfortable coming up with your own algorithms, you are going to be eaten alive by those who are comfortable with both.\n\nFor example, I used to work for a debt collection company a few years back and our data was horrifically sporadic and noisy. The data science team up north used to just shake their heads and say there was little they could do as the data was such a mess. It didn\u2019t fit into the logistic regression algorithm they were obsessed with, and was therefore unusable. Once, we were on the verge of losing a client because we couldn\u2019t figure out a way to contact the people most likely to pay their debts. It was regarded as a foregone conclusion that we would lose this client. However, I was able to use a Na\u00efve Bayes Classifier (written in VBA and Excel because we weren\u2019t allowed Python in our southern branch for \"security reasons\") to assign log-likelihoods of payment to individuals based on about 10-12 features. The fact that these log-likelihoods were almost certainly \u201cinaccurate\u201d didn\u2019t matter. What mattered was that, using this rough metric of quality, you could rank the individuals in descending order of likelihood and just skim off the top few thousand. Then only these would be sent to our call centre, instead of them having to call hundreds of thousands of debtors at random because the edict from the data science team was that the data was unusable. Our debt collections on that client shot up by 270% after I did that. Needless to say, this reflected very well on me and very poorly on the data science team up north, and my bonus reflected this.\n\n2. Choosing complex solutions before checking if simple ones will do\n\nI get it. You spent hundreds of hours learning about random forests, XGBoost, neural networks, stochastic gradient descent, k-means clustering, simulated annealing, and god-knows-what else. You want to start using these algorithms somewhere, anywhere, to make all that time worthwhile. But have you stopped to consider that maybe the particular problem you\u2019re working on right now actually doesn\u2019t require\u2026 well\u2026 any of that?\n\nHow about, instead of spending a month or two trying to fit a neural network to a noisy dataset (including such joys as deciding how many layers it should have, how many nodes per layer, what the activation function should be, whether it should have dropout, etc) and then telling me that you didn\u2019t accomplish anything because the data is so bad, you instead tried drawing a **straight line** through the data instead? The former takes ages and is almost guaranteed to fail, the latter takes 10 minutes and is almost guaranteed to succeed. Fair enough, the fit isn\u2019t great, but it at least it gives you something to extrapolate from, and something to show to management / clients if deadlines suddenly shrink.\n\nAnd you know what else? While you were spending the 10 minutes coding that baby-level linear regression, your muscle memory probably started kicking in, and now you remember that, come to think of it, there\u2019s something called the [generalized linear model](https://en.wikipedia.org/wiki/Generalized_linear_model) which would let you fit the curve to some forms of non-linear data. Maybe the data happens to be of that form and you can adapt the code so that it can do that instead, thereby giving a better fit. Then, maybe after that, you remember that scipy literally has a [curve fit function](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html), in which you can explicitly specify the curve family that you think the curve should be from, and then it just optimizes for the parameters. And so on. If you\u2019ve just made a beeline straight for the most complex thing you can think of, you\u2019re going to just fumble around aimlessly for ages and get nothing done.\n\nIn general, you should always start with the simplest, laziest solution to any problem. This is because: (a) It\u2019s fast, (b) It\u2019s easy, (c) It\u2019s low stress, (d) It gets you \u201cwarmed up\u201d to the problem, so that any future ideas for complex improvements will occur more easily to you, (e) It lets you break the problem into chunks, each of which is easier to solve than the whole, (f) It might be all that you\u2019re able to do anyway, given the quality of the data, and (g) While management / clients may throw around big important-sounding words like \u201coptimization\u201d, \u201cmachine learning\u201d, and \u201calgorithms\u201d, there is a precisely 0% chance that they mean these phrases in the same way you mean them. A \u201cprediction algorithm\u201d can be a straight line to them, and a sigmoid curve will blow their minds. Start simple, then add complexity if necessary.\n\n3. Snobbishness about Excel\n\nExcel is one of the most widely-used data science platforms in the world. I feel sorry for any readers who think it is beneath them, or who think it somehow isn\u2019t a \u201creal\u201d data science platform. You are missing out on such an opportunity. You can write your algorithm out step-by-step in the cells for all the world to see, so they can pick apart the formulas and understand them. That makes it great for demonstrating your ideas to non-experts, or even to other experts who are struggling to follow your line of thinking. Writing out your planned approach in this methodical way also acts as an amazing sanity-check for yourself on your ideas before you hurl yourself into your Jupyter notebook and start waving scikit-learn and pytorch around and spouting nonsense.\n\nYou can even code in Excel if you desperately want to (I once wrote a K-means clustering algorithm in VBA for God\u2019s sake, with a big juicy macro button in the sheet for the user to press). I can assure you there is nothing that management / clients love more than a big button to push, and nothing that they hate more than an unfamiliar environment (i.e. giving them a presentation which involves scrolling through a Jupyter notebook that they don't understand).\n\nSummary\n\nThese are the main problems I see with data scientists. I\u2019m sure this post will get downvoted into oblivion, but if you want advice from the guy who\u2019s been in your shoes and is now doing the hiring, then I would recommend the following:\n\n\u00b7 Get good at [mathematical modelling](https://en.wikipedia.org/wiki/Mathematical_model), not \u201cdata science\u201d. This will let you take the vague BS that managers say they want and turn it into a solvable mathematical problem that mirrors what they actually meant. Additionally, most company data is of too poor quality to use in most fancy data science algorithms anyway. You can call yourself a data scientist if that's the buzzword that gets you the job, but this is the underlying skill you are likely to need.\n\n\u00b7 Get your probability &amp; statistics sharp. I\u2019m talking razor-sharp. Not the fancy BS about \u201cBayesian reasoning\u201d or any of that other crap, but the fundamentals. Are you happy with what an expected value is? Are you happy with conditional probability? Do you understand that subtracting the probability of an event happening from 1 is equal to the probability of it not happening? Are you happy with the probabilistic equivalents of [De Morgan\u2019s laws](https://en.wikipedia.org/wiki/De_Morgan%27s_laws)? Do you understand how to calculate probabilities correctly from vague language statements (e.g. if I roll a dice 6 times, what is the probability that a 2 will have been rolled at some point during those 6 rolls)? I hope you got 66.5% because that\u2019s what the answer is. What about things like simple random simulations? Could you code 10,000 simulations of a random walk with adjustable parameters? This stuff should be like breathing to you.\n\n\u00b7 Don\u2019t be snotty about tools that management like to use just because it isn\u2019t Python code in a Jupyter notebook. You\u2019re the data scientist \u2013 make the tools work for you.", "author_fullname": "t2_5s0mksvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for data scientists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133n4a1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 62, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682855375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Throughout my career, I have always occupied roles which closely resembled what people seem to be talking about when they talk about \u201cdata science\u201d. However, I was never formally trained in data science, or even machine learning, as a subject. As a result of my engineering degree, I had been taught mathematical modelling (i.e. how to translate problems from word-based descriptions into formal mathematical problems which can then be tackled analytically), as well as the concept of iterative development (i.e. how to start with a ridiculously simple solution to something and then add complexity to it progressively to make the solution better and better). I then did a master\u2019s in applied statistics, which taught me probability theory at a deeper level than I could\u2019ve ever imagined, and picked up the ability to code through successive jobs.&lt;/p&gt;\n\n&lt;p&gt;I say all this because I am now at a level of seniority in my career where I now have to hire data scientists, i.e. hire the very person I used to be. And the experience has been\u2026 well\u2026 underwhelming would be to put it kindly. There are serious skill deficits among the data scientists I have interviewed, among those whom I converse with in sister companies, and sadly even among those who I have ended up hiring. (If you are wondering why I would hire someone whose skills aren\u2019t that great, please realise that: 1. It can take time for this deficit to become apparent, 2. The person can still be useful in terms of taking simpler and more annoying work off others, 3. What actually happens during a hiring process is that you are told by your superiors that \u201cwe need a data scientist\u201d and are allotted a budget for that specific role, and if you don\u2019t fill it you get yelled at).&lt;/p&gt;\n\n&lt;p&gt;Here are the most serious problems I have observed among data scientists I have met and interacted with:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Only ever reaching for their \u201cbag of tricks\u201d&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;As the old saying goes: if all you have is a hammer, everything looks like a nail. Pretty much all the data scientists I have met in my time seem to have a mental catalogue of well-known algorithms (K-nearest neighbours, Bayesian networks, logistic regression, etc.), and refer to this catalogue of algorithms in the same way an alchemist from the Middle Ages would refer to a book of alchemical recipes. They\u2019re not quite sure which recipes will work or why, but they know some of them work some of the time. So they try to pattern-match the current situation to previous situations they\u2019ve encountered, and try to remember which recipe seemed to work then.&lt;/p&gt;\n\n&lt;p&gt;The idea of &lt;strong&gt;not&lt;/strong&gt; doing this, of &lt;strong&gt;not&lt;/strong&gt; reaching for one of their pre-cooked algorithmic ready meals, of stopping and examining the problem in detail from its foundations and maybe even coming up with their own method of solving it (yes, from scratch!), seems to fill them with the uttermost horror. And the idea that a problem might even have an &lt;strong&gt;analytic&lt;/strong&gt; solution, if you just think about it a bit, is simply too much for many of them to bear (one who I currently work with calls such an approach \u201cpseudoscience\u201d). &lt;/p&gt;\n\n&lt;p&gt;I suspect this propensity for crowbarring pre-memorized algorithms into unsuitable situations has two underlying causes: (a) A lack of practice at mathematical modelling (which is a different skill from data science), and (b) A lack of comfort with probability and statistics. I\u2019ve had data scientists stare at me, dumbfounded, when I tell them the correlation coefficient only measures straight-line relationships, and will be useless for nonlinear (e.g. U-shaped) relationships. I\u2019ve had a data scientist tell me with confidence that the correct way to calculate the probability of A and B happening is always, under all circumstances, to multiply the probability of A by the probability of B. When I pointed out that this obviously wasn\u2019t true if A and B were tightly correlated and that they might be missing something important (I was trying to see if they were aware of the concept of conditional probability), they had a kind of meltdown and started questioning whether all of probability theory was wrong.&lt;/p&gt;\n\n&lt;p&gt;To those who say, \u201cBut data scientists are trained to use the algorithms that they\u2019re taught, not the weird stuff you\u2019re talking about\u201d, I say I\u2019m afraid that just isn\u2019t good enough. Your job is to extract meaning from data. That is the task you are being hired for. If you are flummoxed by basic probability theory, or are uncomfortable coming up with your own algorithms, you are going to be eaten alive by those who are comfortable with both.&lt;/p&gt;\n\n&lt;p&gt;For example, I used to work for a debt collection company a few years back and our data was horrifically sporadic and noisy. The data science team up north used to just shake their heads and say there was little they could do as the data was such a mess. It didn\u2019t fit into the logistic regression algorithm they were obsessed with, and was therefore unusable. Once, we were on the verge of losing a client because we couldn\u2019t figure out a way to contact the people most likely to pay their debts. It was regarded as a foregone conclusion that we would lose this client. However, I was able to use a Na\u00efve Bayes Classifier (written in VBA and Excel because we weren\u2019t allowed Python in our southern branch for &amp;quot;security reasons&amp;quot;) to assign log-likelihoods of payment to individuals based on about 10-12 features. The fact that these log-likelihoods were almost certainly \u201cinaccurate\u201d didn\u2019t matter. What mattered was that, using this rough metric of quality, you could rank the individuals in descending order of likelihood and just skim off the top few thousand. Then only these would be sent to our call centre, instead of them having to call hundreds of thousands of debtors at random because the edict from the data science team was that the data was unusable. Our debt collections on that client shot up by 270% after I did that. Needless to say, this reflected very well on me and very poorly on the data science team up north, and my bonus reflected this.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Choosing complex solutions before checking if simple ones will do&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I get it. You spent hundreds of hours learning about random forests, XGBoost, neural networks, stochastic gradient descent, k-means clustering, simulated annealing, and god-knows-what else. You want to start using these algorithms somewhere, anywhere, to make all that time worthwhile. But have you stopped to consider that maybe the particular problem you\u2019re working on right now actually doesn\u2019t require\u2026 well\u2026 any of that?&lt;/p&gt;\n\n&lt;p&gt;How about, instead of spending a month or two trying to fit a neural network to a noisy dataset (including such joys as deciding how many layers it should have, how many nodes per layer, what the activation function should be, whether it should have dropout, etc) and then telling me that you didn\u2019t accomplish anything because the data is so bad, you instead tried drawing a &lt;strong&gt;straight line&lt;/strong&gt; through the data instead? The former takes ages and is almost guaranteed to fail, the latter takes 10 minutes and is almost guaranteed to succeed. Fair enough, the fit isn\u2019t great, but it at least it gives you something to extrapolate from, and something to show to management / clients if deadlines suddenly shrink.&lt;/p&gt;\n\n&lt;p&gt;And you know what else? While you were spending the 10 minutes coding that baby-level linear regression, your muscle memory probably started kicking in, and now you remember that, come to think of it, there\u2019s something called the &lt;a href=\"https://en.wikipedia.org/wiki/Generalized_linear_model\"&gt;generalized linear model&lt;/a&gt; which would let you fit the curve to some forms of non-linear data. Maybe the data happens to be of that form and you can adapt the code so that it can do that instead, thereby giving a better fit. Then, maybe after that, you remember that scipy literally has a &lt;a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html\"&gt;curve fit function&lt;/a&gt;, in which you can explicitly specify the curve family that you think the curve should be from, and then it just optimizes for the parameters. And so on. If you\u2019ve just made a beeline straight for the most complex thing you can think of, you\u2019re going to just fumble around aimlessly for ages and get nothing done.&lt;/p&gt;\n\n&lt;p&gt;In general, you should always start with the simplest, laziest solution to any problem. This is because: (a) It\u2019s fast, (b) It\u2019s easy, (c) It\u2019s low stress, (d) It gets you \u201cwarmed up\u201d to the problem, so that any future ideas for complex improvements will occur more easily to you, (e) It lets you break the problem into chunks, each of which is easier to solve than the whole, (f) It might be all that you\u2019re able to do anyway, given the quality of the data, and (g) While management / clients may throw around big important-sounding words like \u201coptimization\u201d, \u201cmachine learning\u201d, and \u201calgorithms\u201d, there is a precisely 0% chance that they mean these phrases in the same way you mean them. A \u201cprediction algorithm\u201d can be a straight line to them, and a sigmoid curve will blow their minds. Start simple, then add complexity if necessary.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Snobbishness about Excel&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Excel is one of the most widely-used data science platforms in the world. I feel sorry for any readers who think it is beneath them, or who think it somehow isn\u2019t a \u201creal\u201d data science platform. You are missing out on such an opportunity. You can write your algorithm out step-by-step in the cells for all the world to see, so they can pick apart the formulas and understand them. That makes it great for demonstrating your ideas to non-experts, or even to other experts who are struggling to follow your line of thinking. Writing out your planned approach in this methodical way also acts as an amazing sanity-check for yourself on your ideas before you hurl yourself into your Jupyter notebook and start waving scikit-learn and pytorch around and spouting nonsense.&lt;/p&gt;\n\n&lt;p&gt;You can even code in Excel if you desperately want to (I once wrote a K-means clustering algorithm in VBA for God\u2019s sake, with a big juicy macro button in the sheet for the user to press). I can assure you there is nothing that management / clients love more than a big button to push, and nothing that they hate more than an unfamiliar environment (i.e. giving them a presentation which involves scrolling through a Jupyter notebook that they don&amp;#39;t understand).&lt;/p&gt;\n\n&lt;p&gt;Summary&lt;/p&gt;\n\n&lt;p&gt;These are the main problems I see with data scientists. I\u2019m sure this post will get downvoted into oblivion, but if you want advice from the guy who\u2019s been in your shoes and is now doing the hiring, then I would recommend the following:&lt;/p&gt;\n\n&lt;p&gt;\u00b7 Get good at &lt;a href=\"https://en.wikipedia.org/wiki/Mathematical_model\"&gt;mathematical modelling&lt;/a&gt;, not \u201cdata science\u201d. This will let you take the vague BS that managers say they want and turn it into a solvable mathematical problem that mirrors what they actually meant. Additionally, most company data is of too poor quality to use in most fancy data science algorithms anyway. You can call yourself a data scientist if that&amp;#39;s the buzzword that gets you the job, but this is the underlying skill you are likely to need.&lt;/p&gt;\n\n&lt;p&gt;\u00b7 Get your probability &amp;amp; statistics sharp. I\u2019m talking razor-sharp. Not the fancy BS about \u201cBayesian reasoning\u201d or any of that other crap, but the fundamentals. Are you happy with what an expected value is? Are you happy with conditional probability? Do you understand that subtracting the probability of an event happening from 1 is equal to the probability of it not happening? Are you happy with the probabilistic equivalents of &lt;a href=\"https://en.wikipedia.org/wiki/De_Morgan%27s_laws\"&gt;De Morgan\u2019s laws&lt;/a&gt;? Do you understand how to calculate probabilities correctly from vague language statements (e.g. if I roll a dice 6 times, what is the probability that a 2 will have been rolled at some point during those 6 rolls)? I hope you got 66.5% because that\u2019s what the answer is. What about things like simple random simulations? Could you code 10,000 simulations of a random walk with adjustable parameters? This stuff should be like breathing to you.&lt;/p&gt;\n\n&lt;p&gt;\u00b7 Don\u2019t be snotty about tools that management like to use just because it isn\u2019t Python code in a Jupyter notebook. You\u2019re the data scientist \u2013 make the tools work for you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "133n4a1", "is_robot_indexable": true, "report_reasons": null, "author": "RuffleCopter", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/133n4a1/advice_for_data_scientists/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/133n4a1/advice_for_data_scientists/", "subreddit_subscribers": 885673, "created_utc": 1682855375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Haven\u2019t seen much discussion of it here. I am mentoring an aspiring DS. She hadn\u2019t taken a math course in about 10 years. She read this book over the course of about a month, and after looking over it, I thought it was pretty good. It was a no fluff introduction to the algebra, calculus, linear algebra, statistics needed for basic DS. \n\nNow of course this book wouldn\u2019t make you a researcher, but it seemed like enough to be dangerous on the job as a product or analytics focused DS, before diving into math more deeply.", "author_fullname": "t2_dbas4m3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on The Book \u201cEssential Math For Data Science\u201d?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133bpns", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682816013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Haven\u2019t seen much discussion of it here. I am mentoring an aspiring DS. She hadn\u2019t taken a math course in about 10 years. She read this book over the course of about a month, and after looking over it, I thought it was pretty good. It was a no fluff introduction to the algebra, calculus, linear algebra, statistics needed for basic DS. &lt;/p&gt;\n\n&lt;p&gt;Now of course this book wouldn\u2019t make you a researcher, but it seemed like enough to be dangerous on the job as a product or analytics focused DS, before diving into math more deeply.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "133bpns", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_Hyena4223", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/133bpns/thoughts_on_the_book_essential_math_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/133bpns/thoughts_on_the_book_essential_math_for_data/", "subreddit_subscribers": 885673, "created_utc": 1682816013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm excited to share the results of my recent comparative sentiment analysis of Fox News and CNN on Twitter. After scraping 500 recent tweets from each news outlet and analyzing the data using Python and the NRC lexicon, I found that Fox News tends to express more fear in their messaging, while CNN expresses more trust.\n\n&amp;#x200B;\n\nThis finding is indicative of the broader Republican and Democratic narratives in American politics. The Republican Party tends to emphasize issues related to law and order, national security, and immigration, which are often framed in terms of threats and dangers. This rhetoric appeals to voters who prioritize safety and security and are more likely to see the world as a dangerous place. On the other hand, the Democratic Party tends to focus on issues related to social justice, equity, and inclusivity, which are often framed in terms of fairness and equality. This rhetoric appeals to voters who prioritize social issues and are more likely to see the world as a diverse and interconnected place.\n\n&amp;#x200B;\n\nBy analyzing sentiments expressed by the two networks, not what people said about them, my analysis offers valuable insights into how American media and politics are shaped by these different narratives. As we approach the 2024 presidential election, understanding these nuances in messaging will be crucial for anyone interested in American politics and media.\n\n&amp;#x200B;\n\nI hope you find these results as insightful as I do.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/y98f8v6e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=55c047f0231b16f55299e2c9cd692e804eccdb8c\n\nhttps://preview.redd.it/k2rnju6e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=cb367cb5f3b2ff3bfa3fda4a41ba075b9bd85279\n\nhttps://preview.redd.it/jwk7dm0t1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=cfefc2186cb0cdc3bca301483ec84319a7a4ce8c\n\nhttps://preview.redd.it/7aeadw6e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a89cf644601ddc9d4034acffc74e2aa0232c0f28\n\nhttps://preview.redd.it/nfdg0o7e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=038a594d2af00a25a424b32e46d4bbf32f0eea43\n\nhttps://preview.redd.it/is4h5p7e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=14732436ccbec7e5708ff0f2ecd4ace8b3054517\n\nhttps://preview.redd.it/qcqnb17e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f6ad20c772eb3d23ef3791d0d505f2dd1d61d8d8\n\nhttps://preview.redd.it/bfmaps7e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=66a967b047f7d5c0995d6807a025a39128a39ed8\n\nhttps://preview.redd.it/lrh8b37e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9c56b6f79230ea954232d3a4d4580cd2a04cfb53", "author_fullname": "t2_s67evjuu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparative Sentiment Analysis of Fox Vs. CNN Twitter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"y98f8v6e1zwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/y98f8v6e1zwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea40d2b4df1f706561d283dd05263b629ed43440"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/y98f8v6e1zwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c682b32e89f5d6cccad04c75880f8cd37657afb"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/y98f8v6e1zwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b1cd51fb449d93fefae2655589e3af6885d6b59"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/y98f8v6e1zwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ec2a96cae5c00600ac1af9f787511362ec4c4a7"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/y98f8v6e1zwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec6bc37973bae46db9e0bed8e63db8391a83d1c3"}], "s": {"y": 540, "x": 960, "u": "https://preview.redd.it/y98f8v6e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=55c047f0231b16f55299e2c9cd692e804eccdb8c"}, "id": "y98f8v6e1zwa1"}, "7aeadw6e1zwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/7aeadw6e1zwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f4ea2d71ab4a0e1ac6bdebb50af9be82cc3e7ad"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/7aeadw6e1zwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dde956962744771821cfd6d43502855ebd7acfd7"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/7aeadw6e1zwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b82e22cbdf38a3af8cf3ffcb03e8928387d1a973"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/7aeadw6e1zwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7757e75c9cf16bdbe2683f1a0d607b8daeddb14"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/7aeadw6e1zwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4673883ce0a8dc32f7533d395623c0c14a157262"}], "s": {"y": 540, "x": 960, "u": "https://preview.redd.it/7aeadw6e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a89cf644601ddc9d4034acffc74e2aa0232c0f28"}, "id": "7aeadw6e1zwa1"}, "k2rnju6e1zwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/k2rnju6e1zwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6074150796244e8af000dc2882104efaf431b95c"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/k2rnju6e1zwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42b2605ae3503894d43880e09e0935dccb0bb4be"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/k2rnju6e1zwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec0cb253944a72acc19f20c5e00c98cd898193cb"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/k2rnju6e1zwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc0ed5e35686dcd32257d8ba39ce7acd5d25f554"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/k2rnju6e1zwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2d5552179778fbb7ca173a08bfcfc4fcd1fd125c"}], "s": {"y": 540, "x": 960, "u": "https://preview.redd.it/k2rnju6e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=cb367cb5f3b2ff3bfa3fda4a41ba075b9bd85279"}, "id": "k2rnju6e1zwa1"}, "qcqnb17e1zwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/qcqnb17e1zwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea14861d6c54ebed7b979562d723c67995ae28db"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/qcqnb17e1zwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6aeefd7beef5fd02fdf6b23f1d889b96812e497"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/qcqnb17e1zwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd51784834ef75e19a2732d300f4cb85687e90cb"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/qcqnb17e1zwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38fd882cd13cfa48b55919fe0bafcf7a0a721a1a"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/qcqnb17e1zwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d17c5f13564cb95027cf4361da09bf44860cc66a"}], "s": {"y": 540, "x": 960, "u": "https://preview.redd.it/qcqnb17e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f6ad20c772eb3d23ef3791d0d505f2dd1d61d8d8"}, "id": "qcqnb17e1zwa1"}, "is4h5p7e1zwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/is4h5p7e1zwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ee1ac8a58c97e350c6af482568df7e0774ccd9a"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/is4h5p7e1zwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=320cdac61a48bef9168a6647efe01d2dbe1c5d24"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/is4h5p7e1zwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb37e0763db31aa6a9bb3acf82de9cbfece042bd"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/is4h5p7e1zwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d598f9404782af30eb1d7640c47dbcc2b39775c"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/is4h5p7e1zwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=703d64f335aff565f7e61caa30ff98c02f577791"}], "s": {"y": 540, "x": 960, "u": "https://preview.redd.it/is4h5p7e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=14732436ccbec7e5708ff0f2ecd4ace8b3054517"}, "id": "is4h5p7e1zwa1"}, "nfdg0o7e1zwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/nfdg0o7e1zwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b3729d869d73f5734efb4e490110490247d7156"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/nfdg0o7e1zwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa7ee4b7949d3ff8a95053fdabf87ff5178045ab"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/nfdg0o7e1zwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d3a0434f423cd8cecc31af5ad73e615fcfc4a053"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/nfdg0o7e1zwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc4aac1c1a843605e15dae1ffd30e61a129bf3ce"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/nfdg0o7e1zwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e7b2917ac8d18c3e79678ef9fd60613211116f2"}], "s": {"y": 540, "x": 960, "u": "https://preview.redd.it/nfdg0o7e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=038a594d2af00a25a424b32e46d4bbf32f0eea43"}, "id": "nfdg0o7e1zwa1"}, "lrh8b37e1zwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/lrh8b37e1zwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02506d684d3c447b0e87d13fca887d819cb3898c"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/lrh8b37e1zwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=56e3ced91531da4bda85a3188136c82d5eee5e1d"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/lrh8b37e1zwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfef97523739709f1b2b0b75f6ef5a2319d1be26"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/lrh8b37e1zwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55bf16561e2ddf3f6d6689c19e371b146d187770"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/lrh8b37e1zwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1d25745672d2ddc6d8610be481097625b1d21e9"}], "s": {"y": 540, "x": 960, "u": "https://preview.redd.it/lrh8b37e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9c56b6f79230ea954232d3a4d4580cd2a04cfb53"}, "id": "lrh8b37e1zwa1"}, "bfmaps7e1zwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/bfmaps7e1zwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c070251bd76817618e42fb21efa24c80f1b26c5"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/bfmaps7e1zwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc7c8e961252a43e6d4c29832c9e9ad1eec662fc"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/bfmaps7e1zwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8f6722161a2f27299495b40bce6ef95aeb70a39"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/bfmaps7e1zwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2bef50899712f9347ac29ed0997579d568158db3"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/bfmaps7e1zwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3fe5a63877309a7daf640836425723e9cfc1276d"}], "s": {"y": 540, "x": 960, "u": "https://preview.redd.it/bfmaps7e1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=66a967b047f7d5c0995d6807a025a39128a39ed8"}, "id": "bfmaps7e1zwa1"}, "jwk7dm0t1zwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/jwk7dm0t1zwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=17c72dcd977ebd3af8afeee20cb891350ced9c57"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/jwk7dm0t1zwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc90b51a104196f19ac1b368b8c8cd474c69b288"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/jwk7dm0t1zwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ad63ea533d3fae9474a2005771fdc7d5787855a"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/jwk7dm0t1zwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e281a1184f7f50d49ad7332144a5dcd0fbfd490e"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/jwk7dm0t1zwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee8eaff5358a315c809cb68cf6f6134ad4b032f1"}], "s": {"y": 540, "x": 960, "u": "https://preview.redd.it/jwk7dm0t1zwa1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=cfefc2186cb0cdc3bca301483ec84319a7a4ce8c"}, "id": "jwk7dm0t1zwa1"}}, "name": "t3_133iehm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/PMavWRpfuOnfllpFMBYHQ5GDIPpVTq8qJA-ONcv6oy8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682838694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m excited to share the results of my recent comparative sentiment analysis of Fox News and CNN on Twitter. After scraping 500 recent tweets from each news outlet and analyzing the data using Python and the NRC lexicon, I found that Fox News tends to express more fear in their messaging, while CNN expresses more trust.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This finding is indicative of the broader Republican and Democratic narratives in American politics. The Republican Party tends to emphasize issues related to law and order, national security, and immigration, which are often framed in terms of threats and dangers. This rhetoric appeals to voters who prioritize safety and security and are more likely to see the world as a dangerous place. On the other hand, the Democratic Party tends to focus on issues related to social justice, equity, and inclusivity, which are often framed in terms of fairness and equality. This rhetoric appeals to voters who prioritize social issues and are more likely to see the world as a diverse and interconnected place.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;By analyzing sentiments expressed by the two networks, not what people said about them, my analysis offers valuable insights into how American media and politics are shaped by these different narratives. As we approach the 2024 presidential election, understanding these nuances in messaging will be crucial for anyone interested in American politics and media.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I hope you find these results as insightful as I do.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/y98f8v6e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=55c047f0231b16f55299e2c9cd692e804eccdb8c\"&gt;https://preview.redd.it/y98f8v6e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=55c047f0231b16f55299e2c9cd692e804eccdb8c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/k2rnju6e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=cb367cb5f3b2ff3bfa3fda4a41ba075b9bd85279\"&gt;https://preview.redd.it/k2rnju6e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=cb367cb5f3b2ff3bfa3fda4a41ba075b9bd85279&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jwk7dm0t1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=cfefc2186cb0cdc3bca301483ec84319a7a4ce8c\"&gt;https://preview.redd.it/jwk7dm0t1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=cfefc2186cb0cdc3bca301483ec84319a7a4ce8c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7aeadw6e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a89cf644601ddc9d4034acffc74e2aa0232c0f28\"&gt;https://preview.redd.it/7aeadw6e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a89cf644601ddc9d4034acffc74e2aa0232c0f28&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nfdg0o7e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=038a594d2af00a25a424b32e46d4bbf32f0eea43\"&gt;https://preview.redd.it/nfdg0o7e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=038a594d2af00a25a424b32e46d4bbf32f0eea43&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/is4h5p7e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=14732436ccbec7e5708ff0f2ecd4ace8b3054517\"&gt;https://preview.redd.it/is4h5p7e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=14732436ccbec7e5708ff0f2ecd4ace8b3054517&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qcqnb17e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f6ad20c772eb3d23ef3791d0d505f2dd1d61d8d8\"&gt;https://preview.redd.it/qcqnb17e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f6ad20c772eb3d23ef3791d0d505f2dd1d61d8d8&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bfmaps7e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=66a967b047f7d5c0995d6807a025a39128a39ed8\"&gt;https://preview.redd.it/bfmaps7e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=66a967b047f7d5c0995d6807a025a39128a39ed8&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lrh8b37e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9c56b6f79230ea954232d3a4d4580cd2a04cfb53\"&gt;https://preview.redd.it/lrh8b37e1zwa1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9c56b6f79230ea954232d3a4d4580cd2a04cfb53&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "133iehm", "is_robot_indexable": true, "report_reasons": null, "author": "data_guy__", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/133iehm/comparative_sentiment_analysis_of_fox_vs_cnn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/133iehm/comparative_sentiment_analysis_of_fox_vs_cnn/", "subreddit_subscribers": 885673, "created_utc": 1682838694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This summer I have to start writing my masters thesis in my MSc Big Data, that if successful I would like to continue in a PhD. I have a lot of time 6 months to an year to complete it. I want to take an existing neural network and improve on it making it either more efficient or changing it to perform on problems it has not before. How does one do this? How is new knowledge in academia founded? There are so many types of neural networks created after the perceptron was. How did those who created them do it? How did they verify that the ideas that came to their heads worked. They probably had to write the neural networks from scratch on the computer to make experiments with. Nowadays people just import models and call themselves data scientist. How can I go back to the old days, the fundamentals when everything was done by hand.", "author_fullname": "t2_aws8tyj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are new DS/ML models created by researchers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_132ygfn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682785714.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682782032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This summer I have to start writing my masters thesis in my MSc Big Data, that if successful I would like to continue in a PhD. I have a lot of time 6 months to an year to complete it. I want to take an existing neural network and improve on it making it either more efficient or changing it to perform on problems it has not before. How does one do this? How is new knowledge in academia founded? There are so many types of neural networks created after the perceptron was. How did those who created them do it? How did they verify that the ideas that came to their heads worked. They probably had to write the neural networks from scratch on the computer to make experiments with. Nowadays people just import models and call themselves data scientist. How can I go back to the old days, the fundamentals when everything was done by hand.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "132ygfn", "is_robot_indexable": true, "report_reasons": null, "author": "AnyJello605", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/132ygfn/how_are_new_dsml_models_created_by_researchers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/132ygfn/how_are_new_dsml_models_created_by_researchers/", "subreddit_subscribers": 885673, "created_utc": 1682782032.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Exactly how important is networking in data science when applying for your first job out of undergrad? \n\nI know networking is always important generally speaking, but compared to an industry such as finance, for example, where you can pretty much network/cold call into some of the highest paying jobs (e.g. investment banking) data science is an industry with higher quantitative merit standards, where it seems just \u201cknowing\u201d someone won\u2019t grant you an important job. \n\nHow likely would it be as someone looking for entry level DA positions to be able to just network like crazy on LinkedIn, get an interview and then get a job (assuming interview goes well)?", "author_fullname": "t2_7qy4humu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Networking in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13394jh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682808682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Exactly how important is networking in data science when applying for your first job out of undergrad? &lt;/p&gt;\n\n&lt;p&gt;I know networking is always important generally speaking, but compared to an industry such as finance, for example, where you can pretty much network/cold call into some of the highest paying jobs (e.g. investment banking) data science is an industry with higher quantitative merit standards, where it seems just \u201cknowing\u201d someone won\u2019t grant you an important job. &lt;/p&gt;\n\n&lt;p&gt;How likely would it be as someone looking for entry level DA positions to be able to just network like crazy on LinkedIn, get an interview and then get a job (assuming interview goes well)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13394jh", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Vermicelli2583", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13394jh/networking_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13394jh/networking_in_data_science/", "subreddit_subscribers": 885673, "created_utc": 1682808682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Greets!\n\nI am a Bolivian Engineer trying to change career into DS, I have already put my first foot in the area, but I am trying to jump into the international market to learn more (Since the internal market of my country does not have DS professionals). For this reason, I am here to ask you for some help regarding **networking, CV formats (Please roast my CV) and others.** Currently I cannot share my real projects due to confidentiality contracts and well, honestly, I have read a lot about market saturation. Is there any way you recommend to get noticed? \n\n&amp;#x200B;\n\nLikewise, I don't like to come empty-handed, so if anyone finds it useful or is just starting out, I would like to share some notes that I have made these days just to remember everything. I sincerely appreciate your time reading this publication!  \n\n&amp;#x200B;\n\nPD: I'm leaving the document and my CV in the front of my GitHub, please roast me!\n\n[https://github.com/jlob97/DataScience-Scripts/](https://github.com/jlob97/DataScience-Scripts/)\n\nAll is useful :)\n\nHave a great day,\n\n Jose Luis", "author_fullname": "t2_aak4i7eq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Career][Education] Sharing my summary into concepts of DS and asking for advice!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133hkzt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682835608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greets!&lt;/p&gt;\n\n&lt;p&gt;I am a Bolivian Engineer trying to change career into DS, I have already put my first foot in the area, but I am trying to jump into the international market to learn more (Since the internal market of my country does not have DS professionals). For this reason, I am here to ask you for some help regarding &lt;strong&gt;networking, CV formats (Please roast my CV) and others.&lt;/strong&gt; Currently I cannot share my real projects due to confidentiality contracts and well, honestly, I have read a lot about market saturation. Is there any way you recommend to get noticed? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Likewise, I don&amp;#39;t like to come empty-handed, so if anyone finds it useful or is just starting out, I would like to share some notes that I have made these days just to remember everything. I sincerely appreciate your time reading this publication!  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;PD: I&amp;#39;m leaving the document and my CV in the front of my GitHub, please roast me!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/jlob97/DataScience-Scripts/\"&gt;https://github.com/jlob97/DataScience-Scripts/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;All is useful :)&lt;/p&gt;\n\n&lt;p&gt;Have a great day,&lt;/p&gt;\n\n&lt;p&gt;Jose Luis&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UjaIQoQG7Sf34jNQgTFxDE85bBAk-dl1dpDLZTVlepk.jpg?auto=webp&amp;v=enabled&amp;s=1d4d164bc65a04c0b3bb6ce43faf3a7d1672ce34", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/UjaIQoQG7Sf34jNQgTFxDE85bBAk-dl1dpDLZTVlepk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52b1ce07e4435948d4ec93bc9cada794a8ceb48b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/UjaIQoQG7Sf34jNQgTFxDE85bBAk-dl1dpDLZTVlepk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1f902a63e494f4fa0f80363ac278817ac917ec2", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/UjaIQoQG7Sf34jNQgTFxDE85bBAk-dl1dpDLZTVlepk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f7e459eee0c5bf54e436255a135fd062ddcf074", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/UjaIQoQG7Sf34jNQgTFxDE85bBAk-dl1dpDLZTVlepk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34710450b8e522944cac97650b1e8349e800ca0e", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/UjaIQoQG7Sf34jNQgTFxDE85bBAk-dl1dpDLZTVlepk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6e8d5eae0a4667db3c64c6c65a44f4181a621f8", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/UjaIQoQG7Sf34jNQgTFxDE85bBAk-dl1dpDLZTVlepk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3021864bd773b87ce114061e2ade4cf52b6ab75", "width": 1080, "height": 540}], "variants": {}, "id": "TKwxxLkG0dmfQ3Dzzl9TzrlMw42_HXSkbe6P44h3yKk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "133hkzt", "is_robot_indexable": true, "report_reasons": null, "author": "Jlob97", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/133hkzt/careereducation_sharing_my_summary_into_concepts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/133hkzt/careereducation_sharing_my_summary_into_concepts/", "subreddit_subscribers": 885673, "created_utc": 1682835608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have held positions with titles such as \"research scientist\", \"data analyst\", and \"algorithm developer\" in the past but I've had 5 years of not working through ill health. I'd like to apply for data scientist positions in larger companies. \n\nAs part of my return to work strategy I'd like to complete some independent study to get used to the routine and build stamina etc.\n\nMy degree is in physics and I have a PhD in computational mathematics. I've worked in Matlab, Python, and a little bit of R. I've used libraries in Python including Numpy, Pandas, and Tensorflow. In Matlab I'm familiar with a number of their toolboxes including neural networks.\n\nI've completed a college level course in databases and sql but I've never had to use them in the real world. This is one area of weakness.\n\nI've also never taken a formal stats course beyond a module on the normal distribution at A-level.\n\nDo you have any suggestions on where I should start enhancing my skills? Any good textbooks or free/cheap online courses to work through? Should I build a portfolio? If so, what would this look like?\n\nThanks", "author_fullname": "t2_mvjwsoml", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need more skills to get back into employment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133hl9m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682835630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have held positions with titles such as &amp;quot;research scientist&amp;quot;, &amp;quot;data analyst&amp;quot;, and &amp;quot;algorithm developer&amp;quot; in the past but I&amp;#39;ve had 5 years of not working through ill health. I&amp;#39;d like to apply for data scientist positions in larger companies. &lt;/p&gt;\n\n&lt;p&gt;As part of my return to work strategy I&amp;#39;d like to complete some independent study to get used to the routine and build stamina etc.&lt;/p&gt;\n\n&lt;p&gt;My degree is in physics and I have a PhD in computational mathematics. I&amp;#39;ve worked in Matlab, Python, and a little bit of R. I&amp;#39;ve used libraries in Python including Numpy, Pandas, and Tensorflow. In Matlab I&amp;#39;m familiar with a number of their toolboxes including neural networks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve completed a college level course in databases and sql but I&amp;#39;ve never had to use them in the real world. This is one area of weakness.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also never taken a formal stats course beyond a module on the normal distribution at A-level.&lt;/p&gt;\n\n&lt;p&gt;Do you have any suggestions on where I should start enhancing my skills? Any good textbooks or free/cheap online courses to work through? Should I build a portfolio? If so, what would this look like?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "133hl9m", "is_robot_indexable": true, "report_reasons": null, "author": "oops_whatnow", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/133hl9m/i_need_more_skills_to_get_back_into_employment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/133hl9m/i_need_more_skills_to_get_back_into_employment/", "subreddit_subscribers": 885673, "created_utc": 1682835630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8n5hmj1gq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quantum Machine Learning \u2014Advanced Project Tutorial", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1334uaf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/FzMRNcsgst1YZzzpbIcMIF-sl6JInXGXHore5kp4Hd0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682797491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/p/84d5793e6946", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j5f0s9FonXHQocgh4HdV7XxEGSW7qtrY8M2FfCysbgY.jpg?auto=webp&amp;v=enabled&amp;s=ad563385217e94805a26bcaf814e6ac283163e64", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/j5f0s9FonXHQocgh4HdV7XxEGSW7qtrY8M2FfCysbgY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dacfa11d9517c59a9473f788c553501e94f6795d", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/j5f0s9FonXHQocgh4HdV7XxEGSW7qtrY8M2FfCysbgY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=159797a2ce2df6c9f315040d3891d74b112ed004", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/j5f0s9FonXHQocgh4HdV7XxEGSW7qtrY8M2FfCysbgY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc635b4f23af486ba6fc3c1bd9a399b65167b7fc", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/j5f0s9FonXHQocgh4HdV7XxEGSW7qtrY8M2FfCysbgY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f999fb58e4d7f04e0293f055b1117a5c5225f3a3", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/j5f0s9FonXHQocgh4HdV7XxEGSW7qtrY8M2FfCysbgY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e056fc079e2ca9f84155fae0af4621196d3d42e6", "width": 960, "height": 960}], "variants": {}, "id": "-vSFEpUNzoEY1hlwJuIGDRkWiu9adbUG4WtnplqI8Xo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1334uaf", "is_robot_indexable": true, "report_reasons": null, "author": "MagazinePerfect9021", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1334uaf/quantum_machine_learning_advanced_project_tutorial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/p/84d5793e6946", "subreddit_subscribers": 885673, "created_utc": 1682797491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I understand that EDA is mostly more of an art than science and there's no blueprint you can follow. But I've read advice on this sub about how referencing EDA notebooks on Kaggle can improve one's, for the lack of a better word, intuition for it and I'm wondering if people have fav EDA notebooks from Kaggle/other sites.", "author_fullname": "t2_bk9hp9qn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Your favourite EDA notebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133i3e8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682837505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand that EDA is mostly more of an art than science and there&amp;#39;s no blueprint you can follow. But I&amp;#39;ve read advice on this sub about how referencing EDA notebooks on Kaggle can improve one&amp;#39;s, for the lack of a better word, intuition for it and I&amp;#39;m wondering if people have fav EDA notebooks from Kaggle/other sites.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "133i3e8", "is_robot_indexable": true, "report_reasons": null, "author": "perfectlylonely13", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/133i3e8/your_favourite_eda_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/133i3e8/your_favourite_eda_notebooks/", "subreddit_subscribers": 885673, "created_utc": 1682837505.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am thinking of building a CNN model with Deep Image Prior. I know that it is a model that does not require any prior training, and that the structure of the model is enough to generate the high resolution image, but can someone tell me how it actually works?\n\nIs it the huge number of epochs that we give that takes the place of the training data?", "author_fullname": "t2_atffdhh0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone tell me how Deep Image Prior functions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1337ydu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682805540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thinking of building a CNN model with Deep Image Prior. I know that it is a model that does not require any prior training, and that the structure of the model is enough to generate the high resolution image, but can someone tell me how it actually works?&lt;/p&gt;\n\n&lt;p&gt;Is it the huge number of epochs that we give that takes the place of the training data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1337ydu", "is_robot_indexable": true, "report_reasons": null, "author": "quilted_reader", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1337ydu/can_anyone_tell_me_how_deep_image_prior_functions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1337ydu/can_anyone_tell_me_how_deep_image_prior_functions/", "subreddit_subscribers": 885673, "created_utc": 1682805540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m starting a ML club at my community college to help myself and others get hands on experience. Keeping in mind that most of us won\u2019t have upper division comp sci nor math courses I was wondering if anyone here knew of resources that teaches someone a simple SVM step by step. Doesn\u2019t have to be anything fancy nor complex, just trying to build the club to get cc students started. Ps open to suggestions for other ML topics if they\u2019ll be easier to learn, for the sake of just getting some practice. Thanks for reading.", "author_fullname": "t2_via8h9yy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Support Vector Machine projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133mix1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682853360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m starting a ML club at my community college to help myself and others get hands on experience. Keeping in mind that most of us won\u2019t have upper division comp sci nor math courses I was wondering if anyone here knew of resources that teaches someone a simple SVM step by step. Doesn\u2019t have to be anything fancy nor complex, just trying to build the club to get cc students started. Ps open to suggestions for other ML topics if they\u2019ll be easier to learn, for the sake of just getting some practice. Thanks for reading.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "133mix1", "is_robot_indexable": true, "report_reasons": null, "author": "lilezekias", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/133mix1/support_vector_machine_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/133mix1/support_vector_machine_projects/", "subreddit_subscribers": 885673, "created_utc": 1682853360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just finished up my first DA internship after graduating, starting to apply for more full time, associate-level positions, and just realized I don't have any coding samples to send that aren't from my internship (which are all under NDA) or my old classwork. I'm looking into projects I can do in R that would show my skills in coding and visualization, but I can't seem to find many good examples of professional coding samples done in R. Does anyone have any advice or examples I can looker at?", "author_fullname": "t2_9anx9qeb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for writing coding samples in R, or any examples?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1332bpd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682791046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just finished up my first DA internship after graduating, starting to apply for more full time, associate-level positions, and just realized I don&amp;#39;t have any coding samples to send that aren&amp;#39;t from my internship (which are all under NDA) or my old classwork. I&amp;#39;m looking into projects I can do in R that would show my skills in coding and visualization, but I can&amp;#39;t seem to find many good examples of professional coding samples done in R. Does anyone have any advice or examples I can looker at?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1332bpd", "is_robot_indexable": true, "report_reasons": null, "author": "sommeilhotel", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1332bpd/advice_for_writing_coding_samples_in_r_or_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1332bpd/advice_for_writing_coding_samples_in_r_or_any/", "subreddit_subscribers": 885673, "created_utc": 1682791046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Am currently stuck on a demand forecasting project with multiple time series, approx. 700 different series for product sales at different locations.  \n\nJust wanted to find which type of model is recommended generally for multiple time series (e.g. fitting autoarima 700 times vs. Putting it into a global model like nbeats). I know it'll ultimately depend on the data, but I'm just curious about the approaches taken for those who have done similar projects.", "author_fullname": "t2_6hd2t89qo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "forecasting demand local or global models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1330vu7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682787465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Am currently stuck on a demand forecasting project with multiple time series, approx. 700 different series for product sales at different locations.  &lt;/p&gt;\n\n&lt;p&gt;Just wanted to find which type of model is recommended generally for multiple time series (e.g. fitting autoarima 700 times vs. Putting it into a global model like nbeats). I know it&amp;#39;ll ultimately depend on the data, but I&amp;#39;m just curious about the approaches taken for those who have done similar projects.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1330vu7", "is_robot_indexable": true, "report_reasons": null, "author": "ryeely", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1330vu7/forecasting_demand_local_or_global_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1330vu7/forecasting_demand_local_or_global_models/", "subreddit_subscribers": 885673, "created_utc": 1682787465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello there!\n\nI am an undergraduate student in the field of Information Systems and I am about to start working on my bachelor thesis. The broad topic is exploring the benefits of XAI techniques in the field of energy trading strategies/energy markets. \n\nThe next step is to narrow down the topic into a concrete research question. I have read a couple of papers and have got some ideas. (Some of my ideas include: building an electricity price forecasting model and using SHAP to explain its predictions, explaining predictions made by already existing electricity price forecasting models, explaining a model forecasting electricity demand, explaining a model forecasting solar power generation, \u2026)\n\nHowever, I would like to hear from you. \n\n**What do you think would be an interesting research question to work on?** \n\nI am looking for something that has a relatively narrow scope and is easy to do. I\u2019d rather do something simple really well than doing something super complex poorly. \n\nThank you for your suggestions!", "author_fullname": "t2_a1xpqmjj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a research question in the field of XAI applied to energy markets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_132uh4z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682778321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there!&lt;/p&gt;\n\n&lt;p&gt;I am an undergraduate student in the field of Information Systems and I am about to start working on my bachelor thesis. The broad topic is exploring the benefits of XAI techniques in the field of energy trading strategies/energy markets. &lt;/p&gt;\n\n&lt;p&gt;The next step is to narrow down the topic into a concrete research question. I have read a couple of papers and have got some ideas. (Some of my ideas include: building an electricity price forecasting model and using SHAP to explain its predictions, explaining predictions made by already existing electricity price forecasting models, explaining a model forecasting electricity demand, explaining a model forecasting solar power generation, \u2026)&lt;/p&gt;\n\n&lt;p&gt;However, I would like to hear from you. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What do you think would be an interesting research question to work on?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;I am looking for something that has a relatively narrow scope and is easy to do. I\u2019d rather do something simple really well than doing something super complex poorly. &lt;/p&gt;\n\n&lt;p&gt;Thank you for your suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "132uh4z", "is_robot_indexable": true, "report_reasons": null, "author": "kaigibson1928", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/132uh4z/looking_for_a_research_question_in_the_field_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/132uh4z/looking_for_a_research_question_in_the_field_of/", "subreddit_subscribers": 885673, "created_utc": 1682778321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR:\nJob interview coming up for Data Analyst role. Needs tips on how to interview for a research oriented role with no true research experience.  \n\nHello, I have applied for and received an interview request for a DA role at a large hospital in my area. I\u2019ve been working for this company but at a separate health facility under the same owner. The role seems to primarily use R as that was the only software or tool mentioned in the desc. I have done work with R back in 2020 when I completed a Healthcare Analytics master program, the hiring manager (who is the PI) asked for my transcripts to get a better idea of what that program entails for courses. Some of my courses had logistical and linear regression, predictable and prescriptive analytics, statistical analysis, hypothesis testing, some ML but that shot was hard, etc. since then the only real R work I have done is on my own. But I utilize sql and Tableau for my current role so I\u2019ll drop those in for added skills in the interview.\n\nI\u2019m worried since I have no experience in the work or research they do I could fall short. The job description lists out the work they do and the datasets available from 4 different studies. I\u2019m about to start researching the department, the PI the primary disease they study, etc to gain knowledge and help me come up with talking points. \n\nI really want this job as it\u2019s perfect for me and the right step to a more technical role with a company o already very much enjoy (internal candidate) \n\nDoes anyone familiar with this type of data analysis work have any interview tips or suggestions? They want to interview me as early as Monday (in 2 days, I applied on 4/25) but they gave me times for Thursday as well? Do I take the two day approach or take it slow and prepare over the next week?\n\nThanks so much in advance!", "author_fullname": "t2_k95d913", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got an interview for Data Analyst role for cancer sequencing group", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1332xkp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682792583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR:\nJob interview coming up for Data Analyst role. Needs tips on how to interview for a research oriented role with no true research experience.  &lt;/p&gt;\n\n&lt;p&gt;Hello, I have applied for and received an interview request for a DA role at a large hospital in my area. I\u2019ve been working for this company but at a separate health facility under the same owner. The role seems to primarily use R as that was the only software or tool mentioned in the desc. I have done work with R back in 2020 when I completed a Healthcare Analytics master program, the hiring manager (who is the PI) asked for my transcripts to get a better idea of what that program entails for courses. Some of my courses had logistical and linear regression, predictable and prescriptive analytics, statistical analysis, hypothesis testing, some ML but that shot was hard, etc. since then the only real R work I have done is on my own. But I utilize sql and Tableau for my current role so I\u2019ll drop those in for added skills in the interview.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m worried since I have no experience in the work or research they do I could fall short. The job description lists out the work they do and the datasets available from 4 different studies. I\u2019m about to start researching the department, the PI the primary disease they study, etc to gain knowledge and help me come up with talking points. &lt;/p&gt;\n\n&lt;p&gt;I really want this job as it\u2019s perfect for me and the right step to a more technical role with a company o already very much enjoy (internal candidate) &lt;/p&gt;\n\n&lt;p&gt;Does anyone familiar with this type of data analysis work have any interview tips or suggestions? They want to interview me as early as Monday (in 2 days, I applied on 4/25) but they gave me times for Thursday as well? Do I take the two day approach or take it slow and prepare over the next week?&lt;/p&gt;\n\n&lt;p&gt;Thanks so much in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1332xkp", "is_robot_indexable": true, "report_reasons": null, "author": "Potential_Lettuce", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1332xkp/got_an_interview_for_data_analyst_role_for_cancer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1332xkp/got_an_interview_for_data_analyst_role_for_cancer/", "subreddit_subscribers": 885673, "created_utc": 1682792583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, \n\nMy data science internship starts in a couple weeks and I feel grossly underprepared for it. I feel like the only thing I should be doing right now is cramming as much data science into my head as possible in the next few weeks so I don't look like a stupid idiot on the job. It's with a large corp (fortune 20) and I'd like to impress them enough for them to convert me to full time afterwards. I don't really have a traditional data science background (only took one course in stats like 2 years ago), so I don't even know how I got this internship in the first place. Any advice/tips on what I should do/focus on before the internship starts (besides brushing up on harmonic means ofc)?", "author_fullname": "t2_bdqv6sie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Internship Preparedness", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1332l0p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682791676.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, &lt;/p&gt;\n\n&lt;p&gt;My data science internship starts in a couple weeks and I feel grossly underprepared for it. I feel like the only thing I should be doing right now is cramming as much data science into my head as possible in the next few weeks so I don&amp;#39;t look like a stupid idiot on the job. It&amp;#39;s with a large corp (fortune 20) and I&amp;#39;d like to impress them enough for them to convert me to full time afterwards. I don&amp;#39;t really have a traditional data science background (only took one course in stats like 2 years ago), so I don&amp;#39;t even know how I got this internship in the first place. Any advice/tips on what I should do/focus on before the internship starts (besides brushing up on harmonic means ofc)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1332l0p", "is_robot_indexable": true, "report_reasons": null, "author": "MichiganSimp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1332l0p/data_science_internship_preparedness/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1332l0p/data_science_internship_preparedness/", "subreddit_subscribers": 885673, "created_utc": 1682791676.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nNew to data visualization. Looking to create a graph to display a stages/checkpoints (which represent E2E coding tests) that are each dependent on each other.  \n\n\nCheckpoint 1  \nCheckpoint 2  \nCheckpoint 3  \nCheckpoint 4  \nCheckpoint 5  \n\n\nIf checkpoint 3 fails then 4 and 5 also fail. Which is why this is critical to surface the severity to triage. I would like to express their pass rate in this view as well. \n\nBonus:   \nCheckpoint 4 could have different tests. a, b, c, d. That all rely on 1, 2, 3. Possible to express this as well? Or might be too cluttered.  \n\n\nWhat graph or examples could do this well? Apologize if there is a better sub for this, Thanks!", "author_fullname": "t2_150kgu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Correct Graph for a series of dependent stages with their success rates, over time if possible.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_132z9na", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682783480.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;New to data visualization. Looking to create a graph to display a stages/checkpoints (which represent E2E coding tests) that are each dependent on each other.  &lt;/p&gt;\n\n&lt;p&gt;Checkpoint 1&lt;br/&gt;\nCheckpoint 2&lt;br/&gt;\nCheckpoint 3&lt;br/&gt;\nCheckpoint 4&lt;br/&gt;\nCheckpoint 5  &lt;/p&gt;\n\n&lt;p&gt;If checkpoint 3 fails then 4 and 5 also fail. Which is why this is critical to surface the severity to triage. I would like to express their pass rate in this view as well. &lt;/p&gt;\n\n&lt;p&gt;Bonus:&lt;br/&gt;\nCheckpoint 4 could have different tests. a, b, c, d. That all rely on 1, 2, 3. Possible to express this as well? Or might be too cluttered.  &lt;/p&gt;\n\n&lt;p&gt;What graph or examples could do this well? Apologize if there is a better sub for this, Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "132z9na", "is_robot_indexable": true, "report_reasons": null, "author": "javaHoosier", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/132z9na/correct_graph_for_a_series_of_dependent_stages/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/132z9na/correct_graph_for_a_series_of_dependent_stages/", "subreddit_subscribers": 885673, "created_utc": 1682783480.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sorry for my English. Hi everyone, How do you interpret this interaction ? Tanks for the help...\n\n&amp;#x200B;\n\nhttps://preview.redd.it/abfbnw3kauwa1.png?width=1116&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9a92881509bae57045d00124aeb93cf71b053870\n\nhttps://preview.redd.it/f43chd2lauwa1.png?width=458&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c54202c67676c3b1b5abc96c55b7866dbc74ecce", "author_fullname": "t2_thbyp5gl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moderation analysis (Model 1)- Simple slope interpretation Sorry for my English. Hi everyone, How do you interpret this interaction ? Tanks for the help...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 95, "top_awarded_type": null, "hide_score": false, "media_metadata": {"abfbnw3kauwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 73, "x": 108, "u": "https://preview.redd.it/abfbnw3kauwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1db1f0bf1e7abecb0983507d85e8f51bb5e0cede"}, {"y": 147, "x": 216, "u": "https://preview.redd.it/abfbnw3kauwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66920f521beffa8e985be88ea1030fd67c92058c"}, {"y": 217, "x": 320, "u": "https://preview.redd.it/abfbnw3kauwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a224882eab33ebf27142bb0da4b6e7238c377efc"}, {"y": 435, "x": 640, "u": "https://preview.redd.it/abfbnw3kauwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab4129d0293fc85227eb0fcafa678b824d812b00"}, {"y": 653, "x": 960, "u": "https://preview.redd.it/abfbnw3kauwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01ede951191e085764894432f29cc87f55122adc"}, {"y": 735, "x": 1080, "u": "https://preview.redd.it/abfbnw3kauwa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f9c7a6697b5feaa5a7587a18b95745401161a606"}], "s": {"y": 760, "x": 1116, "u": "https://preview.redd.it/abfbnw3kauwa1.png?width=1116&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9a92881509bae57045d00124aeb93cf71b053870"}, "id": "abfbnw3kauwa1"}, "f43chd2lauwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/f43chd2lauwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36e4250ac88ee8da3f6e430f2f51947360f3dd9b"}, {"y": 155, "x": 216, "u": "https://preview.redd.it/f43chd2lauwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d24c505416558783e1db4cd6ef0f6832029bb8ba"}, {"y": 230, "x": 320, "u": "https://preview.redd.it/f43chd2lauwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26931495a7f247cdda4899fee8674b5b8264bf96"}], "s": {"y": 330, "x": 458, "u": "https://preview.redd.it/f43chd2lauwa1.png?width=458&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c54202c67676c3b1b5abc96c55b7866dbc74ecce"}, "id": "f43chd2lauwa1"}}, "name": "t3_132xfaa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2f3FyDpgyb_Ne1vxcz-jit0jWAqm7OlLyKfLJWjVKvY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682781090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry for my English. Hi everyone, How do you interpret this interaction ? Tanks for the help...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/abfbnw3kauwa1.png?width=1116&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9a92881509bae57045d00124aeb93cf71b053870\"&gt;https://preview.redd.it/abfbnw3kauwa1.png?width=1116&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9a92881509bae57045d00124aeb93cf71b053870&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/f43chd2lauwa1.png?width=458&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c54202c67676c3b1b5abc96c55b7866dbc74ecce\"&gt;https://preview.redd.it/f43chd2lauwa1.png?width=458&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c54202c67676c3b1b5abc96c55b7866dbc74ecce&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "132xfaa", "is_robot_indexable": true, "report_reasons": null, "author": "Best-Tour-2952", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/132xfaa/moderation_analysis_model_1_simple_slope/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/132xfaa/moderation_analysis_model_1_simple_slope/", "subreddit_subscribers": 885673, "created_utc": 1682781090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m lucky enough to land a role where company can pay for masters (eventually I want to go into data science). But it\u2019s a Customer Service analyst job and the company uses Gainsight. I\u2019ve never heard of this tool before and just want to know if the experience will help my career. (I\u2019m a new grad)", "author_fullname": "t2_27i5pudn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How transferable/valuable is Gainsight?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_132u33n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682777920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m lucky enough to land a role where company can pay for masters (eventually I want to go into data science). But it\u2019s a Customer Service analyst job and the company uses Gainsight. I\u2019ve never heard of this tool before and just want to know if the experience will help my career. (I\u2019m a new grad)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "132u33n", "is_robot_indexable": true, "report_reasons": null, "author": "skibum143", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/132u33n/how_transferablevaluable_is_gainsight/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/132u33n/how_transferablevaluable_is_gainsight/", "subreddit_subscribers": 885673, "created_utc": 1682777920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a senior DS and feel like it's a bit of an abusive relationship. I like what I do and some of the problems are really interesting, but more often than not I just feel tired and frustrated with problems that often don't have a tidy 'closed form' solution. Not to mention the various political reasons that might shut down a good analysis even if the stats are solid. Or project managers trying to force scrum on research projects. Or when business stakeholders try to interpolate preconceived notions where data doesn't exist.\n\nThe metaphorically attractive 'SWE girl' is causing my eye to wander and make me wonder if the grass is greener in engineering. Somebody talk me down before I consider what could potentially be a costly affair (career switch).", "author_fullname": "t2_1l4tydt4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've been flirting with another field and worry that I might cheat", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_133bmtw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682815789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a senior DS and feel like it&amp;#39;s a bit of an abusive relationship. I like what I do and some of the problems are really interesting, but more often than not I just feel tired and frustrated with problems that often don&amp;#39;t have a tidy &amp;#39;closed form&amp;#39; solution. Not to mention the various political reasons that might shut down a good analysis even if the stats are solid. Or project managers trying to force scrum on research projects. Or when business stakeholders try to interpolate preconceived notions where data doesn&amp;#39;t exist.&lt;/p&gt;\n\n&lt;p&gt;The metaphorically attractive &amp;#39;SWE girl&amp;#39; is causing my eye to wander and make me wonder if the grass is greener in engineering. Somebody talk me down before I consider what could potentially be a costly affair (career switch).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "133bmtw", "is_robot_indexable": true, "report_reasons": null, "author": "lil_meep", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/133bmtw/ive_been_flirting_with_another_field_and_worry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/133bmtw/ive_been_flirting_with_another_field_and_worry/", "subreddit_subscribers": 885673, "created_utc": 1682815789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4cwqlmgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guys, I need your inputs on the regression I need to use for this. Does Linear regression make sense when you have a category variable? I have a question in my assignment where they asked to plot a regression line for this scatter plot. However I am clueless regarding which suits best for this.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "name": "t3_1335n25", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/KP8wIrJ5Qvau3A195hFyMRsjVusqqG4HQYeMs10q9I4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682799604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/0iapm857bxwa1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/0iapm857bxwa1.png?auto=webp&amp;v=enabled&amp;s=1a51b147f8989e93b57201b48c94e566313143a3", "width": 1080, "height": 510}, "resolutions": [{"url": "https://preview.redd.it/0iapm857bxwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0d1ae98b78f00c8172e5869d98e28c78d7aafd0", "width": 108, "height": 51}, {"url": "https://preview.redd.it/0iapm857bxwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=541c44abba9d11d4d83a6821a64b63e1fa383aa9", "width": 216, "height": 102}, {"url": "https://preview.redd.it/0iapm857bxwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=502f30b12b8e665263820abe6a2fdc1a90f63179", "width": 320, "height": 151}, {"url": "https://preview.redd.it/0iapm857bxwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c218231c051b4351af25ae7fc739650fb12fd7b", "width": 640, "height": 302}, {"url": "https://preview.redd.it/0iapm857bxwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b27d31302bc0db45c3c76e80574ff078db4183c", "width": 960, "height": 453}, {"url": "https://preview.redd.it/0iapm857bxwa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=090985e1e9bffa250babae1f210b035b08563a57", "width": 1080, "height": 510}], "variants": {}, "id": "YJx2sC-hFINC4MgsDIN_ELK77yHYsfoGsj14cGijEvQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1335n25", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable_Yam_7330", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1335n25/guys_i_need_your_inputs_on_the_regression_i_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/0iapm857bxwa1.png", "subreddit_subscribers": 885673, "created_utc": 1682799604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-supervised learning for stock return prediction based on technical indicators", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_1334dy9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_9x4x53qyp", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yVppJg4LwS33kwZe25F4i1L1juI7CCd0MyOmXrk7cTA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "deeplearning", "selftext": "[Technical indicator-based self-supervised learning for stock price prediction and seeking alpha](https://preview.redd.it/yjg42gwqnuwa1.png?width=1512&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=578fd3a0abd727613504dc0dfb3509b3902c8c4f)\n\n# Goal\n\n* Build a model to predict stock return\n* Build a model to seek alpha\n* Build a model to output beneficial indicators for portfolio management for hedge fund\n\n# Dataset\n\n* Stock price data\n* target stocks are over 3000\n* without alternative data, such as Twitter, satellite image\n* I want to use other data resources after I beat LightGBM with NN\n\n# What I did\n\n* Famous technical indicators + LightGBM -&gt; Best performance\n* Raw stock price data + NN -&gt; Terrible performance\n* A self-supervised method based on technical indicators + LightGBM -&gt; Not bad, Not good\n* A self-supervised method based on technical indicators + NN -&gt; Bad\n\n# Issue\n\n* NN cannot beat LightGBM\n* My proposal method doesn't work\n* NN cannot extract all information from price data worse than technical indicators\n* I cannot find a good research paper to achieve my goal in my desired way\n* I cannot find any paper similar to my idea\n* I don't know if my idea is wrong or if I am thinking of the correct approach\n* I don't understand why NN cannot outperform the decision tree because raw price data has uncompressed information compared to technical indicators\n\n# My theory based on my experience\n\n* NN is not good at technical indicators\n* NN is not good at table data\n* NN is not good at stock price data which contains a lot of noise\n* NN is sensitive to noise, it's useless at least in my environment\n* In the finance field, the quantitative approach is definitely better than NN\n* compared to other AI fields, like NLP, Image, Financial data is very small size and not abstract. very sensitive data. Financial data is different from data in other fields\n* \u2191 That is why LightGBM is good for technical indicators, this model just tries to divide data with linear surface \n* I can say Technical indicators have the capability to predict because technical indicators + LightGBM is best for return prediction in my experimental environment\n\n# What I want to do\n\n* I want to beat LightGBM (baseline) with NN\n* I don't want to use the quantitative method, like ARIMA \n* I don't want to use only a decision tree if possible\n* I want to use NN, I want to find the power of NN in the finance field because for now, I think NN is not good in this field based on my experience\n* I don't want to use technical indicators which everyone uses for trading\n* I want to extract beneficial information, in other words, alpha, with NN\n* I want to convert raw stock price data into abstract vectors which contain a lot of beneficial information\n* I want to train NN which is robustness to noise\n\n# My proposal method (Please find the attached image)\n\n* self-supervised learning based on technical indicators\n   * Try to make a good vector that minimizes MSE between two technical indicator vectors and two vectors\n   * the model outputs are related to each other in technical indicator spaces\n   * I think the model can be noise-robustness after this SSL process\n* Another method: AutoEncoder to get good vector expression\n   * can get a hidden vector that compresses actual price data\n\n# Question\n\n* Can you come up with a better approach?", "author_fullname": "t2_9x4x53qyp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-supervised learning for stock return prediction based on technical indicators", "link_flair_richtext": [], "subreddit_name_prefixed": "r/deeplearning", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "media_metadata": {"yjg42gwqnuwa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/yjg42gwqnuwa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4ac85debd7b7933b4e8140bdbf63f8ed0e36a23"}, {"y": 117, "x": 216, "u": "https://preview.redd.it/yjg42gwqnuwa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04e7653be085b99baef5bed89e0261e64b854918"}, {"y": 173, "x": 320, "u": "https://preview.redd.it/yjg42gwqnuwa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b5d6d8d60a12612039c32072bf3e589596aa88a"}, {"y": 347, "x": 640, "u": "https://preview.redd.it/yjg42gwqnuwa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=996c8670d4dcd29c260fcbbd4ba78b5398c06204"}, {"y": 521, "x": 960, "u": "https://preview.redd.it/yjg42gwqnuwa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5cd3553b366d3e43b17957c9de7d2ba0db79d0a9"}, {"y": 587, "x": 1080, "u": "https://preview.redd.it/yjg42gwqnuwa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad2bbc965658074f1d8adee18943eb37daba6c86"}], "s": {"y": 822, "x": 1512, "u": "https://preview.redd.it/yjg42gwqnuwa1.png?width=1512&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=578fd3a0abd727613504dc0dfb3509b3902c8c4f"}, "id": "yjg42gwqnuwa1"}}, "name": "t3_1330i60", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682786528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.deeplearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/yjg42gwqnuwa1.png?width=1512&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=578fd3a0abd727613504dc0dfb3509b3902c8c4f\"&gt;Technical indicator-based self-supervised learning for stock price prediction and seeking alpha&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Goal&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Build a model to predict stock return&lt;/li&gt;\n&lt;li&gt;Build a model to seek alpha&lt;/li&gt;\n&lt;li&gt;Build a model to output beneficial indicators for portfolio management for hedge fund&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Dataset&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Stock price data&lt;/li&gt;\n&lt;li&gt;target stocks are over 3000&lt;/li&gt;\n&lt;li&gt;without alternative data, such as Twitter, satellite image&lt;/li&gt;\n&lt;li&gt;I want to use other data resources after I beat LightGBM with NN&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;What I did&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Famous technical indicators + LightGBM -&amp;gt; Best performance&lt;/li&gt;\n&lt;li&gt;Raw stock price data + NN -&amp;gt; Terrible performance&lt;/li&gt;\n&lt;li&gt;A self-supervised method based on technical indicators + LightGBM -&amp;gt; Not bad, Not good&lt;/li&gt;\n&lt;li&gt;A self-supervised method based on technical indicators + NN -&amp;gt; Bad&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Issue&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;NN cannot beat LightGBM&lt;/li&gt;\n&lt;li&gt;My proposal method doesn&amp;#39;t work&lt;/li&gt;\n&lt;li&gt;NN cannot extract all information from price data worse than technical indicators&lt;/li&gt;\n&lt;li&gt;I cannot find a good research paper to achieve my goal in my desired way&lt;/li&gt;\n&lt;li&gt;I cannot find any paper similar to my idea&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t know if my idea is wrong or if I am thinking of the correct approach&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t understand why NN cannot outperform the decision tree because raw price data has uncompressed information compared to technical indicators&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;My theory based on my experience&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;NN is not good at technical indicators&lt;/li&gt;\n&lt;li&gt;NN is not good at table data&lt;/li&gt;\n&lt;li&gt;NN is not good at stock price data which contains a lot of noise&lt;/li&gt;\n&lt;li&gt;NN is sensitive to noise, it&amp;#39;s useless at least in my environment&lt;/li&gt;\n&lt;li&gt;In the finance field, the quantitative approach is definitely better than NN&lt;/li&gt;\n&lt;li&gt;compared to other AI fields, like NLP, Image, Financial data is very small size and not abstract. very sensitive data. Financial data is different from data in other fields&lt;/li&gt;\n&lt;li&gt;\u2191 That is why LightGBM is good for technical indicators, this model just tries to divide data with linear surface &lt;/li&gt;\n&lt;li&gt;I can say Technical indicators have the capability to predict because technical indicators + LightGBM is best for return prediction in my experimental environment&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;What I want to do&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I want to beat LightGBM (baseline) with NN&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t want to use the quantitative method, like ARIMA &lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t want to use only a decision tree if possible&lt;/li&gt;\n&lt;li&gt;I want to use NN, I want to find the power of NN in the finance field because for now, I think NN is not good in this field based on my experience&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t want to use technical indicators which everyone uses for trading&lt;/li&gt;\n&lt;li&gt;I want to extract beneficial information, in other words, alpha, with NN&lt;/li&gt;\n&lt;li&gt;I want to convert raw stock price data into abstract vectors which contain a lot of beneficial information&lt;/li&gt;\n&lt;li&gt;I want to train NN which is robustness to noise&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;My proposal method (Please find the attached image)&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;self-supervised learning based on technical indicators\n\n&lt;ul&gt;\n&lt;li&gt;Try to make a good vector that minimizes MSE between two technical indicator vectors and two vectors&lt;/li&gt;\n&lt;li&gt;the model outputs are related to each other in technical indicator spaces&lt;/li&gt;\n&lt;li&gt;I think the model can be noise-robustness after this SSL process&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Another method: AutoEncoder to get good vector expression\n\n&lt;ul&gt;\n&lt;li&gt;can get a hidden vector that compresses actual price data&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Question&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Can you come up with a better approach?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2t5eh", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1330i60", "is_robot_indexable": true, "report_reasons": null, "author": "Common-Ad-1772", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/deeplearning/comments/1330i60/selfsupervised_learning_for_stock_return/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/deeplearning/comments/1330i60/selfsupervised_learning_for_stock_return/", "subreddit_subscribers": 93862, "created_utc": 1682786528.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1682796309.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.deeplearning", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/deeplearning/comments/1330i60/selfsupervised_learning_for_stock_return/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1334dy9", "is_robot_indexable": true, "report_reasons": null, "author": "Common-Ad-1772", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1330i60", "author_flair_text_color": null, "permalink": "/r/datascience/comments/1334dy9/selfsupervised_learning_for_stock_return/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/deeplearning/comments/1330i60/selfsupervised_learning_for_stock_return/", "subreddit_subscribers": 885673, "created_utc": 1682796309.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sorry for my English.\n\nHi everyone, How do you *interpret* this interaction ? Tanks for the help...", "author_fullname": "t2_thbyp5gl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moderation analysis (Model 1)- Simple slope interpretation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_132wg4x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682780177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry for my English.&lt;/p&gt;\n\n&lt;p&gt;Hi everyone, How do you &lt;em&gt;interpret&lt;/em&gt; this interaction ? Tanks for the help...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "132wg4x", "is_robot_indexable": true, "report_reasons": null, "author": "Best-Tour-2952", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/132wg4x/moderation_analysis_model_1_simple_slope/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/132wg4x/moderation_analysis_model_1_simple_slope/", "subreddit_subscribers": 885673, "created_utc": 1682780177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently working as a Business Analyst for a company doing primarily reporting automation. I am three years out of College and starting to look into Grad School in a Data related field. My dad was able to set up a call between me and his old classmate who's the CEO of a company that deals with data solutions. I am talking with him in an hour and want to think of well thought out questions to ask him.\n\nA lot of the information I want to know has to do with what Data fields are increasingly more important in today's world, what tools are vital for me to learn if I want to go down the data science/analytics/comp sci path, what his experiences were in data, any trends he sees in the industry, what should someone who's in a similar spot to me focus on when thinking about how to learn and grow in my career, etc.\n\nFor context, I have experience with SQL, SSRS, Visual Basic, some R and some python but not a whole lot. I'm interested in learning more and getting into either Data Science or Computer Science and this conversation would help to make an informed decision. Also if there are general questions I should be asking, please let me know as well. Appreciate any replies and advice!", "author_fullname": "t2_urq5x6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meeting in an hour! Questions to ask a CEO of a big Data company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_132z6xc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682783296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working as a Business Analyst for a company doing primarily reporting automation. I am three years out of College and starting to look into Grad School in a Data related field. My dad was able to set up a call between me and his old classmate who&amp;#39;s the CEO of a company that deals with data solutions. I am talking with him in an hour and want to think of well thought out questions to ask him.&lt;/p&gt;\n\n&lt;p&gt;A lot of the information I want to know has to do with what Data fields are increasingly more important in today&amp;#39;s world, what tools are vital for me to learn if I want to go down the data science/analytics/comp sci path, what his experiences were in data, any trends he sees in the industry, what should someone who&amp;#39;s in a similar spot to me focus on when thinking about how to learn and grow in my career, etc.&lt;/p&gt;\n\n&lt;p&gt;For context, I have experience with SQL, SSRS, Visual Basic, some R and some python but not a whole lot. I&amp;#39;m interested in learning more and getting into either Data Science or Computer Science and this conversation would help to make an informed decision. Also if there are general questions I should be asking, please let me know as well. Appreciate any replies and advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "132z6xc", "is_robot_indexable": true, "report_reasons": null, "author": "gneev", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/132z6xc/meeting_in_an_hour_questions_to_ask_a_ceo_of_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/132z6xc/meeting_in_an_hour_questions_to_ask_a_ceo_of_a/", "subreddit_subscribers": 885673, "created_utc": 1682783296.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}