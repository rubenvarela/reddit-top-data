{"kind": "Listing", "data": {"after": "t3_12kult0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a49okn69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who owns data quality?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 128, "top_awarded_type": null, "hide_score": false, "name": "t3_12l9mzx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 482, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 482, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pEGgrT6AA0Ee7mh3QIRZ3wvGng2GrkEtE8Vu2pZZaYs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681425657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/8ma1yb67cqta1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/8ma1yb67cqta1.jpg?auto=webp&amp;v=enabled&amp;s=c76f3ae14fda40cd714446ff0014957170862a87", "width": 544, "height": 500}, "resolutions": [{"url": "https://preview.redd.it/8ma1yb67cqta1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0f5357d6ad8fd22807c299e69c1cea0f02eef2a7", "width": 108, "height": 99}, {"url": "https://preview.redd.it/8ma1yb67cqta1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=733fddc2fdf613c203bb9c2be183514abad5d0ee", "width": 216, "height": 198}, {"url": "https://preview.redd.it/8ma1yb67cqta1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b959130ca293342df5aaf140d27d94fe653fe379", "width": 320, "height": 294}], "variants": {}, "id": "_zipJWJt_VoFsn3ElGALbQLgo-DKOM9i4P2OFhKqSN8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "12l9mzx", "is_robot_indexable": true, "report_reasons": null, "author": "Top-Substance2185", "discussion_type": null, "num_comments": 69, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12l9mzx/who_owns_data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/8ma1yb67cqta1.jpg", "subreddit_subscribers": 98854, "created_utc": 1681425657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If yes, which modeling pattern do you see winning out?\n\nprimarily based on Zones or Stages: Bronze -&gt; Silver -&gt; Gold?  \nprimarily based on Star schemas or Snowflake schemas?", "author_fullname": "t2_bv368at0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which data modeling pattern does your data team use today? Is it used much at all? Or have modern data warehouses made it easy for modeling logic to just be bundled into larger or more complex SQL queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12l2n5y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681417718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If yes, which modeling pattern do you see winning out?&lt;/p&gt;\n\n&lt;p&gt;primarily based on Zones or Stages: Bronze -&amp;gt; Silver -&amp;gt; Gold?&lt;br/&gt;\nprimarily based on Star schemas or Snowflake schemas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12l2n5y", "is_robot_indexable": true, "report_reasons": null, "author": "InterestingsBed", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12l2n5y/which_data_modeling_pattern_does_your_data_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12l2n5y/which_data_modeling_pattern_does_your_data_team/", "subreddit_subscribers": 98854, "created_utc": 1681417718.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI am new to AWS and I am reaching out to the community to explore our options for building data pipelines. \n\nWe need to export metrics from AWS Prometheus to S3 every 5 minutes and then use this data in Sagemaker to build some ML models. The pipelines should be declarative in the sense that we want to specify what metrics to query. Also there is the possibility that the bussines will want historical data from Prometheus. The data will be either accesed via Athena or we will send it to Redshift. We haven't decided yet. \n\nWhat would be the best services to use to achieve this? My approach would be to use AWS Airflow and just build custom data pipelines. Is there a better way?\n\nThanks!", "author_fullname": "t2_7sdm747h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lnebj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681455178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am new to AWS and I am reaching out to the community to explore our options for building data pipelines. &lt;/p&gt;\n\n&lt;p&gt;We need to export metrics from AWS Prometheus to S3 every 5 minutes and then use this data in Sagemaker to build some ML models. The pipelines should be declarative in the sense that we want to specify what metrics to query. Also there is the possibility that the bussines will want historical data from Prometheus. The data will be either accesed via Athena or we will send it to Redshift. We haven&amp;#39;t decided yet. &lt;/p&gt;\n\n&lt;p&gt;What would be the best services to use to achieve this? My approach would be to use AWS Airflow and just build custom data pipelines. Is there a better way?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12lnebj", "is_robot_indexable": true, "report_reasons": null, "author": "aliuta", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12lnebj/aws_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lnebj/aws_data_pipelines/", "subreddit_subscribers": 98854, "created_utc": 1681455178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, my department is moving to databricks, to be more specific it is been used already in another departments and our department will be adapting it soon. The other couple of departments swears by it, but I was wondering what are your opinions on it especially the main drawbacks. Thanks", "author_fullname": "t2_8b001z5d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hi all, my department is moving to databricks and I am trying to get familiar with all the merits and most importantly the demerits", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kue6t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681402617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, my department is moving to databricks, to be more specific it is been used already in another departments and our department will be adapting it soon. The other couple of departments swears by it, but I was wondering what are your opinions on it especially the main drawbacks. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12kue6t", "is_robot_indexable": true, "report_reasons": null, "author": "bagsofmysteries", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kue6t/hi_all_my_department_is_moving_to_databricks_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kue6t/hi_all_my_department_is_moving_to_databricks_and/", "subreddit_subscribers": 98854, "created_utc": 1681402617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In every interview for a Data Engineer role, Spark Architecture seems be the only concept the recruiters are interested. \n\nI have 1 year experience as a Data Engineer. I work with Databricks on a day to day basis in Azure, without having to learn what's happening in the background (Spark Architecture). But this does seem to be enough to get a new job as Data Engineer.\n\nI tried searching online for a Spark course, but couldn't find the one that has all the important concepts and good for beginners.\n\nExperts of Spark, how did you learn Spark ? I'd really appreciate if you suggest some good resources/courses to learn Spark Architecture, so that I can clear interviews to get a job.\n\n TIA.", "author_fullname": "t2_tme0hylh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Not clearing interviews due to Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lu3wk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681471782.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In every interview for a Data Engineer role, Spark Architecture seems be the only concept the recruiters are interested. &lt;/p&gt;\n\n&lt;p&gt;I have 1 year experience as a Data Engineer. I work with Databricks on a day to day basis in Azure, without having to learn what&amp;#39;s happening in the background (Spark Architecture). But this does seem to be enough to get a new job as Data Engineer.&lt;/p&gt;\n\n&lt;p&gt;I tried searching online for a Spark course, but couldn&amp;#39;t find the one that has all the important concepts and good for beginners.&lt;/p&gt;\n\n&lt;p&gt;Experts of Spark, how did you learn Spark ? I&amp;#39;d really appreciate if you suggest some good resources/courses to learn Spark Architecture, so that I can clear interviews to get a job.&lt;/p&gt;\n\n&lt;p&gt;TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12lu3wk", "is_robot_indexable": true, "report_reasons": null, "author": "fightinmee", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12lu3wk/not_clearing_interviews_due_to_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lu3wk/not_clearing_interviews_due_to_spark/", "subreddit_subscribers": 98854, "created_utc": 1681471782.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In software engineering we have sdet and QA''s to do testing so in same way do we have specific people to do testing.\nIn my squad we data engineer are it self doing testing for our projects and in other squad data analyst does that\nIs it same in your company also?", "author_fullname": "t2_7yh1jlaz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who does testing in data teams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lnev8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681455216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In software engineering we have sdet and QA&amp;#39;&amp;#39;s to do testing so in same way do we have specific people to do testing.\nIn my squad we data engineer are it self doing testing for our projects and in other squad data analyst does that\nIs it same in your company also?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12lnev8", "is_robot_indexable": true, "report_reasons": null, "author": "Foot_Straight", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12lnev8/who_does_testing_in_data_teams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lnev8/who_does_testing_in_data_teams/", "subreddit_subscribers": 98854, "created_utc": 1681455216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One hassle is that if I change the DAG name, it recognizes it as a new DAG. I'd prefer to maybe have a unique DAG id that never changes but a DAG name that is mutable. Is it possible in Airflow 2?\n\nThought about a second one: In Airflow UI, AFAIK, you can only view code, not the sql files that those code call for, unless they are embedded in code. Yeah I can view them in \"rendered template\" if they already ran once, but what if they are new?\n\n&amp;#x200B;", "author_fullname": "t2_ldvtxo0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One hassle of Airflow that I do not know how to solve", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12l1upw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681416422.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681416179.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One hassle is that if I change the DAG name, it recognizes it as a new DAG. I&amp;#39;d prefer to maybe have a unique DAG id that never changes but a DAG name that is mutable. Is it possible in Airflow 2?&lt;/p&gt;\n\n&lt;p&gt;Thought about a second one: In Airflow UI, AFAIK, you can only view code, not the sql files that those code call for, unless they are embedded in code. Yeah I can view them in &amp;quot;rendered template&amp;quot; if they already ran once, but what if they are new?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12l1upw", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway20220231", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12l1upw/one_hassle_of_airflow_that_i_do_not_know_how_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12l1upw/one_hassle_of_airflow_that_i_do_not_know_how_to/", "subreddit_subscribers": 98854, "created_utc": 1681416179.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data Stack Summit 2023 (live virtual) is next Wednesday 4/19. Passes are free and attendance certificates are issued if you need them for your employer. \n\nhttps://datastacksummit.com\n\nA couple of the interesting sessions: \n\n* 8:05 AM PST - Peer-to-Peer Panel: Managing cloud costs right now w/ Joseph Machado, Carlos Costa, Vikas Ranjan, Mike Fuller, and Mike Mooney\n* 10:25 AM PST - Walmart's self-service metadata-driven data loader framework with Manimuthu Aayyannan and Subramanya Mulgund\n* 12:10 PM PST - Is synthetic data useful for data engineers? with Alexander Mikhalev and Matthew Norton\n\nLive sessions will be available to registrants on-demand post-event, helpful for those in different time zones. Appreciate the support everything we do is community-built.", "author_fullname": "t2_ff7f8okm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Peer sessions at Data Stack Summit + attendance certificate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kxvfs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681480950.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681409343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Stack Summit 2023 (live virtual) is next Wednesday 4/19. Passes are free and attendance certificates are issued if you need them for your employer. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://datastacksummit.com\"&gt;https://datastacksummit.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A couple of the interesting sessions: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;8:05 AM PST - Peer-to-Peer Panel: Managing cloud costs right now w/ Joseph Machado, Carlos Costa, Vikas Ranjan, Mike Fuller, and Mike Mooney&lt;/li&gt;\n&lt;li&gt;10:25 AM PST - Walmart&amp;#39;s self-service metadata-driven data loader framework with Manimuthu Aayyannan and Subramanya Mulgund&lt;/li&gt;\n&lt;li&gt;12:10 PM PST - Is synthetic data useful for data engineers? with Alexander Mikhalev and Matthew Norton&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Live sessions will be available to registrants on-demand post-event, helpful for those in different time zones. Appreciate the support everything we do is community-built.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aQTIs2jcL52LGhuK1NQvonLRIGpjn8QPNEeMwwjWZHQ.jpg?auto=webp&amp;v=enabled&amp;s=bad6e740602f1662394b1fe7dabd8981683aa1fb", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/aQTIs2jcL52LGhuK1NQvonLRIGpjn8QPNEeMwwjWZHQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=161039fc3821f7cd1dfa39f0585f770c15bc946a", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/aQTIs2jcL52LGhuK1NQvonLRIGpjn8QPNEeMwwjWZHQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73294167473cedd820bcad18a90c58650e4e224d", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/aQTIs2jcL52LGhuK1NQvonLRIGpjn8QPNEeMwwjWZHQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76fdcab5605a3d9b860f5c97868c51c45dad182d", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/aQTIs2jcL52LGhuK1NQvonLRIGpjn8QPNEeMwwjWZHQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af3928fee515c51d4526f0278a87666374ae09b1", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/aQTIs2jcL52LGhuK1NQvonLRIGpjn8QPNEeMwwjWZHQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=275fa4eb875cbf9ca0394906f24d080551eabb32", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/aQTIs2jcL52LGhuK1NQvonLRIGpjn8QPNEeMwwjWZHQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58ace0884f5f5330ea81fc7e4ec2429ab9c22d64", "width": 1080, "height": 1080}], "variants": {}, "id": "bgiUBgCfRhBtLAYa6NU8eNVDv2Bm8-xV4rWU9l-rDkI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12kxvfs", "is_robot_indexable": true, "report_reasons": null, "author": "hesanastronaut", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kxvfs/peer_sessions_at_data_stack_summit_attendance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kxvfs/peer_sessions_at_data_stack_summit_attendance/", "subreddit_subscribers": 98854, "created_utc": 1681409343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "ETL can be one of the most expensive costs of data engineering for data warehousing.  Today, Databricks announced they were able to perform the typical ETL of an EDW, with all the transformations and rules, at breakneck speeds, and cheap cost.  Would love your thoughts on this, and can you try it out for yourselves and let us know what you think!  \n\n&amp;#x200B;\n\n[https://www.databricks.com/blog/2023/04/14/how-we-performed-etl-one-billion-records-under-1-delta-live-tables.html](https://www.databricks.com/blog/2023/04/14/how-we-performed-etl-one-billion-records-under-1-delta-live-tables.html)\n\n&amp;#x200B;\n\nDirect link to Repo to Repro: [https://github.com/shannon-barrow/databricks-tpc-di](https://github.com/shannon-barrow/databricks-tpc-di)", "author_fullname": "t2_8ke8s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL 1 Billion rows for less than $1 with Delta Lives Tables on Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12lx0mt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681478295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ETL can be one of the most expensive costs of data engineering for data warehousing.  Today, Databricks announced they were able to perform the typical ETL of an EDW, with all the transformations and rules, at breakneck speeds, and cheap cost.  Would love your thoughts on this, and can you try it out for yourselves and let us know what you think!  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.databricks.com/blog/2023/04/14/how-we-performed-etl-one-billion-records-under-1-delta-live-tables.html\"&gt;https://www.databricks.com/blog/2023/04/14/how-we-performed-etl-one-billion-records-under-1-delta-live-tables.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Direct link to Repo to Repro: &lt;a href=\"https://github.com/shannon-barrow/databricks-tpc-di\"&gt;https://github.com/shannon-barrow/databricks-tpc-di&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?auto=webp&amp;v=enabled&amp;s=15e7319434e1e103352a37e7fabfbd9456a168ef", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1176850e76031e71bb122f9c353101bd7abe6bf", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=429d70d1e08de4ce9c49426ac4caa101f4c3e264", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29cde5f1616959571c9b58b8c1c1900201c77f7e", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83b58b543aa8701ba0a87a3198960697d53ff22c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfd2d8ab37cf854034f841dea22a655dc91a5f3b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47ceb6115a4ccc0e21696967727505ec48f78f37", "width": 1080, "height": 567}], "variants": {}, "id": "RDPFo3n-9ZSpTUT0k9sCNnHc7tSD0wBu2TyDFfITIDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12lx0mt", "is_robot_indexable": true, "report_reasons": null, "author": "letmebefrankwithyou", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12lx0mt/etl_1_billion_rows_for_less_than_1_with_delta/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lx0mt/etl_1_billion_rows_for_less_than_1_with_delta/", "subreddit_subscribers": 98854, "created_utc": 1681478295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just a bit of user research\n\n[View Poll](https://www.reddit.com/poll/12lwprj)", "author_fullname": "t2_txvugrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those of you with Lakehouse Architectures, how do you handle duplicate records?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12lwprj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681477676.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just a bit of user research&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/12lwprj\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Company", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12lwprj", "is_robot_indexable": true, "report_reasons": null, "author": "prequel_co", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1681736876996, "options": [{"text": "Architecture never allows for duplicate records", "id": "22556891"}, {"text": "Upserts via table format like Iceberg, Delta, Hudi, etc", "id": "22556892"}, {"text": "Deduplicate at query time", "id": "22556893"}, {"text": "Other (elaborate in comments)", "id": "22556894"}, {"text": "No answer, just want to see results", "id": "22556895"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 61, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12lwprj/for_those_of_you_with_lakehouse_architectures_how/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/12lwprj/for_those_of_you_with_lakehouse_architectures_how/", "subreddit_subscribers": 98854, "created_utc": 1681477676.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im currently a uni student and realised that DE was not an entry level role out of college, and instead something you transition into. So I wanted to know if the DE knowledge I've accumulated would make me competitive in getting into a DA role by any chance? By knowledge I mean like data warehousing, ETL, data modelling and some experience with using ETL tools?", "author_fullname": "t2_76fvluuq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would DE skills be somewhat useful in a DA role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lkpdd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681448534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im currently a uni student and realised that DE was not an entry level role out of college, and instead something you transition into. So I wanted to know if the DE knowledge I&amp;#39;ve accumulated would make me competitive in getting into a DA role by any chance? By knowledge I mean like data warehousing, ETL, data modelling and some experience with using ETL tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12lkpdd", "is_robot_indexable": true, "report_reasons": null, "author": "notGaruda1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12lkpdd/would_de_skills_be_somewhat_useful_in_a_da_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lkpdd/would_de_skills_be_somewhat_useful_in_a_da_role/", "subreddit_subscribers": 98854, "created_utc": 1681448534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im looking for either an open source tool or a relatively cheap one that could do data profiling, and help support applying DQ rules on data pipelines. Environment runs on  databricks.  Currently we dont have any profiling capabilities, nor an easy way to define and implement DQ rules.", "author_fullname": "t2_imia197u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any open source data quality tools ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12lxg86", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681479207.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im looking for either an open source tool or a relatively cheap one that could do data profiling, and help support applying DQ rules on data pipelines. Environment runs on  databricks.  Currently we dont have any profiling capabilities, nor an easy way to define and implement DQ rules.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12lxg86", "is_robot_indexable": true, "report_reasons": null, "author": "Pty_Rick", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12lxg86/are_there_any_open_source_data_quality_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lxg86/are_there_any_open_source_data_quality_tools/", "subreddit_subscribers": 98854, "created_utc": 1681479207.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello:  \nMy employer has hired a data engineer/architect. We went over his grand design to replace the firms litany of legacy applications that handle everything from real-time transaction data to automated report-making, to email notifications, to FTP, to orchestration. Overall probably 10-14 different applications. Our architect's design is as follows:  \n\n\n* Azure Data Factory to handle literally everything.\n* Logic Apps to handle email notifications, since that's the one thing ADF can't do.\n* A SQL database. \n* Power BI Paginated for reporting.\n\nThat's it. That's all the tools we shall ever require. I think this stems from a phobia of coding, some of his behavior and opinions corroborate with this.   \n\n\nI'm writing to ask you all: is Azure Data Factory really that good? Is it typical \"best practice\" \"industry standard\" to not involve any amount of code? What's your thoughts on low-code? Personally, I think there's some glaring issues with the architecture, but I want to see if I'm missing something not-obvious before opening my mouth.\n\nThanks!", "author_fullname": "t2_lwmkqytr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer is terrified of programming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lobgb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681457482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello:&lt;br/&gt;\nMy employer has hired a data engineer/architect. We went over his grand design to replace the firms litany of legacy applications that handle everything from real-time transaction data to automated report-making, to email notifications, to FTP, to orchestration. Overall probably 10-14 different applications. Our architect&amp;#39;s design is as follows:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Azure Data Factory to handle literally everything.&lt;/li&gt;\n&lt;li&gt;Logic Apps to handle email notifications, since that&amp;#39;s the one thing ADF can&amp;#39;t do.&lt;/li&gt;\n&lt;li&gt;A SQL database. &lt;/li&gt;\n&lt;li&gt;Power BI Paginated for reporting.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;That&amp;#39;s it. That&amp;#39;s all the tools we shall ever require. I think this stems from a phobia of coding, some of his behavior and opinions corroborate with this.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m writing to ask you all: is Azure Data Factory really that good? Is it typical &amp;quot;best practice&amp;quot; &amp;quot;industry standard&amp;quot; to not involve any amount of code? What&amp;#39;s your thoughts on low-code? Personally, I think there&amp;#39;s some glaring issues with the architecture, but I want to see if I&amp;#39;m missing something not-obvious before opening my mouth.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12lobgb", "is_robot_indexable": true, "report_reasons": null, "author": "c0ntrap0sitive", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12lobgb/data_engineer_is_terrified_of_programming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lobgb/data_engineer_is_terrified_of_programming/", "subreddit_subscribers": 98854, "created_utc": 1681457482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am at the early stage in my career, currently looking for a data engineer role, and I am not sure what I should call my first job in my resume.\n\nIn this role I stayed for a year out of college, I primarily (maybe 70% of the time) wrote lots of queries to deliver raw excel files (sometimes very minor visualizations - but never did \u2018analysis\u2019) to all kind of different teams. Our team name was DevOps but I think it was close to what DBA team looks like. I was tasked with auditing/db health monitoring/backup or batch maintenance/etc, those are what I can think of now. (30% of the time)\n\nMy role was called as something like data specialist, but I don\u2019t think that\u2019s a common name. Should I list myself as DBA? What would you say my role was?", "author_fullname": "t2_5pafg8ca6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you call my first job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lmmjx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681453225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am at the early stage in my career, currently looking for a data engineer role, and I am not sure what I should call my first job in my resume.&lt;/p&gt;\n\n&lt;p&gt;In this role I stayed for a year out of college, I primarily (maybe 70% of the time) wrote lots of queries to deliver raw excel files (sometimes very minor visualizations - but never did \u2018analysis\u2019) to all kind of different teams. Our team name was DevOps but I think it was close to what DBA team looks like. I was tasked with auditing/db health monitoring/backup or batch maintenance/etc, those are what I can think of now. (30% of the time)&lt;/p&gt;\n\n&lt;p&gt;My role was called as something like data specialist, but I don\u2019t think that\u2019s a common name. Should I list myself as DBA? What would you say my role was?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12lmmjx", "is_robot_indexable": true, "report_reasons": null, "author": "TaxGreat2308", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12lmmjx/what_would_you_call_my_first_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lmmjx/what_would_you_call_my_first_job/", "subreddit_subscribers": 98854, "created_utc": 1681453225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As stated in the title, there is the need to handle image data in a new project. There are 3 termo-cameras that acquire a frame 640x480 for the visual information and another layer 640x480 for the termo information. Each pixel of the visual information takes 3/4 bytes (I suppose, 3 for the RGB, 1 for the alpha) and the termo information takes 3 bytes (I suppose, as there is a sensitivity of 35mK and the possible range of acquisition is around 800 C\u00b0).\n\nFrom my calculation the worst case scenario of the size of each image, in MB,  is as follows:\n\nVisual: (640x480x4)/(1024x1024) = 1.17 MB\n\nTermo: (640x480x3)/(1024x1024) =  0.88 MB\n\nTotal = 2.05 MB\n\nThe worst-case sampling rate to date is 1Hz as the termo dynamics of the process is slow and the visual information is not exploited for the running algorithms. Taking into account this condition, and the will to save the raw image information, there would be a stream of data as follows:\n\n2.05 \\[MB/camera\\] x 3 \\[camera\\] = 6.15 MB/s\n\nThere is the need to think about an architecture to store these images, because we want to save interesting data. The process could last up to five days, which brings to:\n\n6.15 \\[MB/s\\] x 3600 \\[s/hour\\] x 24 \\[hour/day\\] x 5 \\[day\\] =  2595 \\[GB/process\\] = 2.53 \\[TB/process\\]\n\nWhat would be the best architecture to handle this stream of data and the storage need? In the future we might also access this data, but I think for post-processing analysis, e.g. the access would be sporadic just to perform some data analysis by data scientists or review the process data. Also at the moment, there will be also a edge computing, dedicated to process the acquired frames on-line in order to analysise the process.\n\nThis is my first project with image data, feel free to tell me anything, I'm exploring.", "author_fullname": "t2_vlk568vv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Review needed: first project with data images", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lmjex", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681453004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As stated in the title, there is the need to handle image data in a new project. There are 3 termo-cameras that acquire a frame 640x480 for the visual information and another layer 640x480 for the termo information. Each pixel of the visual information takes 3/4 bytes (I suppose, 3 for the RGB, 1 for the alpha) and the termo information takes 3 bytes (I suppose, as there is a sensitivity of 35mK and the possible range of acquisition is around 800 C\u00b0).&lt;/p&gt;\n\n&lt;p&gt;From my calculation the worst case scenario of the size of each image, in MB,  is as follows:&lt;/p&gt;\n\n&lt;p&gt;Visual: (640x480x4)/(1024x1024) = 1.17 MB&lt;/p&gt;\n\n&lt;p&gt;Termo: (640x480x3)/(1024x1024) =  0.88 MB&lt;/p&gt;\n\n&lt;p&gt;Total = 2.05 MB&lt;/p&gt;\n\n&lt;p&gt;The worst-case sampling rate to date is 1Hz as the termo dynamics of the process is slow and the visual information is not exploited for the running algorithms. Taking into account this condition, and the will to save the raw image information, there would be a stream of data as follows:&lt;/p&gt;\n\n&lt;p&gt;2.05 [MB/camera] x 3 [camera] = 6.15 MB/s&lt;/p&gt;\n\n&lt;p&gt;There is the need to think about an architecture to store these images, because we want to save interesting data. The process could last up to five days, which brings to:&lt;/p&gt;\n\n&lt;p&gt;6.15 [MB/s] x 3600 [s/hour] x 24 [hour/day] x 5 [day] =  2595 [GB/process] = 2.53 [TB/process]&lt;/p&gt;\n\n&lt;p&gt;What would be the best architecture to handle this stream of data and the storage need? In the future we might also access this data, but I think for post-processing analysis, e.g. the access would be sporadic just to perform some data analysis by data scientists or review the process data. Also at the moment, there will be also a edge computing, dedicated to process the acquired frames on-line in order to analysise the process.&lt;/p&gt;\n\n&lt;p&gt;This is my first project with image data, feel free to tell me anything, I&amp;#39;m exploring.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12lmjex", "is_robot_indexable": true, "report_reasons": null, "author": "Plenty-Button8465", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12lmjex/review_needed_first_project_with_data_images/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lmjex/review_needed_first_project_with_data_images/", "subreddit_subscribers": 98854, "created_utc": 1681453004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm deciding on the best tool to grab Jira data. I was originally going to use the Jira api and clean up the data myself but I read that airbyte Jira connector is very useful. \n\nUnfortunately I have been unable to connect it, I keep getting authentication error. I saw some comments on other forums that mentioned the connector only works for Jira cloud not self hosted. Is this true? \n\nIf so is it better to make a custom connector in airbyte or just go with my original plan of grabbing the data via Jira api?", "author_fullname": "t2_cyr5y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is airbyte Jira connector only for SaaS version of jira?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ld8fw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681432553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m deciding on the best tool to grab Jira data. I was originally going to use the Jira api and clean up the data myself but I read that airbyte Jira connector is very useful. &lt;/p&gt;\n\n&lt;p&gt;Unfortunately I have been unable to connect it, I keep getting authentication error. I saw some comments on other forums that mentioned the connector only works for Jira cloud not self hosted. Is this true? &lt;/p&gt;\n\n&lt;p&gt;If so is it better to make a custom connector in airbyte or just go with my original plan of grabbing the data via Jira api?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ld8fw", "is_robot_indexable": true, "report_reasons": null, "author": "bigYman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ld8fw/is_airbyte_jira_connector_only_for_saas_version/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ld8fw/is_airbyte_jira_connector_only_for_saas_version/", "subreddit_subscribers": 98854, "created_utc": 1681432553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How to use Chat GPT or suggest any other online free tool for query tuning.\n\nI have data analysts writing a bunch of queries that uses same set tables of tables over and over again in left joins and CTEs with full table scans \ud83d\ude35\u200d\ud83d\udcab\ud83e\udd74", "author_fullname": "t2_f2obp4el", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "T-Sql Query Tuning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12l8ryw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681424647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How to use Chat GPT or suggest any other online free tool for query tuning.&lt;/p&gt;\n\n&lt;p&gt;I have data analysts writing a bunch of queries that uses same set tables of tables over and over again in left joins and CTEs with full table scans \ud83d\ude35\u200d\ud83d\udcab\ud83e\udd74&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12l8ryw", "is_robot_indexable": true, "report_reasons": null, "author": "InterestingDot8089", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12l8ryw/tsql_query_tuning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12l8ryw/tsql_query_tuning/", "subreddit_subscribers": 98854, "created_utc": 1681424647.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone used https://metaphor.io/ ?\n\nI\u2019m looking for feedback against open source metadata tools like Datahub, Open Metadata etc", "author_fullname": "t2_p0rsp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Metaphor?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kys2r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681410862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone used &lt;a href=\"https://metaphor.io/\"&gt;https://metaphor.io/&lt;/a&gt; ?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking for feedback against open source metadata tools like Datahub, Open Metadata etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12kys2r", "is_robot_indexable": true, "report_reasons": null, "author": "darrenhaken", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kys2r/has_anyone_used_metaphor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kys2r/has_anyone_used_metaphor/", "subreddit_subscribers": 98854, "created_utc": 1681410862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Reddit! Last week we made the codebase for product 100% open source. This week we shipped a dashboard to manage connectors, as well as integrations with Google Drive, Zendesk, Notion and Confluence. This means Sidekick is now the fastest way to sync data from these tools to a vector database.\n\nWhy is this important? For developers building LLM apps, data integrations are often the least interesting and most time consuming part of the process. For those that don\u2019t want to roll their own ETL, Sidekick is an opinionated tool that lets them get an API endpoint to run semantic searches or generative Q&amp;A over their own data in 5 minutes. In a future release, Sidekick will also handle data synchronization via polling/webhooks.\n\nWe use Weaviate\u2019s vector database for the cloud version but plan to be vector database agonistic.\n\nYou can try it here: [https://app.getsidekick.ai/sign-in](https://app.getsidekick.ai/sign-in)\n\nIf you don\u2019t want to share your email, you can use these test credentials: [founders@getsidekick.ai](mailto:founders@getsidekick.ai) / sidekickisawesome\n\nHere's a demo video showing how it works with Zendesk: [https://youtu.be/hH09kWi6Si0](https://youtu.be/hH09kWi6Si0)\n\nGithub link: [https://github.com/ai-sidekick/sidekick](https://github.com/ai-sidekick/sidekick)", "author_fullname": "t2_xle6lsj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sync data from SaaS tools to a vector database automatically", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kwame", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681406302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Reddit! Last week we made the codebase for product 100% open source. This week we shipped a dashboard to manage connectors, as well as integrations with Google Drive, Zendesk, Notion and Confluence. This means Sidekick is now the fastest way to sync data from these tools to a vector database.&lt;/p&gt;\n\n&lt;p&gt;Why is this important? For developers building LLM apps, data integrations are often the least interesting and most time consuming part of the process. For those that don\u2019t want to roll their own ETL, Sidekick is an opinionated tool that lets them get an API endpoint to run semantic searches or generative Q&amp;amp;A over their own data in 5 minutes. In a future release, Sidekick will also handle data synchronization via polling/webhooks.&lt;/p&gt;\n\n&lt;p&gt;We use Weaviate\u2019s vector database for the cloud version but plan to be vector database agonistic.&lt;/p&gt;\n\n&lt;p&gt;You can try it here: &lt;a href=\"https://app.getsidekick.ai/sign-in\"&gt;https://app.getsidekick.ai/sign-in&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you don\u2019t want to share your email, you can use these test credentials: [&lt;a href=\"mailto:founders@getsidekick.ai\"&gt;founders@getsidekick.ai&lt;/a&gt;](mailto:&lt;a href=\"mailto:founders@getsidekick.ai\"&gt;founders@getsidekick.ai&lt;/a&gt;) / sidekickisawesome&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a demo video showing how it works with Zendesk: &lt;a href=\"https://youtu.be/hH09kWi6Si0\"&gt;https://youtu.be/hH09kWi6Si0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Github link: &lt;a href=\"https://github.com/ai-sidekick/sidekick\"&gt;https://github.com/ai-sidekick/sidekick&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "12kwame", "is_robot_indexable": true, "report_reasons": null, "author": "Single_Tomato_6233", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kwame/sync_data_from_saas_tools_to_a_vector_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kwame/sync_data_from_saas_tools_to_a_vector_database/", "subreddit_subscribers": 98854, "created_utc": 1681406302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys - I got a question for you experts out there. I was trying to build a thesis on Modern Data Stack and I wanted to understand why does Snowflake-like products get big (in the data warehousing space) when Google, Amazon, Microsoft all have similar offerings available and all of them have one less challenge to face i.e. the distribution.\n\nAlso, now that Snowflake, Bigquery et al have made their own niche for so many years, why do new companies like Firebolt (an Israeli unicorn, started in 2019) come up every now and then and get so much funding?\n\nCan anyone please explain. TIA", "author_fullname": "t2_a4d2j3fh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Traditional Data tools vs new start-ups that are getting funded", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lvapt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681474642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys - I got a question for you experts out there. I was trying to build a thesis on Modern Data Stack and I wanted to understand why does Snowflake-like products get big (in the data warehousing space) when Google, Amazon, Microsoft all have similar offerings available and all of them have one less challenge to face i.e. the distribution.&lt;/p&gt;\n\n&lt;p&gt;Also, now that Snowflake, Bigquery et al have made their own niche for so many years, why do new companies like Firebolt (an Israeli unicorn, started in 2019) come up every now and then and get so much funding?&lt;/p&gt;\n\n&lt;p&gt;Can anyone please explain. TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12lvapt", "is_robot_indexable": true, "report_reasons": null, "author": "Living-Nobody-2727", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12lvapt/traditional_data_tools_vs_new_startups_that_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lvapt/traditional_data_tools_vs_new_startups_that_are/", "subreddit_subscribers": 98854, "created_utc": 1681474642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically have a group of a few experienced data engineers and we were looking for contracts to setup as side work (with a few of us, can handle work with just about 10 hours commitment each in addition to day jobs).  \n\n\nAnyone know a good place to look for small data engineering contracts?  Thanks in advance!", "author_fullname": "t2_94vh7oax8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good places to find contracts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12l18c0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681415169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically have a group of a few experienced data engineers and we were looking for contracts to setup as side work (with a few of us, can handle work with just about 10 hours commitment each in addition to day jobs).  &lt;/p&gt;\n\n&lt;p&gt;Anyone know a good place to look for small data engineering contracts?  Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12l18c0", "is_robot_indexable": true, "report_reasons": null, "author": "a_library_socialist", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12l18c0/good_places_to_find_contracts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12l18c0/good_places_to_find_contracts/", "subreddit_subscribers": 98854, "created_utc": 1681415169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I'm having trouble finding a solution to implement an incremental loading process from multiple source tables that join on each other to  a target table. I was wondering if anyone has had to do something similar and has any ideas they could share. I'm using databricks as a platform and these are delta tables I am working with.\n\n&amp;#x200B;\n\nExample:\n\nLarge Table: basicStats with columns (nameID,name,fatherID)\n\nLarge Table: moreStats with columns (nameID,height)\n\n&amp;#x200B;\n\nLooking to implement incremental loading on a new table:\n\nselect sha1(basicStats.nameID) nameHashKey,\n\n[basicStats.name](https://basicStats.name) name,\n\nbasicStatsFather[.name](https://father.name) as fatherName,\n\nmoreStats.height as height\n\nfrom basicStats join moreStats\n\non [basicStats.nameID = moreStats.name](https://Table1.name=Table2.name)ID\n\njoin basicStats as basicStatsFather\n\non basicStats.nameID = basicStatsFather.fatherID", "author_fullname": "t2_6pedjzz0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incremental loading to a table that is joined on multiple tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kzgi4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681453590.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681412068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I&amp;#39;m having trouble finding a solution to implement an incremental loading process from multiple source tables that join on each other to  a target table. I was wondering if anyone has had to do something similar and has any ideas they could share. I&amp;#39;m using databricks as a platform and these are delta tables I am working with.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Example:&lt;/p&gt;\n\n&lt;p&gt;Large Table: basicStats with columns (nameID,name,fatherID)&lt;/p&gt;\n\n&lt;p&gt;Large Table: moreStats with columns (nameID,height)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Looking to implement incremental loading on a new table:&lt;/p&gt;\n\n&lt;p&gt;select sha1(basicStats.nameID) nameHashKey,&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://basicStats.name\"&gt;basicStats.name&lt;/a&gt; name,&lt;/p&gt;\n\n&lt;p&gt;basicStatsFather&lt;a href=\"https://father.name\"&gt;.name&lt;/a&gt; as fatherName,&lt;/p&gt;\n\n&lt;p&gt;moreStats.height as height&lt;/p&gt;\n\n&lt;p&gt;from basicStats join moreStats&lt;/p&gt;\n\n&lt;p&gt;on &lt;a href=\"https://Table1.name=Table2.name\"&gt;basicStats.nameID = moreStats.name&lt;/a&gt;ID&lt;/p&gt;\n\n&lt;p&gt;join basicStats as basicStatsFather&lt;/p&gt;\n\n&lt;p&gt;on basicStats.nameID = basicStatsFather.fatherID&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12kzgi4", "is_robot_indexable": true, "report_reasons": null, "author": "Simp4ABGs", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kzgi4/incremental_loading_to_a_table_that_is_joined_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kzgi4/incremental_loading_to_a_table_that_is_joined_on/", "subreddit_subscribers": 98854, "created_utc": 1681412068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Materialized Views", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 54, "top_awarded_type": null, "hide_score": false, "name": "t3_12kr6rl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4fJa4Lp9bvvbQMIT3bAjI_0_cOEE2I92xxRRtCJZu-E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681396307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://open.substack.com/pub/hubertdulay/p/materialized-views?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DDV9KsdJ1CFEbKqBYqQZ3sa48aMHf20q6oAXWvgXc9c.jpg?auto=webp&amp;v=enabled&amp;s=c9781f62089f93045d26b86b18675af56677e8ab", "width": 1200, "height": 470}, "resolutions": [{"url": "https://external-preview.redd.it/DDV9KsdJ1CFEbKqBYqQZ3sa48aMHf20q6oAXWvgXc9c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9404ada6e33e780c5177133e59cb3b108f164739", "width": 108, "height": 42}, {"url": "https://external-preview.redd.it/DDV9KsdJ1CFEbKqBYqQZ3sa48aMHf20q6oAXWvgXc9c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb1204086920c148bf825605d6dd8a52d86d583b", "width": 216, "height": 84}, {"url": "https://external-preview.redd.it/DDV9KsdJ1CFEbKqBYqQZ3sa48aMHf20q6oAXWvgXc9c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca4d2f15014088768e97b3bce7a223f1fae23ddc", "width": 320, "height": 125}, {"url": "https://external-preview.redd.it/DDV9KsdJ1CFEbKqBYqQZ3sa48aMHf20q6oAXWvgXc9c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efa610d35bcdfda54fd56d5073d6929ec277809f", "width": 640, "height": 250}, {"url": "https://external-preview.redd.it/DDV9KsdJ1CFEbKqBYqQZ3sa48aMHf20q6oAXWvgXc9c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98e39697f6354f515757abf3772093f0fdaaf10e", "width": 960, "height": 376}, {"url": "https://external-preview.redd.it/DDV9KsdJ1CFEbKqBYqQZ3sa48aMHf20q6oAXWvgXc9c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d5feca6e2e80e9638df8f0b5ba3c8b1e59ae9463", "width": 1080, "height": 423}], "variants": {}, "id": "RSIDBhxWxKd_v4cQtbut7ua8NlCrEP6UoRGz73GSCQk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12kr6rl", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kr6rl/materialized_views/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.substack.com/pub/hubertdulay/p/materialized-views?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "subreddit_subscribers": 98854, "created_utc": 1681396307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a product review dataset that is a json file. Each product review is its own dictionary, So it's basically a list of dictionaries. I'm currently reading this thing as a for-loop. Many of these reviews do not have the same set of keys. But all have an overlapping set of keys in common: review\\_id, reviewer\\_id, product\\_id, review\\_tags (tags for the review, basically a list of strings), and a review\\_rating float. So I first have 4 empty lists for each key, then I for-loop through the dataset, and populate the lists respectively with their values. Then I make a pandas DataFrame and add them as columns.\n\nNow the actual problem:\n\nSome of these product reviews also have images of the product with it (some products will even have more than 1 image). I'd like to incorporate this picture info if possible. So there's occasionally an extra key called \"image\", which is a string value containing a url(s) to these pictures.\n\n* and so for each url, I have to use the python request package to get the image from the url.\n* Then I feed it to a pre-trained convolutional neural network provided on python through keras (VGGNET) that is able to take in the image, and output a list of the top N most likely text labels of things recognized in the image. And then I append these strings straight onto the review\\_tags string before appending the whole review\\_tags to the list.\n   * There's actually a lot more things going on here. First, since there could be more than 1 url, I'd have to str-split on possible commas in case there's 2+ urls (luckily I won't need an if-statement if there's 1 vs 2+ urls because str-split still works if there's no comma to be found). Then, I need a Try/except statement if the url is broken. And finally the image has to be resized to a shape that the convnet was originally trained on.\n   * Another thing is that its a bit costly to just make the convnet predict things one-by-one. It would be marginally faster to divide all the images into batches, so you could feed the batches into the convnet all at once, and output the top N predicted labels of the batches of images all at once. But, let's just keep things simple and save that idea for later.\n\nThen in the final table, I plan to do 2 separate tables that are groupby's of reviewer\\_id and product\\_id, in terms of AVG(review\\_rating) and GROUP\\_CONCAT(reviews\\_tag)\n\nIf it wasn't for this stuff with the pictures, I guess my answer to whether or not I should for-loop would to be simpler.", "author_fullname": "t2_w594l9jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is for-looping my best option here?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12l5d4u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681421866.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681420871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a product review dataset that is a json file. Each product review is its own dictionary, So it&amp;#39;s basically a list of dictionaries. I&amp;#39;m currently reading this thing as a for-loop. Many of these reviews do not have the same set of keys. But all have an overlapping set of keys in common: review_id, reviewer_id, product_id, review_tags (tags for the review, basically a list of strings), and a review_rating float. So I first have 4 empty lists for each key, then I for-loop through the dataset, and populate the lists respectively with their values. Then I make a pandas DataFrame and add them as columns.&lt;/p&gt;\n\n&lt;p&gt;Now the actual problem:&lt;/p&gt;\n\n&lt;p&gt;Some of these product reviews also have images of the product with it (some products will even have more than 1 image). I&amp;#39;d like to incorporate this picture info if possible. So there&amp;#39;s occasionally an extra key called &amp;quot;image&amp;quot;, which is a string value containing a url(s) to these pictures.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;and so for each url, I have to use the python request package to get the image from the url.&lt;/li&gt;\n&lt;li&gt;Then I feed it to a pre-trained convolutional neural network provided on python through keras (VGGNET) that is able to take in the image, and output a list of the top N most likely text labels of things recognized in the image. And then I append these strings straight onto the review_tags string before appending the whole review_tags to the list.\n\n&lt;ul&gt;\n&lt;li&gt;There&amp;#39;s actually a lot more things going on here. First, since there could be more than 1 url, I&amp;#39;d have to str-split on possible commas in case there&amp;#39;s 2+ urls (luckily I won&amp;#39;t need an if-statement if there&amp;#39;s 1 vs 2+ urls because str-split still works if there&amp;#39;s no comma to be found). Then, I need a Try/except statement if the url is broken. And finally the image has to be resized to a shape that the convnet was originally trained on.&lt;/li&gt;\n&lt;li&gt;Another thing is that its a bit costly to just make the convnet predict things one-by-one. It would be marginally faster to divide all the images into batches, so you could feed the batches into the convnet all at once, and output the top N predicted labels of the batches of images all at once. But, let&amp;#39;s just keep things simple and save that idea for later.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then in the final table, I plan to do 2 separate tables that are groupby&amp;#39;s of reviewer_id and product_id, in terms of AVG(review_rating) and GROUP_CONCAT(reviews_tag)&lt;/p&gt;\n\n&lt;p&gt;If it wasn&amp;#39;t for this stuff with the pictures, I guess my answer to whether or not I should for-loop would to be simpler.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12l5d4u", "is_robot_indexable": true, "report_reasons": null, "author": "Lockonon3", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12l5d4u/is_forlooping_my_best_option_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12l5d4u/is_forlooping_my_best_option_here/", "subreddit_subscribers": 98854, "created_utc": 1681420871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "tl:dr; \n\n* **Status:** Ongoing survey, [participate anonymously here](https://rudderstack.com/survey)\n* **Results:** will update this post with results once it is finished\n\nHey folks, I see many useful surveys here on r/dataengineering. Although they covered specific topics such as database, I didn't find anything in broader context relvant for every data emgineer covering overall modern data stack and customer data management. So this anonymous survey should be useful for everyone here. Organized by Data Engineering Weekly newsletter and RudderStack. I will share the survey results soon on this post. Here's the [survey link](https://rudderstack.com/survey). Appreciate your help and expertise.", "author_fullname": "t2_cbh6ollo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The state of data engineering 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kult0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681403051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;tl:dr; &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Status:&lt;/strong&gt; Ongoing survey, &lt;a href=\"https://rudderstack.com/survey\"&gt;participate anonymously here&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Results:&lt;/strong&gt; will update this post with results once it is finished&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Hey folks, I see many useful surveys here on &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;. Although they covered specific topics such as database, I didn&amp;#39;t find anything in broader context relvant for every data emgineer covering overall modern data stack and customer data management. So this anonymous survey should be useful for everyone here. Organized by Data Engineering Weekly newsletter and RudderStack. I will share the survey results soon on this post. Here&amp;#39;s the &lt;a href=\"https://rudderstack.com/survey\"&gt;survey link&lt;/a&gt;. Appreciate your help and expertise.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vO8vLBxK29SV-uuuP1ppnZeDm_NPzyazL6ceh_OWM9s.jpg?auto=webp&amp;v=enabled&amp;s=8f51f5248db45a6f6e9ff83bcabe87210600327f", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/vO8vLBxK29SV-uuuP1ppnZeDm_NPzyazL6ceh_OWM9s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=212a77180bef2baef66563c0d22033707a11f3ae", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/vO8vLBxK29SV-uuuP1ppnZeDm_NPzyazL6ceh_OWM9s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c837e55233f6f218aa2c485de6bc0a305921764", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/vO8vLBxK29SV-uuuP1ppnZeDm_NPzyazL6ceh_OWM9s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=261aa0a9dc3c53a7f12c429c1ca06ec77bbb1ac9", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/vO8vLBxK29SV-uuuP1ppnZeDm_NPzyazL6ceh_OWM9s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e37ab2d3763b68f3087eb4bf48a49089632a33c", "width": 640, "height": 336}], "variants": {}, "id": "ScU_cRjDcMj0WWWXQBa_pYwa-ynuyq9W04OLJLN9y2Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12kult0", "is_robot_indexable": true, "report_reasons": null, "author": "ephemeral404", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12kult0/the_state_of_data_engineering_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12kult0/the_state_of_data_engineering_2023/", "subreddit_subscribers": 98854, "created_utc": 1681403051.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}