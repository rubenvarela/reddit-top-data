{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Long story short, I got hired as a consultant 5 months ago, but the project I was supposed to do was delayed several months. I have been doing some tasks (develop some scripts in python, NoSQL, nlp and a bit of ML), but I think I am wasting my time, since I am literally doing nothing and it is really frustrating.\n\nI have 3+ years of experience in this field, and I feel stuck. I do like doing online courses (I have done a lot from coursera, including specializations such as DL or NLP) but I am not motivated to do any of them right now (even though I want to learn about cloud and big data tools). \n\nThe company is trying to find new projects for me, I will give them that, but it is hard for me to spend time doing nothing and learning nothing either. At least my position is full remote, but I moved from my old company in order to face new projects and learn a lot, and it is not happening. The company is fine, I feel comfortable with almost everything but not with the zero workload.\n\nHave you ever been in this situation? I would consider moving to another company, but I don't like the idea of having in my CV a 5 month position honestly.", "author_fullname": "t2_2lc0syow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have been in this company for 5 months, and have done nothing relevant yet due to delays, what should I do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kjrc2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 151, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 151, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681380657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, I got hired as a consultant 5 months ago, but the project I was supposed to do was delayed several months. I have been doing some tasks (develop some scripts in python, NoSQL, nlp and a bit of ML), but I think I am wasting my time, since I am literally doing nothing and it is really frustrating.&lt;/p&gt;\n\n&lt;p&gt;I have 3+ years of experience in this field, and I feel stuck. I do like doing online courses (I have done a lot from coursera, including specializations such as DL or NLP) but I am not motivated to do any of them right now (even though I want to learn about cloud and big data tools). &lt;/p&gt;\n\n&lt;p&gt;The company is trying to find new projects for me, I will give them that, but it is hard for me to spend time doing nothing and learning nothing either. At least my position is full remote, but I moved from my old company in order to face new projects and learn a lot, and it is not happening. The company is fine, I feel comfortable with almost everything but not with the zero workload.&lt;/p&gt;\n\n&lt;p&gt;Have you ever been in this situation? I would consider moving to another company, but I don&amp;#39;t like the idea of having in my CV a 5 month position honestly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kjrc2", "is_robot_indexable": true, "report_reasons": null, "author": "Cassegrain07", "discussion_type": null, "num_comments": 57, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kjrc2/i_have_been_in_this_company_for_5_months_and_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kjrc2/i_have_been_in_this_company_for_5_months_and_have/", "subreddit_subscribers": 872429, "created_utc": 1681380657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Like many others I got laid off in December. Been struggling finding work. Interviews have slowed much since q1 and starting to get worried. Anyone have any luck finding a job? Any tips?", "author_fullname": "t2_8o0eldke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone else struggling to find work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kmpif", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 83, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 83, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681387415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Like many others I got laid off in December. Been struggling finding work. Interviews have slowed much since q1 and starting to get worried. Anyone have any luck finding a job? Any tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kmpif", "is_robot_indexable": true, "report_reasons": null, "author": "djaycat", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kmpif/anyone_else_struggling_to_find_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kmpif/anyone_else_struggling_to_find_work/", "subreddit_subscribers": 872429, "created_utc": 1681387415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So, I work for a very large company in their finance department. I recently got a new role on the data analytics team, and to my surprise, it seems like no one knows anything about data science, analytical methods, or best practices. \n\nA bit about myself, for the past 2 years, I've been teaching myself data science in order to get ahead. In this time, I've become really fluent in python, SQL, VBA, and general concepts such as ETL, wrangling...etc. I've also been able to use a lot of what I've learned in my current role. I'm by no means an expert, but I've been able to make some good progress at work with what I've done so far.\n\nBack to the new role. I had a couple of interviews with my new boss and director, and started describing the ETL process I do for email data. They had never heard of ETL. Beyond that, someone from their team reached out to me later and asked if I could help them find the name for a database in MS SQL. When I asked what type of data they were looking for they sent me a screenshot of the table with db name attached. It seemed as if they didn't understand the difference between a db, server, or table.\n\nI'm excited for the opportunity, but has anyone else been here?", "author_fullname": "t2_4emwju7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've found myself in a very unique situation at work. Has anyone else been here?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12k6j9x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681348028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I work for a very large company in their finance department. I recently got a new role on the data analytics team, and to my surprise, it seems like no one knows anything about data science, analytical methods, or best practices. &lt;/p&gt;\n\n&lt;p&gt;A bit about myself, for the past 2 years, I&amp;#39;ve been teaching myself data science in order to get ahead. In this time, I&amp;#39;ve become really fluent in python, SQL, VBA, and general concepts such as ETL, wrangling...etc. I&amp;#39;ve also been able to use a lot of what I&amp;#39;ve learned in my current role. I&amp;#39;m by no means an expert, but I&amp;#39;ve been able to make some good progress at work with what I&amp;#39;ve done so far.&lt;/p&gt;\n\n&lt;p&gt;Back to the new role. I had a couple of interviews with my new boss and director, and started describing the ETL process I do for email data. They had never heard of ETL. Beyond that, someone from their team reached out to me later and asked if I could help them find the name for a database in MS SQL. When I asked what type of data they were looking for they sent me a screenshot of the table with db name attached. It seemed as if they didn&amp;#39;t understand the difference between a db, server, or table.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m excited for the opportunity, but has anyone else been here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12k6j9x", "is_robot_indexable": true, "report_reasons": null, "author": "kkessler1023", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12k6j9x/ive_found_myself_in_a_very_unique_situation_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12k6j9x/ive_found_myself_in_a_very_unique_situation_at/", "subreddit_subscribers": 872429, "created_utc": 1681348028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm curious to hear your experiences on how the hiring bar has changed, especially for those that have been in the field 5+ years.\n\nFrom a purely anecdotal perspective, it feels that the hiring bar for data scientists has gone up and is all over the place. I might be wrong, but it felt that 5 years ago if you knew A/B testing + jupyter notebooks it was good enough.\n\nDisclaimer: there's no one definitive definition of what a data scientist is, so each company/field will have different criteria. Obviously you can't thoroughly test for everything, sometimes it's just a \"Can you tell me what X is and how it's used?\".\n\nThese are the interview elements where I feel the bar has gone up:\n\n* More leetcode medium, DS/ML coding level is moving closer to SWE. Definitely ran into some leetcode hards. \n* MLE leaning roles will ask for knowledge on how to productize DS projects. Knowledge of AWS and containers is sort of expected.\n* DS roles expect at least some idea of how neural networks work, sometimes how transformers work.\n\nWhat has not changed and will probably remain the same:\n\n* SQL still very relevant, not much change in difficulty.\n* Classification metrics.\n* Ability to translate business problems into DS action items.\n* Hypothesis testing.", "author_fullname": "t2_4oceb7wh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reflecting on the Changing Hiring Bar", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12l8o0k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681424518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious to hear your experiences on how the hiring bar has changed, especially for those that have been in the field 5+ years.&lt;/p&gt;\n\n&lt;p&gt;From a purely anecdotal perspective, it feels that the hiring bar for data scientists has gone up and is all over the place. I might be wrong, but it felt that 5 years ago if you knew A/B testing + jupyter notebooks it was good enough.&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: there&amp;#39;s no one definitive definition of what a data scientist is, so each company/field will have different criteria. Obviously you can&amp;#39;t thoroughly test for everything, sometimes it&amp;#39;s just a &amp;quot;Can you tell me what X is and how it&amp;#39;s used?&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;These are the interview elements where I feel the bar has gone up:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;More leetcode medium, DS/ML coding level is moving closer to SWE. Definitely ran into some leetcode hards. &lt;/li&gt;\n&lt;li&gt;MLE leaning roles will ask for knowledge on how to productize DS projects. Knowledge of AWS and containers is sort of expected.&lt;/li&gt;\n&lt;li&gt;DS roles expect at least some idea of how neural networks work, sometimes how transformers work.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What has not changed and will probably remain the same:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SQL still very relevant, not much change in difficulty.&lt;/li&gt;\n&lt;li&gt;Classification metrics.&lt;/li&gt;\n&lt;li&gt;Ability to translate business problems into DS action items.&lt;/li&gt;\n&lt;li&gt;Hypothesis testing.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12l8o0k", "is_robot_indexable": true, "report_reasons": null, "author": "HummusEconomics", "discussion_type": null, "num_comments": 7, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12l8o0k/reflecting_on_the_changing_hiring_bar/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12l8o0k/reflecting_on_the_changing_hiring_bar/", "subreddit_subscribers": 872429, "created_utc": 1681424518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have \\~6k positive samples of a fraud class; and \\~110k unlabeled  samples of mostly negative classes. Although I don't have labels for these 110k samples, I assume that the majority belongs to the negative class.  However, in my assumption, I know that there are some positive samples  in this unlabeled data set. \n\nWhat do you think it would be the best approach to detect these fraud samples in the unlabeled data set?    \n1- I was thinking in a binary classification approach after removing samples that have the highest chance of being outlier/anomaly on the unlabeled data set;  \n2- Maybe go for an anomaly detection model only or one-class classification\n\nThanks in advance!", "author_fullname": "t2_9o8ch0c3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help on this fraud detection problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lahml", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681427122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have ~6k positive samples of a fraud class; and ~110k unlabeled  samples of mostly negative classes. Although I don&amp;#39;t have labels for these 110k samples, I assume that the majority belongs to the negative class.  However, in my assumption, I know that there are some positive samples  in this unlabeled data set. &lt;/p&gt;\n\n&lt;p&gt;What do you think it would be the best approach to detect these fraud samples in the unlabeled data set?&lt;br/&gt;\n1- I was thinking in a binary classification approach after removing samples that have the highest chance of being outlier/anomaly on the unlabeled data set;&lt;br/&gt;\n2- Maybe go for an anomaly detection model only or one-class classification&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12lahml", "is_robot_indexable": true, "report_reasons": null, "author": "le_bebop", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12lahml/help_on_this_fraud_detection_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12lahml/help_on_this_fraud_detection_problem/", "subreddit_subscribers": 872429, "created_utc": 1681427122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a nurse and currently work in public health. I really enjoyed it and gained some experience in health informatics. Unfortunately I will be getting laid off soon so I've started looking for a job. \n\nAny tips on entering the field of data analysis? Or should I forget it?", "author_fullname": "t2_gzcm5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it feasible for nurses to work in data analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12la96q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681426685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a nurse and currently work in public health. I really enjoyed it and gained some experience in health informatics. Unfortunately I will be getting laid off soon so I&amp;#39;ve started looking for a job. &lt;/p&gt;\n\n&lt;p&gt;Any tips on entering the field of data analysis? Or should I forget it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12la96q", "is_robot_indexable": true, "report_reasons": null, "author": "Gracilis67", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12la96q/is_it_feasible_for_nurses_to_work_in_data_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12la96q/is_it_feasible_for_nurses_to_work_in_data_analysis/", "subreddit_subscribers": 872429, "created_utc": 1681426685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am interviewing for a job next week. It\u2019s a really unique roll that requires dealing with data but also requires a law degree. I\u2019m a lawyer and I happen to be in a masters program for data science so I\u2019m oddly perfectly qualified for this job. There\u2019s some other requirements that I\u2019m even more uniquely qualified for but its too much detail for a throw away account. \n\nI frankly don\u2019t know how anyone could have my unique combination of requirements to meet this role. The concern I have is that I\u2019m interviewing with folks that are all lawyers. How do I both impress them with my data science knowledge but not overwhelm them with terminology they aren\u2019t familiar with. I know what the goals of the data analysis is for the role, have some thoughts on data they could gather that they probably aren\u2019t (I have found some reports they\u2019ve released in the past), and have some ideas on how machine learning could be used to meet the end goal. I\u2019m just concerned about translating that for non-data science people, especially the machine learning piece. \n\nI\u2019d really just love any tips for interviewing for a data heavy role with non-data folks. How do you leave an impression without them thinking you are just making up things? \ud83d\ude02", "author_fullname": "t2_mrw1n7xg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview tips for the job I am so oddly qualified for it\u2019s scaring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kp6d2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681392414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am interviewing for a job next week. It\u2019s a really unique roll that requires dealing with data but also requires a law degree. I\u2019m a lawyer and I happen to be in a masters program for data science so I\u2019m oddly perfectly qualified for this job. There\u2019s some other requirements that I\u2019m even more uniquely qualified for but its too much detail for a throw away account. &lt;/p&gt;\n\n&lt;p&gt;I frankly don\u2019t know how anyone could have my unique combination of requirements to meet this role. The concern I have is that I\u2019m interviewing with folks that are all lawyers. How do I both impress them with my data science knowledge but not overwhelm them with terminology they aren\u2019t familiar with. I know what the goals of the data analysis is for the role, have some thoughts on data they could gather that they probably aren\u2019t (I have found some reports they\u2019ve released in the past), and have some ideas on how machine learning could be used to meet the end goal. I\u2019m just concerned about translating that for non-data science people, especially the machine learning piece. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d really just love any tips for interviewing for a data heavy role with non-data folks. How do you leave an impression without them thinking you are just making up things? \ud83d\ude02&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kp6d2", "is_robot_indexable": true, "report_reasons": null, "author": "Comfortable-Lie-2326", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kp6d2/interview_tips_for_the_job_i_am_so_oddly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kp6d2/interview_tips_for_the_job_i_am_so_oddly/", "subreddit_subscribers": 872429, "created_utc": 1681392414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Would like to introduce this tool to everyone. Have been testing with some beta users and see 10X increase in productivity. Currently it works well for less-complex DS tasks but we plan to expand more.\n\nHere what you can do with it all with natural language:\n\n1. Upload/Import data set csv, json, xls\n2. Do any processing task that you can think of\n3. Plot any plot that you can express in NLP and matplotlib can do :)\n4. Build simple model using scikit-learn\n\nLove to hear everyone feedbacks! Follow us here if you like to learn more [https://twitter.com/cnextdotio](https://twitter.com/cnextdotio)\n\nDocs: [https://docs.cnext.io/data-science-tools](https://docs.cnext.io/data-science-tools)\n\nApp: [apis.cnext.io](https://apis.cnext.io)\n\nhttps://preview.redd.it/lzktdauaykta1.png?width=873&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=16f2699204194527675e45531b8712c5f87ad6bd", "author_fullname": "t2_okfnia1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low-code Data Science Tool built on chatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 48, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lzktdauaykta1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/lzktdauaykta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1a5c7a2e3a498c928c74286ec1022650176e409"}, {"y": 174, "x": 216, "u": "https://preview.redd.it/lzktdauaykta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64fdf7e40a0dfe1cde77ce64062f868f4c2c4f87"}, {"y": 259, "x": 320, "u": "https://preview.redd.it/lzktdauaykta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1d528be3d18772ce799d366e50fdc4cc190ca78"}, {"y": 518, "x": 640, "u": "https://preview.redd.it/lzktdauaykta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de47389dd382213677cd067c4da66d6eabb6c87e"}], "s": {"y": 707, "x": 873, "u": "https://preview.redd.it/lzktdauaykta1.png?width=873&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=16f2699204194527675e45531b8712c5f87ad6bd"}, "id": "lzktdauaykta1"}}, "name": "t3_12kc5ls", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 48, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JDDq-pcrrSqsz7GEz0P5mUdLolERVxDSVAkq0fdYtPE.jpg", "edited": 1681362082.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1681360865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would like to introduce this tool to everyone. Have been testing with some beta users and see 10X increase in productivity. Currently it works well for less-complex DS tasks but we plan to expand more.&lt;/p&gt;\n\n&lt;p&gt;Here what you can do with it all with natural language:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Upload/Import data set csv, json, xls&lt;/li&gt;\n&lt;li&gt;Do any processing task that you can think of&lt;/li&gt;\n&lt;li&gt;Plot any plot that you can express in NLP and matplotlib can do :)&lt;/li&gt;\n&lt;li&gt;Build simple model using scikit-learn&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Love to hear everyone feedbacks! Follow us here if you like to learn more &lt;a href=\"https://twitter.com/cnextdotio\"&gt;https://twitter.com/cnextdotio&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Docs: &lt;a href=\"https://docs.cnext.io/data-science-tools\"&gt;https://docs.cnext.io/data-science-tools&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;App: &lt;a href=\"https://apis.cnext.io\"&gt;apis.cnext.io&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lzktdauaykta1.png?width=873&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=16f2699204194527675e45531b8712c5f87ad6bd\"&gt;https://preview.redd.it/lzktdauaykta1.png?width=873&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=16f2699204194527675e45531b8712c5f87ad6bd&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OBM7q-61ka5lkrprnjH6SpgJcEbNjU8Q46FW0LE-JWg.jpg?auto=webp&amp;v=enabled&amp;s=4d07eaa0db50c7c27f8c211c02755bcb7adbc83f", "width": 48, "height": 48}, "resolutions": [], "variants": {}, "id": "OlJRNvDzYa3NMm-BatyvTAOhVor4xM14A8xmLpBW4vI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kc5ls", "is_robot_indexable": true, "report_reasons": null, "author": "SomeProfessional", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kc5ls/lowcode_data_science_tool_built_on_chatgpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kc5ls/lowcode_data_science_tool_built_on_chatgpt/", "subreddit_subscribers": 872429, "created_utc": 1681360865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Lowering the price will likely increase sales but could decrease margin. Vice versa for raising the price. Changing prices then measuring the impact seems inefficient especially since I can only change prices once per month and each product/location could react differently.", "author_fullname": "t2_kcl3tfwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good algorithms/techniques for pricing and revenue optimization strategy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kqu24", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681395599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lowering the price will likely increase sales but could decrease margin. Vice versa for raising the price. Changing prices then measuring the impact seems inefficient especially since I can only change prices once per month and each product/location could react differently.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kqu24", "is_robot_indexable": true, "report_reasons": null, "author": "NewEcho2940", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kqu24/good_algorithmstechniques_for_pricing_and_revenue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kqu24/good_algorithmstechniques_for_pricing_and_revenue/", "subreddit_subscribers": 872429, "created_utc": 1681395599.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All,\n\nI'm wondering if someone has the experience in moving dashboards and analysis from PBI to a real front end framework?\n\nReason I'm asking is that we started to see the limitations of PBI, especially on the performance site. \nDon't get me wrong the MS ekosystem is incredible but I do miss a lot of capability in end user interactions and real time simulation based on manual input. \n\nWe spent significantly amount of time tuning the dashboards so I'm quite confident that it is not a skillset issue.", "author_fullname": "t2_93oh8x44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PowerBi -&gt; JS/HTML/CSS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kfpzo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681369946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if someone has the experience in moving dashboards and analysis from PBI to a real front end framework?&lt;/p&gt;\n\n&lt;p&gt;Reason I&amp;#39;m asking is that we started to see the limitations of PBI, especially on the performance site. \nDon&amp;#39;t get me wrong the MS ekosystem is incredible but I do miss a lot of capability in end user interactions and real time simulation based on manual input. &lt;/p&gt;\n\n&lt;p&gt;We spent significantly amount of time tuning the dashboards so I&amp;#39;m quite confident that it is not a skillset issue.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kfpzo", "is_robot_indexable": true, "report_reasons": null, "author": "Kamil_1987", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kfpzo/powerbi_jshtmlcss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kfpzo/powerbi_jshtmlcss/", "subreddit_subscribers": 872429, "created_utc": 1681369946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have an MS in Data Science and the company I work for doesn't have many opportunities for data science (AI/ML) work. Most of their work is on the data engineering side.\n\nI would like to get that data scientist title but it seems my best current option with my current company is an analytics engineer title.\n\nWhat do you make of the analytics engineer title for career opportunities vs a data scientist title?", "author_fullname": "t2_54v2gqwu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analytics Engineer Job Title", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12l7yez", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681423723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an MS in Data Science and the company I work for doesn&amp;#39;t have many opportunities for data science (AI/ML) work. Most of their work is on the data engineering side.&lt;/p&gt;\n\n&lt;p&gt;I would like to get that data scientist title but it seems my best current option with my current company is an analytics engineer title.&lt;/p&gt;\n\n&lt;p&gt;What do you make of the analytics engineer title for career opportunities vs a data scientist title?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12l7yez", "is_robot_indexable": true, "report_reasons": null, "author": "That-Economics-9481", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12l7yez/analytics_engineer_job_title/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12l7yez/analytics_engineer_job_title/", "subreddit_subscribers": 872429, "created_utc": 1681423723.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been playing around with Causal Forests through the econML package but causal inference in general is quite new to me.\n\nI've read some interesting literature about how these types of random forest models can be thought of as an adaptive nearest neighbor approach which \"learns\" which features are most important in determining neighborhoods, rather than just using a standard distance calc across all features.\n\nThere are lots of tools around determining which features are important (SHAP values, feature importances, etc.), but I was wondering if there was a way to use these models to determine the most similar data points based on this adaptive neighborhood idea (i.e. something like how many leaves they are in together, or % of times they are on the same side of a split, etc.).\n\nI know I can compare on the actual output, but I was also thinking there would be cases where different subgroups might have similar outcomes spuriously despite having different features (i.e. w.r.t. housing price regression: small shore houses having similar price ranges to large suburban homes, despite being very different). \n\nSo I was thinking there must be a better way to do this. Thanks!", "author_fullname": "t2_8nyuj3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any way to \"recover\" nearest neighbors from a Random Forest/Causal Forest model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12l65yl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681421748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been playing around with Causal Forests through the econML package but causal inference in general is quite new to me.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read some interesting literature about how these types of random forest models can be thought of as an adaptive nearest neighbor approach which &amp;quot;learns&amp;quot; which features are most important in determining neighborhoods, rather than just using a standard distance calc across all features.&lt;/p&gt;\n\n&lt;p&gt;There are lots of tools around determining which features are important (SHAP values, feature importances, etc.), but I was wondering if there was a way to use these models to determine the most similar data points based on this adaptive neighborhood idea (i.e. something like how many leaves they are in together, or % of times they are on the same side of a split, etc.).&lt;/p&gt;\n\n&lt;p&gt;I know I can compare on the actual output, but I was also thinking there would be cases where different subgroups might have similar outcomes spuriously despite having different features (i.e. w.r.t. housing price regression: small shore houses having similar price ranges to large suburban homes, despite being very different). &lt;/p&gt;\n\n&lt;p&gt;So I was thinking there must be a better way to do this. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12l65yl", "is_robot_indexable": true, "report_reasons": null, "author": "metsfan1025", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12l65yl/any_way_to_recover_nearest_neighbors_from_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12l65yl/any_way_to_recover_nearest_neighbors_from_a/", "subreddit_subscribers": 872429, "created_utc": 1681421748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR: I projected some performance improvement from my model but when put into production it was a complete shitshow. And now im scared I will either get piped or fired.", "author_fullname": "t2_7uv7n9v6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I worked on a DS project for the last 4 months in my new role ( been here since 7ish months approx). Model was used to basically identify a targeted group of customers to send out mktg message to. But when we put this targeting into place we are not reaching to even 1% of the expected customers.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kq8wu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681394481.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: I projected some performance improvement from my model but when put into production it was a complete shitshow. And now im scared I will either get piped or fired.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kq8wu", "is_robot_indexable": true, "report_reasons": null, "author": "Financial_Ad7856", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kq8wu/i_worked_on_a_ds_project_for_the_last_4_months_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kq8wu/i_worked_on_a_ds_project_for_the_last_4_months_in/", "subreddit_subscribers": 872429, "created_utc": 1681394481.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI am working on a manufacturing data that is fairly new (only has 60 batches produced so far) dataset size is 60 observations of 150 variables and I am building a PLS model to predict the Final Product quantity in Kgs that meets minimum specifications. After removing intermediate product measurements, redundant variables, calculated variables to avoid Colinearity I am left with 60 observations of 110 variables. This PLS model has predictability only at 23% and more than 70% of the variables have huge variations in their data so far. My thoughts are this process data is too early and not sufficient to make a predictive PLS model but I would like to get some expert opinions on this situation. Can I assume adding more observations to this data helps the model? Is there any basic data health check I am missing for PLS modeling before I submit the outcomes to my manufacturing team? Thank you", "author_fullname": "t2_67a9iuah", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data size and health for PLS modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12katta", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681357720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am working on a manufacturing data that is fairly new (only has 60 batches produced so far) dataset size is 60 observations of 150 variables and I am building a PLS model to predict the Final Product quantity in Kgs that meets minimum specifications. After removing intermediate product measurements, redundant variables, calculated variables to avoid Colinearity I am left with 60 observations of 110 variables. This PLS model has predictability only at 23% and more than 70% of the variables have huge variations in their data so far. My thoughts are this process data is too early and not sufficient to make a predictive PLS model but I would like to get some expert opinions on this situation. Can I assume adding more observations to this data helps the model? Is there any basic data health check I am missing for PLS modeling before I submit the outcomes to my manufacturing team? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12katta", "is_robot_indexable": true, "report_reasons": null, "author": "Santhu1414Ind", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12katta/data_size_and_health_for_pls_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12katta/data_size_and_health_for_pls_modeling/", "subreddit_subscribers": 872429, "created_utc": 1681357720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nI'm working in a data set and I'm trying to use groupby() and sum() and column that I'm using has a data type of int32 that is a new column created from a datetime with the function .dt.month\n\nclean\\_all\\_month\\_df\\['MonthNum'\\] = clean\\_all\\_month\\_df\\['Order Date'\\].dt.month\n\n&amp;#x200B;\n\nhttps://preview.redd.it/eggr7gkp1qta1.png?width=848&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2763a0dcf5985482c5897ce5f1ca0ed9e4e62100\n\nwhen trying to do the groupby() I receive an error regarding the data type.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/vl7t1l4x1qta1.png?width=1290&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4b00ce5bb3762a181aace082c0bac1eb3ec3f33a\n\nTypeError: datetime64 type does not support sum operations\n\nAny hint?", "author_fullname": "t2_dkpbwjdv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hints on Data Types", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 68, "top_awarded_type": null, "hide_score": false, "media_metadata": {"eggr7gkp1qta1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 52, "x": 108, "u": "https://preview.redd.it/eggr7gkp1qta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a6abe0491ed304fd7d8ee4ba90b3ab3ab7fe6906"}, {"y": 105, "x": 216, "u": "https://preview.redd.it/eggr7gkp1qta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c128caf4d86a18123721c38c773bb3b5f0404b0b"}, {"y": 156, "x": 320, "u": "https://preview.redd.it/eggr7gkp1qta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=581a4e326776ee9d4a0215ebed79ed7e60a4b7a7"}, {"y": 313, "x": 640, "u": "https://preview.redd.it/eggr7gkp1qta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6edd63ce8e025195fa20d1eea2015b6e54f0aa8e"}], "s": {"y": 416, "x": 848, "u": "https://preview.redd.it/eggr7gkp1qta1.png?width=848&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2763a0dcf5985482c5897ce5f1ca0ed9e4e62100"}, "id": "eggr7gkp1qta1"}, "vl7t1l4x1qta1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 21, "x": 108, "u": "https://preview.redd.it/vl7t1l4x1qta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f58a8b1ff87bbd3b2911491bf767508adb5de4af"}, {"y": 43, "x": 216, "u": "https://preview.redd.it/vl7t1l4x1qta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6dcb4020148a440fd965d0a44141a554afa9f1ae"}, {"y": 64, "x": 320, "u": "https://preview.redd.it/vl7t1l4x1qta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a174d47382d09ccf34d688d39676bc3f9ad1d4b1"}, {"y": 128, "x": 640, "u": "https://preview.redd.it/vl7t1l4x1qta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=854e3768cf62d020c612c8f2e608bbc71ecbe8e5"}, {"y": 192, "x": 960, "u": "https://preview.redd.it/vl7t1l4x1qta1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a81abfc0f371c56cdd4e4b26b16c8f14a4d7be55"}, {"y": 216, "x": 1080, "u": "https://preview.redd.it/vl7t1l4x1qta1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=87c8080b48a3fd41fc547f6e7ddd831815778528"}], "s": {"y": 258, "x": 1290, "u": "https://preview.redd.it/vl7t1l4x1qta1.png?width=1290&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4b00ce5bb3762a181aace082c0bac1eb3ec3f33a"}, "id": "vl7t1l4x1qta1"}}, "name": "t3_12l6mfo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BdxiJ7Gwn6MkNG-bWE-1cNuUkHzor1y3zTIuxGZXQxA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681422245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working in a data set and I&amp;#39;m trying to use groupby() and sum() and column that I&amp;#39;m using has a data type of int32 that is a new column created from a datetime with the function .dt.month&lt;/p&gt;\n\n&lt;p&gt;clean_all_month_df[&amp;#39;MonthNum&amp;#39;] = clean_all_month_df[&amp;#39;Order Date&amp;#39;].dt.month&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/eggr7gkp1qta1.png?width=848&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2763a0dcf5985482c5897ce5f1ca0ed9e4e62100\"&gt;https://preview.redd.it/eggr7gkp1qta1.png?width=848&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2763a0dcf5985482c5897ce5f1ca0ed9e4e62100&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;when trying to do the groupby() I receive an error regarding the data type.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vl7t1l4x1qta1.png?width=1290&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4b00ce5bb3762a181aace082c0bac1eb3ec3f33a\"&gt;https://preview.redd.it/vl7t1l4x1qta1.png?width=1290&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4b00ce5bb3762a181aace082c0bac1eb3ec3f33a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;TypeError: datetime64 type does not support sum operations&lt;/p&gt;\n\n&lt;p&gt;Any hint?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12l6mfo", "is_robot_indexable": true, "report_reasons": null, "author": "nzenzo_209", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12l6mfo/hints_on_data_types/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12l6mfo/hints_on_data_types/", "subreddit_subscribers": 872429, "created_utc": 1681422245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I really want to figure out how to do this. I can totally write the code but I just need help starting out and getting a plan together. Any ideas? I'd like to consider things such as the historical drop off rate of other top NBA players and Lebron's season averages.\n\nEdit: Downvotes are leading me to believe this is a stupid question. Although that may be the case all I'm trying to do is find a jumping off point so I can google/research to figure out the rest.", "author_fullname": "t2_3uk2pfvx6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to build a project to determine the age that Lebron would score less than 10 points. Just looking for a rough guideline. I want to write it all myself obviously.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kyc5o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681415802.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681410243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really want to figure out how to do this. I can totally write the code but I just need help starting out and getting a plan together. Any ideas? I&amp;#39;d like to consider things such as the historical drop off rate of other top NBA players and Lebron&amp;#39;s season averages.&lt;/p&gt;\n\n&lt;p&gt;Edit: Downvotes are leading me to believe this is a stupid question. Although that may be the case all I&amp;#39;m trying to do is find a jumping off point so I can google/research to figure out the rest.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kyc5o", "is_robot_indexable": true, "report_reasons": null, "author": "GlenSheen", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kyc5o/i_want_to_build_a_project_to_determine_the_age/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kyc5o/i_want_to_build_a_project_to_determine_the_age/", "subreddit_subscribers": 872429, "created_utc": 1681410243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_x3vk1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hear from today's real-world data leaders = episode 63 (Daniel Hulme founder of Satalia)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_12kk0m5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bHx6MGGYGs44L0rn8G7qZyVNOlSQjpJKU1zHW09HLIE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681381302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "podcasters.spotify.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://podcasters.spotify.com/pod/show/customerinsightleader/episodes/Episode-63---Daniel-Hulme-Satalia-e1sa7r7", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/K5WSuKshDcIYDOAEJ1dhjM2p-a8TI9pB8zCRtq7zkQ4.jpg?auto=webp&amp;v=enabled&amp;s=cae169dc86c09eee4a4ae4314280786fab102f9c", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/K5WSuKshDcIYDOAEJ1dhjM2p-a8TI9pB8zCRtq7zkQ4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd896b4d68f7063771f4ccdac61a9df4dddef55a", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/K5WSuKshDcIYDOAEJ1dhjM2p-a8TI9pB8zCRtq7zkQ4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=defe7d936a830122b7e94e927cd830f9559de781", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/K5WSuKshDcIYDOAEJ1dhjM2p-a8TI9pB8zCRtq7zkQ4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e60078a475e0369e46be33b37cd05346791259f8", "width": 320, "height": 320}], "variants": {}, "id": "lOmO3YIIHrYfnoN5Ytw44Gi7UDwTX5S2V--yq_mjt-Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kk0m5", "is_robot_indexable": true, "report_reasons": null, "author": "PaulLaughlin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kk0m5/hear_from_todays_realworld_data_leaders_episode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://podcasters.spotify.com/pod/show/customerinsightleader/episodes/Episode-63---Daniel-Hulme-Satalia-e1sa7r7", "subreddit_subscribers": 872429, "created_utc": 1681381302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_pses1cx1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Create Custom Vision Applications with No Code/Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_12kop98", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/7SMySnRRTew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"This is the Remyx!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "This is the Remyx!", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/7SMySnRRTew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"This is the Remyx!\"&gt;&lt;/iframe&gt;", "author_name": "Smells Like ML", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/7SMySnRRTew/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@smellslikeml"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/7SMySnRRTew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"This is the Remyx!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/12kop98", "height": 200}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Y921ytB_CBY6x5dgdVRCINpUolMwggpEFvA5BgtLzF8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681391457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=7SMySnRRTew", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KQmBzm2bojsN_YZ93vIwEvRD1_BXy_WX24-eW-hW_Io.jpg?auto=webp&amp;v=enabled&amp;s=7033f42e0cc95164865faef3cf7a38cf07d5b200", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/KQmBzm2bojsN_YZ93vIwEvRD1_BXy_WX24-eW-hW_Io.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=679bdbdb49df61f212d12447691161a97d926f8f", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/KQmBzm2bojsN_YZ93vIwEvRD1_BXy_WX24-eW-hW_Io.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e9b6b0e9a10ae522f6efe79883034220799ab617", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/KQmBzm2bojsN_YZ93vIwEvRD1_BXy_WX24-eW-hW_Io.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94b832106a26a52282ccbb65c9dd414023c22da4", "width": 320, "height": 240}], "variants": {}, "id": "zV1S95EK_4BSAZsbgDTKRZgh18Hm3L8zbrOwkM81qIg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kop98", "is_robot_indexable": true, "report_reasons": null, "author": "remyxai", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kop98/create_custom_vision_applications_with_no_codedata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=7SMySnRRTew", "subreddit_subscribers": 872429, "created_utc": 1681391457.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "This is the Remyx!", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/7SMySnRRTew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"This is the Remyx!\"&gt;&lt;/iframe&gt;", "author_name": "Smells Like ML", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/7SMySnRRTew/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@smellslikeml"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anyone know any part time data science program (master/graduate level preferred) available out there? All I can find are full time programs\u2026\nI\u2019ve a mid level data analyst job but I really want to get into data science.\nTIA", "author_fullname": "t2_8s1y1k1s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Part time programs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kbglp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681359187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know any part time data science program (master/graduate level preferred) available out there? All I can find are full time programs\u2026\nI\u2019ve a mid level data analyst job but I really want to get into data science.\nTIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kbglp", "is_robot_indexable": true, "report_reasons": null, "author": "stephensplo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kbglp/part_time_programs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kbglp/part_time_programs/", "subreddit_subscribers": 872429, "created_utc": 1681359187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, all. I wanted to ask, how long does it take you to build your own predictive model? Thank you", "author_fullname": "t2_f0mjgii2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time to Build Predictive Model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12kbshh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681359984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, all. I wanted to ask, how long does it take you to build your own predictive model? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12kbshh", "is_robot_indexable": true, "report_reasons": null, "author": "Fickle-Story5526", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12kbshh/time_to_build_predictive_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12kbshh/time_to_build_predictive_model/", "subreddit_subscribers": 872429, "created_utc": 1681359984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\ud83d\udd38According to a report by news outlet Bloomberg, Elon Musk has been secretly working on an artificial intelligence project for Twitter. \n\n&amp;#x200B;\n\n\ud83d\udd38The project reportedly aims to reduce the spread of misinformation and improve the overall health of conversations on the social media platform. Musk's involvement in the project is said to be through his startup, OpenAI, which has previously worked on language processing technology. \n\n&amp;#x200B;\n\n\ud83d\udd38Twitter has faced criticism for not doing enough to curb the spread of misinformation and harmful content on its platform, and this project could be a step towards addressing those concerns.\n\nhttps://preview.redd.it/30mve9bp9qta1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=9c9481d6d8dc0957b6aa48b058512d501885d077", "author_fullname": "t2_v0pkc09z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any thoughts about Elon Musk new plan?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"30mve9bp9qta1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/30mve9bp9qta1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73e000440de78d15f00452482286811f916d571b"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/30mve9bp9qta1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc99bb1e74f556ccaf36c276cfef3078d5c81d6f"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/30mve9bp9qta1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a5bcec4ad221e406b20c36daa8e6e23b3d4df33b"}, {"y": 640, "x": 640, "u": "https://preview.redd.it/30mve9bp9qta1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=214255abb8f8fd6847d2c5b03c81d49a1f3a498b"}, {"y": 960, "x": 960, "u": "https://preview.redd.it/30mve9bp9qta1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f57280273b0674ca01890d6546d6ab7f9f40a6da"}, {"y": 1080, "x": 1080, "u": "https://preview.redd.it/30mve9bp9qta1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9dda01a0452b5ce033e816726bb246885462dbcd"}], "s": {"y": 1280, "x": 1280, "u": "https://preview.redd.it/30mve9bp9qta1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=9c9481d6d8dc0957b6aa48b058512d501885d077"}, "id": "30mve9bp9qta1"}}, "name": "t3_12l8xav", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HnMPdXXr3RgiaN7D7OAwBSN5uKoUwOYDtVnNvka6tcI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681424818.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\ud83d\udd38According to a report by news outlet Bloomberg, Elon Musk has been secretly working on an artificial intelligence project for Twitter. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd38The project reportedly aims to reduce the spread of misinformation and improve the overall health of conversations on the social media platform. Musk&amp;#39;s involvement in the project is said to be through his startup, OpenAI, which has previously worked on language processing technology. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd38Twitter has faced criticism for not doing enough to curb the spread of misinformation and harmful content on its platform, and this project could be a step towards addressing those concerns.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/30mve9bp9qta1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9c9481d6d8dc0957b6aa48b058512d501885d077\"&gt;https://preview.redd.it/30mve9bp9qta1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9c9481d6d8dc0957b6aa48b058512d501885d077&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12l8xav", "is_robot_indexable": true, "report_reasons": null, "author": "goofyshaft", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12l8xav/any_thoughts_about_elon_musk_new_plan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12l8xav/any_thoughts_about_elon_musk_new_plan/", "subreddit_subscribers": 872429, "created_utc": 1681424818.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}