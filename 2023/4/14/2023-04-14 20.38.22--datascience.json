{"kind": "Listing", "data": {"after": "t3_12lqcjr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm curious to hear your experiences on how the hiring bar has changed, especially for those that have been in the field 5+ years.\n\nFrom a purely anecdotal perspective, it feels that the hiring bar for data scientists has gone up and is all over the place. I might be wrong, but it felt that 5 years ago if you knew A/B testing + jupyter notebooks it was good enough.\n\nDisclaimer: there's no one definitive definition of what a data scientist is, so each company/field will have different criteria. Obviously you can't thoroughly test for everything, sometimes it's just a \"Can you tell me what X is and how it's used?\".\n\nThese are the interview elements where I feel the bar has gone up:\n\n* More leetcode medium, DS/ML coding level is moving closer to SWE. Definitely ran into some leetcode hards. \n* MLE leaning roles will ask for knowledge on how to productize DS projects. Knowledge of AWS and containers is sort of expected.\n* DS roles expect at least some idea of how neural networks work, sometimes how transformers work.\n\nWhat has not changed and will probably remain the same:\n\n* SQL still very relevant, not much change in difficulty.\n* Classification metrics.\n* Ability to translate business problems into DS action items.\n* Hypothesis testing.", "author_fullname": "t2_4oceb7wh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reflecting on the Changing Hiring Bar", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12l8o0k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 139, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 139, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681424518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious to hear your experiences on how the hiring bar has changed, especially for those that have been in the field 5+ years.&lt;/p&gt;\n\n&lt;p&gt;From a purely anecdotal perspective, it feels that the hiring bar for data scientists has gone up and is all over the place. I might be wrong, but it felt that 5 years ago if you knew A/B testing + jupyter notebooks it was good enough.&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: there&amp;#39;s no one definitive definition of what a data scientist is, so each company/field will have different criteria. Obviously you can&amp;#39;t thoroughly test for everything, sometimes it&amp;#39;s just a &amp;quot;Can you tell me what X is and how it&amp;#39;s used?&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;These are the interview elements where I feel the bar has gone up:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;More leetcode medium, DS/ML coding level is moving closer to SWE. Definitely ran into some leetcode hards. &lt;/li&gt;\n&lt;li&gt;MLE leaning roles will ask for knowledge on how to productize DS projects. Knowledge of AWS and containers is sort of expected.&lt;/li&gt;\n&lt;li&gt;DS roles expect at least some idea of how neural networks work, sometimes how transformers work.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What has not changed and will probably remain the same:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SQL still very relevant, not much change in difficulty.&lt;/li&gt;\n&lt;li&gt;Classification metrics.&lt;/li&gt;\n&lt;li&gt;Ability to translate business problems into DS action items.&lt;/li&gt;\n&lt;li&gt;Hypothesis testing.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12l8o0k", "is_robot_indexable": true, "report_reasons": null, "author": "HummusEconomics", "discussion_type": null, "num_comments": 45, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12l8o0k/reflecting_on_the_changing_hiring_bar/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12l8o0k/reflecting_on_the_changing_hiring_bar/", "subreddit_subscribers": 872925, "created_utc": 1681424518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I graduated May 2021 and started working as a Data Scientist at General Motors. I was given a project but there was no project manager, customer, deadline or anything. I held myself accountable for 5 months setting my own deadlines etc until I realized that this just wasn't a real project and the company was terribly mismanaged. I took initiative to find other projects and each project I got just kept getting canceled or there wasn't any data.\n\nThen I switched to a Solutions Data Scientist role July 2022 at a larger tech company last year. I spent the first 3 months in training (completely irrelevant to Data Science) and then had absolutely no work. I networked like crazy and got a project on another team last fall which was somewhat exciting but this year there has been absolutely nothing. The other teams seem to have work but they won't let me on to even shadow because they want to prioritize utilization for their employees. My team has no data science work or data to play with. The Solutions Data Scientist role is weird because it is client-facing so if the clients don't want to engage, there is no work. Another challenge is that even when the clients engage, our priority is selling the company's AI products so there is minimal actual data science involved.\n\nI'm kind of concerned that I'm going to end up with years of Data Science experience with nothing to show for it. What should I do? If I applied for Data Science at another company now, it would be hard given the recessionary environment and the fact that I've probably gotten pretty technically soft now.\n\nIs this the reality with Data Science roles? Is it like a fake job? I'm wondering if I should move to a different role, like Product Management, where I might be guaranteed a steady flow of work to do.\n\nI'm also kind of concerned about Chat GPT4. My company sells products in the NLP space and with Chat GPT4, I feel like our products will be pretty obsolete soon.", "author_fullname": "t2_8cg2z0mf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Haven't had any real work for the last 2 years at 2 different companies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12li3r3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 99, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 99, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681493295.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681442744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I graduated May 2021 and started working as a Data Scientist at General Motors. I was given a project but there was no project manager, customer, deadline or anything. I held myself accountable for 5 months setting my own deadlines etc until I realized that this just wasn&amp;#39;t a real project and the company was terribly mismanaged. I took initiative to find other projects and each project I got just kept getting canceled or there wasn&amp;#39;t any data.&lt;/p&gt;\n\n&lt;p&gt;Then I switched to a Solutions Data Scientist role July 2022 at a larger tech company last year. I spent the first 3 months in training (completely irrelevant to Data Science) and then had absolutely no work. I networked like crazy and got a project on another team last fall which was somewhat exciting but this year there has been absolutely nothing. The other teams seem to have work but they won&amp;#39;t let me on to even shadow because they want to prioritize utilization for their employees. My team has no data science work or data to play with. The Solutions Data Scientist role is weird because it is client-facing so if the clients don&amp;#39;t want to engage, there is no work. Another challenge is that even when the clients engage, our priority is selling the company&amp;#39;s AI products so there is minimal actual data science involved.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m kind of concerned that I&amp;#39;m going to end up with years of Data Science experience with nothing to show for it. What should I do? If I applied for Data Science at another company now, it would be hard given the recessionary environment and the fact that I&amp;#39;ve probably gotten pretty technically soft now.&lt;/p&gt;\n\n&lt;p&gt;Is this the reality with Data Science roles? Is it like a fake job? I&amp;#39;m wondering if I should move to a different role, like Product Management, where I might be guaranteed a steady flow of work to do.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also kind of concerned about Chat GPT4. My company sells products in the NLP space and with Chat GPT4, I feel like our products will be pretty obsolete soon.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12li3r3", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate_Ebb3623", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12li3r3/havent_had_any_real_work_for_the_last_2_years_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12li3r3/havent_had_any_real_work_for_the_last_2_years_at/", "subreddit_subscribers": 872925, "created_utc": 1681442744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In February I started a project in my university about air quality. My team downloaded the data from the Spanish Government web and we started cleaning data from then on.\n\nAlmost two months have passed and we haven't finished the data cleaning process. I have to mention that we had filtered the data through many python scripts (w/ pandas) and we have cleaned a lot. I consider that in one week we'll have finished.\n\nThe point here is that everyone else was already analyzing data like a month ago, but I feel that they do not have so much data like us. Moreover, their data comes from some suspicious websites.\n\nMy question is, is it ok? Or should I have reduced the quantity of data? \n\nPD: sorry if my English is wrong, I'm still learning!", "author_fullname": "t2_ulhyxkkk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm in my first project and the data cleaning process is taking sooo long, it is ok?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lnxaw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681456497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In February I started a project in my university about air quality. My team downloaded the data from the Spanish Government web and we started cleaning data from then on.&lt;/p&gt;\n\n&lt;p&gt;Almost two months have passed and we haven&amp;#39;t finished the data cleaning process. I have to mention that we had filtered the data through many python scripts (w/ pandas) and we have cleaned a lot. I consider that in one week we&amp;#39;ll have finished.&lt;/p&gt;\n\n&lt;p&gt;The point here is that everyone else was already analyzing data like a month ago, but I feel that they do not have so much data like us. Moreover, their data comes from some suspicious websites.&lt;/p&gt;\n\n&lt;p&gt;My question is, is it ok? Or should I have reduced the quantity of data? &lt;/p&gt;\n\n&lt;p&gt;PD: sorry if my English is wrong, I&amp;#39;m still learning!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12lnxaw", "is_robot_indexable": true, "report_reasons": null, "author": "LaiqianDS", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12lnxaw/im_in_my_first_project_and_the_data_cleaning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12lnxaw/im_in_my_first_project_and_the_data_cleaning/", "subreddit_subscribers": 872925, "created_utc": 1681456497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have \\~6k positive samples of a fraud class; and \\~110k unlabeled  samples of mostly negative classes. Although I don't have labels for these 110k samples, I assume that the majority belongs to the negative class.  However, in my assumption, I know that there are some positive samples  in this unlabeled data set. \n\nWhat do you think it would be the best approach to detect these fraud samples in the unlabeled data set?    \n1- I was thinking in a binary classification approach after removing samples that have the highest chance of being outlier/anomaly on the unlabeled data set;  \n2- Maybe go for an anomaly detection model only or one-class classification\n\nThanks in advance!", "author_fullname": "t2_9o8ch0c3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help on this fraud detection problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lahml", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681427122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have ~6k positive samples of a fraud class; and ~110k unlabeled  samples of mostly negative classes. Although I don&amp;#39;t have labels for these 110k samples, I assume that the majority belongs to the negative class.  However, in my assumption, I know that there are some positive samples  in this unlabeled data set. &lt;/p&gt;\n\n&lt;p&gt;What do you think it would be the best approach to detect these fraud samples in the unlabeled data set?&lt;br/&gt;\n1- I was thinking in a binary classification approach after removing samples that have the highest chance of being outlier/anomaly on the unlabeled data set;&lt;br/&gt;\n2- Maybe go for an anomaly detection model only or one-class classification&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12lahml", "is_robot_indexable": true, "report_reasons": null, "author": "le_bebop", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12lahml/help_on_this_fraud_detection_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12lahml/help_on_this_fraud_detection_problem/", "subreddit_subscribers": 872925, "created_utc": 1681427122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was looking into self-hosting Bloom as an alternative to GPT. Besides concerns about the context window being too small and the overall quality, I do really like it from a privacy and availability perspective.   \n\n\nBut a production machine running it would cost about 280K per year. I am contemplating setting this up as a shared resource and making it publicly available as an alternative to GPT. Would anyone be interested in that?", "author_fullname": "t2_13mxw7nv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Public Bloom Instance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m27p4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681488484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was looking into self-hosting Bloom as an alternative to GPT. Besides concerns about the context window being too small and the overall quality, I do really like it from a privacy and availability perspective.   &lt;/p&gt;\n\n&lt;p&gt;But a production machine running it would cost about 280K per year. I am contemplating setting this up as a shared resource and making it publicly available as an alternative to GPT. Would anyone be interested in that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m27p4", "is_robot_indexable": true, "report_reasons": null, "author": "fokke2508", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m27p4/public_bloom_instance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m27p4/public_bloom_instance/", "subreddit_subscribers": 872925, "created_utc": 1681488484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I saw a plot today and for some reason, after over a decade in the profession, thought that the standard axes might not be the norm. I was brought up with the standard X-Y axes, but might not be the case in other countries where left to right is not the norm.\n\nSo for people writing in non-latin scripts, Arabic, Hebrew, Standard Chinese, etc, do you draw your plots the same way?\n\nDo you plot time series plots with time going from left to right?", "author_fullname": "t2_v1t0s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Non left-to-right writers: how do you plot time-series?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12loszb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681458693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw a plot today and for some reason, after over a decade in the profession, thought that the standard axes might not be the norm. I was brought up with the standard X-Y axes, but might not be the case in other countries where left to right is not the norm.&lt;/p&gt;\n\n&lt;p&gt;So for people writing in non-latin scripts, Arabic, Hebrew, Standard Chinese, etc, do you draw your plots the same way?&lt;/p&gt;\n\n&lt;p&gt;Do you plot time series plots with time going from left to right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12loszb", "is_robot_indexable": true, "report_reasons": null, "author": "philwinder", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12loszb/non_lefttoright_writers_how_do_you_plot_timeseries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12loszb/non_lefttoright_writers_how_do_you_plot_timeseries/", "subreddit_subscribers": 872925, "created_utc": 1681458693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Picterra &amp; Segment Anything Model (SAM) by Meta AI integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_12m0607", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_9or07", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dut4rnaD6QePyxQacRopSJTipuUS3t7_aEeJff1ijIk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "picterra", "selftext": "", "author_fullname": "t2_9or07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Picterra &amp; Segment Anything Model (SAM) by Meta AI integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/picterra", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_12m01yp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dut4rnaD6QePyxQacRopSJTipuUS3t7_aEeJff1ijIk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1681484330.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/feed/update/urn:li:activity:7052653361631772673", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?auto=webp&amp;v=enabled&amp;s=6c0c8af8576f2ac38fc1186500dae252b30f52a9", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26bdb80dffc3b5d5b7dbbdd0bbafce2b30377b34", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45c6809882717fed47592c987ccaca1789cb0d84", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=585a3f7db351644ade99e89d7a0ab4b6825a9e8e", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a60f537c154d67aa3410a9e4c6062a8ca1ea0bbb", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e465a4f6bec066daec448928ad4b32a5d48fd80", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d033dd5c7387956318a42af5725ee22ae5318a9", "width": 1080, "height": 607}], "variants": {}, "id": "G7yGMdsVFtIRCy7I0oG2pO7X_jXOt0gtbPWTC6mNjEI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_62sdxk", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m01yp", "is_robot_indexable": true, "report_reasons": null, "author": "unsaltedrhino", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/picterra/comments/12m01yp/picterra_segment_anything_model_sam_by_meta_ai/", "parent_whitelist_status": null, "stickied": false, "url": "https://www.linkedin.com/feed/update/urn:li:activity:7052653361631772673", "subreddit_subscribers": 17, "created_utc": 1681484330.0, "num_crossposts": 4, "media": null, "is_video": false}], "created": 1681484529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/feed/update/urn:li:activity:7052653361631772673", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?auto=webp&amp;v=enabled&amp;s=6c0c8af8576f2ac38fc1186500dae252b30f52a9", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26bdb80dffc3b5d5b7dbbdd0bbafce2b30377b34", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45c6809882717fed47592c987ccaca1789cb0d84", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=585a3f7db351644ade99e89d7a0ab4b6825a9e8e", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a60f537c154d67aa3410a9e4c6062a8ca1ea0bbb", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e465a4f6bec066daec448928ad4b32a5d48fd80", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/3hbFvMp3E7wOpZd9I5atrYbuPNLW4RFdPaHLq1f5C_8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d033dd5c7387956318a42af5725ee22ae5318a9", "width": 1080, "height": 607}], "variants": {}, "id": "G7yGMdsVFtIRCy7I0oG2pO7X_jXOt0gtbPWTC6mNjEI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m0607", "is_robot_indexable": true, "report_reasons": null, "author": "unsaltedrhino", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12m01yp", "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m0607/picterra_segment_anything_model_sam_by_meta_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/feed/update/urn:li:activity:7052653361631772673", "subreddit_subscribers": 872925, "created_utc": 1681484529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI am currently working on my application for my master in data science and I have to answer some questions in the process.\n\nOne of the questions is: \n\n Imagine the following: You just graduated from Data Science \u2013 what are the five key  \ncompetencies, skills, or mindsets that you have acquired during your studies? \n\nI figured many of you are already professionals and know what another professional/professor would like to hear as an answer. Every reply is helpful :)", "author_fullname": "t2_63dpyfns", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Key skills in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m1a4v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681486661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am currently working on my application for my master in data science and I have to answer some questions in the process.&lt;/p&gt;\n\n&lt;p&gt;One of the questions is: &lt;/p&gt;\n\n&lt;p&gt;Imagine the following: You just graduated from Data Science \u2013 what are the five key&lt;br/&gt;\ncompetencies, skills, or mindsets that you have acquired during your studies? &lt;/p&gt;\n\n&lt;p&gt;I figured many of you are already professionals and know what another professional/professor would like to hear as an answer. Every reply is helpful :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m1a4v", "is_robot_indexable": true, "report_reasons": null, "author": "StabiloBoss69", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m1a4v/key_skills_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m1a4v/key_skills_in_data_science/", "subreddit_subscribers": 872925, "created_utc": 1681486661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all\n\nJust wondering, in my specific field it is very important for my bosses that subject-experts are involved in the feature selection process. They claim that we cannot fully automate feature selection as some are more prone to overfitting for instance, and subject-experts who understand the business and features should take a look.\n\nPersonally it makes the process very exhausting for me as I'm more dependent in others. \n\nnote: we work with regression and XGBOOST models.\n\n&amp;#x200B;\n\nWhat do you think of this practice, and how does it work in your workplace?", "author_fullname": "t2_5hjxl4ya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How automatic is your pipeline (or: how much do humans intervene in feature selection)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m4cwt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681492586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;Just wondering, in my specific field it is very important for my bosses that subject-experts are involved in the feature selection process. They claim that we cannot fully automate feature selection as some are more prone to overfitting for instance, and subject-experts who understand the business and features should take a look.&lt;/p&gt;\n\n&lt;p&gt;Personally it makes the process very exhausting for me as I&amp;#39;m more dependent in others. &lt;/p&gt;\n\n&lt;p&gt;note: we work with regression and XGBOOST models.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What do you think of this practice, and how does it work in your workplace?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m4cwt", "is_robot_indexable": true, "report_reasons": null, "author": "PlainPiano9", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m4cwt/how_automatic_is_your_pipeline_or_how_much_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m4cwt/how_automatic_is_your_pipeline_or_how_much_do/", "subreddit_subscribers": 872925, "created_utc": 1681492586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I remember a few years ago it would be a google search away to find a csv with basic demo data per blockgroup level, but now I''m having trouble finding them even digging a bit. Is blockgroup level data for post-2020 not yet available? Did they change delivery methods or am I just missing something obvious? Any pointer appreciated, thanks.", "author_fullname": "t2_70gg199h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having issues finding recent US Census blockgroup level data.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m3kli", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681491108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I remember a few years ago it would be a google search away to find a csv with basic demo data per blockgroup level, but now I&amp;#39;&amp;#39;m having trouble finding them even digging a bit. Is blockgroup level data for post-2020 not yet available? Did they change delivery methods or am I just missing something obvious? Any pointer appreciated, thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m3kli", "is_robot_indexable": true, "report_reasons": null, "author": "xlr_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m3kli/having_issues_finding_recent_us_census_blockgroup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m3kli/having_issues_finding_recent_us_census_blockgroup/", "subreddit_subscribers": 872925, "created_utc": 1681491108.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello folks!\n\nI am attempting to perform DBSCAN on a dataset with approximately 2.5 million rows and 23 columns. After reading many places online, I understand that memory allocation is a problem for performing DBSCAN on such a huge dataset. Does anyone know how to do it, and in addition to it, can DBSCAN be used with parallel processing?\n\nThanks!", "author_fullname": "t2_3wr0pzmd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Batch processing for DBSCAN", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12logrh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681457850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks!&lt;/p&gt;\n\n&lt;p&gt;I am attempting to perform DBSCAN on a dataset with approximately 2.5 million rows and 23 columns. After reading many places online, I understand that memory allocation is a problem for performing DBSCAN on such a huge dataset. Does anyone know how to do it, and in addition to it, can DBSCAN be used with parallel processing?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12logrh", "is_robot_indexable": true, "report_reasons": null, "author": "sARUcasm", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12logrh/batch_processing_for_dbscan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12logrh/batch_processing_for_dbscan/", "subreddit_subscribers": 872925, "created_utc": 1681457850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Original Monty Hall Problem.\n\nSuppose you're on a game show, and you're given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what's behind the doors, opens another door, say No. 3, which has a goat. He then says to you, \"Do you want to pick door No. 2?\" Is it to your advantage to switch your choice?\n\n\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n\nWe know that in the original problem, switching has the higher expected value.\n\n\nNow let\u2019s suppose that there are still 3 doors, but there are 2 players this time. Each player picks a unique door, and assuming that they didn\u2019t both pick the doors with the goat, the unpicked door is revealed to show a goat. \n\nUnder the original problem, it would be profitable for both players to switch their selection. But this just feels so counter intuitive?", "author_fullname": "t2_15wxtiq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monty Hall Problem with 2 players", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12m8q4g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681498487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Original Monty Hall Problem.&lt;/p&gt;\n\n&lt;p&gt;Suppose you&amp;#39;re on a game show, and you&amp;#39;re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what&amp;#39;s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, &amp;quot;Do you want to pick door No. 2?&amp;quot; Is it to your advantage to switch your choice?&lt;/p&gt;\n\n&lt;p&gt;\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014&lt;/p&gt;\n\n&lt;p&gt;We know that in the original problem, switching has the higher expected value.&lt;/p&gt;\n\n&lt;p&gt;Now let\u2019s suppose that there are still 3 doors, but there are 2 players this time. Each player picks a unique door, and assuming that they didn\u2019t both pick the doors with the goat, the unpicked door is revealed to show a goat. &lt;/p&gt;\n\n&lt;p&gt;Under the original problem, it would be profitable for both players to switch their selection. But this just feels so counter intuitive?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m8q4g", "is_robot_indexable": true, "report_reasons": null, "author": "ThreeToInfinity", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m8q4g/monty_hall_problem_with_2_players/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m8q4g/monty_hall_problem_with_2_players/", "subreddit_subscribers": 872925, "created_utc": 1681498487.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all, \n\nI am thinking about enrolling in a Datascience Master's this fall, so I've done some due diligence about the current job market. It's not looking... amazing.\n\nThere are quite a few pessimistic posts here, talking about a great change in the demand for data science labor. Or better put, many previously demanded rolls have been let go. \n\nIs this... a good time to consider this specialization? I'm a recent college grad working for government right now, degree in Econ. The pay is just okay. Was thinking this could be a great way to move forward, but it looks like I would be entering a flooded labor market. \n\nAny advice or opinions? Optimism? Thanks!", "author_fullname": "t2_4d0o90mk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thinking about a MSDS. Is this a bad time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12m8ncw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681498376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, &lt;/p&gt;\n\n&lt;p&gt;I am thinking about enrolling in a Datascience Master&amp;#39;s this fall, so I&amp;#39;ve done some due diligence about the current job market. It&amp;#39;s not looking... amazing.&lt;/p&gt;\n\n&lt;p&gt;There are quite a few pessimistic posts here, talking about a great change in the demand for data science labor. Or better put, many previously demanded rolls have been let go. &lt;/p&gt;\n\n&lt;p&gt;Is this... a good time to consider this specialization? I&amp;#39;m a recent college grad working for government right now, degree in Econ. The pay is just okay. Was thinking this could be a great way to move forward, but it looks like I would be entering a flooded labor market. &lt;/p&gt;\n\n&lt;p&gt;Any advice or opinions? Optimism? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m8ncw", "is_robot_indexable": true, "report_reasons": null, "author": "OtherGandalf", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m8ncw/thinking_about_a_msds_is_this_a_bad_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m8ncw/thinking_about_a_msds_is_this_a_bad_time/", "subreddit_subscribers": 872925, "created_utc": 1681498376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Basically my dataset has hundreds of points of their own error attributed to them. I am fitting the model to the data, finding the derivative of that model at a certain point, then using that value in further calculations. \n\n&amp;#x200B;\n\nI can get an error estimate of the regression model, but what value would I attribute to a point estimated by that model which would also incorporate the inherent error of the dataset?", "author_fullname": "t2_15xfqn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Regression error of a single data point which already has error attributed to it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m6g2p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681495532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically my dataset has hundreds of points of their own error attributed to them. I am fitting the model to the data, finding the derivative of that model at a certain point, then using that value in further calculations. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I can get an error estimate of the regression model, but what value would I attribute to a point estimated by that model which would also incorporate the inherent error of the dataset?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m6g2p", "is_robot_indexable": true, "report_reasons": null, "author": "overhollowhills", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m6g2p/regression_error_of_a_single_data_point_which/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m6g2p/regression_error_of_a_single_data_point_which/", "subreddit_subscribers": 872925, "created_utc": 1681495532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI'm excited to share my new course \"GCP Machine Learning Engineer Certification Practice Tests\". This course will prepare you for the Google Cloud Professional Machine Learning Engineer Certification exam.\n\nI'm offering free coupons for a limited time to the members of this forum. You can enjoy the promotion code by following the link that I provide below:\n\n[https://www.udemy.com/course/gcp-machine-learning-engineer-certification-practice-tests/?couponCode=401A9DAE7AD1B7A04A9F](https://www.udemy.com/course/gcp-machine-learning-engineer-certification-practice-tests/?couponCode=401A9DAE7AD1B7A04A9F)\n\nThank you for your time, and I look forward to seeing you in the course.\n\nBest regards", "author_fullname": "t2_5mszqi6z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP Machine Learning Engineer Certification Practice Tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lxy6f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681480221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m excited to share my new course &amp;quot;GCP Machine Learning Engineer Certification Practice Tests&amp;quot;. This course will prepare you for the Google Cloud Professional Machine Learning Engineer Certification exam.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m offering free coupons for a limited time to the members of this forum. You can enjoy the promotion code by following the link that I provide below:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.udemy.com/course/gcp-machine-learning-engineer-certification-practice-tests/?couponCode=401A9DAE7AD1B7A04A9F\"&gt;https://www.udemy.com/course/gcp-machine-learning-engineer-certification-practice-tests/?couponCode=401A9DAE7AD1B7A04A9F&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time, and I look forward to seeing you in the course.&lt;/p&gt;\n\n&lt;p&gt;Best regards&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SkULa4bA-x6rFM2NB9QBvqnw6A8yPis5hoj5bXZp9BY.jpg?auto=webp&amp;v=enabled&amp;s=d1b1e4b558fbd24815a4c40a69f1477abf8c35ec", "width": 480, "height": 270}, "resolutions": [{"url": "https://external-preview.redd.it/SkULa4bA-x6rFM2NB9QBvqnw6A8yPis5hoj5bXZp9BY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab07e42428cc252d1bbe5af1aa462f16dc2f45cd", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/SkULa4bA-x6rFM2NB9QBvqnw6A8yPis5hoj5bXZp9BY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c24f70bd0ca0ae3cb6ef524f9794373b9c286eb", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/SkULa4bA-x6rFM2NB9QBvqnw6A8yPis5hoj5bXZp9BY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f5fbd95be8c60478b2c0a406540ed973a646a50", "width": 320, "height": 180}], "variants": {}, "id": "GcuI27pv6hgL8kaNonF8CXNN7JikQOIVQhitYMJHsrY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12lxy6f", "is_robot_indexable": true, "report_reasons": null, "author": "Entire-Work34", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12lxy6f/gcp_machine_learning_engineer_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12lxy6f/gcp_machine_learning_engineer_certification/", "subreddit_subscribers": 872925, "created_utc": 1681480221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been playing around with Causal Forests through the econML package but causal inference in general is quite new to me.\n\nI've read some interesting literature about how these types of random forest models can be thought of as an adaptive nearest neighbor approach which \"learns\" which features are most important in determining neighborhoods, rather than just using a standard distance calc across all features.\n\nThere are lots of tools around determining which features are important (SHAP values, feature importances, etc.), but I was wondering if there was a way to use these models to determine the most similar data points based on this adaptive neighborhood idea (i.e. something like how many leaves they are in together, or % of times they are on the same side of a split, etc.).\n\nI know I can compare on the actual output, but I was also thinking there would be cases where different subgroups might have similar outcomes spuriously despite having different features (i.e. w.r.t. housing price regression: small shore houses having similar price ranges to large suburban homes, despite being very different). \n\nSo I was thinking there must be a better way to do this. Thanks!", "author_fullname": "t2_8nyuj3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any way to \"recover\" nearest neighbors from a Random Forest/Causal Forest model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12l65yl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681421748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been playing around with Causal Forests through the econML package but causal inference in general is quite new to me.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read some interesting literature about how these types of random forest models can be thought of as an adaptive nearest neighbor approach which &amp;quot;learns&amp;quot; which features are most important in determining neighborhoods, rather than just using a standard distance calc across all features.&lt;/p&gt;\n\n&lt;p&gt;There are lots of tools around determining which features are important (SHAP values, feature importances, etc.), but I was wondering if there was a way to use these models to determine the most similar data points based on this adaptive neighborhood idea (i.e. something like how many leaves they are in together, or % of times they are on the same side of a split, etc.).&lt;/p&gt;\n\n&lt;p&gt;I know I can compare on the actual output, but I was also thinking there would be cases where different subgroups might have similar outcomes spuriously despite having different features (i.e. w.r.t. housing price regression: small shore houses having similar price ranges to large suburban homes, despite being very different). &lt;/p&gt;\n\n&lt;p&gt;So I was thinking there must be a better way to do this. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12l65yl", "is_robot_indexable": true, "report_reasons": null, "author": "metsfan1025", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12l65yl/any_way_to_recover_nearest_neighbors_from_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12l65yl/any_way_to_recover_nearest_neighbors_from_a/", "subreddit_subscribers": 872925, "created_utc": 1681421748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all,\n\nI was just accepted into an online MSc Data Science program, but the institution announced that they\u2019re going to partner with Coursera for the program beginning this Fall. \n\nI\u2019m concerned that this will affect the way future employers are going to view this degree. I don\u2019t want to invest this much time and money into a program that my hiring managers or teams won\u2019t value or respect as much, especially with how competitive this field is. I was already worried about the post-grad job search, but now I feel like I need to find a different program. \n\nThoughts? Do you think this partnership will negatively impact how my future employers and colleagues view this degree? It will still be granted by the accredited institution, but I have no idea if it will mention on the diploma or my transcript that my courses were taught through Coursera.", "author_fullname": "t2_ecucqjlj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My master\u2019s program is now through Coursera?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12mahf8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681501029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I was just accepted into an online MSc Data Science program, but the institution announced that they\u2019re going to partner with Coursera for the program beginning this Fall. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m concerned that this will affect the way future employers are going to view this degree. I don\u2019t want to invest this much time and money into a program that my hiring managers or teams won\u2019t value or respect as much, especially with how competitive this field is. I was already worried about the post-grad job search, but now I feel like I need to find a different program. &lt;/p&gt;\n\n&lt;p&gt;Thoughts? Do you think this partnership will negatively impact how my future employers and colleagues view this degree? It will still be granted by the accredited institution, but I have no idea if it will mention on the diploma or my transcript that my courses were taught through Coursera.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12mahf8", "is_robot_indexable": true, "report_reasons": null, "author": "justtimingthepast", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12mahf8/my_masters_program_is_now_through_coursera/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12mahf8/my_masters_program_is_now_through_coursera/", "subreddit_subscribers": 872925, "created_utc": 1681501029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let's just say you have a data frame that you would like to groupby \n\ndf.groupby(\\['col\\_name', 'col2\\_name'\\]).agg()\n\nYou would like the user to input the groupby columns, how can you make the groupby columns list dynamic?\n\n&amp;#x200B;\n\nI tried \n\nd3 = \\[df.columns.values for c in grouping\\_list\\]\n\ndf.groupby(\\*d3).agg()\n\n&amp;#x200B;\n\nnot surprisingly, it didn't work. I am looking at pandas documentation and I can't find anything that might help. Does anyone know what I can do?", "author_fullname": "t2_3vgbs41g6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can you groupby dynamic list of columns?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12m8876", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681497795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s just say you have a data frame that you would like to groupby &lt;/p&gt;\n\n&lt;p&gt;df.groupby([&amp;#39;col_name&amp;#39;, &amp;#39;col2_name&amp;#39;]).agg()&lt;/p&gt;\n\n&lt;p&gt;You would like the user to input the groupby columns, how can you make the groupby columns list dynamic?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I tried &lt;/p&gt;\n\n&lt;p&gt;d3 = [df.columns.values for c in grouping_list]&lt;/p&gt;\n\n&lt;p&gt;df.groupby(*d3).agg()&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;not surprisingly, it didn&amp;#39;t work. I am looking at pandas documentation and I can&amp;#39;t find anything that might help. Does anyone know what I can do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m8876", "is_robot_indexable": true, "report_reasons": null, "author": "Curious-Fig-9882", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m8876/how_can_you_groupby_dynamic_list_of_columns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m8876/how_can_you_groupby_dynamic_list_of_columns/", "subreddit_subscribers": 872925, "created_utc": 1681497795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know this is quite a subjective question, and so maybe the answers I'm looking for is just guidance on how to approach this, but **how do you determine how you want to roll out a feature following a successful test?**\n\nFor context, we are launching an experiment on a tight timeline, let's say the experiment allocates to 10% of users. \n\nLet's say we find that the test is successful, we're happy with results, and want to globally make the change to all users.\n\n**How do we approach how we want to phase it out? L**et's assume just going from 10% to 100% is out of the question due to minimizing any unforeseen risks.\n\n**How would you determine what %s each \"phase\" should be? do we go 10-25-50-100? how long do you measure each phase for, especially if we're working on a tight deadline?**\n\nThank you for any inputs all.", "author_fullname": "t2_133emd5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to properly roll out a successful test/feature", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m6acs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681495357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this is quite a subjective question, and so maybe the answers I&amp;#39;m looking for is just guidance on how to approach this, but &lt;strong&gt;how do you determine how you want to roll out a feature following a successful test?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;For context, we are launching an experiment on a tight timeline, let&amp;#39;s say the experiment allocates to 10% of users. &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say we find that the test is successful, we&amp;#39;re happy with results, and want to globally make the change to all users.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How do we approach how we want to phase it out? L&lt;/strong&gt;et&amp;#39;s assume just going from 10% to 100% is out of the question due to minimizing any unforeseen risks.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How would you determine what %s each &amp;quot;phase&amp;quot; should be? do we go 10-25-50-100? how long do you measure each phase for, especially if we&amp;#39;re working on a tight deadline?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you for any inputs all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m6acs", "is_robot_indexable": true, "report_reasons": null, "author": "vatom14", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m6acs/how_to_properly_roll_out_a_successful_testfeature/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m6acs/how_to_properly_roll_out_a_successful_testfeature/", "subreddit_subscribers": 872925, "created_utc": 1681495357.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been working as radiological imaging technologist for past two years without any increments and it doesn't add any new experience at all. Now the company planning to laid me off soon and to regret they informed that they won't provide any experience certificates too.\n\nNow I'm intend to start from the scratch again, I'm highly interested in data science, I did few internships in data science. But it is really hard to land into the job. I constantly applying for job but didn't even got single interview.\n\nI did few own projects but I have no idea how to build a portfolio.\n\nWhat should I do?", "author_fullname": "t2_tesccx8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is it possible for a medical Imaging Tech to be a data scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lkaej", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681447583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working as radiological imaging technologist for past two years without any increments and it doesn&amp;#39;t add any new experience at all. Now the company planning to laid me off soon and to regret they informed that they won&amp;#39;t provide any experience certificates too.&lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m intend to start from the scratch again, I&amp;#39;m highly interested in data science, I did few internships in data science. But it is really hard to land into the job. I constantly applying for job but didn&amp;#39;t even got single interview.&lt;/p&gt;\n\n&lt;p&gt;I did few own projects but I have no idea how to build a portfolio.&lt;/p&gt;\n\n&lt;p&gt;What should I do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12lkaej", "is_robot_indexable": true, "report_reasons": null, "author": "Dilly_03", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12lkaej/is_it_possible_for_a_medical_imaging_tech_to_be_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12lkaej/is_it_possible_for_a_medical_imaging_tech_to_be_a/", "subreddit_subscribers": 872925, "created_utc": 1681447583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anyone else applying for jobs right now? I\u2019ve noticed that salaries look overall lower than the last time I applied (2021), there are less postings overall, and most are requiring in office days\u2026\n\nIm also getting less callbacks vs 2021 when I had random recruiters reach out to me! When I do get a callback I\u2018m been getting lowball offers that are less than what I\u2019m making now...\n\nOnly a year or two ago, I feel like there was enough demand where you could ask for a crazy high salary and companies would agree.\u2026\n\nim lucky to be employed but I\u2019m stuck in a very stressful job with long hours.  Wish I had planned a bit better\u2026wonder if the market is going to pick up again or markets officially over saturated\u2026to apply or wait it out?", "author_fullname": "t2_bdnm56dh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job market seems to be getting less favorable by the day\u2026 do we still have negotiating power?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lfmd8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681437564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone else applying for jobs right now? I\u2019ve noticed that salaries look overall lower than the last time I applied (2021), there are less postings overall, and most are requiring in office days\u2026&lt;/p&gt;\n\n&lt;p&gt;Im also getting less callbacks vs 2021 when I had random recruiters reach out to me! When I do get a callback I\u2018m been getting lowball offers that are less than what I\u2019m making now...&lt;/p&gt;\n\n&lt;p&gt;Only a year or two ago, I feel like there was enough demand where you could ask for a crazy high salary and companies would agree.\u2026&lt;/p&gt;\n\n&lt;p&gt;im lucky to be employed but I\u2019m stuck in a very stressful job with long hours.  Wish I had planned a bit better\u2026wonder if the market is going to pick up again or markets officially over saturated\u2026to apply or wait it out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12lfmd8", "is_robot_indexable": true, "report_reasons": null, "author": "Cultural-Gear-1323", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12lfmd8/job_market_seems_to_be_getting_less_favorable_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12lfmd8/job_market_seems_to_be_getting_less_favorable_by/", "subreddit_subscribers": 872925, "created_utc": 1681437564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hey all,\n\nI need to predict when a machine will hit a threshold for wear amount (The machine will be replaced once the threshold is met), where the current wear of the machine is measured about once a month. One of the biggest causes of wear is when the machine is in use, which happens a couple times a month. There are also other factors which affect this machine's wear rate, including temperature, ect.\n\nBy looking at the scatter graph of wear amount against time, it looks to be mostly linear, although the rate is different depending on which machine I am looking at (because of the previously mentioned wear rate factors), the rate for one machine also periodically changes based on other factors not mentioned.\n\nI was going to go down the RUL approach for this problem with Survival Analysis, however before I do this, I was wondering if anyone had any advice or a better approach to use (neural network or some other form of regression). Since the current wear amount is not measured very frequently, how should the input data for the model be structured to account for these gaps of data?\n\nThanks for the help.", "author_fullname": "t2_cvsyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Predictive Maintenance method to use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12led2o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681434862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I need to predict when a machine will hit a threshold for wear amount (The machine will be replaced once the threshold is met), where the current wear of the machine is measured about once a month. One of the biggest causes of wear is when the machine is in use, which happens a couple times a month. There are also other factors which affect this machine&amp;#39;s wear rate, including temperature, ect.&lt;/p&gt;\n\n&lt;p&gt;By looking at the scatter graph of wear amount against time, it looks to be mostly linear, although the rate is different depending on which machine I am looking at (because of the previously mentioned wear rate factors), the rate for one machine also periodically changes based on other factors not mentioned.&lt;/p&gt;\n\n&lt;p&gt;I was going to go down the RUL approach for this problem with Survival Analysis, however before I do this, I was wondering if anyone had any advice or a better approach to use (neural network or some other form of regression). Since the current wear amount is not measured very frequently, how should the input data for the model be structured to account for these gaps of data?&lt;/p&gt;\n\n&lt;p&gt;Thanks for the help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12led2o", "is_robot_indexable": true, "report_reasons": null, "author": "Shuhandler", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12led2o/which_predictive_maintenance_method_to_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12led2o/which_predictive_maintenance_method_to_use/", "subreddit_subscribers": 872925, "created_utc": 1681434862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nMy coworker and I are planning to attend this year's ICML, but we don't have the personal or institutional funding to go. We were denied funding from our university (we are both staff members,) and plan to fill out the financial aid application.\n\nFor those who've sat at the other side of the table, what are you looking for in the financial aid application? We really, completely and utterly do not have any money (just out of college, living on our own, educational staff budget) and we're both women if that helps (other minority affiliations as well,) but not sure what else to write.\n\nThanks!", "author_fullname": "t2_45bgy9c3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you look for in financial aid applications to conferences?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m6m8v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681495726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;My coworker and I are planning to attend this year&amp;#39;s ICML, but we don&amp;#39;t have the personal or institutional funding to go. We were denied funding from our university (we are both staff members,) and plan to fill out the financial aid application.&lt;/p&gt;\n\n&lt;p&gt;For those who&amp;#39;ve sat at the other side of the table, what are you looking for in the financial aid application? We really, completely and utterly do not have any money (just out of college, living on our own, educational staff budget) and we&amp;#39;re both women if that helps (other minority affiliations as well,) but not sure what else to write.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m6m8v", "is_robot_indexable": true, "report_reasons": null, "author": "EasternStuff5015", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m6m8v/what_do_you_look_for_in_financial_aid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m6m8v/what_do_you_look_for_in_financial_aid/", "subreddit_subscribers": 872925, "created_utc": 1681495726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_qqy6or6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the advantage of using Machine learning in Azure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12luj28", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681472838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12luj28", "is_robot_indexable": true, "report_reasons": null, "author": "star-lord-98", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12luj28/what_is_the_advantage_of_using_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12luj28/what_is_the_advantage_of_using_machine_learning/", "subreddit_subscribers": 872925, "created_utc": 1681472838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_jlunblur", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Neuropizza: Models for spike train classification and machine learning parameter identifiability", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_12lqcjr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/gmCBxvCmf3E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Neuropizza: Models for spike train classification and machine learning parameter identifiability\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Neuropizza: Models for spike train classification and machine learning parameter identifiability", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/gmCBxvCmf3E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Neuropizza: Models for spike train classification and machine learning parameter identifiability\"&gt;&lt;/iframe&gt;", "author_name": "Alessandro Crimi", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/gmCBxvCmf3E/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@alecrimi"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/gmCBxvCmf3E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Neuropizza: Models for spike train classification and machine learning parameter identifiability\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/12lqcjr", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8lNZGkMOprrdB1ghwXatBtA54J4xbLDYB9CzK2c3Czw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681462593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=gmCBxvCmf3E", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/L-fyEboM97IOvjzJEFcLUBwj7NiSfQjKykCz78nHuQA.jpg?auto=webp&amp;v=enabled&amp;s=1cf2643d9230ada28a2f582a146b3e5908603f83", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/L-fyEboM97IOvjzJEFcLUBwj7NiSfQjKykCz78nHuQA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d62acf4c880618e6540135b3f3cd3a00fbe2045c", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/L-fyEboM97IOvjzJEFcLUBwj7NiSfQjKykCz78nHuQA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8feb3843340e170c5bd3fd3553efb7c0186021b", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/L-fyEboM97IOvjzJEFcLUBwj7NiSfQjKykCz78nHuQA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6633094d776054bca9a80602c94d88296fa2224", "width": 320, "height": 240}], "variants": {}, "id": "ISUixBol5tj9cIpOo7ZBV3bQ-qx8V_DTqB4IYfkumJA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12lqcjr", "is_robot_indexable": true, "report_reasons": null, "author": "rottoneuro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12lqcjr/neuropizza_models_for_spike_train_classification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=gmCBxvCmf3E", "subreddit_subscribers": 872925, "created_utc": 1681462593.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Neuropizza: Models for spike train classification and machine learning parameter identifiability", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/gmCBxvCmf3E?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Neuropizza: Models for spike train classification and machine learning parameter identifiability\"&gt;&lt;/iframe&gt;", "author_name": "Alessandro Crimi", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/gmCBxvCmf3E/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@alecrimi"}}, "is_video": false}}], "before": null}}