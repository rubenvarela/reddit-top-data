{"kind": "Listing", "data": {"after": "t3_12scn5c", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_c1ny1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imgur is updating their TOS on May 15, 2023: All NSFW content to be banned", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sbch3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": "", "subreddit_type": "public", "ups": 2484, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 2484, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1681940732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "imgurinc.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://imgurinc.com/rules", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "12TB RAID5", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12sbch3", "is_robot_indexable": true, "report_reasons": null, "author": "trd86", "discussion_type": null, "num_comments": 754, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12sbch3/imgur_is_updating_their_tos_on_may_15_2023_all/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://imgurinc.com/rules", "subreddit_subscribers": 678554, "created_utc": 1681940732.0, "num_crossposts": 6, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imgur is updating their TOS on May 15, 2023: All NSFW content to be banned, all content outside of a registered account (no-account uploads) to be removed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sq7ip", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 209, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_of987", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 209, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "apolloapp", "selftext": "", "author_fullname": "t2_5cymt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imgur is updating their TOS on May 15, 2023: All NSFW content to be banned, all content outside of a registered account (no-account uploads) to be removed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/apolloapp", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sjeo5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 976, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Announcement \ud83d\udce3", "can_mod_post": false, "score": 976, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1681958916.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "imgurinc.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://imgurinc.com/rules", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1ba6dd68-f254-11eb-b308-5621ae2f972b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_363lq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12sjeo5", "is_robot_indexable": true, "report_reasons": null, "author": "rekabis", "discussion_type": null, "num_comments": 220, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/apolloapp/comments/12sjeo5/imgur_is_updating_their_tos_on_may_15_2023_all/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://imgurinc.com/rules", "subreddit_subscribers": 767089, "created_utc": 1681958916.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1681976321.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "imgurinc.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://imgurinc.com/rules", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": true, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12sq7ip", "is_robot_indexable": true, "report_reasons": null, "author": "GubmintTroll", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12sjeo5", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12sq7ip/imgur_is_updating_their_tos_on_may_15_2023_all/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://imgurinc.com/rules", "subreddit_subscribers": 678554, "created_utc": 1681976321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We have to prepare ourselves for the possibility that Reddit might try to pull a Tumblr soon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sqpn6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 99, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_udbds5yu", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 99, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Archiveteam", "selftext": "Reddit has been quietly putting restrictions on NSFW subs for a while now. You can't upload videos in then anymore. You can't use Reddit's native image host in them anymore. They won't show up on [r/all](https://www.reddit.com/r/all) anymore. And now, with the upcoming API change, you soon won't be able to access them through 3rd party tools anymore. \n\nAll of this sounds to me a lot like foreplay. I wouldn't be surprised if, soon, Reddit simply pulls the plug on NSFW content altogether. Just look at what they're doing to Imgur, which might I remind you is owned by many of the same people who own Reddit. \n\nReddit, as it stands, is a relic of an older age of the Internet. Far less sanitized than other social media sites. And far less marketable. For the upcoming IPO, they want Reddit to be clean, squeaky clean.", "author_fullname": "t2_udbds5yu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We have to prepare ourselves for the possibility that Reddit might try to pull a Tumblr soon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Archiveteam", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sqopw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 94, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 94, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681977696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.Archiveteam", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Reddit has been quietly putting restrictions on NSFW subs for a while now. You can&amp;#39;t upload videos in then anymore. You can&amp;#39;t use Reddit&amp;#39;s native image host in them anymore. They won&amp;#39;t show up on &lt;a href=\"https://www.reddit.com/r/all\"&gt;r/all&lt;/a&gt; anymore. And now, with the upcoming API change, you soon won&amp;#39;t be able to access them through 3rd party tools anymore. &lt;/p&gt;\n\n&lt;p&gt;All of this sounds to me a lot like foreplay. I wouldn&amp;#39;t be surprised if, soon, Reddit simply pulls the plug on NSFW content altogether. Just look at what they&amp;#39;re doing to Imgur, which might I remind you is owned by many of the same people who own Reddit. &lt;/p&gt;\n\n&lt;p&gt;Reddit, as it stands, is a relic of an older age of the Internet. Far less sanitized than other social media sites. And far less marketable. For the upcoming IPO, they want Reddit to be clean, squeaky clean.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sug0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12sqopw", "is_robot_indexable": true, "report_reasons": null, "author": "I_got_too_silly", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Archiveteam/comments/12sqopw/we_have_to_prepare_ourselves_for_the_possibility/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/Archiveteam/comments/12sqopw/we_have_to_prepare_ourselves_for_the_possibility/", "subreddit_subscribers": 11843, "created_utc": 1681977696.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1681977769.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.Archiveteam", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/Archiveteam/comments/12sqopw/we_have_to_prepare_ourselves_for_the_possibility/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "12sqpn6", "is_robot_indexable": true, "report_reasons": null, "author": "I_got_too_silly", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12sqopw", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12sqpn6/we_have_to_prepare_ourselves_for_the_possibility/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/Archiveteam/comments/12sqopw/we_have_to_prepare_ourselves_for_the_possibility/", "subreddit_subscribers": 678554, "created_utc": 1681977769.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_yaxa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shutting down Legit Torrents after 17 years", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sy755", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 81, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 81, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1681996304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "legittorrents.info", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.legittorrents.info/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12sy755", "is_robot_indexable": true, "report_reasons": null, "author": "en3r0", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12sy755/shutting_down_legit_torrents_after_17_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.legittorrents.info/", "subreddit_subscribers": 678554, "created_utc": 1681996304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know this is kind of rough, but I threw this together in under a couple of hours since finding out about this change.\n\nOne thought I had - if you wanted to archive a bunch of imgur posts, there are sites like 'jizz2' that already made a huge archive of Reddit's NSFW subreddit posts and just repost imgur links. This can be abused to iterate over their collection and pull imgur posts by filter. I gave it a try and wrote a simple scraper with a filter for the desired content type to save: [https://pastebin.com/RytFpAnE](https://pastebin.com/RytFpAnE)\n\nIt shouldn't be too hard to modify for other sites with a similar structure. I found one called 'znsfw' and another '8xxx'. With the help of hoarders on here, this content can be captured and archived. I imagine it'd take longer than one month to pull all 18 million images or so that the site scraped from reddit.\n\nI think the pushshift API could also be used against a reddit NSFW subreddit to more directly query images and just iterate over that to scrape them.\n\nLet me know what you think.\n\nAutoModerator let me know that scripts need to have a license mentioned. Consider this licensed under the WTFPL. [http://www.wtfpl.net/](http://www.wtfpl.net/)", "author_fullname": "t2_34aej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Method of archiving Imgur NSFW content by scraping sites that already scraped it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sgl8x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681952272.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this is kind of rough, but I threw this together in under a couple of hours since finding out about this change.&lt;/p&gt;\n\n&lt;p&gt;One thought I had - if you wanted to archive a bunch of imgur posts, there are sites like &amp;#39;jizz2&amp;#39; that already made a huge archive of Reddit&amp;#39;s NSFW subreddit posts and just repost imgur links. This can be abused to iterate over their collection and pull imgur posts by filter. I gave it a try and wrote a simple scraper with a filter for the desired content type to save: &lt;a href=\"https://pastebin.com/RytFpAnE\"&gt;https://pastebin.com/RytFpAnE&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It shouldn&amp;#39;t be too hard to modify for other sites with a similar structure. I found one called &amp;#39;znsfw&amp;#39; and another &amp;#39;8xxx&amp;#39;. With the help of hoarders on here, this content can be captured and archived. I imagine it&amp;#39;d take longer than one month to pull all 18 million images or so that the site scraped from reddit.&lt;/p&gt;\n\n&lt;p&gt;I think the pushshift API could also be used against a reddit NSFW subreddit to more directly query images and just iterate over that to scrape them.&lt;/p&gt;\n\n&lt;p&gt;Let me know what you think.&lt;/p&gt;\n\n&lt;p&gt;AutoModerator let me know that scripts need to have a license mentioned. Consider this licensed under the WTFPL. &lt;a href=\"http://www.wtfpl.net/\"&gt;http://www.wtfpl.net/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?auto=webp&amp;v=enabled&amp;s=decc328886393c0699bb01cf9d08b602f60525c8", "width": 150, "height": 150}, "resolutions": [{"url": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3cda4e996a0e1c77c65ec3810a634071f4573481", "width": 108, "height": 108}], "variants": {"obfuscated": {"source": {"url": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?blur=40&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3798b5a122c492b0848c441e79f69e6cb40b0244", "width": 150, "height": 150}, "resolutions": [{"url": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=b006012d8862313f71d75720fde9f07ec79de403", "width": 108, "height": 108}]}, "nsfw": {"source": {"url": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?blur=40&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3798b5a122c492b0848c441e79f69e6cb40b0244", "width": 150, "height": 150}, "resolutions": [{"url": "https://external-preview.redd.it/-WiKXADWH5lgU4gQv5fcDAQ9QKNBZTJ-D83BykIL2HA.jpg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=b006012d8862313f71d75720fde9f07ec79de403", "width": 108, "height": 108}]}}, "id": "OgFzGCIRw1ZxjMOSkfV1OiH-_nQiZl8rzSonmOAuhGs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "48TB (8x6TB RAIDZ2)", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12sgl8x", "is_robot_indexable": true, "report_reasons": null, "author": "aliendude5300", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12sgl8x/method_of_archiving_imgur_nsfw_content_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12sgl8x/method_of_archiving_imgur_nsfw_content_by/", "subreddit_subscribers": 678554, "created_utc": 1681952272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've seen a few other posts about this, but it doesn't look like we've seen an effort to create an easily accessible/downloadable archive/repository of it. Perhaps we could start a torrent of it, if it hasn't been done already?", "author_fullname": "t2_kbghbz2m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone started a torrent to archive this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "name": "t3_12saxlz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/ygLDtYLPyQg0UZdLpG8-kHz7LP168uHB74vOhyxyUJM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681939925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "openculture.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen a few other posts about this, but it doesn&amp;#39;t look like we&amp;#39;ve seen an effort to create an easily accessible/downloadable archive/repository of it. Perhaps we could start a torrent of it, if it hasn&amp;#39;t been done already?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.openculture.com/2023/04/the-smithsonian-puts-4-5-million-high-res-images-online.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T737sjWSBwA3kN2hPI4fxKTZpz71o9WukGVqhQ2DlA4.jpg?auto=webp&amp;v=enabled&amp;s=2587981b52c6be0a39cdfdc34fb8fb8bed308580", "width": 1024, "height": 506}, "resolutions": [{"url": "https://external-preview.redd.it/T737sjWSBwA3kN2hPI4fxKTZpz71o9WukGVqhQ2DlA4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4cd4c692e249904043a56b53bc7c34ad58a5db9", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/T737sjWSBwA3kN2hPI4fxKTZpz71o9WukGVqhQ2DlA4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a96870444ddc1aff0980ebe5ddcc2d1bef9a36a1", "width": 216, "height": 106}, {"url": "https://external-preview.redd.it/T737sjWSBwA3kN2hPI4fxKTZpz71o9WukGVqhQ2DlA4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=afac42a081556c31c973ed16a25b3beb242b6d75", "width": 320, "height": 158}, {"url": "https://external-preview.redd.it/T737sjWSBwA3kN2hPI4fxKTZpz71o9WukGVqhQ2DlA4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efba26886f141328606466be531057601b59bd4d", "width": 640, "height": 316}, {"url": "https://external-preview.redd.it/T737sjWSBwA3kN2hPI4fxKTZpz71o9WukGVqhQ2DlA4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04fb78c09a4b07a789f095a47dbdc3e6374f764d", "width": 960, "height": 474}], "variants": {}, "id": "rIZfRnlfU3WEU0jFMiN_Be1posuuQ9GIHQB1MSFQsns"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "12saxlz", "is_robot_indexable": true, "report_reasons": null, "author": "PoisonWaffle3", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12saxlz/has_anyone_started_a_torrent_to_archive_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.openculture.com/2023/04/the-smithsonian-puts-4-5-million-high-res-images-online.html", "subreddit_subscribers": 678554, "created_utc": 1681939925.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_3qve30kb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "reddit-img-dl: Tool to download media and comments from subreddits or reddit users. Its a fork of the The-Eye-Team/reddit-dl with additional features. I worked on this afew years ago, but it might be useful to the people here with the recent reddit and imgur changes.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12t4ohz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1682004665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/IceWreck/reddit-img-dl", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12t4ohz", "is_robot_indexable": true, "report_reasons": null, "author": "HulkaBurninFudge", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12t4ohz/redditimgdl_tool_to_download_media_and_comments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/IceWreck/reddit-img-dl", "subreddit_subscribers": 678554, "created_utc": 1682004665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "With IMGUR's new anti-explicit content starting in May, what are some alternative sites that one could upload albums of explicit content, registered or not, and post to reddit? I'm open to any suggestions.", "author_fullname": "t2_5zv9ym11", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "List of NSFW Image Hosting Alternatives to IMGUR?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12shpt1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681954974.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With IMGUR&amp;#39;s new anti-explicit content starting in May, what are some alternative sites that one could upload albums of explicit content, registered or not, and post to reddit? I&amp;#39;m open to any suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "12shpt1", "is_robot_indexable": true, "report_reasons": null, "author": "AveryAces0828", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12shpt1/list_of_nsfw_image_hosting_alternatives_to_imgur/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12shpt1/list_of_nsfw_image_hosting_alternatives_to_imgur/", "subreddit_subscribers": 678554, "created_utc": 1681954974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hope this is allowed! I figure you guys must know the best.\n\n&amp;#x200B;\n\nI have purchased a new hard drive which I use to store research I do for my job. I have about 5TB to store. I've always used Windows but have started using a Macbook Air for working remotely, and stumbled on the issue of not being able to copy stuff to my new drive because I initially used it on Windows.\n\n&amp;#x200B;\n\nAnyway, google says exFAT 32 should be my go-to so I can use it on Mac and Windows, but on Quora I read multiple comments saying stuff like\n\n&amp;#x200B;\n\n\\- \"\\[The drive\\] will have no security at all for one thing. ExFat may have some limitations that cause problems\\[....\\] It will have no journaling so it is subject to data corruption. and can become unusable, even if a lot of data has alerady been put on it\u2026 This is one reason it works for small file transfer, but not suitable for file backup.\"\n\n\\- \"ExFAT is functional, if an outdated, filesystem. It\u2019s prone to fragmentation (on mechanical drives, this may be a problem), has some peculiar limitations on file names, etc., but it is simple and it works for simple data transfer. Be mindful, however, that things like file permissions, ownership, properties, and whatnot will not behave as expected.\"\n\n&amp;#x200B;\n\nI will almost exclusively use this drive on a Mac. I will be travelling just with the Mac and if the above statements are true I'd rather just keep it formatted exclusively for Mac usage. I can't risk being in another country and having these issues. Being able to use Windows is a maybe but Mac is the must.\n\n&amp;#x200B;\n\nWhat's your advice? Thanks in advance!", "author_fullname": "t2_90me57qk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is formatting a hard drive to exFAT 32 safe? Reading some spooky stuff", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sfbwt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681949457.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681949269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hope this is allowed! I figure you guys must know the best.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have purchased a new hard drive which I use to store research I do for my job. I have about 5TB to store. I&amp;#39;ve always used Windows but have started using a Macbook Air for working remotely, and stumbled on the issue of not being able to copy stuff to my new drive because I initially used it on Windows.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Anyway, google says exFAT 32 should be my go-to so I can use it on Mac and Windows, but on Quora I read multiple comments saying stuff like&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;[The drive] will have no security at all for one thing. ExFat may have some limitations that cause problems[....] It will have no journaling so it is subject to data corruption. and can become unusable, even if a lot of data has alerady been put on it\u2026 This is one reason it works for small file transfer, but not suitable for file backup.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;ExFAT is functional, if an outdated, filesystem. It\u2019s prone to fragmentation (on mechanical drives, this may be a problem), has some peculiar limitations on file names, etc., but it is simple and it works for simple data transfer. Be mindful, however, that things like file permissions, ownership, properties, and whatnot will not behave as expected.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I will almost exclusively use this drive on a Mac. I will be travelling just with the Mac and if the above statements are true I&amp;#39;d rather just keep it formatted exclusively for Mac usage. I can&amp;#39;t risk being in another country and having these issues. Being able to use Windows is a maybe but Mac is the must.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your advice? Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12sfbwt", "is_robot_indexable": true, "report_reasons": null, "author": "Powerful-Employer-20", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12sfbwt/is_formatting_a_hard_drive_to_exfat_32_safe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12sfbwt/is_formatting_a_hard_drive_to_exfat_32_safe/", "subreddit_subscribers": 678554, "created_utc": 1681949269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have over 100 URLs of bookmarks I\u2019ve collected over the years saved in a file. My question is if I wanted to permanently save the actual pages themselves (articles, essays, blog posts etc) what would be the best and easiest way to do it?\n\nIs making a PDF or an HTML file of the page in question sufficient?", "author_fullname": "t2_gfj7b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s the best way to save a webpage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12t6c63", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1682009102.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682006868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have over 100 URLs of bookmarks I\u2019ve collected over the years saved in a file. My question is if I wanted to permanently save the actual pages themselves (articles, essays, blog posts etc) what would be the best and easiest way to do it?&lt;/p&gt;\n\n&lt;p&gt;Is making a PDF or an HTML file of the page in question sufficient?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12t6c63", "is_robot_indexable": true, "report_reasons": null, "author": "Cmyers1980", "discussion_type": null, "num_comments": 6, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12t6c63/whats_the_best_way_to_save_a_webpage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12t6c63/whats_the_best_way_to_save_a_webpage/", "subreddit_subscribers": 678554, "created_utc": 1682006868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So i am currently running httrack for pretty large web backup projects (looking for newer alternatives tho)\n\n**What are your recommendations for deduplication of the downloaded files?**  \n(currently saving everything on a zfs pool with dedup/compression enabled)\n\n**Are there scripts for changing the local urls within the downloaded pages afterwards?**  \nLets say i download [example.com](https://example.com) and [forum.example.com](https://forum.example.com) separatly a couple weeks apart, since they are different projects within httrack all links that go to the other one are still refering to the original instead of the download (if an [forum.example.com](https://forum.example.com) site is linked within an [example.com](https://example.com) site it is still linking to the original [forum.example.com](https://forum.example.com) instad of the downloaded one) which makes sense since httrack didnt know it existed when it was downloaded but is there a way to change is later down the line? Basically a script that goes though all html files and replaces the external domains with internal ones?\n\n**What settings do you use? What to look out for to get the best performance and backup?**", "author_fullname": "t2_8jnr5wv6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HTTRack Discussion | deduplication, merging &amp; optimal settings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12szkc3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681999070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i am currently running httrack for pretty large web backup projects (looking for newer alternatives tho)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What are your recommendations for deduplication of the downloaded files?&lt;/strong&gt;&lt;br/&gt;\n(currently saving everything on a zfs pool with dedup/compression enabled)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Are there scripts for changing the local urls within the downloaded pages afterwards?&lt;/strong&gt;&lt;br/&gt;\nLets say i download &lt;a href=\"https://example.com\"&gt;example.com&lt;/a&gt; and &lt;a href=\"https://forum.example.com\"&gt;forum.example.com&lt;/a&gt; separatly a couple weeks apart, since they are different projects within httrack all links that go to the other one are still refering to the original instead of the download (if an &lt;a href=\"https://forum.example.com\"&gt;forum.example.com&lt;/a&gt; site is linked within an &lt;a href=\"https://example.com\"&gt;example.com&lt;/a&gt; site it is still linking to the original &lt;a href=\"https://forum.example.com\"&gt;forum.example.com&lt;/a&gt; instad of the downloaded one) which makes sense since httrack didnt know it existed when it was downloaded but is there a way to change is later down the line? Basically a script that goes though all html files and replaces the external domains with internal ones?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What settings do you use? What to look out for to get the best performance and backup?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "12szkc3", "is_robot_indexable": true, "report_reasons": null, "author": "Pommes254", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12szkc3/httrack_discussion_deduplication_merging_optimal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12szkc3/httrack_discussion_deduplication_merging_optimal/", "subreddit_subscribers": 678554, "created_utc": 1681999070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "They used to be able to grab the .m3u8 file pretty easily and get the file. \nHowever, now they are possibly using DASH or maybe even .m3u8, but no sniffers are able to find it. They use (from what I have seen), two different video players THEOplayer and bitmovin player. They are also now using DRM protection.\n\nMost people I have spoken to are using OBS to just record it, however, unfortunately, my computer kind of sucks for doing stuff like that. Which results in choppy playback at some points.\n\nDoes anyone here (figured this may be one of the only places someone might) know how to still grab the file and download using FFMPEG?", "author_fullname": "t2_h5d1uatv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LivePhish has been updated", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12su2j8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681986853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;They used to be able to grab the .m3u8 file pretty easily and get the file. \nHowever, now they are possibly using DASH or maybe even .m3u8, but no sniffers are able to find it. They use (from what I have seen), two different video players THEOplayer and bitmovin player. They are also now using DRM protection.&lt;/p&gt;\n\n&lt;p&gt;Most people I have spoken to are using OBS to just record it, however, unfortunately, my computer kind of sucks for doing stuff like that. Which results in choppy playback at some points.&lt;/p&gt;\n\n&lt;p&gt;Does anyone here (figured this may be one of the only places someone might) know how to still grab the file and download using FFMPEG?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12su2j8", "is_robot_indexable": true, "report_reasons": null, "author": "GoldPhysical", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12su2j8/livephish_has_been_updated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12su2j8/livephish_has_been_updated/", "subreddit_subscribers": 678554, "created_utc": 1681986853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm merging dashcam files using bandicam on an HDD that has 400gb of free space. The output file is under 100gb - but I'm getting an error 70% of the way through saying \"not enough disk space on output folder\".\n\nWhat could be the reason for this?", "author_fullname": "t2_n7q75", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Not enough disk space, please change output folder\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12td88j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682020650.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m merging dashcam files using bandicam on an HDD that has 400gb of free space. The output file is under 100gb - but I&amp;#39;m getting an error 70% of the way through saying &amp;quot;not enough disk space on output folder&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;What could be the reason for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12td88j", "is_robot_indexable": true, "report_reasons": null, "author": "StarSurf", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12td88j/not_enough_disk_space_please_change_output_folder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12td88j/not_enough_disk_space_please_change_output_folder/", "subreddit_subscribers": 678554, "created_utc": 1682020650.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a lot of HDD's used on eBay and the seller stated they were all operating as they should. All but one contains some sort of error but this one confused me. Should I be using this drive? Any help is appreciated. Thank you!\n\n    Complete error log:\n    \n    SMART Extended Comprehensive Error Log Version: 1 (6 sectors)\n    Device Error Count: 1\n    \tCR     = Command Register\n    \tFEATR  = Features Register\n    \tCOUNT  = Count (was: Sector Count) Register\n    \tLBA_48 = Upper bytes of LBA High/Mid/Low Registers ]  ATA-8\n    \tLH     = LBA High (was: Cylinder High) Register    ]   LBA\n    \tLM     = LBA Mid (was: Cylinder Low) Register      ] Register\n    \tLL     = LBA Low (was: Sector Number) Register     ]\n    \tDV     = Device (was: Device/Head) Register\n    \tDC     = Device Control Register\n    \tER     = Error register\n    \tST     = Status register\n    Powered_Up_Time is measured from power on, and printed as\n    DDd+hh:mm:SS.sss where DD=days, hh=hours, mm=minutes,\n    SS=sec, and sss=millisec. It \"wraps\" after 49.710 days.\n    \n    Error 1 [0] occurred at disk power-on lifetime: 1321 hours (55 days + 1 hours)\n      When the command that caused the error occurred, the device was active or idle.\n    \n      After command completion occurred, registers were:\n      ER -- ST COUNT  LBA_48  LH LM LL DV DC\n      -- -- -- == -- == == == -- -- -- -- --\n      04 -- 51 00 01 00 00 00 00 00 00 40 00  Error: ABRT\n    \n      Commands leading to the command that caused the error were:\n      CR FEATR COUNT  LBA_48  LH LM LL DV DC  Powered_Up_Time  Command/Feature_Name\n      -- == -- == -- == == == -- -- -- -- --  ---------------  --------------------\n      3f 00 00 00 01 00 00 00 00 00 e0 40 00     00:00:02.250  WRITE LOG EXT\n      ec 00 00 00 00 00 00 00 00 00 00 00 00     00:00:02.250  IDENTIFY DEVICE\n      b0 00 d0 00 00 00 00 00 c2 4f 00 00 00     00:00:02.246  SMART READ DATA\n      ec 00 00 00 00 00 00 00 00 00 00 00 00     00:00:02.246  IDENTIFY DEVICE\n      b0 00 d0 00 00 00 00 00 c2 4f 00 00 00     00:00:02.242  SMART READ DATA", "author_fullname": "t2_11naa8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the meaning of this error given by GSmartControl?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12szliz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681999137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a lot of HDD&amp;#39;s used on eBay and the seller stated they were all operating as they should. All but one contains some sort of error but this one confused me. Should I be using this drive? Any help is appreciated. Thank you!&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Complete error log:\n\nSMART Extended Comprehensive Error Log Version: 1 (6 sectors)\nDevice Error Count: 1\n    CR     = Command Register\n    FEATR  = Features Register\n    COUNT  = Count (was: Sector Count) Register\n    LBA_48 = Upper bytes of LBA High/Mid/Low Registers ]  ATA-8\n    LH     = LBA High (was: Cylinder High) Register    ]   LBA\n    LM     = LBA Mid (was: Cylinder Low) Register      ] Register\n    LL     = LBA Low (was: Sector Number) Register     ]\n    DV     = Device (was: Device/Head) Register\n    DC     = Device Control Register\n    ER     = Error register\n    ST     = Status register\nPowered_Up_Time is measured from power on, and printed as\nDDd+hh:mm:SS.sss where DD=days, hh=hours, mm=minutes,\nSS=sec, and sss=millisec. It &amp;quot;wraps&amp;quot; after 49.710 days.\n\nError 1 [0] occurred at disk power-on lifetime: 1321 hours (55 days + 1 hours)\n  When the command that caused the error occurred, the device was active or idle.\n\n  After command completion occurred, registers were:\n  ER -- ST COUNT  LBA_48  LH LM LL DV DC\n  -- -- -- == -- == == == -- -- -- -- --\n  04 -- 51 00 01 00 00 00 00 00 00 40 00  Error: ABRT\n\n  Commands leading to the command that caused the error were:\n  CR FEATR COUNT  LBA_48  LH LM LL DV DC  Powered_Up_Time  Command/Feature_Name\n  -- == -- == -- == == == -- -- -- -- --  ---------------  --------------------\n  3f 00 00 00 01 00 00 00 00 00 e0 40 00     00:00:02.250  WRITE LOG EXT\n  ec 00 00 00 00 00 00 00 00 00 00 00 00     00:00:02.250  IDENTIFY DEVICE\n  b0 00 d0 00 00 00 00 00 c2 4f 00 00 00     00:00:02.246  SMART READ DATA\n  ec 00 00 00 00 00 00 00 00 00 00 00 00     00:00:02.246  IDENTIFY DEVICE\n  b0 00 d0 00 00 00 00 00 c2 4f 00 00 00     00:00:02.242  SMART READ DATA\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12szliz", "is_robot_indexable": true, "report_reasons": null, "author": "bravemenrun", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12szliz/what_is_the_meaning_of_this_error_given_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12szliz/what_is_the_meaning_of_this_error_given_by/", "subreddit_subscribers": 678554, "created_utc": 1681999137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I relocate overseas for a few months each year, and I am looking for a portable solution.\n\nI am restricted by international travel weight restrictions, so would rather not have anything too heavy.\n\nAt home i run a 4 x 3tb Ironwolf softraid which currently backs up my 2 x 5tb seagate portable drives and macbook.\n\nI usually take the macbook and portable drives overseas with me. One of the 5tb for movies and the other for archived data that i may need. The macbook backups onto the data drive while I am away as a I only add a few gigs. This archive drive is nearly full and the movie drive tired so hence the need for expansion.\n\nMy current thought is either get a Synology DS220j with a single 16tb drive for now which I can expand later or the WD 16 TB Elements Desktop External USBC Hard Drive.   \nThis would allow me to add one of my 5tb portable drives to my softraid, and using the other as an offsite backup as it is getting old and isn't much use for anything else.\n\nDoes anyone have any other ideas?", "author_fullname": "t2_1gm1x1ds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Semi-Portable NAS option? Currently looking at Synology DS220j but would a large external drive be better?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sv8lu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681989723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I relocate overseas for a few months each year, and I am looking for a portable solution.&lt;/p&gt;\n\n&lt;p&gt;I am restricted by international travel weight restrictions, so would rather not have anything too heavy.&lt;/p&gt;\n\n&lt;p&gt;At home i run a 4 x 3tb Ironwolf softraid which currently backs up my 2 x 5tb seagate portable drives and macbook.&lt;/p&gt;\n\n&lt;p&gt;I usually take the macbook and portable drives overseas with me. One of the 5tb for movies and the other for archived data that i may need. The macbook backups onto the data drive while I am away as a I only add a few gigs. This archive drive is nearly full and the movie drive tired so hence the need for expansion.&lt;/p&gt;\n\n&lt;p&gt;My current thought is either get a Synology DS220j with a single 16tb drive for now which I can expand later or the WD 16 TB Elements Desktop External USBC Hard Drive.&lt;br/&gt;\nThis would allow me to add one of my 5tb portable drives to my softraid, and using the other as an offsite backup as it is getting old and isn&amp;#39;t much use for anything else.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any other ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12sv8lu", "is_robot_indexable": true, "report_reasons": null, "author": "matmah", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12sv8lu/semiportable_nas_option_currently_looking_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12sv8lu/semiportable_nas_option_currently_looking_at/", "subreddit_subscribers": 678554, "created_utc": 1681989723.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just wondering if any way to integrate idrive into windows explorer to use it like a network drive. I know it can be done with certain other cloud solutions but havent come across anything for Idrive as of yet. Thanks", "author_fullname": "t2_7kpe57ug", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any Software or Tricks to Integrate Idrive folders in windows explorer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12segqt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681947290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wondering if any way to integrate idrive into windows explorer to use it like a network drive. I know it can be done with certain other cloud solutions but havent come across anything for Idrive as of yet. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12segqt", "is_robot_indexable": true, "report_reasons": null, "author": "Secure_Pomegranate_1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12segqt/is_there_any_software_or_tricks_to_integrate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12segqt/is_there_any_software_or_tricks_to_integrate/", "subreddit_subscribers": 678554, "created_utc": 1681947290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have &gt; 100 million image files (book covers) as a flat list of files under a single \"folder\":\n\n    /images/000000093e7d1825b346e9fc01387c7e449e1ed7\n    /images/000000574c67d7b8c5726f7cfd7bb1c5b3ae2ddf\n    /images/0000005ae12097d69208f6548bf600bd7d270a6f\n    ...\n\nThese were originally stored in Amazon S3, and are now on Backblaze B2.\n\nWhen I made the migration, I don't remember encountering any particular issue (but the number of files was maybe significantly lower).\n\nI'm in the process of migrating once again, to iDrive E2.\n\nI'm experimenting with moving them using rclone, but after 30 min of waiting for `rclone copy` to start, I realized that rclone does not start transferring files until it has received the whole file list.\n\nThe problem is:\n\n* a quick benchmark of `rclone ls` on the folder tells me that transferring the whole file list would take almost 10 hours\n* any problem during transfer (which will take many days) would restart from zero, forcing rclone to download the whole file list again\n* listing files [costs money](https://www.backblaze.com/b2/b2-transactions-price.html) with B2\n\nI tried configuring rclone to copy only a batch of files:\n\n* `rclone copy \"backblaze:/images/0000*\"`, with or without `*`, does not find any file\n* `rclone copy \"backblaze:/images/\" --include \"/0000*\"` seems to download the whole file list as well, and filter on the client\n\nStrangely, it looks like rclone has no problem filtering server-side all files that are under a given \"directory\", for example `/images/`, but cannot do the same with a prefix, such as `/images/0000`.\n\nI thought that S3, and by extension all S3-compatible storages, stored file paths as a flat structure, and that `/` was just a character like any other, and that you could easily list files **under any prefix, ending or not with a** `/`.\n\nAm I mistaken?\n\nI my next storage (E2), should I store files under sub-directories, such as `images/0/0/0/0/`, `images/0/0/0/1`, etc., just like we did in the good old days of storing files in a traditional filesystem?", "author_fullname": "t2_1w4eol1w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storing 100 million files in the same \"folder\" under S3-compatible storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sbk95", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681941169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have &amp;gt; 100 million image files (book covers) as a flat list of files under a single &amp;quot;folder&amp;quot;:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;/images/000000093e7d1825b346e9fc01387c7e449e1ed7\n/images/000000574c67d7b8c5726f7cfd7bb1c5b3ae2ddf\n/images/0000005ae12097d69208f6548bf600bd7d270a6f\n...\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;These were originally stored in Amazon S3, and are now on Backblaze B2.&lt;/p&gt;\n\n&lt;p&gt;When I made the migration, I don&amp;#39;t remember encountering any particular issue (but the number of files was maybe significantly lower).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in the process of migrating once again, to iDrive E2.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m experimenting with moving them using rclone, but after 30 min of waiting for &lt;code&gt;rclone copy&lt;/code&gt; to start, I realized that rclone does not start transferring files until it has received the whole file list.&lt;/p&gt;\n\n&lt;p&gt;The problem is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;a quick benchmark of &lt;code&gt;rclone ls&lt;/code&gt; on the folder tells me that transferring the whole file list would take almost 10 hours&lt;/li&gt;\n&lt;li&gt;any problem during transfer (which will take many days) would restart from zero, forcing rclone to download the whole file list again&lt;/li&gt;\n&lt;li&gt;listing files &lt;a href=\"https://www.backblaze.com/b2/b2-transactions-price.html\"&gt;costs money&lt;/a&gt; with B2&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I tried configuring rclone to copy only a batch of files:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;rclone copy &amp;quot;backblaze:/images/0000*&amp;quot;&lt;/code&gt;, with or without &lt;code&gt;*&lt;/code&gt;, does not find any file&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;rclone copy &amp;quot;backblaze:/images/&amp;quot; --include &amp;quot;/0000*&amp;quot;&lt;/code&gt; seems to download the whole file list as well, and filter on the client&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Strangely, it looks like rclone has no problem filtering server-side all files that are under a given &amp;quot;directory&amp;quot;, for example &lt;code&gt;/images/&lt;/code&gt;, but cannot do the same with a prefix, such as &lt;code&gt;/images/0000&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;I thought that S3, and by extension all S3-compatible storages, stored file paths as a flat structure, and that &lt;code&gt;/&lt;/code&gt; was just a character like any other, and that you could easily list files &lt;strong&gt;under any prefix, ending or not with a&lt;/strong&gt; &lt;code&gt;/&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Am I mistaken?&lt;/p&gt;\n\n&lt;p&gt;I my next storage (E2), should I store files under sub-directories, such as &lt;code&gt;images/0/0/0/0/&lt;/code&gt;, &lt;code&gt;images/0/0/0/1&lt;/code&gt;, etc., just like we did in the good old days of storing files in a traditional filesystem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12sbk95", "is_robot_indexable": true, "report_reasons": null, "author": "bjmrl", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12sbk95/storing_100_million_files_in_the_same_folder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12sbk95/storing_100_million_files_in_the_same_folder/", "subreddit_subscribers": 678554, "created_utc": 1681941169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nI\u2019m looking for some cheap backup for files (especially photos) I have about 10k photos at like 20 gig (and counting) total. What\u2019s a good cheap online backup that won\u2019t be an arm and a leg to retrieve the backup should I need to?\n\nI was looking at storj and s3.\n\nS3 looks like murder in engress / ingress fees lol so I think they are out of the question.\n\n&amp;#x200B;\n\nI guess long story short is I have backups at home, but I want to use offsite backup, but also don't want to pay an arm and a leg to grab those / upload those if I should need to. Which I am sure I will eventually. \n\n&amp;#x200B;\n\nThere is inode, iDrive, pcloud, wasabi, aws, etc.", "author_fullname": "t2_4f5t898d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "backing Up Family Photos, etc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sb0h5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681940087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking for some cheap backup for files (especially photos) I have about 10k photos at like 20 gig (and counting) total. What\u2019s a good cheap online backup that won\u2019t be an arm and a leg to retrieve the backup should I need to?&lt;/p&gt;\n\n&lt;p&gt;I was looking at storj and s3.&lt;/p&gt;\n\n&lt;p&gt;S3 looks like murder in engress / ingress fees lol so I think they are out of the question.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I guess long story short is I have backups at home, but I want to use offsite backup, but also don&amp;#39;t want to pay an arm and a leg to grab those / upload those if I should need to. Which I am sure I will eventually. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;There is inode, iDrive, pcloud, wasabi, aws, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "To the Cloud!", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12sb0h5", "is_robot_indexable": true, "report_reasons": null, "author": "Steeler_Train", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12sb0h5/backing_up_family_photos_etc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12sb0h5/backing_up_family_photos_etc/", "subreddit_subscribers": 678554, "created_utc": 1681940087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I built a PerfectMediaServer using MergerFS across 4 SAS drives and then laid SnapRaid onto it using 1 parity and 3 data disks.\n\nI'd like to spin everything down when not in use if possible. \n\nI have snapraid-runner doing things nightly and smartd monitoring and alerting on anomalies.   \n\n\nWhat's the best way to make the default condition for my server to have all the drive spun down and not spinning?   \nIs this wise?   \nThis is my \"archive\" and I maybe write or read data to it (large chunks) once a week, twice at most.\n\nso aside from those actions, nightly snapraid-runner jobs, and whatever smartd is doing, they should probably just sleep, right?  \n\n\nAny helps or shoves in the right direction would be great! thanks!", "author_fullname": "t2_7ym8o61t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Sleep SAS drives when not in use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sace8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681938762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I built a PerfectMediaServer using MergerFS across 4 SAS drives and then laid SnapRaid onto it using 1 parity and 3 data disks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to spin everything down when not in use if possible. &lt;/p&gt;\n\n&lt;p&gt;I have snapraid-runner doing things nightly and smartd monitoring and alerting on anomalies.   &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best way to make the default condition for my server to have all the drive spun down and not spinning?&lt;br/&gt;\nIs this wise?&lt;br/&gt;\nThis is my &amp;quot;archive&amp;quot; and I maybe write or read data to it (large chunks) once a week, twice at most.&lt;/p&gt;\n\n&lt;p&gt;so aside from those actions, nightly snapraid-runner jobs, and whatever smartd is doing, they should probably just sleep, right?  &lt;/p&gt;\n\n&lt;p&gt;Any helps or shoves in the right direction would be great! thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12sace8", "is_robot_indexable": true, "report_reasons": null, "author": "BoyleTheOcean", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12sace8/how_to_sleep_sas_drives_when_not_in_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12sace8/how_to_sleep_sas_drives_when_not_in_use/", "subreddit_subscribers": 678554, "created_utc": 1681938762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I just built a new PC and in addition to the m.2 drive I grabbed a new 16TB drive to go with it. I\u2019ll eventually be moving over the 40TB of data I have on my old PC as well.\n\nSo BIOS does not recognize the drive at all. Tried all dif SATA ports, cables etc. Put the drive in my old computer and shows up just fine. Dug up an old junk 2TB drive and connected to the same exact port/cables on the new machine and it shows up clear as day in BIOS.\n\nWhy would 1 SATA drive be recognized and another not, when that same drive IS recognized on another machine?\n\nI\u2019ve finally gotten through all the other little issues on the new PC so I\u2019m eager to get this resolved, especially if I need to return the drive.", "author_fullname": "t2_g2z4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HELP! HDD working on one PC and not another?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12s92a7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681936188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I just built a new PC and in addition to the m.2 drive I grabbed a new 16TB drive to go with it. I\u2019ll eventually be moving over the 40TB of data I have on my old PC as well.&lt;/p&gt;\n\n&lt;p&gt;So BIOS does not recognize the drive at all. Tried all dif SATA ports, cables etc. Put the drive in my old computer and shows up just fine. Dug up an old junk 2TB drive and connected to the same exact port/cables on the new machine and it shows up clear as day in BIOS.&lt;/p&gt;\n\n&lt;p&gt;Why would 1 SATA drive be recognized and another not, when that same drive IS recognized on another machine?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve finally gotten through all the other little issues on the new PC so I\u2019m eager to get this resolved, especially if I need to return the drive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12s92a7", "is_robot_indexable": true, "report_reasons": null, "author": "AvsWon33", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12s92a7/help_hdd_working_on_one_pc_and_not_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12s92a7/help_hdd_working_on_one_pc_and_not_another/", "subreddit_subscribers": 678554, "created_utc": 1681936188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for a book scanner to digitize a large collection of books for a project. The scanner should handle various book sizes and types and scan books accurately without causing any damage. The scans need to be high-resolution with clear and sharp images for digital archiving and printing purposes. Open to considering options across different budgets. Please share any experience or recommendations for the best professional book scanner. Thank you!", "author_fullname": "t2_cv6pdkug", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing Book Scanner? Need Recommendation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12tb9z1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682016650.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for a book scanner to digitize a large collection of books for a project. The scanner should handle various book sizes and types and scan books accurately without causing any damage. The scans need to be high-resolution with clear and sharp images for digital archiving and printing purposes. Open to considering options across different budgets. Please share any experience or recommendations for the best professional book scanner. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12tb9z1", "is_robot_indexable": true, "report_reasons": null, "author": "InterestingEmploy669", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12tb9z1/choosing_book_scanner_need_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12tb9z1/choosing_book_scanner_need_recommendation/", "subreddit_subscribers": 678554, "created_utc": 1682016650.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I have a Synology with 2  identical disks (6tb each) but it seems one of them is dying. I got an  email saying it was failing with this on the SMART: Multi\\_zone\\_error\\_rate 1\n\nI tried running a fast SMART and all was ok, but the extended SMART won\u2019t go over 90%, so I am assuming the disk is not ok.\n\nThis a WD RED from 2019, model WDC-WD60EFRX-68L0BN1\n\nI have a few questions I would like your help with, but a bit of an insight about the situation first.\n\nThe NAS is at my parents house  and I am currently in another country. They will swap the disk for me,  but I am buying a new one where I am as it is way cheaper. A friend of  mine will be visiting me and taking the disk  with him, so I will have to wait 3 weeks until I can replace it.\n\n&amp;#x200B;\n\n1. Is  the disk done for, or it just one part of it that is not OK? Being the  later, I am assuming I could use it as a tertiary backup?\n2. If  the disk is done for, should I remove it from the NAS? This question is more on the fact the NAS as a mirror (SHR) and I am afraid the bad disk data  might affect the  good one?\n3. I  am swapping the disk wit a bigger one (from 6 to 8tb). I am aware I  will only have 6tb available and that is fine, but I prefer swapping the  other at a later date  and have different manufacture dates. How does that work? Can I swap  one disk and wait for it to rebuild? And at a later date do it again,  but there will be an extra step to increase the size?\n\n&amp;#x200B;\n\nThank you for your help", "author_fullname": "t2_f4cphpgz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replace disk on synology for bigger one", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sz4ad", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681998150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Synology with 2  identical disks (6tb each) but it seems one of them is dying. I got an  email saying it was failing with this on the SMART: Multi_zone_error_rate 1&lt;/p&gt;\n\n&lt;p&gt;I tried running a fast SMART and all was ok, but the extended SMART won\u2019t go over 90%, so I am assuming the disk is not ok.&lt;/p&gt;\n\n&lt;p&gt;This a WD RED from 2019, model WDC-WD60EFRX-68L0BN1&lt;/p&gt;\n\n&lt;p&gt;I have a few questions I would like your help with, but a bit of an insight about the situation first.&lt;/p&gt;\n\n&lt;p&gt;The NAS is at my parents house  and I am currently in another country. They will swap the disk for me,  but I am buying a new one where I am as it is way cheaper. A friend of  mine will be visiting me and taking the disk  with him, so I will have to wait 3 weeks until I can replace it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is  the disk done for, or it just one part of it that is not OK? Being the  later, I am assuming I could use it as a tertiary backup?&lt;/li&gt;\n&lt;li&gt;If  the disk is done for, should I remove it from the NAS? This question is more on the fact the NAS as a mirror (SHR) and I am afraid the bad disk data  might affect the  good one?&lt;/li&gt;\n&lt;li&gt;I  am swapping the disk wit a bigger one (from 6 to 8tb). I am aware I  will only have 6tb available and that is fine, but I prefer swapping the  other at a later date  and have different manufacture dates. How does that work? Can I swap  one disk and wait for it to rebuild? And at a later date do it again,  but there will be an extra step to increase the size?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12sz4ad", "is_robot_indexable": true, "report_reasons": null, "author": "babs-jojo", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12sz4ad/replace_disk_on_synology_for_bigger_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12sz4ad/replace_disk_on_synology_for_bigger_one/", "subreddit_subscribers": 678554, "created_utc": 1681998150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keeping external TB NVMe SSD's connected overnight", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sqhya", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_15nb5n1c", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "MacOS", "selftext": "I've got a couple of NVMe SSD's connected via Thunderbolt to my mac mini (running ventura). \n\nWhen using a couple of different apps for the first time in the morning - Ableton, Photos, Music so far - there's a definite delay in opening files / starting up, and with Ableton, it 'forgets' the location of plugins stored on that external drive.\n\nIs there any way to make these types of drive act/look more like the internal drive and remain connected at all times (obv without creating heat or performance issues). I know they can't spin down like HDD but any advice appreciated. Thanks", "author_fullname": "t2_15nb5n1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keeping external TB NVMe SSD's connected overnight", "link_flair_richtext": [{"e": "text", "t": "Help"}], "subreddit_name_prefixed": "r/MacOS", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sqhhk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681977128.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MacOS", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a couple of NVMe SSD&amp;#39;s connected via Thunderbolt to my mac mini (running ventura). &lt;/p&gt;\n\n&lt;p&gt;When using a couple of different apps for the first time in the morning - Ableton, Photos, Music so far - there&amp;#39;s a definite delay in opening files / starting up, and with Ableton, it &amp;#39;forgets&amp;#39; the location of plugins stored on that external drive.&lt;/p&gt;\n\n&lt;p&gt;Is there any way to make these types of drive act/look more like the internal drive and remain connected at all times (obv without creating heat or performance issues). I know they can&amp;#39;t spin down like HDD but any advice appreciated. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "85adf2d4-c706-11ea-ab81-0e3be20b73c5", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2s2gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12sqhhk", "is_robot_indexable": true, "report_reasons": null, "author": "ohsomacho", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MacOS/comments/12sqhhk/keeping_external_tb_nvme_ssds_connected_overnight/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/MacOS/comments/12sqhhk/keeping_external_tb_nvme_ssds_connected_overnight/", "subreddit_subscribers": 259372, "created_utc": 1681977128.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1681977171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MacOS", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/MacOS/comments/12sqhhk/keeping_external_tb_nvme_ssds_connected_overnight/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12sqhya", "is_robot_indexable": true, "report_reasons": null, "author": "ohsomacho", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12sqhhk", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12sqhya/keeping_external_tb_nvme_ssds_connected_overnight/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/MacOS/comments/12sqhhk/keeping_external_tb_nvme_ssds_connected_overnight/", "subreddit_subscribers": 678554, "created_utc": 1681977171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking for buying a few sn640. The seller is WD authorized. The disks are brand new manufactured around 2022/7.\n\nThey told me that they can offer a free operation that they use a tool to flash this 7.68T disk to 6.4T mode and this will increase its DWPD from 0.8 to 2. And it won't impact warranty.\n\nHow does that work? Is it real? I plan to use this disk for PT/BT downloading so I probably can benefit from it.", "author_fullname": "t2_n5tzu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does reducing capacity help on DWPD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sizh5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681957929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for buying a few sn640. The seller is WD authorized. The disks are brand new manufactured around 2022/7.&lt;/p&gt;\n\n&lt;p&gt;They told me that they can offer a free operation that they use a tool to flash this 7.68T disk to 6.4T mode and this will increase its DWPD from 0.8 to 2. And it won&amp;#39;t impact warranty.&lt;/p&gt;\n\n&lt;p&gt;How does that work? Is it real? I plan to use this disk for PT/BT downloading so I probably can benefit from it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12sizh5", "is_robot_indexable": true, "report_reasons": null, "author": "Xtr_", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12sizh5/how_does_reducing_capacity_help_on_dwpd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12sizh5/how_does_reducing_capacity_help_on_dwpd/", "subreddit_subscribers": 678554, "created_utc": 1681957929.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "136 files", "author_fullname": "t2_m1h4k4in", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how do I bulk convert audio (with image built-in) to video", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12scn5c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681943372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;136 files&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12scn5c", "is_robot_indexable": true, "report_reasons": null, "author": "Wowo_80", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12scn5c/how_do_i_bulk_convert_audio_with_image_builtin_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12scn5c/how_do_i_bulk_convert_audio_with_image_builtin_to/", "subreddit_subscribers": 678554, "created_utc": 1681943372.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}