{"kind": "Listing", "data": {"after": "t3_12mso17", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_u6k3jpmi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newegg Selling Seagate's New Ironwolf Pro (CMR) 22TB for $80 off MSRP @ $399.99", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nmtyh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 74, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 74, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1681601260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "newegg.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.newegg.com/seagate-ironwolf-pro-st22000nt001-22tb/p/N82E16822185096", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12nmtyh", "is_robot_indexable": true, "report_reasons": null, "author": "TheMissingVoteBallot", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12nmtyh/newegg_selling_seagates_new_ironwolf_pro_cmr_22tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.newegg.com/seagate-ironwolf-pro-st22000nt001-22tb/p/N82E16822185096", "subreddit_subscribers": 677976, "created_utc": 1681601260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_dfgjhry0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I don't have much data (especially compared to some of you guys O_O) but I was wondering if this is a competent backup strategy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_12modde", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RY8IXSDQkHFdfVdZBwCFWFzM4KhQ-8to4z_vva_MxYw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681529322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/39c54kegwyta1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/39c54kegwyta1.png?auto=webp&amp;v=enabled&amp;s=5a25f22a9f5058970fff2cb0e5b7a3392a6ada03", "width": 4000, "height": 2250}, "resolutions": [{"url": "https://preview.redd.it/39c54kegwyta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d5eced2dc69d235483a2d00daf25f057996dfea3", "width": 108, "height": 60}, {"url": "https://preview.redd.it/39c54kegwyta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92e313366dbf5df03564efe8980df2d7364a2a58", "width": 216, "height": 121}, {"url": "https://preview.redd.it/39c54kegwyta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f822103bb9e44fe55d65f2ece13818428ec6d6f2", "width": 320, "height": 180}, {"url": "https://preview.redd.it/39c54kegwyta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea116338b9bc9f95f6d42a5b607cdea9763840c0", "width": 640, "height": 360}, {"url": "https://preview.redd.it/39c54kegwyta1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b4cd05dc7d6ebfdf2f53cecb3d55f98118f6aa68", "width": 960, "height": 540}, {"url": "https://preview.redd.it/39c54kegwyta1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48162045d67dcbabef0a88d6f2b01994c181b152", "width": 1080, "height": 607}], "variants": {}, "id": "der-WrnDqesBzp4YZJxfkWXWVcI49I5UiFRB2hgq2gE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12modde", "is_robot_indexable": true, "report_reasons": null, "author": "Leftover-Waffle", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12modde/i_dont_have_much_data_especially_compared_to_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/39c54kegwyta1.png", "subreddit_subscribers": 677976, "created_utc": 1681529322.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Around 100k images", "author_fullname": "t2_80r87i4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't download \"thisisnthappiness.com\" with TumblThree. They have some special sort of tumblr page. The archive is complete, anybody know how to download alll images of the archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12my30k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681555200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Around 100k images&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12my30k", "is_robot_indexable": true, "report_reasons": null, "author": "PalmMallMars", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12my30k/cant_download_thisisnthappinesscom_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12my30k/cant_download_thisisnthappinesscom_with/", "subreddit_subscribers": 677976, "created_utc": 1681555200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Title says it all.  Going to ship the NAS.  Am I safe(ish?) leaving the drives mounted? Maybe rubber washers on each drive?  I'm just trying to avoid a broken RAID array when the shipper arrives and I unpack.", "author_fullname": "t2_9b8zs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving, safest way to ship my NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12np0br", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681605926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title says it all.  Going to ship the NAS.  Am I safe(ish?) leaving the drives mounted? Maybe rubber washers on each drive?  I&amp;#39;m just trying to avoid a broken RAID array when the shipper arrives and I unpack.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "96TB TrueNas on Isilon", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12np0br", "is_robot_indexable": true, "report_reasons": null, "author": "trollboy665", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12np0br/moving_safest_way_to_ship_my_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12np0br/moving_safest_way_to_ship_my_nas/", "subreddit_subscribers": 677976, "created_utc": 1681605926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://www.amazon.com/Elements-Desktop-External-external-storage/dp/B0BTFPTSNQ](https://www.amazon.com/Elements-Desktop-External-external-storage/dp/B0BTFPTSNQ)\n\n$17/TB before Tax. Not the greatest, but if you've been in the market for a 22TB, this is the lowest it's been so far.", "author_fullname": "t2_au90zx6l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD Elements 22TB for $380 on Amazon!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12notr0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681605531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.amazon.com/Elements-Desktop-External-external-storage/dp/B0BTFPTSNQ\"&gt;https://www.amazon.com/Elements-Desktop-External-external-storage/dp/B0BTFPTSNQ&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;$17/TB before Tax. Not the greatest, but if you&amp;#39;ve been in the market for a 22TB, this is the lowest it&amp;#39;s been so far.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12notr0", "is_robot_indexable": true, "report_reasons": null, "author": "FanboyKilla", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12notr0/wd_elements_22tb_for_380_on_amazon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12notr0/wd_elements_22tb_for_380_on_amazon/", "subreddit_subscribers": 677976, "created_utc": 1681605531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm sure someone already asked that question, but after reading the FAQs and dozens of threads without any luck, I'll just ask...\n\nScenario:\nI have about 10 different sized, external, encrypted HDDs (1 to 18TB), where I backup all kind of data. To prevent data loss in case of a hardware failure, I have stored pretty much every file on two different HDDs. This worked quite fine for me, but over the years I'm now at a point where I lost track, if really every file has a duplicate somewhere else...\n\nNow it's a mess and in case of a failure I would not even know which files I lost or where to find the backup of the backup.\n\nI know that there are some indexing tools, which would help me keep track of the files, but are there also tools which support for such a backup strategy? Something which would show me an overview of files, where only one copy exists?", "author_fullname": "t2_d2lct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backup on multiple external drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nbp3z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681579238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m sure someone already asked that question, but after reading the FAQs and dozens of threads without any luck, I&amp;#39;ll just ask...&lt;/p&gt;\n\n&lt;p&gt;Scenario:\nI have about 10 different sized, external, encrypted HDDs (1 to 18TB), where I backup all kind of data. To prevent data loss in case of a hardware failure, I have stored pretty much every file on two different HDDs. This worked quite fine for me, but over the years I&amp;#39;m now at a point where I lost track, if really every file has a duplicate somewhere else...&lt;/p&gt;\n\n&lt;p&gt;Now it&amp;#39;s a mess and in case of a failure I would not even know which files I lost or where to find the backup of the backup.&lt;/p&gt;\n\n&lt;p&gt;I know that there are some indexing tools, which would help me keep track of the files, but are there also tools which support for such a backup strategy? Something which would show me an overview of files, where only one copy exists?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12nbp3z", "is_robot_indexable": true, "report_reasons": null, "author": "hash0", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12nbp3z/backup_on_multiple_external_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12nbp3z/backup_on_multiple_external_drives/", "subreddit_subscribers": 677976, "created_utc": 1681579238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My understanding with USB is that as long as it's capable to move data, you can guarantee it's a good cable -- there's rarely something as \"slightly\" faulty. If it's broken, it won't give either power or data at all.\n\nThen comes my HDD. Suddenly on every transfer, it'd cause A LOT of problem. Speed drops to 0 often, causing hangs midway (and I have to force eject to let my Windows continue to work), and I can't delete a lot of data without causing issues.\n\nAll which are gone when I swap my USB cable (for now).\n\nThe one prompting me to suspect USB is UltraDMA CRC Error Count in SMART, people say it's due to SATA cable issue, but here I'm using USB.\n\nCan anyone clarify on this?", "author_fullname": "t2_tac95", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible an External HDD USB cable causing problem to data transfer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mz5e5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681557954.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My understanding with USB is that as long as it&amp;#39;s capable to move data, you can guarantee it&amp;#39;s a good cable -- there&amp;#39;s rarely something as &amp;quot;slightly&amp;quot; faulty. If it&amp;#39;s broken, it won&amp;#39;t give either power or data at all.&lt;/p&gt;\n\n&lt;p&gt;Then comes my HDD. Suddenly on every transfer, it&amp;#39;d cause A LOT of problem. Speed drops to 0 often, causing hangs midway (and I have to force eject to let my Windows continue to work), and I can&amp;#39;t delete a lot of data without causing issues.&lt;/p&gt;\n\n&lt;p&gt;All which are gone when I swap my USB cable (for now).&lt;/p&gt;\n\n&lt;p&gt;The one prompting me to suspect USB is UltraDMA CRC Error Count in SMART, people say it&amp;#39;s due to SATA cable issue, but here I&amp;#39;m using USB.&lt;/p&gt;\n\n&lt;p&gt;Can anyone clarify on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12mz5e5", "is_robot_indexable": true, "report_reasons": null, "author": "ArsenicBismuth", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12mz5e5/is_it_possible_an_external_hdd_usb_cable_causing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12mz5e5/is_it_possible_an_external_hdd_usb_cable_causing/", "subreddit_subscribers": 677976, "created_utc": 1681557954.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am trying to get some data off a likely bad drive.  I rebooted my W11 desktop recently and when it came back on and connected via one of the 3 drives in a R0 setup is not detected, at first it said drive not connected then it said other issues and currently in the storage aspect of the QNAP.  I have purchased 2 new 14TB drives to swap out with that one and another with low level SMART stats.\n\n&amp;#x200B;\n\nWhat options do I have to restore the data off the 3 drives to transfer to other drives then remove them and combine the 2x14TB drives and rebuild.\n\n&amp;#x200B;\n\nI know that I should have other options and am working towards another NAS to use as secondary and tertiary backup.  I just would like to find a way to restore the data at least as long as possible to copy data off.  At this point there is about 21TB of data across the 3x R0 combined drives.", "author_fullname": "t2_d1f2mdx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drive issues QNAP 873", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12my5pp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681555400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to get some data off a likely bad drive.  I rebooted my W11 desktop recently and when it came back on and connected via one of the 3 drives in a R0 setup is not detected, at first it said drive not connected then it said other issues and currently in the storage aspect of the QNAP.  I have purchased 2 new 14TB drives to swap out with that one and another with low level SMART stats.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What options do I have to restore the data off the 3 drives to transfer to other drives then remove them and combine the 2x14TB drives and rebuild.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know that I should have other options and am working towards another NAS to use as secondary and tertiary backup.  I just would like to find a way to restore the data at least as long as possible to copy data off.  At this point there is about 21TB of data across the 3x R0 combined drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "86TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12my5pp", "is_robot_indexable": true, "report_reasons": null, "author": "kookykrazee", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12my5pp/drive_issues_qnap_873/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12my5pp/drive_issues_qnap_873/", "subreddit_subscribers": 677976, "created_utc": 1681555400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_h0c8uq0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Digital hoarding", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mx5vh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1681552768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hobbygenerator.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://hobbygenerator.com/hobby?hobby=Digital%20hoarding", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "2x8TB+2x4TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12mx5vh", "is_robot_indexable": true, "report_reasons": null, "author": "theniwo", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12mx5vh/digital_hoarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://hobbygenerator.com/hobby?hobby=Digital%20hoarding", "subreddit_subscribers": 677976, "created_utc": 1681552768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am posting here in hope someone will guide me in the right direction. I have alread checked some posts, but was unsure if my method is correct.\n\nMy main system in Linux Manjaro, and currently I'm manually syncing files to another system on LAN that is running same OS. Ideally, I would like this to be automated, but I have no experience with any of that. All (or almost all) data is backed up in cloud as well. The problem is, with adding or removing data, I must have some duplicates somewhere, or files that have been deleted from my system on a backup system; which is pointless.\n\nI have 2 HDD's  dedicated for backups that will be stored in a separate location. The drives would be 1:1 copy if one fails. I think that is sufficient enough, basically having 4 copies of each file on different HDDs.\n\nThose HDDs, I'd like to sync about once a month, and write all the changes that happened since last backup. So files that got modified, deleted, added... I don't know what the most convenient way would be.\n\nThe files consist of all types, and maybe having a hash/index of all of them would make sense, since search is really slow sometimes. Is there a program that would manage all of that for me? The drives I have now are 12TB ones - the offline ones are SMR, and will only be used as a backup.", "author_fullname": "t2_1nikfyn2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Indexing / hashing files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mx533", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681552703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am posting here in hope someone will guide me in the right direction. I have alread checked some posts, but was unsure if my method is correct.&lt;/p&gt;\n\n&lt;p&gt;My main system in Linux Manjaro, and currently I&amp;#39;m manually syncing files to another system on LAN that is running same OS. Ideally, I would like this to be automated, but I have no experience with any of that. All (or almost all) data is backed up in cloud as well. The problem is, with adding or removing data, I must have some duplicates somewhere, or files that have been deleted from my system on a backup system; which is pointless.&lt;/p&gt;\n\n&lt;p&gt;I have 2 HDD&amp;#39;s  dedicated for backups that will be stored in a separate location. The drives would be 1:1 copy if one fails. I think that is sufficient enough, basically having 4 copies of each file on different HDDs.&lt;/p&gt;\n\n&lt;p&gt;Those HDDs, I&amp;#39;d like to sync about once a month, and write all the changes that happened since last backup. So files that got modified, deleted, added... I don&amp;#39;t know what the most convenient way would be.&lt;/p&gt;\n\n&lt;p&gt;The files consist of all types, and maybe having a hash/index of all of them would make sense, since search is really slow sometimes. Is there a program that would manage all of that for me? The drives I have now are 12TB ones - the offline ones are SMR, and will only be used as a backup.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12mx533", "is_robot_indexable": true, "report_reasons": null, "author": "StrlA", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12mx533/indexing_hashing_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12mx533/indexing_hashing_files/", "subreddit_subscribers": 677976, "created_utc": 1681552703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, it all started when I found a kinda silly amazon review video but when getting the m3u8 of it in vlc mp4 is a wreck and webm generates an insane 47 year long file that is actually 20 seconds worth but cannot be interfaced with because programs die when I try to convert and decorrupt this to mp4. My friend is a huge south park fan, and I saved this to show them the silly bootleg Cartman. Here's the result.\n\n[4 seconds of 20 some here and it got corrupted sorta](https://reddit.com/link/12nsjl5/video/oahoz1ddt5ua1/player)\n\nThis isn't a video I care about really, so whatever that the stupid one does not work right? Well all of them are like this. Pasta strainer? Bricked. Cheese grater? Borked. 55 Gallons of blue Italian Soda flavoring syrup? Believe it or not, Broke.\n\n&amp;#x200B;\n\nAs useless as bootleg Cartman is, considering I don't actually need the rest of the review and I don't care about south park, this shows a major pitfall in our saving tech. Who knows! Maybe one will want to save a video for a documentary about a product or, like here, just because it was funny and someone will get a kick out of it. If anyone knows m3u8 saving tips, tell me, but if not, someone's gotta make one. TONS of sites use m3u8. It's like building the most secure house (of archival) and accidentally leaving the door open.\n\n&amp;#x200B;\n\nAlso, does anyone know how to fix corrupted MKV files? I've got too many broke ones to not fix them.", "author_fullname": "t2_718mpex4a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The pitfall of archiving - m3u8", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "media_metadata": {"oahoz1ddt5ua1": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/12nsjl5/asset/oahoz1ddt5ua1/DASHPlaylist.mpd?a=1684208293%2CYzQzZjE3Y2U2ZmZhZmVkZmI3MjNkZDc3OGM3NGY0OWE5Yjk1MGIxOTRkMmZjYjI2YWI0YzQxYmVhZjBjZTU2OA%3D%3D&amp;v=1&amp;f=sd", "x": 1920, "y": 1080, "hlsUrl": "https://v.redd.it/link/12nsjl5/asset/oahoz1ddt5ua1/HLSPlaylist.m3u8?a=1684208293%2CYjI2OTFiNzUwODRmMDhiMWU1ZjJjOWQ4NGY1YTY3MjUzZDdjOTBmMzRjZDk1ZWY5YWQwMmMxMjlmMWRmZTE2Nw%3D%3D&amp;v=1&amp;f=sd", "id": "oahoz1ddt5ua1", "isGif": false}}, "name": "t3_12nsjl5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681613697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, it all started when I found a kinda silly amazon review video but when getting the m3u8 of it in vlc mp4 is a wreck and webm generates an insane 47 year long file that is actually 20 seconds worth but cannot be interfaced with because programs die when I try to convert and decorrupt this to mp4. My friend is a huge south park fan, and I saved this to show them the silly bootleg Cartman. Here&amp;#39;s the result.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/12nsjl5/video/oahoz1ddt5ua1/player\"&gt;4 seconds of 20 some here and it got corrupted sorta&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This isn&amp;#39;t a video I care about really, so whatever that the stupid one does not work right? Well all of them are like this. Pasta strainer? Bricked. Cheese grater? Borked. 55 Gallons of blue Italian Soda flavoring syrup? Believe it or not, Broke.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As useless as bootleg Cartman is, considering I don&amp;#39;t actually need the rest of the review and I don&amp;#39;t care about south park, this shows a major pitfall in our saving tech. Who knows! Maybe one will want to save a video for a documentary about a product or, like here, just because it was funny and someone will get a kick out of it. If anyone knows m3u8 saving tips, tell me, but if not, someone&amp;#39;s gotta make one. TONS of sites use m3u8. It&amp;#39;s like building the most secure house (of archival) and accidentally leaving the door open.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Also, does anyone know how to fix corrupted MKV files? I&amp;#39;ve got too many broke ones to not fix them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "6TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "12nsjl5", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_McGuggins", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12nsjl5/the_pitfall_of_archiving_m3u8/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12nsjl5/the_pitfall_of_archiving_m3u8/", "subreddit_subscribers": 677976, "created_utc": 1681613697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi is there a difference in terms of longevity for the same enterprise hard drive with different interface?", "author_fullname": "t2_ebocf1py", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a difference between sata and sas on the same model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12nqwvt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681610255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi is there a difference in terms of longevity for the same enterprise hard drive with different interface?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12nqwvt", "is_robot_indexable": true, "report_reasons": null, "author": "Fearless_Ad6014", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12nqwvt/is_there_a_difference_between_sata_and_sas_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12nqwvt/is_there_a_difference_between_sata_and_sas_on_the/", "subreddit_subscribers": 677976, "created_utc": 1681610255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 6x Seagate EXOS 20 tb drives, upgrading from 2x in my new custom-built PC.\n\nFound out that I have to increase the sector sizes (or something like that) to make a storage pool larger than 18 TB in Windows Storage Spaces, so I am getting a cheap-o 20 tb WD MyElements and moving everything off before re-doing the whole shabang.\n\nShould I increase sector size and go with Widnows Storage Spaces again, (but I have a lot of small files i.e. metadata files that are less than 64 kB) or like I've seen others point out, is Drivepool plus SnapRaid a better option for me? I plan on using the array in RAID 1 or 5 (haven't decided). I also have BackBlaze and backing up archival data on BlueRay. Soon going to be transitioning to tape drives for archival storage.\n\nI am a timelapse photographer, so yes, I legitimately use this data on the daily. I am sometimes producing 1-2 tb/day of RAW data.\n\nEdit: ignore my embarrassing typo in the post title lol", "author_fullname": "t2_j8uu1ow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage Spaces vs. DrivePool+Snapraid for 120 tb Dekstop Storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12noil7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681604867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 6x Seagate EXOS 20 tb drives, upgrading from 2x in my new custom-built PC.&lt;/p&gt;\n\n&lt;p&gt;Found out that I have to increase the sector sizes (or something like that) to make a storage pool larger than 18 TB in Windows Storage Spaces, so I am getting a cheap-o 20 tb WD MyElements and moving everything off before re-doing the whole shabang.&lt;/p&gt;\n\n&lt;p&gt;Should I increase sector size and go with Widnows Storage Spaces again, (but I have a lot of small files i.e. metadata files that are less than 64 kB) or like I&amp;#39;ve seen others point out, is Drivepool plus SnapRaid a better option for me? I plan on using the array in RAID 1 or 5 (haven&amp;#39;t decided). I also have BackBlaze and backing up archival data on BlueRay. Soon going to be transitioning to tape drives for archival storage.&lt;/p&gt;\n\n&lt;p&gt;I am a timelapse photographer, so yes, I legitimately use this data on the daily. I am sometimes producing 1-2 tb/day of RAW data.&lt;/p&gt;\n\n&lt;p&gt;Edit: ignore my embarrassing typo in the post title lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12noil7", "is_robot_indexable": true, "report_reasons": null, "author": "VincentLedvina", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12noil7/storage_spaces_vs_drivepoolsnapraid_for_120_tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12noil7/storage_spaces_vs_drivepoolsnapraid_for_120_tb/", "subreddit_subscribers": 677976, "created_utc": 1681604867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I wanting to back up my PC\u2019s data, and my wife\u2019s iPhone and mine.\nSay about 8TB of data in total.\n\nI would like to be able to access these online if needed, but not regularly.\n\nA lot of the data is RAW photos.\n\n\nI am not needing anything fancy like media streaming or VMs.\n\nUnfortunately I don\u2019t have the time to build and maintain a TrueNAS, so needing something more of the shelf and secure.", "author_fullname": "t2_mhgnkw7h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NAS recommendations for home?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12no676", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681604112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanting to back up my PC\u2019s data, and my wife\u2019s iPhone and mine.\nSay about 8TB of data in total.&lt;/p&gt;\n\n&lt;p&gt;I would like to be able to access these online if needed, but not regularly.&lt;/p&gt;\n\n&lt;p&gt;A lot of the data is RAW photos.&lt;/p&gt;\n\n&lt;p&gt;I am not needing anything fancy like media streaming or VMs.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately I don\u2019t have the time to build and maintain a TrueNAS, so needing something more of the shelf and secure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12no676", "is_robot_indexable": true, "report_reasons": null, "author": "22radiodogs", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12no676/nas_recommendations_for_home/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12no676/nas_recommendations_for_home/", "subreddit_subscribers": 677976, "created_utc": 1681604112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm not super familiar with these, I'm not really a tech guy. I've got a 3TB drive that's filling up and I don't want to have to worry about it anymore. I saw I can get a 16TB for $250 which seems like a good deal for me.", "author_fullname": "t2_fxa6t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are Seagate Expansion 16TB drives through Amazon trustworthy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nk1ok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681595498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not super familiar with these, I&amp;#39;m not really a tech guy. I&amp;#39;ve got a 3TB drive that&amp;#39;s filling up and I don&amp;#39;t want to have to worry about it anymore. I saw I can get a 16TB for $250 which seems like a good deal for me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12nk1ok", "is_robot_indexable": true, "report_reasons": null, "author": "onlytoask", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12nk1ok/are_seagate_expansion_16tb_drives_through_amazon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12nk1ok/are_seagate_expansion_16tb_drives_through_amazon/", "subreddit_subscribers": 677976, "created_utc": 1681595498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have around 10Tb of total data (unique), stored in a variety of cloud service providers across multiple account (OneDrive, Google Drive, Box, Dropbox, etc). I've recently begun thinking about backing up this data, as this is the only copy of data I have.\n\n&amp;#x200B;\n\nDue to the size of the data, browsing reddit has impressed upon me that the best way to back up all this data to backblaze would be to get a large VPS, download, and then rclone to backblaze.\n\n&amp;#x200B;\n\nIs this the best solution, or is there potentially something smarter I'm missing?", "author_fullname": "t2_9ghuw0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redundancy Backups of Cloud Data via Backblaze", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nfsxp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681587243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have around 10Tb of total data (unique), stored in a variety of cloud service providers across multiple account (OneDrive, Google Drive, Box, Dropbox, etc). I&amp;#39;ve recently begun thinking about backing up this data, as this is the only copy of data I have.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Due to the size of the data, browsing reddit has impressed upon me that the best way to back up all this data to backblaze would be to get a large VPS, download, and then rclone to backblaze.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this the best solution, or is there potentially something smarter I&amp;#39;m missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12nfsxp", "is_robot_indexable": true, "report_reasons": null, "author": "SmittyJohnsontheone", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12nfsxp/redundancy_backups_of_cloud_data_via_backblaze/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12nfsxp/redundancy_backups_of_cloud_data_via_backblaze/", "subreddit_subscribers": 677976, "created_utc": 1681587243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is this a crazy idea for some reason? I am thinking it's not. Zfs copies = 2 plus compression means I dont lose a ton of space plus I get bitrot protection. Snapraid allows me to recover from total drive failures and to add one drive at a time. Mergerfs makes the whole thing seamless.", "author_fullname": "t2_13g9il", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snapraid / Mergerfs with single drives formatted as zfs copies=2", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ncbu2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681580501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is this a crazy idea for some reason? I am thinking it&amp;#39;s not. Zfs copies = 2 plus compression means I dont lose a ton of space plus I get bitrot protection. Snapraid allows me to recover from total drive failures and to add one drive at a time. Mergerfs makes the whole thing seamless.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12ncbu2", "is_robot_indexable": true, "report_reasons": null, "author": "linuxman1929", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12ncbu2/snapraid_mergerfs_with_single_drives_formatted_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12ncbu2/snapraid_mergerfs_with_single_drives_formatted_as/", "subreddit_subscribers": 677976, "created_utc": 1681580501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recall there being some software that could reliably replicate / copy data from A to B, whilst also performing a check (CRC check??).\n\nTried Google and I get pretty much all the paid-promoted stuff which is clearly being pushed by the algo, and not because the software is necessarily good.\n\nWhat do folks around here use and recommend?\n\nEssentially I have 1TB (yes I know, nothing compare to some of you, but still plenty for me!) that I've copied from one 2TB drive to another 2TB drive.\n\nI'll periodically update files on one drive, and would like to be able to hit a button and 'sync' the recently changed files or new files to the second drive - what's the best way to do this?\n\n**Edit: I've found this interesting article** [**https://kinolios.com/en/blog/cinematography/post-production/backups-et-integrite-des-donnees-partie-i-freefilesync/**](https://kinolios.com/en/blog/cinematography/post-production/backups-et-integrite-des-donnees-partie-i-freefilesync/) **which looks legit. I think it's partially in French, but it looks like someone's actual hands-on experience, which is what I'm after**", "author_fullname": "t2_4d5ehhv2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best software for keeping data replicated / in sync when backing up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n3upo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681569256.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681567990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recall there being some software that could reliably replicate / copy data from A to B, whilst also performing a check (CRC check??).&lt;/p&gt;\n\n&lt;p&gt;Tried Google and I get pretty much all the paid-promoted stuff which is clearly being pushed by the algo, and not because the software is necessarily good.&lt;/p&gt;\n\n&lt;p&gt;What do folks around here use and recommend?&lt;/p&gt;\n\n&lt;p&gt;Essentially I have 1TB (yes I know, nothing compare to some of you, but still plenty for me!) that I&amp;#39;ve copied from one 2TB drive to another 2TB drive.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll periodically update files on one drive, and would like to be able to hit a button and &amp;#39;sync&amp;#39; the recently changed files or new files to the second drive - what&amp;#39;s the best way to do this?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit: I&amp;#39;ve found this interesting article&lt;/strong&gt; &lt;a href=\"https://kinolios.com/en/blog/cinematography/post-production/backups-et-integrite-des-donnees-partie-i-freefilesync/\"&gt;&lt;strong&gt;https://kinolios.com/en/blog/cinematography/post-production/backups-et-integrite-des-donnees-partie-i-freefilesync/&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;which looks legit. I think it&amp;#39;s partially in French, but it looks like someone&amp;#39;s actual hands-on experience, which is what I&amp;#39;m after&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7YhI2SiGD2uVXilhB6wby5U6dXSPbVWD-wwSucElV2E.jpg?auto=webp&amp;v=enabled&amp;s=20be7e8ed32871e5b0a9b98fac6535e24fd2ad76", "width": 1500, "height": 762}, "resolutions": [{"url": "https://external-preview.redd.it/7YhI2SiGD2uVXilhB6wby5U6dXSPbVWD-wwSucElV2E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51ea4c4466a0bf0f940ff42bd0f6f5b94bc53330", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/7YhI2SiGD2uVXilhB6wby5U6dXSPbVWD-wwSucElV2E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25167e5aa8ae173b0a4ab70d8b25a33ea5405fb8", "width": 216, "height": 109}, {"url": "https://external-preview.redd.it/7YhI2SiGD2uVXilhB6wby5U6dXSPbVWD-wwSucElV2E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b52333862e737171f7d1ee781f9b71ec5630aed8", "width": 320, "height": 162}, {"url": "https://external-preview.redd.it/7YhI2SiGD2uVXilhB6wby5U6dXSPbVWD-wwSucElV2E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d53c0226c8371ca56382db9e4633966b75beb695", "width": 640, "height": 325}, {"url": "https://external-preview.redd.it/7YhI2SiGD2uVXilhB6wby5U6dXSPbVWD-wwSucElV2E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1488dece49d903dbf698a921da5270a373147db0", "width": 960, "height": 487}, {"url": "https://external-preview.redd.it/7YhI2SiGD2uVXilhB6wby5U6dXSPbVWD-wwSucElV2E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=236fa4c8611fe7532aaf84788152199512cd330a", "width": 1080, "height": 548}], "variants": {}, "id": "jHqT9gQOb5yPP3xY1QsHs_8DB2Xi4cY0A6ExV9xUBWU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12n3upo", "is_robot_indexable": true, "report_reasons": null, "author": "i-dm", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12n3upo/whats_the_best_software_for_keeping_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12n3upo/whats_the_best_software_for_keeping_data/", "subreddit_subscribers": 677976, "created_utc": 1681567990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What's the best way to store, organise and self-transport multiple \"passport\" style external drives, such as WD Elements?   Ideally I'd like a lightweight stackable plastic case containing foam where 10-20 such drives and/or SSDs can be stored edge-on (hence edge- labelled and placed/found easily).  Do such things exist, and if so where?   I've searched lots and not found anything like this.  Currently I use strong reusable carrier bags, which feels poor and leads to lots of rummaging.  What do other people in my situation do (that's better)?", "author_fullname": "t2_v9cgie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What/where are cases to store/organise/self-transport multiple \"passport\" style external drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n29ot", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681564978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the best way to store, organise and self-transport multiple &amp;quot;passport&amp;quot; style external drives, such as WD Elements?   Ideally I&amp;#39;d like a lightweight stackable plastic case containing foam where 10-20 such drives and/or SSDs can be stored edge-on (hence edge- labelled and placed/found easily).  Do such things exist, and if so where?   I&amp;#39;ve searched lots and not found anything like this.  Currently I use strong reusable carrier bags, which feels poor and leads to lots of rummaging.  What do other people in my situation do (that&amp;#39;s better)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12n29ot", "is_robot_indexable": true, "report_reasons": null, "author": "davidgaryesp", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12n29ot/whatwhere_are_cases_to_storeorganiseselftransport/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12n29ot/whatwhere_are_cases_to_storeorganiseselftransport/", "subreddit_subscribers": 677976, "created_utc": 1681564978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a program that you can load in the predefined start and end times of pieces of the same video and the program will extract the defined pieces as their own separate files automatically and as a batch process?  \n\n\nIn other words, if a video is 3 minutes long, a user can load in the following:  \n\n\n0:00-1:00 - extracts to file 1  \n1:00-2:00 - extracts to file 2  \n2:00-3:00 - extracts to file 3  \n\n\nand the program automatically creates 3 files based on the above definition?", "author_fullname": "t2_74i2uwce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a program that cut YouTube videos into user-defined start and end times from the video?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n10m3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681562300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a program that you can load in the predefined start and end times of pieces of the same video and the program will extract the defined pieces as their own separate files automatically and as a batch process?  &lt;/p&gt;\n\n&lt;p&gt;In other words, if a video is 3 minutes long, a user can load in the following:  &lt;/p&gt;\n\n&lt;p&gt;0:00-1:00 - extracts to file 1&lt;br/&gt;\n1:00-2:00 - extracts to file 2&lt;br/&gt;\n2:00-3:00 - extracts to file 3  &lt;/p&gt;\n\n&lt;p&gt;and the program automatically creates 3 files based on the above definition?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12n10m3", "is_robot_indexable": true, "report_reasons": null, "author": "humelectra2000", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12n10m3/is_there_a_program_that_cut_youtube_videos_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12n10m3/is_there_a_program_that_cut_youtube_videos_into/", "subreddit_subscribers": 677976, "created_utc": 1681562300.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i live in a relatively small flat so there's no way to move it anywhere else, i have 2x WD Red 12TB and those aren't that loud; been looking at Seagate Exos X20 20TB - wondering how loud would it be if i had 8 of those in a Fractal Node 804? or if there is anything quieter at a similar price point (i'm in germany so the exos is 320 EUR).\n\nthanks in advance", "author_fullname": "t2_ak0pkhdl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "quietest 20TB HDD for a home server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mzldr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681559039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i live in a relatively small flat so there&amp;#39;s no way to move it anywhere else, i have 2x WD Red 12TB and those aren&amp;#39;t that loud; been looking at Seagate Exos X20 20TB - wondering how loud would it be if i had 8 of those in a Fractal Node 804? or if there is anything quieter at a similar price point (i&amp;#39;m in germany so the exos is 320 EUR).&lt;/p&gt;\n\n&lt;p&gt;thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12mzldr", "is_robot_indexable": true, "report_reasons": null, "author": "basedqwq", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12mzldr/quietest_20tb_hdd_for_a_home_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12mzldr/quietest_20tb_hdd_for_a_home_server/", "subreddit_subscribers": 677976, "created_utc": 1681559039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Greetings,\n\nRecently, I got this drive (from the title). It was described as untested and in unknown state, but the price was low enough for a gamble (and I have regular dealings with that seller).\n\nBut I am stuck at a point where I cannot ascertain is it functional or not.\n\nWhen plugged in:\n\u2013 it definitely warms up like it's working;\n\u2013 Four SMD LEDs on it are not lighting up;\n\u2013 it is not detected, neither in BIOS (i.e. UEFI) nor by Windows.\n\nI've encountered [this forum thread](https://rog-forum.asus.com/t5/hardware-build-advice/intel-dc-p3500-nvme-drive-not-showing-up/m-p/704418) that references the need to cover/isolate a specific pin on the card \u2248\"for this enterprise device to be detected on the consumer hardware\", with the original asker even confirming that it worked. So, essentially analogous to the need\nto cover the 3.3V pin when shucking some WD HDDs. (Sure, sounds weird, considering it is PCIe, but okay.) \n \nBUT: the link to the referenced thread now leads to nowhere useful, because Intel's community forums were completely restructured/changed in the interim, (and they were too lazy to set up redirects for old links).\n\nI tried archive.org, no luck; tried digging up anything on the current version of the Intel community forum, to no avail; googled, binged, and even chatGPT-ed my heart out, zilch; consulted the device manual, found nothing of relevance. \n\nSo, I am stuck. I hate bothering others, but I have no other recourse. I'm asking this question here due to nature of this sub-reddit, and from what I've read through years, with the reasoning that its denizens are more likely to encounter the enterprise level hardware, and making it work in consumer/home systems, so...\n\nAny help/suggestions with the pin issue, or some other way of troubleshooting it are welcome. (Or where else to inquire.) Thanks.\n\n(P.S. Apologies for the long post... I could not be succinct even if my life depended on it. Also, ideally, I would have cross-posted this with r/HomeServer, but I don't know how to do it [or my custom reddit client is lacking this functionality].)\n\nEDIT: My motherboard model is Gigabyte Z370 HD3P, rev 1.0. I also tried it in another system (more recent, don't know the MB model off the top of my head, but with identical results as listed above).", "author_fullname": "t2_qkbiw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Enterprise PCIe NVMe SSD not detected in consumer motherboard (Intel DC P3500 Series)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12npsoc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681608323.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681607760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings,&lt;/p&gt;\n\n&lt;p&gt;Recently, I got this drive (from the title). It was described as untested and in unknown state, but the price was low enough for a gamble (and I have regular dealings with that seller).&lt;/p&gt;\n\n&lt;p&gt;But I am stuck at a point where I cannot ascertain is it functional or not.&lt;/p&gt;\n\n&lt;p&gt;When plugged in:\n\u2013 it definitely warms up like it&amp;#39;s working;\n\u2013 Four SMD LEDs on it are not lighting up;\n\u2013 it is not detected, neither in BIOS (i.e. UEFI) nor by Windows.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve encountered &lt;a href=\"https://rog-forum.asus.com/t5/hardware-build-advice/intel-dc-p3500-nvme-drive-not-showing-up/m-p/704418\"&gt;this forum thread&lt;/a&gt; that references the need to cover/isolate a specific pin on the card \u2248&amp;quot;for this enterprise device to be detected on the consumer hardware&amp;quot;, with the original asker even confirming that it worked. So, essentially analogous to the need\nto cover the 3.3V pin when shucking some WD HDDs. (Sure, sounds weird, considering it is PCIe, but okay.) &lt;/p&gt;\n\n&lt;p&gt;BUT: the link to the referenced thread now leads to nowhere useful, because Intel&amp;#39;s community forums were completely restructured/changed in the interim, (and they were too lazy to set up redirects for old links).&lt;/p&gt;\n\n&lt;p&gt;I tried archive.org, no luck; tried digging up anything on the current version of the Intel community forum, to no avail; googled, binged, and even chatGPT-ed my heart out, zilch; consulted the device manual, found nothing of relevance. &lt;/p&gt;\n\n&lt;p&gt;So, I am stuck. I hate bothering others, but I have no other recourse. I&amp;#39;m asking this question here due to nature of this sub-reddit, and from what I&amp;#39;ve read through years, with the reasoning that its denizens are more likely to encounter the enterprise level hardware, and making it work in consumer/home systems, so...&lt;/p&gt;\n\n&lt;p&gt;Any help/suggestions with the pin issue, or some other way of troubleshooting it are welcome. (Or where else to inquire.) Thanks.&lt;/p&gt;\n\n&lt;p&gt;(P.S. Apologies for the long post... I could not be succinct even if my life depended on it. Also, ideally, I would have cross-posted this with &lt;a href=\"/r/HomeServer\"&gt;r/HomeServer&lt;/a&gt;, but I don&amp;#39;t know how to do it [or my custom reddit client is lacking this functionality].)&lt;/p&gt;\n\n&lt;p&gt;EDIT: My motherboard model is Gigabyte Z370 HD3P, rev 1.0. I also tried it in another system (more recent, don&amp;#39;t know the MB model off the top of my head, but with identical results as listed above).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12npsoc", "is_robot_indexable": true, "report_reasons": null, "author": "RunDVDFirst", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12npsoc/enterprise_pcie_nvme_ssd_not_detected_in_consumer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12npsoc/enterprise_pcie_nvme_ssd_not_detected_in_consumer/", "subreddit_subscribers": 677976, "created_utc": 1681607760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I will be getting my hands on an old DOS scene CD tomorrow, and wanted to know the best software to use to grab the disk - bad sectors, weirdness, gaps and all, so I can try and get the on disk browser menu working again in DosBox / on vintage PCs\n\nOnly really have my windows 10 laptop to work with (I can load 7 if I need)\n\nWhat's my best bet here?", "author_fullname": "t2_4watb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows 10 software to exactly archive CD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nf13p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681585748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will be getting my hands on an old DOS scene CD tomorrow, and wanted to know the best software to use to grab the disk - bad sectors, weirdness, gaps and all, so I can try and get the on disk browser menu working again in DosBox / on vintage PCs&lt;/p&gt;\n\n&lt;p&gt;Only really have my windows 10 laptop to work with (I can load 7 if I need)&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s my best bet here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12nf13p", "is_robot_indexable": true, "report_reasons": null, "author": "sapopeonarope", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12nf13p/windows_10_software_to_exactly_archive_cd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12nf13p/windows_10_software_to_exactly_archive_cd/", "subreddit_subscribers": 677976, "created_utc": 1681585748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've tried a few hash programs to validate my .md5 files, and have yet to find one that is capable of loading all hash files in a folder (including subfolders) for example...\n\nDrive X:\\\\ has a folder named \"TV Series\" and several subfolders for rach season containing individual episodes. I created seperate hash files for each file for every episode. (Not sure if it's better to create a hash for each *completed* season though instead) \n\nUsing programs like TurboSFV, I can only load a single folder and I'd have to load each folder one by one to check my hashes. There is no option for subfolders. \n\nI am on Windows, I have a program to create hashes but need one to validate them.\n\nAny help is appreciated.", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hash file program that validates folders or entire drive containing hashes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nb8pe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681578326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve tried a few hash programs to validate my .md5 files, and have yet to find one that is capable of loading all hash files in a folder (including subfolders) for example...&lt;/p&gt;\n\n&lt;p&gt;Drive X:\\ has a folder named &amp;quot;TV Series&amp;quot; and several subfolders for rach season containing individual episodes. I created seperate hash files for each file for every episode. (Not sure if it&amp;#39;s better to create a hash for each &lt;em&gt;completed&lt;/em&gt; season though instead) &lt;/p&gt;\n\n&lt;p&gt;Using programs like TurboSFV, I can only load a single folder and I&amp;#39;d have to load each folder one by one to check my hashes. There is no option for subfolders. &lt;/p&gt;\n\n&lt;p&gt;I am on Windows, I have a program to create hashes but need one to validate them.&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "36TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12nb8pe", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12nb8pe/hash_file_program_that_validates_folders_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12nb8pe/hash_file_program_that_validates_folders_or/", "subreddit_subscribers": 677976, "created_utc": 1681578326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all; long-time reader, occasional poster here.\n\nWith large capacity hard drive prices coming down, I've decided to add a physical off-site backup to my backup strategy. Specifically, I'm looking at making a local copy of my Windows Server 2016-based NAS to a spare HDD, and then storing that drive off-site.\n\nThe only difficult requirement is that I'd like to have the backup drive encrypted, so that it wouldn't be trivial to access my data if someone else got their hands on the drive. And the encryption needs to *not* be keyed to the host computer, so that I can access the drive from another Windows computer should the worst happen to my NAS.\n\nThere seems to be no shortage of backup software on Windows, most of which is either more powerful or more complex than what I really need (e.g. I don't need a DB-based system with incremental backups or things like that). So I'm at a bit of a loss trying to dig through all the options.\n\nSo what are my best options here?", "author_fullname": "t2_e56kq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software Options For Offline Encrypted NAS Backups on Windows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mso17", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681540107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all; long-time reader, occasional poster here.&lt;/p&gt;\n\n&lt;p&gt;With large capacity hard drive prices coming down, I&amp;#39;ve decided to add a physical off-site backup to my backup strategy. Specifically, I&amp;#39;m looking at making a local copy of my Windows Server 2016-based NAS to a spare HDD, and then storing that drive off-site.&lt;/p&gt;\n\n&lt;p&gt;The only difficult requirement is that I&amp;#39;d like to have the backup drive encrypted, so that it wouldn&amp;#39;t be trivial to access my data if someone else got their hands on the drive. And the encryption needs to &lt;em&gt;not&lt;/em&gt; be keyed to the host computer, so that I can access the drive from another Windows computer should the worst happen to my NAS.&lt;/p&gt;\n\n&lt;p&gt;There seems to be no shortage of backup software on Windows, most of which is either more powerful or more complex than what I really need (e.g. I don&amp;#39;t need a DB-based system with incremental backups or things like that). So I&amp;#39;m at a bit of a loss trying to dig through all the options.&lt;/p&gt;\n\n&lt;p&gt;So what are my best options here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12mso17", "is_robot_indexable": true, "report_reasons": null, "author": "Verite_Rendition", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12mso17/software_options_for_offline_encrypted_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12mso17/software_options_for_offline_encrypted_nas/", "subreddit_subscribers": 677976, "created_utc": 1681540107.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}