{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "on an architectural level...", "author_fullname": "t2_7owm6ym1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data lake just a theoretical construct? How does it look on a code level when we say implement in GCP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12o0euv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681631817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;on an architectural level...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12o0euv", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Tradition-3450", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o0euv/is_data_lake_just_a_theoretical_construct_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12o0euv/is_data_lake_just_a_theoretical_construct_how/", "subreddit_subscribers": 99660, "created_utc": 1681631817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have an s3 based data lake where the data is partitioned on org_id and date. There is a use case where in a customer can choose a time range and export the data. The following is the design I have in mind\n1. The user prompt will trigger a lambda that will take the date range and org id. \n2. The lambda will query against athena. The athena results are stored in s3. \n3. The above s3 put event will return the s3 path and the lambda will create a s3 presigned url. \n4. Send the presigned url to the user as an email. \n\n\nMy question is, will the above architecture work for data exports- esp using athena as a query engine on top of the s3 data lake?  Any idea on the number of concurrent queries athena can handle? Is there anything i need to include such as a mechanism to handle queuing of query requests?", "author_fullname": "t2_icq6ey6g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Architecture Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12o15z8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681633695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have an s3 based data lake where the data is partitioned on org_id and date. There is a use case where in a customer can choose a time range and export the data. The following is the design I have in mind\n1. The user prompt will trigger a lambda that will take the date range and org id. \n2. The lambda will query against athena. The athena results are stored in s3. \n3. The above s3 put event will return the s3 path and the lambda will create a s3 presigned url. \n4. Send the presigned url to the user as an email. &lt;/p&gt;\n\n&lt;p&gt;My question is, will the above architecture work for data exports- esp using athena as a query engine on top of the s3 data lake?  Any idea on the number of concurrent queries athena can handle? Is there anything i need to include such as a mechanism to handle queuing of query requests?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12o15z8", "is_robot_indexable": true, "report_reasons": null, "author": "Direct-Wrongdoer-939", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o15z8/data_architecture_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12o15z8/data_architecture_question/", "subreddit_subscribers": 99660, "created_utc": 1681633695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a front-end engineer trying to practice my way to DE. \n\nI currently have a Task (Spec: I should use **Prefect** as an orchestration platform) to make a **pipeline**(s) to process **75k audio files** that are stored on \"`Google Cloud Storage`\" and extract words from them, then store extracted data in DW.\n\n&amp;#x200B;\n\nThen it should be a **stream** that will process every newly uploaded file the same way.\n\nFor now, I have only one Agent machine which is not always available (but might have one or two more later).\n\n&amp;#x200B;\n\n**I am a bit confused about:**\n\n\\- Should I create one `Flow` (deployed on one `Queue`) with \"`task_runner=DaskTaskRunner`\" that handles all the files ?\n\n\\- or Should I make multiple `Flows` for each file running on one single `Queue`?\n\n\\- lastly, What is the best way to handle the stream of new files (considering they are submitted by the app users and stored in the `GCS`), also considering that it is a small app, it doesn't make sense to have an overkill stack like Kafka?", "author_fullname": "t2_l6ymtf0x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prefect cloud - Junior DE Question for processing a huge number of files.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12o8mju", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681651996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a front-end engineer trying to practice my way to DE. &lt;/p&gt;\n\n&lt;p&gt;I currently have a Task (Spec: I should use &lt;strong&gt;Prefect&lt;/strong&gt; as an orchestration platform) to make a &lt;strong&gt;pipeline&lt;/strong&gt;(s) to process &lt;strong&gt;75k audio files&lt;/strong&gt; that are stored on &amp;quot;&lt;code&gt;Google Cloud Storage&lt;/code&gt;&amp;quot; and extract words from them, then store extracted data in DW.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Then it should be a &lt;strong&gt;stream&lt;/strong&gt; that will process every newly uploaded file the same way.&lt;/p&gt;\n\n&lt;p&gt;For now, I have only one Agent machine which is not always available (but might have one or two more later).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I am a bit confused about:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- Should I create one &lt;code&gt;Flow&lt;/code&gt; (deployed on one &lt;code&gt;Queue&lt;/code&gt;) with &amp;quot;&lt;code&gt;task_runner=DaskTaskRunner&lt;/code&gt;&amp;quot; that handles all the files ?&lt;/p&gt;\n\n&lt;p&gt;- or Should I make multiple &lt;code&gt;Flows&lt;/code&gt; for each file running on one single &lt;code&gt;Queue&lt;/code&gt;?&lt;/p&gt;\n\n&lt;p&gt;- lastly, What is the best way to handle the stream of new files (considering they are submitted by the app users and stored in the &lt;code&gt;GCS&lt;/code&gt;), also considering that it is a small app, it doesn&amp;#39;t make sense to have an overkill stack like Kafka?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12o8mju", "is_robot_indexable": true, "report_reasons": null, "author": "rafaaferid", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o8mju/prefect_cloud_junior_de_question_for_processing_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12o8mju/prefect_cloud_junior_de_question_for_processing_a/", "subreddit_subscribers": 99660, "created_utc": 1681651996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Fluke is a Python package that can be used to easily read files that do not reside within the local file system, e.g. on a remote server or on the cloud, as well as transfer them between said locations.\n\nMost changes introduced in version 0.3.0 are focused on reading files, adding functionality regarding reading large files in chunks, partially reading files, and more.\n\nGithub: [https://github.com/manoss96/fluke](https://github.com/manoss96/fluke)\n\nDocs:  [https://fluke.rtfd.io/](https://fluke.rtfd.io/)\n\nAny feedback is welcome!", "author_fullname": "t2_q7l1xoqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fluke v0.3.0 has been released!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12oenvo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681660590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fluke is a Python package that can be used to easily read files that do not reside within the local file system, e.g. on a remote server or on the cloud, as well as transfer them between said locations.&lt;/p&gt;\n\n&lt;p&gt;Most changes introduced in version 0.3.0 are focused on reading files, adding functionality regarding reading large files in chunks, partially reading files, and more.&lt;/p&gt;\n\n&lt;p&gt;Github: &lt;a href=\"https://github.com/manoss96/fluke\"&gt;https://github.com/manoss96/fluke&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Docs:  &lt;a href=\"https://fluke.rtfd.io/\"&gt;https://fluke.rtfd.io/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any feedback is welcome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e27iJwdTDiMUMjMwyihMu8n-S08RMcoarP6ObneMzW8.jpg?auto=webp&amp;v=enabled&amp;s=03923c7e18e6975fa0a3e01654a87a2b6f0cc2b3", "width": 1280, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/e27iJwdTDiMUMjMwyihMu8n-S08RMcoarP6ObneMzW8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f521a8cb43c395aeca794cf0f3ec60f80f55269b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/e27iJwdTDiMUMjMwyihMu8n-S08RMcoarP6ObneMzW8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f34131bc19b7a2460d2a180839b9720bf985f3f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/e27iJwdTDiMUMjMwyihMu8n-S08RMcoarP6ObneMzW8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86ce753cf5795c7b4d99c1fe48a8ced1918f7952", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/e27iJwdTDiMUMjMwyihMu8n-S08RMcoarP6ObneMzW8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=678ed5c0637d5d5fc0a9955230dd5f28cab16df6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/e27iJwdTDiMUMjMwyihMu8n-S08RMcoarP6ObneMzW8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7620a8bdf7a387d600a8110309c627f2cc9946c4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/e27iJwdTDiMUMjMwyihMu8n-S08RMcoarP6ObneMzW8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=784adf700ac1116ddeddb06409d4e8f7022d314e", "width": 1080, "height": 540}], "variants": {}, "id": "jLtdjHFEEy8dK1PXEN0uUAKPCiwcnjgJmAi80-3-9Xw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "12oenvo", "is_robot_indexable": true, "report_reasons": null, "author": "WerdenWissen", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12oenvo/fluke_v030_has_been_released/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12oenvo/fluke_v030_has_been_released/", "subreddit_subscribers": 99660, "created_utc": 1681660590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First of all - I want to apologise. I know a large percentage of the posts here are from beginners looking into the field and I know it's annoying. But I think this one is at least a little different from the usual salary expectations or \"how to learn DE\" thread.\n\nI am currently a PhD student in molecular biology, but I have been thinking of mastering out and transitioning to DE/DA/DS. I naturally looked at DE as it seems to be the most coveted/high-paying of the three, but some of the concepts were fuzzy to me. I started reading \"Designing Data-Intensive Applications\" and it has helped a lot, a very well written book. One of the things it makes clear is that the need for data warehousing arises particularly in the context of large businesses where you want to separate the OLTP infrastructure from the OLAP infrastructure, so that analysts aren't making expensive queries on business critical operational databases. \n\nComing from a scientific background where data are essentially *entirely* analytical, this is a bit of an odd distinction to think about. It seems like data warehousing has no real analog in science. I wondered if there is something I am missing about data warehousing as a concept that goes beyond just a \"separate database for analytical queries\", considering it seems to be at the core of DE (which is again seemingly the most coveted of the Dx professions)? \n\nI can certainly see that structuring data in logical schemas and knowing tools to bring data in (and organise it) should be useful in science or anywhere. But having said that, I am now wondering how much of this field specifically is built around a workflow that applies in large organisations with huge customer/transaction databases and their peculiar needs. So, in other words, what do people here think -- are there DE workflows with academic science or other \"pure analytics\" domains in mind, and do warehousing concepts in particular have relevance there?", "author_fullname": "t2_42aau", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Non-traditional uses for data warehousing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12o3gz8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681639398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all - I want to apologise. I know a large percentage of the posts here are from beginners looking into the field and I know it&amp;#39;s annoying. But I think this one is at least a little different from the usual salary expectations or &amp;quot;how to learn DE&amp;quot; thread.&lt;/p&gt;\n\n&lt;p&gt;I am currently a PhD student in molecular biology, but I have been thinking of mastering out and transitioning to DE/DA/DS. I naturally looked at DE as it seems to be the most coveted/high-paying of the three, but some of the concepts were fuzzy to me. I started reading &amp;quot;Designing Data-Intensive Applications&amp;quot; and it has helped a lot, a very well written book. One of the things it makes clear is that the need for data warehousing arises particularly in the context of large businesses where you want to separate the OLTP infrastructure from the OLAP infrastructure, so that analysts aren&amp;#39;t making expensive queries on business critical operational databases. &lt;/p&gt;\n\n&lt;p&gt;Coming from a scientific background where data are essentially &lt;em&gt;entirely&lt;/em&gt; analytical, this is a bit of an odd distinction to think about. It seems like data warehousing has no real analog in science. I wondered if there is something I am missing about data warehousing as a concept that goes beyond just a &amp;quot;separate database for analytical queries&amp;quot;, considering it seems to be at the core of DE (which is again seemingly the most coveted of the Dx professions)? &lt;/p&gt;\n\n&lt;p&gt;I can certainly see that structuring data in logical schemas and knowing tools to bring data in (and organise it) should be useful in science or anywhere. But having said that, I am now wondering how much of this field specifically is built around a workflow that applies in large organisations with huge customer/transaction databases and their peculiar needs. So, in other words, what do people here think -- are there DE workflows with academic science or other &amp;quot;pure analytics&amp;quot; domains in mind, and do warehousing concepts in particular have relevance there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12o3gz8", "is_robot_indexable": true, "report_reasons": null, "author": "omgpop", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o3gz8/nontraditional_uses_for_data_warehousing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12o3gz8/nontraditional_uses_for_data_warehousing/", "subreddit_subscribers": 99660, "created_utc": 1681639398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not an expert in snowflake so looking for some input from those who are. We have business requirements that currently cause us to load modeled data sets to both our data lake modeled zone as well as snowflake tables. While this load pattern supports the business requirement, it obviously means we are writing the same data to two different destinations. I'd love for everyone to just query the data from the data lake and not snowflake but that's not possible at present so I'm looking to reduce the cost impact of snowflake. What I'm curious about is can you create views in Snowflake that are built on top of data in my data lake as opposed to creating a base table in snowflake then creating views from that table?  In other words, can the based table for my snowflake views be in s3?\n\nI know loading (and unloading) data between snowflake and s3 is a common pattern via external tables, just not sure about how views would work in my particular case as I want to avoid a base table in snowflake.", "author_fullname": "t2_puuzgu6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating views in snowflake from source data in s3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12o8pm6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681652184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not an expert in snowflake so looking for some input from those who are. We have business requirements that currently cause us to load modeled data sets to both our data lake modeled zone as well as snowflake tables. While this load pattern supports the business requirement, it obviously means we are writing the same data to two different destinations. I&amp;#39;d love for everyone to just query the data from the data lake and not snowflake but that&amp;#39;s not possible at present so I&amp;#39;m looking to reduce the cost impact of snowflake. What I&amp;#39;m curious about is can you create views in Snowflake that are built on top of data in my data lake as opposed to creating a base table in snowflake then creating views from that table?  In other words, can the based table for my snowflake views be in s3?&lt;/p&gt;\n\n&lt;p&gt;I know loading (and unloading) data between snowflake and s3 is a common pattern via external tables, just not sure about how views would work in my particular case as I want to avoid a base table in snowflake.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12o8pm6", "is_robot_indexable": true, "report_reasons": null, "author": "getafterit123", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o8pm6/creating_views_in_snowflake_from_source_data_in_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12o8pm6/creating_views_in_snowflake_from_source_data_in_s3/", "subreddit_subscribers": 99660, "created_utc": 1681652184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Context:**\n\nI'm building a new product using a Postgres database for all application data and a vector database (Pinecone) for AI &amp; semantic search needs\n\n&amp;#x200B;\n\nI need to constantly sync one of the postgres table with the vector database in a reliable way so that every change is reflected in Pinecone (create, delete, update of this table rows)\n\n&amp;#x200B;\n\nI'm using a Go backend and we are a team of only 2 devs, so I try to find the right balance between not overengineer our MVP but also avoiding dealing with inconsistency between the 2 databases in the future\n\n&amp;#x200B;\n\n**Potential solutions considered:**\n\n\\- using postgres hooks to add custom logic before and after mutations \n\n\\- using a distributed transaction framework (like [https://github.com/dtm-labs/dtm](https://github.com/dtm-labs/dtm))\n\n&amp;#x200B;\n\nI would love to have some guidance from more experienced people!\n\nThanks", "author_fullname": "t2_a22a3w6a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to reliably sync 2 application databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12o9prs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681654366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m building a new product using a Postgres database for all application data and a vector database (Pinecone) for AI &amp;amp; semantic search needs&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I need to constantly sync one of the postgres table with the vector database in a reliable way so that every change is reflected in Pinecone (create, delete, update of this table rows)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using a Go backend and we are a team of only 2 devs, so I try to find the right balance between not overengineer our MVP but also avoiding dealing with inconsistency between the 2 databases in the future&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Potential solutions considered:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- using postgres hooks to add custom logic before and after mutations &lt;/p&gt;\n\n&lt;p&gt;- using a distributed transaction framework (like &lt;a href=\"https://github.com/dtm-labs/dtm\"&gt;https://github.com/dtm-labs/dtm&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I would love to have some guidance from more experienced people!&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HeXbpCee_O0-BBgVGpTcUTFcv5vIKlWLRxaGEghhRqU.jpg?auto=webp&amp;v=enabled&amp;s=6a515930ad21b5c4e86872be39b153d4e9b06532", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/HeXbpCee_O0-BBgVGpTcUTFcv5vIKlWLRxaGEghhRqU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53fca312b6ceab60e79e1b683fe6a84c6acfaef6", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/HeXbpCee_O0-BBgVGpTcUTFcv5vIKlWLRxaGEghhRqU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02af7c07af0a5e174a6d3b6ddb811cc74d47518d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/HeXbpCee_O0-BBgVGpTcUTFcv5vIKlWLRxaGEghhRqU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f51fa26a1c7310d1b38ad8c7a3cb8a131465d1bf", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/HeXbpCee_O0-BBgVGpTcUTFcv5vIKlWLRxaGEghhRqU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c87e62f8412ee868dabedefe27080e00b97aa243", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/HeXbpCee_O0-BBgVGpTcUTFcv5vIKlWLRxaGEghhRqU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd59dd7c68cc2bf596ea84dc53a64cc5dbe7ce90", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/HeXbpCee_O0-BBgVGpTcUTFcv5vIKlWLRxaGEghhRqU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74dae20db2aa857b249ecc3a389255a237e72b93", "width": 1080, "height": 540}], "variants": {}, "id": "BVV3qR8GKkBE4eItD5wumj02M3u8FA-C4jTjJqk53_w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12o9prs", "is_robot_indexable": true, "report_reasons": null, "author": "CoolFounder", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o9prs/how_to_reliably_sync_2_application_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12o9prs/how_to_reliably_sync_2_application_databases/", "subreddit_subscribers": 99660, "created_utc": 1681654366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all!\nI have a question regarding this weird situation I am encountering.\nI am running a python script which makes a db connection to a Vertica database.\nOnce the connection is established, the script has 1 string which contains the following queries in the order below:\n\n- Delete records from the table (Commit after this)\n- 3 insert queries into a local temp session tables (with on commit preserve rows)\n- Final insert query selecting the data from the session tables into a database table. (commit after this)\n\nWhen I run the script locally through Airflow, the script runs perfectly fine.\nOn Production, the script completes but the database table does not have any records inserted.\n\nAny idea why this is happening?", "author_fullname": "t2_ahi836bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DB Query Execution from Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nprcv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681607678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all!\nI have a question regarding this weird situation I am encountering.\nI am running a python script which makes a db connection to a Vertica database.\nOnce the connection is established, the script has 1 string which contains the following queries in the order below:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Delete records from the table (Commit after this)&lt;/li&gt;\n&lt;li&gt;3 insert queries into a local temp session tables (with on commit preserve rows)&lt;/li&gt;\n&lt;li&gt;Final insert query selecting the data from the session tables into a database table. (commit after this)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;When I run the script locally through Airflow, the script runs perfectly fine.\nOn Production, the script completes but the database table does not have any records inserted.&lt;/p&gt;\n\n&lt;p&gt;Any idea why this is happening?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12nprcv", "is_robot_indexable": true, "report_reasons": null, "author": "yyforthewin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12nprcv/db_query_execution_from_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12nprcv/db_query_execution_from_python/", "subreddit_subscribers": 99660, "created_utc": 1681607678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone ever done migration from cloud postgresql to bigquery?\nI am struggling with this. I would really appreciate if you can share how i can do it or any good tutorial. I can't use third party tool. I tried doing with python but no success. Also can't query from external source in bigquery.", "author_fullname": "t2_vkmvzdm7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to migrate Google cloud SQL data to bigquery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nnpu5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681603156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone ever done migration from cloud postgresql to bigquery?\nI am struggling with this. I would really appreciate if you can share how i can do it or any good tutorial. I can&amp;#39;t use third party tool. I tried doing with python but no success. Also can&amp;#39;t query from external source in bigquery.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12nnpu5", "is_robot_indexable": true, "report_reasons": null, "author": "shaikh21", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12nnpu5/how_to_migrate_google_cloud_sql_data_to_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12nnpu5/how_to_migrate_google_cloud_sql_data_to_bigquery/", "subreddit_subscribers": 99660, "created_utc": 1681603156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Schema Registry Statistics Tool is a small utility that allows you to easily identify the usage of different schema versions within a topic. Using this tool, you can consume from a topic, while calculating the percentage of each schema version.\n\nNow, you can generate a pie chart visualisation:\n\n[https://github.com/EladLeev/schema-registry-statistics#generate-pie-chart](https://github.com/EladLeev/schema-registry-statistics#generate-pie-chart)\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/oemfi3pby9ua1.png?width=826&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=408d7a86e76ea2cd6c9d60556d073d7940791a1f", "author_fullname": "t2_zrj6c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Schema Registry Statistics Tool is a small utility that allows you to easily identify the usage of different schema versions within a topic - now you can generate a pie chart from the results! \ud83d\ude80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 81, "top_awarded_type": null, "hide_score": false, "media_metadata": {"oemfi3pby9ua1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 63, "x": 108, "u": "https://preview.redd.it/oemfi3pby9ua1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd1fa0e78386bd8b87c1756748f03b9527f52765"}, {"y": 126, "x": 216, "u": "https://preview.redd.it/oemfi3pby9ua1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4258a79a66ee464065b92c5cee8c77b9f96d942b"}, {"y": 186, "x": 320, "u": "https://preview.redd.it/oemfi3pby9ua1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=902ae850be7cf5843c831ede0de3a83c1621e971"}, {"y": 373, "x": 640, "u": "https://preview.redd.it/oemfi3pby9ua1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7971b00e2a5a6582b8fa65ef53b30dd8a576ac10"}], "s": {"y": 482, "x": 826, "u": "https://preview.redd.it/oemfi3pby9ua1.png?width=826&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=408d7a86e76ea2cd6c9d60556d073d7940791a1f"}, "id": "oemfi3pby9ua1"}}, "name": "t3_12ogjlw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6Gr5TNFFJi5f3cshEHorniaSkint54n7ZSpbkgONQSw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1681663185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Schema Registry Statistics Tool is a small utility that allows you to easily identify the usage of different schema versions within a topic. Using this tool, you can consume from a topic, while calculating the percentage of each schema version.&lt;/p&gt;\n\n&lt;p&gt;Now, you can generate a pie chart visualisation:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/EladLeev/schema-registry-statistics#generate-pie-chart\"&gt;https://github.com/EladLeev/schema-registry-statistics#generate-pie-chart&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oemfi3pby9ua1.png?width=826&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=408d7a86e76ea2cd6c9d60556d073d7940791a1f\"&gt;https://preview.redd.it/oemfi3pby9ua1.png?width=826&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=408d7a86e76ea2cd6c9d60556d073d7940791a1f&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nMVeCqog8L1_DTShIMO_YJRinLKFx4x9CYtP5NwiyrM.jpg?auto=webp&amp;v=enabled&amp;s=29878004fcefff62a03f1e78c696739c014646e8", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/nMVeCqog8L1_DTShIMO_YJRinLKFx4x9CYtP5NwiyrM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f9efcd3b49ba6e8a24b18ee4c3e05fd594f4a817", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/nMVeCqog8L1_DTShIMO_YJRinLKFx4x9CYtP5NwiyrM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2795c009d62be8900fa30d59d80b79599daafe43", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/nMVeCqog8L1_DTShIMO_YJRinLKFx4x9CYtP5NwiyrM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=470b0be56bb28e6e520ed171524c6e79ecb5a216", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/nMVeCqog8L1_DTShIMO_YJRinLKFx4x9CYtP5NwiyrM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e85be684f7a19d3b9b24ee550e3f32545883fb8", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/nMVeCqog8L1_DTShIMO_YJRinLKFx4x9CYtP5NwiyrM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=578310c7a7cb10c94b8f4774d433eee3fbe4c4d8", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/nMVeCqog8L1_DTShIMO_YJRinLKFx4x9CYtP5NwiyrM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9151c82b0da43768f1889e746212ca0b098196b9", "width": 1080, "height": 540}], "variants": {}, "id": "MYzj5_ljryDZlsyPOShFIj6Hcpg0Je9ZkqeUh5pI8Fo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "12ogjlw", "is_robot_indexable": true, "report_reasons": null, "author": "eladleev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ogjlw/schema_registry_statistics_tool_is_a_small/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ogjlw/schema_registry_statistics_tool_is_a_small/", "subreddit_subscribers": 99660, "created_utc": 1681663185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nI'm a student and need some help.\n\nI need a few suggestions for where can I find large datasets (csv or excel files larger than 1 gb or something) for a Big data project I want to do for my portfolio. The idea is to load this large data set from csv to HDFS and create a few Hive tables and query for some analytics insights. I could also do some PySpark as well.\n\nP.S I looked at Kaggle, but just need a few expert suggestions to get started properly..\n\nThank you for taking the time to read.", "author_fullname": "t2_iascmrib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big Data dataset suggestion needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12of5ed", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681661239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a student and need some help.&lt;/p&gt;\n\n&lt;p&gt;I need a few suggestions for where can I find large datasets (csv or excel files larger than 1 gb or something) for a Big data project I want to do for my portfolio. The idea is to load this large data set from csv to HDFS and create a few Hive tables and query for some analytics insights. I could also do some PySpark as well.&lt;/p&gt;\n\n&lt;p&gt;P.S I looked at Kaggle, but just need a few expert suggestions to get started properly..&lt;/p&gt;\n\n&lt;p&gt;Thank you for taking the time to read.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12of5ed", "is_robot_indexable": true, "report_reasons": null, "author": "catchereye22", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12of5ed/big_data_dataset_suggestion_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12of5ed/big_data_dataset_suggestion_needed/", "subreddit_subscribers": 99660, "created_utc": 1681661239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey boys and girls, I was lucky enough to land an intern position as a DE that will be starting in a week or so. As I have limited experience Id like to ask for some basic tips on things I should know and what I could be expecting. \n\nAs I was interviewed I made it clear Ive started my transition (I come from retail) into IT just last October. I have  basic knowledge of Python and I do ok with SQL (which the intern could be quite heavy of. that and Azure). Ive studied almost enough to be able to take on AZ-900, but thats it really as far as cloud goes. Ive uploades couple of programs for assignments I was given for interviwes. Ive used Docker, Github, Jira. Ive played around with Snowflake and Airflow, but am far from experienced.\n\nAs far as the intern goes (approx. 6months)I will be under a \u201dtechnical consultant\u201d title and will be placed in a team to struggle with smaller tickets. The catch is that the goal of the intern is to prep me and learn enough to be able to get hired in the same company as a junior DE. \n\nIve started reading \u201dFundamentals of Data engineering\u201d as it appears to be mostly accepted as a good read. I am trying to decide wether I should start the IBM data engineer cert on Coursera or something else. The course seems to cover a lot of interesting topics and thought Id grind through it in a week and go as far as I can get.  One thing im a little anxious about is my Python isnt very strong.\n\nAny tips or suggestions/comments are most welcome! Thank you.", "author_fullname": "t2_tlsyf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting as a DE intern in a week. Id appreciate some \u201dwhat to expect\u201d and tips if have some.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12oo46l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681677548.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey boys and girls, I was lucky enough to land an intern position as a DE that will be starting in a week or so. As I have limited experience Id like to ask for some basic tips on things I should know and what I could be expecting. &lt;/p&gt;\n\n&lt;p&gt;As I was interviewed I made it clear Ive started my transition (I come from retail) into IT just last October. I have  basic knowledge of Python and I do ok with SQL (which the intern could be quite heavy of. that and Azure). Ive studied almost enough to be able to take on AZ-900, but thats it really as far as cloud goes. Ive uploades couple of programs for assignments I was given for interviwes. Ive used Docker, Github, Jira. Ive played around with Snowflake and Airflow, but am far from experienced.&lt;/p&gt;\n\n&lt;p&gt;As far as the intern goes (approx. 6months)I will be under a \u201dtechnical consultant\u201d title and will be placed in a team to struggle with smaller tickets. The catch is that the goal of the intern is to prep me and learn enough to be able to get hired in the same company as a junior DE. &lt;/p&gt;\n\n&lt;p&gt;Ive started reading \u201dFundamentals of Data engineering\u201d as it appears to be mostly accepted as a good read. I am trying to decide wether I should start the IBM data engineer cert on Coursera or something else. The course seems to cover a lot of interesting topics and thought Id grind through it in a week and go as far as I can get.  One thing im a little anxious about is my Python isnt very strong.&lt;/p&gt;\n\n&lt;p&gt;Any tips or suggestions/comments are most welcome! Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12oo46l", "is_robot_indexable": true, "report_reasons": null, "author": "BoSt0nov", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12oo46l/starting_as_a_de_intern_in_a_week_id_appreciate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12oo46l/starting_as_a_de_intern_in_a_week_id_appreciate/", "subreddit_subscribers": 99660, "created_utc": 1681677548.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any thoughts on what's the best practices, pros and cons !!! Thanks in advance.", "author_fullname": "t2_kbwr9eii", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can we use Data lake for a staging layer ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ol4x0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681671900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any thoughts on what&amp;#39;s the best practices, pros and cons !!! Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ol4x0", "is_robot_indexable": true, "report_reasons": null, "author": "Dismal-Ad3028", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ol4x0/can_we_use_data_lake_for_a_staging_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ol4x0/can_we_use_data_lake_for_a_staging_layer/", "subreddit_subscribers": 99660, "created_utc": 1681671900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI was looking for some nice events to attend and I stumbled upon this behemoth.\n\nTopics are super interesting but it is legit to ask if they are worth an EU month salary + the travel.\n\nI guess you get valuable information plus the possibility to network with other commited people that spend this much (?)\n\nAnybody knows anything about it?", "author_fullname": "t2_d0ifg2cb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "World Data Summit in Amsterdam. Is it worth the (2000\u20ac) ticket?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12oiu6w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681669712.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681667575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I was looking for some nice events to attend and I stumbled upon this behemoth.&lt;/p&gt;\n\n&lt;p&gt;Topics are super interesting but it is legit to ask if they are worth an EU month salary + the travel.&lt;/p&gt;\n\n&lt;p&gt;I guess you get valuable information plus the possibility to network with other commited people that spend this much (?)&lt;/p&gt;\n\n&lt;p&gt;Anybody knows anything about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12oiu6w", "is_robot_indexable": true, "report_reasons": null, "author": "Awkward-Cupcake6219", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12oiu6w/world_data_summit_in_amsterdam_is_it_worth_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12oiu6w/world_data_summit_in_amsterdam_is_it_worth_the/", "subreddit_subscribers": 99660, "created_utc": 1681667575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working at a large tech adjacent company as a Data Analyst for almost a year, and I am straight out of my bachelor\u2019s degree. I learned to code in college, have learned Tableau on the job, but have hardly done any actual data analysis since I started working. I have written three pipelines since I got here, use our GitHub repo, and fix existing pipelines. My team does not have any senior engineers or technical management, but I have been asking for the past 6 months to get a title change to DE, or for at least the expectations to be clear about what a title change would entail. I know that I lack experience in the field but my job now seems to align more with engineering than analyst work. Additionally, having an engineering title would change the way I\u2019m perceived at my work place. Some coworkers will gatekeep databases and other resources just based on me having an analyst title, and I am just trying to perform my job.\n\nIn terms of where I want to go with my career, I would love to be a DE for a couple years then maybe go into DevOps or DA. My educational background aligns more with systems optimization, so long term Id love to get back into that in some capacity.\n\nMy question is: is it fair to ask for this title change? If so, what can I say as evidence for my case? If not, where do I need to grow in order to make it happen? I understand many of these roles mean different things to different companies, but in the absence of a clear internally communicated standard for what a DE or an analyst is (we are still hiring externally though), I want to make my case. \n\nThank you!", "author_fullname": "t2_9ryn3bzj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analyst -&gt; Data Engineering Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12oheyn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681664787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working at a large tech adjacent company as a Data Analyst for almost a year, and I am straight out of my bachelor\u2019s degree. I learned to code in college, have learned Tableau on the job, but have hardly done any actual data analysis since I started working. I have written three pipelines since I got here, use our GitHub repo, and fix existing pipelines. My team does not have any senior engineers or technical management, but I have been asking for the past 6 months to get a title change to DE, or for at least the expectations to be clear about what a title change would entail. I know that I lack experience in the field but my job now seems to align more with engineering than analyst work. Additionally, having an engineering title would change the way I\u2019m perceived at my work place. Some coworkers will gatekeep databases and other resources just based on me having an analyst title, and I am just trying to perform my job.&lt;/p&gt;\n\n&lt;p&gt;In terms of where I want to go with my career, I would love to be a DE for a couple years then maybe go into DevOps or DA. My educational background aligns more with systems optimization, so long term Id love to get back into that in some capacity.&lt;/p&gt;\n\n&lt;p&gt;My question is: is it fair to ask for this title change? If so, what can I say as evidence for my case? If not, where do I need to grow in order to make it happen? I understand many of these roles mean different things to different companies, but in the absence of a clear internally communicated standard for what a DE or an analyst is (we are still hiring externally though), I want to make my case. &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12oheyn", "is_robot_indexable": true, "report_reasons": null, "author": "500Monarch59", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12oheyn/data_analyst_data_engineering_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12oheyn/data_analyst_data_engineering_question/", "subreddit_subscribers": 99660, "created_utc": 1681664787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_i6ulm8ug", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Data Engineer Interview Questions: Prepare for Your Next Data Engineering Job Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_12o96fw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RD3RtGP0z_4CEx-kflJ4YaxVTDK7O1lD7fWFR2H50vQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681653228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "itcertificate.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://itcertificate.org/blog/azure/azure-data-engineer-interview-questions", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1SeqWOmlwMsqlbroAmzs9ypulcEpJTO_0-LxqmvZcng.jpg?auto=webp&amp;v=enabled&amp;s=bcb7db6b500576c294a4e84196b24348b7f93a5b", "width": 612, "height": 404}, "resolutions": [{"url": "https://external-preview.redd.it/1SeqWOmlwMsqlbroAmzs9ypulcEpJTO_0-LxqmvZcng.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c994e367e173501b83a378cffc6fdfac7d7bad7", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/1SeqWOmlwMsqlbroAmzs9ypulcEpJTO_0-LxqmvZcng.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9adb84894e04de1e629c77d1349e92f7e0cb3a71", "width": 216, "height": 142}, {"url": "https://external-preview.redd.it/1SeqWOmlwMsqlbroAmzs9ypulcEpJTO_0-LxqmvZcng.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=171e71cc3040cac5050c8ec156d171c85f0ee68d", "width": 320, "height": 211}], "variants": {}, "id": "Zd0su1Wh39OTuM7yPbTcCRONnc65VKnfN9I3S6Jn1DY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12o96fw", "is_robot_indexable": true, "report_reasons": null, "author": "Intelligent_Tune_392", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o96fw/azure_data_engineer_interview_questions_prepare/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://itcertificate.org/blog/azure/azure-data-engineer-interview-questions", "subreddit_subscribers": 99660, "created_utc": 1681653228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Everyone,I am trying to run my airflow's cpu/memory task on Fargate (so we only pay for what we use). Currently we are running self-managed airflow in AWS EKS cluster and all my Dags use k8s operator to run POD per task and we don't have auto-scaling yet. I have explored ECS operator but that will require creating Task per image and it will be too much(given we have lot's of different images.\n\nI am wondering if we can do it some other way in which i don't have to modify my existing Dags too much", "author_fullname": "t2_tvjfoaqq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running Airflow task intensive Dags on Fargate.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12o1luy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681635791.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681634799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Everyone,I am trying to run my airflow&amp;#39;s cpu/memory task on Fargate (so we only pay for what we use). Currently we are running self-managed airflow in AWS EKS cluster and all my Dags use k8s operator to run POD per task and we don&amp;#39;t have auto-scaling yet. I have explored ECS operator but that will require creating Task per image and it will be too much(given we have lot&amp;#39;s of different images.&lt;/p&gt;\n\n&lt;p&gt;I am wondering if we can do it some other way in which i don&amp;#39;t have to modify my existing Dags too much&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12o1luy", "is_robot_indexable": true, "report_reasons": null, "author": "msf_venom", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o1luy/running_airflow_task_intensive_dags_on_fargate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12o1luy/running_airflow_task_intensive_dags_on_fargate/", "subreddit_subscribers": 99660, "created_utc": 1681634799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "could some one elaborate the cases where its preferred to chose one over the another?", "author_fullname": "t2_7owm6ym1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "why do we load it to GCS and then to bigquery and not directly to bigquery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12o0dar", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681631713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;could some one elaborate the cases where its preferred to chose one over the another?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12o0dar", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Tradition-3450", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o0dar/why_do_we_load_it_to_gcs_and_then_to_bigquery_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12o0dar/why_do_we_load_it_to_gcs_and_then_to_bigquery_and/", "subreddit_subscribers": 99660, "created_utc": 1681631713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I am exploring some ideas in the analytics &amp; data space and wonder what are most of the people doing for analytics once the data is in the datawarehouse. Mixpanel and amplitudes of the world are not designed for datawarehouses and metabase, looker UI/UX is not as user friendly especially for the business stakeholders. Thoughts?", "author_fullname": "t2_3tiq5c7i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to make the most out of Data Warehouse analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nkwld", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681597254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I am exploring some ideas in the analytics &amp;amp; data space and wonder what are most of the people doing for analytics once the data is in the datawarehouse. Mixpanel and amplitudes of the world are not designed for datawarehouses and metabase, looker UI/UX is not as user friendly especially for the business stakeholders. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12nkwld", "is_robot_indexable": true, "report_reasons": null, "author": "ownubie", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12nkwld/how_to_make_the_most_out_of_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12nkwld/how_to_make_the_most_out_of_data_warehouse/", "subreddit_subscribers": 99660, "created_utc": 1681597254.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Keep hearing the data gets cleaned/ transformed- what does it look like at the code level?", "author_fullname": "t2_7owm6ym1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When we say data gets transformed via dataflow/dataproc - what are some of example jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12oj8bi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681668326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Keep hearing the data gets cleaned/ transformed- what does it look like at the code level?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12oj8bi", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Tradition-3450", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12oj8bi/when_we_say_data_gets_transformed_via/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12oj8bi/when_we_say_data_gets_transformed_via/", "subreddit_subscribers": 99660, "created_utc": 1681668326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently looking for a on-prem application solutions for end user's to input data into a OLTP database. Something like what you could do with MS Access where you could create a front end. The database could be Azure SQL DB or just SQL server. Would I need to learn how to be a software developer or are there other \"low code\" solutions out there?", "author_fullname": "t2_8yface1u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Front-end for OLTP database options?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12njryb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681594959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently looking for a on-prem application solutions for end user&amp;#39;s to input data into a OLTP database. Something like what you could do with MS Access where you could create a front end. The database could be Azure SQL DB or just SQL server. Would I need to learn how to be a software developer or are there other &amp;quot;low code&amp;quot; solutions out there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12njryb", "is_robot_indexable": true, "report_reasons": null, "author": "Benmagz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12njryb/frontend_for_oltp_database_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12njryb/frontend_for_oltp_database_options/", "subreddit_subscribers": 99660, "created_utc": 1681594959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "do you think that would help in a DE job?", "author_fullname": "t2_1xbf9q7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "thinking of studying set theory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ocwja", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681658342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;do you think that would help in a DE job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ocwja", "is_robot_indexable": true, "report_reasons": null, "author": "aerdna69", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ocwja/thinking_of_studying_set_theory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ocwja/thinking_of_studying_set_theory/", "subreddit_subscribers": 99660, "created_utc": 1681658342.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}