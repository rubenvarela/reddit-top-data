{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thats all, thats the post. Idk why but it is just simply not intuitive. I feel like Dagster has so many great concepts, but trying to create my simple pipeline into a reality has been a real pain. Does anyone else feel this way? Do I need to keep sticking with it? \n\nIf anyone has any repositories or things/concepts that helped it click for you let me know.", "author_fullname": "t2_88vvqsgc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster Documentation Hurts my Brain", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ndwmo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681583580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thats all, thats the post. Idk why but it is just simply not intuitive. I feel like Dagster has so many great concepts, but trying to create my simple pipeline into a reality has been a real pain. Does anyone else feel this way? Do I need to keep sticking with it? &lt;/p&gt;\n\n&lt;p&gt;If anyone has any repositories or things/concepts that helped it click for you let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ndwmo", "is_robot_indexable": true, "report_reasons": null, "author": "roastmecerebrally", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ndwmo/dagster_documentation_hurts_my_brain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ndwmo/dagster_documentation_hurts_my_brain/", "subreddit_subscribers": 99498, "created_utc": 1681583580.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "on an architectural level...", "author_fullname": "t2_7owm6ym1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data lake just a theoretical construct? How does it look on a code level when we say implement in GCP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12o0euv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681631817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;on an architectural level...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12o0euv", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Tradition-3450", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o0euv/is_data_lake_just_a_theoretical_construct_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12o0euv/is_data_lake_just_a_theoretical_construct_how/", "subreddit_subscribers": 99498, "created_utc": 1681631817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have an s3 based data lake where the data is partitioned on org_id and date. There is a use case where in a customer can choose a time range and export the data. The following is the design I have in mind\n1. The user prompt will trigger a lambda that will take the date range and org id. \n2. The lambda will query against athena. The athena results are stored in s3. \n3. The above s3 put event will return the s3 path and the lambda will create a s3 presigned url. \n4. Send the presigned url to the user as an email. \n\n\nMy question is, will the above architecture work for data exports- esp using athena as a query engine on top of the s3 data lake?  Any idea on the number of concurrent queries athena can handle? Is there anything i need to include such as a mechanism to handle queuing of query requests?", "author_fullname": "t2_icq6ey6g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Architecture Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12o15z8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681633695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have an s3 based data lake where the data is partitioned on org_id and date. There is a use case where in a customer can choose a time range and export the data. The following is the design I have in mind\n1. The user prompt will trigger a lambda that will take the date range and org id. \n2. The lambda will query against athena. The athena results are stored in s3. \n3. The above s3 put event will return the s3 path and the lambda will create a s3 presigned url. \n4. Send the presigned url to the user as an email. &lt;/p&gt;\n\n&lt;p&gt;My question is, will the above architecture work for data exports- esp using athena as a query engine on top of the s3 data lake?  Any idea on the number of concurrent queries athena can handle? Is there anything i need to include such as a mechanism to handle queuing of query requests?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12o15z8", "is_robot_indexable": true, "report_reasons": null, "author": "Direct-Wrongdoer-939", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o15z8/data_architecture_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12o15z8/data_architecture_question/", "subreddit_subscribers": 99498, "created_utc": 1681633695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all!\nI have a question regarding this weird situation I am encountering.\nI am running a python script which makes a db connection to a Vertica database.\nOnce the connection is established, the script has 1 string which contains the following queries in the order below:\n\n- Delete records from the table (Commit after this)\n- 3 insert queries into a local temp session tables (with on commit preserve rows)\n- Final insert query selecting the data from the session tables into a database table. (commit after this)\n\nWhen I run the script locally through Airflow, the script runs perfectly fine.\nOn Production, the script completes but the database table does not have any records inserted.\n\nAny idea why this is happening?", "author_fullname": "t2_ahi836bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DB Query Execution from Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nprcv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681607678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all!\nI have a question regarding this weird situation I am encountering.\nI am running a python script which makes a db connection to a Vertica database.\nOnce the connection is established, the script has 1 string which contains the following queries in the order below:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Delete records from the table (Commit after this)&lt;/li&gt;\n&lt;li&gt;3 insert queries into a local temp session tables (with on commit preserve rows)&lt;/li&gt;\n&lt;li&gt;Final insert query selecting the data from the session tables into a database table. (commit after this)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;When I run the script locally through Airflow, the script runs perfectly fine.\nOn Production, the script completes but the database table does not have any records inserted.&lt;/p&gt;\n\n&lt;p&gt;Any idea why this is happening?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12nprcv", "is_robot_indexable": true, "report_reasons": null, "author": "yyforthewin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12nprcv/db_query_execution_from_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12nprcv/db_query_execution_from_python/", "subreddit_subscribers": 99498, "created_utc": 1681607678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone ever done migration from cloud postgresql to bigquery?\nI am struggling with this. I would really appreciate if you can share how i can do it or any good tutorial. I can't use third party tool. I tried doing with python but no success. Also can't query from external source in bigquery.", "author_fullname": "t2_vkmvzdm7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to migrate Google cloud SQL data to bigquery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nnpu5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681603156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone ever done migration from cloud postgresql to bigquery?\nI am struggling with this. I would really appreciate if you can share how i can do it or any good tutorial. I can&amp;#39;t use third party tool. I tried doing with python but no success. Also can&amp;#39;t query from external source in bigquery.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12nnpu5", "is_robot_indexable": true, "report_reasons": null, "author": "shaikh21", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12nnpu5/how_to_migrate_google_cloud_sql_data_to_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12nnpu5/how_to_migrate_google_cloud_sql_data_to_bigquery/", "subreddit_subscribers": 99498, "created_utc": 1681603156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working with Teradata for nearly 2 years now.Worked on many things related to it.\nBut I have limited knowledge on performance tuning  with Teradata(aware of basics- explain plan, collecting stats etc, PPIs, secondary indexes etc.)\n\nIs there any online content where I can find more details on performance tuning of SQL queries?  Any recommendation of online blogs, video tutorial links will be appreciated.\n\nThanks.", "author_fullname": "t2_qfsr1gqi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Teradata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ncqnn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681581323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working with Teradata for nearly 2 years now.Worked on many things related to it.\nBut I have limited knowledge on performance tuning  with Teradata(aware of basics- explain plan, collecting stats etc, PPIs, secondary indexes etc.)&lt;/p&gt;\n\n&lt;p&gt;Is there any online content where I can find more details on performance tuning of SQL queries?  Any recommendation of online blogs, video tutorial links will be appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12ncqnn", "is_robot_indexable": true, "report_reasons": null, "author": "Light7986", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ncqnn/teradata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ncqnn/teradata/", "subreddit_subscribers": 99498, "created_utc": 1681581323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First of all - I want to apologise. I know a large percentage of the posts here are from beginners looking into the field and I know it's annoying. But I think this one is at least a little different from the usual salary expectations or \"how to learn DE\" thread.\n\nI am currently a PhD student in molecular biology, but I have been thinking of mastering out and transitioning to DE/DA/DS. I naturally looked at DE as it seems to be the most coveted/high-paying of the three, but some of the concepts were fuzzy to me. I started reading \"Designing Data-Intensive Applications\" and it has helped a lot, a very well written book. One of the things it makes clear is that the need for data warehousing arises particularly in the context of large businesses where you want to separate the OLTP infrastructure from the OLAP infrastructure, so that analysts aren't making expensive queries on business critical operational databases. \n\nComing from a scientific background where data are essentially *entirely* analytical, this is a bit of an odd distinction to think about. It seems like data warehousing has no real analog in science. I wondered if there is something I am missing about data warehousing as a concept that goes beyond just a \"separate database for analytical queries\", considering it seems to be at the core of DE (which is again seemingly the most coveted of the Dx professions)? \n\nI can certainly see that structuring data in logical schemas and knowing tools to bring data in (and organise it) should be useful in science or anywhere. But having said that, I am now wondering how much of this field specifically is built around a workflow that applies in large organisations with huge customer/transaction databases and their peculiar needs. So, in other words, what do people here think -- are there DE workflows with academic science or other \"pure analytics\" domains in mind, and do warehousing concepts in particular have relevance there?", "author_fullname": "t2_42aau", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Non-traditional uses for data warehousing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12o3gz8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681639398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all - I want to apologise. I know a large percentage of the posts here are from beginners looking into the field and I know it&amp;#39;s annoying. But I think this one is at least a little different from the usual salary expectations or &amp;quot;how to learn DE&amp;quot; thread.&lt;/p&gt;\n\n&lt;p&gt;I am currently a PhD student in molecular biology, but I have been thinking of mastering out and transitioning to DE/DA/DS. I naturally looked at DE as it seems to be the most coveted/high-paying of the three, but some of the concepts were fuzzy to me. I started reading &amp;quot;Designing Data-Intensive Applications&amp;quot; and it has helped a lot, a very well written book. One of the things it makes clear is that the need for data warehousing arises particularly in the context of large businesses where you want to separate the OLTP infrastructure from the OLAP infrastructure, so that analysts aren&amp;#39;t making expensive queries on business critical operational databases. &lt;/p&gt;\n\n&lt;p&gt;Coming from a scientific background where data are essentially &lt;em&gt;entirely&lt;/em&gt; analytical, this is a bit of an odd distinction to think about. It seems like data warehousing has no real analog in science. I wondered if there is something I am missing about data warehousing as a concept that goes beyond just a &amp;quot;separate database for analytical queries&amp;quot;, considering it seems to be at the core of DE (which is again seemingly the most coveted of the Dx professions)? &lt;/p&gt;\n\n&lt;p&gt;I can certainly see that structuring data in logical schemas and knowing tools to bring data in (and organise it) should be useful in science or anywhere. But having said that, I am now wondering how much of this field specifically is built around a workflow that applies in large organisations with huge customer/transaction databases and their peculiar needs. So, in other words, what do people here think -- are there DE workflows with academic science or other &amp;quot;pure analytics&amp;quot; domains in mind, and do warehousing concepts in particular have relevance there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12o3gz8", "is_robot_indexable": true, "report_reasons": null, "author": "omgpop", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o3gz8/nontraditional_uses_for_data_warehousing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12o3gz8/nontraditional_uses_for_data_warehousing/", "subreddit_subscribers": 99498, "created_utc": 1681639398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Everyone,I am trying to run my airflow's cpu/memory task on Fargate (so we only pay for what we use). Currently we are running self-managed airflow in AWS EKS cluster and all my Dags use k8s operator to run POD per task and we don't have auto-scaling yet. I have explored ECS operator but that will require creating Task per image and it will be too much(given we have lot's of different images.\n\nI am wondering if we can do it some other way in which i don't have to modify my existing Dags too much", "author_fullname": "t2_tvjfoaqq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running Airflow task intensive Dags on Fargate.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12o1luy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681635791.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681634799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Everyone,I am trying to run my airflow&amp;#39;s cpu/memory task on Fargate (so we only pay for what we use). Currently we are running self-managed airflow in AWS EKS cluster and all my Dags use k8s operator to run POD per task and we don&amp;#39;t have auto-scaling yet. I have explored ECS operator but that will require creating Task per image and it will be too much(given we have lot&amp;#39;s of different images.&lt;/p&gt;\n\n&lt;p&gt;I am wondering if we can do it some other way in which i don&amp;#39;t have to modify my existing Dags too much&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12o1luy", "is_robot_indexable": true, "report_reasons": null, "author": "msf_venom", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o1luy/running_airflow_task_intensive_dags_on_fargate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12o1luy/running_airflow_task_intensive_dags_on_fargate/", "subreddit_subscribers": 99498, "created_utc": 1681634799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "could some one elaborate the cases where its preferred to chose one over the another?", "author_fullname": "t2_7owm6ym1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "why do we load it to GCS and then to bigquery and not directly to bigquery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12o0dar", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681631713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;could some one elaborate the cases where its preferred to chose one over the another?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12o0dar", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Tradition-3450", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12o0dar/why_do_we_load_it_to_gcs_and_then_to_bigquery_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12o0dar/why_do_we_load_it_to_gcs_and_then_to_bigquery_and/", "subreddit_subscribers": 99498, "created_utc": 1681631713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I am exploring some ideas in the analytics &amp; data space and wonder what are most of the people doing for analytics once the data is in the datawarehouse. Mixpanel and amplitudes of the world are not designed for datawarehouses and metabase, looker UI/UX is not as user friendly especially for the business stakeholders. Thoughts?", "author_fullname": "t2_3tiq5c7i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to make the most out of Data Warehouse analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nkwld", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681597254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I am exploring some ideas in the analytics &amp;amp; data space and wonder what are most of the people doing for analytics once the data is in the datawarehouse. Mixpanel and amplitudes of the world are not designed for datawarehouses and metabase, looker UI/UX is not as user friendly especially for the business stakeholders. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12nkwld", "is_robot_indexable": true, "report_reasons": null, "author": "ownubie", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12nkwld/how_to_make_the_most_out_of_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12nkwld/how_to_make_the_most_out_of_data_warehouse/", "subreddit_subscribers": 99498, "created_utc": 1681597254.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We currently run Spark and Hudi on EMR.  I\u2019ve been asked to do a POC for setting up the same stack on Kubernetes.\n\nIs anyone aware of reliable Helm charts or Docker images that could be leveraged as a baseline?\n\nThis is my first foray into K8s and it feels like a lot to learn. Any tips or guidance?  We will be looking at Fargate and also EKS.", "author_fullname": "t2_fer0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experience setting up Spark and Hudi on Kubernetes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12na3wg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681576224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We currently run Spark and Hudi on EMR.  I\u2019ve been asked to do a POC for setting up the same stack on Kubernetes.&lt;/p&gt;\n\n&lt;p&gt;Is anyone aware of reliable Helm charts or Docker images that could be leveraged as a baseline?&lt;/p&gt;\n\n&lt;p&gt;This is my first foray into K8s and it feels like a lot to learn. Any tips or guidance?  We will be looking at Fargate and also EKS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12na3wg", "is_robot_indexable": true, "report_reasons": null, "author": "TheCauthon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12na3wg/experience_setting_up_spark_and_hudi_on_kubernetes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12na3wg/experience_setting_up_spark_and_hudi_on_kubernetes/", "subreddit_subscribers": 99498, "created_utc": 1681576224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are adopting bigquery and I have a requirement to export large tables to a single CSV. These are tables well in excess of the 1GB file limit. \n\nThere seems to be many different ways to do this, none of which are particularly good? \n\n1) Recursive compose - I found python code from a google dev blog that allows for compose in excess of 32 files but when I try it soaks up all the cpu and hangs, even on 1 file. Still looking into this. \n\n2) Pyspark - fine to do the export, but it seems like it's very inefficient to run the coalesce on the dataframe to get one partition as that happens on a single node? I am going to try running this in serverless dataproc mode to see if autoscaling helps. \n\n3) Copy the files to the local file system and run cat. Would work but seems kinda old school? \n\nDo you all have other ideas?", "author_fullname": "t2_39nrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "bigquery large tables to csv", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n9nvf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681575555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are adopting bigquery and I have a requirement to export large tables to a single CSV. These are tables well in excess of the 1GB file limit. &lt;/p&gt;\n\n&lt;p&gt;There seems to be many different ways to do this, none of which are particularly good? &lt;/p&gt;\n\n&lt;p&gt;1) Recursive compose - I found python code from a google dev blog that allows for compose in excess of 32 files but when I try it soaks up all the cpu and hangs, even on 1 file. Still looking into this. &lt;/p&gt;\n\n&lt;p&gt;2) Pyspark - fine to do the export, but it seems like it&amp;#39;s very inefficient to run the coalesce on the dataframe to get one partition as that happens on a single node? I am going to try running this in serverless dataproc mode to see if autoscaling helps. &lt;/p&gt;\n\n&lt;p&gt;3) Copy the files to the local file system and run cat. Would work but seems kinda old school? &lt;/p&gt;\n\n&lt;p&gt;Do you all have other ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12n9nvf", "is_robot_indexable": true, "report_reasons": null, "author": "arborealguy", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12n9nvf/bigquery_large_tables_to_csv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12n9nvf/bigquery_large_tables_to_csv/", "subreddit_subscribers": 99498, "created_utc": 1681575555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5cgbpdbh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Diving into the Future: Serverless Data Warehouse Platform Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 59, "top_awarded_type": null, "hide_score": false, "name": "t3_12n6shn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Dpm5A_UJvVPcJoU5Ej3aqiwZa26424uqj1Iffv6efQY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681571540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "databend.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.databend.com/blog/2023/04/13/diving-into-the-future-serverless-data-warehouse-platform-architecture/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2i4y4ur_w9Zm5GLTTCxPmFxtidjIA37wypTJic1hGA8.jpg?auto=webp&amp;v=enabled&amp;s=91391bd25d84a560236232ee3c0ad4c936cc33a4", "width": 1876, "height": 799}, "resolutions": [{"url": "https://external-preview.redd.it/2i4y4ur_w9Zm5GLTTCxPmFxtidjIA37wypTJic1hGA8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d5e8ce9a98a80da9bf5ab68a5d868c99632b78b5", "width": 108, "height": 45}, {"url": "https://external-preview.redd.it/2i4y4ur_w9Zm5GLTTCxPmFxtidjIA37wypTJic1hGA8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c2f2c585db55edd51e07bee86ac9d4beebfd0692", "width": 216, "height": 91}, {"url": "https://external-preview.redd.it/2i4y4ur_w9Zm5GLTTCxPmFxtidjIA37wypTJic1hGA8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7129633690960b716cdd465a6f0b95e07d2b988c", "width": 320, "height": 136}, {"url": "https://external-preview.redd.it/2i4y4ur_w9Zm5GLTTCxPmFxtidjIA37wypTJic1hGA8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4816b53b13ace18152784d12856d82c950f651b4", "width": 640, "height": 272}, {"url": "https://external-preview.redd.it/2i4y4ur_w9Zm5GLTTCxPmFxtidjIA37wypTJic1hGA8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d64784ed0d0911d035ce370630a05ea285dbc4d", "width": 960, "height": 408}, {"url": "https://external-preview.redd.it/2i4y4ur_w9Zm5GLTTCxPmFxtidjIA37wypTJic1hGA8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bda5ec9483c46ab209ebd0fd852a6c2e306e166f", "width": 1080, "height": 459}], "variants": {}, "id": "rPO5lJ3zPMxPH3wNXtvkYTcOqg6BHOpTKgvVTe_M61k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12n6shn", "is_robot_indexable": true, "report_reasons": null, "author": "PsiACE", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12n6shn/diving_into_the_future_serverless_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.databend.com/blog/2023/04/13/diving-into-the-future-serverless-data-warehouse-platform-architecture/", "subreddit_subscribers": 99498, "created_utc": 1681571540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently looking for a on-prem application solutions for end user's to input data into a OLTP database. Something like what you could do with MS Access where you could create a front end. The database could be Azure SQL DB or just SQL server. Would I need to learn how to be a software developer or are there other \"low code\" solutions out there?", "author_fullname": "t2_8yface1u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Front-end for OLTP database options?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12njryb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681594959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently looking for a on-prem application solutions for end user&amp;#39;s to input data into a OLTP database. Something like what you could do with MS Access where you could create a front end. The database could be Azure SQL DB or just SQL server. Would I need to learn how to be a software developer or are there other &amp;quot;low code&amp;quot; solutions out there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12njryb", "is_robot_indexable": true, "report_reasons": null, "author": "Benmagz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12njryb/frontend_for_oltp_database_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12njryb/frontend_for_oltp_database_options/", "subreddit_subscribers": 99498, "created_utc": 1681594959.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}