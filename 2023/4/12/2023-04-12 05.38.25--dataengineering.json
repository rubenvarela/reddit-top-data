{"kind": "Listing", "data": {"after": "t3_12j14x0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have experience in DE for about 7 years and currently promoted to Data Architect role. I understand my responsibilities which include laying out data models, architecture diagrams, suggesting the best tools for a particular scenario. I have worked majorly in Azure and Databricks .\n\nPlease suggest the learning path / thinking methodology for me to be better at my current role.", "author_fullname": "t2_2xxs9nne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have been recently promoted to Data Architect Role. I need help on learning resources/pointers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12iaaka", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 64, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 64, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681199121.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681192407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have experience in DE for about 7 years and currently promoted to Data Architect role. I understand my responsibilities which include laying out data models, architecture diagrams, suggesting the best tools for a particular scenario. I have worked majorly in Azure and Databricks .&lt;/p&gt;\n\n&lt;p&gt;Please suggest the learning path / thinking methodology for me to be better at my current role.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12iaaka", "is_robot_indexable": true, "report_reasons": null, "author": "inglocines", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12iaaka/i_have_been_recently_promoted_to_data_architect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12iaaka/i_have_been_recently_promoted_to_data_architect/", "subreddit_subscribers": 98156, "created_utc": 1681192407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_975og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to use dbt source freshness tests to detect stale data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_12inq6z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/noCUQVwfgAxpdD300vlHP-w_Vk1xBMS_Ttf-9Ny8RNw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681227499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datafold.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.datafold.com/blog/dbt-source-freshness", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?auto=webp&amp;v=enabled&amp;s=4a2e7bf440d31e813fbfed118f2002466730cdef", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd999aa101b6b02ad7b9401b6512c65d55b7d934", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e543df1eb9d1e1b52ec25a320c6494e1e6eb4ba", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c8ac3945ef71a946231120973bab1279083550a", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a64035e5ef1f38e6d55725ff6d4e337d9d60bee", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32af2cff24ddc953b8c0d4f53d80d44fd01cd7ab", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db2d5a8b7088d3f01673eab7d94b8ca156d2b999", "width": 1080, "height": 607}], "variants": {}, "id": "Hk_DWgM9iMOzRYbc08qVJTco8z-aNttuxoSZwBKbciQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12inq6z", "is_robot_indexable": true, "report_reasons": null, "author": "arimbr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12inq6z/how_to_use_dbt_source_freshness_tests_to_detect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.datafold.com/blog/dbt-source-freshness", "subreddit_subscribers": 98156, "created_utc": 1681227499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_y15lw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "can't wait for an end to end python stack with no JVM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 103, "top_awarded_type": null, "hide_score": false, "name": "t3_12j7r5a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IVtkBFTdy6wb_ultldon2dXCzFnQtjFqzFZiKdkcPHM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681268644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/a7vapom3ddta1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/a7vapom3ddta1.png?auto=webp&amp;v=enabled&amp;s=8e49a38b53640e241ecd7a0c63338e79f610bb88", "width": 675, "height": 499}, "resolutions": [{"url": "https://preview.redd.it/a7vapom3ddta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e59f54818661a1f02c1f2caaf39abb88727f732f", "width": 108, "height": 79}, {"url": "https://preview.redd.it/a7vapom3ddta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47db9062274382922b857ae6c9765d3c07590a52", "width": 216, "height": 159}, {"url": "https://preview.redd.it/a7vapom3ddta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8ba2a12d1ebaa941c5e23368adbf91175876411", "width": 320, "height": 236}, {"url": "https://preview.redd.it/a7vapom3ddta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de2d220ff2b85f9e9be938ffe6e988ee53d28ab8", "width": 640, "height": 473}], "variants": {}, "id": "VWAOafcCAez2w9lRangcKQAjb5pHZtPJuWUg41y5Jbw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "12j7r5a", "is_robot_indexable": true, "report_reasons": null, "author": "gorkemyurt", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12j7r5a/cant_wait_for_an_end_to_end_python_stack_with_no/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/a7vapom3ddta1.png", "subreddit_subscribers": 98156, "created_utc": 1681268644.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've made a simple ETL project orchestrated by Airflow. The process is basically download &gt;&gt; transform &gt;&gt; load into Postgres.\n\n    with DAG(...):\n        task1 = PythonOperator(\n            task_id = \"DownloadData\",\n            python_callable = download_task\n        \u00a0 \u00a0 )\n        task2 = PythonOperator(\n            task_id = \"TransformData\",\n            python_callable = transform_task\n        \u00a0 \u00a0 )\n        ...\n        task1 &gt;&gt; task2 &gt;&gt; task3\n\nFirst task downloads more than 10k text-based files containing weather data. Its speed is okay (4 minutes w/ multithreading).\n\nThe problem is the second task. I used pandas to transform text-based files into clean data in .tsv format.\n\n    def _read_file(filename):\n        with open(filename, \"r\", encoding=\"UTF-8\") as f:\n            for line in f:           \n                line_content = [float(i) for i in line.split()]\n                yield {\n                    \"station_id\": filename,\n                    \"date\": f\"line_content[0]-line_content[1]-line_content[2]\"\n                    \"air_temperature\": line_content[4],\n                    ...\n                }\n\nI use `_read_file()` to read the content of the text-based file and make it a pandas dataframe to transform it.\n\n[raw text-based file \\(weather hourly data\\)](https://preview.redd.it/vritpkald8ta1.png?width=867&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c0bd6140837ad95c0bb1e21554326086803ea5c2)\n\n&amp;#x200B;\n\n    def transform(filename):        \n        # Create a dataframe out of file data\n        file_data = _read_file(filename)\n        df = pd.DataFrame(file_data)\n    \n        # Get the summarization of data (min, mean, max)\n        df = df.groupby(['station_id', 'date']).agg(\n            air_temperature_avg = ('air_temperature', 'mean'),\n            air_temperature_min = ('air_temperature', 'min'),\n            air_temperature_max = ('air_temperature', 'max'),\n            ...\n        )\n    \n        df.to_csv(f\"{filename}.tsv\", sep = \"\\t\")\n\n&amp;#x200B;\n\n[transformed data \\(daily summary: mean, min, and max\\)](https://preview.redd.it/06xqm23od8ta1.png?width=890&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1748787299abfd1424251c2c3aaa1c2fae69a4b0)\n\nThen i use the transform function in transform\\_task to summarize 10k+ raw text-based files one by one\n\n    def transform_task():\n        for filename in glob.glob(\"raw_directory/*\"): \u00a0 \u00a0 \u00a0 \u00a0 \n            transform(filename)\n\n&amp;#x200B;\n\nNote: I'm doing this locally in my laptop, not in cloud\n\nTransformation of each file is quick, about 0.15-0.20 seconds each. However, there are more than 10k files to transform so it takes about 40 minutes to accomplish the task. What do you think can be done to make this process faster?  Thanks in advance!", "author_fullname": "t2_3j0efkbj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[ETL Project] Transformation with Python pandas too slow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vritpkald8ta1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 53, "x": 108, "u": "https://preview.redd.it/vritpkald8ta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d107e03c8260dff820045e7e6b041408e268535"}, {"y": 107, "x": 216, "u": "https://preview.redd.it/vritpkald8ta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=305ecb53d459cda96dc5281d32a37c1d34e2191d"}, {"y": 159, "x": 320, "u": "https://preview.redd.it/vritpkald8ta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7efb5852a4692e1ef85dbbd54b5e6c9f1e7fd6c9"}, {"y": 318, "x": 640, "u": "https://preview.redd.it/vritpkald8ta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c4f60aaf2291325653e15b89ac6d89ad0170331"}], "s": {"y": 432, "x": 867, "u": "https://preview.redd.it/vritpkald8ta1.png?width=867&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c0bd6140837ad95c0bb1e21554326086803ea5c2"}, "id": "vritpkald8ta1"}, "06xqm23od8ta1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 34, "x": 108, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93511b5de9624e32b16b8c2cffa927a77321a831"}, {"y": 68, "x": 216, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=828c0732137bab2a055716c074977acf9fb5a5da"}, {"y": 101, "x": 320, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=782d8bd64676f91b572919eafda1b15c4c9eb021"}, {"y": 202, "x": 640, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=61f15eef99db8331ce810c947905e612bba073c8"}], "s": {"y": 281, "x": 890, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=890&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1748787299abfd1424251c2c3aaa1c2fae69a4b0"}, "id": "06xqm23od8ta1"}}, "name": "t3_12ie2fq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wf4RNpLcW-lz-jrhuDtUGh4NumBHQWJQDlF-mGfc-uA.jpg", "edited": 1681211557.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681204509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve made a simple ETL project orchestrated by Airflow. The process is basically download &amp;gt;&amp;gt; transform &amp;gt;&amp;gt; load into Postgres.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;with DAG(...):\n    task1 = PythonOperator(\n        task_id = &amp;quot;DownloadData&amp;quot;,\n        python_callable = download_task\n    \u00a0 \u00a0 )\n    task2 = PythonOperator(\n        task_id = &amp;quot;TransformData&amp;quot;,\n        python_callable = transform_task\n    \u00a0 \u00a0 )\n    ...\n    task1 &amp;gt;&amp;gt; task2 &amp;gt;&amp;gt; task3\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;First task downloads more than 10k text-based files containing weather data. Its speed is okay (4 minutes w/ multithreading).&lt;/p&gt;\n\n&lt;p&gt;The problem is the second task. I used pandas to transform text-based files into clean data in .tsv format.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def _read_file(filename):\n    with open(filename, &amp;quot;r&amp;quot;, encoding=&amp;quot;UTF-8&amp;quot;) as f:\n        for line in f:           \n            line_content = [float(i) for i in line.split()]\n            yield {\n                &amp;quot;station_id&amp;quot;: filename,\n                &amp;quot;date&amp;quot;: f&amp;quot;line_content[0]-line_content[1]-line_content[2]&amp;quot;\n                &amp;quot;air_temperature&amp;quot;: line_content[4],\n                ...\n            }\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I use &lt;code&gt;_read_file()&lt;/code&gt; to read the content of the text-based file and make it a pandas dataframe to transform it.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vritpkald8ta1.png?width=867&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c0bd6140837ad95c0bb1e21554326086803ea5c2\"&gt;raw text-based file (weather hourly data)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def transform(filename):        \n    # Create a dataframe out of file data\n    file_data = _read_file(filename)\n    df = pd.DataFrame(file_data)\n\n    # Get the summarization of data (min, mean, max)\n    df = df.groupby([&amp;#39;station_id&amp;#39;, &amp;#39;date&amp;#39;]).agg(\n        air_temperature_avg = (&amp;#39;air_temperature&amp;#39;, &amp;#39;mean&amp;#39;),\n        air_temperature_min = (&amp;#39;air_temperature&amp;#39;, &amp;#39;min&amp;#39;),\n        air_temperature_max = (&amp;#39;air_temperature&amp;#39;, &amp;#39;max&amp;#39;),\n        ...\n    )\n\n    df.to_csv(f&amp;quot;{filename}.tsv&amp;quot;, sep = &amp;quot;\\t&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/06xqm23od8ta1.png?width=890&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1748787299abfd1424251c2c3aaa1c2fae69a4b0\"&gt;transformed data (daily summary: mean, min, and max)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Then i use the transform function in transform_task to summarize 10k+ raw text-based files one by one&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def transform_task():\n    for filename in glob.glob(&amp;quot;raw_directory/*&amp;quot;): \u00a0 \u00a0 \u00a0 \u00a0 \n        transform(filename)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Note: I&amp;#39;m doing this locally in my laptop, not in cloud&lt;/p&gt;\n\n&lt;p&gt;Transformation of each file is quick, about 0.15-0.20 seconds each. However, there are more than 10k files to transform so it takes about 40 minutes to accomplish the task. What do you think can be done to make this process faster?  Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ie2fq", "is_robot_indexable": true, "report_reasons": null, "author": "Pervert_Spongebob", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ie2fq/etl_project_transformation_with_python_pandas_too/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ie2fq/etl_project_transformation_with_python_pandas_too/", "subreddit_subscribers": 98156, "created_utc": 1681204509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Project with Airflow, DuckDB, MinIO, Streamlit and the AstroSDK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_12io51t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ir3H1xOoIb8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow Quickstart Project with DuckDB, MinIO and Streamlit\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Airflow Quickstart Project with DuckDB, MinIO and Streamlit", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ir3H1xOoIb8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow Quickstart Project with DuckDB, MinIO and Streamlit\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ir3H1xOoIb8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ir3H1xOoIb8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow Quickstart Project with DuckDB, MinIO and Streamlit\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/12io51t", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/C1naVPMCf-NVQ2t-oeXHMl4fPtikScSkrLYr21lQT7E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681228317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/ir3H1xOoIb8", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ncIe23vBi-MwJHABiGjw0JSN8zu2i_6GCRasr2wttP4.jpg?auto=webp&amp;v=enabled&amp;s=6a0b7647651ce6f2c4af2fce28200cdcfc7c73f3", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/ncIe23vBi-MwJHABiGjw0JSN8zu2i_6GCRasr2wttP4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b290915d178f1ee75ceff5f7e053dc7566fd4c3a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/ncIe23vBi-MwJHABiGjw0JSN8zu2i_6GCRasr2wttP4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=138ae22da4e6f615e245d1293fccfb34a57665cf", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/ncIe23vBi-MwJHABiGjw0JSN8zu2i_6GCRasr2wttP4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b8bf888802f94138883b0e352a8feb2a5456274", "width": 320, "height": 240}], "variants": {}, "id": "JA9sMYD-6aEO4BCBc0r4btyF20uJ4WxAJhbu-4uefp8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12io51t", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12io51t/data_engineering_project_with_airflow_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/ir3H1xOoIb8", "subreddit_subscribers": 98156, "created_utc": 1681228317.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Airflow Quickstart Project with DuckDB, MinIO and Streamlit", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ir3H1xOoIb8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow Quickstart Project with DuckDB, MinIO and Streamlit\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ir3H1xOoIb8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all\n\nI'm making my way through the data engineering course on Databricks Academy and it's alright but I feel like every lesson is just someone reading from a notebook and executing SQL/ Python in the notebook. Feels like there's a lot of context missing (e.g there's course setup code but we never see this code).\n\nIs there any alternatives you prefer when learning Databricks?", "author_fullname": "t2_56o0g58i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative to Databricks academy for learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ivqk8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681243414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m making my way through the data engineering course on Databricks Academy and it&amp;#39;s alright but I feel like every lesson is just someone reading from a notebook and executing SQL/ Python in the notebook. Feels like there&amp;#39;s a lot of context missing (e.g there&amp;#39;s course setup code but we never see this code).&lt;/p&gt;\n\n&lt;p&gt;Is there any alternatives you prefer when learning Databricks?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ivqk8", "is_robot_indexable": true, "report_reasons": null, "author": "IG-55", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ivqk8/alternative_to_databricks_academy_for_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ivqk8/alternative_to_databricks_academy_for_learning/", "subreddit_subscribers": 98156, "created_utc": 1681243414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are you familiar with Data Quality and Great Expectations? \n\nI recently started using this library on a data pipeline. As a junior Data Engineer, I found the documentation quite overwhelming and unsuitable for Databricks. However, I was able to create a workflow for my team: \n\n1. **Fill a form to create an expectation suite**\n2. **run / schedule a data factory**\n3. **get mail /notification with report**\n\nI'm also looking for ways to automate data exploration so I can better understand the values associated with each expectation. I know Ydata exists, but my data scientist doesn't seem to like it.   \n\nGreat Expectations is a library that runs tests without the need for manual coding them.\n\nIf anyone is experienced with this library and wants to provide me with some tips, feel free to reach out! I'm also eager to discuss my ideas for a future post.", "author_fullname": "t2_7clw5kel", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monitoring data with Great Expectations - Junior Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12j5ltv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681263762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are you familiar with Data Quality and Great Expectations? &lt;/p&gt;\n\n&lt;p&gt;I recently started using this library on a data pipeline. As a junior Data Engineer, I found the documentation quite overwhelming and unsuitable for Databricks. However, I was able to create a workflow for my team: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Fill a form to create an expectation suite&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;run / schedule a data factory&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;get mail /notification with report&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m also looking for ways to automate data exploration so I can better understand the values associated with each expectation. I know Ydata exists, but my data scientist doesn&amp;#39;t seem to like it.   &lt;/p&gt;\n\n&lt;p&gt;Great Expectations is a library that runs tests without the need for manual coding them.&lt;/p&gt;\n\n&lt;p&gt;If anyone is experienced with this library and wants to provide me with some tips, feel free to reach out! I&amp;#39;m also eager to discuss my ideas for a future post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12j5ltv", "is_robot_indexable": true, "report_reasons": null, "author": "Independent_Ad6023", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12j5ltv/monitoring_data_with_great_expectations_junior/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12j5ltv/monitoring_data_with_great_expectations_junior/", "subreddit_subscribers": 98156, "created_utc": 1681263762.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious how everyone is feeling.\n\n[View Poll](https://www.reddit.com/poll/12ir3f6)", "author_fullname": "t2_rdm9w1f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How burnt out are you? (Non Students)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ir3f6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681234429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious how everyone is feeling.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/12ir3f6\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ir3f6", "is_robot_indexable": true, "report_reasons": null, "author": "keeney_arcadia", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1681493629835, "options": [{"text": "I love my job!", "id": "22511488"}, {"text": "It comes in waves", "id": "22511489"}, {"text": "I'm regularly stressed", "id": "22511490"}, {"text": "I loathe going to work", "id": "22511491"}, {"text": "I'm buried in work and see no light at the end of the tunnel", "id": "22511492"}, {"text": "It's just a job, I put my 8 hours in and dip", "id": "22511493"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 953, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ir3f6/how_burnt_out_are_you_non_students/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/12ir3f6/how_burnt_out_are_you_non_students/", "subreddit_subscribers": 98156, "created_utc": 1681234429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team currently have our data sitting in a delta lake in an Azure storage account. We use Databricks on Azure to ingest and process data.\n\nWe have gotten to the stage where we would like to create an API to act as an interface to output data to web applications run by other teams as we don't want to tie their applications directly to the use of delta. We want them to be able to pass in parameters, we would then do some final steps of processing using the parameters provided, and then we want to send the output data directly back to the calling application. The final output of data will be a time-series and we expect that in the future the time-series could have in excess of one million items. The tables that will be queried are fairly large and growing so we want to minimise the compute time of the calculations by using Spark or some other method that is as fast. Ideally, we would want to do this without a wrapper layer that we would need to host external to Databricks, at least for now.\n\nWe realise that our setup is fairly similar to what other teams seem to have and were wondering how anyone else has managed to achieve what we are trying to.", "author_fullname": "t2_n937n0g6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Lake/Databricks egress via API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12iodei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681228788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team currently have our data sitting in a delta lake in an Azure storage account. We use Databricks on Azure to ingest and process data.&lt;/p&gt;\n\n&lt;p&gt;We have gotten to the stage where we would like to create an API to act as an interface to output data to web applications run by other teams as we don&amp;#39;t want to tie their applications directly to the use of delta. We want them to be able to pass in parameters, we would then do some final steps of processing using the parameters provided, and then we want to send the output data directly back to the calling application. The final output of data will be a time-series and we expect that in the future the time-series could have in excess of one million items. The tables that will be queried are fairly large and growing so we want to minimise the compute time of the calculations by using Spark or some other method that is as fast. Ideally, we would want to do this without a wrapper layer that we would need to host external to Databricks, at least for now.&lt;/p&gt;\n\n&lt;p&gt;We realise that our setup is fairly similar to what other teams seem to have and were wondering how anyone else has managed to achieve what we are trying to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12iodei", "is_robot_indexable": true, "report_reasons": null, "author": "piri9825", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12iodei/delta_lakedatabricks_egress_via_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12iodei/delta_lakedatabricks_egress_via_api/", "subreddit_subscribers": 98156, "created_utc": 1681228788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \nAbout me: I joined the corporate world as an Data engineer just after graduating in mid 2021 (but my current work revolves around Data analytics, SQL and Python). Total exp: 1.5yrs\n\nI am currently in a dilemma: whether I should continue as a Data Engineer by expanding my skills (learning Spark etc) or switch to SDE roles (safe evergreen option).\n\nI have few concerns about DE role which is kinda stopping me from fully deep diving into it. \n\n1. Are data engineers considered 2nd class employees in a company? I have read that DE is a role that supports business functions and Data scientist and are generally not profit generating employees (away from business) hence their efforts can sometimes go unnoticed.\n\n2. How does day in a life looks like? Work life balance and work environment?\n\n3. Growth prospects: Can a DE transition/grow into leadership positions?\n\n\nLooking for some guidance. Thanks in advance!", "author_fullname": "t2_75txeq7v4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is DE a good role in terms of work and work life balance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12idd74", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681204269.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681202190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, \nAbout me: I joined the corporate world as an Data engineer just after graduating in mid 2021 (but my current work revolves around Data analytics, SQL and Python). Total exp: 1.5yrs&lt;/p&gt;\n\n&lt;p&gt;I am currently in a dilemma: whether I should continue as a Data Engineer by expanding my skills (learning Spark etc) or switch to SDE roles (safe evergreen option).&lt;/p&gt;\n\n&lt;p&gt;I have few concerns about DE role which is kinda stopping me from fully deep diving into it. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Are data engineers considered 2nd class employees in a company? I have read that DE is a role that supports business functions and Data scientist and are generally not profit generating employees (away from business) hence their efforts can sometimes go unnoticed.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How does day in a life looks like? Work life balance and work environment?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Growth prospects: Can a DE transition/grow into leadership positions?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Looking for some guidance. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12idd74", "is_robot_indexable": true, "report_reasons": null, "author": "Skrirraa", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12idd74/is_de_a_good_role_in_terms_of_work_and_work_life/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12idd74/is_de_a_good_role_in_terms_of_work_and_work_life/", "subreddit_subscribers": 98156, "created_utc": 1681202190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've seen a few people mention trino + data lake. I see in the trino docs that it's designed to query different sources directly, ie without prior etl/elt. \n\nSo why bother with a data lake? \n\nI can imagine it's to make reads faster, for better organization, and to avoid noisy neighbor type issues on source systems. \n\nAnyone have ideas on those or other reasons?", "author_fullname": "t2_ut20i32q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why use trino on a data lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ip77n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681230527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen a few people mention trino + data lake. I see in the trino docs that it&amp;#39;s designed to query different sources directly, ie without prior etl/elt. &lt;/p&gt;\n\n&lt;p&gt;So why bother with a data lake? &lt;/p&gt;\n\n&lt;p&gt;I can imagine it&amp;#39;s to make reads faster, for better organization, and to avoid noisy neighbor type issues on source systems. &lt;/p&gt;\n\n&lt;p&gt;Anyone have ideas on those or other reasons?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ip77n", "is_robot_indexable": true, "report_reasons": null, "author": "alex_o_h", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ip77n/why_use_trino_on_a_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ip77n/why_use_trino_on_a_data_lake/", "subreddit_subscribers": 98156, "created_utc": 1681230527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello DE friends.\n\nMy current company uses Apache Airflow for scheduling, and we are quite happy with it. But giving technically gifted PMs the ability to make simple DAGs from a visual interface would be amazing.\n\nFor this we love the N8N interface. \n\nHowever the native N8N scheduler and workflows are too lacking and overcomplicated to use for our workflows.\n\nHence my question.\n\nHas anyone connected N8N or any no-code solution to Airflow? \n\nLet me be specific. We aren't looking to trigger a DAG from N8N. We'd like to build it there, task by task, and then have the resulting DAG deployed on Airflow.\n\nIf you have any hints, ideas or projects that you think are doing this, I'd be super interested.\n\nThanks for your help \ud83d\ude4f", "author_fullname": "t2_85uwiihz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using no-code to create simple Airflow Dags", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12icsvl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681200327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello DE friends.&lt;/p&gt;\n\n&lt;p&gt;My current company uses Apache Airflow for scheduling, and we are quite happy with it. But giving technically gifted PMs the ability to make simple DAGs from a visual interface would be amazing.&lt;/p&gt;\n\n&lt;p&gt;For this we love the N8N interface. &lt;/p&gt;\n\n&lt;p&gt;However the native N8N scheduler and workflows are too lacking and overcomplicated to use for our workflows.&lt;/p&gt;\n\n&lt;p&gt;Hence my question.&lt;/p&gt;\n\n&lt;p&gt;Has anyone connected N8N or any no-code solution to Airflow? &lt;/p&gt;\n\n&lt;p&gt;Let me be specific. We aren&amp;#39;t looking to trigger a DAG from N8N. We&amp;#39;d like to build it there, task by task, and then have the resulting DAG deployed on Airflow.&lt;/p&gt;\n\n&lt;p&gt;If you have any hints, ideas or projects that you think are doing this, I&amp;#39;d be super interested.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your help \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12icsvl", "is_robot_indexable": true, "report_reasons": null, "author": "GeekyTricky", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12icsvl/using_nocode_to_create_simple_airflow_dags/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12icsvl/using_nocode_to_create_simple_airflow_dags/", "subreddit_subscribers": 98156, "created_utc": 1681200327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have experience with these (cloud or open source) and can either recommend or warn against using them?", "author_fullname": "t2_hhn5ois5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Estuary or Airbyte for binlog/WAL CDC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12j3jzu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681259250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have experience with these (cloud or open source) and can either recommend or warn against using them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12j3jzu", "is_robot_indexable": true, "report_reasons": null, "author": "datarbeiter", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12j3jzu/estuary_or_airbyte_for_binlogwal_cdc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12j3jzu/estuary_or_airbyte_for_binlogwal_cdc/", "subreddit_subscribers": 98156, "created_utc": 1681259250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9wrfjdsj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Lakehouse by the sea: Migrating Seafowl storage layer to delta-rs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_12ivoi5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/rESLgC8lkPhmLkFb5qvPHsEMV5HAbJcWWjzDSMWoV_4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681243302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "splitgraph.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.splitgraph.com/blog/seafowl-delta-storage-layer", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?auto=webp&amp;v=enabled&amp;s=0e71ea909937e503f7c833b044201cba0a51063c", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65db8ae9f1540d295f00950b12174d7be3508625", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef63e238179153a4a97e6b2aeb3be247c0fab18a", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=114619e03e3054a5fa0cae59378077ea601c4948", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b01ec1e97553be30eeef904cd70222598fa4dbac", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b850d0b1d23c39f8132a7f3d26e2ae978ddea7b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=726ad6e29157a5a4b019406464a60331cf91597c", "width": 1080, "height": 567}], "variants": {}, "id": "kwl5UPry6AuAlyMdIEIWUnQ47W6ryiRkRihcsErskV4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12ivoi5", "is_robot_indexable": true, "report_reasons": null, "author": "gruuya", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ivoi5/a_lakehouse_by_the_sea_migrating_seafowl_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.splitgraph.com/blog/seafowl-delta-storage-layer", "subreddit_subscribers": 98156, "created_utc": 1681243302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, I have a question, probably very strange one, but I have a task on this which is killing me.\nThe problem is that I have a lot of JSON files that need to be processed. The files have different structure schema, but the requester wants to have the data flattened in a table with a very general structure, to cover all formats. The data will be used then for reporting.\n Is there any possible way to do this? \nI would appreciate any suggestion on how the final table may look like and how to flatten the data. The implementation should be done in Java, but I would not focus now on this.\n Thank you very much!", "author_fullname": "t2_8ouamdf5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Generic JSON schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12irysl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681236123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I have a question, probably very strange one, but I have a task on this which is killing me.\nThe problem is that I have a lot of JSON files that need to be processed. The files have different structure schema, but the requester wants to have the data flattened in a table with a very general structure, to cover all formats. The data will be used then for reporting.\n Is there any possible way to do this? \nI would appreciate any suggestion on how the final table may look like and how to flatten the data. The implementation should be done in Java, but I would not focus now on this.\n Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12irysl", "is_robot_indexable": true, "report_reasons": null, "author": "adaptrix", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12irysl/generic_json_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12irysl/generic_json_schema/", "subreddit_subscribers": 98156, "created_utc": 1681236123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A few months ago, I left a position I liked because a recruiter called and offered me significantly more money.  I can tell this new job is not a fit.  People are checked out.  My manager is like a C-. The pace is slow.  I can do the job, but it probably won't be enjoyable.  It is kinda of a heads down focus on your task and dont rock the boat sort of place.  This is really not my personality.  I  like to work with people who are trying to shake things up and build cool shit.\n\nThere is a good chance my previous team would take me back - I left on positive terms.\n\nHave any of you bummerranged back a previous team? What was your experience? Is this a bad idea? Anyone else had a similar experience, what did you do?", "author_fullname": "t2_6dg4p0s1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Returning to previous employer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12j7oys", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681268510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few months ago, I left a position I liked because a recruiter called and offered me significantly more money.  I can tell this new job is not a fit.  People are checked out.  My manager is like a C-. The pace is slow.  I can do the job, but it probably won&amp;#39;t be enjoyable.  It is kinda of a heads down focus on your task and dont rock the boat sort of place.  This is really not my personality.  I  like to work with people who are trying to shake things up and build cool shit.&lt;/p&gt;\n\n&lt;p&gt;There is a good chance my previous team would take me back - I left on positive terms.&lt;/p&gt;\n\n&lt;p&gt;Have any of you bummerranged back a previous team? What was your experience? Is this a bad idea? Anyone else had a similar experience, what did you do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12j7oys", "is_robot_indexable": true, "report_reasons": null, "author": "discord-ian", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12j7oys/returning_to_previous_employer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12j7oys/returning_to_previous_employer/", "subreddit_subscribers": 98156, "created_utc": 1681268510.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have seen the data space have emerged in the last few years, I have mostly build tools from scratch or frameworks on top of open source tools like great expectations.\n\nHowever, currently looking for some good tools like Monte Carlo, that gives all in one and monitors data at rest in the lake or warehouse.\n\nI am looking for some suggestions and experience in that space and cost associated as well.\n\nParticularly looking for tools with nice UI that can run all the top checks like freshness, activity, table size monitor, count monitor etc by default without manual setup, having OSS would be nice.\n\n\nThanks", "author_fullname": "t2_dhgy4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tool do you use for data observability?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12j7dgx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681270463.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681267809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have seen the data space have emerged in the last few years, I have mostly build tools from scratch or frameworks on top of open source tools like great expectations.&lt;/p&gt;\n\n&lt;p&gt;However, currently looking for some good tools like Monte Carlo, that gives all in one and monitors data at rest in the lake or warehouse.&lt;/p&gt;\n\n&lt;p&gt;I am looking for some suggestions and experience in that space and cost associated as well.&lt;/p&gt;\n\n&lt;p&gt;Particularly looking for tools with nice UI that can run all the top checks like freshness, activity, table size monitor, count monitor etc by default without manual setup, having OSS would be nice.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12j7dgx", "is_robot_indexable": true, "report_reasons": null, "author": "mjfnd", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12j7dgx/what_tool_do_you_use_for_data_observability/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12j7dgx/what_tool_do_you_use_for_data_observability/", "subreddit_subscribers": 98156, "created_utc": 1681267809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since each company uses different tools for their environment how do we manage to learn the one's we don't know when applying for a role? How in-depth should I go when learning a new tool since I might not use that tool for too long before having to switch to something new at a different company?", "author_fullname": "t2_76fvluuq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with learning the many changes of tools in this field.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12iyemq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681248637.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since each company uses different tools for their environment how do we manage to learn the one&amp;#39;s we don&amp;#39;t know when applying for a role? How in-depth should I go when learning a new tool since I might not use that tool for too long before having to switch to something new at a different company?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12iyemq", "is_robot_indexable": true, "report_reasons": null, "author": "notGaruda1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12iyemq/how_to_deal_with_learning_the_many_changes_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12iyemq/how_to_deal_with_learning_the_many_changes_of/", "subreddit_subscribers": 98156, "created_utc": 1681248637.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7idw1yfm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The database inside out with event streams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 61, "top_awarded_type": null, "hide_score": false, "name": "t3_12ih4dp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b-6fjQm3Jj02KsbW6pCoFxI7xmg1wQorUJ0tT_uF0wM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681213375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@hugo.oliveira.rocha/the-database-inside-out-with-event-streams-86d4a54192eb", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FK2aKV_Zmm73XT_WBi7YAIU3ZvECCLmfmj_94ivkAPE.jpg?auto=webp&amp;v=enabled&amp;s=e08d1b7c1918c19adb4f232f59c8b09c12447f7e", "width": 675, "height": 295}, "resolutions": [{"url": "https://external-preview.redd.it/FK2aKV_Zmm73XT_WBi7YAIU3ZvECCLmfmj_94ivkAPE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=439e1fdf2dfa6e664df9b1d530e5ee3e3f69daf6", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/FK2aKV_Zmm73XT_WBi7YAIU3ZvECCLmfmj_94ivkAPE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d127b0df7284249c7496901a227819ab91d9d14e", "width": 216, "height": 94}, {"url": "https://external-preview.redd.it/FK2aKV_Zmm73XT_WBi7YAIU3ZvECCLmfmj_94ivkAPE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e83383852aeae4e29f66cd0177a00b25f7013c3b", "width": 320, "height": 139}, {"url": "https://external-preview.redd.it/FK2aKV_Zmm73XT_WBi7YAIU3ZvECCLmfmj_94ivkAPE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d925b3c797747156f3e1761c2dbd2b7a9b901f21", "width": 640, "height": 279}], "variants": {}, "id": "4WI2vDdx00P6JZuRulbSxSPr0L92GguFn-TKiPFusZE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12ih4dp", "is_robot_indexable": true, "report_reasons": null, "author": "-segmentationfault-", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ih4dp/the_database_inside_out_with_event_streams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@hugo.oliveira.rocha/the-database-inside-out-with-event-streams-86d4a54192eb", "subreddit_subscribers": 98156, "created_utc": 1681213375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm building a credit scoring system to calculate the credit score of customers. I was using Airbyte and AWS Glue to load and transform data. After I have cleansed customer data, I need to load and, schedule, calculate score in a Nodejs backend system. Should I use the AWS Glue data catalog or use directly s3 parquet file to load customer data on the Nodejs backend server?", "author_fullname": "t2_jrfbf4ez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I use AWS Glue Data Catalog, Parquet S3 AWS file to load data on Nodejs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12jag37", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681275101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m building a credit scoring system to calculate the credit score of customers. I was using Airbyte and AWS Glue to load and transform data. After I have cleansed customer data, I need to load and, schedule, calculate score in a Nodejs backend system. Should I use the AWS Glue data catalog or use directly s3 parquet file to load customer data on the Nodejs backend server?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12jag37", "is_robot_indexable": true, "report_reasons": null, "author": "Jazzlike_Tax7147", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12jag37/should_i_use_aws_glue_data_catalog_parquet_s3_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12jag37/should_i_use_aws_glue_data_catalog_parquet_s3_aws/", "subreddit_subscribers": 98156, "created_utc": 1681275101.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am pretty new to elastic search and this thing has been confusing me for sometime. My company has an AWS Opensearch cluster and the indices have key mappings(python script for creating index with key mappings and is run for creating the index). But when I query the index, I see fields that are not present in the key mapping. My assumption was that the mapping is done to provide more or less a schema to the index. Am I missing something?", "author_fullname": "t2_icq6ey6g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opensearch Confusion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12j7t9w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681268776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am pretty new to elastic search and this thing has been confusing me for sometime. My company has an AWS Opensearch cluster and the indices have key mappings(python script for creating index with key mappings and is run for creating the index). But when I query the index, I see fields that are not present in the key mapping. My assumption was that the mapping is done to provide more or less a schema to the index. Am I missing something?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12j7t9w", "is_robot_indexable": true, "report_reasons": null, "author": "Direct-Wrongdoer-939", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12j7t9w/opensearch_confusion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12j7t9w/opensearch_confusion/", "subreddit_subscribers": 98156, "created_utc": 1681268776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What to expect on a final interview with a VP?\n\nAfter skipping the initial phone screen I jumped straight into meeting with the hiring managers. \n\nThen I did a technical assessment round two days later.\n\nNow a day after that I have a final 30 minute interview with a VP. \n\nThis is moving extremely fast as I am used to longer turnaround times. Is there something I could prepare for? Do final interviews focus more on a certain aspect? Or is this just a formality?", "author_fullname": "t2_8u28pzjt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to expect on a final round interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12j7968", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681267537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What to expect on a final interview with a VP?&lt;/p&gt;\n\n&lt;p&gt;After skipping the initial phone screen I jumped straight into meeting with the hiring managers. &lt;/p&gt;\n\n&lt;p&gt;Then I did a technical assessment round two days later.&lt;/p&gt;\n\n&lt;p&gt;Now a day after that I have a final 30 minute interview with a VP. &lt;/p&gt;\n\n&lt;p&gt;This is moving extremely fast as I am used to longer turnaround times. Is there something I could prepare for? Do final interviews focus more on a certain aspect? Or is this just a formality?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12j7968", "is_robot_indexable": true, "report_reasons": null, "author": "sidesalads", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12j7968/what_to_expect_on_a_final_round_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12j7968/what_to_expect_on_a_final_round_interview/", "subreddit_subscribers": 98156, "created_utc": 1681267537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm kind of new to this but my understanding is that non-structured data can but uploaded to a data warehouse and them transformed. ELT so to speak.\n\nNow when I think of non-structured data I'm thinking of something like video or pictures or things of that nature. I've never worked with either of those things. However, I seem to be working a lot with poorly formatted text files from a legacy financial system.\n\nThe files look something like the below example...\n\nDon't focus on the made up data, focus on the structure.\n\nThis is the kind of garbage I've been working with.  I've been using AWK and SED and regular expressions to parse through all this crap to turn it into a Column/Row dataset.\n\nIt's not easy, sometimes I'll have to take header data like 'OP: A031' and 'USER:XSYS1414 ' and create columns for those as well because that will change throughout the entire file.\n\nI guess my questions are:\n\n1. What do you call doing this type of shit of turning dog-shit into diamonds? ETL Development?\n2. Is there an easier way of doing this?\n\n&amp;#x200B;\n\n\\--1             ------- REPORT.THIS.IS-THE.REPORT\\_NAME\\_5411 -------                                1/2111 USER:XSYS1414         \n\n4/11/2023 2340  OP: A031                                                                                                                     X\\_RTXN\\_JNL\n\nLOC# ACCT\\_NBR  POLICY  OP# DATETIME TXN\\_CODE     RATE    AMT\\_DUE    NEXT\\_DUE  LC         BALANCE \n\n   12A 1234567     G18         H152  0955         60                   4.5        1,000.16      5/11/2023  0.00   -9,999.16 \n\n   99   84124581 T800         T1000 0955          50                   2.5         500.16       5/11/2023  0.00   1,500.16 \n\n   99   645665485T800         T1000 0955         60                   4.5        1,000.16      5/12/2023  39.00-9,999.16 \n\n\\--2             ------- REPORT.THIS.IS-THE.REPORT\\_NAME\\_5411 -------                                2/2111 USER:XSYS1414         \n\n4/11/2023 2340  OP: A031                                                                                                                     X\\_RTXN\\_JNL\n\n   12A 1234567     G18         H152  0955         60                   4.5        1,000.16      5/11/2023  0.00   -9,999.16 \n\n   99   84124581 T800         T1000 0955          50                   2.5         500.16       5/11/2023  0.00   1,500.16 \n\n   99   645665485T800         T1000 0955         60                   4.5        1,000.16      5/12/2023  39.00-9,999.16 \n\n\\--3             ------- REPORT.THIS.IS-THE.REPORT\\_NAME\\_5411 -------                                3/2111 USER:XSYS1414         \n\n4/11/2023 2340  OP: A031                                                                                                                     X\\_RTXN\\_JNL        \n\n   12A 1234567     G18         H152  0955         60                   4.5        1,000.16      5/11/2023  0.00   -9,999.16 \n\n   99   84124581 T800         T1000 0955          50                   2.5         500.16       5/11/2023  0.00   1,500.16 \n\n   99   645665485T800         T1000 0955         60                   4.5        1,000.16      5/12/2023  39.00-9,999.16 \n\n\\*\n\n\\*\\*\n\n\\*\\*\\*                                           LOC#                       BALANCE             AVG BALANCE\n\n\\*\\*\\*\\*                                         12A                          $1,565,568.13      $487.684.08\n\n\\*\\*\\*\\*\\*                                         99                           $5,665,138.19     $268.586.12\n\n\\*\\*\\*\\*\\*\\*                                                                    =============    =============\n\n\\*\\*\\*\\*\\*\\*\\*                                                                    $99,874,698.15    $3,555,987.01\n\n\\--4             ------- REPORT.THIS.IS-THE.REPORT\\_NAME\\_5411 -------                                3/2111 USER:XSYS1414         \n\n4/11/2023 2340  OP: A031                                                                                                                     X\\_RTXN\\_JNL        \n\n   12A 1234567     G18         H152  0955         60                   4.5        1,000.16      5/11/2023  0.00   -9,999.16 \n\n   99   84124581 T800         T1000 0955          50                   2.5         500.16       5/11/2023  0.00   1,500.16 \n\n   99   645665485T800         T1000 0955         60                   4.5        1,000.16      5/12/2023  39.00-9,999.16", "author_fullname": "t2_12fb7o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hi All. Question about ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12j53i2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681262621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m kind of new to this but my understanding is that non-structured data can but uploaded to a data warehouse and them transformed. ELT so to speak.&lt;/p&gt;\n\n&lt;p&gt;Now when I think of non-structured data I&amp;#39;m thinking of something like video or pictures or things of that nature. I&amp;#39;ve never worked with either of those things. However, I seem to be working a lot with poorly formatted text files from a legacy financial system.&lt;/p&gt;\n\n&lt;p&gt;The files look something like the below example...&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t focus on the made up data, focus on the structure.&lt;/p&gt;\n\n&lt;p&gt;This is the kind of garbage I&amp;#39;ve been working with.  I&amp;#39;ve been using AWK and SED and regular expressions to parse through all this crap to turn it into a Column/Row dataset.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not easy, sometimes I&amp;#39;ll have to take header data like &amp;#39;OP: A031&amp;#39; and &amp;#39;USER:XSYS1414 &amp;#39; and create columns for those as well because that will change throughout the entire file.&lt;/p&gt;\n\n&lt;p&gt;I guess my questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What do you call doing this type of shit of turning dog-shit into diamonds? ETL Development?&lt;/li&gt;\n&lt;li&gt;Is there an easier way of doing this?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;--1             ------- REPORT.THIS.IS-THE.REPORT_NAME_5411 -------                                1/2111 USER:XSYS1414         &lt;/p&gt;\n\n&lt;p&gt;4/11/2023 2340  OP: A031                                                                                                                     X_RTXN_JNL&lt;/p&gt;\n\n&lt;p&gt;LOC# ACCT_NBR  POLICY  OP# DATETIME TXN_CODE     RATE    AMT_DUE    NEXT_DUE  LC         BALANCE &lt;/p&gt;\n\n&lt;p&gt;12A 1234567     G18         H152  0955         60                   4.5        1,000.16      5/11/2023  0.00   -9,999.16 &lt;/p&gt;\n\n&lt;p&gt;99   84124581 T800         T1000 0955          50                   2.5         500.16       5/11/2023  0.00   1,500.16 &lt;/p&gt;\n\n&lt;p&gt;99   645665485T800         T1000 0955         60                   4.5        1,000.16      5/12/2023  39.00-9,999.16 &lt;/p&gt;\n\n&lt;p&gt;--2             ------- REPORT.THIS.IS-THE.REPORT_NAME_5411 -------                                2/2111 USER:XSYS1414         &lt;/p&gt;\n\n&lt;p&gt;4/11/2023 2340  OP: A031                                                                                                                     X_RTXN_JNL&lt;/p&gt;\n\n&lt;p&gt;12A 1234567     G18         H152  0955         60                   4.5        1,000.16      5/11/2023  0.00   -9,999.16 &lt;/p&gt;\n\n&lt;p&gt;99   84124581 T800         T1000 0955          50                   2.5         500.16       5/11/2023  0.00   1,500.16 &lt;/p&gt;\n\n&lt;p&gt;99   645665485T800         T1000 0955         60                   4.5        1,000.16      5/12/2023  39.00-9,999.16 &lt;/p&gt;\n\n&lt;p&gt;--3             ------- REPORT.THIS.IS-THE.REPORT_NAME_5411 -------                                3/2111 USER:XSYS1414         &lt;/p&gt;\n\n&lt;p&gt;4/11/2023 2340  OP: A031                                                                                                                     X_RTXN_JNL        &lt;/p&gt;\n\n&lt;p&gt;12A 1234567     G18         H152  0955         60                   4.5        1,000.16      5/11/2023  0.00   -9,999.16 &lt;/p&gt;\n\n&lt;p&gt;99   84124581 T800         T1000 0955          50                   2.5         500.16       5/11/2023  0.00   1,500.16 &lt;/p&gt;\n\n&lt;p&gt;99   645665485T800         T1000 0955         60                   4.5        1,000.16      5/12/2023  39.00-9,999.16 &lt;/p&gt;\n\n&lt;p&gt;*&lt;/p&gt;\n\n&lt;p&gt;**&lt;/p&gt;\n\n&lt;p&gt;***                                           LOC#                       BALANCE             AVG BALANCE&lt;/p&gt;\n\n&lt;p&gt;****                                         12A                          $1,565,568.13      $487.684.08&lt;/p&gt;\n\n&lt;p&gt;*****                                         99                           $5,665,138.19     $268.586.12&lt;/p&gt;\n\n&lt;p&gt;******                                                                    =============    =============&lt;/p&gt;\n\n&lt;p&gt;*******                                                                    $99,874,698.15    $3,555,987.01&lt;/p&gt;\n\n&lt;p&gt;--4             ------- REPORT.THIS.IS-THE.REPORT_NAME_5411 -------                                3/2111 USER:XSYS1414         &lt;/p&gt;\n\n&lt;p&gt;4/11/2023 2340  OP: A031                                                                                                                     X_RTXN_JNL        &lt;/p&gt;\n\n&lt;p&gt;12A 1234567     G18         H152  0955         60                   4.5        1,000.16      5/11/2023  0.00   -9,999.16 &lt;/p&gt;\n\n&lt;p&gt;99   84124581 T800         T1000 0955          50                   2.5         500.16       5/11/2023  0.00   1,500.16 &lt;/p&gt;\n\n&lt;p&gt;99   645665485T800         T1000 0955         60                   4.5        1,000.16      5/12/2023  39.00-9,999.16&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12j53i2", "is_robot_indexable": true, "report_reasons": null, "author": "Mad_Finesse", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12j53i2/hi_all_question_about_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12j53i2/hi_all_question_about_etl/", "subreddit_subscribers": 98156, "created_utc": 1681262621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "audit\\_helper vs data-diff for validating dbt model changes: [https://www.datafold.com/blog/dbt-audit-helper-vs-data-diff](https://www.datafold.com/blog/dbt-audit-helper-vs-data-diff)\n\naudit\\_helper and data-diff are both open source tools that help you ensure unexpected data changes don't break your dbt data and ruin your day/week/job/reputation.\n\nDisclosure: I work for Datafold (maintainer of data-diff). I hope you'll find my assessment credible and reasonably unbiased, as I remain an active contributor to both tools.\n\nAlso, this is pretty much my first time posting here, so please forgive me if I've done it wrong.", "author_fullname": "t2_ifguj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "audit_helper vs data-diff for validating dbt model changes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12j2ypg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681257990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;audit_helper vs data-diff for validating dbt model changes: &lt;a href=\"https://www.datafold.com/blog/dbt-audit-helper-vs-data-diff\"&gt;https://www.datafold.com/blog/dbt-audit-helper-vs-data-diff&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;audit_helper and data-diff are both open source tools that help you ensure unexpected data changes don&amp;#39;t break your dbt data and ruin your day/week/job/reputation.&lt;/p&gt;\n\n&lt;p&gt;Disclosure: I work for Datafold (maintainer of data-diff). I hope you&amp;#39;ll find my assessment credible and reasonably unbiased, as I remain an active contributor to both tools.&lt;/p&gt;\n\n&lt;p&gt;Also, this is pretty much my first time posting here, so please forgive me if I&amp;#39;ve done it wrong.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zzW2E5_qvZIAM8kjSZRgTanD7778oTTggMOCta4D3e0.jpg?auto=webp&amp;v=enabled&amp;s=3dfe62649eb7f5201768bf964f507b2999f0d1e6", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/zzW2E5_qvZIAM8kjSZRgTanD7778oTTggMOCta4D3e0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d35fe03ee21d00b409f7d2d37b3bd78d22d0304", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/zzW2E5_qvZIAM8kjSZRgTanD7778oTTggMOCta4D3e0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c7513d2cfa7efc1dff38d6cd4f60463f01b0d7d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/zzW2E5_qvZIAM8kjSZRgTanD7778oTTggMOCta4D3e0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a6def34249d6832e94980c60f1a9b74f6b12f37", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/zzW2E5_qvZIAM8kjSZRgTanD7778oTTggMOCta4D3e0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19f22968e22ccc17637a2f1d8c344a6cc9c67906", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/zzW2E5_qvZIAM8kjSZRgTanD7778oTTggMOCta4D3e0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de586443e63d6a4756e8033bc3c4db55a2d411a4", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/zzW2E5_qvZIAM8kjSZRgTanD7778oTTggMOCta4D3e0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff017948218d5e271b4e25038643405a08bdb485", "width": 1080, "height": 607}], "variants": {}, "id": "qnpsOWNS__r_rxa3Y5IFco3E9_px-laotq8WpV6ekgg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "12j2ypg", "is_robot_indexable": true, "report_reasons": null, "author": "leoebrown", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12j2ypg/audit_helper_vs_datadiff_for_validating_dbt_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12j2ypg/audit_helper_vs_datadiff_for_validating_dbt_model/", "subreddit_subscribers": 98156, "created_utc": 1681257990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3yleu7rp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is Data Lineage and Techniques to Implement it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 81, "top_awarded_type": null, "hide_score": false, "name": "t3_12j14x0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VF6MCDNr9N1PWnqW5p6_9mYALWcVmjAFSNZkp40aBQA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681254216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/alvin-ai/what-is-data-lineage-and-techniques-to-implement-it-4f1939b11327", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-h1Hqjbj9IvWRBFPSqWrG-r7WNvMK2bjvWdJtTZTeeY.jpg?auto=webp&amp;v=enabled&amp;s=c6f1da1b8154f316a58090cc6c6c7f530585d921", "width": 1200, "height": 696}, "resolutions": [{"url": "https://external-preview.redd.it/-h1Hqjbj9IvWRBFPSqWrG-r7WNvMK2bjvWdJtTZTeeY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94e87a2fd0ca7f2fcbc92e947dcf67fa3e48135b", "width": 108, "height": 62}, {"url": "https://external-preview.redd.it/-h1Hqjbj9IvWRBFPSqWrG-r7WNvMK2bjvWdJtTZTeeY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e6eb179644db7d2e38e6d21faa63371a109f398", "width": 216, "height": 125}, {"url": "https://external-preview.redd.it/-h1Hqjbj9IvWRBFPSqWrG-r7WNvMK2bjvWdJtTZTeeY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e5af42b03665c9cfd65694ffe5570cd7f316392", "width": 320, "height": 185}, {"url": "https://external-preview.redd.it/-h1Hqjbj9IvWRBFPSqWrG-r7WNvMK2bjvWdJtTZTeeY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2a34c5e9eab1d91d9e651113f9e0c477bb865e2", "width": 640, "height": 371}, {"url": "https://external-preview.redd.it/-h1Hqjbj9IvWRBFPSqWrG-r7WNvMK2bjvWdJtTZTeeY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a1e5ac0d470a08abc7922c5c3118d20595522ff", "width": 960, "height": 556}, {"url": "https://external-preview.redd.it/-h1Hqjbj9IvWRBFPSqWrG-r7WNvMK2bjvWdJtTZTeeY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b0f14ec14f4b4cc1015da7542d31312d5c228424", "width": 1080, "height": 626}], "variants": {}, "id": "VBeG5Dp67xreLwp4k-0bslAs1J16qklu6xm7xlmcq08"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12j14x0", "is_robot_indexable": true, "report_reasons": null, "author": "gabsferreiradev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12j14x0/what_is_data_lineage_and_techniques_to_implement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/alvin-ai/what-is-data-lineage-and-techniques-to-implement-it-4f1939b11327", "subreddit_subscribers": 98156, "created_utc": 1681254216.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}