{"kind": "Listing", "data": {"after": "t3_12crttu", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone, I\u2019m part of Fight for the Future, a digital rights org that\u2019s been fighting for ebook access.\n\nFollowing  the recent ruling against the Internet Archive (and libraries in  general), we\u2019re organizing an in-person rally outside IA\u2019s San Francisco  headquarters. We want to get loud and demonstrate the popular support  for libraries and their ability to own, lend, and preserve ebooks.\n\nIf  you\u2019re in the SF area and have been following this case, we\u2019d love to  see you this Saturday at 11am. We\u2019ll have signs but encourage you to  BYOS as well! Here\u2019s a link to RSVP: [https://actionnetwork.org/events/dont-delete-our-books-rally-in-san-francisco](https://actionnetwork.org/events/dont-delete-our-books-rally-in-san-francisco)\n\nThanks, hope to see some of you there.", "author_fullname": "t2_6ncim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rally to support Internet Archive in SF on Saturday", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ct6wl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 767, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 767, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680718879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I\u2019m part of Fight for the Future, a digital rights org that\u2019s been fighting for ebook access.&lt;/p&gt;\n\n&lt;p&gt;Following  the recent ruling against the Internet Archive (and libraries in  general), we\u2019re organizing an in-person rally outside IA\u2019s San Francisco  headquarters. We want to get loud and demonstrate the popular support  for libraries and their ability to own, lend, and preserve ebooks.&lt;/p&gt;\n\n&lt;p&gt;If  you\u2019re in the SF area and have been following this case, we\u2019d love to  see you this Saturday at 11am. We\u2019ll have signs but encourage you to  BYOS as well! Here\u2019s a link to RSVP: &lt;a href=\"https://actionnetwork.org/events/dont-delete-our-books-rally-in-san-francisco\"&gt;https://actionnetwork.org/events/dont-delete-our-books-rally-in-san-francisco&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks, hope to see some of you there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1kdCSboRP9L798pwV44r8v6B3fn6XKQRiH0_6OI9FTs.jpg?auto=webp&amp;v=enabled&amp;s=6a0d48fe5f3f2e457c6533ff3898cdb06cad83f4", "width": 1044, "height": 609}, "resolutions": [{"url": "https://external-preview.redd.it/1kdCSboRP9L798pwV44r8v6B3fn6XKQRiH0_6OI9FTs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae75a5bd3a8297bc92bbe4f4e02cd8803ee13b23", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/1kdCSboRP9L798pwV44r8v6B3fn6XKQRiH0_6OI9FTs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4801024549889833039217918c37148402277df", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/1kdCSboRP9L798pwV44r8v6B3fn6XKQRiH0_6OI9FTs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89242a225888d5d2b1d2a12ff2b80f30817adaea", "width": 320, "height": 186}, {"url": "https://external-preview.redd.it/1kdCSboRP9L798pwV44r8v6B3fn6XKQRiH0_6OI9FTs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=60a40260230bdc902ce0e26aaa1c86fcf5a98b9e", "width": 640, "height": 373}, {"url": "https://external-preview.redd.it/1kdCSboRP9L798pwV44r8v6B3fn6XKQRiH0_6OI9FTs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c940038c7b6be1928773d4fff112d15d5195c0b", "width": 960, "height": 560}], "variants": {}, "id": "1aCJ5vBn2mNaAADMcDA-J6AMGJOhkbrkMAh7L1_AxJA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12ct6wl", "is_robot_indexable": true, "report_reasons": null, "author": "fightforthefuture", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12ct6wl/rally_to_support_internet_archive_in_sf_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12ct6wl/rally_to_support_internet_archive_in_sf_on/", "subreddit_subscribers": 676807, "created_utc": 1680718879.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "to download images from a pinterest board I am using the extension mentioned above, but something happens that it keeps replicating the image several times in different resolutions. \n\nThanks if anyone knows how to fix this, or at least suggest me another good extension that downloads the images from the board with good quality\n\nanother help can be to recommend me some program to delete repeated images from a windows folder", "author_fullname": "t2_6oian2l9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "does anyone know of any good extensions that download all images from a pinterest board, or at least know how the image assistant image batch downloader works", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ch6gu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 148, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 148, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680694160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;to download images from a pinterest board I am using the extension mentioned above, but something happens that it keeps replicating the image several times in different resolutions. &lt;/p&gt;\n\n&lt;p&gt;Thanks if anyone knows how to fix this, or at least suggest me another good extension that downloads the images from the board with good quality&lt;/p&gt;\n\n&lt;p&gt;another help can be to recommend me some program to delete repeated images from a windows folder&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12ch6gu", "is_robot_indexable": true, "report_reasons": null, "author": "designygued3s", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12ch6gu/does_anyone_know_of_any_good_extensions_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12ch6gu/does_anyone_know_of_any_good_extensions_that/", "subreddit_subscribers": 676807, "created_utc": 1680694160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a big family and they all have their own photos, videos, notes, etc. We've also been digitizing a lot of family history.\n\n--\n\nI'm looking at help with:\n\n**1:** Organizing the data\n\n**2:** storing meta data\n\n--\n\n**1:** In terms of organizing, right now it's just a big dump.  It's basically just a big folder on a NAS and it's not well organized.  Everything is folder based and everyone has their own naming conversation, or just generic names.  \n\n--\n\n\n**2:** The other problem is I don't know how to store meta-data.  \n\nFor example: If my grandma tells me a story about a photo, how do I keep that information with the photo?  \n\nExample 2: Or simple documenting who is in the video and the location and date it was shot, etc.\n\n(caveat: you can store meta-data in some photo formats, but not everything is a photo.  Some will be videos, sound files, text documents, etc)\n\n--\n\nFor meta-data, I want it to be in a \"open format\" that is non-propriety, since propriety software might not work in future.  (My grandpa had all his photos in a commercial photo album that ran on windows 95 and it was a huge pain to extract that data since it was all in some closed source janky database).\n\n\n\n\n\n--\n\nWe want to pass these digital files down though the generations.  So hard to know what the future holds, but want to try our best to make them accessible and not lock ourselves into some specific software choice.\n\n\n--\n\n\nAny tips from the horde on best way to tackle these problems?  Has anyone else done a project like this ?", "author_fullname": "t2_9gtvi5rc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on managing a shared digital \"archive\" for the family?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12cnhak", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680707503.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a big family and they all have their own photos, videos, notes, etc. We&amp;#39;ve also been digitizing a lot of family history.&lt;/p&gt;\n\n&lt;h2&gt;&lt;/h2&gt;\n\n&lt;p&gt;I&amp;#39;m looking at help with:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1:&lt;/strong&gt; Organizing the data&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2:&lt;/strong&gt; storing meta data&lt;/p&gt;\n\n&lt;h2&gt;&lt;/h2&gt;\n\n&lt;p&gt;&lt;strong&gt;1:&lt;/strong&gt; In terms of organizing, right now it&amp;#39;s just a big dump.  It&amp;#39;s basically just a big folder on a NAS and it&amp;#39;s not well organized.  Everything is folder based and everyone has their own naming conversation, or just generic names.  &lt;/p&gt;\n\n&lt;h2&gt;&lt;/h2&gt;\n\n&lt;p&gt;&lt;strong&gt;2:&lt;/strong&gt; The other problem is I don&amp;#39;t know how to store meta-data.  &lt;/p&gt;\n\n&lt;p&gt;For example: If my grandma tells me a story about a photo, how do I keep that information with the photo?  &lt;/p&gt;\n\n&lt;p&gt;Example 2: Or simple documenting who is in the video and the location and date it was shot, etc.&lt;/p&gt;\n\n&lt;p&gt;(caveat: you can store meta-data in some photo formats, but not everything is a photo.  Some will be videos, sound files, text documents, etc)&lt;/p&gt;\n\n&lt;h2&gt;&lt;/h2&gt;\n\n&lt;p&gt;For meta-data, I want it to be in a &amp;quot;open format&amp;quot; that is non-propriety, since propriety software might not work in future.  (My grandpa had all his photos in a commercial photo album that ran on windows 95 and it was a huge pain to extract that data since it was all in some closed source janky database).&lt;/p&gt;\n\n&lt;h2&gt;&lt;/h2&gt;\n\n&lt;p&gt;We want to pass these digital files down though the generations.  So hard to know what the future holds, but want to try our best to make them accessible and not lock ourselves into some specific software choice.&lt;/p&gt;\n\n&lt;h2&gt;&lt;/h2&gt;\n\n&lt;p&gt;Any tips from the horde on best way to tackle these problems?  Has anyone else done a project like this ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "12cnhak", "is_robot_indexable": true, "report_reasons": null, "author": "ZjY5MjFk", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12cnhak/thoughts_on_managing_a_shared_digital_archive_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12cnhak/thoughts_on_managing_a_shared_digital_archive_for/", "subreddit_subscribers": 676807, "created_utc": 1680707503.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nSome time ago, I had a conversation here where I mentioned a Python script I wrote and use to check for bit rot in my archives.  It's kind of simple really: it hashes files in target directories and stores the hashes (plus last modified times) of the files in a database.  On subsequent runs, it recalculates the checksums and compares them (as well as the last modified information) and reports mismatches.  It reports checksum mismatches as bit rot unless the file system last modified is newer, in which case it silently updates the database on the assumption that the file simply changed (and if the file system last modified happens to be older than what's in the database then that's reported as a possible file system problem).  \n\nNothing fancy, and nothing you couldn't do with some shell scripts, but it is perhaps a little nicer to use and has some configuration flexibility.\n\nIt's always been just something for me, but I finally got around to polishing and enhancing it a bit and putting it up on my GitHub.  \n\nIf it sounds like something you might be interested in, have a look:\n\n[https://github.com/fzammetti/python/tree/main/FileIntegrityCheckerScript](https://github.com/fzammetti/python/tree/main/FileIntegrityCheckerScript)\n\n(and as I wrote this, I realized that I probably want a configuration option for whether to report a checksum mismatch as bit rot regardless of the last modified info, so that for directories where it's truly an archive, where you wouldn't ever expect the files to change, that can be reported since it'll effectively be missed right now... I'll work on that)", "author_fullname": "t2_6q4oi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File Integrity Checker Script", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12cukum", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680721716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Some time ago, I had a conversation here where I mentioned a Python script I wrote and use to check for bit rot in my archives.  It&amp;#39;s kind of simple really: it hashes files in target directories and stores the hashes (plus last modified times) of the files in a database.  On subsequent runs, it recalculates the checksums and compares them (as well as the last modified information) and reports mismatches.  It reports checksum mismatches as bit rot unless the file system last modified is newer, in which case it silently updates the database on the assumption that the file simply changed (and if the file system last modified happens to be older than what&amp;#39;s in the database then that&amp;#39;s reported as a possible file system problem).  &lt;/p&gt;\n\n&lt;p&gt;Nothing fancy, and nothing you couldn&amp;#39;t do with some shell scripts, but it is perhaps a little nicer to use and has some configuration flexibility.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s always been just something for me, but I finally got around to polishing and enhancing it a bit and putting it up on my GitHub.  &lt;/p&gt;\n\n&lt;p&gt;If it sounds like something you might be interested in, have a look:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/fzammetti/python/tree/main/FileIntegrityCheckerScript\"&gt;https://github.com/fzammetti/python/tree/main/FileIntegrityCheckerScript&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;(and as I wrote this, I realized that I probably want a configuration option for whether to report a checksum mismatch as bit rot regardless of the last modified info, so that for directories where it&amp;#39;s truly an archive, where you wouldn&amp;#39;t ever expect the files to change, that can be reported since it&amp;#39;ll effectively be missed right now... I&amp;#39;ll work on that)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Xo44xbUMHZPkHGMKw9eKJwnuXUgbK0ccfFA-ZlVQcjE.jpg?auto=webp&amp;v=enabled&amp;s=14585cff9577f838810ffc919516fcb371b3f220", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Xo44xbUMHZPkHGMKw9eKJwnuXUgbK0ccfFA-ZlVQcjE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=56716d3e42dfc2180dfd69ec928d437ef6c5520e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Xo44xbUMHZPkHGMKw9eKJwnuXUgbK0ccfFA-ZlVQcjE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70e92846c42c8eabf6bf7d9ce982c0d09d215cca", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Xo44xbUMHZPkHGMKw9eKJwnuXUgbK0ccfFA-ZlVQcjE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1344a838ae95af40600bbb9090376e019e5ce723", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Xo44xbUMHZPkHGMKw9eKJwnuXUgbK0ccfFA-ZlVQcjE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c7a84cce4865f99f9b4cca255d13e239dfb56c9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Xo44xbUMHZPkHGMKw9eKJwnuXUgbK0ccfFA-ZlVQcjE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6ee47a0a2afefe53c607dfc0501de738ccc05d0", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Xo44xbUMHZPkHGMKw9eKJwnuXUgbK0ccfFA-ZlVQcjE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f12f635629428415a2f123b83749363b0829a4e0", "width": 1080, "height": 540}], "variants": {}, "id": "SGKtmJubJppojVXVbF-UHGsxCH_GOIdzCk9lmw2elYM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12cukum", "is_robot_indexable": true, "report_reasons": null, "author": "fzammetti", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12cukum/file_integrity_checker_script/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12cukum/file_integrity_checker_script/", "subreddit_subscribers": 676807, "created_utc": 1680721716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://status.mycloud.com/os4\n\n\"Contact Support\" button is also down.\n\nI use this to run Plex on my TV. Anyone have a better suggestion for a Plex Media Server?", "author_fullname": "t2_v653fh9g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Western Digital MyCloud has been down for 3 days", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12cnj64", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680707610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://status.mycloud.com/os4\"&gt;https://status.mycloud.com/os4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Contact Support&amp;quot; button is also down.&lt;/p&gt;\n\n&lt;p&gt;I use this to run Plex on my TV. Anyone have a better suggestion for a Plex Media Server?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12cnj64", "is_robot_indexable": true, "report_reasons": null, "author": "HowIsYourBreathing", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12cnj64/western_digital_mycloud_has_been_down_for_3_days/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12cnj64/western_digital_mycloud_has_been_down_for_3_days/", "subreddit_subscribers": 676807, "created_utc": 1680707610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Pretty interesting documentary covering the transition from one technology to another which many of us take for granted\u2026\n\nhttps://youtu.be/1MGjFKs9bnU", "author_fullname": "t2_2l7vdc8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FarewellEtaoinShrdlu", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12d4o0g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680744050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty interesting documentary covering the transition from one technology to another which many of us take for granted\u2026&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/1MGjFKs9bnU\"&gt;https://youtu.be/1MGjFKs9bnU&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PA5i4jiCDBWD316MFNg_G6jf53VZl1IgivqKmNWKTyU.jpg?auto=webp&amp;v=enabled&amp;s=1960e49ff04bd11408ca39b3c8c1daf8cd8cc999", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/PA5i4jiCDBWD316MFNg_G6jf53VZl1IgivqKmNWKTyU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1157f04552a182f9155992c2cd7e40f351bbc4ce", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/PA5i4jiCDBWD316MFNg_G6jf53VZl1IgivqKmNWKTyU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff356b1bbeb88a3953ffe6491745b3650ebdedaf", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/PA5i4jiCDBWD316MFNg_G6jf53VZl1IgivqKmNWKTyU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2617f2178c3d1684d02f61072174e5317e2d4102", "width": 320, "height": 240}], "variants": {}, "id": "tyn_vKgpvcMVKPlUjKYva-8WVKSR6j0_c-Y5Ym3XEwY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12d4o0g", "is_robot_indexable": true, "report_reasons": null, "author": "qlippoth513", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12d4o0g/farewelletaoinshrdlu/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12d4o0g/farewelletaoinshrdlu/", "subreddit_subscribers": 676807, "created_utc": 1680744050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What are some tips and best practices for file naming and folder structure? I use a NAS to store everything, and want to clean things up after learning from this community.   \n\nDo you still avoid using spaces or special characters to ensure maximum file system compatibility? Do you avoid them when naming directories as well?  \n\nWould love to know how you seasoned veterans do things.", "author_fullname": "t2_c6v6parp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File naming and folder structure best practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12db8yt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680762199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some tips and best practices for file naming and folder structure? I use a NAS to store everything, and want to clean things up after learning from this community.   &lt;/p&gt;\n\n&lt;p&gt;Do you still avoid using spaces or special characters to ensure maximum file system compatibility? Do you avoid them when naming directories as well?  &lt;/p&gt;\n\n&lt;p&gt;Would love to know how you seasoned veterans do things.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12db8yt", "is_robot_indexable": true, "report_reasons": null, "author": "x6q5g3o7", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12db8yt/file_naming_and_folder_structure_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12db8yt/file_naming_and_folder_structure_best_practices/", "subreddit_subscribers": 676807, "created_utc": 1680762199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If I understand correctly, DrivePool's file duplication more or less duplicates each file to a \"random\" drive selected from the pool. Due to this, it can only tolerate 1 drive failure in the pool before losing data (assuming 2x duplication). I understand why this limitation exists, but I was wondering if it was possible to mimic RAID10-like drive mirroring rather than just duplicating to a random drive in the pool.\n\nI don't have enough spare disks to test this, but my assumption is that you can set up multiple 2-drive pools with duplication enabled (\"RAID 1\"), then using hierarchical pooling you can pool all these together into a main pool (\"RAID 0\"). This way all data is still duplicated, but the pool is much more resistant to drive failures (1 from each pool rather than only 1 total). I understand DrivePool doesn't stripe the data, so the performance characteristics wouldn't be the same as true RAID10, but I only care about the resiliency.\n\nDoes this setup work, does anyone use it this way? If so, are there any downsides to setting up the pools like this?", "author_fullname": "t2_5kann", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mimicking RAID10 failure resiliency in DrivePool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12d2qfr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680739515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I understand correctly, DrivePool&amp;#39;s file duplication more or less duplicates each file to a &amp;quot;random&amp;quot; drive selected from the pool. Due to this, it can only tolerate 1 drive failure in the pool before losing data (assuming 2x duplication). I understand why this limitation exists, but I was wondering if it was possible to mimic RAID10-like drive mirroring rather than just duplicating to a random drive in the pool.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have enough spare disks to test this, but my assumption is that you can set up multiple 2-drive pools with duplication enabled (&amp;quot;RAID 1&amp;quot;), then using hierarchical pooling you can pool all these together into a main pool (&amp;quot;RAID 0&amp;quot;). This way all data is still duplicated, but the pool is much more resistant to drive failures (1 from each pool rather than only 1 total). I understand DrivePool doesn&amp;#39;t stripe the data, so the performance characteristics wouldn&amp;#39;t be the same as true RAID10, but I only care about the resiliency.&lt;/p&gt;\n\n&lt;p&gt;Does this setup work, does anyone use it this way? If so, are there any downsides to setting up the pools like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "34TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12d2qfr", "is_robot_indexable": true, "report_reasons": null, "author": "Hakkin", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12d2qfr/mimicking_raid10_failure_resiliency_in_drivepool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12d2qfr/mimicking_raid10_failure_resiliency_in_drivepool/", "subreddit_subscribers": 676807, "created_utc": 1680739515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My Google Drive storage is almost full. I believe most of it is due to files that I've uploaded to a folder, shared the folder with someone else, then later deleted that folder from my own GDrive. Despite my deletions of folders, Drive keeps the files inside these folders to a) continue to provide the files to the people with whom they've been shared and b) force us to buy more storage. :/\n\nIs there a filter to display files that account for my storage quota that exist in shared-deleted-folders?  \nPerhaps a third-party plugin to do this?  \n\n\nThanks in advance,  \nDax.  \n\n\n**UPDATE:** ***I've discovered the underlying problem.*** I have folders which I assigned to other users' accounts by using Transfer Ownership. The trouble is that the files inside those folders are still assigned to me! When I deleted those folders, I removed them from my GDrive folder tree, but the files are still \"mine\".  \nI'm hoping there is a solution to delete files that belong to you that are located in folders that don't belong to you.\n\nhttps://preview.redd.it/sg3j9zepu5sa1.png?width=2643&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=05ebcf8e846a3e86265d7938a55e364eed00abe5", "author_fullname": "t2_ucssf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Drive retains files inside deleted shared folders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 54, "top_awarded_type": null, "hide_score": false, "media_metadata": {"sg3j9zepu5sa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 42, "x": 108, "u": "https://preview.redd.it/sg3j9zepu5sa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44ab81918235980d60a8a8aeea8b0bfc5ecc4491"}, {"y": 84, "x": 216, "u": "https://preview.redd.it/sg3j9zepu5sa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f6757ab8b4e085c592a68bd626a572ce5a95006"}, {"y": 124, "x": 320, "u": "https://preview.redd.it/sg3j9zepu5sa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=163b1ad1634cd75145a8c861a120fc1b0ce339e3"}, {"y": 248, "x": 640, "u": "https://preview.redd.it/sg3j9zepu5sa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b8f6e7ea52e45d0daffe63f05131076aa5c1ed2"}, {"y": 373, "x": 960, "u": "https://preview.redd.it/sg3j9zepu5sa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=77104e174537c1217969d75695e0957b044e902b"}, {"y": 420, "x": 1080, "u": "https://preview.redd.it/sg3j9zepu5sa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1575e172a926d147c30228cbd35bfabfe0c355f9"}], "s": {"y": 1028, "x": 2643, "u": "https://preview.redd.it/sg3j9zepu5sa1.png?width=2643&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=05ebcf8e846a3e86265d7938a55e364eed00abe5"}, "id": "sg3j9zepu5sa1"}}, "name": "t3_12d1jiy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ksaAzSKZJACtR3IDx8KNnziL5T06NMJnSLN4vXPNXcs.jpg", "edited": 1680741860.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680736809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My Google Drive storage is almost full. I believe most of it is due to files that I&amp;#39;ve uploaded to a folder, shared the folder with someone else, then later deleted that folder from my own GDrive. Despite my deletions of folders, Drive keeps the files inside these folders to a) continue to provide the files to the people with whom they&amp;#39;ve been shared and b) force us to buy more storage. :/&lt;/p&gt;\n\n&lt;p&gt;Is there a filter to display files that account for my storage quota that exist in shared-deleted-folders?&lt;br/&gt;\nPerhaps a third-party plugin to do this?  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance,&lt;br/&gt;\nDax.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;I&amp;#39;ve discovered the underlying problem.&lt;/em&gt;&lt;/strong&gt; I have folders which I assigned to other users&amp;#39; accounts by using Transfer Ownership. The trouble is that the files inside those folders are still assigned to me! When I deleted those folders, I removed them from my GDrive folder tree, but the files are still &amp;quot;mine&amp;quot;.&lt;br/&gt;\nI&amp;#39;m hoping there is a solution to delete files that belong to you that are located in folders that don&amp;#39;t belong to you.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/sg3j9zepu5sa1.png?width=2643&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=05ebcf8e846a3e86265d7938a55e364eed00abe5\"&gt;https://preview.redd.it/sg3j9zepu5sa1.png?width=2643&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=05ebcf8e846a3e86265d7938a55e364eed00abe5&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12d1jiy", "is_robot_indexable": true, "report_reasons": null, "author": "daxliniere", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12d1jiy/google_drive_retains_files_inside_deleted_shared/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12d1jiy/google_drive_retains_files_inside_deleted_shared/", "subreddit_subscribers": 676807, "created_utc": 1680736809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know this is a long shot but I have a couple  IXSystems X10 HA systems that came from IX with 32gb of RAM in each HA node. I'm looking to upgrade this and IX has told me they cannot give me any proprietary information such as max ram per slot/system or max supported memory speed (seriously...)\n\n\nAnyone here have any experience with these or that has seen one with a large amount of RAM? Each node in each chassis is running 2x 16gb DDR4-2400 ECC Sodimm, and I'm trying to avoid having to buy a bunch of different sizes and speeds to see what works.\n\nPretty fucking ridiculous that they won't share this basic information on a 3 year old $15,000 server if you ask me...", "author_fullname": "t2_6bubo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IXSystems X10 Memory Upgrades", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12cyh03", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680729893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this is a long shot but I have a couple  IXSystems X10 HA systems that came from IX with 32gb of RAM in each HA node. I&amp;#39;m looking to upgrade this and IX has told me they cannot give me any proprietary information such as max ram per slot/system or max supported memory speed (seriously...)&lt;/p&gt;\n\n&lt;p&gt;Anyone here have any experience with these or that has seen one with a large amount of RAM? Each node in each chassis is running 2x 16gb DDR4-2400 ECC Sodimm, and I&amp;#39;m trying to avoid having to buy a bunch of different sizes and speeds to see what works.&lt;/p&gt;\n\n&lt;p&gt;Pretty fucking ridiculous that they won&amp;#39;t share this basic information on a 3 year old $15,000 server if you ask me...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "176TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12cyh03", "is_robot_indexable": true, "report_reasons": null, "author": "ycatsce", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12cyh03/ixsystems_x10_memory_upgrades/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12cyh03/ixsystems_x10_memory_upgrades/", "subreddit_subscribers": 676807, "created_utc": 1680729893.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was making a backup using robocopy in CMD, but sadly the PC shut down. Now I wonder if using the same command again will rewrite the files , it tried to do the first time or will I end up with corrputed files?\n\nMy command :\nRobocopy \"A\" \"B\"   /xj /e /COPYALL /ZB /DCOPY:T /r:1 /w:1 /mt:128", "author_fullname": "t2_3lyupz8a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can an arborted robocopy command be redone without any drawbacks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12cp8uf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680711011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was making a backup using robocopy in CMD, but sadly the PC shut down. Now I wonder if using the same command again will rewrite the files , it tried to do the first time or will I end up with corrputed files?&lt;/p&gt;\n\n&lt;p&gt;My command :\nRobocopy &amp;quot;A&amp;quot; &amp;quot;B&amp;quot;   /xj /e /COPYALL /ZB /DCOPY:T /r:1 /w:1 /mt:128&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12cp8uf", "is_robot_indexable": true, "report_reasons": null, "author": "seronlover", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12cp8uf/can_an_arborted_robocopy_command_be_redone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12cp8uf/can_an_arborted_robocopy_command_be_redone/", "subreddit_subscribers": 676807, "created_utc": 1680711011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nHello everyone.\n\nI bought a pendrive to use as an mp3 archive, to be used with a karaoke machine.\n\nSo after downloading with the pc some mp3s, I insert them into the Pendrive, and then plug the pendrive into the karaoke machine.\n\nWhich initially plays the songs and then after a few days does not recognize the pendrive.\n\nI tried formatting the pen drive, but to no avail.\n\nThen I bought another identical pen drive and, likewise, it is recognized by Karaoke for a few days and then no longer works.\n\nHowever, in the pc both pendrives work regularly.\n\nWhere could the problem be?", "author_fullname": "t2_sou1g6gm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Usb is read for a limited time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12cjqjh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680699918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone.&lt;/p&gt;\n\n&lt;p&gt;I bought a pendrive to use as an mp3 archive, to be used with a karaoke machine.&lt;/p&gt;\n\n&lt;p&gt;So after downloading with the pc some mp3s, I insert them into the Pendrive, and then plug the pendrive into the karaoke machine.&lt;/p&gt;\n\n&lt;p&gt;Which initially plays the songs and then after a few days does not recognize the pendrive.&lt;/p&gt;\n\n&lt;p&gt;I tried formatting the pen drive, but to no avail.&lt;/p&gt;\n\n&lt;p&gt;Then I bought another identical pen drive and, likewise, it is recognized by Karaoke for a few days and then no longer works.&lt;/p&gt;\n\n&lt;p&gt;However, in the pc both pendrives work regularly.&lt;/p&gt;\n\n&lt;p&gt;Where could the problem be?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12cjqjh", "is_robot_indexable": true, "report_reasons": null, "author": "Maleficent_Quote_392", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12cjqjh/usb_is_read_for_a_limited_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12cjqjh/usb_is_read_for_a_limited_time/", "subreddit_subscribers": 676807, "created_utc": 1680699918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My relatively new and not much used  **WD80EFAX** is doing click(ing) of death. I have shucked it just to see if maybe it will work like that but its the same. As its filled with helium, the last resort of opening it and trying to move the heads is out of the question.  Anything else I can do before shooting it? Thank you!", "author_fullname": "t2_8g6po", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Click of death - WD80EFAX (256 MB Cache) - 8TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12cs1sz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680716532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My relatively new and not much used  &lt;strong&gt;WD80EFAX&lt;/strong&gt; is doing click(ing) of death. I have shucked it just to see if maybe it will work like that but its the same. As its filled with helium, the last resort of opening it and trying to move the heads is out of the question.  Anything else I can do before shooting it? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12cs1sz", "is_robot_indexable": true, "report_reasons": null, "author": "Genie52", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12cs1sz/click_of_death_wd80efax_256_mb_cache_8tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12cs1sz/click_of_death_wd80efax_256_mb_cache_8tb/", "subreddit_subscribers": 676807, "created_utc": 1680716532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_6bch24w8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Everything not saved will be lost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_12d4sxc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p_UBu7vLCIlxkROoahkDwQnb9KKpVHOc-Z1Vt2bP4yQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680744373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "reddit.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/r/comics/comments/12cna56/everything_not_saved_will_be_lost/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DmCpBW5AhzTO0wm5cj9Cuk9Jh49vcz1n1jfKPnP-xh8.png?auto=webp&amp;v=enabled&amp;s=98046f69266ded08089d6c92edd87497fde3921e", "width": 2000, "height": 2218}, "resolutions": [{"url": "https://external-preview.redd.it/DmCpBW5AhzTO0wm5cj9Cuk9Jh49vcz1n1jfKPnP-xh8.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4c519873e8982986161b1c19a299b41a3416b77", "width": 108, "height": 119}, {"url": "https://external-preview.redd.it/DmCpBW5AhzTO0wm5cj9Cuk9Jh49vcz1n1jfKPnP-xh8.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=290c077c2d23ee10644afd2cba0fd2c199ee88cc", "width": 216, "height": 239}, {"url": "https://external-preview.redd.it/DmCpBW5AhzTO0wm5cj9Cuk9Jh49vcz1n1jfKPnP-xh8.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e252c185b50d37448e2a7490da948d1abf760bc", "width": 320, "height": 354}, {"url": "https://external-preview.redd.it/DmCpBW5AhzTO0wm5cj9Cuk9Jh49vcz1n1jfKPnP-xh8.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74edd02c910caa2f7b778f5bf827054159f98051", "width": 640, "height": 709}, {"url": "https://external-preview.redd.it/DmCpBW5AhzTO0wm5cj9Cuk9Jh49vcz1n1jfKPnP-xh8.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=87a7827f8b21f7563e21be6c3b248baccc9e8d20", "width": 960, "height": 1064}, {"url": "https://external-preview.redd.it/DmCpBW5AhzTO0wm5cj9Cuk9Jh49vcz1n1jfKPnP-xh8.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3960f55cb4251b081e59886b7bc12be9cdc2d9ea", "width": 1080, "height": 1197}], "variants": {}, "id": "uva8goHot84KAgZUELzjSNJiAYedxil9H5bt7B2VmD4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12d4sxc", "is_robot_indexable": true, "report_reasons": null, "author": "burger4d", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12d4sxc/everything_not_saved_will_be_lost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/comics/comments/12cna56/everything_not_saved_will_be_lost/", "subreddit_subscribers": 676807, "created_utc": 1680744373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello.  I'm planning on buying several shows/movies in dvd and blu-ray. The thing is though, I'm worried about the possibility of defects in some of the discs. I've heard experiences from a few people about how they encountered disc-skipping and other errors in the middle of watching one/some of their discs, even though the whole set was brand-new and the disc had no visible imperfections.\n\nWith that said, is there a way to test or scan discs for defects, skipping, etc.?\n\n\"Bruteforcing\" it by watching the entirety of every disc is out of the question. I simply do not have the free-time to go through that much media within the 30-day return period.\n\nThe reason I ask here of all places is because I couldn't find many answers elsewhere online. Usually it's just other people on forums complaining about the disc-skipping issues they have. I figured that this subreddit, which deals with collecting &amp; maybe verifying data/media, must surely have some people with technical expertise in the matter.\n\nAny insight or suggestions would be greatly appreciated.", "author_fullname": "t2_rwuwsvku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any methods for detecting errors in physical media? (DVD's/Blu-Rays)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12d2fwk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680738876.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.  I&amp;#39;m planning on buying several shows/movies in dvd and blu-ray. The thing is though, I&amp;#39;m worried about the possibility of defects in some of the discs. I&amp;#39;ve heard experiences from a few people about how they encountered disc-skipping and other errors in the middle of watching one/some of their discs, even though the whole set was brand-new and the disc had no visible imperfections.&lt;/p&gt;\n\n&lt;p&gt;With that said, is there a way to test or scan discs for defects, skipping, etc.?&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Bruteforcing&amp;quot; it by watching the entirety of every disc is out of the question. I simply do not have the free-time to go through that much media within the 30-day return period.&lt;/p&gt;\n\n&lt;p&gt;The reason I ask here of all places is because I couldn&amp;#39;t find many answers elsewhere online. Usually it&amp;#39;s just other people on forums complaining about the disc-skipping issues they have. I figured that this subreddit, which deals with collecting &amp;amp; maybe verifying data/media, must surely have some people with technical expertise in the matter.&lt;/p&gt;\n\n&lt;p&gt;Any insight or suggestions would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12d2fwk", "is_robot_indexable": true, "report_reasons": null, "author": "tatertoter10", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12d2fwk/any_methods_for_detecting_errors_in_physical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12d2fwk/any_methods_for_detecting_errors_in_physical/", "subreddit_subscribers": 676807, "created_utc": 1680738876.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It seems like my Seagate 5 TB portable backup HDD (Model: SRD0NF1; P/N: 2N1AP8-500; 2020; 3 partitions [encrypted APFS + exFAT + encrypted old HFS+(journal)] just died a hour ago. My 4 computers (2 MBPs (2012 Mojave &amp; 2020's Big Sur) + 2 PCs [Linux/Debian bullseye and 64-bit Windows 10]) don't see the connected drive anymore. \n\nEarlier today, I was doing a Time Machine back up fine in 2020 MBP. And then, I tried to do it again. macOS Big Sur got stuck with its animated colorful pinwheel. I tried to abort and eject, but it failed. I pulled its old school USB cable connection to make MBP respond. I rebooted and retried. It never saw the drive even though the HDD's light blinked. I tried it on another (older) MBP's Mojave, and it never saw it but its light blinked only once right after physically connecting. Same with my Linux/Debian and 64-bit W10 PCs. My Debian's dmesg -T showed failures it seems as shown in https://paste2.org/xeHxaxKN. \n\nAlso, I can feel the drive vibration after connecting and seeing its white light up either once or blink. I'm going to leave the drive physically connected to see if the drive will ever show up.\n\nWhat do you think? Dead/Broken? Warranty expired last year according to Seagate's web site with the serial number. Time for a new one? If so, then which reliable brand and model to get to replace it for cheap? :(\n\nThank you for reading and hopefully answering soon. :)", "author_fullname": "t2_4a27h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dead external Seagate 5 TB portable HDD from 2020 (ordered at that year IIRC)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12cyvxz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": "", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680761200.0, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680730798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems like my Seagate 5 TB portable backup HDD (Model: SRD0NF1; P/N: 2N1AP8-500; 2020; 3 partitions [encrypted APFS + exFAT + encrypted old HFS+(journal)] just died a hour ago. My 4 computers (2 MBPs (2012 Mojave &amp;amp; 2020&amp;#39;s Big Sur) + 2 PCs [Linux/Debian bullseye and 64-bit Windows 10]) don&amp;#39;t see the connected drive anymore. &lt;/p&gt;\n\n&lt;p&gt;Earlier today, I was doing a Time Machine back up fine in 2020 MBP. And then, I tried to do it again. macOS Big Sur got stuck with its animated colorful pinwheel. I tried to abort and eject, but it failed. I pulled its old school USB cable connection to make MBP respond. I rebooted and retried. It never saw the drive even though the HDD&amp;#39;s light blinked. I tried it on another (older) MBP&amp;#39;s Mojave, and it never saw it but its light blinked only once right after physically connecting. Same with my Linux/Debian and 64-bit W10 PCs. My Debian&amp;#39;s dmesg -T showed failures it seems as shown in &lt;a href=\"https://paste2.org/xeHxaxKN\"&gt;https://paste2.org/xeHxaxKN&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;Also, I can feel the drive vibration after connecting and seeing its white light up either once or blink. I&amp;#39;m going to leave the drive physically connected to see if the drive will ever show up.&lt;/p&gt;\n\n&lt;p&gt;What do you think? Dead/Broken? Warranty expired last year according to Seagate&amp;#39;s web site with the serial number. Time for a new one? If so, then which reliable brand and model to get to replace it for cheap? :(&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading and hopefully answering soon. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Where's the big big floppy disk(ette) flair? :P", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12cyvxz", "is_robot_indexable": true, "report_reasons": null, "author": "antdude", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12cyvxz/dead_external_seagate_5_tb_portable_hdd_from_2020/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12cyvxz/dead_external_seagate_5_tb_portable_hdd_from_2020/", "subreddit_subscribers": 676807, "created_utc": 1680730798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All,\n\nSo I met a guy who's autistic daughter loves the families Singing Douglas Fir Christmas Tree. (like this one: [https://www.youtube.com/watch?v=NxNWgfFZmRs](https://www.youtube.com/watch?v=NxNWgfFZmRs)) \n\nThe tree operates via a cassette player and an aux cord. The cassette tape that came with his setup has started dying and he has been having a ton of trouble getting it ripped and working. When he did rip it to his computer the tree only sang, but did not dance. So I think it may be left channel sing, right channel dance. \n\nThis may be the single most random thing to try to find, but if anyone had archived it, it would be on r/DataHoarder. Does anyone have a two channel audio file of the song / dance? Or could point me in the right direction? \n\nThanks!", "author_fullname": "t2_342bg6eb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[File Request] Singing Christmas Douglas Fir song / dance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12cx3kh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "File Reqest", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680727113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;So I met a guy who&amp;#39;s autistic daughter loves the families Singing Douglas Fir Christmas Tree. (like this one: &lt;a href=\"https://www.youtube.com/watch?v=NxNWgfFZmRs\"&gt;https://www.youtube.com/watch?v=NxNWgfFZmRs&lt;/a&gt;) &lt;/p&gt;\n\n&lt;p&gt;The tree operates via a cassette player and an aux cord. The cassette tape that came with his setup has started dying and he has been having a ton of trouble getting it ripped and working. When he did rip it to his computer the tree only sang, but did not dance. So I think it may be left channel sing, right channel dance. &lt;/p&gt;\n\n&lt;p&gt;This may be the single most random thing to try to find, but if anyone had archived it, it would be on &lt;a href=\"/r/DataHoarder\"&gt;r/DataHoarder&lt;/a&gt;. Does anyone have a two channel audio file of the song / dance? Or could point me in the right direction? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GUFIoBRJNlOYJHLcrn4JN-_kHeXZZ2IbRAk7j-yUoL4.jpg?auto=webp&amp;v=enabled&amp;s=dc88acc39b6dcf5fc78b16de834645442c2bb90f", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/GUFIoBRJNlOYJHLcrn4JN-_kHeXZZ2IbRAk7j-yUoL4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4452d064c44808c8800ad82c53629a10d083c01d", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/GUFIoBRJNlOYJHLcrn4JN-_kHeXZZ2IbRAk7j-yUoL4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70d9beb738a108f3682959c1f280806f79ce3145", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/GUFIoBRJNlOYJHLcrn4JN-_kHeXZZ2IbRAk7j-yUoL4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ffae2eced3bca39884050043205c324bd9db38a2", "width": 320, "height": 240}], "variants": {}, "id": "z0mDjGh9mBmXujPtUx1P7g_Vy_Nvjo3pSEOgGiXNAxs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "12cx3kh", "is_robot_indexable": true, "report_reasons": null, "author": "SpaceRex1776", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12cx3kh/file_request_singing_christmas_douglas_fir_song/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12cx3kh/file_request_singing_christmas_douglas_fir_song/", "subreddit_subscribers": 676807, "created_utc": 1680727113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to simply back up my 3tb of data on my pc - most is archive stuff, like videos, templates, etc. If I need something, I would copy it to my 2tb m.2 ssd, and use it there till I'm done.   \n\n\nHave been told the following:  \n1) Just add those 2 drives to your pc and create your backup copies (If a fire happens on your house, NAS/DAS also dies either way, so not worth buying them)  \n2) A Das is enough. You create a copy of your data, when needed you just attach it to whatever device you need it, and it's faster than nas.  \n3) A NAS has so many more uses, like connect to both laptop and desktop through network, etc, which has so much more potential If you're gonna spend money, just go for something better.  \n\n\nSo, which is it? Any advice is appreciated :)", "author_fullname": "t2_or8du", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bought 16tb (2x8tb) - Now what?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12cufyd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680721438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to simply back up my 3tb of data on my pc - most is archive stuff, like videos, templates, etc. If I need something, I would copy it to my 2tb m.2 ssd, and use it there till I&amp;#39;m done.   &lt;/p&gt;\n\n&lt;p&gt;Have been told the following:&lt;br/&gt;\n1) Just add those 2 drives to your pc and create your backup copies (If a fire happens on your house, NAS/DAS also dies either way, so not worth buying them)&lt;br/&gt;\n2) A Das is enough. You create a copy of your data, when needed you just attach it to whatever device you need it, and it&amp;#39;s faster than nas.&lt;br/&gt;\n3) A NAS has so many more uses, like connect to both laptop and desktop through network, etc, which has so much more potential If you&amp;#39;re gonna spend money, just go for something better.  &lt;/p&gt;\n\n&lt;p&gt;So, which is it? Any advice is appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12cufyd", "is_robot_indexable": true, "report_reasons": null, "author": "Mangomagno123", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12cufyd/bought_16tb_2x8tb_now_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12cufyd/bought_16tb_2x8tb_now_what/", "subreddit_subscribers": 676807, "created_utc": 1680721438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am getting another 10tb Elements to do a simple cold backup of some of my favorite files. \n\nI already have a 10TB Elements I've had in use since 2020. \n\nShould I transfer my existing data from the older drive to the new drive since it will be the one receiving more frequent weekly backups, or use the newest 10TB Elements as the semi-cold backup (used twice yearly)?", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use newer/older drive of pair for periodic (weekly) backups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12dgf10", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680778569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am getting another 10tb Elements to do a simple cold backup of some of my favorite files. &lt;/p&gt;\n\n&lt;p&gt;I already have a 10TB Elements I&amp;#39;ve had in use since 2020. &lt;/p&gt;\n\n&lt;p&gt;Should I transfer my existing data from the older drive to the new drive since it will be the one receiving more frequent weekly backups, or use the newest 10TB Elements as the semi-cold backup (used twice yearly)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "36TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "12dgf10", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12dgf10/use_newerolder_drive_of_pair_for_periodic_weekly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12dgf10/use_newerolder_drive_of_pair_for_periodic_weekly/", "subreddit_subscribers": 676807, "created_utc": 1680778569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have Seagate IronWolf 8TB and SkyHawk 4TB, with following configuration:\n\n* Pool 1\n   * RAID Group 1 Single\n      * IronWolf\n   * RAID Group 2 Single\n      * SkyHawk\n\nwith one thick volume taking the whole capacity of both drives. I have a little over 3 TB of data. It's not critical data, mostly movies and Steam backups, it gets lost - shit happens.\n\nI want to swap SkyHawk for another IronWolf 8TB, as I'm not sure how long SkyHawk will chug along - it likes to re-spin it's platters once in a while, and it's making weird noises. Not SMART nor full rw scan haven't shown nothing wrong, but better safe than sorry.\n\nSo - can I just power off NAS, yoink the old drive, clone it (with dd or similar) as is onto the new one, expand partition, plug the new drive and expand volume in QTS?\n\nOr should I just rsync everything onto new one, wipe both drives from NAS, initialize old IronWolf in NAS, rsync data back to NAS and initialize second one?", "author_fullname": "t2_2fh0nwks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Swapping drive in QNAP TS-233", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12dfizv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680776263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have Seagate IronWolf 8TB and SkyHawk 4TB, with following configuration:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Pool 1\n\n&lt;ul&gt;\n&lt;li&gt;RAID Group 1 Single\n\n&lt;ul&gt;\n&lt;li&gt;IronWolf&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;RAID Group 2 Single\n\n&lt;ul&gt;\n&lt;li&gt;SkyHawk&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;with one thick volume taking the whole capacity of both drives. I have a little over 3 TB of data. It&amp;#39;s not critical data, mostly movies and Steam backups, it gets lost - shit happens.&lt;/p&gt;\n\n&lt;p&gt;I want to swap SkyHawk for another IronWolf 8TB, as I&amp;#39;m not sure how long SkyHawk will chug along - it likes to re-spin it&amp;#39;s platters once in a while, and it&amp;#39;s making weird noises. Not SMART nor full rw scan haven&amp;#39;t shown nothing wrong, but better safe than sorry.&lt;/p&gt;\n\n&lt;p&gt;So - can I just power off NAS, yoink the old drive, clone it (with dd or similar) as is onto the new one, expand partition, plug the new drive and expand volume in QTS?&lt;/p&gt;\n\n&lt;p&gt;Or should I just rsync everything onto new one, wipe both drives from NAS, initialize old IronWolf in NAS, rsync data back to NAS and initialize second one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "14\u00bd TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12dfizv", "is_robot_indexable": true, "report_reasons": null, "author": "Calslock", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12dfizv/swapping_drive_in_qnap_ts233/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12dfizv/swapping_drive_in_qnap_ts233/", "subreddit_subscribers": 676807, "created_utc": 1680776263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "We would like to create a hardened backup repository within the company to protect ourselves from ramsomware and sleep more peacefully.\n\n&amp;#x200B;\n\nWe would choose TrueNAS Scale and follow the [documentation](https://www.truenas.com/docs/scale/scaletutorials/communityrecommends/hardened-backup-repository-for-veeam/) to create a solid backup, what do you think?\n\n&amp;#x200B;\n\nWe would like to buy the hardware from TrueNAS to get a turnkey solution.\n\n&amp;#x200B;\n\nConsidering configuring 3 periodic snapshots (hourly, daily and weekly) and having 5TB of data.\n\nHow much space should ZFS snapshots take up?", "author_fullname": "t2_ettqq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hardened Backup advices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dchdo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680766380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We would like to create a hardened backup repository within the company to protect ourselves from ramsomware and sleep more peacefully.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We would choose TrueNAS Scale and follow the &lt;a href=\"https://www.truenas.com/docs/scale/scaletutorials/communityrecommends/hardened-backup-repository-for-veeam/\"&gt;documentation&lt;/a&gt; to create a solid backup, what do you think?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We would like to buy the hardware from TrueNAS to get a turnkey solution.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Considering configuring 3 periodic snapshots (hourly, daily and weekly) and having 5TB of data.&lt;/p&gt;\n\n&lt;p&gt;How much space should ZFS snapshots take up?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12dchdo", "is_robot_indexable": true, "report_reasons": null, "author": "skar3", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12dchdo/hardened_backup_advices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12dchdo/hardened_backup_advices/", "subreddit_subscribers": 676807, "created_utc": 1680766380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm thinking of starting with two 4TB HDD drives in a raid one array. My pc has two drive bays and my motherboard supports raid.\n\nI may eventually put those drives in a 4-drive NAS, but I'd have to buy a 200 something NAS and spend another 100 or so dollars on the other two drives.\n\nHow good would a two drive array be?", "author_fullname": "t2_gjiw7o0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How good is a 2 drive array? What's a good setup for a beginner data hoarder?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12dber9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680762739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m thinking of starting with two 4TB HDD drives in a raid one array. My pc has two drive bays and my motherboard supports raid.&lt;/p&gt;\n\n&lt;p&gt;I may eventually put those drives in a 4-drive NAS, but I&amp;#39;d have to buy a 200 something NAS and spend another 100 or so dollars on the other two drives.&lt;/p&gt;\n\n&lt;p&gt;How good would a two drive array be?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12dber9", "is_robot_indexable": true, "report_reasons": null, "author": "GamerboyJD", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12dber9/how_good_is_a_2_drive_array_whats_a_good_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12dber9/how_good_is_a_2_drive_array_whats_a_good_setup/", "subreddit_subscribers": 676807, "created_utc": 1680762739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello people. \nI have an old desktop pc I am gone use as a server. But I don\u2019t trust the PSU to run 24/7. So I\u2019m looking for a new one. \n\nI need to connect 15 drives and a PSU there can handle 20 will be preferred. I don\u2019t need the 6+2 pci power. And the mb only have a 4 pin cpu power. Beside the 24pin. \n\nI have a lot of Corsair PSU 4x15pin cables . And was wondering if I can buy a new Corsair PSU and use them. Some how. \n\nOr maybe split a pci/cpu power into some 15pin Sata. I know is a risky move. And there is a lot of bad products out there. But maybe your guy\u2019s know a way to do it properly. That I don\u2019t. \n\nAnd I prefer a cheap way to do it.", "author_fullname": "t2_6mm1xxyyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a new PSU for my data pc.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12d5co1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680745722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello people. \nI have an old desktop pc I am gone use as a server. But I don\u2019t trust the PSU to run 24/7. So I\u2019m looking for a new one. &lt;/p&gt;\n\n&lt;p&gt;I need to connect 15 drives and a PSU there can handle 20 will be preferred. I don\u2019t need the 6+2 pci power. And the mb only have a 4 pin cpu power. Beside the 24pin. &lt;/p&gt;\n\n&lt;p&gt;I have a lot of Corsair PSU 4x15pin cables . And was wondering if I can buy a new Corsair PSU and use them. Some how. &lt;/p&gt;\n\n&lt;p&gt;Or maybe split a pci/cpu power into some 15pin Sata. I know is a risky move. And there is a lot of bad products out there. But maybe your guy\u2019s know a way to do it properly. That I don\u2019t. &lt;/p&gt;\n\n&lt;p&gt;And I prefer a cheap way to do it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12d5co1", "is_robot_indexable": true, "report_reasons": null, "author": "DSandholm", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12d5co1/looking_for_a_new_psu_for_my_data_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12d5co1/looking_for_a_new_psu_for_my_data_pc/", "subreddit_subscribers": 676807, "created_utc": 1680745722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "When doing embedded album covers what size do you roll with for the album covers?? I am thinking about going with 1000x1000x or 1200x1200 with size 350kbps to 400kbs size what size should I go with?? I am planning to update album covers for 156k traxx the rest of the metadata is fine", "author_fullname": "t2_34nci", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When doing embedded album covers what size do you roll with for the album covers??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12d01pq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680733399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When doing embedded album covers what size do you roll with for the album covers?? I am thinking about going with 1000x1000x or 1200x1200 with size 350kbps to 400kbs size what size should I go with?? I am planning to update album covers for 156k traxx the rest of the metadata is fine&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "12d01pq", "is_robot_indexable": true, "report_reasons": null, "author": "DJboutit", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12d01pq/when_doing_embedded_album_covers_what_size_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12d01pq/when_doing_embedded_album_covers_what_size_do_you/", "subreddit_subscribers": 676807, "created_utc": 1680733399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm thinking of buying 1 tb Samsung t7 shield which is available on Amazon for Rs 10000.\n\nWhat are other better options availalble(in India) in this price range?\n\nShould I buy t7 instead and save Rs 1000? I won't be traveling much around with the ssd.\n\nThanks in advance!", "author_fullname": "t2_epo2u4fy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best ssd in India under or around Rs 10000", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12crttu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680716077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m thinking of buying 1 tb Samsung t7 shield which is available on Amazon for Rs 10000.&lt;/p&gt;\n\n&lt;p&gt;What are other better options availalble(in India) in this price range?&lt;/p&gt;\n\n&lt;p&gt;Should I buy t7 instead and save Rs 1000? I won&amp;#39;t be traveling much around with the ssd.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12crttu", "is_robot_indexable": true, "report_reasons": null, "author": "mave7rick", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12crttu/best_ssd_in_india_under_or_around_rs_10000/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12crttu/best_ssd_in_india_under_or_around_rs_10000/", "subreddit_subscribers": 676807, "created_utc": 1680716077.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}