{"kind": "Listing", "data": {"after": "t3_12idu7y", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have experience in DE for about 7 years and currently promoted to Data Architect role. I understand my responsibilities which include laying out data models, architecture diagrams, suggesting the best tools for a particular scenario. I have worked majorly in Azure and Databricks .\n\nPlease suggest the learning path / thinking methodology for me to be better at my current role.", "author_fullname": "t2_2xxs9nne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have been recently promoted to Data Architect Role. I need help on learning resources/pointers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12iaaka", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681199121.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681192407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have experience in DE for about 7 years and currently promoted to Data Architect role. I understand my responsibilities which include laying out data models, architecture diagrams, suggesting the best tools for a particular scenario. I have worked majorly in Azure and Databricks .&lt;/p&gt;\n\n&lt;p&gt;Please suggest the learning path / thinking methodology for me to be better at my current role.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12iaaka", "is_robot_indexable": true, "report_reasons": null, "author": "inglocines", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12iaaka/i_have_been_recently_promoted_to_data_architect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12iaaka/i_have_been_recently_promoted_to_data_architect/", "subreddit_subscribers": 98037, "created_utc": 1681192407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, college student here, I\u2019m currently interested in working in the Data space. One job that seems interesting to me is ETL Developer, however, many are telling me that ETL Developer is an outdated job, and that ETL development is generally in the domain of the data engineer nowadays. But on the other hand, there are others who tell me that most data engineers hate doing ETL, and that a lot of companies still have so much ETL work to do that they hire specialized ETL Devs on top of data engineers. I\u2019m not sure if I\u2019m interested in the entirety of data engineering. I\u2019ve only shown interest in pipeline development and data \nmovement so far, so I\u2019m a bit lost as to what career direction I should take. Do you guys think ETL developer is still very much a legit role that is worth aiming for? Or should I switch gears to data engineering jobs?", "author_fullname": "t2_c2u69kfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is ETL Developer still a legit and in-demand career? Or is it just housed under Data Engineering now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12i0nh1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681170057.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681169608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, college student here, I\u2019m currently interested in working in the Data space. One job that seems interesting to me is ETL Developer, however, many are telling me that ETL Developer is an outdated job, and that ETL development is generally in the domain of the data engineer nowadays. But on the other hand, there are others who tell me that most data engineers hate doing ETL, and that a lot of companies still have so much ETL work to do that they hire specialized ETL Devs on top of data engineers. I\u2019m not sure if I\u2019m interested in the entirety of data engineering. I\u2019ve only shown interest in pipeline development and data \nmovement so far, so I\u2019m a bit lost as to what career direction I should take. Do you guys think ETL developer is still very much a legit role that is worth aiming for? Or should I switch gears to data engineering jobs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12i0nh1", "is_robot_indexable": true, "report_reasons": null, "author": "IllMorning741", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12i0nh1/is_etl_developer_still_a_legit_and_indemand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12i0nh1/is_etl_developer_still_a_legit_and_indemand/", "subreddit_subscribers": 98037, "created_utc": 1681169608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_975og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to use dbt source freshness tests to detect stale data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_12inq6z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/noCUQVwfgAxpdD300vlHP-w_Vk1xBMS_Ttf-9Ny8RNw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681227499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datafold.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.datafold.com/blog/dbt-source-freshness", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?auto=webp&amp;v=enabled&amp;s=4a2e7bf440d31e813fbfed118f2002466730cdef", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd999aa101b6b02ad7b9401b6512c65d55b7d934", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e543df1eb9d1e1b52ec25a320c6494e1e6eb4ba", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c8ac3945ef71a946231120973bab1279083550a", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a64035e5ef1f38e6d55725ff6d4e337d9d60bee", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32af2cff24ddc953b8c0d4f53d80d44fd01cd7ab", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db2d5a8b7088d3f01673eab7d94b8ca156d2b999", "width": 1080, "height": 607}], "variants": {}, "id": "Hk_DWgM9iMOzRYbc08qVJTco8z-aNttuxoSZwBKbciQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12inq6z", "is_robot_indexable": true, "report_reasons": null, "author": "arimbr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12inq6z/how_to_use_dbt_source_freshness_tests_to_detect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.datafold.com/blog/dbt-source-freshness", "subreddit_subscribers": 98037, "created_utc": 1681227499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've made a simple ETL project orchestrated by Airflow. The process is basically download &gt;&gt; transform &gt;&gt; load into Postgres.\n\n    with DAG(...):\n        task1 = PythonOperator(\n            task_id = \"DownloadData\",\n            python_callable = download_task\n        \u00a0 \u00a0 )\n        task2 = PythonOperator(\n            task_id = \"TransformData\",\n            python_callable = transform_task\n        \u00a0 \u00a0 )\n        ...\n        task1 &gt;&gt; task2 &gt;&gt; task3\n\nFirst task downloads more than 10k text-based files containing weather data. Its speed is okay (4 minutes w/ multithreading).\n\nThe problem is the second task. I used pandas to transform text-based files into clean data in .tsv format.\n\n    def _read_file(filename):\n        with open(filename, \"r\", encoding=\"UTF-8\") as f:\n            for line in f:           \n                line_content = [float(i) for i in line.split()]\n                yield {\n                    \"station_id\": filename,\n                    \"date\": f\"line_content[0]-line_content[1]-line_content[2]\"\n                    \"air_temperature\": line_content[4],\n                    ...\n                }\n\nI use `_read_file()` to read the content of the text-based file and make it a pandas dataframe to transform it.\n\n[raw text-based file \\(weather hourly data\\)](https://preview.redd.it/vritpkald8ta1.png?width=867&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c0bd6140837ad95c0bb1e21554326086803ea5c2)\n\n&amp;#x200B;\n\n    def transform(filename):        \n        # Create a dataframe out of file data\n        file_data = _read_file(filename)\n        df = pd.DataFrame(file_data)\n    \n        # Get the summarization of data (min, mean, max)\n        df = df.groupby(['station_id', 'date']).agg(\n            air_temperature_avg = ('air_temperature', 'mean'),\n            air_temperature_min = ('air_temperature', 'min'),\n            air_temperature_max = ('air_temperature', 'max'),\n            ...\n        )\n    \n        df.to_csv(f\"{filename}.tsv\", sep = \"\\t\")\n\n&amp;#x200B;\n\n[transformed data \\(daily summary: mean, min, and max\\)](https://preview.redd.it/06xqm23od8ta1.png?width=890&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1748787299abfd1424251c2c3aaa1c2fae69a4b0)\n\nThen i use the transform function in transform\\_task to summarize 10k+ raw text-based files one by one\n\n    def transform_task():\n        for filename in glob.glob(\"raw_directory/*\"): \u00a0 \u00a0 \u00a0 \u00a0 \n            transform(filename)\n\n&amp;#x200B;\n\nNote: I'm doing this locally in my laptop, not in cloud\n\nTransformation of each file is quick, about 0.15-0.20 seconds each. However, there are more than 10k files to transform so it takes about 40 minutes to accomplish the task. What do you think can be done to make this process faster?  Thanks in advance!", "author_fullname": "t2_3j0efkbj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[ETL Project] Transformation with Python pandas too slow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vritpkald8ta1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 53, "x": 108, "u": "https://preview.redd.it/vritpkald8ta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d107e03c8260dff820045e7e6b041408e268535"}, {"y": 107, "x": 216, "u": "https://preview.redd.it/vritpkald8ta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=305ecb53d459cda96dc5281d32a37c1d34e2191d"}, {"y": 159, "x": 320, "u": "https://preview.redd.it/vritpkald8ta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7efb5852a4692e1ef85dbbd54b5e6c9f1e7fd6c9"}, {"y": 318, "x": 640, "u": "https://preview.redd.it/vritpkald8ta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c4f60aaf2291325653e15b89ac6d89ad0170331"}], "s": {"y": 432, "x": 867, "u": "https://preview.redd.it/vritpkald8ta1.png?width=867&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c0bd6140837ad95c0bb1e21554326086803ea5c2"}, "id": "vritpkald8ta1"}, "06xqm23od8ta1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 34, "x": 108, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93511b5de9624e32b16b8c2cffa927a77321a831"}, {"y": 68, "x": 216, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=828c0732137bab2a055716c074977acf9fb5a5da"}, {"y": 101, "x": 320, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=782d8bd64676f91b572919eafda1b15c4c9eb021"}, {"y": 202, "x": 640, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=61f15eef99db8331ce810c947905e612bba073c8"}], "s": {"y": 281, "x": 890, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=890&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1748787299abfd1424251c2c3aaa1c2fae69a4b0"}, "id": "06xqm23od8ta1"}}, "name": "t3_12ie2fq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wf4RNpLcW-lz-jrhuDtUGh4NumBHQWJQDlF-mGfc-uA.jpg", "edited": 1681211557.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681204509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve made a simple ETL project orchestrated by Airflow. The process is basically download &amp;gt;&amp;gt; transform &amp;gt;&amp;gt; load into Postgres.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;with DAG(...):\n    task1 = PythonOperator(\n        task_id = &amp;quot;DownloadData&amp;quot;,\n        python_callable = download_task\n    \u00a0 \u00a0 )\n    task2 = PythonOperator(\n        task_id = &amp;quot;TransformData&amp;quot;,\n        python_callable = transform_task\n    \u00a0 \u00a0 )\n    ...\n    task1 &amp;gt;&amp;gt; task2 &amp;gt;&amp;gt; task3\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;First task downloads more than 10k text-based files containing weather data. Its speed is okay (4 minutes w/ multithreading).&lt;/p&gt;\n\n&lt;p&gt;The problem is the second task. I used pandas to transform text-based files into clean data in .tsv format.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def _read_file(filename):\n    with open(filename, &amp;quot;r&amp;quot;, encoding=&amp;quot;UTF-8&amp;quot;) as f:\n        for line in f:           \n            line_content = [float(i) for i in line.split()]\n            yield {\n                &amp;quot;station_id&amp;quot;: filename,\n                &amp;quot;date&amp;quot;: f&amp;quot;line_content[0]-line_content[1]-line_content[2]&amp;quot;\n                &amp;quot;air_temperature&amp;quot;: line_content[4],\n                ...\n            }\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I use &lt;code&gt;_read_file()&lt;/code&gt; to read the content of the text-based file and make it a pandas dataframe to transform it.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vritpkald8ta1.png?width=867&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c0bd6140837ad95c0bb1e21554326086803ea5c2\"&gt;raw text-based file (weather hourly data)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def transform(filename):        \n    # Create a dataframe out of file data\n    file_data = _read_file(filename)\n    df = pd.DataFrame(file_data)\n\n    # Get the summarization of data (min, mean, max)\n    df = df.groupby([&amp;#39;station_id&amp;#39;, &amp;#39;date&amp;#39;]).agg(\n        air_temperature_avg = (&amp;#39;air_temperature&amp;#39;, &amp;#39;mean&amp;#39;),\n        air_temperature_min = (&amp;#39;air_temperature&amp;#39;, &amp;#39;min&amp;#39;),\n        air_temperature_max = (&amp;#39;air_temperature&amp;#39;, &amp;#39;max&amp;#39;),\n        ...\n    )\n\n    df.to_csv(f&amp;quot;{filename}.tsv&amp;quot;, sep = &amp;quot;\\t&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/06xqm23od8ta1.png?width=890&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1748787299abfd1424251c2c3aaa1c2fae69a4b0\"&gt;transformed data (daily summary: mean, min, and max)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Then i use the transform function in transform_task to summarize 10k+ raw text-based files one by one&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def transform_task():\n    for filename in glob.glob(&amp;quot;raw_directory/*&amp;quot;): \u00a0 \u00a0 \u00a0 \u00a0 \n        transform(filename)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Note: I&amp;#39;m doing this locally in my laptop, not in cloud&lt;/p&gt;\n\n&lt;p&gt;Transformation of each file is quick, about 0.15-0.20 seconds each. However, there are more than 10k files to transform so it takes about 40 minutes to accomplish the task. What do you think can be done to make this process faster?  Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ie2fq", "is_robot_indexable": true, "report_reasons": null, "author": "Pervert_Spongebob", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ie2fq/etl_project_transformation_with_python_pandas_too/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ie2fq/etl_project_transformation_with_python_pandas_too/", "subreddit_subscribers": 98037, "created_utc": 1681204509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am a young graduate in data science and I am currently looking for a data engineering job. I had a health problem after graduation so I could not apply to jobs immediately. Thus I have a gap of a few months and I am currently having trouble finding a job. I suspect employers are reluctant to pick me because of this gap. I would like to have a more attractive profile as a data engineer. What are some tips to have better chances of landing a job in Data Engineering and which story I could tell about the gap to avoid mentioning health problems?\n\nThank you,\n\nBest regards.", "author_fullname": "t2_adoxjqxf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some tips to get a data engineering job with a gap of a few months.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12i3iqy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681175989.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am a young graduate in data science and I am currently looking for a data engineering job. I had a health problem after graduation so I could not apply to jobs immediately. Thus I have a gap of a few months and I am currently having trouble finding a job. I suspect employers are reluctant to pick me because of this gap. I would like to have a more attractive profile as a data engineer. What are some tips to have better chances of landing a job in Data Engineering and which story I could tell about the gap to avoid mentioning health problems?&lt;/p&gt;\n\n&lt;p&gt;Thank you,&lt;/p&gt;\n\n&lt;p&gt;Best regards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12i3iqy", "is_robot_indexable": true, "report_reasons": null, "author": "Educational-Turn-419", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12i3iqy/what_are_some_tips_to_get_a_data_engineering_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12i3iqy/what_are_some_tips_to_get_a_data_engineering_job/", "subreddit_subscribers": 98037, "created_utc": 1681175989.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, I recently moved from mobile engineering to data engineering. I'm seeing no documentation about how to structure SQL code (e.g. MVC). Are there any articles or projects working on this?", "author_fullname": "t2_xl0mt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model View Controller (MVC) for DAGs and or models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hz7sb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681166677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, I recently moved from mobile engineering to data engineering. I&amp;#39;m seeing no documentation about how to structure SQL code (e.g. MVC). Are there any articles or projects working on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12hz7sb", "is_robot_indexable": true, "report_reasons": null, "author": "tokyopanda1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12hz7sb/model_view_controller_mvc_for_dags_and_or_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12hz7sb/model_view_controller_mvc_for_dags_and_or_models/", "subreddit_subscribers": 98037, "created_utc": 1681166677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If my 10s of TB of data can fit into an MPP database (Redshift/Snowflake) and can be loaded via SQL, what's the profit of data lake?", "author_fullname": "t2_mgfnv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why data lake over MPP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hrhda", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681151401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If my 10s of TB of data can fit into an MPP database (Redshift/Snowflake) and can be loaded via SQL, what&amp;#39;s the profit of data lake?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12hrhda", "is_robot_indexable": true, "report_reasons": null, "author": "kotpeter", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12hrhda/why_data_lake_over_mpp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12hrhda/why_data_lake_over_mpp/", "subreddit_subscribers": 98037, "created_utc": 1681151401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/12hvyqb)", "author_fullname": "t2_9ag9k9ly", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What entry level role did you work as before moving to DE? (If any)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hvyqb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681160217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/12hvyqb\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12hvyqb", "is_robot_indexable": true, "report_reasons": null, "author": "Ecstatic-Rabbit2089", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1681333017703, "options": [{"text": "Data Analyst", "id": "22497878"}, {"text": "Data Scientist", "id": "22497879"}, {"text": "Software Engineer", "id": "22497880"}, {"text": "Other (mention in comments)", "id": "22497881"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 662, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12hvyqb/what_entry_level_role_did_you_work_as_before/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/12hvyqb/what_entry_level_role_did_you_work_as_before/", "subreddit_subscribers": 98037, "created_utc": 1681160217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \nAbout me: I joined the corporate world as an Data engineer just after graduating in mid 2021 (but my current work revolves around Data analytics, SQL and Python). Total exp: 1.5yrs\n\nI am currently in a dilemma: whether I should continue as a Data Engineer by expanding my skills (learning Spark etc) or switch to SDE roles (safe evergreen option).\n\nI have few concerns about DE role which is kinda stopping me from fully deep diving into it. \n\n1. Are data engineers considered 2nd class employees in a company? I have read that DE is a role that supports business functions and Data scientist and are generally not profit generating employees (away from business) hence their efforts can sometimes go unnoticed.\n\n2. How does day in a life looks like? Work life balance and work environment?\n\n3. Growth prospects: Can a DE transition/grow into leadership positions?\n\n\nLooking for some guidance. Thanks in advance!", "author_fullname": "t2_75txeq7v4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is DE a good role in terms of work and work life balance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12idd74", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681204269.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681202190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, \nAbout me: I joined the corporate world as an Data engineer just after graduating in mid 2021 (but my current work revolves around Data analytics, SQL and Python). Total exp: 1.5yrs&lt;/p&gt;\n\n&lt;p&gt;I am currently in a dilemma: whether I should continue as a Data Engineer by expanding my skills (learning Spark etc) or switch to SDE roles (safe evergreen option).&lt;/p&gt;\n\n&lt;p&gt;I have few concerns about DE role which is kinda stopping me from fully deep diving into it. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Are data engineers considered 2nd class employees in a company? I have read that DE is a role that supports business functions and Data scientist and are generally not profit generating employees (away from business) hence their efforts can sometimes go unnoticed.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How does day in a life looks like? Work life balance and work environment?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Growth prospects: Can a DE transition/grow into leadership positions?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Looking for some guidance. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12idd74", "is_robot_indexable": true, "report_reasons": null, "author": "Skrirraa", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12idd74/is_de_a_good_role_in_terms_of_work_and_work_life/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12idd74/is_de_a_good_role_in_terms_of_work_and_work_life/", "subreddit_subscribers": 98037, "created_utc": 1681202190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello DE friends.\n\nMy current company uses Apache Airflow for scheduling, and we are quite happy with it. But giving technically gifted PMs the ability to make simple DAGs from a visual interface would be amazing.\n\nFor this we love the N8N interface. \n\nHowever the native N8N scheduler and workflows are too lacking and overcomplicated to use for our workflows.\n\nHence my question.\n\nHas anyone connected N8N or any no-code solution to Airflow? \n\nLet me be specific. We aren't looking to trigger a DAG from N8N. We'd like to build it there, task by task, and then have the resulting DAG deployed on Airflow.\n\nIf you have any hints, ideas or projects that you think are doing this, I'd be super interested.\n\nThanks for your help \ud83d\ude4f", "author_fullname": "t2_85uwiihz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using no-code to create simple Airflow Dags", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12icsvl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681200327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello DE friends.&lt;/p&gt;\n\n&lt;p&gt;My current company uses Apache Airflow for scheduling, and we are quite happy with it. But giving technically gifted PMs the ability to make simple DAGs from a visual interface would be amazing.&lt;/p&gt;\n\n&lt;p&gt;For this we love the N8N interface. &lt;/p&gt;\n\n&lt;p&gt;However the native N8N scheduler and workflows are too lacking and overcomplicated to use for our workflows.&lt;/p&gt;\n\n&lt;p&gt;Hence my question.&lt;/p&gt;\n\n&lt;p&gt;Has anyone connected N8N or any no-code solution to Airflow? &lt;/p&gt;\n\n&lt;p&gt;Let me be specific. We aren&amp;#39;t looking to trigger a DAG from N8N. We&amp;#39;d like to build it there, task by task, and then have the resulting DAG deployed on Airflow.&lt;/p&gt;\n\n&lt;p&gt;If you have any hints, ideas or projects that you think are doing this, I&amp;#39;d be super interested.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your help \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12icsvl", "is_robot_indexable": true, "report_reasons": null, "author": "GeekyTricky", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12icsvl/using_nocode_to_create_simple_airflow_dags/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12icsvl/using_nocode_to_create_simple_airflow_dags/", "subreddit_subscribers": 98037, "created_utc": 1681200327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team currently have our data sitting in a delta lake in an Azure storage account. We use Databricks on Azure to ingest and process data.\n\nWe have gotten to the stage where we would like to create an API to act as an interface to output data to web applications run by other teams as we don't want to tie their applications directly to the use of delta. We want them to be able to pass in parameters, we would then do some final steps of processing using the parameters provided, and then we want to send the output data directly back to the calling application. The final output of data will be a time-series and we expect that in the future the time-series could have in excess of one million items. The tables that will be queried are fairly large and growing so we want to minimise the compute time of the calculations by using Spark or some other method that is as fast. Ideally, we would want to do this without a wrapper layer that we would need to host external to Databricks, at least for now.\n\nWe realise that our setup is fairly similar to what other teams seem to have and were wondering how anyone else has managed to achieve what we are trying to.", "author_fullname": "t2_n937n0g6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Lake/Databricks egress via API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12iodei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681228788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team currently have our data sitting in a delta lake in an Azure storage account. We use Databricks on Azure to ingest and process data.&lt;/p&gt;\n\n&lt;p&gt;We have gotten to the stage where we would like to create an API to act as an interface to output data to web applications run by other teams as we don&amp;#39;t want to tie their applications directly to the use of delta. We want them to be able to pass in parameters, we would then do some final steps of processing using the parameters provided, and then we want to send the output data directly back to the calling application. The final output of data will be a time-series and we expect that in the future the time-series could have in excess of one million items. The tables that will be queried are fairly large and growing so we want to minimise the compute time of the calculations by using Spark or some other method that is as fast. Ideally, we would want to do this without a wrapper layer that we would need to host external to Databricks, at least for now.&lt;/p&gt;\n\n&lt;p&gt;We realise that our setup is fairly similar to what other teams seem to have and were wondering how anyone else has managed to achieve what we are trying to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12iodei", "is_robot_indexable": true, "report_reasons": null, "author": "piri9825", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12iodei/delta_lakedatabricks_egress_via_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12iodei/delta_lakedatabricks_egress_via_api/", "subreddit_subscribers": 98037, "created_utc": 1681228788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Project with Airflow, DuckDB, MinIO, Streamlit and the AstroSDK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_12io51t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ir3H1xOoIb8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow Quickstart Project with DuckDB, MinIO and Streamlit\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Airflow Quickstart Project with DuckDB, MinIO and Streamlit", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ir3H1xOoIb8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow Quickstart Project with DuckDB, MinIO and Streamlit\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ir3H1xOoIb8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ir3H1xOoIb8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow Quickstart Project with DuckDB, MinIO and Streamlit\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/12io51t", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/C1naVPMCf-NVQ2t-oeXHMl4fPtikScSkrLYr21lQT7E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681228317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/ir3H1xOoIb8", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ncIe23vBi-MwJHABiGjw0JSN8zu2i_6GCRasr2wttP4.jpg?auto=webp&amp;v=enabled&amp;s=6a0b7647651ce6f2c4af2fce28200cdcfc7c73f3", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/ncIe23vBi-MwJHABiGjw0JSN8zu2i_6GCRasr2wttP4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b290915d178f1ee75ceff5f7e053dc7566fd4c3a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/ncIe23vBi-MwJHABiGjw0JSN8zu2i_6GCRasr2wttP4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=138ae22da4e6f615e245d1293fccfb34a57665cf", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/ncIe23vBi-MwJHABiGjw0JSN8zu2i_6GCRasr2wttP4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b8bf888802f94138883b0e352a8feb2a5456274", "width": 320, "height": 240}], "variants": {}, "id": "JA9sMYD-6aEO4BCBc0r4btyF20uJ4WxAJhbu-4uefp8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12io51t", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12io51t/data_engineering_project_with_airflow_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/ir3H1xOoIb8", "subreddit_subscribers": 98037, "created_utc": 1681228317.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Airflow Quickstart Project with DuckDB, MinIO and Streamlit", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ir3H1xOoIb8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow Quickstart Project with DuckDB, MinIO and Streamlit\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ir3H1xOoIb8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've seen a few people mention trino + data lake. I see in the trino docs that it's designed to query different sources directly, ie without prior etl/elt. \n\nSo why bother with a data lake? \n\nI can imagine it's to make reads faster, for better organization, and to avoid noisy neighbor type issues on source systems. \n\nAnyone have ideas on those or other reasons?", "author_fullname": "t2_ut20i32q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why use trino on a data lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ip77n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681230527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen a few people mention trino + data lake. I see in the trino docs that it&amp;#39;s designed to query different sources directly, ie without prior etl/elt. &lt;/p&gt;\n\n&lt;p&gt;So why bother with a data lake? &lt;/p&gt;\n\n&lt;p&gt;I can imagine it&amp;#39;s to make reads faster, for better organization, and to avoid noisy neighbor type issues on source systems. &lt;/p&gt;\n\n&lt;p&gt;Anyone have ideas on those or other reasons?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ip77n", "is_robot_indexable": true, "report_reasons": null, "author": "alex_o_h", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ip77n/why_use_trino_on_a_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ip77n/why_use_trino_on_a_data_lake/", "subreddit_subscribers": 98037, "created_utc": 1681230527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm a fresh Cs grad who recently applied for a data engineering position at a startup even though I had no related experience/projects in the field. I went through two phases, the first was more of an hr interview and the second was an online assessment that covered SQL Queries and definitions of data terms such as Big Data and Data Normalization. I also had a coding task in which I created a Web Scrapper.  \nWhat kind of questions should I expect in the final technical interview and is there anything specific I should revise other than the topics covered in the assessment?", "author_fullname": "t2_36yjr0ht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upcoming Final Technical Interview, What to Expect?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hvziz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681160263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m a fresh Cs grad who recently applied for a data engineering position at a startup even though I had no related experience/projects in the field. I went through two phases, the first was more of an hr interview and the second was an online assessment that covered SQL Queries and definitions of data terms such as Big Data and Data Normalization. I also had a coding task in which I created a Web Scrapper.&lt;br/&gt;\nWhat kind of questions should I expect in the final technical interview and is there anything specific I should revise other than the topics covered in the assessment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12hvziz", "is_robot_indexable": true, "report_reasons": null, "author": "ramezgaras", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12hvziz/upcoming_final_technical_interview_what_to_expect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12hvziz/upcoming_final_technical_interview_what_to_expect/", "subreddit_subscribers": 98037, "created_utc": 1681160263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a bit of a career question that turned into an argument.  Which organization would you say have the most skilled/advanced developers (not DEs exclusively, but developers in general)?\n\n[View Poll](https://www.reddit.com/poll/12hvsjf)", "author_fullname": "t2_7yk2o6hxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which organizations have the strongest developers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hvsjf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681159863.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a bit of a career question that turned into an argument.  Which organization would you say have the most skilled/advanced developers (not DEs exclusively, but developers in general)?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/12hvsjf\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12hvsjf", "is_robot_indexable": true, "report_reasons": null, "author": "grahamdietz", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1681419063522, "options": [{"text": "Large consultants (TaTa, Infosys)", "id": "22497821"}, {"text": "Specialized 'boutique' Consulting firms (Brooklyn Data, Rittman)", "id": "22497822"}, {"text": "Larger enterprises/corporations", "id": "22497823"}, {"text": "Smaller data driven start-ups", "id": "22497824"}, {"text": "Academics", "id": "22497825"}, {"text": "DevTool vendors", "id": "22497826"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 960, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12hvsjf/which_organizations_have_the_strongest_developers/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/12hvsjf/which_organizations_have_the_strongest_developers/", "subreddit_subscribers": 98037, "created_utc": 1681159863.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, I have a question, probably very strange one, but I have a task on this which is killing me.\nThe problem is that I have a lot of JSON files that need to be processed. The files have different structure schema, but the requester wants to have the data flattened in a table with a very general structure, to cover all formats. The data will be used then for reporting.\n Is there any possible way to do this? \nI would appreciate any suggestion on how the final table may look like and how to flatten the data. The implementation should be done in Java, but I would not focus now on this.\n Thank you very much!", "author_fullname": "t2_8ouamdf5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Generic JSON schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12irysl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681236123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I have a question, probably very strange one, but I have a task on this which is killing me.\nThe problem is that I have a lot of JSON files that need to be processed. The files have different structure schema, but the requester wants to have the data flattened in a table with a very general structure, to cover all formats. The data will be used then for reporting.\n Is there any possible way to do this? \nI would appreciate any suggestion on how the final table may look like and how to flatten the data. The implementation should be done in Java, but I would not focus now on this.\n Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12irysl", "is_robot_indexable": true, "report_reasons": null, "author": "adaptrix", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12irysl/generic_json_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12irysl/generic_json_schema/", "subreddit_subscribers": 98037, "created_utc": 1681236123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What exactly is the difference between a linter (like sqlfluff) and a formatter (like sqlfmt)? Doesn\u2019t sqlfluff act like a formatter if you run \u201csqlfluff fix\u201d? Besides, are there better SQL formatters available? What are you working with?", "author_fullname": "t2_gzpboep7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL formatting (sqlfluff vs sqlfmt)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12irh9h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681235209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What exactly is the difference between a linter (like sqlfluff) and a formatter (like sqlfmt)? Doesn\u2019t sqlfluff act like a formatter if you run \u201csqlfluff fix\u201d? Besides, are there better SQL formatters available? What are you working with?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12irh9h", "is_robot_indexable": true, "report_reasons": null, "author": "themouthoftruth", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12irh9h/sql_formatting_sqlfluff_vs_sqlfmt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12irh9h/sql_formatting_sqlfluff_vs_sqlfmt/", "subreddit_subscribers": 98037, "created_utc": 1681235209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious how everyone is feeling.\n\n[View Poll](https://www.reddit.com/poll/12ir3f6)", "author_fullname": "t2_rdm9w1f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How burnt out are you? (Non Students)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12ir3f6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681234429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious how everyone is feeling.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/12ir3f6\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ir3f6", "is_robot_indexable": true, "report_reasons": null, "author": "keeney_arcadia", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1681493629835, "options": [{"text": "I love my job!", "id": "22511488"}, {"text": "It comes in waves", "id": "22511489"}, {"text": "I'm regularly stressed", "id": "22511490"}, {"text": "I loathe going to work", "id": "22511491"}, {"text": "I'm buried in work and see no light at the end of the tunnel", "id": "22511492"}, {"text": "It's just a job, I put my 8 hours in and dip", "id": "22511493"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 58, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ir3f6/how_burnt_out_are_you_non_students/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/12ir3f6/how_burnt_out_are_you_non_students/", "subreddit_subscribers": 98037, "created_utc": 1681234429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I am building a glue job that writes in iceberg tables and I am running some memory issues when I try to do a full historical load. Does an approach like splitting the source data per month and iterate over the chunks make sense in pyspark or is it completely off? If it makes sense anything that I should keep in mind (caching/transactions etc)", "author_fullname": "t2_174pk4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Split source data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12imxfe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681225969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I am building a glue job that writes in iceberg tables and I am running some memory issues when I try to do a full historical load. Does an approach like splitting the source data per month and iterate over the chunks make sense in pyspark or is it completely off? If it makes sense anything that I should keep in mind (caching/transactions etc)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12imxfe", "is_robot_indexable": true, "report_reasons": null, "author": "Avlio27", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12imxfe/split_source_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12imxfe/split_source_data/", "subreddit_subscribers": 98037, "created_utc": 1681225969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First if all it is a legit program by MIT? As I've seen many scams regarding online courses. Second, I am a business management graduate walking into a business analytics master, will it help if I do the MIT course before I begin my course in September?", "author_fullname": "t2_a4bk8wks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MIT Professional Education's Applied Data Science Program worth?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12imwi2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681225923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First if all it is a legit program by MIT? As I&amp;#39;ve seen many scams regarding online courses. Second, I am a business management graduate walking into a business analytics master, will it help if I do the MIT course before I begin my course in September?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12imwi2", "is_robot_indexable": true, "report_reasons": null, "author": "Jamesgeorge96", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12imwi2/mit_professional_educations_applied_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12imwi2/mit_professional_educations_applied_data_science/", "subreddit_subscribers": 98037, "created_utc": 1681225923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In this blog one of our engineers at Coiled shares some views that they\u2019ve found useful when digging into our costs for running data-science workloads on EC2 instances. \n\n[https://medium.com/coiled-hq/aws-cost-explorer-tips-and-tricks-496d0d7c47f3](https://medium.com/coiled-hq/aws-cost-explorer-tips-and-tricks-496d0d7c47f3)", "author_fullname": "t2_w7crvjmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Cost Explorer Tips and Tricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12imppa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681225563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In this blog one of our engineers at Coiled shares some views that they\u2019ve found useful when digging into our costs for running data-science workloads on EC2 instances. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/coiled-hq/aws-cost-explorer-tips-and-tricks-496d0d7c47f3\"&gt;https://medium.com/coiled-hq/aws-cost-explorer-tips-and-tricks-496d0d7c47f3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?auto=webp&amp;v=enabled&amp;s=376205117e289a15fca45bb488f4cc97972b448d", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8f9bfc25260063d87ea6c0718c0be12ac131418", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35c471bca895018de46bb3bbf59c940767a5c469", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02d1a379840e344caf74472d22bf10a48fc62999", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a9e24f05b112454ef102b4024dc5c9ec910a95d", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=483c0850c69c787275da78c86f011f8fca2bda45", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=023869729d1cdc861a7101ac192650cecb802880", "width": 1080, "height": 607}], "variants": {}, "id": "vuThvwZ6-8NSiwargOfiF6vUrslGkZ64Tg1ArqcUXOU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12imppa", "is_robot_indexable": true, "report_reasons": null, "author": "dask-jeeves", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12imppa/aws_cost_explorer_tips_and_tricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12imppa/aws_cost_explorer_tips_and_tricks/", "subreddit_subscribers": 98037, "created_utc": 1681225563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It's been 3 months since I started working at a started, as a Junior Data Engineer. Currently, I am in the final year of CIS Undergraduate program.  The boss wants me to attempt the GC Prof. DE exam and is giving me one month for preparation. Is one month enough time? \nThe company will bear all the expenses. Its certainly a good opportunity to get an industry-recognised credential, but I am worried whether I will be able to pull this off. \nHave worked on BigQuery, proficient with python and SQL, sound knowledge of crucial DS/ DE concepts(foundational and advanced). Never used DataFlow or Dataproc, though.", "author_fullname": "t2_eo907yrs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Cloud Prof. Data Engineer certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ikdue", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681220744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s been 3 months since I started working at a started, as a Junior Data Engineer. Currently, I am in the final year of CIS Undergraduate program.  The boss wants me to attempt the GC Prof. DE exam and is giving me one month for preparation. Is one month enough time? \nThe company will bear all the expenses. Its certainly a good opportunity to get an industry-recognised credential, but I am worried whether I will be able to pull this off. \nHave worked on BigQuery, proficient with python and SQL, sound knowledge of crucial DS/ DE concepts(foundational and advanced). Never used DataFlow or Dataproc, though.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12ikdue", "is_robot_indexable": true, "report_reasons": null, "author": "avg_ali", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ikdue/google_cloud_prof_data_engineer_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ikdue/google_cloud_prof_data_engineer_certification/", "subreddit_subscribers": 98037, "created_utc": 1681220744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7idw1yfm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The database inside out with event streams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 61, "top_awarded_type": null, "hide_score": false, "name": "t3_12ih4dp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b-6fjQm3Jj02KsbW6pCoFxI7xmg1wQorUJ0tT_uF0wM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681213375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@hugo.oliveira.rocha/the-database-inside-out-with-event-streams-86d4a54192eb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FK2aKV_Zmm73XT_WBi7YAIU3ZvECCLmfmj_94ivkAPE.jpg?auto=webp&amp;v=enabled&amp;s=e08d1b7c1918c19adb4f232f59c8b09c12447f7e", "width": 675, "height": 295}, "resolutions": [{"url": "https://external-preview.redd.it/FK2aKV_Zmm73XT_WBi7YAIU3ZvECCLmfmj_94ivkAPE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=439e1fdf2dfa6e664df9b1d530e5ee3e3f69daf6", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/FK2aKV_Zmm73XT_WBi7YAIU3ZvECCLmfmj_94ivkAPE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d127b0df7284249c7496901a227819ab91d9d14e", "width": 216, "height": 94}, {"url": "https://external-preview.redd.it/FK2aKV_Zmm73XT_WBi7YAIU3ZvECCLmfmj_94ivkAPE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e83383852aeae4e29f66cd0177a00b25f7013c3b", "width": 320, "height": 139}, {"url": "https://external-preview.redd.it/FK2aKV_Zmm73XT_WBi7YAIU3ZvECCLmfmj_94ivkAPE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d925b3c797747156f3e1761c2dbd2b7a9b901f21", "width": 640, "height": 279}], "variants": {}, "id": "4WI2vDdx00P6JZuRulbSxSPr0L92GguFn-TKiPFusZE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12ih4dp", "is_robot_indexable": true, "report_reasons": null, "author": "-segmentationfault-", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ih4dp/the_database_inside_out_with_event_streams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@hugo.oliveira.rocha/the-database-inside-out-with-event-streams-86d4a54192eb", "subreddit_subscribers": 98037, "created_utc": 1681213375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Morning.\n\nI would like your advice. I work on Azure Sql.\n\nWe have 3 environments (Dev, Test and Prod) Each environment has a specific tenant.\n\nEvery month, I would like to copy the database from Production to the Test environment.\n\nWhat solution do you recommend to perform this task?\n\nRegards", "author_fullname": "t2_j68sac68", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synchronize Azure Production Db to Test Db", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ifh4c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681208873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Morning.&lt;/p&gt;\n\n&lt;p&gt;I would like your advice. I work on Azure Sql.&lt;/p&gt;\n\n&lt;p&gt;We have 3 environments (Dev, Test and Prod) Each environment has a specific tenant.&lt;/p&gt;\n\n&lt;p&gt;Every month, I would like to copy the database from Production to the Test environment.&lt;/p&gt;\n\n&lt;p&gt;What solution do you recommend to perform this task?&lt;/p&gt;\n\n&lt;p&gt;Regards&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ifh4c", "is_robot_indexable": true, "report_reasons": null, "author": "Playful-Sprinkles-27", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ifh4c/synchronize_azure_production_db_to_test_db/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ifh4c/synchronize_azure_production_db_to_test_db/", "subreddit_subscribers": 98037, "created_utc": 1681208873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nWe have a pipeline that's repsonsible for populating a DW on GCP. I am trying to find a way to create a log system that's readable so we know when each step starts and finishes. \n\nRight now we recreate a dataproc cluster on GCP everyday and submit spark jobs like that and save the logs in temp buckets by cluster id and job id. Problem with that is that it's not readable easily and helps you only if you know the specifics, otherwise you have to browse through many files. \n\nIf I am just trying to achieve a high level log system that tells me when something started, when it ended, which are the cluster and job ids used during that step, how would you approach it? \n\nI was thinking to just get the info from python process on when it submited spark jobs? Or have a file on gcp where I append the necessary information? Do these solution seem okay or is there an easy / good way of doing this? \n\nAny kind input is appreciated", "author_fullname": "t2_dcv9v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Logging spark jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12idu7y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681203764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;We have a pipeline that&amp;#39;s repsonsible for populating a DW on GCP. I am trying to find a way to create a log system that&amp;#39;s readable so we know when each step starts and finishes. &lt;/p&gt;\n\n&lt;p&gt;Right now we recreate a dataproc cluster on GCP everyday and submit spark jobs like that and save the logs in temp buckets by cluster id and job id. Problem with that is that it&amp;#39;s not readable easily and helps you only if you know the specifics, otherwise you have to browse through many files. &lt;/p&gt;\n\n&lt;p&gt;If I am just trying to achieve a high level log system that tells me when something started, when it ended, which are the cluster and job ids used during that step, how would you approach it? &lt;/p&gt;\n\n&lt;p&gt;I was thinking to just get the info from python process on when it submited spark jobs? Or have a file on gcp where I append the necessary information? Do these solution seem okay or is there an easy / good way of doing this? &lt;/p&gt;\n\n&lt;p&gt;Any kind input is appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12idu7y", "is_robot_indexable": true, "report_reasons": null, "author": "Szemmoz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12idu7y/logging_spark_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12idu7y/logging_spark_jobs/", "subreddit_subscribers": 98037, "created_utc": 1681203764.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}