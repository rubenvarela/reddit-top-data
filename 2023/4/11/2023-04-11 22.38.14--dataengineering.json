{"kind": "Listing", "data": {"after": "t3_12imppa", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have experience in DE for about 7 years and currently promoted to Data Architect role. I understand my responsibilities which include laying out data models, architecture diagrams, suggesting the best tools for a particular scenario. I have worked majorly in Azure and Databricks .\n\nPlease suggest the learning path / thinking methodology for me to be better at my current role.", "author_fullname": "t2_2xxs9nne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have been recently promoted to Data Architect Role. I need help on learning resources/pointers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12iaaka", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681199121.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681192407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have experience in DE for about 7 years and currently promoted to Data Architect role. I understand my responsibilities which include laying out data models, architecture diagrams, suggesting the best tools for a particular scenario. I have worked majorly in Azure and Databricks .&lt;/p&gt;\n\n&lt;p&gt;Please suggest the learning path / thinking methodology for me to be better at my current role.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12iaaka", "is_robot_indexable": true, "report_reasons": null, "author": "inglocines", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12iaaka/i_have_been_recently_promoted_to_data_architect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12iaaka/i_have_been_recently_promoted_to_data_architect/", "subreddit_subscribers": 98086, "created_utc": 1681192407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, college student here, I\u2019m currently interested in working in the Data space. One job that seems interesting to me is ETL Developer, however, many are telling me that ETL Developer is an outdated job, and that ETL development is generally in the domain of the data engineer nowadays. But on the other hand, there are others who tell me that most data engineers hate doing ETL, and that a lot of companies still have so much ETL work to do that they hire specialized ETL Devs on top of data engineers. I\u2019m not sure if I\u2019m interested in the entirety of data engineering. I\u2019ve only shown interest in pipeline development and data \nmovement so far, so I\u2019m a bit lost as to what career direction I should take. Do you guys think ETL developer is still very much a legit role that is worth aiming for? Or should I switch gears to data engineering jobs?", "author_fullname": "t2_c2u69kfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is ETL Developer still a legit and in-demand career? Or is it just housed under Data Engineering now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12i0nh1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681170057.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681169608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, college student here, I\u2019m currently interested in working in the Data space. One job that seems interesting to me is ETL Developer, however, many are telling me that ETL Developer is an outdated job, and that ETL development is generally in the domain of the data engineer nowadays. But on the other hand, there are others who tell me that most data engineers hate doing ETL, and that a lot of companies still have so much ETL work to do that they hire specialized ETL Devs on top of data engineers. I\u2019m not sure if I\u2019m interested in the entirety of data engineering. I\u2019ve only shown interest in pipeline development and data \nmovement so far, so I\u2019m a bit lost as to what career direction I should take. Do you guys think ETL developer is still very much a legit role that is worth aiming for? Or should I switch gears to data engineering jobs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12i0nh1", "is_robot_indexable": true, "report_reasons": null, "author": "IllMorning741", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12i0nh1/is_etl_developer_still_a_legit_and_indemand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12i0nh1/is_etl_developer_still_a_legit_and_indemand/", "subreddit_subscribers": 98086, "created_utc": 1681169608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_975og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to use dbt source freshness tests to detect stale data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_12inq6z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/noCUQVwfgAxpdD300vlHP-w_Vk1xBMS_Ttf-9Ny8RNw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681227499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datafold.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.datafold.com/blog/dbt-source-freshness", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?auto=webp&amp;v=enabled&amp;s=4a2e7bf440d31e813fbfed118f2002466730cdef", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd999aa101b6b02ad7b9401b6512c65d55b7d934", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e543df1eb9d1e1b52ec25a320c6494e1e6eb4ba", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c8ac3945ef71a946231120973bab1279083550a", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a64035e5ef1f38e6d55725ff6d4e337d9d60bee", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32af2cff24ddc953b8c0d4f53d80d44fd01cd7ab", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/WxpGs6QZU6CXiLkU96qO8RJjw4_4kfZ7qRcgOwFtsso.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db2d5a8b7088d3f01673eab7d94b8ca156d2b999", "width": 1080, "height": 607}], "variants": {}, "id": "Hk_DWgM9iMOzRYbc08qVJTco8z-aNttuxoSZwBKbciQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12inq6z", "is_robot_indexable": true, "report_reasons": null, "author": "arimbr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12inq6z/how_to_use_dbt_source_freshness_tests_to_detect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.datafold.com/blog/dbt-source-freshness", "subreddit_subscribers": 98086, "created_utc": 1681227499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've made a simple ETL project orchestrated by Airflow. The process is basically download &gt;&gt; transform &gt;&gt; load into Postgres.\n\n    with DAG(...):\n        task1 = PythonOperator(\n            task_id = \"DownloadData\",\n            python_callable = download_task\n        \u00a0 \u00a0 )\n        task2 = PythonOperator(\n            task_id = \"TransformData\",\n            python_callable = transform_task\n        \u00a0 \u00a0 )\n        ...\n        task1 &gt;&gt; task2 &gt;&gt; task3\n\nFirst task downloads more than 10k text-based files containing weather data. Its speed is okay (4 minutes w/ multithreading).\n\nThe problem is the second task. I used pandas to transform text-based files into clean data in .tsv format.\n\n    def _read_file(filename):\n        with open(filename, \"r\", encoding=\"UTF-8\") as f:\n            for line in f:           \n                line_content = [float(i) for i in line.split()]\n                yield {\n                    \"station_id\": filename,\n                    \"date\": f\"line_content[0]-line_content[1]-line_content[2]\"\n                    \"air_temperature\": line_content[4],\n                    ...\n                }\n\nI use `_read_file()` to read the content of the text-based file and make it a pandas dataframe to transform it.\n\n[raw text-based file \\(weather hourly data\\)](https://preview.redd.it/vritpkald8ta1.png?width=867&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c0bd6140837ad95c0bb1e21554326086803ea5c2)\n\n&amp;#x200B;\n\n    def transform(filename):        \n        # Create a dataframe out of file data\n        file_data = _read_file(filename)\n        df = pd.DataFrame(file_data)\n    \n        # Get the summarization of data (min, mean, max)\n        df = df.groupby(['station_id', 'date']).agg(\n            air_temperature_avg = ('air_temperature', 'mean'),\n            air_temperature_min = ('air_temperature', 'min'),\n            air_temperature_max = ('air_temperature', 'max'),\n            ...\n        )\n    \n        df.to_csv(f\"{filename}.tsv\", sep = \"\\t\")\n\n&amp;#x200B;\n\n[transformed data \\(daily summary: mean, min, and max\\)](https://preview.redd.it/06xqm23od8ta1.png?width=890&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1748787299abfd1424251c2c3aaa1c2fae69a4b0)\n\nThen i use the transform function in transform\\_task to summarize 10k+ raw text-based files one by one\n\n    def transform_task():\n        for filename in glob.glob(\"raw_directory/*\"): \u00a0 \u00a0 \u00a0 \u00a0 \n            transform(filename)\n\n&amp;#x200B;\n\nNote: I'm doing this locally in my laptop, not in cloud\n\nTransformation of each file is quick, about 0.15-0.20 seconds each. However, there are more than 10k files to transform so it takes about 40 minutes to accomplish the task. What do you think can be done to make this process faster?  Thanks in advance!", "author_fullname": "t2_3j0efkbj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[ETL Project] Transformation with Python pandas too slow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vritpkald8ta1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 53, "x": 108, "u": "https://preview.redd.it/vritpkald8ta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d107e03c8260dff820045e7e6b041408e268535"}, {"y": 107, "x": 216, "u": "https://preview.redd.it/vritpkald8ta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=305ecb53d459cda96dc5281d32a37c1d34e2191d"}, {"y": 159, "x": 320, "u": "https://preview.redd.it/vritpkald8ta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7efb5852a4692e1ef85dbbd54b5e6c9f1e7fd6c9"}, {"y": 318, "x": 640, "u": "https://preview.redd.it/vritpkald8ta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c4f60aaf2291325653e15b89ac6d89ad0170331"}], "s": {"y": 432, "x": 867, "u": "https://preview.redd.it/vritpkald8ta1.png?width=867&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c0bd6140837ad95c0bb1e21554326086803ea5c2"}, "id": "vritpkald8ta1"}, "06xqm23od8ta1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 34, "x": 108, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93511b5de9624e32b16b8c2cffa927a77321a831"}, {"y": 68, "x": 216, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=828c0732137bab2a055716c074977acf9fb5a5da"}, {"y": 101, "x": 320, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=782d8bd64676f91b572919eafda1b15c4c9eb021"}, {"y": 202, "x": 640, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=61f15eef99db8331ce810c947905e612bba073c8"}], "s": {"y": 281, "x": 890, "u": "https://preview.redd.it/06xqm23od8ta1.png?width=890&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1748787299abfd1424251c2c3aaa1c2fae69a4b0"}, "id": "06xqm23od8ta1"}}, "name": "t3_12ie2fq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wf4RNpLcW-lz-jrhuDtUGh4NumBHQWJQDlF-mGfc-uA.jpg", "edited": 1681211557.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681204509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve made a simple ETL project orchestrated by Airflow. The process is basically download &amp;gt;&amp;gt; transform &amp;gt;&amp;gt; load into Postgres.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;with DAG(...):\n    task1 = PythonOperator(\n        task_id = &amp;quot;DownloadData&amp;quot;,\n        python_callable = download_task\n    \u00a0 \u00a0 )\n    task2 = PythonOperator(\n        task_id = &amp;quot;TransformData&amp;quot;,\n        python_callable = transform_task\n    \u00a0 \u00a0 )\n    ...\n    task1 &amp;gt;&amp;gt; task2 &amp;gt;&amp;gt; task3\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;First task downloads more than 10k text-based files containing weather data. Its speed is okay (4 minutes w/ multithreading).&lt;/p&gt;\n\n&lt;p&gt;The problem is the second task. I used pandas to transform text-based files into clean data in .tsv format.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def _read_file(filename):\n    with open(filename, &amp;quot;r&amp;quot;, encoding=&amp;quot;UTF-8&amp;quot;) as f:\n        for line in f:           \n            line_content = [float(i) for i in line.split()]\n            yield {\n                &amp;quot;station_id&amp;quot;: filename,\n                &amp;quot;date&amp;quot;: f&amp;quot;line_content[0]-line_content[1]-line_content[2]&amp;quot;\n                &amp;quot;air_temperature&amp;quot;: line_content[4],\n                ...\n            }\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I use &lt;code&gt;_read_file()&lt;/code&gt; to read the content of the text-based file and make it a pandas dataframe to transform it.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vritpkald8ta1.png?width=867&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c0bd6140837ad95c0bb1e21554326086803ea5c2\"&gt;raw text-based file (weather hourly data)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def transform(filename):        \n    # Create a dataframe out of file data\n    file_data = _read_file(filename)\n    df = pd.DataFrame(file_data)\n\n    # Get the summarization of data (min, mean, max)\n    df = df.groupby([&amp;#39;station_id&amp;#39;, &amp;#39;date&amp;#39;]).agg(\n        air_temperature_avg = (&amp;#39;air_temperature&amp;#39;, &amp;#39;mean&amp;#39;),\n        air_temperature_min = (&amp;#39;air_temperature&amp;#39;, &amp;#39;min&amp;#39;),\n        air_temperature_max = (&amp;#39;air_temperature&amp;#39;, &amp;#39;max&amp;#39;),\n        ...\n    )\n\n    df.to_csv(f&amp;quot;{filename}.tsv&amp;quot;, sep = &amp;quot;\\t&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/06xqm23od8ta1.png?width=890&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1748787299abfd1424251c2c3aaa1c2fae69a4b0\"&gt;transformed data (daily summary: mean, min, and max)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Then i use the transform function in transform_task to summarize 10k+ raw text-based files one by one&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def transform_task():\n    for filename in glob.glob(&amp;quot;raw_directory/*&amp;quot;): \u00a0 \u00a0 \u00a0 \u00a0 \n        transform(filename)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Note: I&amp;#39;m doing this locally in my laptop, not in cloud&lt;/p&gt;\n\n&lt;p&gt;Transformation of each file is quick, about 0.15-0.20 seconds each. However, there are more than 10k files to transform so it takes about 40 minutes to accomplish the task. What do you think can be done to make this process faster?  Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ie2fq", "is_robot_indexable": true, "report_reasons": null, "author": "Pervert_Spongebob", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ie2fq/etl_project_transformation_with_python_pandas_too/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ie2fq/etl_project_transformation_with_python_pandas_too/", "subreddit_subscribers": 98086, "created_utc": 1681204509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am a young graduate in data science and I am currently looking for a data engineering job. I had a health problem after graduation so I could not apply to jobs immediately. Thus I have a gap of a few months and I am currently having trouble finding a job. I suspect employers are reluctant to pick me because of this gap. I would like to have a more attractive profile as a data engineer. What are some tips to have better chances of landing a job in Data Engineering and which story I could tell about the gap to avoid mentioning health problems?\n\nThank you,\n\nBest regards.", "author_fullname": "t2_adoxjqxf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some tips to get a data engineering job with a gap of a few months.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12i3iqy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681175989.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am a young graduate in data science and I am currently looking for a data engineering job. I had a health problem after graduation so I could not apply to jobs immediately. Thus I have a gap of a few months and I am currently having trouble finding a job. I suspect employers are reluctant to pick me because of this gap. I would like to have a more attractive profile as a data engineer. What are some tips to have better chances of landing a job in Data Engineering and which story I could tell about the gap to avoid mentioning health problems?&lt;/p&gt;\n\n&lt;p&gt;Thank you,&lt;/p&gt;\n\n&lt;p&gt;Best regards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12i3iqy", "is_robot_indexable": true, "report_reasons": null, "author": "Educational-Turn-419", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12i3iqy/what_are_some_tips_to_get_a_data_engineering_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12i3iqy/what_are_some_tips_to_get_a_data_engineering_job/", "subreddit_subscribers": 98086, "created_utc": 1681175989.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, I recently moved from mobile engineering to data engineering. I'm seeing no documentation about how to structure SQL code (e.g. MVC). Are there any articles or projects working on this?", "author_fullname": "t2_xl0mt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model View Controller (MVC) for DAGs and or models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hz7sb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681166677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, I recently moved from mobile engineering to data engineering. I&amp;#39;m seeing no documentation about how to structure SQL code (e.g. MVC). Are there any articles or projects working on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12hz7sb", "is_robot_indexable": true, "report_reasons": null, "author": "tokyopanda1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12hz7sb/model_view_controller_mvc_for_dags_and_or_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12hz7sb/model_view_controller_mvc_for_dags_and_or_models/", "subreddit_subscribers": 98086, "created_utc": 1681166677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Project with Airflow, DuckDB, MinIO, Streamlit and the AstroSDK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_12io51t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ir3H1xOoIb8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow Quickstart Project with DuckDB, MinIO and Streamlit\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Airflow Quickstart Project with DuckDB, MinIO and Streamlit", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ir3H1xOoIb8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow Quickstart Project with DuckDB, MinIO and Streamlit\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ir3H1xOoIb8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ir3H1xOoIb8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow Quickstart Project with DuckDB, MinIO and Streamlit\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/12io51t", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/C1naVPMCf-NVQ2t-oeXHMl4fPtikScSkrLYr21lQT7E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681228317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/ir3H1xOoIb8", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ncIe23vBi-MwJHABiGjw0JSN8zu2i_6GCRasr2wttP4.jpg?auto=webp&amp;v=enabled&amp;s=6a0b7647651ce6f2c4af2fce28200cdcfc7c73f3", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/ncIe23vBi-MwJHABiGjw0JSN8zu2i_6GCRasr2wttP4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b290915d178f1ee75ceff5f7e053dc7566fd4c3a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/ncIe23vBi-MwJHABiGjw0JSN8zu2i_6GCRasr2wttP4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=138ae22da4e6f615e245d1293fccfb34a57665cf", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/ncIe23vBi-MwJHABiGjw0JSN8zu2i_6GCRasr2wttP4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b8bf888802f94138883b0e352a8feb2a5456274", "width": 320, "height": 240}], "variants": {}, "id": "JA9sMYD-6aEO4BCBc0r4btyF20uJ4WxAJhbu-4uefp8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12io51t", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12io51t/data_engineering_project_with_airflow_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/ir3H1xOoIb8", "subreddit_subscribers": 98086, "created_utc": 1681228317.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Airflow Quickstart Project with DuckDB, MinIO and Streamlit", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/ir3H1xOoIb8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow Quickstart Project with DuckDB, MinIO and Streamlit\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/ir3H1xOoIb8/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \nAbout me: I joined the corporate world as an Data engineer just after graduating in mid 2021 (but my current work revolves around Data analytics, SQL and Python). Total exp: 1.5yrs\n\nI am currently in a dilemma: whether I should continue as a Data Engineer by expanding my skills (learning Spark etc) or switch to SDE roles (safe evergreen option).\n\nI have few concerns about DE role which is kinda stopping me from fully deep diving into it. \n\n1. Are data engineers considered 2nd class employees in a company? I have read that DE is a role that supports business functions and Data scientist and are generally not profit generating employees (away from business) hence their efforts can sometimes go unnoticed.\n\n2. How does day in a life looks like? Work life balance and work environment?\n\n3. Growth prospects: Can a DE transition/grow into leadership positions?\n\n\nLooking for some guidance. Thanks in advance!", "author_fullname": "t2_75txeq7v4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is DE a good role in terms of work and work life balance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12idd74", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681204269.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681202190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, \nAbout me: I joined the corporate world as an Data engineer just after graduating in mid 2021 (but my current work revolves around Data analytics, SQL and Python). Total exp: 1.5yrs&lt;/p&gt;\n\n&lt;p&gt;I am currently in a dilemma: whether I should continue as a Data Engineer by expanding my skills (learning Spark etc) or switch to SDE roles (safe evergreen option).&lt;/p&gt;\n\n&lt;p&gt;I have few concerns about DE role which is kinda stopping me from fully deep diving into it. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Are data engineers considered 2nd class employees in a company? I have read that DE is a role that supports business functions and Data scientist and are generally not profit generating employees (away from business) hence their efforts can sometimes go unnoticed.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How does day in a life looks like? Work life balance and work environment?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Growth prospects: Can a DE transition/grow into leadership positions?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Looking for some guidance. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12idd74", "is_robot_indexable": true, "report_reasons": null, "author": "Skrirraa", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12idd74/is_de_a_good_role_in_terms_of_work_and_work_life/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12idd74/is_de_a_good_role_in_terms_of_work_and_work_life/", "subreddit_subscribers": 98086, "created_utc": 1681202190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team currently have our data sitting in a delta lake in an Azure storage account. We use Databricks on Azure to ingest and process data.\n\nWe have gotten to the stage where we would like to create an API to act as an interface to output data to web applications run by other teams as we don't want to tie their applications directly to the use of delta. We want them to be able to pass in parameters, we would then do some final steps of processing using the parameters provided, and then we want to send the output data directly back to the calling application. The final output of data will be a time-series and we expect that in the future the time-series could have in excess of one million items. The tables that will be queried are fairly large and growing so we want to minimise the compute time of the calculations by using Spark or some other method that is as fast. Ideally, we would want to do this without a wrapper layer that we would need to host external to Databricks, at least for now.\n\nWe realise that our setup is fairly similar to what other teams seem to have and were wondering how anyone else has managed to achieve what we are trying to.", "author_fullname": "t2_n937n0g6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Lake/Databricks egress via API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12iodei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681228788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team currently have our data sitting in a delta lake in an Azure storage account. We use Databricks on Azure to ingest and process data.&lt;/p&gt;\n\n&lt;p&gt;We have gotten to the stage where we would like to create an API to act as an interface to output data to web applications run by other teams as we don&amp;#39;t want to tie their applications directly to the use of delta. We want them to be able to pass in parameters, we would then do some final steps of processing using the parameters provided, and then we want to send the output data directly back to the calling application. The final output of data will be a time-series and we expect that in the future the time-series could have in excess of one million items. The tables that will be queried are fairly large and growing so we want to minimise the compute time of the calculations by using Spark or some other method that is as fast. Ideally, we would want to do this without a wrapper layer that we would need to host external to Databricks, at least for now.&lt;/p&gt;\n\n&lt;p&gt;We realise that our setup is fairly similar to what other teams seem to have and were wondering how anyone else has managed to achieve what we are trying to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12iodei", "is_robot_indexable": true, "report_reasons": null, "author": "piri9825", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12iodei/delta_lakedatabricks_egress_via_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12iodei/delta_lakedatabricks_egress_via_api/", "subreddit_subscribers": 98086, "created_utc": 1681228788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello DE friends.\n\nMy current company uses Apache Airflow for scheduling, and we are quite happy with it. But giving technically gifted PMs the ability to make simple DAGs from a visual interface would be amazing.\n\nFor this we love the N8N interface. \n\nHowever the native N8N scheduler and workflows are too lacking and overcomplicated to use for our workflows.\n\nHence my question.\n\nHas anyone connected N8N or any no-code solution to Airflow? \n\nLet me be specific. We aren't looking to trigger a DAG from N8N. We'd like to build it there, task by task, and then have the resulting DAG deployed on Airflow.\n\nIf you have any hints, ideas or projects that you think are doing this, I'd be super interested.\n\nThanks for your help \ud83d\ude4f", "author_fullname": "t2_85uwiihz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using no-code to create simple Airflow Dags", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12icsvl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681200327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello DE friends.&lt;/p&gt;\n\n&lt;p&gt;My current company uses Apache Airflow for scheduling, and we are quite happy with it. But giving technically gifted PMs the ability to make simple DAGs from a visual interface would be amazing.&lt;/p&gt;\n\n&lt;p&gt;For this we love the N8N interface. &lt;/p&gt;\n\n&lt;p&gt;However the native N8N scheduler and workflows are too lacking and overcomplicated to use for our workflows.&lt;/p&gt;\n\n&lt;p&gt;Hence my question.&lt;/p&gt;\n\n&lt;p&gt;Has anyone connected N8N or any no-code solution to Airflow? &lt;/p&gt;\n\n&lt;p&gt;Let me be specific. We aren&amp;#39;t looking to trigger a DAG from N8N. We&amp;#39;d like to build it there, task by task, and then have the resulting DAG deployed on Airflow.&lt;/p&gt;\n\n&lt;p&gt;If you have any hints, ideas or projects that you think are doing this, I&amp;#39;d be super interested.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your help \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12icsvl", "is_robot_indexable": true, "report_reasons": null, "author": "GeekyTricky", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12icsvl/using_nocode_to_create_simple_airflow_dags/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12icsvl/using_nocode_to_create_simple_airflow_dags/", "subreddit_subscribers": 98086, "created_utc": 1681200327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all\n\nI'm making my way through the data engineering course on Databricks Academy and it's alright but I feel like every lesson is just someone reading from a notebook and executing SQL/ Python in the notebook. Feels like there's a lot of context missing (e.g there's course setup code but we never see this code).\n\nIs there any alternatives you prefer when learning Databricks?", "author_fullname": "t2_56o0g58i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative to Databricks academy for learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ivqk8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681243414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m making my way through the data engineering course on Databricks Academy and it&amp;#39;s alright but I feel like every lesson is just someone reading from a notebook and executing SQL/ Python in the notebook. Feels like there&amp;#39;s a lot of context missing (e.g there&amp;#39;s course setup code but we never see this code).&lt;/p&gt;\n\n&lt;p&gt;Is there any alternatives you prefer when learning Databricks?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ivqk8", "is_robot_indexable": true, "report_reasons": null, "author": "IG-55", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ivqk8/alternative_to_databricks_academy_for_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ivqk8/alternative_to_databricks_academy_for_learning/", "subreddit_subscribers": 98086, "created_utc": 1681243414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've seen a few people mention trino + data lake. I see in the trino docs that it's designed to query different sources directly, ie without prior etl/elt. \n\nSo why bother with a data lake? \n\nI can imagine it's to make reads faster, for better organization, and to avoid noisy neighbor type issues on source systems. \n\nAnyone have ideas on those or other reasons?", "author_fullname": "t2_ut20i32q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why use trino on a data lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ip77n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681230527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen a few people mention trino + data lake. I see in the trino docs that it&amp;#39;s designed to query different sources directly, ie without prior etl/elt. &lt;/p&gt;\n\n&lt;p&gt;So why bother with a data lake? &lt;/p&gt;\n\n&lt;p&gt;I can imagine it&amp;#39;s to make reads faster, for better organization, and to avoid noisy neighbor type issues on source systems. &lt;/p&gt;\n\n&lt;p&gt;Anyone have ideas on those or other reasons?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ip77n", "is_robot_indexable": true, "report_reasons": null, "author": "alex_o_h", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ip77n/why_use_trino_on_a_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ip77n/why_use_trino_on_a_data_lake/", "subreddit_subscribers": 98086, "created_utc": 1681230527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9wrfjdsj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Lakehouse by the sea: Migrating Seafowl storage layer to delta-rs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_12ivoi5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/rESLgC8lkPhmLkFb5qvPHsEMV5HAbJcWWjzDSMWoV_4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681243302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "splitgraph.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.splitgraph.com/blog/seafowl-delta-storage-layer", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?auto=webp&amp;v=enabled&amp;s=0e71ea909937e503f7c833b044201cba0a51063c", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65db8ae9f1540d295f00950b12174d7be3508625", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef63e238179153a4a97e6b2aeb3be247c0fab18a", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=114619e03e3054a5fa0cae59378077ea601c4948", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b01ec1e97553be30eeef904cd70222598fa4dbac", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b850d0b1d23c39f8132a7f3d26e2ae978ddea7b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/cbi3Dc--2pOvkY1v9YYEvc-dHCC71jiiWQNeScaoxgA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=726ad6e29157a5a4b019406464a60331cf91597c", "width": 1080, "height": 567}], "variants": {}, "id": "kwl5UPry6AuAlyMdIEIWUnQ47W6ryiRkRihcsErskV4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12ivoi5", "is_robot_indexable": true, "report_reasons": null, "author": "gruuya", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ivoi5/a_lakehouse_by_the_sea_migrating_seafowl_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.splitgraph.com/blog/seafowl-delta-storage-layer", "subreddit_subscribers": 98086, "created_utc": 1681243302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, I have a question, probably very strange one, but I have a task on this which is killing me.\nThe problem is that I have a lot of JSON files that need to be processed. The files have different structure schema, but the requester wants to have the data flattened in a table with a very general structure, to cover all formats. The data will be used then for reporting.\n Is there any possible way to do this? \nI would appreciate any suggestion on how the final table may look like and how to flatten the data. The implementation should be done in Java, but I would not focus now on this.\n Thank you very much!", "author_fullname": "t2_8ouamdf5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Generic JSON schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12irysl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681236123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I have a question, probably very strange one, but I have a task on this which is killing me.\nThe problem is that I have a lot of JSON files that need to be processed. The files have different structure schema, but the requester wants to have the data flattened in a table with a very general structure, to cover all formats. The data will be used then for reporting.\n Is there any possible way to do this? \nI would appreciate any suggestion on how the final table may look like and how to flatten the data. The implementation should be done in Java, but I would not focus now on this.\n Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12irysl", "is_robot_indexable": true, "report_reasons": null, "author": "adaptrix", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12irysl/generic_json_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12irysl/generic_json_schema/", "subreddit_subscribers": 98086, "created_utc": 1681236123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious how everyone is feeling.\n\n[View Poll](https://www.reddit.com/poll/12ir3f6)", "author_fullname": "t2_rdm9w1f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How burnt out are you? (Non Students)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ir3f6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681234429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious how everyone is feeling.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/12ir3f6\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ir3f6", "is_robot_indexable": true, "report_reasons": null, "author": "keeney_arcadia", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1681493629835, "options": [{"text": "I love my job!", "id": "22511488"}, {"text": "It comes in waves", "id": "22511489"}, {"text": "I'm regularly stressed", "id": "22511490"}, {"text": "I loathe going to work", "id": "22511491"}, {"text": "I'm buried in work and see no light at the end of the tunnel", "id": "22511492"}, {"text": "It's just a job, I put my 8 hours in and dip", "id": "22511493"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 408, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ir3f6/how_burnt_out_are_you_non_students/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/12ir3f6/how_burnt_out_are_you_non_students/", "subreddit_subscribers": 98086, "created_utc": 1681234429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It's been 3 months since I started working at a started, as a Junior Data Engineer. Currently, I am in the final year of CIS Undergraduate program.  The boss wants me to attempt the GC Prof. DE exam and is giving me one month for preparation. Is one month enough time? \nThe company will bear all the expenses. Its certainly a good opportunity to get an industry-recognised credential, but I am worried whether I will be able to pull this off. \nHave worked on BigQuery, proficient with python and SQL, sound knowledge of crucial DS/ DE concepts(foundational and advanced). Never used DataFlow or Dataproc, though.", "author_fullname": "t2_eo907yrs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Cloud Prof. Data Engineer certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ikdue", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681220744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s been 3 months since I started working at a started, as a Junior Data Engineer. Currently, I am in the final year of CIS Undergraduate program.  The boss wants me to attempt the GC Prof. DE exam and is giving me one month for preparation. Is one month enough time? \nThe company will bear all the expenses. Its certainly a good opportunity to get an industry-recognised credential, but I am worried whether I will be able to pull this off. \nHave worked on BigQuery, proficient with python and SQL, sound knowledge of crucial DS/ DE concepts(foundational and advanced). Never used DataFlow or Dataproc, though.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12ikdue", "is_robot_indexable": true, "report_reasons": null, "author": "avg_ali", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ikdue/google_cloud_prof_data_engineer_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ikdue/google_cloud_prof_data_engineer_certification/", "subreddit_subscribers": 98086, "created_utc": 1681220744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is an article that I made while looking for a new job opportunity. I hope you like it and feel useful. \ud83d\ude42\n\nhttps://link.medium.com/DlqgDCJaVyb", "author_fullname": "t2_7dy3sswp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Technical Questions for Data Engineer Position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12iz03x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681249832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is an article that I made while looking for a new job opportunity. I hope you like it and feel useful. \ud83d\ude42&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://link.medium.com/DlqgDCJaVyb\"&gt;https://link.medium.com/DlqgDCJaVyb&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/stmCrhIOkvhAnChrOXgM5u_pFO4rIBPulHtME_M6PUY.jpg?auto=webp&amp;v=enabled&amp;s=82b52d66521725fb9753026764f6d42f33631a3b", "width": 654, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/stmCrhIOkvhAnChrOXgM5u_pFO4rIBPulHtME_M6PUY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ad4a26f4c64a03987d74b6b02175833d5116803", "width": 108, "height": 105}, {"url": "https://external-preview.redd.it/stmCrhIOkvhAnChrOXgM5u_pFO4rIBPulHtME_M6PUY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=185c19e79728ccd451688b0f73cff82bd9626d07", "width": 216, "height": 211}, {"url": "https://external-preview.redd.it/stmCrhIOkvhAnChrOXgM5u_pFO4rIBPulHtME_M6PUY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e102f85878f9878c62fcb4388720560e2c5acb2", "width": 320, "height": 313}, {"url": "https://external-preview.redd.it/stmCrhIOkvhAnChrOXgM5u_pFO4rIBPulHtME_M6PUY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9feca868b20dee598b0a0cca632b9a508f934403", "width": 640, "height": 626}], "variants": {}, "id": "gtOGOD6SzSH2tDhEzVVZ7S6sXOQHSGRHz6hspz_seeU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12iz03x", "is_robot_indexable": true, "report_reasons": null, "author": "Asleep-Organization7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12iz03x/technical_questions_for_data_engineer_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12iz03x/technical_questions_for_data_engineer_position/", "subreddit_subscribers": 98086, "created_utc": 1681249832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since each company uses different tools for their environment how do we manage to learn the one's we don't know when applying for a role? How in-depth should I go when learning a new tool since I might not use that tool for too long before having to switch to something new at a different company?", "author_fullname": "t2_76fvluuq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with learning the many changes of tools in this field.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12iyemq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681248637.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since each company uses different tools for their environment how do we manage to learn the one&amp;#39;s we don&amp;#39;t know when applying for a role? How in-depth should I go when learning a new tool since I might not use that tool for too long before having to switch to something new at a different company?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12iyemq", "is_robot_indexable": true, "report_reasons": null, "author": "notGaruda1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12iyemq/how_to_deal_with_learning_the_many_changes_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12iyemq/how_to_deal_with_learning_the_many_changes_of/", "subreddit_subscribers": 98086, "created_utc": 1681248637.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nI am looking to gain as much insight as I can find for an upcoming interview. Please forgive me if this is not the appropriate subreddit for this post.\n\nI am interviewing with an organization that is looking to migrate historical data from AWS Redshift to Databricks. Other tools they have mentioned they will use are dbt and Snowflake. They also mentioned automation as a part of this process.\n\nIn your professional experiences, how is a process like this usually done (from a high-level or low-level or both)? What would you say is important for someone aiding in this process to know technically wise? Could you think of any technical questions you think you'd be asked if you were in my situation (or that you would ask a candidate)?\n\nIf I don't reply to you, please know that I am grateful for any and all advice and suggestions!", "author_fullname": "t2_bevcyk6f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Interview] Advice on interviewing for a role that involves Data Migration and Data Warehouse tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12iy3ig", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681248018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I am looking to gain as much insight as I can find for an upcoming interview. Please forgive me if this is not the appropriate subreddit for this post.&lt;/p&gt;\n\n&lt;p&gt;I am interviewing with an organization that is looking to migrate historical data from AWS Redshift to Databricks. Other tools they have mentioned they will use are dbt and Snowflake. They also mentioned automation as a part of this process.&lt;/p&gt;\n\n&lt;p&gt;In your professional experiences, how is a process like this usually done (from a high-level or low-level or both)? What would you say is important for someone aiding in this process to know technically wise? Could you think of any technical questions you think you&amp;#39;d be asked if you were in my situation (or that you would ask a candidate)?&lt;/p&gt;\n\n&lt;p&gt;If I don&amp;#39;t reply to you, please know that I am grateful for any and all advice and suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12iy3ig", "is_robot_indexable": true, "report_reasons": null, "author": "exceln00bie", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12iy3ig/interview_advice_on_interviewing_for_a_role_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12iy3ig/interview_advice_on_interviewing_for_a_role_that/", "subreddit_subscribers": 98086, "created_utc": 1681248018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The problem: delete a small subset of keys from many large stage files\n\nCurrently the job is written using RDDs and it's processed in a sequential order. \n\nMy idea is to use a glob to read all stage files at the same time. Add input_file_name and perform a left anti join to delete the subset of keys. Obviously broadcasting the keys table. Then if the before and after counts are not the same then write to disk using the path from input_file_name. Each stage file could be around or bigger than a terabyte.\n\nMy concern is that my job will be doing the same work as before but I wanted to know if you guys think there is any performance advantage to processing the deletion of the keys all at once? \n\nOr if anyone has a better idea I'm all ears.", "author_fullname": "t2_1z6shw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on large batch delete", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12itnjn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681239313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The problem: delete a small subset of keys from many large stage files&lt;/p&gt;\n\n&lt;p&gt;Currently the job is written using RDDs and it&amp;#39;s processed in a sequential order. &lt;/p&gt;\n\n&lt;p&gt;My idea is to use a glob to read all stage files at the same time. Add input_file_name and perform a left anti join to delete the subset of keys. Obviously broadcasting the keys table. Then if the before and after counts are not the same then write to disk using the path from input_file_name. Each stage file could be around or bigger than a terabyte.&lt;/p&gt;\n\n&lt;p&gt;My concern is that my job will be doing the same work as before but I wanted to know if you guys think there is any performance advantage to processing the deletion of the keys all at once? &lt;/p&gt;\n\n&lt;p&gt;Or if anyone has a better idea I&amp;#39;m all ears.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12itnjn", "is_robot_indexable": true, "report_reasons": null, "author": "cockoala", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12itnjn/advice_on_large_batch_delete/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12itnjn/advice_on_large_batch_delete/", "subreddit_subscribers": 98086, "created_utc": 1681239313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for some experiences and tips to how to best network and play politics effectively to do the best work possible. I feel DE requires more networking than swe, but curious to hear other\u2019s opinions", "author_fullname": "t2_7jt0qboi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Politics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12isu7q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681237770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for some experiences and tips to how to best network and play politics effectively to do the best work possible. I feel DE requires more networking than swe, but curious to hear other\u2019s opinions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12isu7q", "is_robot_indexable": true, "report_reasons": null, "author": "omscsdatathrow", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12isu7q/data_engineering_politics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12isu7q/data_engineering_politics/", "subreddit_subscribers": 98086, "created_utc": 1681237770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What exactly is the difference between a linter (like sqlfluff) and a formatter (like sqlfmt)? Doesn\u2019t sqlfluff act like a formatter if you run \u201csqlfluff fix\u201d? Besides, are there better SQL formatters available? What are you working with?", "author_fullname": "t2_gzpboep7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL formatting (sqlfluff vs sqlfmt)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12irh9h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681235209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What exactly is the difference between a linter (like sqlfluff) and a formatter (like sqlfmt)? Doesn\u2019t sqlfluff act like a formatter if you run \u201csqlfluff fix\u201d? Besides, are there better SQL formatters available? What are you working with?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12irh9h", "is_robot_indexable": true, "report_reasons": null, "author": "themouthoftruth", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12irh9h/sql_formatting_sqlfluff_vs_sqlfmt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12irh9h/sql_formatting_sqlfluff_vs_sqlfmt/", "subreddit_subscribers": 98086, "created_utc": 1681235209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I am building a glue job that writes in iceberg tables and I am running some memory issues when I try to do a full historical load. Does an approach like splitting the source data per month and iterate over the chunks make sense in pyspark or is it completely off? If it makes sense anything that I should keep in mind (caching/transactions etc)", "author_fullname": "t2_174pk4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Split source data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12imxfe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681225969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I am building a glue job that writes in iceberg tables and I am running some memory issues when I try to do a full historical load. Does an approach like splitting the source data per month and iterate over the chunks make sense in pyspark or is it completely off? If it makes sense anything that I should keep in mind (caching/transactions etc)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12imxfe", "is_robot_indexable": true, "report_reasons": null, "author": "Avlio27", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12imxfe/split_source_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12imxfe/split_source_data/", "subreddit_subscribers": 98086, "created_utc": 1681225969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First if all it is a legit program by MIT? As I've seen many scams regarding online courses. Second, I am a business management graduate walking into a business analytics master, will it help if I do the MIT course before I begin my course in September?", "author_fullname": "t2_a4bk8wks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MIT Professional Education's Applied Data Science Program worth?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12imwi2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681225923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First if all it is a legit program by MIT? As I&amp;#39;ve seen many scams regarding online courses. Second, I am a business management graduate walking into a business analytics master, will it help if I do the MIT course before I begin my course in September?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12imwi2", "is_robot_indexable": true, "report_reasons": null, "author": "Jamesgeorge96", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12imwi2/mit_professional_educations_applied_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12imwi2/mit_professional_educations_applied_data_science/", "subreddit_subscribers": 98086, "created_utc": 1681225923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In this blog one of our engineers at Coiled shares some views that they\u2019ve found useful when digging into our costs for running data-science workloads on EC2 instances. \n\n[https://medium.com/coiled-hq/aws-cost-explorer-tips-and-tricks-496d0d7c47f3](https://medium.com/coiled-hq/aws-cost-explorer-tips-and-tricks-496d0d7c47f3)", "author_fullname": "t2_w7crvjmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Cost Explorer Tips and Tricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12imppa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681225563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In this blog one of our engineers at Coiled shares some views that they\u2019ve found useful when digging into our costs for running data-science workloads on EC2 instances. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/coiled-hq/aws-cost-explorer-tips-and-tricks-496d0d7c47f3\"&gt;https://medium.com/coiled-hq/aws-cost-explorer-tips-and-tricks-496d0d7c47f3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?auto=webp&amp;v=enabled&amp;s=376205117e289a15fca45bb488f4cc97972b448d", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8f9bfc25260063d87ea6c0718c0be12ac131418", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35c471bca895018de46bb3bbf59c940767a5c469", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02d1a379840e344caf74472d22bf10a48fc62999", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a9e24f05b112454ef102b4024dc5c9ec910a95d", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=483c0850c69c787275da78c86f011f8fca2bda45", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/GWrH7TG0iXhsczFAt7nZsB097nAncSxYRtVx2ma_7ac.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=023869729d1cdc861a7101ac192650cecb802880", "width": 1080, "height": 607}], "variants": {}, "id": "vuThvwZ6-8NSiwargOfiF6vUrslGkZ64Tg1ArqcUXOU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12imppa", "is_robot_indexable": true, "report_reasons": null, "author": "dask-jeeves", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12imppa/aws_cost_explorer_tips_and_tricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12imppa/aws_cost_explorer_tips_and_tricks/", "subreddit_subscribers": 98086, "created_utc": 1681225563.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}