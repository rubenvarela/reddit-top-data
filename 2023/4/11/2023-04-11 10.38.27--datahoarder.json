{"kind": "Listing", "data": {"after": "t3_12hxjyt", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Holy Bible prototype ROM for the GBA has been dumped", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_12hiuj7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 144, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "author_fullname": "t2_7k499ptf", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 144, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_7M_IM4xRkH9e0MneoiTuXAyt-r0VCLYqJ2P8FBL31o.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Roms", "selftext": "", "author_fullname": "t2_7k499ptf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Holy Bible prototype ROM for the GBA has been dumped", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Roms", "hidden": false, "pwls": 6, "link_flair_css_class": "other", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_12hin3t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 323, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Other", "can_mod_post": false, "score": 323, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_7M_IM4xRkH9e0MneoiTuXAyt-r0VCLYqJ2P8FBL31o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681132849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "forestillusion.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://forestillusion.com/2023/the-holy-bible-world-english-bible-usa-prototype", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TeHAg_BpA1XZg17J77OIxOJjFP6XvazFzjEgKLs3Q4Y.jpg?auto=webp&amp;v=enabled&amp;s=88781d9c13eb8dceea2ca002aa169c4f97378f55", "width": 240, "height": 160}, "resolutions": [{"url": "https://external-preview.redd.it/TeHAg_BpA1XZg17J77OIxOJjFP6XvazFzjEgKLs3Q4Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8abcaa71898b9fcf8594e4bd6877d1a759722df5", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/TeHAg_BpA1XZg17J77OIxOJjFP6XvazFzjEgKLs3Q4Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=845f264e52c93a3f5353ed521cd8c62638d108cf", "width": 216, "height": 144}], "variants": {}, "id": "TevefzP4sBkT5KVDUUoBYhJcsDrjKLAVCjc0_LgfZSA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "c7eb311c-98e4-11e9-904d-0e638640b570", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sjex", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12hin3t", "is_robot_indexable": true, "report_reasons": null, "author": "NXGZ", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Roms/comments/12hin3t/the_holy_bible_prototype_rom_for_the_gba_has_been/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://forestillusion.com/2023/the-holy-bible-world-english-bible-usa-prototype", "subreddit_subscribers": 237236, "created_utc": 1681132849.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1681133343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "forestillusion.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://forestillusion.com/2023/the-holy-bible-world-english-bible-usa-prototype", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TeHAg_BpA1XZg17J77OIxOJjFP6XvazFzjEgKLs3Q4Y.jpg?auto=webp&amp;v=enabled&amp;s=88781d9c13eb8dceea2ca002aa169c4f97378f55", "width": 240, "height": 160}, "resolutions": [{"url": "https://external-preview.redd.it/TeHAg_BpA1XZg17J77OIxOJjFP6XvazFzjEgKLs3Q4Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8abcaa71898b9fcf8594e4bd6877d1a759722df5", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/TeHAg_BpA1XZg17J77OIxOJjFP6XvazFzjEgKLs3Q4Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=845f264e52c93a3f5353ed521cd8c62638d108cf", "width": 216, "height": 144}], "variants": {}, "id": "TevefzP4sBkT5KVDUUoBYhJcsDrjKLAVCjc0_LgfZSA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Collector", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hiuj7", "is_robot_indexable": true, "report_reasons": null, "author": "NXGZ", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12hin3t", "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12hiuj7/the_holy_bible_prototype_rom_for_the_gba_has_been/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://forestillusion.com/2023/the-holy-bible-world-english-bible-usa-prototype", "subreddit_subscribers": 677406, "created_utc": 1681133343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "from my first piece of code in 2009, my homeschool photos all throughout my life, everything.. i decided to get an HDD cage, i bought 4 total 12 TB seagate enterprise 16x drives, and am gonna run it in Raid 5. I also now have a cloud storage incase that fails, as well as a \"to-go\" 5 TB hdd. i will not let this happen again. \n\nbefore you tell me that i was an idiot, i recognize i very much was, and recognize backing stuff up this much won't bring my data back, but you can never be so secure. i just never really thought about it was the problem. I'm currently 23, so this will be a major learned lesson for my life\n\nRemember to back up your data!!!", "author_fullname": "t2_an387ph9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After losing all my data (6 TB)..", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12i8tgw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 104, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 104, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681188636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;from my first piece of code in 2009, my homeschool photos all throughout my life, everything.. i decided to get an HDD cage, i bought 4 total 12 TB seagate enterprise 16x drives, and am gonna run it in Raid 5. I also now have a cloud storage incase that fails, as well as a &amp;quot;to-go&amp;quot; 5 TB hdd. i will not let this happen again. &lt;/p&gt;\n\n&lt;p&gt;before you tell me that i was an idiot, i recognize i very much was, and recognize backing stuff up this much won&amp;#39;t bring my data back, but you can never be so secure. i just never really thought about it was the problem. I&amp;#39;m currently 23, so this will be a major learned lesson for my life&lt;/p&gt;\n\n&lt;p&gt;Remember to back up your data!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "12i8tgw", "is_robot_indexable": true, "report_reasons": null, "author": "IsshouPrism", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12i8tgw/after_losing_all_my_data_6_tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12i8tgw/after_losing_all_my_data_6_tb/", "subreddit_subscribers": 677406, "created_utc": 1681188636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4aynv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DPReview closure: an update", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_12hl9zs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jE865tI3yKedxA2XuzuzuWVjBtyab5GMQaI7vaI6Zbg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681138647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dpreview.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dpreview.com/news/0507902613/dpreview-closure-an-update", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?auto=webp&amp;v=enabled&amp;s=62800be361d0e710877115d585fc54f6bc091987", "width": 745, "height": 745}, "resolutions": [{"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c85ecc4153f61d9a247d4758d9430569622282d", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a74b7694c73ea2345e65d9ea046b7453dce349cd", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3dbcef5e3e8892307008a8899734f8a2c64159c5", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b46d7621039f2b84e5eb82a6de9d0d1874068788", "width": 640, "height": 640}], "variants": {}, "id": "KDAVLRZTXaBom3MDvF95i0FH6bCPweDv6BPK8qmCi6E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hl9zs", "is_robot_indexable": true, "report_reasons": null, "author": "retrac1324", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hl9zs/dpreview_closure_an_update/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dpreview.com/news/0507902613/dpreview-closure-an-update", "subreddit_subscribers": 677406, "created_utc": 1681138647.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Would data recovery be guaranteed if I were to store thousands of copies of the same file on a DVD?", "author_fullname": "t2_c7b49yt3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need to store a 1MB file for 20 years, would making thousands of copies on a 4.7gb DVD be enough?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hrquv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681151926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would data recovery be guaranteed if I were to store thousands of copies of the same file on a DVD?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hrquv", "is_robot_indexable": true, "report_reasons": null, "author": "IlIIllIIIlllIlllIIll", "discussion_type": null, "num_comments": 78, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hrquv/i_need_to_store_a_1mb_file_for_20_years_would/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12hrquv/i_need_to_store_a_1mb_file_for_20_years_would/", "subreddit_subscribers": 677406, "created_utc": 1681151926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, there are plenty of threads out there discussing ext4 by default adds 5% overhead with reserved blocks, which can be decreased using tune2fs. Most people seem to bring up there being risks only if the overhead is set to 0% on the system partition (can potentially lock you out of the system if the disk becomes completely full), but some also use the argument \"that it helps to prevent fragmentation\", without going further into what that actually means.\n\nIs there any point in having overhead on archive disks containing about 70% large media files, and 30% smaller files? Most of the archive is never touched, but sometimes I clean out some content and replace with new.\n\nI have 2 x 10TB and 1 x 18TB, and currently set the 10TBs to 3%, and the 18TB to 1%. But can someone explain why this would help preventing fragmentation?", "author_fullname": "t2_2xmc8zlr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ext4 - any point of having reserved blocks for \"fragmentation\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hxcxz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681162993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, there are plenty of threads out there discussing ext4 by default adds 5% overhead with reserved blocks, which can be decreased using tune2fs. Most people seem to bring up there being risks only if the overhead is set to 0% on the system partition (can potentially lock you out of the system if the disk becomes completely full), but some also use the argument &amp;quot;that it helps to prevent fragmentation&amp;quot;, without going further into what that actually means.&lt;/p&gt;\n\n&lt;p&gt;Is there any point in having overhead on archive disks containing about 70% large media files, and 30% smaller files? Most of the archive is never touched, but sometimes I clean out some content and replace with new.&lt;/p&gt;\n\n&lt;p&gt;I have 2 x 10TB and 1 x 18TB, and currently set the 10TBs to 3%, and the 18TB to 1%. But can someone explain why this would help preventing fragmentation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hxcxz", "is_robot_indexable": true, "report_reasons": null, "author": "snattack_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hxcxz/ext4_any_point_of_having_reserved_blocks_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12hxcxz/ext4_any_point_of_having_reserved_blocks_for/", "subreddit_subscribers": 677406, "created_utc": 1681162993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently, all my relevant data (documents and stuff like that) is stored in a single place: my Google Drive. This is obviously bad because I am risking loosing everything in case something bad happens (i.e. I get hacked, something happens with Google or stuff like that). I was thinking about adopting a system that automatically syncs my files between multiple places. I was thinking:\n\n- a \"main\" folder on my Linux computer, stored locally on my hard drive\n- an external hard drive that would be plugged to my computer all the time, automatically backing up that main folder\n- a Google Drive account that also gets updated accordingly when I change data on that main folder\n- some other cloud storage provider that behaves the same as Google Drive\n\nAdditionally, every place should automatically update itself when I change data in somewhere else, i.e.: when I rename a file in Google Drive, it should be renamed in other places when they first come online. The same should be true for every other place.\n\nIdeally, I want to forget about making backups: it should all be done automatically and be stored in multiple places. Is there a solution for that? \n\nThanks in advance", "author_fullname": "t2_2ntrutgg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a system for backing up files in multiple places both locally and on the cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hz2y7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681166401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, all my relevant data (documents and stuff like that) is stored in a single place: my Google Drive. This is obviously bad because I am risking loosing everything in case something bad happens (i.e. I get hacked, something happens with Google or stuff like that). I was thinking about adopting a system that automatically syncs my files between multiple places. I was thinking:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;a &amp;quot;main&amp;quot; folder on my Linux computer, stored locally on my hard drive&lt;/li&gt;\n&lt;li&gt;an external hard drive that would be plugged to my computer all the time, automatically backing up that main folder&lt;/li&gt;\n&lt;li&gt;a Google Drive account that also gets updated accordingly when I change data on that main folder&lt;/li&gt;\n&lt;li&gt;some other cloud storage provider that behaves the same as Google Drive&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Additionally, every place should automatically update itself when I change data in somewhere else, i.e.: when I rename a file in Google Drive, it should be renamed in other places when they first come online. The same should be true for every other place.&lt;/p&gt;\n\n&lt;p&gt;Ideally, I want to forget about making backups: it should all be done automatically and be stored in multiple places. Is there a solution for that? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hz2y7", "is_robot_indexable": true, "report_reasons": null, "author": "brubsabrubs", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hz2y7/looking_for_a_system_for_backing_up_files_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12hz2y7/looking_for_a_system_for_backing_up_files_in/", "subreddit_subscribers": 677406, "created_utc": 1681166401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello. Last year, I bought a 1TB external HDD, which I still use today. I have more important data on it. I want to back up my data, but I currently can't afford 3 drives, so I will have 2. What should I get? A HDD or an SSD? When I will have 3 drives, what should I have? 3 HDDs, 3 SSDs, 2 HDDs and an SSD or 2 SSDs and 1 HDD? Also, internal laptop SSDs are cheaper than external SSDs. Should I get those? If yes, can you recommend me a good SATA to USB cable? I have one, but it doesn't work half of the time.   \n\n\nCurrently, I want to back up my 1TB HDD with important data, but I have around 2TB that aren't important, and they're scattered on many different drives, and flash drives. I also have some on my laptop. The same story as before, what should I get? HDD or SSD (3 HDDs, 3 SSDs, 2 HDDs and an SSD or 2 SSDs and 1 HDD)? Should I group them into 2 1TB drives, or get 1 2TB drive (of each, not in total)?  \n\n\nIf you have any questions, or you don't understand something, on what I want/mean, please ask in the comments. I will reply to all.", "author_fullname": "t2_4rgbkiho", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way for 3-2-1 data backup? (what/how should I use, read post)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hpa12", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681146914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. Last year, I bought a 1TB external HDD, which I still use today. I have more important data on it. I want to back up my data, but I currently can&amp;#39;t afford 3 drives, so I will have 2. What should I get? A HDD or an SSD? When I will have 3 drives, what should I have? 3 HDDs, 3 SSDs, 2 HDDs and an SSD or 2 SSDs and 1 HDD? Also, internal laptop SSDs are cheaper than external SSDs. Should I get those? If yes, can you recommend me a good SATA to USB cable? I have one, but it doesn&amp;#39;t work half of the time.   &lt;/p&gt;\n\n&lt;p&gt;Currently, I want to back up my 1TB HDD with important data, but I have around 2TB that aren&amp;#39;t important, and they&amp;#39;re scattered on many different drives, and flash drives. I also have some on my laptop. The same story as before, what should I get? HDD or SSD (3 HDDs, 3 SSDs, 2 HDDs and an SSD or 2 SSDs and 1 HDD)? Should I group them into 2 1TB drives, or get 1 2TB drive (of each, not in total)?  &lt;/p&gt;\n\n&lt;p&gt;If you have any questions, or you don&amp;#39;t understand something, on what I want/mean, please ask in the comments. I will reply to all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hpa12", "is_robot_indexable": true, "report_reasons": null, "author": "SuioganWilliam21", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12hpa12/best_way_for_321_data_backup_whathow_should_i_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12hpa12/best_way_for_321_data_backup_whathow_should_i_use/", "subreddit_subscribers": 677406, "created_utc": 1681146914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Complete beginner, so please bare with me.\n\nI built my first NAS with a full tower PC case, with 10/10 drive slots currently used.\n\nI would love for that to be 20 hard drives, someday - but I don't know the next process to extending this thing.\n\nThere is a ton of spare SATA ports on the HBA card currently inside, along with an empty PCI-E slot (potentially for a second HBA card?)\n\nIs there some kind of hard drive-only case I can buy and somehow feed the drives to the main server PC?\n\nThank you", "author_fullname": "t2_7dop5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would I extend my NAS that has no more HDD slots?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hsnaf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681153703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Complete beginner, so please bare with me.&lt;/p&gt;\n\n&lt;p&gt;I built my first NAS with a full tower PC case, with 10/10 drive slots currently used.&lt;/p&gt;\n\n&lt;p&gt;I would love for that to be 20 hard drives, someday - but I don&amp;#39;t know the next process to extending this thing.&lt;/p&gt;\n\n&lt;p&gt;There is a ton of spare SATA ports on the HBA card currently inside, along with an empty PCI-E slot (potentially for a second HBA card?)&lt;/p&gt;\n\n&lt;p&gt;Is there some kind of hard drive-only case I can buy and somehow feed the drives to the main server PC?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hsnaf", "is_robot_indexable": true, "report_reasons": null, "author": "FromThatOtherPlace", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hsnaf/how_would_i_extend_my_nas_that_has_no_more_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12hsnaf/how_would_i_extend_my_nas_that_has_no_more_hdd/", "subreddit_subscribers": 677406, "created_utc": 1681153703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://www.gsmarena.com/samsung\\_galaxy\\_a34-pictures-12074.php](https://www.gsmarena.com/samsung_galaxy_a34-pictures-12074.php)  \n\n\nGSM arena is using a website called binkies 3d to show the phone in 3d. I would love to have the 3d file . Im not quite understanding how to download it. I tried finding in the code with inspector on chrome", "author_fullname": "t2_10vsid", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I download a 3d asset on a website?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hs7kx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681152850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.gsmarena.com/samsung_galaxy_a34-pictures-12074.php\"&gt;https://www.gsmarena.com/samsung_galaxy_a34-pictures-12074.php&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;GSM arena is using a website called binkies 3d to show the phone in 3d. I would love to have the 3d file . Im not quite understanding how to download it. I tried finding in the code with inspector on chrome&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hs7kx", "is_robot_indexable": true, "report_reasons": null, "author": "alexandremix", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hs7kx/can_i_download_a_3d_asset_on_a_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12hs7kx/can_i_download_a_3d_asset_on_a_website/", "subreddit_subscribers": 677406, "created_utc": 1681152850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 13 additional disks in my main pc and I\u2019m getting an upgrade but I want these drives mounted externally and I\u2019m not sure what best suits my needs. \nMy extra disks are only for a movie collection using Kodi that serves a HTPC via LAN so most of the time only 1 disk is used at a time when watching a movie. \nIf I get a NAS I\u2019ll have this built rather than an off the shelf system.\nWhich do you suggest?", "author_fullname": "t2_5vxyublw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "JBOD enclosures or NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hfdv0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681124739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 13 additional disks in my main pc and I\u2019m getting an upgrade but I want these drives mounted externally and I\u2019m not sure what best suits my needs. \nMy extra disks are only for a movie collection using Kodi that serves a HTPC via LAN so most of the time only 1 disk is used at a time when watching a movie. \nIf I get a NAS I\u2019ll have this built rather than an off the shelf system.\nWhich do you suggest?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hfdv0", "is_robot_indexable": true, "report_reasons": null, "author": "AdAmbitious9654", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hfdv0/jbod_enclosures_or_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12hfdv0/jbod_enclosures_or_nas/", "subreddit_subscribers": 677406, "created_utc": 1681124739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "With my limited knowledge they look ok.\n\nShould I stress test them? How do I do that if so?\n\n \nI may be using one in my personal pc and the other as offline storage. I don't mess with raid or NAS. I am very basic when it comes to data storage having 3 or 4 drives in my PC that I use daily and backing up once in awhile to a couple of offline backups.", "author_fullname": "t2_e4udh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Used 2015 WD Gold $11/TB - Should I stress test new-to-me hard drives? How do I do that?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qe3zuat1e4ta1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 192, "x": 108, "u": "https://preview.redd.it/qe3zuat1e4ta1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=937645178a6e8fc2c028db49fa407a1ffed45fae"}, {"y": 384, "x": 216, "u": "https://preview.redd.it/qe3zuat1e4ta1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4a1ed7705a23f1d89771b592afadfddb22a0fae"}, {"y": 568, "x": 320, "u": "https://preview.redd.it/qe3zuat1e4ta1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=929f21a5379a4eff7e8e0cec786c2c6d7bb2131a"}, {"y": 1137, "x": 640, "u": "https://preview.redd.it/qe3zuat1e4ta1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ce17d2d52b6c09a1ae25c3318acb621ca413c71"}, {"y": 1706, "x": 960, "u": "https://preview.redd.it/qe3zuat1e4ta1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=99bcf2b06f95144d72318cfc3c84cb56fc9f7d1f"}, {"y": 1920, "x": 1080, "u": "https://preview.redd.it/qe3zuat1e4ta1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6aec1eef4e01a81b86e7cb6883de1308a045e2d8"}], "s": {"y": 4032, "x": 2268, "u": "https://preview.redd.it/qe3zuat1e4ta1.jpg?width=2268&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c78276324c604690081a38ed465118bd3eae5c47"}, "id": "qe3zuat1e4ta1"}, "s97nava1e4ta1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 192, "x": 108, "u": "https://preview.redd.it/s97nava1e4ta1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3ba624471119108293762771707c11ac4853b7f"}, {"y": 384, "x": 216, "u": "https://preview.redd.it/s97nava1e4ta1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f77ed43faba0542fed06c9c42cda6355d85ea6d"}, {"y": 568, "x": 320, "u": "https://preview.redd.it/s97nava1e4ta1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e07474547a871e21356645a5d98b2a67f742b122"}, {"y": 1137, "x": 640, "u": "https://preview.redd.it/s97nava1e4ta1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=946adc7b7aa5c72034a8026760e51e2f16a7bf50"}, {"y": 1706, "x": 960, "u": "https://preview.redd.it/s97nava1e4ta1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d1e8573179cf58894dbaafd82eac3959480df71"}, {"y": 1920, "x": 1080, "u": "https://preview.redd.it/s97nava1e4ta1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8297fb14ac13478d05efe98097016efe2445b28c"}], "s": {"y": 4032, "x": 2268, "u": "https://preview.redd.it/s97nava1e4ta1.jpg?width=2268&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=36e25912ca60c63ab973dae544698799461322b3"}, "id": "s97nava1e4ta1"}}, "name": "t3_12hvtk3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "ups": 6, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "s97nava1e4ta1", "id": 261979698}, {"media_id": "qe3zuat1e4ta1", "id": 261979699}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/emu_6K5M0RI7y5gDFhisk_bVjSIWMlzc3bms02IQmtM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681159921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With my limited knowledge they look ok.&lt;/p&gt;\n\n&lt;p&gt;Should I stress test them? How do I do that if so?&lt;/p&gt;\n\n&lt;p&gt;I may be using one in my personal pc and the other as offline storage. I don&amp;#39;t mess with raid or NAS. I am very basic when it comes to data storage having 3 or 4 drives in my PC that I use daily and backing up once in awhile to a couple of offline backups.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/12hvtk3", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hvtk3", "is_robot_indexable": true, "report_reasons": null, "author": "Charleaux330", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hvtk3/used_2015_wd_gold_11tb_should_i_stress_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/12hvtk3", "subreddit_subscribers": 677406, "created_utc": 1681159921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there an easy way to break up long youtube music mix videos into tracks with in video chapters/track times?  I am trying to download some of that old N64/PS1 era jungle DnB.\n\n&amp;#x200B;\n\nI cant seem to find any playlists on soundcloud for easy downloading of this type of music.  and I'm not sure how to go about collecting it easily in bulk.\n\n&amp;#x200B;\n\nThanks hoarders!", "author_fullname": "t2_1u51rpru", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Breaking up long YT video mixes or assistance finding some stuff", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hveqk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681159095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there an easy way to break up long youtube music mix videos into tracks with in video chapters/track times?  I am trying to download some of that old N64/PS1 era jungle DnB.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I cant seem to find any playlists on soundcloud for easy downloading of this type of music.  and I&amp;#39;m not sure how to go about collecting it easily in bulk.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks hoarders!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hveqk", "is_robot_indexable": true, "report_reasons": null, "author": "vann_of_fanelia", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hveqk/breaking_up_long_yt_video_mixes_or_assistance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12hveqk/breaking_up_long_yt_video_mixes_or_assistance/", "subreddit_subscribers": 677406, "created_utc": 1681159095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As the title stated, is the file safe or i need to download all those folders to be safe.\n\nThanks in advance!!", "author_fullname": "t2_c41c7h88", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What happens to synced folders in pc from \u201cshared with me\u201d folders in google drive if the original folders on the drive are deleted or no longer accesible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hn69t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681142608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title stated, is the file safe or i need to download all those folders to be safe.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hn69t", "is_robot_indexable": true, "report_reasons": null, "author": "Livid-Adeptness6021", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hn69t/what_happens_to_synced_folders_in_pc_from_shared/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12hn69t/what_happens_to_synced_folders_in_pc_from_shared/", "subreddit_subscribers": 677406, "created_utc": 1681142608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " this is the line i'm using:  \n python.exe -m bdfr clone C:\\\\folder\\\\data\\\\ --user me --saved --authenticate  --file-scheme '{POSTID}\n\nit also ends on this line:  \n DuplicateReplaceException: A duplicate comment has been detected. Are  you attempting to call 'replace\\_more\\_comments' more than once?", "author_fullname": "t2_45q9k41p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "i'm using bulk downloader for reddit and my download is capped at 50 posts. i don't know if doing something wrong please help.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hn69k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681142607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;this is the line i&amp;#39;m using:&lt;br/&gt;\n python.exe -m bdfr clone C:\\folder\\data\\ --user me --saved --authenticate  --file-scheme &amp;#39;{POSTID}&lt;/p&gt;\n\n&lt;p&gt;it also ends on this line:&lt;br/&gt;\n DuplicateReplaceException: A duplicate comment has been detected. Are  you attempting to call &amp;#39;replace_more_comments&amp;#39; more than once?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hn69k", "is_robot_indexable": true, "report_reasons": null, "author": "mukesh_foo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hn69k/im_using_bulk_downloader_for_reddit_and_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12hn69k/im_using_bulk_downloader_for_reddit_and_my/", "subreddit_subscribers": 677406, "created_utc": 1681142607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nIs there a recommended free unlimited PDF editor for daily use?", "author_fullname": "t2_9xbsnvq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free PDF Editor Recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12idug5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681203784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a recommended free unlimited PDF editor for daily use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12idug5", "is_robot_indexable": true, "report_reasons": null, "author": "RevolutionaryFocus10", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12idug5/free_pdf_editor_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12idug5/free_pdf_editor_recommendations/", "subreddit_subscribers": 677406, "created_utc": 1681203784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, I got the set of Harry Potter bluray movies. I thought I was getting an extended edition without realizing that the \"extended\" bits were actually deleted scenes and not part of the movie.\n\nI want to take all that data off the disc, edit the deleted scenes into the movie where they belong, then export all that to a new disc so I can watch it all in one film instead of the bits and pieces it came in, if that makes any sense.\n\nI have no experience doing this, but I know how to edit them unless there's a weird thing with bluray files I need to be aware of.\n\nHere's my questions: Will an external bluray ripper be enough or do I also need a writer (??) and will I need fresh bluray discs or can I put it all back on the original disc?\n\nNot sure how to begin to google this so I figured I'd start with this subreddit and go from there. Thank you :D\n\nAlso, if there are any key terms to look up, let me know. I like doing research to figure it out myself, for the most part, but I'm just not sure how to get started with this project lol", "author_fullname": "t2_qx8e6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rip Blu-Ray Movie, Edit, Then Put on Another Blu-Ray Disc??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12i7ean", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681184970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I got the set of Harry Potter bluray movies. I thought I was getting an extended edition without realizing that the &amp;quot;extended&amp;quot; bits were actually deleted scenes and not part of the movie.&lt;/p&gt;\n\n&lt;p&gt;I want to take all that data off the disc, edit the deleted scenes into the movie where they belong, then export all that to a new disc so I can watch it all in one film instead of the bits and pieces it came in, if that makes any sense.&lt;/p&gt;\n\n&lt;p&gt;I have no experience doing this, but I know how to edit them unless there&amp;#39;s a weird thing with bluray files I need to be aware of.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my questions: Will an external bluray ripper be enough or do I also need a writer (??) and will I need fresh bluray discs or can I put it all back on the original disc?&lt;/p&gt;\n\n&lt;p&gt;Not sure how to begin to google this so I figured I&amp;#39;d start with this subreddit and go from there. Thank you :D&lt;/p&gt;\n\n&lt;p&gt;Also, if there are any key terms to look up, let me know. I like doing research to figure it out myself, for the most part, but I&amp;#39;m just not sure how to get started with this project lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12i7ean", "is_robot_indexable": true, "report_reasons": null, "author": "StrawberryWolfGamez", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12i7ean/rip_bluray_movie_edit_then_put_on_another_bluray/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12i7ean/rip_bluray_movie_edit_then_put_on_another_bluray/", "subreddit_subscribers": 677406, "created_utc": 1681184970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to locate some old music. The studio with the original masters burned down and no one we know has any copy of the music.", "author_fullname": "t2_speo3xmt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any backups of the early 2000s mp3.com?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12i5tuq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681181168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to locate some old music. The studio with the original masters burned down and no one we know has any copy of the music.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12i5tuq", "is_robot_indexable": true, "report_reasons": null, "author": "Vile-X", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12i5tuq/is_there_any_backups_of_the_early_2000s_mp3com/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12i5tuq/is_there_any_backups_of_the_early_2000s_mp3com/", "subreddit_subscribers": 677406, "created_utc": 1681181168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a Samsung BD-EM67C at a thrift store for $1. It was one of those Goodwill outlet stores with the bins of junk, for those wondering why it was so cheap. \n\nI don't have a Blu-Ray player that I can connect to my PC via USB, and I don't have a SATA BD drive either. So I was wondering if it was, in any way, possible to rip Blu-Rays from Samsung player and maybe put them on a USB drive or something. \n\nI read that a lot of Blu-Ray players use versions of Linux, but I don't know if that's any helpful info.", "author_fullname": "t2_5ydpstp2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any way to rip Blu-Rays and DVDs using a dedicated player?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12i2b7y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681173170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a Samsung BD-EM67C at a thrift store for $1. It was one of those Goodwill outlet stores with the bins of junk, for those wondering why it was so cheap. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have a Blu-Ray player that I can connect to my PC via USB, and I don&amp;#39;t have a SATA BD drive either. So I was wondering if it was, in any way, possible to rip Blu-Rays from Samsung player and maybe put them on a USB drive or something. &lt;/p&gt;\n\n&lt;p&gt;I read that a lot of Blu-Ray players use versions of Linux, but I don&amp;#39;t know if that&amp;#39;s any helpful info.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12i2b7y", "is_robot_indexable": true, "report_reasons": null, "author": "oddiefox", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12i2b7y/is_there_any_way_to_rip_blurays_and_dvds_using_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12i2b7y/is_there_any_way_to_rip_blurays_and_dvds_using_a/", "subreddit_subscribers": 677406, "created_utc": 1681173170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a gaming PC with 8x internal hard drives that have all my backup bluray movies on.\n\nI would like to give the PC to my son, as he loves to game and I don't have the time.\n\nCan I make a pc for myself and install all drives and drive pool will work exactly as it should?\n\nI'm unsure how drive pool would deal with this transfer??\n\nPlease advise \ud83d\ude4f", "author_fullname": "t2_804y1v9i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drive pool question :)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hzg2w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681167168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a gaming PC with 8x internal hard drives that have all my backup bluray movies on.&lt;/p&gt;\n\n&lt;p&gt;I would like to give the PC to my son, as he loves to game and I don&amp;#39;t have the time.&lt;/p&gt;\n\n&lt;p&gt;Can I make a pc for myself and install all drives and drive pool will work exactly as it should?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m unsure how drive pool would deal with this transfer??&lt;/p&gt;\n\n&lt;p&gt;Please advise \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hzg2w", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Improvement611", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hzg2w/drive_pool_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12hzg2w/drive_pool_question/", "subreddit_subscribers": 677406, "created_utc": 1681167168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI was wondering if it is possible to take a file which is stored online but too big to download and virtually link it to a location on my physical linux drive for use with plex. I know rclone can be used for entire directories and google drive etc, but I only have access to this single video file which I want to map to my drive. Is this possible? (P.S. dw its not piracy)", "author_fullname": "t2_85uip7jy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Link online file url to a location on hard drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hgdpm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681127263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I was wondering if it is possible to take a file which is stored online but too big to download and virtually link it to a location on my physical linux drive for use with plex. I know rclone can be used for entire directories and google drive etc, but I only have access to this single video file which I want to map to my drive. Is this possible? (P.S. dw its not piracy)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hgdpm", "is_robot_indexable": true, "report_reasons": null, "author": "AmountOk3836", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hgdpm/link_online_file_url_to_a_location_on_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12hgdpm/link_online_file_url_to_a_location_on_hard_drive/", "subreddit_subscribers": 677406, "created_utc": 1681127263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What do you think is better for an enterprise to store their data, especially marketing collaterals. Google Drive or a paid Digital Asset Management tool?", "author_fullname": "t2_udue1w9k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is better?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12icyq3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681200865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you think is better for an enterprise to store their data, especially marketing collaterals. Google Drive or a paid Digital Asset Management tool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12icyq3", "is_robot_indexable": true, "report_reasons": null, "author": "ArtworkFlow_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12icyq3/which_is_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12icyq3/which_is_better/", "subreddit_subscribers": 677406, "created_utc": 1681200865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi Archivists.\n\nI'm about to dump several drawers full of old CD-ROMs (Magazine disks; CD-R's; Games disks; driver CDs; you name it) down to my home server. At the moment I am trying to determine the best format to keep these in. For example, do I keep every disc as a nice neat ISO file? \n\nBut then I do like the idea of being able to index, search and browse the contents. I may build a web front end for this. In which case maybe just dropping the file structure down on disk is better so there is no need to mount ISOs etc.\n\nAn then there's the consideration of compression. If I gzip directories can I still have the files be web browsable online? There are potentially a lot of text files so compression would be quite efficient.\n\nSo any thoughts? I would love to hear from someone already doing this. What works for you? Any off the shelf solutions? What tools or utils did you use?\n\nFor reference: Fedora 37 with approx 64TB raw spinning rust. Plenty of breathing space.", "author_fullname": "t2_mo11s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dumping to HDD, Storing and making browsable lot of CD-ROMs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12icdb4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681198913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Archivists.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m about to dump several drawers full of old CD-ROMs (Magazine disks; CD-R&amp;#39;s; Games disks; driver CDs; you name it) down to my home server. At the moment I am trying to determine the best format to keep these in. For example, do I keep every disc as a nice neat ISO file? &lt;/p&gt;\n\n&lt;p&gt;But then I do like the idea of being able to index, search and browse the contents. I may build a web front end for this. In which case maybe just dropping the file structure down on disk is better so there is no need to mount ISOs etc.&lt;/p&gt;\n\n&lt;p&gt;An then there&amp;#39;s the consideration of compression. If I gzip directories can I still have the files be web browsable online? There are potentially a lot of text files so compression would be quite efficient.&lt;/p&gt;\n\n&lt;p&gt;So any thoughts? I would love to hear from someone already doing this. What works for you? Any off the shelf solutions? What tools or utils did you use?&lt;/p&gt;\n\n&lt;p&gt;For reference: Fedora 37 with approx 64TB raw spinning rust. Plenty of breathing space.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12icdb4", "is_robot_indexable": true, "report_reasons": null, "author": "Finno_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12icdb4/dumping_to_hdd_storing_and_making_browsable_lot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12icdb4/dumping_to_hdd_storing_and_making_browsable_lot/", "subreddit_subscribers": 677406, "created_utc": 1681198913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have zero idea where to even start.\n\nI need some sort of program/something so for example, I want to have two separate computers with two same sized drives, and have Drive A remotely connect to Drive B and every time Drive A gets a new file/folder/whatever it is cloned to Drive B as soon as Drive A gets the file", "author_fullname": "t2_h6jqxm2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No idea where to start", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12iaxyl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681194306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have zero idea where to even start.&lt;/p&gt;\n\n&lt;p&gt;I need some sort of program/something so for example, I want to have two separate computers with two same sized drives, and have Drive A remotely connect to Drive B and every time Drive A gets a new file/folder/whatever it is cloned to Drive B as soon as Drive A gets the file&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12iaxyl", "is_robot_indexable": true, "report_reasons": null, "author": "BroodyDoggo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12iaxyl/no_idea_where_to_start/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12iaxyl/no_idea_where_to_start/", "subreddit_subscribers": 677406, "created_utc": 1681194306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! A long time ago I had found on (I believe) this subreddit a simple tool to ID what drive is inside an external USB drive encolsure (like my book, elements, etc...) I cannot recall the name and do not have it on my new PC. I haven't had any luck locating it through google, and was hoping if some one knew!\n\nIt would tell you the drive model/sn/capacity. \n\nThanks!", "author_fullname": "t2_5hzr9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External Drive ID tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12i2yfd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681174657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! A long time ago I had found on (I believe) this subreddit a simple tool to ID what drive is inside an external USB drive encolsure (like my book, elements, etc...) I cannot recall the name and do not have it on my new PC. I haven&amp;#39;t had any luck locating it through google, and was hoping if some one knew!&lt;/p&gt;\n\n&lt;p&gt;It would tell you the drive model/sn/capacity. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12i2yfd", "is_robot_indexable": true, "report_reasons": null, "author": "f0rcedinducti0n", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12i2yfd/external_drive_id_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12i2yfd/external_drive_id_tool/", "subreddit_subscribers": 677406, "created_utc": 1681174657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "is there some type of (destructive)write tester for linux that test if the drive is smr/cmr? thx", "author_fullname": "t2_kir7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is there some type of (destructive)write tester for linux that test if the drive is smr/cmr? thx", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12hxjyt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681163387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;is there some type of (destructive)write tester for linux that test if the drive is smr/cmr? thx&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12hxjyt", "is_robot_indexable": true, "report_reasons": null, "author": "kocoman", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12hxjyt/is_there_some_type_of_destructivewrite_tester_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12hxjyt/is_there_some_type_of_destructivewrite_tester_for/", "subreddit_subscribers": 677406, "created_utc": 1681163387.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}