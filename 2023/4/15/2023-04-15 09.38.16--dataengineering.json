{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_16q5j0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exporting to excel is always a people pleaser...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_12m8ml7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 501, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 501, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vEaDT3jzNOo03b2pQKsXWm6Ub5wKYYAGzWEdyltISTY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681498344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/6vtglxi2cwta1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/6vtglxi2cwta1.png?auto=webp&amp;v=enabled&amp;s=9cf19b47ab4a682995c2dc993bbab60faf5e6678", "width": 1182, "height": 1280}, "resolutions": [{"url": "https://preview.redd.it/6vtglxi2cwta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74e103d9a117ab2ea94bb361002ddf3cca4c34c9", "width": 108, "height": 116}, {"url": "https://preview.redd.it/6vtglxi2cwta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e62c682e16c902679a397e81e186cb076821ea6", "width": 216, "height": 233}, {"url": "https://preview.redd.it/6vtglxi2cwta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=61d45e345641564675e100b9818ec876e9286225", "width": 320, "height": 346}, {"url": "https://preview.redd.it/6vtglxi2cwta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e04a031c8f71e72bd1a6cb58439184f1045ed49", "width": 640, "height": 693}, {"url": "https://preview.redd.it/6vtglxi2cwta1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f1685f7d00c688a18cbc5efa2096749d6948205", "width": 960, "height": 1039}, {"url": "https://preview.redd.it/6vtglxi2cwta1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32cd0519cfc66341a05a9ee9fb848816a3bbcb2c", "width": 1080, "height": 1169}], "variants": {}, "id": "4T_doMPlm1O7dNGlmOIpToj64res7j58NG4Xkccej7A"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "12m8ml7", "is_robot_indexable": true, "report_reasons": null, "author": "audiologician", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12m8ml7/exporting_to_excel_is_always_a_people_pleaser/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/6vtglxi2cwta1.png", "subreddit_subscribers": 99117, "created_utc": 1681498344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In every interview for a Data Engineer role, Spark Architecture seems be the only concept the recruiters are interested. \n\nI have 1 year experience as a Data Engineer. I work with Databricks on a day to day basis in Azure, without having to learn what's happening in the background (Spark Architecture). But this does seem to be enough to get a new job as Data Engineer.\n\nI tried searching online for a Spark course, but couldn't find the one that has all the important concepts and good for beginners.\n\nExperts of Spark, how did you learn Spark ? I'd really appreciate if you suggest some good resources/courses to learn Spark Architecture, so that I can clear interviews to get a job.\n\n TIA.", "author_fullname": "t2_tme0hylh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Not clearing interviews due to Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lu3wk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 83, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 83, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681471782.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In every interview for a Data Engineer role, Spark Architecture seems be the only concept the recruiters are interested. &lt;/p&gt;\n\n&lt;p&gt;I have 1 year experience as a Data Engineer. I work with Databricks on a day to day basis in Azure, without having to learn what&amp;#39;s happening in the background (Spark Architecture). But this does seem to be enough to get a new job as Data Engineer.&lt;/p&gt;\n\n&lt;p&gt;I tried searching online for a Spark course, but couldn&amp;#39;t find the one that has all the important concepts and good for beginners.&lt;/p&gt;\n\n&lt;p&gt;Experts of Spark, how did you learn Spark ? I&amp;#39;d really appreciate if you suggest some good resources/courses to learn Spark Architecture, so that I can clear interviews to get a job.&lt;/p&gt;\n\n&lt;p&gt;TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12lu3wk", "is_robot_indexable": true, "report_reasons": null, "author": "fightinmee", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12lu3wk/not_clearing_interviews_due_to_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lu3wk/not_clearing_interviews_due_to_spark/", "subreddit_subscribers": 99117, "created_utc": 1681471782.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7e04ujnq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One day we\u2019ll get the respect we deserve \ud83e\udd72", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_12meohj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": "transparent", "ups": 64, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 64, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GmsK2oEav88xxMD7QOlgMfPZV2WFRX1Bpqxo7d7bKYU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681508747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/pqafjpltoyta1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/pqafjpltoyta1.jpg?auto=webp&amp;v=enabled&amp;s=11ef40cedf5bfac7083596aa648a9f410b82384c", "width": 1098, "height": 1226}, "resolutions": [{"url": "https://preview.redd.it/pqafjpltoyta1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66ff07132e1bc0507ed0cd9c59a3ed0f161d6a15", "width": 108, "height": 120}, {"url": "https://preview.redd.it/pqafjpltoyta1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12448513d4d5ccd06f7d98fc8b445c195b90b606", "width": 216, "height": 241}, {"url": "https://preview.redd.it/pqafjpltoyta1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a74f3a1d8588ed2465d697fc918633baf921f5b2", "width": 320, "height": 357}, {"url": "https://preview.redd.it/pqafjpltoyta1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b41b4d9a92b0ae85633b9cfe33f9248e6720cdd", "width": 640, "height": 714}, {"url": "https://preview.redd.it/pqafjpltoyta1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=950423ddfb43696d3aee15c1b088be56fd774027", "width": 960, "height": 1071}, {"url": "https://preview.redd.it/pqafjpltoyta1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=381d5638798b83bbfc888e8bb60a898876b27f3e", "width": 1080, "height": 1205}], "variants": {}, "id": "jh4DkOdZ72CqqpKCLgwjLYq3-IWOCCRc5lIMe3RgrhI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer That Broke All ETLs", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "12meohj", "is_robot_indexable": true, "report_reasons": null, "author": "ThatGrayZ", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12meohj/one_day_well_get_the_respect_we_deserve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/pqafjpltoyta1.jpg", "subreddit_subscribers": 99117, "created_utc": 1681508747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For anyone that has any interest, I've updated the backend of my Premier League Visualization (Football Data Pipeline) project with the following:\n\n* Implemented code formatting with [Black](https://github.com/psf/black) and linting with [Pylint](https://github.com/pylint-dev/pylint) in my CI pipeline.\n   * Here is my updated GitHub Actions Workflow file: [ci.yml](https://github.com/digitalghost-dev/premier-league/blob/main/.github/workflows/ci.yml) \n* Split up the data endpoints into their own Docker images to achieve more of a \"micro-services\" architecture. Previously, I had one Docker image for all endpoints and made troubleshooting a bit tougher.\n   * The files are under the `/data` folder in my [repo](https://github.com/digitalghost-dev/premier-league/tree/main/data).\n   * I run the containers twice a day now. I'm thinking of upgrading my subscription to allow more calls for more frequent updates.\n   * I also plan to bring in a \"fixtures\" tab to show game scores and history.\n* I also updated the [Streamlit dashboard](https://premierleague.streamlit.app) to include the rest of the teams in the league with their form for their 5 previous games (only games played in the Premier League) in the \"Top Teams Tab\".\n\nI've been learning a lot about code quality and whatnot so I wanted to share how I implemented some of my learnings.\n\nFlowchart has been updated:  \n\n\n[Flowchart](https://preview.redd.it/j35bye26wuta1.png?width=1796&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=340250f3d2f43200e57ca248cb1935d91a200aba)\n\nThanks \ud83e\udee1", "author_fullname": "t2_bix7v2w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Premier League Project Infrastructure Update", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 110, "top_awarded_type": null, "hide_score": false, "media_metadata": {"j35bye26wuta1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 85, "x": 108, "u": "https://preview.redd.it/j35bye26wuta1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=691d81b1d99bccdabc41dab92775c53968142e69"}, {"y": 171, "x": 216, "u": "https://preview.redd.it/j35bye26wuta1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b899741e6ca5b8546d32ca0d11c4187deb1b6d1c"}, {"y": 253, "x": 320, "u": "https://preview.redd.it/j35bye26wuta1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=40c8e3d5f84f987f65399e0d39341b343418eb00"}, {"y": 506, "x": 640, "u": "https://preview.redd.it/j35bye26wuta1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b0d4f5541797f574c5ba298341fb5779a6261c8"}, {"y": 760, "x": 960, "u": "https://preview.redd.it/j35bye26wuta1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=193b6ac8b2279f9dd78eb44b379b53a9456b4881"}, {"y": 855, "x": 1080, "u": "https://preview.redd.it/j35bye26wuta1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9099ab1a74b6e285acfce07e937880be3f086f64"}], "s": {"y": 1422, "x": 1796, "u": "https://preview.redd.it/j35bye26wuta1.png?width=1796&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=340250f3d2f43200e57ca248cb1935d91a200aba"}, "id": "j35bye26wuta1"}}, "name": "t3_12lyhbw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mPkJXkG_MsFx917j3RCKy1vvH253lbEjuLnd6TBcCZs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1681481275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For anyone that has any interest, I&amp;#39;ve updated the backend of my Premier League Visualization (Football Data Pipeline) project with the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Implemented code formatting with &lt;a href=\"https://github.com/psf/black\"&gt;Black&lt;/a&gt; and linting with &lt;a href=\"https://github.com/pylint-dev/pylint\"&gt;Pylint&lt;/a&gt; in my CI pipeline.\n\n&lt;ul&gt;\n&lt;li&gt;Here is my updated GitHub Actions Workflow file: &lt;a href=\"https://github.com/digitalghost-dev/premier-league/blob/main/.github/workflows/ci.yml\"&gt;ci.yml&lt;/a&gt; &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Split up the data endpoints into their own Docker images to achieve more of a &amp;quot;micro-services&amp;quot; architecture. Previously, I had one Docker image for all endpoints and made troubleshooting a bit tougher.\n\n&lt;ul&gt;\n&lt;li&gt;The files are under the &lt;code&gt;/data&lt;/code&gt; folder in my &lt;a href=\"https://github.com/digitalghost-dev/premier-league/tree/main/data\"&gt;repo&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;I run the containers twice a day now. I&amp;#39;m thinking of upgrading my subscription to allow more calls for more frequent updates.&lt;/li&gt;\n&lt;li&gt;I also plan to bring in a &amp;quot;fixtures&amp;quot; tab to show game scores and history.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;I also updated the &lt;a href=\"https://premierleague.streamlit.app\"&gt;Streamlit dashboard&lt;/a&gt; to include the rest of the teams in the league with their form for their 5 previous games (only games played in the Premier League) in the &amp;quot;Top Teams Tab&amp;quot;.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve been learning a lot about code quality and whatnot so I wanted to share how I implemented some of my learnings.&lt;/p&gt;\n\n&lt;p&gt;Flowchart has been updated:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/j35bye26wuta1.png?width=1796&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=340250f3d2f43200e57ca248cb1935d91a200aba\"&gt;Flowchart&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks \ud83e\udee1&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/E5RkEeNtiOx_n3keeFD7y2mZVFNB5FygQ9Y6q2dIenY.jpg?auto=webp&amp;v=enabled&amp;s=2c587632c67a07b89e6842a9dd3f37419c65d61b", "width": 1280, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/E5RkEeNtiOx_n3keeFD7y2mZVFNB5FygQ9Y6q2dIenY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=002f43b3448db5e6361301bdbaead77d63601f6d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/E5RkEeNtiOx_n3keeFD7y2mZVFNB5FygQ9Y6q2dIenY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=952476ece38f5de8797306207f7c39c3d462b7b1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/E5RkEeNtiOx_n3keeFD7y2mZVFNB5FygQ9Y6q2dIenY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a6ac2f02e0e585c439bfbaf1c4c8accefe7254b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/E5RkEeNtiOx_n3keeFD7y2mZVFNB5FygQ9Y6q2dIenY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98ce183d313105e69598ee6e8900a64614d8bd74", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/E5RkEeNtiOx_n3keeFD7y2mZVFNB5FygQ9Y6q2dIenY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c63feafe7fa664a917fda5dfa034816f2cbdea49", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/E5RkEeNtiOx_n3keeFD7y2mZVFNB5FygQ9Y6q2dIenY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f05ea347bf85e629969925af89607a39b309dab3", "width": 1080, "height": 540}], "variants": {}, "id": "3gZoHpwb4UeknyioIxffQdkrkZhaIE_OItkbDbkxS3E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "12lyhbw", "is_robot_indexable": true, "report_reasons": null, "author": "digitalghost-dev", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12lyhbw/premier_league_project_infrastructure_update/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lyhbw/premier_league_project_infrastructure_update/", "subreddit_subscribers": 99117, "created_utc": 1681481275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "cc /u/cosmicBb0y", "author_fullname": "t2_3qlqubb2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ArjanCodes: How to Use Pandas With Pandera to Validate Your Data in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_12malx1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/-tU7fuUiq7w?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How to Use Pandas With Pandera to Validate Your Data in Python\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How to Use Pandas With Pandera to Validate Your Data in Python", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/-tU7fuUiq7w?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How to Use Pandas With Pandera to Validate Your Data in Python\"&gt;&lt;/iframe&gt;", "author_name": "ArjanCodes", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/-tU7fuUiq7w/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ArjanCodes"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/-tU7fuUiq7w?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How to Use Pandas With Pandera to Validate Your Data in Python\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/12malx1", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/pJryRzjFi8keLzZTP6aHwFCOIIEqur6MaBTgKpOZPO4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681501223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;cc &lt;a href=\"/u/cosmicBb0y\"&gt;/u/cosmicBb0y&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/-tU7fuUiq7w", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KQk5h-3dDIbI0zxJoeYHj7YOnAcc5X76Rjd-taBTIbQ.jpg?auto=webp&amp;v=enabled&amp;s=9a94916997565943bda38b1a61e337546537998d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/KQk5h-3dDIbI0zxJoeYHj7YOnAcc5X76Rjd-taBTIbQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6220ed74050f390859a25279a58f6417e4c1f93e", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/KQk5h-3dDIbI0zxJoeYHj7YOnAcc5X76Rjd-taBTIbQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c8e62a1f6e14b71c2f3bcfd371e8f5c35d7b5a33", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/KQk5h-3dDIbI0zxJoeYHj7YOnAcc5X76Rjd-taBTIbQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a44a3a4b66cf77773d1f41656b54d1b58099740", "width": 320, "height": 240}], "variants": {}, "id": "bEK7On-ViuRVvW7es_cui0WHxoZKbaxvhRL-8wwjTxc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12malx1", "is_robot_indexable": true, "report_reasons": null, "author": "EarthGoddessDude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12malx1/arjancodes_how_to_use_pandas_with_pandera_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/-tU7fuUiq7w", "subreddit_subscribers": 99117, "created_utc": 1681501223.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How to Use Pandas With Pandera to Validate Your Data in Python", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/-tU7fuUiq7w?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How to Use Pandas With Pandera to Validate Your Data in Python\"&gt;&lt;/iframe&gt;", "author_name": "ArjanCodes", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/-tU7fuUiq7w/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ArjanCodes"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How would you achieve this?   \n\n\nFor the brave, I will add some caveats, but I am still interested in your approach in the simple case described in the title.\n\nCaveats:\n\n\\- Postgres uses table partitioning (this means, that the WAL changes are associated with the partition tables and not the top-level table)\n\n\\- No dupes in Redshift. Redshift doesn't enforce primary key uniqueness, and so you may have duplicate entries for the same ID. That is undesirable.\n\n\\- Can it be done in AWS only?", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Move data from Postgres to Redshift with CDC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m2ukb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681489717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How would you achieve this?   &lt;/p&gt;\n\n&lt;p&gt;For the brave, I will add some caveats, but I am still interested in your approach in the simple case described in the title.&lt;/p&gt;\n\n&lt;p&gt;Caveats:&lt;/p&gt;\n\n&lt;p&gt;- Postgres uses table partitioning (this means, that the WAL changes are associated with the partition tables and not the top-level table)&lt;/p&gt;\n\n&lt;p&gt;- No dupes in Redshift. Redshift doesn&amp;#39;t enforce primary key uniqueness, and so you may have duplicate entries for the same ID. That is undesirable.&lt;/p&gt;\n\n&lt;p&gt;- Can it be done in AWS only?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12m2ukb", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12m2ukb/move_data_from_postgres_to_redshift_with_cdc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12m2ukb/move_data_from_postgres_to_redshift_with_cdc/", "subreddit_subscribers": 99117, "created_utc": 1681489717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just a bit of user research\n\n[View Poll](https://www.reddit.com/poll/12lwprj)", "author_fullname": "t2_txvugrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those of you with Lakehouse Architectures, how do you handle duplicate records?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lwprj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681477676.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just a bit of user research&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/12lwprj\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Company", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12lwprj", "is_robot_indexable": true, "report_reasons": null, "author": "prequel_co", "discussion_type": null, "num_comments": 19, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1681736876996, "options": [{"text": "Architecture never allows for duplicate records", "id": "22556891"}, {"text": "Upserts via table format like Iceberg, Delta, Hudi, etc", "id": "22556892"}, {"text": "Deduplicate at query time", "id": "22556893"}, {"text": "Other (elaborate in comments)", "id": "22556894"}, {"text": "No answer, just want to see results", "id": "22556895"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 432, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12lwprj/for_those_of_you_with_lakehouse_architectures_how/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/12lwprj/for_those_of_you_with_lakehouse_architectures_how/", "subreddit_subscribers": 99117, "created_utc": 1681477676.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, \n\nI was tasked with implementing BigQuery to our web application and sending data to it for our analytics team.\n\nAs I've had no whatsoever experience with BigQuery and didn't really know where or how to start, I asked you guys around here some questions:\n\n* [What should I know before using BigQuery, having traditional MySQL knowledge?](https://www.reddit.com/r/dataengineering/comments/12cbbw0/what_should_i_know_before_using_bigquery_having/)\n* [How should I understand query limitations in BigQuery?](https://www.reddit.com/r/dataengineering/comments/12cicp2/how_should_i_understand_query_limitations_in/)\n* [Using redis to batch data from various sources and then bulk insert into BigQuery, is this common?](https://www.reddit.com/r/dataengineering/comments/12dh2ht/using_redis_to_batch_data_from_various_sources/)\n\nWith the help and lead from you folks, I think I finally managed to get the bigger picture. At the same time, I've been writing things down which will hopefully help other software developers or traditional database users get into BigQuery, without going through several courses and documentation to get this \"Ahaaa, that's what it is used for, how it works, and how we should use it\" moment.\n\nI've written such down [as a guide here (preview)](https://hashnode.com/preview/643975a89ce48a000fb1867b), and would love to have some feedback (if possible), just to make sure that I'm not spreading misinformation.\n\nAnyway, thanks so much to this subreddit for all the help you have already given!", "author_fullname": "t2_n726hnv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Need feedback] I wrote a guide about the fundamentals of BigQuery for software developers &amp; traditional database users", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mccxv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681504289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, &lt;/p&gt;\n\n&lt;p&gt;I was tasked with implementing BigQuery to our web application and sending data to it for our analytics team.&lt;/p&gt;\n\n&lt;p&gt;As I&amp;#39;ve had no whatsoever experience with BigQuery and didn&amp;#39;t really know where or how to start, I asked you guys around here some questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/12cbbw0/what_should_i_know_before_using_bigquery_having/\"&gt;What should I know before using BigQuery, having traditional MySQL knowledge?&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/12cicp2/how_should_i_understand_query_limitations_in/\"&gt;How should I understand query limitations in BigQuery?&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/12dh2ht/using_redis_to_batch_data_from_various_sources/\"&gt;Using redis to batch data from various sources and then bulk insert into BigQuery, is this common?&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;With the help and lead from you folks, I think I finally managed to get the bigger picture. At the same time, I&amp;#39;ve been writing things down which will hopefully help other software developers or traditional database users get into BigQuery, without going through several courses and documentation to get this &amp;quot;Ahaaa, that&amp;#39;s what it is used for, how it works, and how we should use it&amp;quot; moment.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve written such down &lt;a href=\"https://hashnode.com/preview/643975a89ce48a000fb1867b\"&gt;as a guide here (preview)&lt;/a&gt;, and would love to have some feedback (if possible), just to make sure that I&amp;#39;m not spreading misinformation.&lt;/p&gt;\n\n&lt;p&gt;Anyway, thanks so much to this subreddit for all the help you have already given!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8OvFWeDpodmiwEWwwL-nlJxeGVB5QZvLbIhWtfKapmo.jpg?auto=webp&amp;v=enabled&amp;s=62defc0be251764d5b096ae39b8f3a0b70085635", "width": 1549, "height": 840}, "resolutions": [{"url": "https://external-preview.redd.it/8OvFWeDpodmiwEWwwL-nlJxeGVB5QZvLbIhWtfKapmo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=125555f86fe45e004504f7773a2f63e82f1c6bd4", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/8OvFWeDpodmiwEWwwL-nlJxeGVB5QZvLbIhWtfKapmo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1c8335002e4f1dd15e3155836126761a017f92c", "width": 216, "height": 117}, {"url": "https://external-preview.redd.it/8OvFWeDpodmiwEWwwL-nlJxeGVB5QZvLbIhWtfKapmo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac474d0f76b6dc0b062dca3efe72a57762ee3751", "width": 320, "height": 173}, {"url": "https://external-preview.redd.it/8OvFWeDpodmiwEWwwL-nlJxeGVB5QZvLbIhWtfKapmo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2386e612d99fc461faac9b23f8e31365cf50333", "width": 640, "height": 347}, {"url": "https://external-preview.redd.it/8OvFWeDpodmiwEWwwL-nlJxeGVB5QZvLbIhWtfKapmo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f88e776b52d428bc55ecc1e19740a898b4d82fb8", "width": 960, "height": 520}, {"url": "https://external-preview.redd.it/8OvFWeDpodmiwEWwwL-nlJxeGVB5QZvLbIhWtfKapmo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e695de79f1de20268e94f94b0f7a180c17e4d9b9", "width": 1080, "height": 585}], "variants": {}, "id": "Sv3ekwo8yyXSEkV18TtP4eDCKZ_ZqF5Ig7c267Z19ow"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12mccxv", "is_robot_indexable": true, "report_reasons": null, "author": "Fit-Swordfish-5533", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12mccxv/need_feedback_i_wrote_a_guide_about_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12mccxv/need_feedback_i_wrote_a_guide_about_the/", "subreddit_subscribers": 99117, "created_utc": 1681504289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_owff7qyq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I got annoyed by maintaining custom web scrapers, so I built an LLM-powered tool that can turn any website into an API.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": true, "name": "t3_12mvq2a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/jna11sdih0ua1/DASH_720.mp4?source=fallback", "height": 720, "width": 1280, "scrubber_media_url": "https://v.redd.it/jna11sdih0ua1/DASH_96.mp4", "dash_url": "https://v.redd.it/jna11sdih0ua1/DASHPlaylist.mpd?a=1684143496%2CZTNhNWQ5NWRlMjUxZWZkZWI0NGNlMDlkYjIxNGNjZGRkNjQ1ZGI2NGNiNGYzNzViZTE3MjY2YzhjOWM4OTA3Mw%3D%3D&amp;v=1&amp;f=sd", "duration": 52, "hls_url": "https://v.redd.it/jna11sdih0ua1/HLSPlaylist.m3u8?a=1684143496%2CMjVhM2Q4ZTEwNjNmNmMyY2I3ZjQ2MGIzYmY3YTU2YTI4MDQwNDliYmZmNjU3NzBkNzJjMDNmZDQ5ODZiN2JhYg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/q-SMWwc7T6M8a0hy8izibdRyMGqXSyeR5F4DU5wRrxI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681548580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/jna11sdih0ua1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GgMyP3n5rkYXExyHfe9qC6g2_apb4TkoaTfosmjm1Oc.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=05c3f704137efd1e4dc7c163cb8837782fb12e69", "width": 1280, "height": 769}, "resolutions": [{"url": "https://external-preview.redd.it/GgMyP3n5rkYXExyHfe9qC6g2_apb4TkoaTfosmjm1Oc.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=b220e69e933fb78e23542e1067b592ff119e6cc8", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/GgMyP3n5rkYXExyHfe9qC6g2_apb4TkoaTfosmjm1Oc.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=4c7d27429e47aa843c8709d87e14bf392c660e55", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/GgMyP3n5rkYXExyHfe9qC6g2_apb4TkoaTfosmjm1Oc.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=40835c781bfda0d9f7dbc2df2d834863cbedabec", "width": 320, "height": 192}, {"url": "https://external-preview.redd.it/GgMyP3n5rkYXExyHfe9qC6g2_apb4TkoaTfosmjm1Oc.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=903cf10e2bce9deaa877231dcd53aad4c14faff6", "width": 640, "height": 384}, {"url": "https://external-preview.redd.it/GgMyP3n5rkYXExyHfe9qC6g2_apb4TkoaTfosmjm1Oc.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=507b550afad67981f653bf005af379717a221509", "width": 960, "height": 576}, {"url": "https://external-preview.redd.it/GgMyP3n5rkYXExyHfe9qC6g2_apb4TkoaTfosmjm1Oc.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=cf94f1a9dbb18426f9fad75270ce158c876707b2", "width": 1080, "height": 648}], "variants": {}, "id": "xMDwm3Ahba4dSy_5xqOeVcmyYr6cbauHQInm6iRVRco"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "12mvq2a", "is_robot_indexable": true, "report_reasons": null, "author": "madredditscientist", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12mvq2a/i_got_annoyed_by_maintaining_custom_web_scrapers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/jna11sdih0ua1", "subreddit_subscribers": 99117, "created_utc": 1681548580.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/jna11sdih0ua1/DASH_720.mp4?source=fallback", "height": 720, "width": 1280, "scrubber_media_url": "https://v.redd.it/jna11sdih0ua1/DASH_96.mp4", "dash_url": "https://v.redd.it/jna11sdih0ua1/DASHPlaylist.mpd?a=1684143496%2CZTNhNWQ5NWRlMjUxZWZkZWI0NGNlMDlkYjIxNGNjZGRkNjQ1ZGI2NGNiNGYzNzViZTE3MjY2YzhjOWM4OTA3Mw%3D%3D&amp;v=1&amp;f=sd", "duration": 52, "hls_url": "https://v.redd.it/jna11sdih0ua1/HLSPlaylist.m3u8?a=1684143496%2CMjVhM2Q4ZTEwNjNmNmMyY2I3ZjQ2MGIzYmY3YTU2YTI4MDQwNDliYmZmNjU3NzBkNzJjMDNmZDQ5ODZiN2JhYg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_17hfml", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Business Intelligence 101: Data within Multidimensional View - Part 2", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 118, "top_awarded_type": null, "hide_score": false, "name": "t3_12mo5oe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/B7NDWZLQaKnSVHRZ5rOhBEd2SmxpB816jc5X8EEw2O8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681528836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datafriends.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.datafriends.co/categories/business-intelligence/business-intelligence-101-data-within-multidimensional-view-part-2/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-vj2E3id8ebBR3Z1cfuqljJgFOQr6nGsefTY14fs-nw.jpg?auto=webp&amp;v=enabled&amp;s=301554cca1dc6a23e5d53ec021f47f630abc40ed", "width": 1264, "height": 1073}, "resolutions": [{"url": "https://external-preview.redd.it/-vj2E3id8ebBR3Z1cfuqljJgFOQr6nGsefTY14fs-nw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=abe2774539d625801cfe30db6a52d76dd7cc49f5", "width": 108, "height": 91}, {"url": "https://external-preview.redd.it/-vj2E3id8ebBR3Z1cfuqljJgFOQr6nGsefTY14fs-nw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fcdbe89d7c6e7e5e08cab15e9f97890f2162741", "width": 216, "height": 183}, {"url": "https://external-preview.redd.it/-vj2E3id8ebBR3Z1cfuqljJgFOQr6nGsefTY14fs-nw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d3025c5ad8f96b061aa86f3385dc4e408a4cbaf0", "width": 320, "height": 271}, {"url": "https://external-preview.redd.it/-vj2E3id8ebBR3Z1cfuqljJgFOQr6nGsefTY14fs-nw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47c849a7937894bf66c9ea75fdff3ae0331bd332", "width": 640, "height": 543}, {"url": "https://external-preview.redd.it/-vj2E3id8ebBR3Z1cfuqljJgFOQr6nGsefTY14fs-nw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=484f2a81494fde0e4f96d9d9c04e3c210772780a", "width": 960, "height": 814}, {"url": "https://external-preview.redd.it/-vj2E3id8ebBR3Z1cfuqljJgFOQr6nGsefTY14fs-nw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67eb40c789eec371fa96be888ddcf4bc101a7522", "width": 1080, "height": 916}], "variants": {}, "id": "9cmMtWi_38dCpM-4sDVMXNrBJgGYfdInfQ4omvFbmwc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12mo5oe", "is_robot_indexable": true, "report_reasons": null, "author": "harlkwin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/12mo5oe/business_intelligence_101_data_within/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.datafriends.co/categories/business-intelligence/business-intelligence-101-data-within-multidimensional-view-part-2/", "subreddit_subscribers": 99117, "created_utc": 1681528836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need some guidance on who should be involved and what should be the responsibilities of this group? \n\nMembers:\nTechnical writer\nEngineer architect\nData engineer\nData Product mgr \n\nResponsibilities:\nSet guidelines for API standard format \nSet guidelines for standard field field format, definitions etc \nSign off on any APIs before they are release \n\nWhat else am I missing?", "author_fullname": "t2_6ighbrn4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with an API committee", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mgeab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681512102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need some guidance on who should be involved and what should be the responsibilities of this group? &lt;/p&gt;\n\n&lt;p&gt;Members:\nTechnical writer\nEngineer architect\nData engineer\nData Product mgr &lt;/p&gt;\n\n&lt;p&gt;Responsibilities:\nSet guidelines for API standard format \nSet guidelines for standard field field format, definitions etc \nSign off on any APIs before they are release &lt;/p&gt;\n\n&lt;p&gt;What else am I missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12mgeab", "is_robot_indexable": true, "report_reasons": null, "author": "Particular-Essay-361", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12mgeab/need_help_with_an_api_committee/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12mgeab/need_help_with_an_api_committee/", "subreddit_subscribers": 99117, "created_utc": 1681512102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nLooking for some suggestions. We get Kafka data landed directly in Snowflake. A table per event with two variant columns:\n\n- meta_data;\n- event_content.\n\nThe first contains a json payload with partition, offset, timestamp. The second contains the actual payload.\n\nThe first step is to flatten the data, which is performed as a view. We then have an incrementally loaded table of the flattened data, that uses a QUALIFY statement to remove duplicates, as Kafka will deliver at least once.\n\nWith the timestamp being contained in a variant column, how much overhead are we likely eating up each time we need to incrementally load our table? Has this been architected badly? It was done before my time. It might be fine, but it seems we might be chewing through a fair amount of compute as a result of this design.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advise on incremental process of Kafka data on Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m2azk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681488660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Looking for some suggestions. We get Kafka data landed directly in Snowflake. A table per event with two variant columns:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;meta_data;&lt;/li&gt;\n&lt;li&gt;event_content.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The first contains a json payload with partition, offset, timestamp. The second contains the actual payload.&lt;/p&gt;\n\n&lt;p&gt;The first step is to flatten the data, which is performed as a view. We then have an incrementally loaded table of the flattened data, that uses a QUALIFY statement to remove duplicates, as Kafka will deliver at least once.&lt;/p&gt;\n\n&lt;p&gt;With the timestamp being contained in a variant column, how much overhead are we likely eating up each time we need to incrementally load our table? Has this been architected badly? It was done before my time. It might be fine, but it seems we might be chewing through a fair amount of compute as a result of this design.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12m2azk", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12m2azk/advise_on_incremental_process_of_kafka_data_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12m2azk/advise_on_incremental_process_of_kafka_data_on/", "subreddit_subscribers": 99117, "created_utc": 1681488660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are currently looking for an alternative to our aging hadoop cluster (very tiny, \\~6 instances)\n\nDo you think Databend.rs would be an alternative? Is is production ready? Or is it too early?", "author_fullname": "t2_5o9ebpsl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Databend production ready?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m0mup", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681485422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently looking for an alternative to our aging hadoop cluster (very tiny, ~6 instances)&lt;/p&gt;\n\n&lt;p&gt;Do you think Databend.rs would be an alternative? Is is production ready? Or is it too early?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12m0mup", "is_robot_indexable": true, "report_reasons": null, "author": "mosquitsch", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12m0mup/is_databend_production_ready/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12m0mup/is_databend_production_ready/", "subreddit_subscribers": 99117, "created_utc": 1681485422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm evaluating couchbase for one of my projects. I require some of the features in the enterprise version but as it's just a small personal project I don't want to buy the license. \nI tried and it seems that they let you download the Couchbase server ee, Couchbase gateway ee and Couchbase lite ee without any license key, so can I just use it without a key forever?", "author_fullname": "t2_aygxdws", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Couchbase Enterprise license", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12mv5ln", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681546889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m evaluating couchbase for one of my projects. I require some of the features in the enterprise version but as it&amp;#39;s just a small personal project I don&amp;#39;t want to buy the license. \nI tried and it seems that they let you download the Couchbase server ee, Couchbase gateway ee and Couchbase lite ee without any license key, so can I just use it without a key forever?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12mv5ln", "is_robot_indexable": true, "report_reasons": null, "author": "__haha", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12mv5ln/couchbase_enterprise_license/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12mv5ln/couchbase_enterprise_license/", "subreddit_subscribers": 99117, "created_utc": 1681546889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I can only think of 1 benefit for federated learning scenarios where sharing a schema with other trusted clients could be beneficial, where machine learning can be carried out on heterogenous datasets that have different formats but require a ML model that solves a specific problem which everyone shares. \n\nThis involves having the data never leaving their internal systems, with a model trained locally. It would require the training set to have the same schema across all clients. \n\nAny other potential uses or benefits for this?", "author_fullname": "t2_bk9ikdyl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benefits of sharing schemas externally to other trusted parties?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mu6zk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681544183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can only think of 1 benefit for federated learning scenarios where sharing a schema with other trusted clients could be beneficial, where machine learning can be carried out on heterogenous datasets that have different formats but require a ML model that solves a specific problem which everyone shares. &lt;/p&gt;\n\n&lt;p&gt;This involves having the data never leaving their internal systems, with a model trained locally. It would require the training set to have the same schema across all clients. &lt;/p&gt;\n\n&lt;p&gt;Any other potential uses or benefits for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12mu6zk", "is_robot_indexable": true, "report_reasons": null, "author": "yinyanglanguage", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12mu6zk/benefits_of_sharing_schemas_externally_to_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12mu6zk/benefits_of_sharing_schemas_externally_to_other/", "subreddit_subscribers": 99117, "created_utc": 1681544183.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI'm loooking for advice on switching to a more modern data architecture/stack.\nI'm a senior data analyst and currently building analytics capabilities for a bank \u00een the fraud domain. \nI want to challenge the current reference arhitecture from datalake to data lakehouse.\nWe have the datalake on-premise using IBM tools like Netezza and also a analytics platform build on open source where we do a lot of data science stuff (similar with Databricks)\nHow do I convinge my architects to build a data lakehouse on our analytics platform?\nI'm working on creating some slides about the data lakehouse benefits and share with them, what should I keep in mind when discussing this?", "author_fullname": "t2_6l3fp7bm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switching to data lakehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mr7or", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681536224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m loooking for advice on switching to a more modern data architecture/stack.\nI&amp;#39;m a senior data analyst and currently building analytics capabilities for a bank \u00een the fraud domain. \nI want to challenge the current reference arhitecture from datalake to data lakehouse.\nWe have the datalake on-premise using IBM tools like Netezza and also a analytics platform build on open source where we do a lot of data science stuff (similar with Databricks)\nHow do I convinge my architects to build a data lakehouse on our analytics platform?\nI&amp;#39;m working on creating some slides about the data lakehouse benefits and share with them, what should I keep in mind when discussing this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12mr7or", "is_robot_indexable": true, "report_reasons": null, "author": "Wise_Solid1904", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12mr7or/switching_to_data_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12mr7or/switching_to_data_lakehouse/", "subreddit_subscribers": 99117, "created_utc": 1681536224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Where do you normally put your business logic in analytical application? Stored Procedures ,view or separate layer? Do you consider Transformation Logic as business layer? In my opinion, all the business logic related to data should remain within data world.   \n\n\nI have seen many data patterns where T are done by python or some other languages. I am not sure why would you want to do that. Why would you pull the data from analytical platform(Usually database and MPP database) which can handle complex query and transformation efficiently and again put it back to database. You are not severely underutilizing the power of these analytical platform. I am not against python but in my opinion there are lots of bad practice going on in the industry because of hype. Python definitely has very specific role in data engineering and I understand that but I have seen many patterns where people have been misusing it severely specially on transformation side.   \n\n\nExample, In one my previous teams, data engineer pull the data from snowflake using python which was running in a VM, wrote a lots of data frames, transformed it and put it back into snowflake. I meant why? It's like you bought a ferrari but you chose drive in busy street which has one lane.", "author_fullname": "t2_hnxu1e2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you put your business logic?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mfhhk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681510270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Where do you normally put your business logic in analytical application? Stored Procedures ,view or separate layer? Do you consider Transformation Logic as business layer? In my opinion, all the business logic related to data should remain within data world.   &lt;/p&gt;\n\n&lt;p&gt;I have seen many data patterns where T are done by python or some other languages. I am not sure why would you want to do that. Why would you pull the data from analytical platform(Usually database and MPP database) which can handle complex query and transformation efficiently and again put it back to database. You are not severely underutilizing the power of these analytical platform. I am not against python but in my opinion there are lots of bad practice going on in the industry because of hype. Python definitely has very specific role in data engineering and I understand that but I have seen many patterns where people have been misusing it severely specially on transformation side.   &lt;/p&gt;\n\n&lt;p&gt;Example, In one my previous teams, data engineer pull the data from snowflake using python which was running in a VM, wrote a lots of data frames, transformed it and put it back into snowflake. I meant why? It&amp;#39;s like you bought a ferrari but you chose drive in busy street which has one lane.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12mfhhk", "is_robot_indexable": true, "report_reasons": null, "author": "boogie_woogie_100", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12mfhhk/where_do_you_put_your_business_logic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12mfhhk/where_do_you_put_your_business_logic/", "subreddit_subscribers": 99117, "created_utc": 1681510270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For the folks who are self-hosting Dremio, what are your preferred method of hosting in AWS?\n\nI have deployed via the AWS Market option for the demo but long term will probably want some other option for deployment other than the AWS Market Cloudformation.\n\n&amp;#x200B;\n\nAre folks deploying Dremio via EC2 instances (in which we would define the infra with Terraform)?  Anyone running Dremio on Kubernetes?", "author_fullname": "t2_fwy0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dremio - Preferred Deployment Method for Self-Hosting in AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mcuus", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681505274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the folks who are self-hosting Dremio, what are your preferred method of hosting in AWS?&lt;/p&gt;\n\n&lt;p&gt;I have deployed via the AWS Market option for the demo but long term will probably want some other option for deployment other than the AWS Market Cloudformation.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Are folks deploying Dremio via EC2 instances (in which we would define the infra with Terraform)?  Anyone running Dremio on Kubernetes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12mcuus", "is_robot_indexable": true, "report_reasons": null, "author": "exemaitch", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12mcuus/dremio_preferred_deployment_method_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12mcuus/dremio_preferred_deployment_method_for/", "subreddit_subscribers": 99117, "created_utc": 1681505274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys - I got a question for you experts out there. I was trying to build a thesis on Modern Data Stack and I wanted to understand why does Snowflake-like products get big (in the data warehousing space) when Google, Amazon, Microsoft all have similar offerings available and all of them have one less challenge to face i.e. the distribution.\n\nAlso, now that Snowflake, Bigquery et al have made their own niche for so many years, why do new companies like Firebolt (an Israeli unicorn, started in 2019) come up every now and then and get so much funding?\n\nCan anyone please explain. TIA", "author_fullname": "t2_a4d2j3fh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Traditional Data tools vs new start-ups that are getting funded", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lvapt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681474642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys - I got a question for you experts out there. I was trying to build a thesis on Modern Data Stack and I wanted to understand why does Snowflake-like products get big (in the data warehousing space) when Google, Amazon, Microsoft all have similar offerings available and all of them have one less challenge to face i.e. the distribution.&lt;/p&gt;\n\n&lt;p&gt;Also, now that Snowflake, Bigquery et al have made their own niche for so many years, why do new companies like Firebolt (an Israeli unicorn, started in 2019) come up every now and then and get so much funding?&lt;/p&gt;\n\n&lt;p&gt;Can anyone please explain. TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12lvapt", "is_robot_indexable": true, "report_reasons": null, "author": "Living-Nobody-2727", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12lvapt/traditional_data_tools_vs_new_startups_that_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lvapt/traditional_data_tools_vs_new_startups_that_are/", "subreddit_subscribers": 99117, "created_utc": 1681474642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I can only think of 1 benefit for federated learning scenarios where sharing a schema with other trusted clients could be beneficial, where machine learning can be carried out on heterogenous datasets that have different formats but require a ML model that solves a specific problem which everyone shares. \n\nThis involves having the data never leaving their internal systems, with a model trained locally. It would require the training set to have the same schema across all clients. \n\nAny other potential uses or benefits for this?", "author_fullname": "t2_bk9ikdyl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benefits of sharing schemas externally to other trusted parties?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mu721", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681544187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can only think of 1 benefit for federated learning scenarios where sharing a schema with other trusted clients could be beneficial, where machine learning can be carried out on heterogenous datasets that have different formats but require a ML model that solves a specific problem which everyone shares. &lt;/p&gt;\n\n&lt;p&gt;This involves having the data never leaving their internal systems, with a model trained locally. It would require the training set to have the same schema across all clients. &lt;/p&gt;\n\n&lt;p&gt;Any other potential uses or benefits for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12mu721", "is_robot_indexable": true, "report_reasons": null, "author": "yinyanglanguage", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12mu721/benefits_of_sharing_schemas_externally_to_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12mu721/benefits_of_sharing_schemas_externally_to_other/", "subreddit_subscribers": 99117, "created_utc": 1681544187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm evaluating couchbase for one of my projects. I require some of the features in the enterprise version but as it's just a small personal project I don't want to buy the license.   \nI tried and it seems that they let you download the Couchbase server ee, Couchbase gateway ee and Couchbase lite ee without any license key, so can I just use it without a key forever?\n\nHow would that stop someone from using enterprise edition Couchbase for commercial purposes?", "author_fullname": "t2_99l81eq0h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Couchbase Enterprise license", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12msgxv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681539559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m evaluating couchbase for one of my projects. I require some of the features in the enterprise version but as it&amp;#39;s just a small personal project I don&amp;#39;t want to buy the license.&lt;br/&gt;\nI tried and it seems that they let you download the Couchbase server ee, Couchbase gateway ee and Couchbase lite ee without any license key, so can I just use it without a key forever?&lt;/p&gt;\n\n&lt;p&gt;How would that stop someone from using enterprise edition Couchbase for commercial purposes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12msgxv", "is_robot_indexable": true, "report_reasons": null, "author": "Mysterious-Reading72", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12msgxv/couchbase_enterprise_license/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12msgxv/couchbase_enterprise_license/", "subreddit_subscribers": 99117, "created_utc": 1681539559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am wondering a custom Data Catalog vs  existing solution like data hub. Our data schema is not huge but high skus for an e-commerce mart. Has anyone here seen/done building custom Data Catalog and succeeded/failed?", "author_fullname": "t2_6zaja793", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Custom Data Catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mp3yb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681531253.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681531054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am wondering a custom Data Catalog vs  existing solution like data hub. Our data schema is not huge but high skus for an e-commerce mart. Has anyone here seen/done building custom Data Catalog and succeeded/failed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12mp3yb", "is_robot_indexable": true, "report_reasons": null, "author": "Ambitious_Cucumber96", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12mp3yb/custom_data_catalog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12mp3yb/custom_data_catalog/", "subreddit_subscribers": 99117, "created_utc": 1681531054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "ETL can be one of the most expensive costs of data engineering for data warehousing.  Today, Databricks announced they were able to perform the typical ETL of an EDW, with all the transformations and rules, at breakneck speeds, and cheap cost.  Would love your thoughts on this, and can you try it out for yourselves and let us know what you think!  \n\n&amp;#x200B;\n\n[https://www.databricks.com/blog/2023/04/14/how-we-performed-etl-one-billion-records-under-1-delta-live-tables.html](https://www.databricks.com/blog/2023/04/14/how-we-performed-etl-one-billion-records-under-1-delta-live-tables.html)\n\n&amp;#x200B;\n\nDirect link to Repo to Repro: [https://github.com/shannon-barrow/databricks-tpc-di](https://github.com/shannon-barrow/databricks-tpc-di)", "author_fullname": "t2_8ke8s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL 1 Billion rows for less than $1 with Delta Lives Tables on Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12lx0mt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681478295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ETL can be one of the most expensive costs of data engineering for data warehousing.  Today, Databricks announced they were able to perform the typical ETL of an EDW, with all the transformations and rules, at breakneck speeds, and cheap cost.  Would love your thoughts on this, and can you try it out for yourselves and let us know what you think!  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.databricks.com/blog/2023/04/14/how-we-performed-etl-one-billion-records-under-1-delta-live-tables.html\"&gt;https://www.databricks.com/blog/2023/04/14/how-we-performed-etl-one-billion-records-under-1-delta-live-tables.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Direct link to Repo to Repro: &lt;a href=\"https://github.com/shannon-barrow/databricks-tpc-di\"&gt;https://github.com/shannon-barrow/databricks-tpc-di&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?auto=webp&amp;v=enabled&amp;s=15e7319434e1e103352a37e7fabfbd9456a168ef", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1176850e76031e71bb122f9c353101bd7abe6bf", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=429d70d1e08de4ce9c49426ac4caa101f4c3e264", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29cde5f1616959571c9b58b8c1c1900201c77f7e", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83b58b543aa8701ba0a87a3198960697d53ff22c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfd2d8ab37cf854034f841dea22a655dc91a5f3b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47ceb6115a4ccc0e21696967727505ec48f78f37", "width": 1080, "height": 567}], "variants": {}, "id": "RDPFo3n-9ZSpTUT0k9sCNnHc7tSD0wBu2TyDFfITIDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12lx0mt", "is_robot_indexable": true, "report_reasons": null, "author": "letmebefrankwithyou", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12lx0mt/etl_1_billion_rows_for_less_than_1_with_delta/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12lx0mt/etl_1_billion_rows_for_less_than_1_with_delta/", "subreddit_subscribers": 99117, "created_utc": 1681478295.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}