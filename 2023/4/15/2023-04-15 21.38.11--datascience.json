{"kind": "Listing", "data": {"after": null, "dist": 12, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_782al", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I just created `ipython-gpt`: query Chat GPT directly from Jupyter/IPython. Very early version, suggestions are welcome!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_12n4wna", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 66, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 66, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eqgDEHfj9RhzyRI8GJ0H6t1GViV1JorbxFWEFipn62Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681569184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/santiagobasulto/ipython-gpt", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?auto=webp&amp;v=enabled&amp;s=2d0e1689fb9e69e031a3cc7b92d499465b642fd2", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd3a4cd235b7f47aa5a7a6d4b8037a59607e1682", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1319cd47a547758fa8454835acc768367ef74974", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2c0c4e59726628de155b473081bc1f4632a4f3f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbc9c608c9055e9c92dbd2734f9130544dee54b8", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df28a37b4592073f1619cc9f99b47a5a219914fa", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b8923f0d62c03639c25836c452dc67cea9b288e", "width": 1080, "height": 540}], "variants": {}, "id": "PflMko7f-86H8GLCMfeylSkw84h0_b0MQ0qkcs9IhMA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n4wna", "is_robot_indexable": true, "report_reasons": null, "author": "santiagobasulto", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n4wna/i_just_created_ipythongpt_query_chat_gpt_directly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/santiagobasulto/ipython-gpt", "subreddit_subscribers": 873657, "created_utc": 1681569184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Say you train a model and find that the test scores are not going high. What methods do you most frequently follow from there apart from the ones mentioned in the title?", "author_fullname": "t2_4s456zpp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What methods do you usually use to improve model performance other than feature selection, hyperparameter tuning and trying out other ML algorithms?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mxnsc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681554066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you train a model and find that the test scores are not going high. What methods do you most frequently follow from there apart from the ones mentioned in the title?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12mxnsc", "is_robot_indexable": true, "report_reasons": null, "author": "dopplegangery", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12mxnsc/what_methods_do_you_usually_use_to_improve_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12mxnsc/what_methods_do_you_usually_use_to_improve_model/", "subreddit_subscribers": 873657, "created_utc": 1681554066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I think I already know the answer but want to get other opinions.\n\nI have two large data sets that I had access to in the past: 1 was shared with me on Github and is still available on their profile - Its real data but redacted for HIPAA reasons. \n\nAnother Data set I had been given access to for during my Capstone project  - Its also redacted and does not have any direct patient identifiers (Medical recor numbers but this means nothing to me or This is the only thing I'm worried about)\n\n&amp;#x200B;\n\nWould it be appropriate for me to re-use these data sets and put them up on my portfolio with data visualizations and as 'data cleaning' projects?\n\n&amp;#x200B;\n\nAny advice is appreciated", "author_fullname": "t2_k95d913", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it ethical or I guess allowed for me to use a prior data set for practice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mga65", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681511873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think I already know the answer but want to get other opinions.&lt;/p&gt;\n\n&lt;p&gt;I have two large data sets that I had access to in the past: 1 was shared with me on Github and is still available on their profile - Its real data but redacted for HIPAA reasons. &lt;/p&gt;\n\n&lt;p&gt;Another Data set I had been given access to for during my Capstone project  - Its also redacted and does not have any direct patient identifiers (Medical recor numbers but this means nothing to me or This is the only thing I&amp;#39;m worried about)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Would it be appropriate for me to re-use these data sets and put them up on my portfolio with data visualizations and as &amp;#39;data cleaning&amp;#39; projects?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12mga65", "is_robot_indexable": true, "report_reasons": null, "author": "Potential_Lettuce", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12mga65/is_it_ethical_or_i_guess_allowed_for_me_to_use_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12mga65/is_it_ethical_or_i_guess_allowed_for_me_to_use_a/", "subreddit_subscribers": 873657, "created_utc": 1681511873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What time series techniques/methods has anyone used here to successfully forecast minute level data? We\u2019ve tested out several common time series models (ARIMA, SARIMA, exponential smoothing, Prophet) with little success and are now testing LSTM models and having a bit more success. Any pieces of advice/insight are much appreciated!\n\nP.S. We have to forecast at the minute level. No aggregating to hourly, daily, etc. unfortunately.", "author_fullname": "t2_4eanykz0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Forecasting Minute Level Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n3m0b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681567709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What time series techniques/methods has anyone used here to successfully forecast minute level data? We\u2019ve tested out several common time series models (ARIMA, SARIMA, exponential smoothing, Prophet) with little success and are now testing LSTM models and having a bit more success. Any pieces of advice/insight are much appreciated!&lt;/p&gt;\n\n&lt;p&gt;P.S. We have to forecast at the minute level. No aggregating to hourly, daily, etc. unfortunately.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n3m0b", "is_robot_indexable": true, "report_reasons": null, "author": "_EY_YO_", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n3m0b/forecasting_minute_level_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12n3m0b/forecasting_minute_level_data/", "subreddit_subscribers": 873657, "created_utc": 1681567709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Accessing a sql server, using pyodbc, trying to get sql tables which I would like to merge into one csv/parquet or anything like that.\n\nPandas is too slow when using the pd.read_sql\n; what's my other alternative that I can use to ingest the table? Dask? Duckdb? Something directly from the pyodbc?", "author_fullname": "t2_rtximd9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accessing SQL server: using python: best way to ingest SQL tables because pandas can't handle tables that big?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n6lak", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681571269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Accessing a sql server, using pyodbc, trying to get sql tables which I would like to merge into one csv/parquet or anything like that.&lt;/p&gt;\n\n&lt;p&gt;Pandas is too slow when using the pd.read_sql\n; what&amp;#39;s my other alternative that I can use to ingest the table? Dask? Duckdb? Something directly from the pyodbc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n6lak", "is_robot_indexable": true, "report_reasons": null, "author": "macORnvidia", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n6lak/accessing_sql_server_using_python_best_way_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12n6lak/accessing_sql_server_using_python_best_way_to/", "subreddit_subscribers": 873657, "created_utc": 1681571269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Good morning everyone!\n\nI have 70+ features that I have to monitor over time, what would be the best approach to accomplish this? \n\nI want to be able to detect a drift that could prevent a decrease in performance of the model in production.", "author_fullname": "t2_914tfcv6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for recommendations to monitor / detect data drifts over time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12naikn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681576926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good morning everyone!&lt;/p&gt;\n\n&lt;p&gt;I have 70+ features that I have to monitor over time, what would be the best approach to accomplish this? &lt;/p&gt;\n\n&lt;p&gt;I want to be able to detect a drift that could prevent a decrease in performance of the model in production.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12naikn", "is_robot_indexable": true, "report_reasons": null, "author": "luisdanielTJ", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12naikn/looking_for_recommendations_to_monitor_detect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12naikn/looking_for_recommendations_to_monitor_detect/", "subreddit_subscribers": 873657, "created_utc": 1681576926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a manager of a DS team - 6 data scientists, no other profiles. We have one planning session every two weeks and one session per week where we share updates. I hold 1on1s on a weekly basis. We don't have daily standups. Has anyone tried daily standups for a purely DS team before? How did it turn out?", "author_fullname": "t2_c3smhalc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS teams and daily standups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12nhsvo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681591114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a manager of a DS team - 6 data scientists, no other profiles. We have one planning session every two weeks and one session per week where we share updates. I hold 1on1s on a weekly basis. We don&amp;#39;t have daily standups. Has anyone tried daily standups for a purely DS team before? How did it turn out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12nhsvo", "is_robot_indexable": true, "report_reasons": null, "author": "pnevmatikepirelli", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12nhsvo/ds_teams_and_daily_standups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12nhsvo/ds_teams_and_daily_standups/", "subreddit_subscribers": 873657, "created_utc": 1681591114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've decided I want to enroll in a data science masters program starting the 2024-25 academic year. I have a \\~3.6 cum gpa from a relatively large state school and have 2 pretty strong research experiences under my belt and should be able to get some pretty strong letters of recommendation for my applications. But I'm struggling finding information on good in person masters programs that suit my academics. Does anyone have any advice on where to look for programs and/or advice in general for applications? Also how high should I try to reach in terms of schools given my academics?", "author_fullname": "t2_aghpz5g9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science masters advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12nh0qv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681589604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve decided I want to enroll in a data science masters program starting the 2024-25 academic year. I have a ~3.6 cum gpa from a relatively large state school and have 2 pretty strong research experiences under my belt and should be able to get some pretty strong letters of recommendation for my applications. But I&amp;#39;m struggling finding information on good in person masters programs that suit my academics. Does anyone have any advice on where to look for programs and/or advice in general for applications? Also how high should I try to reach in terms of schools given my academics?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12nh0qv", "is_robot_indexable": true, "report_reasons": null, "author": "Careless-Tailor-2317", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12nh0qv/data_science_masters_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12nh0qv/data_science_masters_advice/", "subreddit_subscribers": 873657, "created_utc": 1681589604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I have a silly question. I own an Nvidia A100, and I'll honestly admit that I don't know what to do with it other than sell it. So here's my question: What would you do if you had an NVIDIA A100 80GB, besides selling it", "author_fullname": "t2_7ntcmrrxp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A100 80GB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nd8mm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681582296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have a silly question. I own an Nvidia A100, and I&amp;#39;ll honestly admit that I don&amp;#39;t know what to do with it other than sell it. So here&amp;#39;s my question: What would you do if you had an NVIDIA A100 80GB, besides selling it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12nd8mm", "is_robot_indexable": true, "report_reasons": null, "author": "mATIBLEv22", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12nd8mm/a100_80gb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12nd8mm/a100_80gb/", "subreddit_subscribers": 873657, "created_utc": 1681582296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I'm working on a binary classification problem and need some help in evaluating my model's performance. I have two datasets, 'train' and 'test', and my dataset has a large number of features. I used UMAP with n\\_components=2 to reduce the dimensions and plotted the points.\n\nHere's an image of the distribution of labels (0 and 1) on the reduced 2D space: \n\n&amp;#x200B;\n\n[train labels distribution](https://preview.redd.it/lxnlofpcx2ua1.jpg?width=638&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=144e68341ec119f9e8e95c64f2a924e453cf15b6)\n\nI found that there are distinct regions where the majority of points are either class 0 or 1, suggesting that my model should be able to classify them easily. However, there is an area where the two labels overlap, making it more challenging for my model to predict the correct class.\n\nIn this overlapping region, there are many training samples but very few test samples. As a result, my model achieves an F1 score of 0.75 for the training set and 0.96 for the test set, which are significantly different.\n\nHere's an image of the distribution of train and test points with 1 being train samples and 0 being test samples.\n\n[train test distribution](https://preview.redd.it/tulsvocqx2ua1.jpg?width=657&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=94f2f687810fb591b7f7f687138d5040311f912d)\n\nI'd appreciate any advice on how to assess my model's performance accurately in this scenario.", "author_fullname": "t2_7uwwf65z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "evaluating binary classification model with different train and test distribution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 111, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tulsvocqx2ua1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 82, "x": 108, "u": "https://preview.redd.it/tulsvocqx2ua1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=60496cbbb5842d9adcb0e9ace71d66c91fce3f16"}, {"y": 165, "x": 216, "u": "https://preview.redd.it/tulsvocqx2ua1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a85869e6188beca623ca2bf3d070da413f1e5e6b"}, {"y": 245, "x": 320, "u": "https://preview.redd.it/tulsvocqx2ua1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fc19b37c2442bf837d7b9b3d4861fd050beaf3a"}, {"y": 490, "x": 640, "u": "https://preview.redd.it/tulsvocqx2ua1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4a16b58e309c942dd105bae5971f6183d907ae9"}], "s": {"y": 504, "x": 657, "u": "https://preview.redd.it/tulsvocqx2ua1.jpg?width=657&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=94f2f687810fb591b7f7f687138d5040311f912d"}, "id": "tulsvocqx2ua1"}, "lxnlofpcx2ua1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 85, "x": 108, "u": "https://preview.redd.it/lxnlofpcx2ua1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b289f03e9f02d39fac8f37f8290c95b5dd1000d"}, {"y": 171, "x": 216, "u": "https://preview.redd.it/lxnlofpcx2ua1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20296214e024895c5b4291d1548114decc00405d"}, {"y": 254, "x": 320, "u": "https://preview.redd.it/lxnlofpcx2ua1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c57462f3816eb8800de78df003cef54a18b112c4"}], "s": {"y": 508, "x": 638, "u": "https://preview.redd.it/lxnlofpcx2ua1.jpg?width=638&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=144e68341ec119f9e8e95c64f2a924e453cf15b6"}, "id": "lxnlofpcx2ua1"}}, "name": "t3_12nb8ev", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zxNOp4XfX4LjYUp3bQ1cNUoMMR63xBM8s-U-ZTAVrNc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681578311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a binary classification problem and need some help in evaluating my model&amp;#39;s performance. I have two datasets, &amp;#39;train&amp;#39; and &amp;#39;test&amp;#39;, and my dataset has a large number of features. I used UMAP with n_components=2 to reduce the dimensions and plotted the points.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s an image of the distribution of labels (0 and 1) on the reduced 2D space: &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lxnlofpcx2ua1.jpg?width=638&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=144e68341ec119f9e8e95c64f2a924e453cf15b6\"&gt;train labels distribution&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I found that there are distinct regions where the majority of points are either class 0 or 1, suggesting that my model should be able to classify them easily. However, there is an area where the two labels overlap, making it more challenging for my model to predict the correct class.&lt;/p&gt;\n\n&lt;p&gt;In this overlapping region, there are many training samples but very few test samples. As a result, my model achieves an F1 score of 0.75 for the training set and 0.96 for the test set, which are significantly different.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s an image of the distribution of train and test points with 1 being train samples and 0 being test samples.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tulsvocqx2ua1.jpg?width=657&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=94f2f687810fb591b7f7f687138d5040311f912d\"&gt;train test distribution&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any advice on how to assess my model&amp;#39;s performance accurately in this scenario.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12nb8ev", "is_robot_indexable": true, "report_reasons": null, "author": "Hamdi_bks", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12nb8ev/evaluating_binary_classification_model_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12nb8ev/evaluating_binary_classification_model_with/", "subreddit_subscribers": 873657, "created_utc": 1681578311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Bias can occur at any stage of the data science process, from data collection to analysis and interpretation. As data science continues to grow in importance, it is essential to understand the different types of bias and how to mitigate them.\nPlease let me know if anything has been missed in this article.", "author_fullname": "t2_4hu9d8ja", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bias in Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "name": "t3_12n99vm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NUQPkX8i7ByE7smjYAOKbqMSlJZsDpWgTS38zS2bnqs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681574990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "link.medium.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Bias can occur at any stage of the data science process, from data collection to analysis and interpretation. As data science continues to grow in importance, it is essential to understand the different types of bias and how to mitigate them.\nPlease let me know if anything has been missed in this article.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://link.medium.com/XlYT9VTp1yb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?auto=webp&amp;v=enabled&amp;s=04602810f0f6af4557f3890b53b9be964ab3c16f", "width": 787, "height": 390}, "resolutions": [{"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae0983e4fd4ac67421dde8e27c25061ad7fbc7dd", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3bde715a1ba0e6b0b0d3d0090fb9401746e46bb3", "width": 216, "height": 107}, {"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fc28f4bdc1b29d75943fab13a3b0e122ad760cc", "width": 320, "height": 158}, {"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f9c3db594fe78b82d4e4c8f0bbf204a8f35769b", "width": 640, "height": 317}], "variants": {}, "id": "MtSJDgstA2YVB0n1HbH-1oFu_KmAVVKGZeUhV6UbBPA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n99vm", "is_robot_indexable": true, "report_reasons": null, "author": "Confident_Western", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n99vm/bias_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://link.medium.com/XlYT9VTp1yb", "subreddit_subscribers": 873657, "created_utc": 1681574990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "what are some exit opportunities after data science consulting? other than data scientist in industry, does consulting help you gain any skills for other jobs? Also, am i screwing myself over by becoming a data science consultant as a new grad \u2014 i\u2019ve seen some posts saying it sucks on this subreddit", "author_fullname": "t2_l3i27gan", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "exit opps after ds consulting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n5ykb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681570458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what are some exit opportunities after data science consulting? other than data scientist in industry, does consulting help you gain any skills for other jobs? Also, am i screwing myself over by becoming a data science consultant as a new grad \u2014 i\u2019ve seen some posts saying it sucks on this subreddit&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n5ykb", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway124929595", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n5ykb/exit_opps_after_ds_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12n5ykb/exit_opps_after_ds_consulting/", "subreddit_subscribers": 873657, "created_utc": 1681570458.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}