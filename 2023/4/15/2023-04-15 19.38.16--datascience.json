{"kind": "Listing", "data": {"after": null, "dist": 15, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am really struggling to get an interview lately for data science roles. I apply for jobs that my resume matches almost exactly, yet I get an automated email 1 day later saying that I am rejected and they are pursuing \"candidates that are more suited for the role\". How are other candidates more suited for a role when I am literally exactly suited for the role? I even apply for jobs that are in person/hybrid when I live 5 minutes away from their office, and literally meet every job requirement. I have an MS in Data Science. I live 5 minutes away. I have the exact number of years of experience you are asking for in all of the tech stacks you require, I have the exact same salary expectations, I have the exact same industry and domain level expertise, yet I'm still rejected instantly after applying. I even apply for jobs that literally just opened, as in they were posted less than 1 day ago, and I still get instantly rejected saying \"they decided to pursue other more suitable candidates for the role\". How have you already decided to pursue other candidates after the job has only been posted for 3 hours and I live 5 minutes away for an in person role and I meet all the requirements and also all of the \"nice to have's\"? I don't get it.", "author_fullname": "t2_fztbyin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatically rejected for every job I apply for, but I meet literally all of the requirements and \"nice to have\" requirements also", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m9hch", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 273, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 273, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681499548.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am really struggling to get an interview lately for data science roles. I apply for jobs that my resume matches almost exactly, yet I get an automated email 1 day later saying that I am rejected and they are pursuing &amp;quot;candidates that are more suited for the role&amp;quot;. How are other candidates more suited for a role when I am literally exactly suited for the role? I even apply for jobs that are in person/hybrid when I live 5 minutes away from their office, and literally meet every job requirement. I have an MS in Data Science. I live 5 minutes away. I have the exact number of years of experience you are asking for in all of the tech stacks you require, I have the exact same salary expectations, I have the exact same industry and domain level expertise, yet I&amp;#39;m still rejected instantly after applying. I even apply for jobs that literally just opened, as in they were posted less than 1 day ago, and I still get instantly rejected saying &amp;quot;they decided to pursue other more suitable candidates for the role&amp;quot;. How have you already decided to pursue other candidates after the job has only been posted for 3 hours and I live 5 minutes away for an in person role and I meet all the requirements and also all of the &amp;quot;nice to have&amp;#39;s&amp;quot;? I don&amp;#39;t get it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m9hch", "is_robot_indexable": true, "report_reasons": null, "author": "Edge779", "discussion_type": null, "num_comments": 130, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m9hch/automatically_rejected_for_every_job_i_apply_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m9hch/automatically_rejected_for_every_job_i_apply_for/", "subreddit_subscribers": 873595, "created_utc": 1681499548.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_782al", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I just created `ipython-gpt`: query Chat GPT directly from Jupyter/IPython. Very early version, suggestions are welcome!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_12n4wna", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eqgDEHfj9RhzyRI8GJ0H6t1GViV1JorbxFWEFipn62Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681569184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/santiagobasulto/ipython-gpt", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?auto=webp&amp;v=enabled&amp;s=2d0e1689fb9e69e031a3cc7b92d499465b642fd2", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd3a4cd235b7f47aa5a7a6d4b8037a59607e1682", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1319cd47a547758fa8454835acc768367ef74974", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2c0c4e59726628de155b473081bc1f4632a4f3f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbc9c608c9055e9c92dbd2734f9130544dee54b8", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df28a37b4592073f1619cc9f99b47a5a219914fa", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b8923f0d62c03639c25836c452dc67cea9b288e", "width": 1080, "height": 540}], "variants": {}, "id": "PflMko7f-86H8GLCMfeylSkw84h0_b0MQ0qkcs9IhMA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n4wna", "is_robot_indexable": true, "report_reasons": null, "author": "santiagobasulto", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n4wna/i_just_created_ipythongpt_query_chat_gpt_directly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/santiagobasulto/ipython-gpt", "subreddit_subscribers": 873595, "created_utc": 1681569184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Say you train a model and find that the test scores are not going high. What methods do you most frequently follow from there apart from the ones mentioned in the title?", "author_fullname": "t2_4s456zpp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What methods do you usually use to improve model performance other than feature selection, hyperparameter tuning and trying out other ML algorithms?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mxnsc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681554066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you train a model and find that the test scores are not going high. What methods do you most frequently follow from there apart from the ones mentioned in the title?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12mxnsc", "is_robot_indexable": true, "report_reasons": null, "author": "dopplegangery", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12mxnsc/what_methods_do_you_usually_use_to_improve_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12mxnsc/what_methods_do_you_usually_use_to_improve_model/", "subreddit_subscribers": 873595, "created_utc": 1681554066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I think I already know the answer but want to get other opinions.\n\nI have two large data sets that I had access to in the past: 1 was shared with me on Github and is still available on their profile - Its real data but redacted for HIPAA reasons. \n\nAnother Data set I had been given access to for during my Capstone project  - Its also redacted and does not have any direct patient identifiers (Medical recor numbers but this means nothing to me or This is the only thing I'm worried about)\n\n&amp;#x200B;\n\nWould it be appropriate for me to re-use these data sets and put them up on my portfolio with data visualizations and as 'data cleaning' projects?\n\n&amp;#x200B;\n\nAny advice is appreciated", "author_fullname": "t2_k95d913", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it ethical or I guess allowed for me to use a prior data set for practice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mga65", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681511873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think I already know the answer but want to get other opinions.&lt;/p&gt;\n\n&lt;p&gt;I have two large data sets that I had access to in the past: 1 was shared with me on Github and is still available on their profile - Its real data but redacted for HIPAA reasons. &lt;/p&gt;\n\n&lt;p&gt;Another Data set I had been given access to for during my Capstone project  - Its also redacted and does not have any direct patient identifiers (Medical recor numbers but this means nothing to me or This is the only thing I&amp;#39;m worried about)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Would it be appropriate for me to re-use these data sets and put them up on my portfolio with data visualizations and as &amp;#39;data cleaning&amp;#39; projects?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12mga65", "is_robot_indexable": true, "report_reasons": null, "author": "Potential_Lettuce", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12mga65/is_it_ethical_or_i_guess_allowed_for_me_to_use_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12mga65/is_it_ethical_or_i_guess_allowed_for_me_to_use_a/", "subreddit_subscribers": 873595, "created_utc": 1681511873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I used to work collecting and processing data for subsea construction, but we had a specific role and title and DA wasnt it. I'd like to learn more about being a data analyst and maybe even data scientist. What does a DA actually do? What are their inputs and outputs? I can Google just fine but that isnt going to give me the info you can. Thanks.", "author_fullname": "t2_lxz9oqjp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A DA does what...?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mmxh7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681526065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to work collecting and processing data for subsea construction, but we had a specific role and title and DA wasnt it. I&amp;#39;d like to learn more about being a data analyst and maybe even data scientist. What does a DA actually do? What are their inputs and outputs? I can Google just fine but that isnt going to give me the info you can. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12mmxh7", "is_robot_indexable": true, "report_reasons": null, "author": "grizgrin75", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12mmxh7/a_da_does_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12mmxh7/a_da_does_what/", "subreddit_subscribers": 873595, "created_utc": 1681526065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently graduated from my bachelors, and I majored in data science. I received an email regarding a data engineer position with a local bank company. \n\nAt first, they gave me a take-home assignment where I needed to format data, clean it up, etc, etc. Nothing too special nor difficult.\n\nAfterwards, they called me in for an interview. During the interview, they showed me an excel file that displays two sets of data (Sheet A &amp; B).\n\nThey said there was a mismatch in the values for both sets. Meaning, the sum value was not the same when it should have been. So, they asked me ways to explain ways I can fix the problem or pinpoint where the problem may occur. Long story short, my way was not as efficient as it should be. \n\nTo summarize, I screwed up, maybe I froze, and my brain stopped working as this was my first technical interview. \n\n&amp;#x200B;\n\n***But, I would like to know from the experts on this subreddit, how do you go about when seeing new datasets? What is the first thing that you will do or perhaps the first thing you will think of doing?***  \n\n\nI feel like, I need to make a flowchart when I am presented with a dataset. For instance, the first time I open a dataset, step 1 is to understand what the data is about. Step 2 is to identify the data types of the columns, etc etc. \n\n&amp;#x200B;\n\nTLDR;\n\nWhat should I do first or think of first when I am presented with data? What techniques or analysis should I perform first?\n\n&amp;#x200B;\n\nThank you in advance.", "author_fullname": "t2_46qj3zfd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Screwed up at an interview. Learning from mistakes. (Analysing data)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nbowy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681579229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently graduated from my bachelors, and I majored in data science. I received an email regarding a data engineer position with a local bank company. &lt;/p&gt;\n\n&lt;p&gt;At first, they gave me a take-home assignment where I needed to format data, clean it up, etc, etc. Nothing too special nor difficult.&lt;/p&gt;\n\n&lt;p&gt;Afterwards, they called me in for an interview. During the interview, they showed me an excel file that displays two sets of data (Sheet A &amp;amp; B).&lt;/p&gt;\n\n&lt;p&gt;They said there was a mismatch in the values for both sets. Meaning, the sum value was not the same when it should have been. So, they asked me ways to explain ways I can fix the problem or pinpoint where the problem may occur. Long story short, my way was not as efficient as it should be. &lt;/p&gt;\n\n&lt;p&gt;To summarize, I screwed up, maybe I froze, and my brain stopped working as this was my first technical interview. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;But, I would like to know from the experts on this subreddit, how do you go about when seeing new datasets? What is the first thing that you will do or perhaps the first thing you will think of doing?&lt;/em&gt;&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;I feel like, I need to make a flowchart when I am presented with a dataset. For instance, the first time I open a dataset, step 1 is to understand what the data is about. Step 2 is to identify the data types of the columns, etc etc. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;TLDR;&lt;/p&gt;\n\n&lt;p&gt;What should I do first or think of first when I am presented with data? What techniques or analysis should I perform first?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12nbowy", "is_robot_indexable": true, "report_reasons": null, "author": "FlyingRaijinEX", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12nbowy/screwed_up_at_an_interview_learning_from_mistakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12nbowy/screwed_up_at_an_interview_learning_from_mistakes/", "subreddit_subscribers": 873595, "created_utc": 1681579229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Accessing a sql server, using pyodbc, trying to get sql tables which I would like to merge into one csv/parquet or anything like that.\n\nPandas is too slow when using the pd.read_sql\n; what's my other alternative that I can use to ingest the table? Dask? Duckdb? Something directly from the pyodbc?", "author_fullname": "t2_rtximd9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accessing SQL server: using python: best way to ingest SQL tables because pandas can't handle tables that big?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n6lak", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681571269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Accessing a sql server, using pyodbc, trying to get sql tables which I would like to merge into one csv/parquet or anything like that.&lt;/p&gt;\n\n&lt;p&gt;Pandas is too slow when using the pd.read_sql\n; what&amp;#39;s my other alternative that I can use to ingest the table? Dask? Duckdb? Something directly from the pyodbc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n6lak", "is_robot_indexable": true, "report_reasons": null, "author": "macORnvidia", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n6lak/accessing_sql_server_using_python_best_way_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12n6lak/accessing_sql_server_using_python_best_way_to/", "subreddit_subscribers": 873595, "created_utc": 1681571269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What time series techniques/methods has anyone used here to successfully forecast minute level data? We\u2019ve tested out several common time series models (ARIMA, SARIMA, exponential smoothing, Prophet) with little success and are now testing LSTM models and having a bit more success. Any pieces of advice/insight are much appreciated!\n\nP.S. We have to forecast at the minute level. No aggregating to hourly, daily, etc. unfortunately.", "author_fullname": "t2_4eanykz0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Forecasting Minute Level Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n3m0b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681567709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What time series techniques/methods has anyone used here to successfully forecast minute level data? We\u2019ve tested out several common time series models (ARIMA, SARIMA, exponential smoothing, Prophet) with little success and are now testing LSTM models and having a bit more success. Any pieces of advice/insight are much appreciated!&lt;/p&gt;\n\n&lt;p&gt;P.S. We have to forecast at the minute level. No aggregating to hourly, daily, etc. unfortunately.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n3m0b", "is_robot_indexable": true, "report_reasons": null, "author": "_EY_YO_", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n3m0b/forecasting_minute_level_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12n3m0b/forecasting_minute_level_data/", "subreddit_subscribers": 873595, "created_utc": 1681567709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I have a silly question. I own an Nvidia A100, and I'll honestly admit that I don't know what to do with it other than sell it. So here's my question: What would you do if you had an NVIDIA A100 80GB, besides selling it", "author_fullname": "t2_7ntcmrrxp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A100 80GB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12nd8mm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681582296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have a silly question. I own an Nvidia A100, and I&amp;#39;ll honestly admit that I don&amp;#39;t know what to do with it other than sell it. So here&amp;#39;s my question: What would you do if you had an NVIDIA A100 80GB, besides selling it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12nd8mm", "is_robot_indexable": true, "report_reasons": null, "author": "mATIBLEv22", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12nd8mm/a100_80gb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12nd8mm/a100_80gb/", "subreddit_subscribers": 873595, "created_utc": 1681582296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi Data Scientist community,\n\nI currently have a master's in business, got a data scientist offer in a good company, but have already applied to PhD in business and have admission for fall. Do you think having a PhD will help me in the long term to achieve higher positions? Does having a PhD degree increase my chance of getting promotion/better positions in data science or do you think 5 years of industry experience is more valuable than a degree? When hiring, do you prefer a master's holder with 5 years of experience to a new Phd grad?\n\nI really appreciate all of your information and insight.", "author_fullname": "t2_9ap4pksw1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Quitting Data Scientist Job to pursue PhD worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12nblr1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681579053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Data Scientist community,&lt;/p&gt;\n\n&lt;p&gt;I currently have a master&amp;#39;s in business, got a data scientist offer in a good company, but have already applied to PhD in business and have admission for fall. Do you think having a PhD will help me in the long term to achieve higher positions? Does having a PhD degree increase my chance of getting promotion/better positions in data science or do you think 5 years of industry experience is more valuable than a degree? When hiring, do you prefer a master&amp;#39;s holder with 5 years of experience to a new Phd grad?&lt;/p&gt;\n\n&lt;p&gt;I really appreciate all of your information and insight.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12nblr1", "is_robot_indexable": true, "report_reasons": null, "author": "NinaSafe", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12nblr1/is_quitting_data_scientist_job_to_pursue_phd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12nblr1/is_quitting_data_scientist_job_to_pursue_phd/", "subreddit_subscribers": 873595, "created_utc": 1681579053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Good morning everyone!\n\nI have 70+ features that I have to monitor over time, what would be the best approach to accomplish this? \n\nI want to be able to detect a drift that could prevent a decrease in performance of the model in production.", "author_fullname": "t2_914tfcv6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for recommendations to monitor / detect data drifts over time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12naikn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681576926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good morning everyone!&lt;/p&gt;\n\n&lt;p&gt;I have 70+ features that I have to monitor over time, what would be the best approach to accomplish this? &lt;/p&gt;\n\n&lt;p&gt;I want to be able to detect a drift that could prevent a decrease in performance of the model in production.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12naikn", "is_robot_indexable": true, "report_reasons": null, "author": "luisdanielTJ", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12naikn/looking_for_recommendations_to_monitor_detect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12naikn/looking_for_recommendations_to_monitor_detect/", "subreddit_subscribers": 873595, "created_utc": 1681576926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Dear Community, I\u2019m working on a project, I have to extract data from Sql server with R.\nI tried any documentation about this subject  but I still have an error message like \u201c Driver SQL server 18 not found\u201d, I have installed this driver ! \nDo you have any sources that could help me ? \nMany thanks", "author_fullname": "t2_gnhzyiiu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Connect R and Sql Server On Mac OS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n8bx0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681573672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Dear Community, I\u2019m working on a project, I have to extract data from Sql server with R.\nI tried any documentation about this subject  but I still have an error message like \u201c Driver SQL server 18 not found\u201d, I have installed this driver ! \nDo you have any sources that could help me ? \nMany thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n8bx0", "is_robot_indexable": true, "report_reasons": null, "author": "hlama26", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n8bx0/connect_r_and_sql_server_on_mac_os/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12n8bx0/connect_r_and_sql_server_on_mac_os/", "subreddit_subscribers": 873595, "created_utc": 1681573672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I'm working on a binary classification problem and need some help in evaluating my model's performance. I have two datasets, 'train' and 'test', and my dataset has a large number of features. I used UMAP with n\\_components=2 to reduce the dimensions and plotted the points.\n\nHere's an image of the distribution of labels (0 and 1) on the reduced 2D space: \n\n&amp;#x200B;\n\n[train labels distribution](https://preview.redd.it/lxnlofpcx2ua1.jpg?width=638&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=144e68341ec119f9e8e95c64f2a924e453cf15b6)\n\nI found that there are distinct regions where the majority of points are either class 0 or 1, suggesting that my model should be able to classify them easily. However, there is an area where the two labels overlap, making it more challenging for my model to predict the correct class.\n\nIn this overlapping region, there are many training samples but very few test samples. As a result, my model achieves an F1 score of 0.75 for the training set and 0.96 for the test set, which are significantly different.\n\nHere's an image of the distribution of train and test points with 1 being train samples and 0 being test samples.\n\n[train test distribution](https://preview.redd.it/tulsvocqx2ua1.jpg?width=657&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=94f2f687810fb591b7f7f687138d5040311f912d)\n\nI'd appreciate any advice on how to assess my model's performance accurately in this scenario.", "author_fullname": "t2_7uwwf65z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "evaluating binary classification model with different train and test distribution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 111, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tulsvocqx2ua1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 82, "x": 108, "u": "https://preview.redd.it/tulsvocqx2ua1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=60496cbbb5842d9adcb0e9ace71d66c91fce3f16"}, {"y": 165, "x": 216, "u": "https://preview.redd.it/tulsvocqx2ua1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a85869e6188beca623ca2bf3d070da413f1e5e6b"}, {"y": 245, "x": 320, "u": "https://preview.redd.it/tulsvocqx2ua1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fc19b37c2442bf837d7b9b3d4861fd050beaf3a"}, {"y": 490, "x": 640, "u": "https://preview.redd.it/tulsvocqx2ua1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4a16b58e309c942dd105bae5971f6183d907ae9"}], "s": {"y": 504, "x": 657, "u": "https://preview.redd.it/tulsvocqx2ua1.jpg?width=657&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=94f2f687810fb591b7f7f687138d5040311f912d"}, "id": "tulsvocqx2ua1"}, "lxnlofpcx2ua1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 85, "x": 108, "u": "https://preview.redd.it/lxnlofpcx2ua1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b289f03e9f02d39fac8f37f8290c95b5dd1000d"}, {"y": 171, "x": 216, "u": "https://preview.redd.it/lxnlofpcx2ua1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20296214e024895c5b4291d1548114decc00405d"}, {"y": 254, "x": 320, "u": "https://preview.redd.it/lxnlofpcx2ua1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c57462f3816eb8800de78df003cef54a18b112c4"}], "s": {"y": 508, "x": 638, "u": "https://preview.redd.it/lxnlofpcx2ua1.jpg?width=638&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=144e68341ec119f9e8e95c64f2a924e453cf15b6"}, "id": "lxnlofpcx2ua1"}}, "name": "t3_12nb8ev", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zxNOp4XfX4LjYUp3bQ1cNUoMMR63xBM8s-U-ZTAVrNc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681578311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a binary classification problem and need some help in evaluating my model&amp;#39;s performance. I have two datasets, &amp;#39;train&amp;#39; and &amp;#39;test&amp;#39;, and my dataset has a large number of features. I used UMAP with n_components=2 to reduce the dimensions and plotted the points.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s an image of the distribution of labels (0 and 1) on the reduced 2D space: &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lxnlofpcx2ua1.jpg?width=638&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=144e68341ec119f9e8e95c64f2a924e453cf15b6\"&gt;train labels distribution&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I found that there are distinct regions where the majority of points are either class 0 or 1, suggesting that my model should be able to classify them easily. However, there is an area where the two labels overlap, making it more challenging for my model to predict the correct class.&lt;/p&gt;\n\n&lt;p&gt;In this overlapping region, there are many training samples but very few test samples. As a result, my model achieves an F1 score of 0.75 for the training set and 0.96 for the test set, which are significantly different.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s an image of the distribution of train and test points with 1 being train samples and 0 being test samples.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tulsvocqx2ua1.jpg?width=657&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=94f2f687810fb591b7f7f687138d5040311f912d\"&gt;train test distribution&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any advice on how to assess my model&amp;#39;s performance accurately in this scenario.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12nb8ev", "is_robot_indexable": true, "report_reasons": null, "author": "Hamdi_bks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12nb8ev/evaluating_binary_classification_model_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12nb8ev/evaluating_binary_classification_model_with/", "subreddit_subscribers": 873595, "created_utc": 1681578311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "what are some exit opportunities after data science consulting? other than data scientist in industry, does consulting help you gain any skills for other jobs? Also, am i screwing myself over by becoming a data science consultant as a new grad \u2014 i\u2019ve seen some posts saying it sucks on this subreddit", "author_fullname": "t2_l3i27gan", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "exit opps after ds consulting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n5ykb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681570458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what are some exit opportunities after data science consulting? other than data scientist in industry, does consulting help you gain any skills for other jobs? Also, am i screwing myself over by becoming a data science consultant as a new grad \u2014 i\u2019ve seen some posts saying it sucks on this subreddit&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n5ykb", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway124929595", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n5ykb/exit_opps_after_ds_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12n5ykb/exit_opps_after_ds_consulting/", "subreddit_subscribers": 873595, "created_utc": 1681570458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Bias can occur at any stage of the data science process, from data collection to analysis and interpretation. As data science continues to grow in importance, it is essential to understand the different types of bias and how to mitigate them.\nPlease let me know if anything has been missed in this article.", "author_fullname": "t2_4hu9d8ja", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bias in Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "name": "t3_12n99vm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NUQPkX8i7ByE7smjYAOKbqMSlJZsDpWgTS38zS2bnqs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681574990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "link.medium.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Bias can occur at any stage of the data science process, from data collection to analysis and interpretation. As data science continues to grow in importance, it is essential to understand the different types of bias and how to mitigate them.\nPlease let me know if anything has been missed in this article.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://link.medium.com/XlYT9VTp1yb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?auto=webp&amp;v=enabled&amp;s=04602810f0f6af4557f3890b53b9be964ab3c16f", "width": 787, "height": 390}, "resolutions": [{"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae0983e4fd4ac67421dde8e27c25061ad7fbc7dd", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3bde715a1ba0e6b0b0d3d0090fb9401746e46bb3", "width": 216, "height": 107}, {"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fc28f4bdc1b29d75943fab13a3b0e122ad760cc", "width": 320, "height": 158}, {"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f9c3db594fe78b82d4e4c8f0bbf204a8f35769b", "width": 640, "height": 317}], "variants": {}, "id": "MtSJDgstA2YVB0n1HbH-1oFu_KmAVVKGZeUhV6UbBPA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n99vm", "is_robot_indexable": true, "report_reasons": null, "author": "Confident_Western", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n99vm/bias_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://link.medium.com/XlYT9VTp1yb", "subreddit_subscribers": 873595, "created_utc": 1681574990.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}