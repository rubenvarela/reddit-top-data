{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am really struggling to get an interview lately for data science roles. I apply for jobs that my resume matches almost exactly, yet I get an automated email 1 day later saying that I am rejected and they are pursuing \"candidates that are more suited for the role\". How are other candidates more suited for a role when I am literally exactly suited for the role? I even apply for jobs that are in person/hybrid when I live 5 minutes away from their office, and literally meet every job requirement. I have an MS in Data Science. I live 5 minutes away. I have the exact number of years of experience you are asking for in all of the tech stacks you require, I have the exact same salary expectations, I have the exact same industry and domain level expertise, yet I'm still rejected instantly after applying. I even apply for jobs that literally just opened, as in they were posted less than 1 day ago, and I still get instantly rejected saying \"they decided to pursue other more suitable candidates for the role\". How have you already decided to pursue other candidates after the job has only been posted for 3 hours and I live 5 minutes away for an in person role and I meet all the requirements and also all of the \"nice to have's\"? I don't get it.", "author_fullname": "t2_fztbyin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatically rejected for every job I apply for, but I meet literally all of the requirements and \"nice to have\" requirements also", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m9hch", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 268, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 268, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681499548.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am really struggling to get an interview lately for data science roles. I apply for jobs that my resume matches almost exactly, yet I get an automated email 1 day later saying that I am rejected and they are pursuing &amp;quot;candidates that are more suited for the role&amp;quot;. How are other candidates more suited for a role when I am literally exactly suited for the role? I even apply for jobs that are in person/hybrid when I live 5 minutes away from their office, and literally meet every job requirement. I have an MS in Data Science. I live 5 minutes away. I have the exact number of years of experience you are asking for in all of the tech stacks you require, I have the exact same salary expectations, I have the exact same industry and domain level expertise, yet I&amp;#39;m still rejected instantly after applying. I even apply for jobs that literally just opened, as in they were posted less than 1 day ago, and I still get instantly rejected saying &amp;quot;they decided to pursue other more suitable candidates for the role&amp;quot;. How have you already decided to pursue other candidates after the job has only been posted for 3 hours and I live 5 minutes away for an in person role and I meet all the requirements and also all of the &amp;quot;nice to have&amp;#39;s&amp;quot;? I don&amp;#39;t get it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m9hch", "is_robot_indexable": true, "report_reasons": null, "author": "Edge779", "discussion_type": null, "num_comments": 126, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m9hch/automatically_rejected_for_every_job_i_apply_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m9hch/automatically_rejected_for_every_job_i_apply_for/", "subreddit_subscribers": 873528, "created_utc": 1681499548.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_782al", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I just created `ipython-gpt`: query Chat GPT directly from Jupyter/IPython. Very early version, suggestions are welcome!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_12n4wna", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eqgDEHfj9RhzyRI8GJ0H6t1GViV1JorbxFWEFipn62Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681569184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/santiagobasulto/ipython-gpt", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?auto=webp&amp;v=enabled&amp;s=2d0e1689fb9e69e031a3cc7b92d499465b642fd2", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd3a4cd235b7f47aa5a7a6d4b8037a59607e1682", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1319cd47a547758fa8454835acc768367ef74974", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2c0c4e59726628de155b473081bc1f4632a4f3f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbc9c608c9055e9c92dbd2734f9130544dee54b8", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df28a37b4592073f1619cc9f99b47a5a219914fa", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/e4v4w91MBeAl95wEAdTifneoRvGPWkjIf4abXhE1xNA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b8923f0d62c03639c25836c452dc67cea9b288e", "width": 1080, "height": 540}], "variants": {}, "id": "PflMko7f-86H8GLCMfeylSkw84h0_b0MQ0qkcs9IhMA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n4wna", "is_robot_indexable": true, "report_reasons": null, "author": "santiagobasulto", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n4wna/i_just_created_ipythongpt_query_chat_gpt_directly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/santiagobasulto/ipython-gpt", "subreddit_subscribers": 873528, "created_utc": 1681569184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Say you train a model and find that the test scores are not going high. What methods do you most frequently follow from there apart from the ones mentioned in the title?", "author_fullname": "t2_4s456zpp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What methods do you usually use to improve model performance other than feature selection, hyperparameter tuning and trying out other ML algorithms?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mxnsc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681554066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you train a model and find that the test scores are not going high. What methods do you most frequently follow from there apart from the ones mentioned in the title?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12mxnsc", "is_robot_indexable": true, "report_reasons": null, "author": "dopplegangery", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12mxnsc/what_methods_do_you_usually_use_to_improve_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12mxnsc/what_methods_do_you_usually_use_to_improve_model/", "subreddit_subscribers": 873528, "created_utc": 1681554066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I think I already know the answer but want to get other opinions.\n\nI have two large data sets that I had access to in the past: 1 was shared with me on Github and is still available on their profile - Its real data but redacted for HIPAA reasons. \n\nAnother Data set I had been given access to for during my Capstone project  - Its also redacted and does not have any direct patient identifiers (Medical recor numbers but this means nothing to me or This is the only thing I'm worried about)\n\n&amp;#x200B;\n\nWould it be appropriate for me to re-use these data sets and put them up on my portfolio with data visualizations and as 'data cleaning' projects?\n\n&amp;#x200B;\n\nAny advice is appreciated", "author_fullname": "t2_k95d913", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it ethical or I guess allowed for me to use a prior data set for practice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mga65", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681511873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think I already know the answer but want to get other opinions.&lt;/p&gt;\n\n&lt;p&gt;I have two large data sets that I had access to in the past: 1 was shared with me on Github and is still available on their profile - Its real data but redacted for HIPAA reasons. &lt;/p&gt;\n\n&lt;p&gt;Another Data set I had been given access to for during my Capstone project  - Its also redacted and does not have any direct patient identifiers (Medical recor numbers but this means nothing to me or This is the only thing I&amp;#39;m worried about)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Would it be appropriate for me to re-use these data sets and put them up on my portfolio with data visualizations and as &amp;#39;data cleaning&amp;#39; projects?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12mga65", "is_robot_indexable": true, "report_reasons": null, "author": "Potential_Lettuce", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12mga65/is_it_ethical_or_i_guess_allowed_for_me_to_use_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12mga65/is_it_ethical_or_i_guess_allowed_for_me_to_use_a/", "subreddit_subscribers": 873528, "created_utc": 1681511873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I used to work collecting and processing data for subsea construction, but we had a specific role and title and DA wasnt it. I'd like to learn more about being a data analyst and maybe even data scientist. What does a DA actually do? What are their inputs and outputs? I can Google just fine but that isnt going to give me the info you can. Thanks.", "author_fullname": "t2_lxz9oqjp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A DA does what...?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12mmxh7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681526065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to work collecting and processing data for subsea construction, but we had a specific role and title and DA wasnt it. I&amp;#39;d like to learn more about being a data analyst and maybe even data scientist. What does a DA actually do? What are their inputs and outputs? I can Google just fine but that isnt going to give me the info you can. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12mmxh7", "is_robot_indexable": true, "report_reasons": null, "author": "grizgrin75", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12mmxh7/a_da_does_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12mmxh7/a_da_does_what/", "subreddit_subscribers": 873528, "created_utc": 1681526065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all\n\nJust wondering, in my specific field it is very important for my bosses that subject-experts are involved in the feature selection process. They claim that we cannot fully automate feature selection as some are more prone to overfitting for instance, and subject-experts who understand the business and features should take a look.\n\nPersonally it makes the process very exhausting for me as I'm more dependent in others. \n\nnote: we work with regression and XGBOOST models.\n\n&amp;#x200B;\n\nWhat do you think of this practice, and how does it work in your workplace?", "author_fullname": "t2_5hjxl4ya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How automatic is your pipeline (or: how much do humans intervene in feature selection)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m4cwt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681492586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;Just wondering, in my specific field it is very important for my bosses that subject-experts are involved in the feature selection process. They claim that we cannot fully automate feature selection as some are more prone to overfitting for instance, and subject-experts who understand the business and features should take a look.&lt;/p&gt;\n\n&lt;p&gt;Personally it makes the process very exhausting for me as I&amp;#39;m more dependent in others. &lt;/p&gt;\n\n&lt;p&gt;note: we work with regression and XGBOOST models.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What do you think of this practice, and how does it work in your workplace?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m4cwt", "is_robot_indexable": true, "report_reasons": null, "author": "PlainPiano9", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m4cwt/how_automatic_is_your_pipeline_or_how_much_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m4cwt/how_automatic_is_your_pipeline_or_how_much_do/", "subreddit_subscribers": 873528, "created_utc": 1681492586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What time series techniques/methods has anyone used here to successfully forecast minute level data? We\u2019ve tested out several common time series models (ARIMA, SARIMA, exponential smoothing, Prophet) with little success and are now testing LSTM models and having a bit more success. Any pieces of advice/insight are much appreciated!\n\nP.S. We have to forecast at the minute level. No aggregating to hourly, daily, etc. unfortunately.", "author_fullname": "t2_4eanykz0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Forecasting Minute Level Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n3m0b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681567709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What time series techniques/methods has anyone used here to successfully forecast minute level data? We\u2019ve tested out several common time series models (ARIMA, SARIMA, exponential smoothing, Prophet) with little success and are now testing LSTM models and having a bit more success. Any pieces of advice/insight are much appreciated!&lt;/p&gt;\n\n&lt;p&gt;P.S. We have to forecast at the minute level. No aggregating to hourly, daily, etc. unfortunately.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n3m0b", "is_robot_indexable": true, "report_reasons": null, "author": "_EY_YO_", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n3m0b/forecasting_minute_level_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12n3m0b/forecasting_minute_level_data/", "subreddit_subscribers": 873528, "created_utc": 1681567709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Basically my dataset has hundreds of points of their own error attributed to them. I am fitting the model to the data, finding the derivative of that model at a certain point, then using that value in further calculations. \n\n&amp;#x200B;\n\nI can get an error estimate of the regression model, but what value would I attribute to a point estimated by that model which would also incorporate the inherent error of the dataset?", "author_fullname": "t2_15xfqn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Regression error of a single data point which already has error attributed to it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m6g2p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681495532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically my dataset has hundreds of points of their own error attributed to them. I am fitting the model to the data, finding the derivative of that model at a certain point, then using that value in further calculations. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I can get an error estimate of the regression model, but what value would I attribute to a point estimated by that model which would also incorporate the inherent error of the dataset?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m6g2p", "is_robot_indexable": true, "report_reasons": null, "author": "overhollowhills", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m6g2p/regression_error_of_a_single_data_point_which/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m6g2p/regression_error_of_a_single_data_point_which/", "subreddit_subscribers": 873528, "created_utc": 1681495532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Good morning everyone!\n\nI have 70+ features that I have to monitor over time, what would be the best approach to accomplish this? \n\nI want to be able to detect a drift that could prevent a decrease in performance of the model in production.", "author_fullname": "t2_914tfcv6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for recommendations to monitor / detect data drifts over time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12naikn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681576926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good morning everyone!&lt;/p&gt;\n\n&lt;p&gt;I have 70+ features that I have to monitor over time, what would be the best approach to accomplish this? &lt;/p&gt;\n\n&lt;p&gt;I want to be able to detect a drift that could prevent a decrease in performance of the model in production.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12naikn", "is_robot_indexable": true, "report_reasons": null, "author": "luisdanielTJ", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12naikn/looking_for_recommendations_to_monitor_detect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12naikn/looking_for_recommendations_to_monitor_detect/", "subreddit_subscribers": 873528, "created_utc": 1681576926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Dear Community, I\u2019m working on a project, I have to extract data from Sql server with R.\nI tried any documentation about this subject  but I still have an error message like \u201c Driver SQL server 18 not found\u201d, I have installed this driver ! \nDo you have any sources that could help me ? \nMany thanks", "author_fullname": "t2_gnhzyiiu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Connect R and Sql Server On Mac OS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12n8bx0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681573672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Dear Community, I\u2019m working on a project, I have to extract data from Sql server with R.\nI tried any documentation about this subject  but I still have an error message like \u201c Driver SQL server 18 not found\u201d, I have installed this driver ! \nDo you have any sources that could help me ? \nMany thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n8bx0", "is_robot_indexable": true, "report_reasons": null, "author": "hlama26", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n8bx0/connect_r_and_sql_server_on_mac_os/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12n8bx0/connect_r_and_sql_server_on_mac_os/", "subreddit_subscribers": 873528, "created_utc": 1681573672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Accessing a sql server, using pyodbc, trying to get sql tables which I would like to merge into one csv/parquet or anything like that.\n\nPandas is too slow when using the pd.read_sql\n; what's my other alternative that I can use to ingest the table? Dask? Duckdb? Something directly from the pyodbc?", "author_fullname": "t2_rtximd9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accessing SQL server: using python: best way to ingest SQL tables because pandas can't handle tables that big?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n6lak", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681571269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Accessing a sql server, using pyodbc, trying to get sql tables which I would like to merge into one csv/parquet or anything like that.&lt;/p&gt;\n\n&lt;p&gt;Pandas is too slow when using the pd.read_sql\n; what&amp;#39;s my other alternative that I can use to ingest the table? Dask? Duckdb? Something directly from the pyodbc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n6lak", "is_robot_indexable": true, "report_reasons": null, "author": "macORnvidia", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n6lak/accessing_sql_server_using_python_best_way_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12n6lak/accessing_sql_server_using_python_best_way_to/", "subreddit_subscribers": 873528, "created_utc": 1681571269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Original Monty Hall Problem.\n\nSuppose you're on a game show, and you're given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what's behind the doors, opens another door, say No. 3, which has a goat. He then says to you, \"Do you want to pick door No. 2?\" Is it to your advantage to switch your choice?\n\n\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n\nWe know that in the original problem, switching has the higher expected value.\n\n\nNow let\u2019s suppose that there are still 3 doors, but there are 2 players this time. Each player picks a unique door, and assuming that they didn\u2019t both pick the doors with the goat, the unpicked door is revealed to show a goat. \n\nUnder the original problem, it would be profitable for both players to switch their selection. But this just feels so counter intuitive?", "author_fullname": "t2_15wxtiq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monty Hall Problem with 2 players", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12m8q4g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681498487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Original Monty Hall Problem.&lt;/p&gt;\n\n&lt;p&gt;Suppose you&amp;#39;re on a game show, and you&amp;#39;re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what&amp;#39;s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, &amp;quot;Do you want to pick door No. 2?&amp;quot; Is it to your advantage to switch your choice?&lt;/p&gt;\n\n&lt;p&gt;\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014&lt;/p&gt;\n\n&lt;p&gt;We know that in the original problem, switching has the higher expected value.&lt;/p&gt;\n\n&lt;p&gt;Now let\u2019s suppose that there are still 3 doors, but there are 2 players this time. Each player picks a unique door, and assuming that they didn\u2019t both pick the doors with the goat, the unpicked door is revealed to show a goat. &lt;/p&gt;\n\n&lt;p&gt;Under the original problem, it would be profitable for both players to switch their selection. But this just feels so counter intuitive?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12m8q4g", "is_robot_indexable": true, "report_reasons": null, "author": "ThreeToInfinity", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12m8q4g/monty_hall_problem_with_2_players/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12m8q4g/monty_hall_problem_with_2_players/", "subreddit_subscribers": 873528, "created_utc": 1681498487.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Bias can occur at any stage of the data science process, from data collection to analysis and interpretation. As data science continues to grow in importance, it is essential to understand the different types of bias and how to mitigate them.\nPlease let me know if anything has been missed in this article.", "author_fullname": "t2_4hu9d8ja", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bias in Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": true, "name": "t3_12n99vm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NUQPkX8i7ByE7smjYAOKbqMSlJZsDpWgTS38zS2bnqs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681574990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "link.medium.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Bias can occur at any stage of the data science process, from data collection to analysis and interpretation. As data science continues to grow in importance, it is essential to understand the different types of bias and how to mitigate them.\nPlease let me know if anything has been missed in this article.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://link.medium.com/XlYT9VTp1yb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?auto=webp&amp;v=enabled&amp;s=04602810f0f6af4557f3890b53b9be964ab3c16f", "width": 787, "height": 390}, "resolutions": [{"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae0983e4fd4ac67421dde8e27c25061ad7fbc7dd", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3bde715a1ba0e6b0b0d3d0090fb9401746e46bb3", "width": 216, "height": 107}, {"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fc28f4bdc1b29d75943fab13a3b0e122ad760cc", "width": 320, "height": 158}, {"url": "https://external-preview.redd.it/-YicoavndzErMzSB6inpscao_7xfLushcqGtj8nteww.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f9c3db594fe78b82d4e4c8f0bbf204a8f35769b", "width": 640, "height": 317}], "variants": {}, "id": "MtSJDgstA2YVB0n1HbH-1oFu_KmAVVKGZeUhV6UbBPA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n99vm", "is_robot_indexable": true, "report_reasons": null, "author": "Confident_Western", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n99vm/bias_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://link.medium.com/XlYT9VTp1yb", "subreddit_subscribers": 873528, "created_utc": 1681574990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "what are some exit opportunities after data science consulting? other than data scientist in industry, does consulting help you gain any skills for other jobs? Also, am i screwing myself over by becoming a data science consultant as a new grad \u2014 i\u2019ve seen some posts saying it sucks on this subreddit", "author_fullname": "t2_l3i27gan", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "exit opps after ds consulting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12n5ykb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681570458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what are some exit opportunities after data science consulting? other than data scientist in industry, does consulting help you gain any skills for other jobs? Also, am i screwing myself over by becoming a data science consultant as a new grad \u2014 i\u2019ve seen some posts saying it sucks on this subreddit&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12n5ykb", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway124929595", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12n5ykb/exit_opps_after_ds_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12n5ykb/exit_opps_after_ds_consulting/", "subreddit_subscribers": 873528, "created_utc": 1681570458.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}