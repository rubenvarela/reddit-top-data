{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI had to quit my job as a senior data scientist in my company because of constant negative feedback from my managers, stress and health issues. I lost my confidence completely once I was put on a PIP and quit my job the next day. I don't have a job right now. \n\nI feel it's really hard but not impossible to bounce back from this \"failure\". First of all, I'm taking some time off to take care of my physical and mental health by doing strength training, meditation and Yoga, working on my diet, spending time with family etc. \n\nSecondly, I'm trying to focus on my strengths (computer vision and deep learning) and working on toy problems related to object detection and segmentation to get my mojo back. But the sheer amount of stuff that a data scientist is supposed to know is just too overwhelming for me. \n\nHas anyone experienced something similar? If yes, how did you bounce back from it? I'd love to read your stories.\n\nEdit - Thanks a lot for your comments, suggestions and stories. I will reply to each and everyone of you, but allow me some time. I feel really happy to be a part of such a supportive group.", "author_fullname": "t2_7aj1qm5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bouncing back after a bad work experience as a data scientist in an organization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12g7hdy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 174, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 174, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681047964.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681010958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I had to quit my job as a senior data scientist in my company because of constant negative feedback from my managers, stress and health issues. I lost my confidence completely once I was put on a PIP and quit my job the next day. I don&amp;#39;t have a job right now. &lt;/p&gt;\n\n&lt;p&gt;I feel it&amp;#39;s really hard but not impossible to bounce back from this &amp;quot;failure&amp;quot;. First of all, I&amp;#39;m taking some time off to take care of my physical and mental health by doing strength training, meditation and Yoga, working on my diet, spending time with family etc. &lt;/p&gt;\n\n&lt;p&gt;Secondly, I&amp;#39;m trying to focus on my strengths (computer vision and deep learning) and working on toy problems related to object detection and segmentation to get my mojo back. But the sheer amount of stuff that a data scientist is supposed to know is just too overwhelming for me. &lt;/p&gt;\n\n&lt;p&gt;Has anyone experienced something similar? If yes, how did you bounce back from it? I&amp;#39;d love to read your stories.&lt;/p&gt;\n\n&lt;p&gt;Edit - Thanks a lot for your comments, suggestions and stories. I will reply to each and everyone of you, but allow me some time. I feel really happy to be a part of such a supportive group.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12g7hdy", "is_robot_indexable": true, "report_reasons": null, "author": "madhav1113", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12g7hdy/bouncing_back_after_a_bad_work_experience_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12g7hdy/bouncing_back_after_a_bad_work_experience_as_a/", "subreddit_subscribers": 870146, "created_utc": 1681010958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been doing several interviews for \"Data Scientist\" positions. Yet, when I got the invitation, the title will changed to \"Data Engineer\" or \"Database Architect\" interviews. Me being curious, I went to the interview hoping it was just a silly mistake. Guess what? All these people will always said \"Yeah we need a full-stack data scientist\" or \"see? It's not a research project, Data Scientist only work when they are \"inspired\", other than that, no work done!\". I may have know nothing at all, but, is this a common thing? \n\nN.B. I came from a third world country that is left far behind in terms of technological advances. Let that sink in.", "author_fullname": "t2_3j4e33js", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is the term \"Full-Stack Data Scientist\" a thing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12gbzqa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681024430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been doing several interviews for &amp;quot;Data Scientist&amp;quot; positions. Yet, when I got the invitation, the title will changed to &amp;quot;Data Engineer&amp;quot; or &amp;quot;Database Architect&amp;quot; interviews. Me being curious, I went to the interview hoping it was just a silly mistake. Guess what? All these people will always said &amp;quot;Yeah we need a full-stack data scientist&amp;quot; or &amp;quot;see? It&amp;#39;s not a research project, Data Scientist only work when they are &amp;quot;inspired&amp;quot;, other than that, no work done!&amp;quot;. I may have know nothing at all, but, is this a common thing? &lt;/p&gt;\n\n&lt;p&gt;N.B. I came from a third world country that is left far behind in terms of technological advances. Let that sink in.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12gbzqa", "is_robot_indexable": true, "report_reasons": null, "author": "OxheadGreg123", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12gbzqa/is_the_term_fullstack_data_scientist_a_thing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12gbzqa/is_the_term_fullstack_data_scientist_a_thing/", "subreddit_subscribers": 870146, "created_utc": 1681024430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Twitter open-sourcing a majority of its recommendation algorithm offers an exciting opportunity for researchers, industry practitioners, and RecSys enthusiasts to closely examine how Twitter computes the recommended feed for the For You page.\n\n[Twitter's announcement](https://blog.twitter.com/en_us/topics/company/2023/a-new-era-of-transparency-for-twitter) | [Main GitHub Repo](https://github.com/twitter/the-algorithm/) | [ML GitHub Repo](https://github.com/twitter/the-algorithm-ml) | [Engineering Blog Post](https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm)\n\nTL;DR:\n\n**Candidate Generation**\n\n* For You Feed has an equal split for in-network tweets and out-of-network tweets.\n* In-network tweets are sourced using a logistic regression on features derived from Twitter's RealGraph framework (batch-updated daily).\n   *  Twitter also mentioned that the logistic regression model was trained several years ago and is being redesigned. \n* Some out-of-network tweets are sourced from 2 types of random walks over a real-time, in-memory, bipartite graph based on the GraphJet engine. While the majority is sourced from SimClusters in latent embedding space.\n* Pretrained Heterogeneous Information Network (TwHIN) embeddings are used for multiple downstream tasks including candidate generation and ranking.\n\n**Ranking**\n\n* Early ranking is done in EarlyBird using a logistic regression model.\n   * Twitter notes that \u201c*the current model was last trained several years ago, and uses some very strange features.*\u201d and they are working on training a new model. \n* A Parallel MaskNet (originally proposed by Weibo) is used as the heavy ranker.\n\n**Heuristics and Filtering**\n\n* Out-of-network competitor URLs and out-of-network tweets without second-degree connection are removed.\n* Blue verified accounts are boosted by a factor of 2 or 4 (out-of-network vs in-network).\n\n**Mixing**\n\n* Ads, promotions, and follow recommendations are blended into the feed.\n\nTwitter also released a lot of artifacts like the associated code, model configs, hyperparameters, input feature descriptions, feature weights, combined score calculation formulas, etc. that are immensely valuable for ML practitioners.\n\n&amp;#x200B;\n\nI made a post that compiles all the important ML-related information here: [https://blog.reachsumit.com/posts/2023/04/the-twitter-ml-algo/](https://blog.reachsumit.com/posts/2023/04/the-twitter-ml-algo/)", "author_fullname": "t2_ili6r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Twitter's For You Recommendation Algorithm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12gp6d3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681060157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Twitter open-sourcing a majority of its recommendation algorithm offers an exciting opportunity for researchers, industry practitioners, and RecSys enthusiasts to closely examine how Twitter computes the recommended feed for the For You page.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blog.twitter.com/en_us/topics/company/2023/a-new-era-of-transparency-for-twitter\"&gt;Twitter&amp;#39;s announcement&lt;/a&gt; | &lt;a href=\"https://github.com/twitter/the-algorithm/\"&gt;Main GitHub Repo&lt;/a&gt; | &lt;a href=\"https://github.com/twitter/the-algorithm-ml\"&gt;ML GitHub Repo&lt;/a&gt; | &lt;a href=\"https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm\"&gt;Engineering Blog Post&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;TL;DR:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Candidate Generation&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;For You Feed has an equal split for in-network tweets and out-of-network tweets.&lt;/li&gt;\n&lt;li&gt;In-network tweets are sourced using a logistic regression on features derived from Twitter&amp;#39;s RealGraph framework (batch-updated daily).\n\n&lt;ul&gt;\n&lt;li&gt; Twitter also mentioned that the logistic regression model was trained several years ago and is being redesigned. &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Some out-of-network tweets are sourced from 2 types of random walks over a real-time, in-memory, bipartite graph based on the GraphJet engine. While the majority is sourced from SimClusters in latent embedding space.&lt;/li&gt;\n&lt;li&gt;Pretrained Heterogeneous Information Network (TwHIN) embeddings are used for multiple downstream tasks including candidate generation and ranking.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Ranking&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Early ranking is done in EarlyBird using a logistic regression model.\n\n&lt;ul&gt;\n&lt;li&gt;Twitter notes that \u201c&lt;em&gt;the current model was last trained several years ago, and uses some very strange features.&lt;/em&gt;\u201d and they are working on training a new model. &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;A Parallel MaskNet (originally proposed by Weibo) is used as the heavy ranker.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Heuristics and Filtering&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Out-of-network competitor URLs and out-of-network tweets without second-degree connection are removed.&lt;/li&gt;\n&lt;li&gt;Blue verified accounts are boosted by a factor of 2 or 4 (out-of-network vs in-network).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Mixing&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Ads, promotions, and follow recommendations are blended into the feed.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Twitter also released a lot of artifacts like the associated code, model configs, hyperparameters, input feature descriptions, feature weights, combined score calculation formulas, etc. that are immensely valuable for ML practitioners.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I made a post that compiles all the important ML-related information here: &lt;a href=\"https://blog.reachsumit.com/posts/2023/04/the-twitter-ml-algo/\"&gt;https://blog.reachsumit.com/posts/2023/04/the-twitter-ml-algo/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/o3w9suNXRjckjrzlLhwLzSg4cpt6f6tUcMnvFkzQJUI.jpg?auto=webp&amp;v=enabled&amp;s=a9f65e64546c5d8e4e0a96c115c8d9b80d629366", "width": 768, "height": 403}, "resolutions": [{"url": "https://external-preview.redd.it/o3w9suNXRjckjrzlLhwLzSg4cpt6f6tUcMnvFkzQJUI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b7619545f964a18fe11a56d132965276fe4bbb2", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/o3w9suNXRjckjrzlLhwLzSg4cpt6f6tUcMnvFkzQJUI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7255911be5eddf4e66bb6009867688bd23b6aad9", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/o3w9suNXRjckjrzlLhwLzSg4cpt6f6tUcMnvFkzQJUI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd42aac78195a453b6f4f67a2a3401f0011418a4", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/o3w9suNXRjckjrzlLhwLzSg4cpt6f6tUcMnvFkzQJUI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=afba9af45a0b4cd9aea7be8cec1a5ab3c5f77cb9", "width": 640, "height": 335}], "variants": {}, "id": "gfbHrselNHruCl1eZs-KshHr1WRnpaRWfG4-sUAmSOY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12gp6d3", "is_robot_indexable": true, "report_reasons": null, "author": "SirCasms", "discussion_type": null, "num_comments": 6, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12gp6d3/twitters_for_you_recommendation_algorithm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12gp6d3/twitters_for_you_recommendation_algorithm/", "subreddit_subscribers": 870146, "created_utc": 1681060157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "o I'm studying economics in my second year and for the last month and a half I've been learning python and I've been  enjoying it.\nI've been reading about data science and I'm really interested in it, however I wanted to ask if there are any self taught data scientist and what resources you used.\nSorry if what I say seems naive.\nThank you\nEdit: I can't rely to all the comments, but I read and appreciate all of them! Thank you", "author_fullname": "t2_eo6c27us", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it realistic to become a self taught data scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12go95y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681071610.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681058111.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;o I&amp;#39;m studying economics in my second year and for the last month and a half I&amp;#39;ve been learning python and I&amp;#39;ve been  enjoying it.\nI&amp;#39;ve been reading about data science and I&amp;#39;m really interested in it, however I wanted to ask if there are any self taught data scientist and what resources you used.\nSorry if what I say seems naive.\nThank you\nEdit: I can&amp;#39;t rely to all the comments, but I read and appreciate all of them! Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12go95y", "is_robot_indexable": true, "report_reasons": null, "author": "Blufferg", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12go95y/is_it_realistic_to_become_a_self_taught_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12go95y/is_it_realistic_to_become_a_self_taught_data/", "subreddit_subscribers": 870146, "created_utc": 1681058111.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all, hopefully this isn't a duplicate question, search didn't turn up much. \n\nI'm a water resources engineer working for a small and highly specialized firm. We do a lot of work related to water quality modeling, long-term flow modeling in rivers, etc. My company has expressed interest in \"adding data science capabilities\" and, being a dork who loves learning new stuff, I volunteered to look into it. \n\nHowever, at this point I don't know enough to know what I don't know. I guess in my mind I'd like to work backward by identifying what capabilities would be useful for our line of work, then identifying how I can get there. \n\nI'm an intermediate programmer with a decent amount of Python experience. I learn well on my own but I'm not opposed to formal courses/bootcamps/EdX/etc if that would be useful - and my company will pay for tuition if it's something I can make a good argument for. \n\nWhere would you all recommend I start for someone not wanting a career change, but wanting to add data science capabilities with a geospatial/environmental focus?", "author_fullname": "t2_138odd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Water Resources+Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12glkza", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681051913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, hopefully this isn&amp;#39;t a duplicate question, search didn&amp;#39;t turn up much. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a water resources engineer working for a small and highly specialized firm. We do a lot of work related to water quality modeling, long-term flow modeling in rivers, etc. My company has expressed interest in &amp;quot;adding data science capabilities&amp;quot; and, being a dork who loves learning new stuff, I volunteered to look into it. &lt;/p&gt;\n\n&lt;p&gt;However, at this point I don&amp;#39;t know enough to know what I don&amp;#39;t know. I guess in my mind I&amp;#39;d like to work backward by identifying what capabilities would be useful for our line of work, then identifying how I can get there. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m an intermediate programmer with a decent amount of Python experience. I learn well on my own but I&amp;#39;m not opposed to formal courses/bootcamps/EdX/etc if that would be useful - and my company will pay for tuition if it&amp;#39;s something I can make a good argument for. &lt;/p&gt;\n\n&lt;p&gt;Where would you all recommend I start for someone not wanting a career change, but wanting to add data science capabilities with a geospatial/environmental focus?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12glkza", "is_robot_indexable": true, "report_reasons": null, "author": "deltaexdeltatee", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12glkza/water_resourcesdata_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12glkza/water_resourcesdata_science/", "subreddit_subscribers": 870146, "created_utc": 1681051913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What books, tutorials, or resources would you recommend for practicing EDAs? I've heard Kaggle kernels are an excellent way to start. \n\n1. My first goal is to figure out ways to draw insights from the data.\n2. My secondary objective is to understand how to draw predictions through models. I've been told that EDAs are used to understand your data for model selection and feature engineering.\n\nApart from the above, is there a way for me to gauge my expertise in EDAs through testing? Whenever I apply for an analytics position and submit an assignment, I tend to fall short of what is required.", "author_fullname": "t2_gwuxfiui", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Practicing Exploratory Data Analysis (EDA)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12gaok5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681020323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What books, tutorials, or resources would you recommend for practicing EDAs? I&amp;#39;ve heard Kaggle kernels are an excellent way to start. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;My first goal is to figure out ways to draw insights from the data.&lt;/li&gt;\n&lt;li&gt;My secondary objective is to understand how to draw predictions through models. I&amp;#39;ve been told that EDAs are used to understand your data for model selection and feature engineering.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Apart from the above, is there a way for me to gauge my expertise in EDAs through testing? Whenever I apply for an analytics position and submit an assignment, I tend to fall short of what is required.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12gaok5", "is_robot_indexable": true, "report_reasons": null, "author": "Artistic_Row_6581", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12gaok5/practicing_exploratory_data_analysis_eda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12gaok5/practicing_exploratory_data_analysis_eda/", "subreddit_subscribers": 870146, "created_utc": 1681020323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Where is the best place to find a senior level data scientist with ML experience that might be available to do some side consulting work?  Is there a goto for the community?   \n\n\nTrying to avoid places like upwork etc.  All the people I know are already at capacity.  I'm also assuming $150-350/hour is reasonable depending on experience.  (btw need advise on an project that's in requirements/discovery phase.  Involves price predictions and possibly computer vision. I'm too early in my learning of datasci/ML to do this work for my company). Thanks!", "author_fullname": "t2_15f4wq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I find senior-level data scientists for side consulting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12g8stp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681015194.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681014649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Where is the best place to find a senior level data scientist with ML experience that might be available to do some side consulting work?  Is there a goto for the community?   &lt;/p&gt;\n\n&lt;p&gt;Trying to avoid places like upwork etc.  All the people I know are already at capacity.  I&amp;#39;m also assuming $150-350/hour is reasonable depending on experience.  (btw need advise on an project that&amp;#39;s in requirements/discovery phase.  Involves price predictions and possibly computer vision. I&amp;#39;m too early in my learning of datasci/ML to do this work for my company). Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12g8stp", "is_robot_indexable": true, "report_reasons": null, "author": "billowingwallabees", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12g8stp/where_can_i_find_seniorlevel_data_scientists_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12g8stp/where_can_i_find_seniorlevel_data_scientists_for/", "subreddit_subscribers": 870146, "created_utc": 1681014649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, I am doing a my first training from scratch, so I  am a noob.\n\n1-I have a dataset  wit ha ddos atack, i did all the pre-processing data, and from 80 features I have left 38.\n\n2-I split this dataset in 3 datasets \"training, validation and test\" using 60,20 and 20.. I also used shuffle in tihs process.\n\n&amp;#x200B;\n\n3-I removed no numerical values and converted all my features to values between 0-1, did this for all datasets:\n\n`train\u00a0=\u00a0pd.read_csv(\"train_dataset.csv\")`  \n`train\u00a0=\u00a0train.drop(['dst_mac',\u00a0'src_ip',\u00a0'dst_ip',\u00a0'timestamp'],\u00a0axis=1)`  \n`scaler\u00a0=\u00a0MinMaxScaler()`  \n[`scaler.fit`](https://scaler.fit)`(train)`  \n`scaled\u00a0=\u00a0scaler.fit_transform(train)`  \n`train\u00a0=\u00a0pd.DataFrame(scaled,\u00a0columns=train.columns)`\n\n4-Applied the balanced class for all algorithms that I am using:\n\n `decisonTree\u00a0=\u00a0tree.DecisionTreeClassifier(class_weight=\"balanced\")`  \n`randomForest\u00a0=\u00a0RandomForestClassifier(class_weight=\"balanced\")`  \n`svm\u00a0=\u00a0svm.SVC(class_weight=\"balanced\")`\n\n5-Finaly traning and verifying the score for all the algorithhs:\n\n`decisonTree.fit(X=train[train.columns[0:38]],\u00a0y=train[train.columns[38]])`  \n`randomForest.fit(X=train[train.columns[0:38]],\u00a0y=train[train.columns[38]])`  \n[`svm.fit`](https://svm.fit)`(X=train[train.columns[0:38]],\u00a0y=train[train.columns[38]])`\n\n`randomForest.score(test[test.columns[0:38]],\u00a0test[test.columns[38]])` \n\n`svm.score(test[test.columns[0:38]],\u00a0test[test.columns[38]])`\n\n`decisonTree.score(test[test.columns[0:38]],\u00a0test[test.columns[38]])`\n\n&amp;#x200B;\n\nDid I miss any steps? or anything that I could do better? \n\nAdditionally, I got a really high prediction score. I saw that cold be a problem with my data some  Overfitting , is that the case ?\n\n&amp;#x200B;\n\nThanks.", "author_fullname": "t2_1411zu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I missing any step in my training?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12gfplh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681036405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I am doing a my first training from scratch, so I  am a noob.&lt;/p&gt;\n\n&lt;p&gt;1-I have a dataset  wit ha ddos atack, i did all the pre-processing data, and from 80 features I have left 38.&lt;/p&gt;\n\n&lt;p&gt;2-I split this dataset in 3 datasets &amp;quot;training, validation and test&amp;quot; using 60,20 and 20.. I also used shuffle in tihs process.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;3-I removed no numerical values and converted all my features to values between 0-1, did this for all datasets:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;train\u00a0=\u00a0pd.read_csv(&amp;quot;train_dataset.csv&amp;quot;)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;train\u00a0=\u00a0train.drop([&amp;#39;dst_mac&amp;#39;,\u00a0&amp;#39;src_ip&amp;#39;,\u00a0&amp;#39;dst_ip&amp;#39;,\u00a0&amp;#39;timestamp&amp;#39;],\u00a0axis=1)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;scaler\u00a0=\u00a0MinMaxScaler()&lt;/code&gt;&lt;br/&gt;\n&lt;a href=\"https://scaler.fit\"&gt;&lt;code&gt;scaler.fit&lt;/code&gt;&lt;/a&gt;&lt;code&gt;(train)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;scaled\u00a0=\u00a0scaler.fit_transform(train)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;train\u00a0=\u00a0pd.DataFrame(scaled,\u00a0columns=train.columns)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;4-Applied the balanced class for all algorithms that I am using:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;decisonTree\u00a0=\u00a0tree.DecisionTreeClassifier(class_weight=&amp;quot;balanced&amp;quot;)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;randomForest\u00a0=\u00a0RandomForestClassifier(class_weight=&amp;quot;balanced&amp;quot;)&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;svm\u00a0=\u00a0svm.SVC(class_weight=&amp;quot;balanced&amp;quot;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;5-Finaly traning and verifying the score for all the algorithhs:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;decisonTree.fit(X=train[train.columns[0:38]],\u00a0y=train[train.columns[38]])&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;randomForest.fit(X=train[train.columns[0:38]],\u00a0y=train[train.columns[38]])&lt;/code&gt;&lt;br/&gt;\n&lt;a href=\"https://svm.fit\"&gt;&lt;code&gt;svm.fit&lt;/code&gt;&lt;/a&gt;&lt;code&gt;(X=train[train.columns[0:38]],\u00a0y=train[train.columns[38]])&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;randomForest.score(test[test.columns[0:38]],\u00a0test[test.columns[38]])&lt;/code&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;svm.score(test[test.columns[0:38]],\u00a0test[test.columns[38]])&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;decisonTree.score(test[test.columns[0:38]],\u00a0test[test.columns[38]])&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Did I miss any steps? or anything that I could do better? &lt;/p&gt;\n\n&lt;p&gt;Additionally, I got a really high prediction score. I saw that cold be a problem with my data some  Overfitting , is that the case ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12gfplh", "is_robot_indexable": true, "report_reasons": null, "author": "raikone14", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12gfplh/am_i_missing_any_step_in_my_training/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12gfplh/am_i_missing_any_step_in_my_training/", "subreddit_subscribers": 870146, "created_utc": 1681036405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "PyGAD is a Python library for solving optimization problems using the genetic algorithm and training machine learning algorithms.\n\n* Docs: [https://pygad.readthedocs.io](https://pygad.readthedocs.io)\n* GitHub: [https://github.com/ahmedfgad/GeneticAlgorithmPython](https://github.com/ahmedfgad/GeneticAlgorithmPython)\n\nDonation:\n\n* Credit/Debit Card: [https://donate.stripe.com/eVa5kO866elKgM0144](https://donate.stripe.com/eVa5kO866elKgM0144)\n* Open Collective: opencollective.com/pygad\n* PayPal: paypal.me/ahmedfgad\n\nRelease Notes Summary (Check for full notes [https://pygad.readthedocs.io/en/latest/Footer.html#pygad-3-0-0](https://pygad.readthedocs.io/en/latest/Footer.html#pygad-3-0-0)):\n\n* The library has a new structure.\n* Use of the logging module instead of printing the outputs.\n* The GA instance is passed to the fitness function to access any property.\n* Solve an issue with parallel processing.", "author_fullname": "t2_a8i2hluj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PyGAD 3.0.0 Released! A Python Library for Building the Genetic Algorithm and Training Machine Learning Algorithms (Supports Keras and PyTorch)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12gslrm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681067575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;PyGAD is a Python library for solving optimization problems using the genetic algorithm and training machine learning algorithms.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Docs: &lt;a href=\"https://pygad.readthedocs.io\"&gt;https://pygad.readthedocs.io&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;GitHub: &lt;a href=\"https://github.com/ahmedfgad/GeneticAlgorithmPython\"&gt;https://github.com/ahmedfgad/GeneticAlgorithmPython&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Donation:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Credit/Debit Card: &lt;a href=\"https://donate.stripe.com/eVa5kO866elKgM0144\"&gt;https://donate.stripe.com/eVa5kO866elKgM0144&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Open Collective: opencollective.com/pygad&lt;/li&gt;\n&lt;li&gt;PayPal: paypal.me/ahmedfgad&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Release Notes Summary (Check for full notes &lt;a href=\"https://pygad.readthedocs.io/en/latest/Footer.html#pygad-3-0-0\"&gt;https://pygad.readthedocs.io/en/latest/Footer.html#pygad-3-0-0&lt;/a&gt;):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The library has a new structure.&lt;/li&gt;\n&lt;li&gt;Use of the logging module instead of printing the outputs.&lt;/li&gt;\n&lt;li&gt;The GA instance is passed to the fitness function to access any property.&lt;/li&gt;\n&lt;li&gt;Solve an issue with parallel processing.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12gslrm", "is_robot_indexable": true, "report_reasons": null, "author": "ahmed26gad", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12gslrm/pygad_300_released_a_python_library_for_building/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12gslrm/pygad_300_released_a_python_library_for_building/", "subreddit_subscribers": 870146, "created_utc": 1681067575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, i'm currently studying actuarial science and i'm trying to get to know more about the programming and data side of it.\n\nMy current desktop PC has a RX 5600XT GPU, and i'm thinking about upgrading it, but I've seen that certain libraries take advantage of the CUDA cores of nvidia gpus.\n\nI wanted to ask, is that advantage that much of a day-night change?  If so, I'd consider getting a new nvidia gpu over a radeon one, even though I can get a better deal for gaming with a radeon gpu.", "author_fullname": "t2_3uh62yoh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much of a need is an nvidia GPU?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12gpdga", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681060605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, i&amp;#39;m currently studying actuarial science and i&amp;#39;m trying to get to know more about the programming and data side of it.&lt;/p&gt;\n\n&lt;p&gt;My current desktop PC has a RX 5600XT GPU, and i&amp;#39;m thinking about upgrading it, but I&amp;#39;ve seen that certain libraries take advantage of the CUDA cores of nvidia gpus.&lt;/p&gt;\n\n&lt;p&gt;I wanted to ask, is that advantage that much of a day-night change?  If so, I&amp;#39;d consider getting a new nvidia gpu over a radeon one, even though I can get a better deal for gaming with a radeon gpu.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12gpdga", "is_robot_indexable": true, "report_reasons": null, "author": "dongabooo", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12gpdga/how_much_of_a_need_is_an_nvidia_gpu/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12gpdga/how_much_of_a_need_is_an_nvidia_gpu/", "subreddit_subscribers": 870146, "created_utc": 1681060605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am finishing up a completely unrelated bachelor's degree (in science) and am looking for jobs in data science and/or data analysis. However, I have two years of academic research experience analysing medical data using Python so am quite comfortable with Pandas, NumPy, SciPy, Scikit-learn, etc and have been using them pretty much daily for the past two years. I've been doing some novel machine learning classification work and have at least been doing well enough that I have had researchers from other universities contact me to analyse their data for them so I should be getting listed as an author in some publications this year as well. \n\nI'm not sure what kind of jobs I should be looking for with my experience. Since I don't have a degree in a related field or experience working in companies, I'm not sure if I have enough experience for an intermediate level role and am worried I wouldn't be good enough or that the work would be too different to what I've been doing and that I would mess it up and be a disappointment not having the same technical foundation as others since I am self-taught. But at the same time, I feel like all the roles I've seen at entry level are aimed towards graduates with no experience at all and so would be too low level for me as well as me not meeting the requirements for them (they ask for a degree in computer science or data science or other related field) as well as having terrible pay at barely above min wage.\n\nDoes anyone have any advice for me? Should I try go for intermediate roles anyway or just try for entry level? Also, with my background, do you think that I should be looking for roles as a data analyst or as a data scientist?\n\nEDIT: Not looking in the US but in NZ", "author_fullname": "t2_2e82j8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I be looking for entry or intermediate level jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12gh4s5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681042574.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681040715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am finishing up a completely unrelated bachelor&amp;#39;s degree (in science) and am looking for jobs in data science and/or data analysis. However, I have two years of academic research experience analysing medical data using Python so am quite comfortable with Pandas, NumPy, SciPy, Scikit-learn, etc and have been using them pretty much daily for the past two years. I&amp;#39;ve been doing some novel machine learning classification work and have at least been doing well enough that I have had researchers from other universities contact me to analyse their data for them so I should be getting listed as an author in some publications this year as well. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure what kind of jobs I should be looking for with my experience. Since I don&amp;#39;t have a degree in a related field or experience working in companies, I&amp;#39;m not sure if I have enough experience for an intermediate level role and am worried I wouldn&amp;#39;t be good enough or that the work would be too different to what I&amp;#39;ve been doing and that I would mess it up and be a disappointment not having the same technical foundation as others since I am self-taught. But at the same time, I feel like all the roles I&amp;#39;ve seen at entry level are aimed towards graduates with no experience at all and so would be too low level for me as well as me not meeting the requirements for them (they ask for a degree in computer science or data science or other related field) as well as having terrible pay at barely above min wage.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any advice for me? Should I try go for intermediate roles anyway or just try for entry level? Also, with my background, do you think that I should be looking for roles as a data analyst or as a data scientist?&lt;/p&gt;\n\n&lt;p&gt;EDIT: Not looking in the US but in NZ&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12gh4s5", "is_robot_indexable": true, "report_reasons": null, "author": "Mister__Wednesday", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12gh4s5/should_i_be_looking_for_entry_or_intermediate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12gh4s5/should_i_be_looking_for_entry_or_intermediate/", "subreddit_subscribers": 870146, "created_utc": 1681040715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\n&amp;#x200B;\n\nShort Intro:\n\nI am a major student of process engineering and I am currently writing my thesis. I am with a company and my job is to increase the amount of insights they get from their process data. The data source are direct querys to the SPS.  \nSince my university really lacks in the field of educating programming I have gained all my knowledge in self studys on small projects, but this task is on a whole diffrent level to what I had to deal with so far.\n\n&amp;#x200B;\n\nQuestion:\n\nCurrently I am getting my data via csv Imports, as it allows me to analyse the data without requiering ressources from other departments. I read the data once per week, the data comes from 8 Plants, with around 150 (currently) and 1000 (once we extend the evaluation on the whole process) individual Columns. Since the come from SPS they generate a data point roughly every 3 seconds, but not in an periodic intervall. My Idea was it to pre process the Data by generating a Dataset which calculates me:\n\n\\- moving Average\n\n\\-moving weigted Average\n\n\\- moving Median\n\n&amp;#x200B;\n\nevery 15 Seconds, eg 12:00:00, 12:00:15 etc.\n\n&amp;#x200B;\n\nI was hoping to get this done with the pandas.rolling() command, but I struggle to just get a datapoint to each of the required Timestamps.\n\n&amp;#x200B;\n\nPossible Solutions I see:\n\n1) Generate Datapoints on the required positions and append them.\n\n2) Interpolate a value at generated Datapoints\n\n3) calculate pandas.rolling(centered, freq=30s)\n\n4) Delete all the not necassary Datapoints\n\n&amp;#x200B;\n\nProblem: I am fairly confident this will yield me the required results, but I am afraid that once the amount of processed Data increases the Perfomance might lack (Hardware Ressources should be available in Theory, but still). Therfore I was wondering if you see a more efficent way to achieve the aspired result.", "author_fullname": "t2_g7w9sl9k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas on generalizing a time stamp based set of process parameters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12gda6o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681028611.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Short Intro:&lt;/p&gt;\n\n&lt;p&gt;I am a major student of process engineering and I am currently writing my thesis. I am with a company and my job is to increase the amount of insights they get from their process data. The data source are direct querys to the SPS.&lt;br/&gt;\nSince my university really lacks in the field of educating programming I have gained all my knowledge in self studys on small projects, but this task is on a whole diffrent level to what I had to deal with so far.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Question:&lt;/p&gt;\n\n&lt;p&gt;Currently I am getting my data via csv Imports, as it allows me to analyse the data without requiering ressources from other departments. I read the data once per week, the data comes from 8 Plants, with around 150 (currently) and 1000 (once we extend the evaluation on the whole process) individual Columns. Since the come from SPS they generate a data point roughly every 3 seconds, but not in an periodic intervall. My Idea was it to pre process the Data by generating a Dataset which calculates me:&lt;/p&gt;\n\n&lt;p&gt;- moving Average&lt;/p&gt;\n\n&lt;p&gt;-moving weigted Average&lt;/p&gt;\n\n&lt;p&gt;- moving Median&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;every 15 Seconds, eg 12:00:00, 12:00:15 etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was hoping to get this done with the pandas.rolling() command, but I struggle to just get a datapoint to each of the required Timestamps.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Possible Solutions I see:&lt;/p&gt;\n\n&lt;p&gt;1) Generate Datapoints on the required positions and append them.&lt;/p&gt;\n\n&lt;p&gt;2) Interpolate a value at generated Datapoints&lt;/p&gt;\n\n&lt;p&gt;3) calculate pandas.rolling(centered, freq=30s)&lt;/p&gt;\n\n&lt;p&gt;4) Delete all the not necassary Datapoints&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Problem: I am fairly confident this will yield me the required results, but I am afraid that once the amount of processed Data increases the Perfomance might lack (Hardware Ressources should be available in Theory, but still). Therfore I was wondering if you see a more efficent way to achieve the aspired result.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12gda6o", "is_robot_indexable": true, "report_reasons": null, "author": "26Pudding26", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12gda6o/ideas_on_generalizing_a_time_stamp_based_set_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12gda6o/ideas_on_generalizing_a_time_stamp_based_set_of/", "subreddit_subscribers": 870146, "created_utc": 1681028611.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently working on a personal project where I download my credit card transactions from the online banking website in a tabular format, and categorize them. For example, transaction with Walmart and No Frills should be categorized as \"grocery\" whereas Uber and local transit card would be considered \"transportation.\"\n\nI'm aware that Mastercard and Visa have APIs\\* for enterprise use, but I'll probably not afford it for my personal proejct. Anyone has recommendations for what would be good routes to take?\n\nI'm thinking if there's a list of merchants and its categories (if someone knows this, please let me know), I could use fuzzy matching to the merchant ID in the transaction records.\n\nNote: \n\n* Location is US/Canada.\n* The overall goal is to characterize monthly spending at a high level.\n\n\\*Example of Mastercard and Visa APIs\n\n* [https://developer.visa.com/capabilities/merchant\\_search](https://developer.visa.com/capabilities/merchant_search)\n* [https://developer.mastercard.com/merchant-identifier/documentation/](https://developer.mastercard.com/merchant-identifier/documentation/)", "author_fullname": "t2_aqy0xc2u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are my options for getting more info on credit card transaction merchants?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12g6z7o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681009574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working on a personal project where I download my credit card transactions from the online banking website in a tabular format, and categorize them. For example, transaction with Walmart and No Frills should be categorized as &amp;quot;grocery&amp;quot; whereas Uber and local transit card would be considered &amp;quot;transportation.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that Mastercard and Visa have APIs* for enterprise use, but I&amp;#39;ll probably not afford it for my personal proejct. Anyone has recommendations for what would be good routes to take?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking if there&amp;#39;s a list of merchants and its categories (if someone knows this, please let me know), I could use fuzzy matching to the merchant ID in the transaction records.&lt;/p&gt;\n\n&lt;p&gt;Note: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Location is US/Canada.&lt;/li&gt;\n&lt;li&gt;The overall goal is to characterize monthly spending at a high level.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;*Example of Mastercard and Visa APIs&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://developer.visa.com/capabilities/merchant_search\"&gt;https://developer.visa.com/capabilities/merchant_search&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://developer.mastercard.com/merchant-identifier/documentation/\"&gt;https://developer.mastercard.com/merchant-identifier/documentation/&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12g6z7o", "is_robot_indexable": true, "report_reasons": null, "author": "goldenfoxinthewild", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12g6z7o/what_are_my_options_for_getting_more_info_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12g6z7o/what_are_my_options_for_getting_more_info_on/", "subreddit_subscribers": 870146, "created_utc": 1681009574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_17hfml", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Business Intelligence 101: From Data to Insights - Part 1", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 111, "top_awarded_type": null, "hide_score": false, "name": "t3_12g0y0u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MrgG1z9mMKDp7LUU7XIl6HYkfXHYUCwCXq8ls645mDw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680993957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datafriends.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.datafriends.co/categories/business-intelligence/business-intelligence-101-from-data-to-insights-part-1/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u7utMrOQNTETure1lRy92JvoIP9-jLEMg4Cn_F4fawc.jpg?auto=webp&amp;v=enabled&amp;s=3a1e09177c346082baaddf81e5f9f323201e0ebc", "width": 6285, "height": 4997}, "resolutions": [{"url": "https://external-preview.redd.it/u7utMrOQNTETure1lRy92JvoIP9-jLEMg4Cn_F4fawc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=877afc4be485195ff99c46a6fa5a949f87607162", "width": 108, "height": 85}, {"url": "https://external-preview.redd.it/u7utMrOQNTETure1lRy92JvoIP9-jLEMg4Cn_F4fawc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=835da73a4a4b537543129b69f161bfe1a654f819", "width": 216, "height": 171}, {"url": "https://external-preview.redd.it/u7utMrOQNTETure1lRy92JvoIP9-jLEMg4Cn_F4fawc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc4f29ddfe675d83f97f8281100ebc22dd1af29b", "width": 320, "height": 254}, {"url": "https://external-preview.redd.it/u7utMrOQNTETure1lRy92JvoIP9-jLEMg4Cn_F4fawc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48279a10e2c0b833f1da0b3cb314d0c36d47d71d", "width": 640, "height": 508}, {"url": "https://external-preview.redd.it/u7utMrOQNTETure1lRy92JvoIP9-jLEMg4Cn_F4fawc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa43c810bc64f846ab000395123c3cb40f3af9f2", "width": 960, "height": 763}, {"url": "https://external-preview.redd.it/u7utMrOQNTETure1lRy92JvoIP9-jLEMg4Cn_F4fawc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=676ec2cf74e99b84f064899b6da923bf5b0fd8d8", "width": 1080, "height": 858}], "variants": {}, "id": "gDCpLLBw9ifErhw2olVp7nI8CCBYld-K99fUREkagIg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12g0y0u", "is_robot_indexable": true, "report_reasons": null, "author": "harlkwin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12g0y0u/business_intelligence_101_from_data_to_insights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.datafriends.co/categories/business-intelligence/business-intelligence-101-from-data-to-insights-part-1/", "subreddit_subscribers": 870146, "created_utc": 1680993957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello All, \n\nI am currently in Product Management and working on building my data science skills so that I can transition towards data science role in a year probably. \n\nAt the same time, I don't want to wait for a data science job to start using my skills. So I am very intrigued by the idea of working on a research papers , however can't figure out where to start. If you guys don't mind sharing, how did you guys got your first opportunity to write and publish a paper?", "author_fullname": "t2_ybwx6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Collaboration Opportunities on Research Paper", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12gudvz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681071436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All, &lt;/p&gt;\n\n&lt;p&gt;I am currently in Product Management and working on building my data science skills so that I can transition towards data science role in a year probably. &lt;/p&gt;\n\n&lt;p&gt;At the same time, I don&amp;#39;t want to wait for a data science job to start using my skills. So I am very intrigued by the idea of working on a research papers , however can&amp;#39;t figure out where to start. If you guys don&amp;#39;t mind sharing, how did you guys got your first opportunity to write and publish a paper?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12gudvz", "is_robot_indexable": true, "report_reasons": null, "author": "ajmaverick007", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12gudvz/looking_for_collaboration_opportunities_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12gudvz/looking_for_collaboration_opportunities_on/", "subreddit_subscribers": 870146, "created_utc": 1681071436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I\u2019m wrapping up my bachelors in Data Science and Statistics and I had a question over a phase of machine learning that I haven\u2019t heard touched on much. After I\u2019ve built an adequate model and have an accuracy I\u2019m happy with what\u2019s next in terms of utility for the model? How do I present that information to non DS folks in a meaningful way? I know visualizations are typically the next steps but from that point how do we make inferences about the results?", "author_fullname": "t2_16a4uu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s after model adequacy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12gszzz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681068426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I\u2019m wrapping up my bachelors in Data Science and Statistics and I had a question over a phase of machine learning that I haven\u2019t heard touched on much. After I\u2019ve built an adequate model and have an accuracy I\u2019m happy with what\u2019s next in terms of utility for the model? How do I present that information to non DS folks in a meaningful way? I know visualizations are typically the next steps but from that point how do we make inferences about the results?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12gszzz", "is_robot_indexable": true, "report_reasons": null, "author": "Lewisite466", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12gszzz/whats_after_model_adequacy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12gszzz/whats_after_model_adequacy/", "subreddit_subscribers": 870146, "created_utc": 1681068426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\n&amp;#x200B;\n\nI am currently working on the implementation of a more in depth Data Analysis for a production process of a bin company with multiple plants across the globe.\n\n&amp;#x200B;\n\nSince I have to embedd my workflow in the companys environment I am limited in the used tools and I have to work with the comany\u00b4s API\u00b4s. I expect the general Situation to look like this:\n\n&amp;#x200B;\n\n\\- retrieve Process Data from Database\n\n\\- retrive Product Spec etc. from SAP\n\n\\- process and combine data and send some of the Data back to SAP\n\n\\- Correlating Thread about the Data processing you can find [here](https://www.reddit.com/r/datascience/comments/12gda6o/ideas_on_generalizing_a_time_stamp_based_set_of/?utm_source=share&amp;utm_medium=web2x&amp;context=3)\n\n&amp;#x200B;\n\nIn order to get a better understanding please have a look at my diagramm.\n\n&amp;#x200B;\n\nI do expect severals hardships:\n\n\\- Database Firewalls (should be solveable)\n\n\\- SAP: I got told that it is in theory possible to send Data from a Knime process to SAP but I do not have any understanding of SAP in order to verify how that works and how the data is formatted.\n\n&amp;#x200B;\n\nTherfore my questions:\n\n\\- What is your general experience with Knime?\n\n\\- Do you see my approach viable?\n\n\\- How to link SAP to Knime\n\n&amp;#x200B;\n\nRegards Pudding\n\n[Process Diagram](https://preview.redd.it/ovncko8dptsa1.png?width=1400&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=26875ab5ea7ca9bead29792d099eba0ea0d05022)", "author_fullname": "t2_g7w9sl9k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build company Data workflow with knime combine and Databases, SAP and process Data with Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 28, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ovncko8dptsa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 21, "x": 108, "u": "https://preview.redd.it/ovncko8dptsa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a09003dc872fc8d78ec49404d4212274976c217b"}, {"y": 43, "x": 216, "u": "https://preview.redd.it/ovncko8dptsa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98a8083f1f5637a870423520a99c22b921e877ae"}, {"y": 64, "x": 320, "u": "https://preview.redd.it/ovncko8dptsa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=434fe7e66fd624ed875e5768e508b740cdc9e5f4"}, {"y": 128, "x": 640, "u": "https://preview.redd.it/ovncko8dptsa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98d267c5a3255e45114a59814a671b92a22b685d"}, {"y": 192, "x": 960, "u": "https://preview.redd.it/ovncko8dptsa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdb904432735c6bc27532fdb0f93f98ed4e37c1d"}, {"y": 216, "x": 1080, "u": "https://preview.redd.it/ovncko8dptsa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f9a7b04df4ba8d8712953b7afadd70b93d35da4"}], "s": {"y": 280, "x": 1400, "u": "https://preview.redd.it/ovncko8dptsa1.png?width=1400&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=26875ab5ea7ca9bead29792d099eba0ea0d05022"}, "id": "ovncko8dptsa1"}}, "name": "t3_12gdqv3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mjkDr4uii8ojpiDahE5C0fXH8mOdnxEcUEXVgFSevGw.jpg", "edited": 1681030558.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681030133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am currently working on the implementation of a more in depth Data Analysis for a production process of a bin company with multiple plants across the globe.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Since I have to embedd my workflow in the companys environment I am limited in the used tools and I have to work with the comany\u00b4s API\u00b4s. I expect the general Situation to look like this:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;- retrieve Process Data from Database&lt;/p&gt;\n\n&lt;p&gt;- retrive Product Spec etc. from SAP&lt;/p&gt;\n\n&lt;p&gt;- process and combine data and send some of the Data back to SAP&lt;/p&gt;\n\n&lt;p&gt;- Correlating Thread about the Data processing you can find &lt;a href=\"https://www.reddit.com/r/datascience/comments/12gda6o/ideas_on_generalizing_a_time_stamp_based_set_of/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In order to get a better understanding please have a look at my diagramm.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I do expect severals hardships:&lt;/p&gt;\n\n&lt;p&gt;- Database Firewalls (should be solveable)&lt;/p&gt;\n\n&lt;p&gt;- SAP: I got told that it is in theory possible to send Data from a Knime process to SAP but I do not have any understanding of SAP in order to verify how that works and how the data is formatted.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Therfore my questions:&lt;/p&gt;\n\n&lt;p&gt;- What is your general experience with Knime?&lt;/p&gt;\n\n&lt;p&gt;- Do you see my approach viable?&lt;/p&gt;\n\n&lt;p&gt;- How to link SAP to Knime&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Regards Pudding&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ovncko8dptsa1.png?width=1400&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=26875ab5ea7ca9bead29792d099eba0ea0d05022\"&gt;Process Diagram&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12gdqv3", "is_robot_indexable": true, "report_reasons": null, "author": "26Pudding26", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12gdqv3/build_company_data_workflow_with_knime_combine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12gdqv3/build_company_data_workflow_with_knime_combine/", "subreddit_subscribers": 870146, "created_utc": 1681030133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a data-set with a few features that have a bunch of NaNs (about 70% of the feature column).  Keep in mind I have to keep those NaNs since imputing them with zeroes does not make any sense for my business use case. Using an XGboost model should account for this since it tries both directions of the split (left and right) and calculates the gain of the split for each direction and then assigns the missing value to the direction that results in the highest gain.\n\nHowever, when I create a summary SHAP plot, the features are kind of non-sensical in the sense of their impact on the outcome being counter-intuitive to what I should be expecting. I was wondering if it\u2019s a way SHAP handles missing values that\u2019s different from XGboost? Any insights/discussion regarding missing values here would be highly appreciated.\n\nEDIT: For context, the model is a binary classification model but with heavy imbalance (so I ended up optimizing for F1/F2 metric and applied cost sensitive learning).", "author_fullname": "t2_5oa45vrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Impact of NaNs on SHAP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12g1gsc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680995509.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680995184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a data-set with a few features that have a bunch of NaNs (about 70% of the feature column).  Keep in mind I have to keep those NaNs since imputing them with zeroes does not make any sense for my business use case. Using an XGboost model should account for this since it tries both directions of the split (left and right) and calculates the gain of the split for each direction and then assigns the missing value to the direction that results in the highest gain.&lt;/p&gt;\n\n&lt;p&gt;However, when I create a summary SHAP plot, the features are kind of non-sensical in the sense of their impact on the outcome being counter-intuitive to what I should be expecting. I was wondering if it\u2019s a way SHAP handles missing values that\u2019s different from XGboost? Any insights/discussion regarding missing values here would be highly appreciated.&lt;/p&gt;\n\n&lt;p&gt;EDIT: For context, the model is a binary classification model but with heavy imbalance (so I ended up optimizing for F1/F2 metric and applied cost sensitive learning).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12g1gsc", "is_robot_indexable": true, "report_reasons": null, "author": "amsr7691", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12g1gsc/impact_of_nans_on_shap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12g1gsc/impact_of_nans_on_shap/", "subreddit_subscribers": 870146, "created_utc": 1680995184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have an assignment for university. I have done 70% of the work, but now I'm stuck. I was given a csv data containing census data. I have to first clean the data, analyze the trends (using python) and answer the questions ( a. and b.) mentioned below. \n\nCan somebody help with what kind of graphs/ visualizations I have to create in order to answer the two questions. \n\nI have created age pyramid chart. but I need help with others. (see hints sections)\n\n&amp;#x200B;\n\n**Assignment brief -** \n\nThe mock census you will be given contains randomly generate data using the Faker package in Python. It has been generated in a similar manner to (and designed to directly emulate the format of) the 1881 census of the UK wherein only a few questions were asked of the population. The fields recorded are as follows:\n\n1. Street Number (this is set to \u201c1\u201d if it is a unique dwelling); \n\n2. Street Name; 3. First Name of occupant; \n\n4. Surname of occupant; \n\n5. Age of occupant; \n\n6. Relationship to the \u201cHead\u201d of the household (anyone aged over 18 can be a \u201cHead\u201d \u2013 they are simply the person who had the responsibility to fill in the census details); \n\n7. Marital status (one of: Single, Married, Divorced, Widowed, or \u201cNA\u201d in the case of minors); \n\n8. Gender (one of: Male, Female; note that other responses were not implemented in 1881); \n\n9. Occupation (this field was implemented in a modern style, rather than typical 1881 occupations); \n\n10. Infirmity (we have implemented a limited set of infirmities following the style of 1881); \n\n11. Religion (we have implemented a set of real-world religions).  \n\n&amp;#x200B;\n\n**The Task.**\n\nThe town from the census is a modestly sized one sandwiched between two much larger cities that it is connected to by motorways. The town does not have a university, but students do live in the town and commute to the nearby cities. Once you have a cleaned dataset to analyze, your task is to decide the following:  \n\n**(a)** What should be built on an unoccupied plot of land that the local government wishes to develop? Your choices are: \n\n1. High-density housing. This should be built if the population is significantly expanding. \n2. Low-density housing. This should be built if the population is \u201caffluent\u201d and there is demand for large family housing. \n3. Train station. There are potentially a lot of commuters in the town and building a train station could take pressure off the roads. But how will you identify commuters? \n4. Religious building. There is already one place of worship for Catholics in the town. Is there demand for a second Church (if so, which denomination?), or for a different religious building? \n5. Emergency medical building. Not a full hospital, but a minor injuries centre. This should be built if there are many injuries or future pregnancies likely in the population. \n6. Something else? \n\nWhichever you choose, you must justify it from the data provided to you and argue it is a priority against other choices.  \n\n **(b)** Which one of the following options should be invested in? \n\n1. Employment and training. If there is evidence for a lot of unemployment, we should retrain people for new skills. \n2. Old age care. If there is evidence for increasing numbers of retired people in future years, the town will need to allocate more funding for end of life care. \n3. Increase spending for schooling. If there is evidence of a growing population of schoolaged children (new births, or families moving in to the town), then schooling spend should increase.\n4.  General infrastructure. If the town is expanding, then services (waste collection; road maintenance, etc.) will require more investment.  \n\n&amp;#x200B;\n\n**Hints**\n\nIn order to address these two questions, it is suggested that some of the analysis you undertake is: \n\n1. Examine the age distribution (age pyramid) of the population. Is it growing or shrinking? Will there be more retired aged people in the future, more school-aged children, more young people, etc. \n2. Examine unemployment trends. Are certain ages more likely to be unemployed than others. \n3. Examine religious affiliations. Are any religions growing, or shrinking? Are there any newer religions that are increasing in numbers? \n4. Examine the divorce and marriage rate. This might impact how you think about housing. \n5. Examine the occupancy level (how many people per house) and determine if existing housing is being under or over-used. \n6. Examine the number of university students. All of these are commuters since there are no universities in the town. Are there any other professions that are likely to be commuters? \n7. What is the birth rate and death rate for the town?  \n\nThese are merely suggestions, there are plentiful other analyses that could be undertaken that will be discussed in the videos and in class. Ultimately, your answers to (a) and (b) must be justified from the census data, and argued by balancing the different needs of the population and supported through statistics and where appropriate, hypothesis testing. As such, this is a \u201creal\u201d exercise but based on artificial data", "author_fullname": "t2_d0th00bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can somebody give me suggestions on what graph / visualizations to choose, to analyze trends in a census data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12gqtr1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681063780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an assignment for university. I have done 70% of the work, but now I&amp;#39;m stuck. I was given a csv data containing census data. I have to first clean the data, analyze the trends (using python) and answer the questions ( a. and b.) mentioned below. &lt;/p&gt;\n\n&lt;p&gt;Can somebody help with what kind of graphs/ visualizations I have to create in order to answer the two questions. &lt;/p&gt;\n\n&lt;p&gt;I have created age pyramid chart. but I need help with others. (see hints sections)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Assignment brief -&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;The mock census you will be given contains randomly generate data using the Faker package in Python. It has been generated in a similar manner to (and designed to directly emulate the format of) the 1881 census of the UK wherein only a few questions were asked of the population. The fields recorded are as follows:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Street Number (this is set to \u201c1\u201d if it is a unique dwelling); &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Street Name; 3. First Name of occupant; &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Surname of occupant; &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Age of occupant; &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Relationship to the \u201cHead\u201d of the household (anyone aged over 18 can be a \u201cHead\u201d \u2013 they are simply the person who had the responsibility to fill in the census details); &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Marital status (one of: Single, Married, Divorced, Widowed, or \u201cNA\u201d in the case of minors); &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Gender (one of: Male, Female; note that other responses were not implemented in 1881); &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Occupation (this field was implemented in a modern style, rather than typical 1881 occupations); &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Infirmity (we have implemented a limited set of infirmities following the style of 1881); &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Religion (we have implemented a set of real-world religions).  &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Task.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The town from the census is a modestly sized one sandwiched between two much larger cities that it is connected to by motorways. The town does not have a university, but students do live in the town and commute to the nearby cities. Once you have a cleaned dataset to analyze, your task is to decide the following:  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;(a)&lt;/strong&gt; What should be built on an unoccupied plot of land that the local government wishes to develop? Your choices are: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;High-density housing. This should be built if the population is significantly expanding. &lt;/li&gt;\n&lt;li&gt;Low-density housing. This should be built if the population is \u201caffluent\u201d and there is demand for large family housing. &lt;/li&gt;\n&lt;li&gt;Train station. There are potentially a lot of commuters in the town and building a train station could take pressure off the roads. But how will you identify commuters? &lt;/li&gt;\n&lt;li&gt;Religious building. There is already one place of worship for Catholics in the town. Is there demand for a second Church (if so, which denomination?), or for a different religious building? &lt;/li&gt;\n&lt;li&gt;Emergency medical building. Not a full hospital, but a minor injuries centre. This should be built if there are many injuries or future pregnancies likely in the population. &lt;/li&gt;\n&lt;li&gt;Something else? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Whichever you choose, you must justify it from the data provided to you and argue it is a priority against other choices.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;(b)&lt;/strong&gt; Which one of the following options should be invested in? &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Employment and training. If there is evidence for a lot of unemployment, we should retrain people for new skills. &lt;/li&gt;\n&lt;li&gt;Old age care. If there is evidence for increasing numbers of retired people in future years, the town will need to allocate more funding for end of life care. &lt;/li&gt;\n&lt;li&gt;Increase spending for schooling. If there is evidence of a growing population of schoolaged children (new births, or families moving in to the town), then schooling spend should increase.&lt;/li&gt;\n&lt;li&gt; General infrastructure. If the town is expanding, then services (waste collection; road maintenance, etc.) will require more investment.&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Hints&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;In order to address these two questions, it is suggested that some of the analysis you undertake is: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Examine the age distribution (age pyramid) of the population. Is it growing or shrinking? Will there be more retired aged people in the future, more school-aged children, more young people, etc. &lt;/li&gt;\n&lt;li&gt;Examine unemployment trends. Are certain ages more likely to be unemployed than others. &lt;/li&gt;\n&lt;li&gt;Examine religious affiliations. Are any religions growing, or shrinking? Are there any newer religions that are increasing in numbers? &lt;/li&gt;\n&lt;li&gt;Examine the divorce and marriage rate. This might impact how you think about housing. &lt;/li&gt;\n&lt;li&gt;Examine the occupancy level (how many people per house) and determine if existing housing is being under or over-used. &lt;/li&gt;\n&lt;li&gt;Examine the number of university students. All of these are commuters since there are no universities in the town. Are there any other professions that are likely to be commuters? &lt;/li&gt;\n&lt;li&gt;What is the birth rate and death rate for the town?&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;These are merely suggestions, there are plentiful other analyses that could be undertaken that will be discussed in the videos and in class. Ultimately, your answers to (a) and (b) must be justified from the census data, and argued by balancing the different needs of the population and supported through statistics and where appropriate, hypothesis testing. As such, this is a \u201creal\u201d exercise but based on artificial data&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12gqtr1", "is_robot_indexable": true, "report_reasons": null, "author": "Predator_069", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12gqtr1/can_somebody_give_me_suggestions_on_what_graph/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12gqtr1/can_somebody_give_me_suggestions_on_what_graph/", "subreddit_subscribers": 870146, "created_utc": 1681063780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi peeps! I have a lot of interest in becoming a data scientist/analyst and I've been taking courses to help upgrade my skills to achieve my goal but while I do want to pursue this career, there is this one thing which has been bugging me inside and making me question if data science is the right choice for me. That is my social anxiety and overall lack of communication skills. I'm generally a person who will get very nervous very quickly and this is specially true in social settings such as giving presentations. I know that this anxiety can be managed if I work on it but even then I feel like it's a personality trait that I have developed, and I'll never be truly comfortable around people. I'm well aware how important the soft skill of communication and interacting with people is in the role of a data scientist and I just can't worry thinking about if it is the right career option for me or should I go for something which involves less overall interaction.", "author_fullname": "t2_9ag9k9ly", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you still be a data scientist if you have extreme social anxiety?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12g8sr1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681015022.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681014645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi peeps! I have a lot of interest in becoming a data scientist/analyst and I&amp;#39;ve been taking courses to help upgrade my skills to achieve my goal but while I do want to pursue this career, there is this one thing which has been bugging me inside and making me question if data science is the right choice for me. That is my social anxiety and overall lack of communication skills. I&amp;#39;m generally a person who will get very nervous very quickly and this is specially true in social settings such as giving presentations. I know that this anxiety can be managed if I work on it but even then I feel like it&amp;#39;s a personality trait that I have developed, and I&amp;#39;ll never be truly comfortable around people. I&amp;#39;m well aware how important the soft skill of communication and interacting with people is in the role of a data scientist and I just can&amp;#39;t worry thinking about if it is the right career option for me or should I go for something which involves less overall interaction.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12g8sr1", "is_robot_indexable": true, "report_reasons": null, "author": "Ecstatic-Rabbit2089", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12g8sr1/can_you_still_be_a_data_scientist_if_you_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12g8sr1/can_you_still_be_a_data_scientist_if_you_have/", "subreddit_subscribers": 870146, "created_utc": 1681014645.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}