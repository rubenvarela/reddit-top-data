{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been working as a DS for the last 3 months in a government agency in the UK. A typical day of work is roughly &lt;1 hour of actual work, and since it is remote, I just play videogames or watch series the reminder 7 hs.\nI have tried to be proactive at work, come up with possible projects and contribute as much as I can, but there is only so much work and my boss prefers to keep me in 'stand by' in case an urgent request comes rather than to start whole new projects.\n\nSince I have only just started this job, I don't feel the urge to grind leetcode or get more certifications (since the pay is good enough, I'll most likely stay in this position for the next 2 years). Those in similar situations, what do you do to pass the time and avoid feeling you're collecting paychecks? Are there any good DS competitions or mentoring as to not get too rusty?", "author_fullname": "t2_2jaddzio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lots of downtime as a DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12v5j8e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 93, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 93, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682169095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working as a DS for the last 3 months in a government agency in the UK. A typical day of work is roughly &amp;lt;1 hour of actual work, and since it is remote, I just play videogames or watch series the reminder 7 hs.\nI have tried to be proactive at work, come up with possible projects and contribute as much as I can, but there is only so much work and my boss prefers to keep me in &amp;#39;stand by&amp;#39; in case an urgent request comes rather than to start whole new projects.&lt;/p&gt;\n\n&lt;p&gt;Since I have only just started this job, I don&amp;#39;t feel the urge to grind leetcode or get more certifications (since the pay is good enough, I&amp;#39;ll most likely stay in this position for the next 2 years). Those in similar situations, what do you do to pass the time and avoid feeling you&amp;#39;re collecting paychecks? Are there any good DS competitions or mentoring as to not get too rusty?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12v5j8e", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofme", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12v5j8e/lots_of_downtime_as_a_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12v5j8e/lots_of_downtime_as_a_ds/", "subreddit_subscribers": 878615, "created_utc": 1682169095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "But how do you approach identifing those that are not wrong? I thought about building a classifier on top of the outlier detector. Are there any other options?", "author_fullname": "t2_4oockqg5s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Not all outliers are wrong", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12uzusd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 86, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 86, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682153353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;But how do you approach identifing those that are not wrong? I thought about building a classifier on top of the outlier detector. Are there any other options?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12uzusd", "is_robot_indexable": true, "report_reasons": null, "author": "furioncruz", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12uzusd/not_all_outliers_are_wrong/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12uzusd/not_all_outliers_are_wrong/", "subreddit_subscribers": 878615, "created_utc": 1682153353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_97o87945r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the purpose of a confusion matrix in machine learning? How do you interpret the different metrics (such as precision, recall, F1 score) from a confusion matrix?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12uwgzo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682142969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12uwgzo", "is_robot_indexable": true, "report_reasons": null, "author": "asquare-buzz", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12uwgzo/what_is_the_purpose_of_a_confusion_matrix_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12uwgzo/what_is_the_purpose_of_a_confusion_matrix_in/", "subreddit_subscribers": 878615, "created_utc": 1682142969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was trying to evaluate different classification models on MNIST dataset.\n\nThere are two datasets provided : \\`train\\` - 42000 images, and \\`test\\` - 28000 images.\n\n&amp;#x200B;\n\nI first divided the original training dataset (42000 images) into a (80:20 split ) of \\`train\\_set\\` (33600) and \\`test\\_set\\` (8400) .\n\nI trained several models, from on \\`training set\\`, \\`cross-validated\\` them on the \\`training\\_set\\` only, and lastly evaluated the final model on the \\`test\\_set\\` for generalization error.\n\n&amp;#x200B;\n\nNow that my final model is ready to generate the \\`submission file\\` using the Kaggle provided \\`test\\` set, should I train my model on the whole Kaggle provided \\`training\\` set, ie \\`train\\_set + test\\_set\\` (ie the full 42000 images provided, instead of just 33600 images that I split), since Kaggle is going to evaluate my model on its own provided \\`test\\` set ?", "author_fullname": "t2_ehnipsvn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I train my final model on the (train+validation) set before final submission?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vcuj7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682184167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was trying to evaluate different classification models on MNIST dataset.&lt;/p&gt;\n\n&lt;p&gt;There are two datasets provided : `train` - 42000 images, and `test` - 28000 images.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I first divided the original training dataset (42000 images) into a (80:20 split ) of `train_set` (33600) and `test_set` (8400) .&lt;/p&gt;\n\n&lt;p&gt;I trained several models, from on `training set`, `cross-validated` them on the `training_set` only, and lastly evaluated the final model on the `test_set` for generalization error.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now that my final model is ready to generate the `submission file` using the Kaggle provided `test` set, should I train my model on the whole Kaggle provided `training` set, ie `train_set + test_set` (ie the full 42000 images provided, instead of just 33600 images that I split), since Kaggle is going to evaluate my model on its own provided `test` set ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vcuj7", "is_robot_indexable": true, "report_reasons": null, "author": "DietzscheNostoevsky", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vcuj7/should_i_train_my_final_model_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vcuj7/should_i_train_my_final_model_on_the/", "subreddit_subscribers": 878615, "created_utc": 1682184167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone!  \nI'm excited to announce that I've completed the Portfolio Project: OKCupid Date-A-Scientist. I've put a lot of effort into this project and I'm eager to hear what you all think about it.\n\nI would really appreciate it if you could take a look at my project and provide some constructive feedback. Your comments and suggestions will help me improve my skills and become a better data scientist.\n\nI hope you enjoy exploring my project as much as I enjoyed working on it. Thank you in advance for your time and feedback!   \n\n\n[https://github.com/Pavich-3/OkCupid-Date-A-Scientist](https://github.com/Pavich-3/OkCupid-Date-A-Scientist)", "author_fullname": "t2_vipqbbhx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Check out my Portfolio Project: OKCupid Date-A-Scientist - Looking for Feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12v2guq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682160946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;br/&gt;\nI&amp;#39;m excited to announce that I&amp;#39;ve completed the Portfolio Project: OKCupid Date-A-Scientist. I&amp;#39;ve put a lot of effort into this project and I&amp;#39;m eager to hear what you all think about it.&lt;/p&gt;\n\n&lt;p&gt;I would really appreciate it if you could take a look at my project and provide some constructive feedback. Your comments and suggestions will help me improve my skills and become a better data scientist.&lt;/p&gt;\n\n&lt;p&gt;I hope you enjoy exploring my project as much as I enjoyed working on it. Thank you in advance for your time and feedback!   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/Pavich-3/OkCupid-Date-A-Scientist\"&gt;https://github.com/Pavich-3/OkCupid-Date-A-Scientist&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wWcvwb_jdIBbTuZU2Sd-B-q0Bq3L7o5FdXjSe7p0ABA.jpg?auto=webp&amp;v=enabled&amp;s=c0f7136ac74b183f41f9c1f90d419c5e99f19a18", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/wWcvwb_jdIBbTuZU2Sd-B-q0Bq3L7o5FdXjSe7p0ABA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc91615c6560712b8cc441882bb8549ecbcfabf2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/wWcvwb_jdIBbTuZU2Sd-B-q0Bq3L7o5FdXjSe7p0ABA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ec03b2ea7ecec44a6c491e0f7f96dd1f7bf1994", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/wWcvwb_jdIBbTuZU2Sd-B-q0Bq3L7o5FdXjSe7p0ABA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0aa0e279ad701a1b6f9b07df4879feba5392dffc", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/wWcvwb_jdIBbTuZU2Sd-B-q0Bq3L7o5FdXjSe7p0ABA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=62d94573395f5fdd6c8456109393f8cd941312f5", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/wWcvwb_jdIBbTuZU2Sd-B-q0Bq3L7o5FdXjSe7p0ABA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2bb4bf88d51e6b2b83dca5916c819e986bdca537", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/wWcvwb_jdIBbTuZU2Sd-B-q0Bq3L7o5FdXjSe7p0ABA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98cf1cf792ec28f9a3edb966b62dab7e950992da", "width": 1080, "height": 540}], "variants": {}, "id": "SwsTkbKq0cUlwWK-R-jskT4AsGsyxaxakUDv8CyZ2z4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12v2guq", "is_robot_indexable": true, "report_reasons": null, "author": "pavich_03", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12v2guq/check_out_my_portfolio_project_okcupid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12v2guq/check_out_my_portfolio_project_okcupid/", "subreddit_subscribers": 878615, "created_utc": 1682160946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ejh5mwyx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Found this on an analyst position job ad on LinkedIn. Do you think the shade is reasonable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 12, "top_awarded_type": null, "hide_score": true, "name": "t3_12vl384", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VIyQtNBtJrlzs5p8QhPi68rYH3Th_PqRohiNlUxcV3U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682201044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/cxcftudodiva1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/cxcftudodiva1.png?auto=webp&amp;v=enabled&amp;s=6019ae5fdcf12dae0e88afef5f4b60d0d257be12", "width": 749, "height": 67}, "resolutions": [{"url": "https://preview.redd.it/cxcftudodiva1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b44887fa79ad7a9df108a5a870ae4b3bf26796e", "width": 108, "height": 9}, {"url": "https://preview.redd.it/cxcftudodiva1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6848f4463a05664270bd8aa2ff568568483dffc", "width": 216, "height": 19}, {"url": "https://preview.redd.it/cxcftudodiva1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e1f4013faf2c7648879cab698bfb6afc9466398", "width": 320, "height": 28}, {"url": "https://preview.redd.it/cxcftudodiva1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ec8019426ec49a746198e1567a9a074c289583f", "width": 640, "height": 57}], "variants": {}, "id": "pnDReaq2XX32Gbj1cUcCt8IkpgaLQf2jX1jVm98t2jM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vl384", "is_robot_indexable": true, "report_reasons": null, "author": "BiggusCinnamusRollus", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vl384/found_this_on_an_analyst_position_job_ad_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/cxcftudodiva1.png", "subreddit_subscribers": 878615, "created_utc": 1682201044.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Ok so I had this idea when sipping on my creatine. Not sure if something like this already exists or is impossible. \nThis may work for other smaller neural networks but let's take time series neural network with a training period of 3 year as an example. \nWhen passing samples to our neural network, can we see which samples affect the gradient the most and isolate the most important features from that sample set to get an understanding of which samples have a great impact on the learning. This can give us an idea of real life feature set and how the model reacts to it. So when things either work or don't work we can refer to these sets and confirm the impact.\nI don't know if it makes sense but thought I would just put it here.", "author_fullname": "t2_5fdcznre", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Explainability of time series model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vcqth", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682183965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ok so I had this idea when sipping on my creatine. Not sure if something like this already exists or is impossible. \nThis may work for other smaller neural networks but let&amp;#39;s take time series neural network with a training period of 3 year as an example. \nWhen passing samples to our neural network, can we see which samples affect the gradient the most and isolate the most important features from that sample set to get an understanding of which samples have a great impact on the learning. This can give us an idea of real life feature set and how the model reacts to it. So when things either work or don&amp;#39;t work we can refer to these sets and confirm the impact.\nI don&amp;#39;t know if it makes sense but thought I would just put it here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vcqth", "is_robot_indexable": true, "report_reasons": null, "author": "KaaleenBaba", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vcqth/explainability_of_time_series_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vcqth/explainability_of_time_series_model/", "subreddit_subscribers": 878615, "created_utc": 1682183965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there!\n\nAfter two years in my company, I still have very little overview about what data we have and where.  By now I am convinced no one does. \n\nHow does your company create a map of the data landscape it posesses, such that it does not fade into oblivion? Is there a huge UML Diagram, is there a wiki where databases can have their wiki page? Do you work with a data catalog? \n\nOr are all these approaches infeasable, as they deprecate too quickly, when the data changes?\n\nHow does one get an overview of whats available?", "author_fullname": "t2_dmmmdubd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overview of all available Data in a Company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12uyzii", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682150436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there!&lt;/p&gt;\n\n&lt;p&gt;After two years in my company, I still have very little overview about what data we have and where.  By now I am convinced no one does. &lt;/p&gt;\n\n&lt;p&gt;How does your company create a map of the data landscape it posesses, such that it does not fade into oblivion? Is there a huge UML Diagram, is there a wiki where databases can have their wiki page? Do you work with a data catalog? &lt;/p&gt;\n\n&lt;p&gt;Or are all these approaches infeasable, as they deprecate too quickly, when the data changes?&lt;/p&gt;\n\n&lt;p&gt;How does one get an overview of whats available?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12uyzii", "is_robot_indexable": true, "report_reasons": null, "author": "Strivenby", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12uyzii/overview_of_all_available_data_in_a_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12uyzii/overview_of_all_available_data_in_a_company/", "subreddit_subscribers": 878615, "created_utc": 1682150436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The reason I'm asking is because I see it near the top of like every \"Things to learn as a data scientist\" list. But I just can't convince myself to take the time to learn it without better understanding the use case.\n\nI'm a Data Scientist at a Saas company, and we have a fairly mature data science / ml team and Terabytes of data to play with. That being said, none of us have ever touched or even thought of touching Hadoop. It's not that we don't have lots of data -- but I'm just not seeing the use case. Most stuff you can just batch if the data is too large. Or spin up an AWS instance that's a little bigger. Compute just seems to be growing sufficiently fast that I'm not really into the Hadoop hype. Even things like, say a linear model where you really can't do the matrix inversion in batches you can just take a random sample of 100k data points and basically converge to the model.", "author_fullname": "t2_1zkrsyfq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone use Hadoop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12vlt86", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682202515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The reason I&amp;#39;m asking is because I see it near the top of like every &amp;quot;Things to learn as a data scientist&amp;quot; list. But I just can&amp;#39;t convince myself to take the time to learn it without better understanding the use case.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a Data Scientist at a Saas company, and we have a fairly mature data science / ml team and Terabytes of data to play with. That being said, none of us have ever touched or even thought of touching Hadoop. It&amp;#39;s not that we don&amp;#39;t have lots of data -- but I&amp;#39;m just not seeing the use case. Most stuff you can just batch if the data is too large. Or spin up an AWS instance that&amp;#39;s a little bigger. Compute just seems to be growing sufficiently fast that I&amp;#39;m not really into the Hadoop hype. Even things like, say a linear model where you really can&amp;#39;t do the matrix inversion in batches you can just take a random sample of 100k data points and basically converge to the model.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vlt86", "is_robot_indexable": true, "report_reasons": null, "author": "Any-Fig-921", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vlt86/does_anyone_use_hadoop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vlt86/does_anyone_use_hadoop/", "subreddit_subscribers": 878615, "created_utc": 1682202515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I would like to know, what are the differences between week of Data analyst, Data scientist, Data engineer and ML engineer. What things are they doing? How repetitive the job is through the week? Do you do less same things for more clients, or work for less clients doing more complex work?", "author_fullname": "t2_tuwq1ase", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does work week of each role in this field look alike?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12uwxcv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682144266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to know, what are the differences between week of Data analyst, Data scientist, Data engineer and ML engineer. What things are they doing? How repetitive the job is through the week? Do you do less same things for more clients, or work for less clients doing more complex work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12uwxcv", "is_robot_indexable": true, "report_reasons": null, "author": "No_Philosophy_8520", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12uwxcv/how_does_work_week_of_each_role_in_this_field/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12uwxcv/how_does_work_week_of_each_role_in_this_field/", "subreddit_subscribers": 878615, "created_utc": 1682144266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey folks,\n\nToday is Earth Day, and it's time to do our part in protecting our planet's natural resources. One way you can contribute is by monitoring forests and trees to identify regions with high tree loss. And the good news is that you can do this in just 15 minutes, for free! Here is how: https://www.spacesense.ai/blog-posts/build-a-deforestation-monitoring-solution-using-satellite-imagery-in-15-minutes\n\nSpaceSense is a platform that allows you to do just that. It uses satellite imagery to help you identify areas with high tree loss. And when you share your findings with #datascientist4climate, you'll be making a significant contribution to the fight against climate change.\n\nSo, put on your nature hats, fire up SpaceSense, and start monitoring those trees! Let's all be heroes to the planet.\n\nregister for a free licence here: https://www.spacesense.ai/platform", "author_fullname": "t2_9rwjtia18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Happy Earth Day! Join the fight to protect our planet's forests and trees with SpaceSense and #datascientist4climatep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vjxs5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682198820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;Today is Earth Day, and it&amp;#39;s time to do our part in protecting our planet&amp;#39;s natural resources. One way you can contribute is by monitoring forests and trees to identify regions with high tree loss. And the good news is that you can do this in just 15 minutes, for free! Here is how: &lt;a href=\"https://www.spacesense.ai/blog-posts/build-a-deforestation-monitoring-solution-using-satellite-imagery-in-15-minutes\"&gt;https://www.spacesense.ai/blog-posts/build-a-deforestation-monitoring-solution-using-satellite-imagery-in-15-minutes&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;SpaceSense is a platform that allows you to do just that. It uses satellite imagery to help you identify areas with high tree loss. And when you share your findings with #datascientist4climate, you&amp;#39;ll be making a significant contribution to the fight against climate change.&lt;/p&gt;\n\n&lt;p&gt;So, put on your nature hats, fire up SpaceSense, and start monitoring those trees! Let&amp;#39;s all be heroes to the planet.&lt;/p&gt;\n\n&lt;p&gt;register for a free licence here: &lt;a href=\"https://www.spacesense.ai/platform\"&gt;https://www.spacesense.ai/platform&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?auto=webp&amp;v=enabled&amp;s=e64919c0ef67486fa3736cb8d803fb16da60bd8b", "width": 1920, "height": 1920}, "resolutions": [{"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc58e965c719d62e327aa6c09ce2642baa221f42", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=602bbf9640187d1e4da61a3bf811b8369f0f37ac", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d930e00d4880b7d3c1ffdaa05f9f1f07a376f6f4", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0716b184c23e57f3ab2da207d18aabaa47a32ced", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3fbd7dc0333a9b62c35ca59ec78dc4d256eb0d9a", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=200824811fd64a2f52a74ce65be9ef77b890f2de", "width": 1080, "height": 1080}], "variants": {}, "id": "JJ-9SwnXzqvDvkPIN3BJrvthVJAb-LCanr5yn2nP3xM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vjxs5", "is_robot_indexable": true, "report_reasons": null, "author": "Space4earth", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vjxs5/happy_earth_day_join_the_fight_to_protect_our/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vjxs5/happy_earth_day_join_the_fight_to_protect_our/", "subreddit_subscribers": 878615, "created_utc": 1682198820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We are creating an Open Source  Project to customize a NLP model for the Energy Industry.  While open source is great, our year 2 and year 3 goal will also be for folks to be able to monetize it after by offering consulting services (you can set your own rates for this work).   We have obtained enough funding for two years of hosting fees and software/platform and have some end clients that have signed on (it is a win-win for them since they are not paying anything initially and get . We are almost done setting up a framework/infrastructure that will simplify the task using a tool similar to ML flow (but a lot more powerful/integrated with multiple data sets). We will not start officially until we have all the framework in place so we don't waste people's time but this is roughly around May 15 so we are starting to look for folks now. So far we have two folks on-board but we figure we would ideally like 10-20 contributors. \n\nSerious inquiries only please.", "author_fullname": "t2_71ikgu3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open Source Initiative- Join us!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vjh5l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682197914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are creating an Open Source  Project to customize a NLP model for the Energy Industry.  While open source is great, our year 2 and year 3 goal will also be for folks to be able to monetize it after by offering consulting services (you can set your own rates for this work).   We have obtained enough funding for two years of hosting fees and software/platform and have some end clients that have signed on (it is a win-win for them since they are not paying anything initially and get . We are almost done setting up a framework/infrastructure that will simplify the task using a tool similar to ML flow (but a lot more powerful/integrated with multiple data sets). We will not start officially until we have all the framework in place so we don&amp;#39;t waste people&amp;#39;s time but this is roughly around May 15 so we are starting to look for folks now. So far we have two folks on-board but we figure we would ideally like 10-20 contributors. &lt;/p&gt;\n\n&lt;p&gt;Serious inquiries only please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vjh5l", "is_robot_indexable": true, "report_reasons": null, "author": "SnooTangerines240", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vjh5l/open_source_initiative_join_us/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vjh5l/open_source_initiative_join_us/", "subreddit_subscribers": 878615, "created_utc": 1682197914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi!\n\nFor  my master's thesis, I am writing an algorithm that can predict which  books will become popular on Tiktok. Right now I am working on getting  the right labels for the dataset, based on the viewcounts of the books  on Tiktok. I have a large dataset with titles and viewcounts, and a list of 19 books that have done well on Tiktok, with their viewcounts (there are probably  more, but I had to make a list myself of what I know for sure are famous  books). I want to use their viewcounts to set a baseline for what is  considered popular on tiktok and what is not considered popular.  However, the viewcounts all lie pretty far apart. They are the following  numbers:66089172, 909551, 14159253, 5771561,  68456152, 20982050,  6767132, 61012995, 39505320, 1299157, 27307,  38193455, 34048345,  9830311, 87600000, 37921810, 88484025, 55764970,  108154.\n\nI  have considered using the mean or median, but since the numbers lie  pretty far apart and they aren't normally distributed, I don't think I  can use those. I then considered using the mean - 3 times the standard  deviation, but this gave me a lower bound of zero, meaning that all  books would be considered tiktok famous. I also tried using the 25  percentile - 1.5 times the interquartile range, but he same thing  happened.\n\nRight now I am thinking I  could just use the lowest number of the list, since I know that one is  Tiktok famous so ones with even slightly more views will be considered  famous as well, but this feels like it's very wrong, statistically  speaking, so I was wondering on your opinion on this, and if you had any  advice or recommendations?\n\nThank you so much in advance!", "author_fullname": "t2_2uua33bh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Q] [E] Question about finding the appropriate lower boundary for adding labels to my dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vj8yo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682197471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;For  my master&amp;#39;s thesis, I am writing an algorithm that can predict which  books will become popular on Tiktok. Right now I am working on getting  the right labels for the dataset, based on the viewcounts of the books  on Tiktok. I have a large dataset with titles and viewcounts, and a list of 19 books that have done well on Tiktok, with their viewcounts (there are probably  more, but I had to make a list myself of what I know for sure are famous  books). I want to use their viewcounts to set a baseline for what is  considered popular on tiktok and what is not considered popular.  However, the viewcounts all lie pretty far apart. They are the following  numbers:66089172, 909551, 14159253, 5771561,  68456152, 20982050,  6767132, 61012995, 39505320, 1299157, 27307,  38193455, 34048345,  9830311, 87600000, 37921810, 88484025, 55764970,  108154.&lt;/p&gt;\n\n&lt;p&gt;I  have considered using the mean or median, but since the numbers lie  pretty far apart and they aren&amp;#39;t normally distributed, I don&amp;#39;t think I  can use those. I then considered using the mean - 3 times the standard  deviation, but this gave me a lower bound of zero, meaning that all  books would be considered tiktok famous. I also tried using the 25  percentile - 1.5 times the interquartile range, but he same thing  happened.&lt;/p&gt;\n\n&lt;p&gt;Right now I am thinking I  could just use the lowest number of the list, since I know that one is  Tiktok famous so ones with even slightly more views will be considered  famous as well, but this feels like it&amp;#39;s very wrong, statistically  speaking, so I was wondering on your opinion on this, and if you had any  advice or recommendations?&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vj8yo", "is_robot_indexable": true, "report_reasons": null, "author": "Romcom1398", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vj8yo/q_e_question_about_finding_the_appropriate_lower/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vj8yo/q_e_question_about_finding_the_appropriate_lower/", "subreddit_subscribers": 878615, "created_utc": 1682197471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I've been working on a financial data set from where I've to classify early loan default among customers (binary Classification). Its a relatively smaller data set (about 3k rows) &amp; highly imbalanced class distribution and i've been trying to fit a XGB algo on it. But upon decile analysis gini is around 98 &amp; 97 % for test &amp; train respectively. Other than that f1, accuracy, recall all are 1.00 I found this to be very fishy. Can anybody help me out figuring what is going on ?", "author_fullname": "t2_8b1tcpps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overfitting in XGB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12veat4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682187232.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working on a financial data set from where I&amp;#39;ve to classify early loan default among customers (binary Classification). Its a relatively smaller data set (about 3k rows) &amp;amp; highly imbalanced class distribution and i&amp;#39;ve been trying to fit a XGB algo on it. But upon decile analysis gini is around 98 &amp;amp; 97 % for test &amp;amp; train respectively. Other than that f1, accuracy, recall all are 1.00 I found this to be very fishy. Can anybody help me out figuring what is going on ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12veat4", "is_robot_indexable": true, "report_reasons": null, "author": "MustBeHuman", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12veat4/overfitting_in_xgb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12veat4/overfitting_in_xgb/", "subreddit_subscribers": 878615, "created_utc": 1682187232.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve noticed that we're seeing big advancements almost every day, but it feels like the quality of papers is going downhill when it comes to backing up their claims.\n\nAnyone else feel this way? Do you think it's just because of all the buzz around generative AI, or is this something that's here to stay?", "author_fullname": "t2_8l29q3sh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] What are your thoughts on the quality of papers recently?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12v98us", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682177089.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve noticed that we&amp;#39;re seeing big advancements almost every day, but it feels like the quality of papers is going downhill when it comes to backing up their claims.&lt;/p&gt;\n\n&lt;p&gt;Anyone else feel this way? Do you think it&amp;#39;s just because of all the buzz around generative AI, or is this something that&amp;#39;s here to stay?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12v98us", "is_robot_indexable": true, "report_reasons": null, "author": "spenny972", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12v98us/d_what_are_your_thoughts_on_the_quality_of_papers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12v98us/d_what_are_your_thoughts_on_the_quality_of_papers/", "subreddit_subscribers": 878615, "created_utc": 1682177089.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_f6pv008z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is a better option University of Regina(Masters in Data Science ) or Trent University(MSc in Big data analytics) in terms of study and career aspects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12uuzn9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682138854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12uuzn9", "is_robot_indexable": true, "report_reasons": null, "author": "Jaime156", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12uuzn9/which_is_a_better_option_university_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12uuzn9/which_is_a_better_option_university_of/", "subreddit_subscribers": 878615, "created_utc": 1682138854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8n5hmj1gq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Generate Fake Images that Look Real with Just a Few Lines of Code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_12vbzpp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FIIcfs6TlDzKM3DyRalK3CJDzrf31swn--55zwRPfrI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682182473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/p/1eaea5769e2c", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?auto=webp&amp;v=enabled&amp;s=6a7df6f8eef838e51cec0364000963a309cd0d5e", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ff9a527a6230bdf677f4552891883222cfd5564", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8645b8bb339c712d2ec5e7c0928d45158b01eab3", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b0eea5cd15fbfae11ed8cc3b2cbd3d7036ff4d5", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fe102408f1e91ca5d2414624faf2352e9a46d80", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89c27ec64d6598db41a503ba1264ad669e6033e9", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=903c1210ab1bb8647ce8320201602153752fa90a", "width": 1080, "height": 720}], "variants": {}, "id": "UjeJjO1zCxH5XvPNH0FUWokVc-iXNE9Q_HuclqbS980"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vbzpp", "is_robot_indexable": true, "report_reasons": null, "author": "MagazinePerfect9021", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vbzpp/how_to_generate_fake_images_that_look_real_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/p/1eaea5769e2c", "subreddit_subscribers": 878615, "created_utc": 1682182473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm running a mentorship platform and trying to figure out what data scientists need a mentor for. If you are a data scientist, why would you want to talk to a mentor?", "author_fullname": "t2_kv63zgqt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do data scientists need mentorship about?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12v9xi7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682178416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m running a mentorship platform and trying to figure out what data scientists need a mentor for. If you are a data scientist, why would you want to talk to a mentor?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12v9xi7", "is_robot_indexable": true, "report_reasons": null, "author": "mentordial", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12v9xi7/what_do_data_scientists_need_mentorship_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12v9xi7/what_do_data_scientists_need_mentorship_about/", "subreddit_subscribers": 878615, "created_utc": 1682178416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi Data Nerds! I want to expand my network on LinkedIn, beef up my profile, particularly in my endorsements. I'm trying to land my first Data Analyst role but I'm struggling to get attraction.\n\nIf anyone wants their profile to appear more professional with the addition of mutual endorsements, message me and we can exchange LinkedIn!", "author_fullname": "t2_8nm1yk3t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LinkedIn Endorsements", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12uxvmr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.06, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682147062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Data Nerds! I want to expand my network on LinkedIn, beef up my profile, particularly in my endorsements. I&amp;#39;m trying to land my first Data Analyst role but I&amp;#39;m struggling to get attraction.&lt;/p&gt;\n\n&lt;p&gt;If anyone wants their profile to appear more professional with the addition of mutual endorsements, message me and we can exchange LinkedIn!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12uxvmr", "is_robot_indexable": true, "report_reasons": null, "author": "Moezus__", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12uxvmr/linkedin_endorsements/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12uxvmr/linkedin_endorsements/", "subreddit_subscribers": 878615, "created_utc": 1682147062.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}