{"kind": "Listing", "data": {"after": "t3_12q6gp8", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey r/datascience!I found [this ancient thread](https://www.reddit.com/r/datascience/comments/bx59cv/tool_for_integrating_sql_jupyter_seamlessly/) about Jupyter Notebooks and SQL queries.I\u2019m wondering if:\n\n1. Are people here still running SQL from within the notebook?\n2. What best practices/tips do you have?\n3. What are the main use cases?\n\nI usually use it to connect to multiple sources, store the queries within the notebook, and then put the notebooks into version control. I also found pandas way slower from running a [duckdb](https://jupysql.ploomber.io/en/latest/integrations/duckdb.html) \\+ [jupysql](https://github.com/ploomber/jupysql) when possible.", "author_fullname": "t2_sy01bb7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best practices around Jupyter and SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ptgo1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 111, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 111, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681821067.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681759204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;!I found &lt;a href=\"https://www.reddit.com/r/datascience/comments/bx59cv/tool_for_integrating_sql_jupyter_seamlessly/\"&gt;this ancient thread&lt;/a&gt; about Jupyter Notebooks and SQL queries.I\u2019m wondering if:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Are people here still running SQL from within the notebook?&lt;/li&gt;\n&lt;li&gt;What best practices/tips do you have?&lt;/li&gt;\n&lt;li&gt;What are the main use cases?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I usually use it to connect to multiple sources, store the queries within the notebook, and then put the notebooks into version control. I also found pandas way slower from running a &lt;a href=\"https://jupysql.ploomber.io/en/latest/integrations/duckdb.html\"&gt;duckdb&lt;/a&gt; + &lt;a href=\"https://github.com/ploomber/jupysql\"&gt;jupysql&lt;/a&gt; when possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ptgo1", "is_robot_indexable": true, "report_reasons": null, "author": "idomic", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ptgo1/what_are_the_best_practices_around_jupyter_and_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ptgo1/what_are_the_best_practices_around_jupyter_and_sql/", "subreddit_subscribers": 875499, "created_utc": 1681759204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, let me preface this: **I understand this is a very general ask and therefore I can only expect very general responses.**\n\nI am most likely going to transition from my current data scientist role into a data analytics role because it aligns better with my interests and skillset. I know that generally speaking, the data scientist's salary is higher than that of the data analyst, but I also expect I will be able to leverage my experience to get a more senior role within data analytics that I am hoping will at least offset the difference.\n\nMy current role is an Associate-level Data Scientist, and my target role will be a Senior-level Data Analyst. Again, **I know there are a lot of variables at play here**, but in a very general sense, what do people think I should expect salary-wise? A slight decrease? Slight increase? Roughly the same?\n\nAny and all input is appreciated. Thanks all!", "author_fullname": "t2_ngcpuv32", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salary expectations moving from data science into data analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q8oaq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 66, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 66, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681788406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, let me preface this: &lt;strong&gt;I understand this is a very general ask and therefore I can only expect very general responses.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I am most likely going to transition from my current data scientist role into a data analytics role because it aligns better with my interests and skillset. I know that generally speaking, the data scientist&amp;#39;s salary is higher than that of the data analyst, but I also expect I will be able to leverage my experience to get a more senior role within data analytics that I am hoping will at least offset the difference.&lt;/p&gt;\n\n&lt;p&gt;My current role is an Associate-level Data Scientist, and my target role will be a Senior-level Data Analyst. Again, &lt;strong&gt;I know there are a lot of variables at play here&lt;/strong&gt;, but in a very general sense, what do people think I should expect salary-wise? A slight decrease? Slight increase? Roughly the same?&lt;/p&gt;\n\n&lt;p&gt;Any and all input is appreciated. Thanks all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q8oaq", "is_robot_indexable": true, "report_reasons": null, "author": "abnormal_oats", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q8oaq/salary_expectations_moving_from_data_science_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q8oaq/salary_expectations_moving_from_data_science_into/", "subreddit_subscribers": 875499, "created_utc": 1681788406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Fitter:  \n [cokelaer/fitter: Fit data to many distributions (github.com)](https://github.com/cokelaer/fitter)", "author_fullname": "t2_3op9qx89", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I recently discovered the python package 'fitter', which is a really nifty package for fitting various data distributions. Has anyone discovered any other cool packages that the field would find useful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ppj7g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681751794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fitter:&lt;br/&gt;\n &lt;a href=\"https://github.com/cokelaer/fitter\"&gt;cokelaer/fitter: Fit data to many distributions (github.com)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ppj7g", "is_robot_indexable": true, "report_reasons": null, "author": "LatterConcentrate6", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ppj7g/i_recently_discovered_the_python_package_fitter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ppj7g/i_recently_discovered_the_python_package_fitter/", "subreddit_subscribers": 875499, "created_utc": 1681751794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I will be starting my masters program in US from this fall. I would like to buy an new laptop for me to do projects. I guess we need nvdia gpu for cuda support. So please drop your suggestions", "author_fullname": "t2_7clcwm7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Laptop suggestions for ML/Data Science/CV projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qa0n0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681791341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I will be starting my masters program in US from this fall. I would like to buy an new laptop for me to do projects. I guess we need nvdia gpu for cuda support. So please drop your suggestions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qa0n0", "is_robot_indexable": true, "report_reasons": null, "author": "Southern-Acadia-3744", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qa0n0/laptop_suggestions_for_mldata_sciencecv_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qa0n0/laptop_suggestions_for_mldata_sciencecv_projects/", "subreddit_subscribers": 875499, "created_utc": 1681791341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am having a business problem, where we used to send some metrics Numbers each day, by putting them into excel sheet,  and send them to each stakeholders \n\nI have used Python to automate the numbers, and send the stakeholders daily mails using smtp lib.\n\nBut that doesn't  looks nice to present them to stakeholders like, CEO ,\n\nSo, I just wanna know, can we replicate this view using CSS/HTML or any other method,\n\nif yes, which method would work? I am data analyst So dont have any idea in css html or any other ,\n\n&amp;#x200B;\n\nhttps://preview.redd.it/yh9wlmk0xmua1.png?width=1073&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=245e3cb63690ed90500f7907803a01857d141144", "author_fullname": "t2_agvtvokn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replicating a sheet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"yh9wlmk0xmua1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 177, "x": 108, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ff7756410f3eff1a130b849b9733885d6cbbe71"}, {"y": 354, "x": 216, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a330aca0093670629bdfb7c2d8eea74925eb44e8"}, {"y": 525, "x": 320, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9cedccd7673911d2cb53e763715c91d52ef7a5b"}, {"y": 1050, "x": 640, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5278ca7cab7a0e72f6fce20abe0491ca5182860b"}, {"y": 1575, "x": 960, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd92b7bf8f9bf0b60daf7879c2010376c3209941"}], "s": {"y": 1761, "x": 1073, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=1073&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=245e3cb63690ed90500f7907803a01857d141144"}, "id": "yh9wlmk0xmua1"}}, "name": "t3_12ql37a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CIVfGZm5nguI7lUIpCWOZ9xw4WgLmAzBMvYI162AuBM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681820093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am having a business problem, where we used to send some metrics Numbers each day, by putting them into excel sheet,  and send them to each stakeholders &lt;/p&gt;\n\n&lt;p&gt;I have used Python to automate the numbers, and send the stakeholders daily mails using smtp lib.&lt;/p&gt;\n\n&lt;p&gt;But that doesn&amp;#39;t  looks nice to present them to stakeholders like, CEO ,&lt;/p&gt;\n\n&lt;p&gt;So, I just wanna know, can we replicate this view using CSS/HTML or any other method,&lt;/p&gt;\n\n&lt;p&gt;if yes, which method would work? I am data analyst So dont have any idea in css html or any other ,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yh9wlmk0xmua1.png?width=1073&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=245e3cb63690ed90500f7907803a01857d141144\"&gt;https://preview.redd.it/yh9wlmk0xmua1.png?width=1073&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=245e3cb63690ed90500f7907803a01857d141144&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ql37a", "is_robot_indexable": true, "report_reasons": null, "author": "chilly_tomato", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ql37a/replicating_a_sheet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ql37a/replicating_a_sheet/", "subreddit_subscribers": 875499, "created_utc": 1681820093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As title, I understand the concept of market mix modeling from the analysis/modeling aspect, but once the model has been approved, how the media optimization works afterward?\n\nit utilizes the outputs/parameters from the model, and it can be done in linear and non linear, but that is about what I know.\n\nAnyone can shed some lights into this? TiA", "author_fullname": "t2_ul5y0kdu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Media Optimization in Marketing Mix Model project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q36b1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681777377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As title, I understand the concept of market mix modeling from the analysis/modeling aspect, but once the model has been approved, how the media optimization works afterward?&lt;/p&gt;\n\n&lt;p&gt;it utilizes the outputs/parameters from the model, and it can be done in linear and non linear, but that is about what I know.&lt;/p&gt;\n\n&lt;p&gt;Anyone can shed some lights into this? TiA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q36b1", "is_robot_indexable": true, "report_reasons": null, "author": "kyleireddit", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q36b1/media_optimization_in_marketing_mix_model_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q36b1/media_optimization_in_marketing_mix_model_project/", "subreddit_subscribers": 875499, "created_utc": 1681777377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m trying to back track from survival function down to hazard function which upon dividing by the partial hazard should give the same baseline hazard for any 2 example subjects. Unfortunately predict_hazard function in CoxPHFitter is throwing an error (doesn\u2019t have the attribute apparently, which is v weird). And if I manually get to a hazard function from the cumulative hazard function (not super sure of the calculation), the step after dividing by partial hazard is not the same i.e., 2 different baseline hazards. Any help appreciated.", "author_fullname": "t2_u3vhf5lz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Facing inconsistencies while trying to reconstruct Cox PH predictions by lifelines package", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qltap", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681821775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to back track from survival function down to hazard function which upon dividing by the partial hazard should give the same baseline hazard for any 2 example subjects. Unfortunately predict_hazard function in CoxPHFitter is throwing an error (doesn\u2019t have the attribute apparently, which is v weird). And if I manually get to a hazard function from the cumulative hazard function (not super sure of the calculation), the step after dividing by partial hazard is not the same i.e., 2 different baseline hazards. Any help appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qltap", "is_robot_indexable": true, "report_reasons": null, "author": "thesaintyouneed", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qltap/facing_inconsistencies_while_trying_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qltap/facing_inconsistencies_while_trying_to/", "subreddit_subscribers": 875499, "created_utc": 1681821775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! I am currently writing a series of articles about the pre-processing steps for time series data.  \n\nIn the first article, I suggest the following order: \n\n1. Handle missing values \n2. Remove trend \n3. Remove seasonality \n4. Check for stationarity and make it stationary if necessary \n5. Normalize the data \n6. Remove outliers \n7. Smooth the data \n\nHowever, I know this order is not universal and can be changed depending on our data. Also, not all the steps are always required.  \n\nMy question is, which would be the \"standard\" order that you would suggest?  \n\nI leave the first part of these articles [here](https://mlpills.dev/time-series/clean-your-time-series-data-i/) and the second one [here](https://mlpills.dev/time-series/clean-your-time-series-data-ii/). The last two parts are written but not published yet :( \n\nI'd love to hear some feedback. :)\n\n Thanks!", "author_fullname": "t2_gvvf9r1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pre-processing order for time series data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qi9b4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681812524.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I am currently writing a series of articles about the pre-processing steps for time series data.  &lt;/p&gt;\n\n&lt;p&gt;In the first article, I suggest the following order: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Handle missing values &lt;/li&gt;\n&lt;li&gt;Remove trend &lt;/li&gt;\n&lt;li&gt;Remove seasonality &lt;/li&gt;\n&lt;li&gt;Check for stationarity and make it stationary if necessary &lt;/li&gt;\n&lt;li&gt;Normalize the data &lt;/li&gt;\n&lt;li&gt;Remove outliers &lt;/li&gt;\n&lt;li&gt;Smooth the data &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;However, I know this order is not universal and can be changed depending on our data. Also, not all the steps are always required.  &lt;/p&gt;\n\n&lt;p&gt;My question is, which would be the &amp;quot;standard&amp;quot; order that you would suggest?  &lt;/p&gt;\n\n&lt;p&gt;I leave the first part of these articles &lt;a href=\"https://mlpills.dev/time-series/clean-your-time-series-data-i/\"&gt;here&lt;/a&gt; and the second one &lt;a href=\"https://mlpills.dev/time-series/clean-your-time-series-data-ii/\"&gt;here&lt;/a&gt;. The last two parts are written but not published yet :( &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear some feedback. :)&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?auto=webp&amp;v=enabled&amp;s=2e987cc53a9606585b9baea3b9c3056362d77e3f", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b73276f3c7bed3898752484fca308aad5f66cc0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e2fa795d34a622e420f1f36e8388f25a2ac8789", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=358d8be8f2dd2edc85977a8aa927b07835df2b53", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b01d8de571f37cfff87ee9b58097cff988258d1", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0d9065265650f0e4234b339bc7f47411a7c790b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8de1b636fa63a6391629a2acd3898bee1f5f405", "width": 1080, "height": 607}], "variants": {}, "id": "z2mUwpw_935DsBDU4V1KJzNU_rF0PEhxMVMa8oVerhk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qi9b4", "is_robot_indexable": true, "report_reasons": null, "author": "daansan-ml", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qi9b4/preprocessing_order_for_time_series_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qi9b4/preprocessing_order_for_time_series_data/", "subreddit_subscribers": 875499, "created_utc": 1681812524.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All\n\nI've been posting on here quite a bit and have been really enjoying the responses I've been getting and have been learning a ton.\n\nI had a question about A/B testing with CTR\n\nLet's assume we will run an experiment where CTR is our primary metric, and that our experiment will allocate/sample on a user-level\n\nThis means when we calculate sample size and power analysis, this should be done on a user-level, is that correct?\n\nWhat is the proper way to do this, given ad data is typically on an impression level?\n\nMy thoughts:\n\naggregate on a user-level, where columns are # of impressions, # of clicks, and ctr of each user\n\nyour metric is now continuous since it is ctr of each user, and you can calculate the weighted stdev/variance.\n\n&amp;#x200B;\n\nis this a valid approach?", "author_fullname": "t2_133emd5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A/B Test with CTR - User Level", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q3a13", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681777582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been posting on here quite a bit and have been really enjoying the responses I&amp;#39;ve been getting and have been learning a ton.&lt;/p&gt;\n\n&lt;p&gt;I had a question about A/B testing with CTR&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s assume we will run an experiment where CTR is our primary metric, and that our experiment will allocate/sample on a user-level&lt;/p&gt;\n\n&lt;p&gt;This means when we calculate sample size and power analysis, this should be done on a user-level, is that correct?&lt;/p&gt;\n\n&lt;p&gt;What is the proper way to do this, given ad data is typically on an impression level?&lt;/p&gt;\n\n&lt;p&gt;My thoughts:&lt;/p&gt;\n\n&lt;p&gt;aggregate on a user-level, where columns are # of impressions, # of clicks, and ctr of each user&lt;/p&gt;\n\n&lt;p&gt;your metric is now continuous since it is ctr of each user, and you can calculate the weighted stdev/variance.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;is this a valid approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q3a13", "is_robot_indexable": true, "report_reasons": null, "author": "vatom14", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q3a13/ab_test_with_ctr_user_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q3a13/ab_test_with_ctr_user_level/", "subreddit_subscribers": 875499, "created_utc": 1681777582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi friends, I\u2019m working on a uni project where I have I have to attribute multiple factors (e.g. promotions, inventory levels, store closures, etc.) to a retail sales increase / decrease for a particular week. So like I want to say like \u201cgood weather was responsible for driving sales this week.\u201d\n\nWhat\u2019s the best type of causal model / lib to use in this case? I\u2019m thinking of using something like DoWhy, but not sure if there\u2019s other causal frameworks out there that could be more relevant? \n\nThanks!", "author_fullname": "t2_1blas9up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Retail Sales Attribution Models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pw7za", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681764497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends, I\u2019m working on a uni project where I have I have to attribute multiple factors (e.g. promotions, inventory levels, store closures, etc.) to a retail sales increase / decrease for a particular week. So like I want to say like \u201cgood weather was responsible for driving sales this week.\u201d&lt;/p&gt;\n\n&lt;p&gt;What\u2019s the best type of causal model / lib to use in this case? I\u2019m thinking of using something like DoWhy, but not sure if there\u2019s other causal frameworks out there that could be more relevant? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pw7za", "is_robot_indexable": true, "report_reasons": null, "author": "chocolate_bear95", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pw7za/retail_sales_attribution_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pw7za/retail_sales_attribution_models/", "subreddit_subscribers": 875499, "created_utc": 1681764497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm training an xgboost model in R using the caret package. I added class weights to the train control because my binary outcome is very skewed. However, the model with weights has an AUROC of 0.49, whereas the model without the weights has an AUROC of 0.88. I have other models too including logistic regression, random forest, etc, and their AUROC increased after implementing the weights. So why does it decrease it so much for XGBoost, is it because XGB already gives bigger weight to wrongly predicted observations in previous iterations?", "author_fullname": "t2_ing7dag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about class weights in xgboost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12poilz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681749797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m training an xgboost model in R using the caret package. I added class weights to the train control because my binary outcome is very skewed. However, the model with weights has an AUROC of 0.49, whereas the model without the weights has an AUROC of 0.88. I have other models too including logistic regression, random forest, etc, and their AUROC increased after implementing the weights. So why does it decrease it so much for XGBoost, is it because XGB already gives bigger weight to wrongly predicted observations in previous iterations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12poilz", "is_robot_indexable": true, "report_reasons": null, "author": "Goliof", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12poilz/question_about_class_weights_in_xgboost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12poilz/question_about_class_weights_in_xgboost/", "subreddit_subscribers": 875499, "created_utc": 1681749797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2ju6xn4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u202aFound this inspiring. Are there any current database systems that transform natural language queries into SQL?\u202c", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_12qo3hx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kOEbs7vYaLoap9AKdH0bQz3hs0qNffXXnwqhMfg2cxc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681826581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1chuzepdgnua1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1chuzepdgnua1.jpg?auto=webp&amp;v=enabled&amp;s=2bdca876fc559a0bf94a223bbc5720cbd74f17d7", "width": 750, "height": 868}, "resolutions": [{"url": "https://preview.redd.it/1chuzepdgnua1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d731759c06c0e6ca63fd711d55b56afb3b20bf11", "width": 108, "height": 124}, {"url": "https://preview.redd.it/1chuzepdgnua1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8423ada8ac05088220a5f361239466a1a3ce586", "width": 216, "height": 249}, {"url": "https://preview.redd.it/1chuzepdgnua1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba94b588f04fb27112f3dc886ca223e19511cfcf", "width": 320, "height": 370}, {"url": "https://preview.redd.it/1chuzepdgnua1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3e42f0e958bb960cb5e28f5f933535bf6f33641", "width": 640, "height": 740}], "variants": {}, "id": "oFgUzF6gGGU-L6uiYyWIQ-AKPSRuNwJyQdSMCTeTvGE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qo3hx", "is_robot_indexable": true, "report_reasons": null, "author": "Jebertian", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qo3hx/found_this_inspiring_are_there_any_current/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1chuzepdgnua1.jpg", "subreddit_subscribers": 875499, "created_utc": 1681826581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Please recommend data science/ml books for retail industry/supply chain with more practical implementations.", "author_fullname": "t2_aspf3blq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book recommendations: data science in retail, practical implementations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qnww7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681826205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please recommend data science/ml books for retail industry/supply chain with more practical implementations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qnww7", "is_robot_indexable": true, "report_reasons": null, "author": "Bayesian8", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qnww7/book_recommendations_data_science_in_retail/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qnww7/book_recommendations_data_science_in_retail/", "subreddit_subscribers": 875499, "created_utc": 1681826205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys! In 2 weeks I'm starting my new role as a data scientist. Since I come from another field and I'm still such a green bean, my new boss has decided to get me into a bootcamp. He suggested the one from DataScientest (~285 hours) unless I propose another one. To those of you in Europe: Have you guys heard anything of this bootcamp? Any good/bad experiences you can share about it?", "author_fullname": "t2_6xiu1hs9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataScientest bootcamp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qnwdf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681826173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys! In 2 weeks I&amp;#39;m starting my new role as a data scientist. Since I come from another field and I&amp;#39;m still such a green bean, my new boss has decided to get me into a bootcamp. He suggested the one from DataScientest (~285 hours) unless I propose another one. To those of you in Europe: Have you guys heard anything of this bootcamp? Any good/bad experiences you can share about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qnwdf", "is_robot_indexable": true, "report_reasons": null, "author": "Davidat0r", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qnwdf/datascientest_bootcamp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qnwdf/datascientest_bootcamp/", "subreddit_subscribers": 875499, "created_utc": 1681826173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For my work I\u2019m hunting a dataset that is:\nWestern companies doing their manufacturing of electronics specifically in China or Taiwan. \n\nI\u2019m having a tough time coming up with a comprehensive dataset or list of these companies. \n\nOnly thing I\u2019m able to find is the largest 50 companies from Google searches. Any advice? Thanks in advance!", "author_fullname": "t2_a7xiz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you find datasets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qnn5h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681825634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For my work I\u2019m hunting a dataset that is:\nWestern companies doing their manufacturing of electronics specifically in China or Taiwan. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m having a tough time coming up with a comprehensive dataset or list of these companies. &lt;/p&gt;\n\n&lt;p&gt;Only thing I\u2019m able to find is the largest 50 companies from Google searches. Any advice? Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qnn5h", "is_robot_indexable": true, "report_reasons": null, "author": "HomeStar182", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qnn5h/where_do_you_find_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qnn5h/where_do_you_find_datasets/", "subreddit_subscribers": 875499, "created_utc": 1681825634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Question to all the veterans out there:\n\n1. What are some of the most common problems that the current ML tools/startups are NOT able to solve?\n\n2. If given an option, hypothetically speaking, what all features would you have added in your favourite tool to make it 100% complete and a \"go-to\" software?", "author_fullname": "t2_a4d2j3fh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Problem with current ML tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qfblm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681804454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Question to all the veterans out there:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What are some of the most common problems that the current ML tools/startups are NOT able to solve?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;If given an option, hypothetically speaking, what all features would you have added in your favourite tool to make it 100% complete and a &amp;quot;go-to&amp;quot; software?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qfblm", "is_robot_indexable": true, "report_reasons": null, "author": "Living-Nobody-2727", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qfblm/problem_with_current_ml_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qfblm/problem_with_current_ml_tools/", "subreddit_subscribers": 875499, "created_utc": 1681804454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hi! right now im looking to major in cs at georgia tech, and i'm not sure how much of a pipeline that leaves me out of undergrad. if i want to get in to data science out of undergrad, what might i need to do? does anyone have any experiences to share?\n\nim thinking of doing computational data analysis as a minor, infosystems and intelligence as \"subfocuses\" within my major, and i plan on joining some data science and ML bootcamps and clubs.... any other suggestions?\n\ni want to stick to a comp sci major, because i still want a good compsci foundation, just in case i dont end up enjoying ds. ", "author_fullname": "t2_5rc1mk09o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what might i need to get into data science as an undergrad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q7dbo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681785696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi! right now im looking to major in cs at georgia tech, and i&amp;#39;m not sure how much of a pipeline that leaves me out of undergrad. if i want to get in to data science out of undergrad, what might i need to do? does anyone have any experiences to share?&lt;/p&gt;\n\n&lt;p&gt;im thinking of doing computational data analysis as a minor, infosystems and intelligence as &amp;quot;subfocuses&amp;quot; within my major, and i plan on joining some data science and ML bootcamps and clubs.... any other suggestions?&lt;/p&gt;\n\n&lt;p&gt;i want to stick to a comp sci major, because i still want a good compsci foundation, just in case i dont end up enjoying ds. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q7dbo", "is_robot_indexable": true, "report_reasons": null, "author": "desperate_DS_student", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q7dbo/what_might_i_need_to_get_into_data_science_as_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q7dbo/what_might_i_need_to_get_into_data_science_as_an/", "subreddit_subscribers": 875499, "created_utc": 1681785696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Quality Checks, lack of a standard, complexity of BRMS.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qmgwt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_fcv4rhtp", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow redditors. I am currently working on a project wihere i have to create a data quality framework. I am at the point where i have to implement a bunch of data quality checks/rules, be they simple rules such as checking nullity, uniqueness, or more complexe involving accuracy, consistency and validation (Rules checking if value X is present then Y must be present and have specific value + some coherence with dates). The metrics mentioned previously are 5 metrics of data quality in general (i know there are more but i am restrained  to those.\n\n  \nThe data quality is performed on raw data present in an oracle database and my technical constraints are as follow :\n\n1. No Proprietary solutions\n2. No Cloud (means no spark and no deequ)\n\nThe data range from 10 to 100 GB per table, and for the current table i am working on i have at least a 100 rules to implements (more to come). I made ***POC*** using python, implementing just a few rules which resulted in the following conclusions for each metric  (made an individual function for each metrics) :\n\n1. Completeness:  Getting the nulls for each columns, was easy to implement using pure sql.\n2. Uniqueness : Checking uniqueness for multiple columns, not hard to implement but needs optimization.\n3. Accuracy, Consistency, Validation : Necessity of manual if else like implementation, which would results in spaghetti code if more rules were added.\n4. Overall : Performance was ignored when implementing, but it became clear that more rules will lead to additionnal problems be it in performance or maintanability.\n\nThis lead me to search for an alternative solutions and a BRE seemed like one but there doesn't seem to be a standard of which tool to use in terms of data quality, and while i am not afraid of learning a new language like CLIPS (PYCLIPS), or Java (DROOLS) (already have some \"basics\" since i had some course in java for the sake of the OOP paradigms). I am lost as to what to tool to consider and invest my time in it, it would be quite painful to spend a few months in a language/framework, to finally notice it was a bad choice and non-standard.\n\n(I checked out Soda-core SodaCL but i lack the experience to tell if it is a good solution especially since it's recent and doesn't fully support my oracle database version)  \n\n\nCan anyone please orient me towards a language or set of tools that would allow me to achieve the desired results ? The current favorite is CLIPS as it would allow me full control on the engine but i am not sure if it is worth it. Also as it seems that all  the answers i could find were  either outdated or were outside any data quality topic, i will try to edit this post accordingly.  \nThis project is done during my data science internship.  \n\n\nThank you for your time.", "author_fullname": "t2_fcv4rhtp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Quality Checks, lack of a standard, complexity of BRMS.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qmg64", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681823112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow redditors. I am currently working on a project wihere i have to create a data quality framework. I am at the point where i have to implement a bunch of data quality checks/rules, be they simple rules such as checking nullity, uniqueness, or more complexe involving accuracy, consistency and validation (Rules checking if value X is present then Y must be present and have specific value + some coherence with dates). The metrics mentioned previously are 5 metrics of data quality in general (i know there are more but i am restrained  to those.&lt;/p&gt;\n\n&lt;p&gt;The data quality is performed on raw data present in an oracle database and my technical constraints are as follow :&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;No Proprietary solutions&lt;/li&gt;\n&lt;li&gt;No Cloud (means no spark and no deequ)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The data range from 10 to 100 GB per table, and for the current table i am working on i have at least a 100 rules to implements (more to come). I made &lt;strong&gt;&lt;em&gt;POC&lt;/em&gt;&lt;/strong&gt; using python, implementing just a few rules which resulted in the following conclusions for each metric  (made an individual function for each metrics) :&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Completeness:  Getting the nulls for each columns, was easy to implement using pure sql.&lt;/li&gt;\n&lt;li&gt;Uniqueness : Checking uniqueness for multiple columns, not hard to implement but needs optimization.&lt;/li&gt;\n&lt;li&gt;Accuracy, Consistency, Validation : Necessity of manual if else like implementation, which would results in spaghetti code if more rules were added.&lt;/li&gt;\n&lt;li&gt;Overall : Performance was ignored when implementing, but it became clear that more rules will lead to additionnal problems be it in performance or maintanability.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This lead me to search for an alternative solutions and a BRE seemed like one but there doesn&amp;#39;t seem to be a standard of which tool to use in terms of data quality, and while i am not afraid of learning a new language like CLIPS (PYCLIPS), or Java (DROOLS) (already have some &amp;quot;basics&amp;quot; since i had some course in java for the sake of the OOP paradigms). I am lost as to what to tool to consider and invest my time in it, it would be quite painful to spend a few months in a language/framework, to finally notice it was a bad choice and non-standard.&lt;/p&gt;\n\n&lt;p&gt;(I checked out Soda-core SodaCL but i lack the experience to tell if it is a good solution especially since it&amp;#39;s recent and doesn&amp;#39;t fully support my oracle database version)  &lt;/p&gt;\n\n&lt;p&gt;Can anyone please orient me towards a language or set of tools that would allow me to achieve the desired results ? The current favorite is CLIPS as it would allow me full control on the engine but i am not sure if it is worth it. Also as it seems that all  the answers i could find were  either outdated or were outside any data quality topic, i will try to edit this post accordingly.&lt;br/&gt;\nThis project is done during my data science internship.  &lt;/p&gt;\n\n&lt;p&gt;Thank you for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12qmg64", "is_robot_indexable": true, "report_reasons": null, "author": "Still-W1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12qmg64/data_quality_checks_lack_of_a_standard_complexity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12qmg64/data_quality_checks_lack_of_a_standard_complexity/", "subreddit_subscribers": 100212, "created_utc": 1681823112.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1681823153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/dataengineering/comments/12qmg64/data_quality_checks_lack_of_a_standard_complexity/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qmgwt", "is_robot_indexable": true, "report_reasons": null, "author": "Still-W1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12qmg64", "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qmgwt/data_quality_checks_lack_of_a_standard_complexity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/dataengineering/comments/12qmg64/data_quality_checks_lack_of_a_standard_complexity/", "subreddit_subscribers": 875499, "created_utc": 1681823153.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A bit of context here, I\u2019m a recent masters graduate in data science, and have worked in this start up for over a year. \n\nI am leaving for a different position but they would like to offer me a part-time data science consultant role, having meetings about 1-2 hours per week. \n\nAdditionally, I was also the sole data scientist in the start-up, henceforth have a lot of inside knowledge of the business and built up a lot of their models. The question is how much should I ask for (per hour) as a novice data science consultant? Is there an average salary I can find?\n\nThanks in advance.", "author_fullname": "t2_5bnzok06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much should a data science consultant earn (UK)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qk0er", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681817172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A bit of context here, I\u2019m a recent masters graduate in data science, and have worked in this start up for over a year. &lt;/p&gt;\n\n&lt;p&gt;I am leaving for a different position but they would like to offer me a part-time data science consultant role, having meetings about 1-2 hours per week. &lt;/p&gt;\n\n&lt;p&gt;Additionally, I was also the sole data scientist in the start-up, henceforth have a lot of inside knowledge of the business and built up a lot of their models. The question is how much should I ask for (per hour) as a novice data science consultant? Is there an average salary I can find?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qk0er", "is_robot_indexable": true, "report_reasons": null, "author": "rawpenguinsauce", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qk0er/how_much_should_a_data_science_consultant_earn_uk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qk0er/how_much_should_a_data_science_consultant_earn_uk/", "subreddit_subscribers": 875499, "created_utc": 1681817172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm just starting taking a coursera lecture of Deeplearning.ai with many recommendations from here. My question is where the slide notes used during the course are....? I'm quite tired of taking screenshots of every scenes.\nThanks!", "author_fullname": "t2_8hz0gfkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coursera slide notes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qjpez", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681816273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m just starting taking a coursera lecture of Deeplearning.ai with many recommendations from here. My question is where the slide notes used during the course are....? I&amp;#39;m quite tired of taking screenshots of every scenes.\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qjpez", "is_robot_indexable": true, "report_reasons": null, "author": "August_SEO", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qjpez/coursera_slide_notes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qjpez/coursera_slide_notes/", "subreddit_subscribers": 875499, "created_utc": 1681816273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A data set including 700,000 pictures of industrial items with defects is given to you. The only thing you are aware of is that every image contains at least one obvious flaw. But you don't know where the flaw is or what kind of problem it is. Build a classifier that can distinguish between pieces that are OK and those that are defective. What would be your strategy?\n\n**Edit** : \nWhat would you say - if I would try to use an algorithm to try to match each image with one another, and transform an image via homography from one to another and try to find the difference between the images. Build an image which has all common features and then augment 80% of the images to remove all defects, but still have all variations of image perspectives. Would this be possible?", "author_fullname": "t2_30m20xwn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datascience Challenge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qij3w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.36, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681820860.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681813262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A data set including 700,000 pictures of industrial items with defects is given to you. The only thing you are aware of is that every image contains at least one obvious flaw. But you don&amp;#39;t know where the flaw is or what kind of problem it is. Build a classifier that can distinguish between pieces that are OK and those that are defective. What would be your strategy?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit&lt;/strong&gt; : \nWhat would you say - if I would try to use an algorithm to try to match each image with one another, and transform an image via homography from one to another and try to find the difference between the images. Build an image which has all common features and then augment 80% of the images to remove all defects, but still have all variations of image perspectives. Would this be possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qij3w", "is_robot_indexable": true, "report_reasons": null, "author": "_synaps_", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qij3w/datascience_challenge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qij3w/datascience_challenge/", "subreddit_subscribers": 875499, "created_utc": 1681813262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Can anyone provide me a brief summary or Article on How to Choose the Right Visualizations for Data Science?", "author_fullname": "t2_g6jw1icc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Choose the Right Visualizations fir Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qi4hs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681812177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone provide me a brief summary or Article on How to Choose the Right Visualizations for Data Science?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qi4hs", "is_robot_indexable": true, "report_reasons": null, "author": "Typical-Impress-4182", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qi4hs/how_to_choose_the_right_visualizations_fir_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qi4hs/how_to_choose_the_right_visualizations_fir_data/", "subreddit_subscribers": 875499, "created_utc": 1681812177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have an HR screening interview for a data analyst role and wonder what questions will be asked. I know some common questions like tell me about yourself, what are you interested in this role? Why this company?Biggest accomplishment? Do you have any thoughts on other types of questions?", "author_fullname": "t2_8lzodaki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HR Screening Interview for half an hour", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qevdw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681803127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an HR screening interview for a data analyst role and wonder what questions will be asked. I know some common questions like tell me about yourself, what are you interested in this role? Why this company?Biggest accomplishment? Do you have any thoughts on other types of questions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qevdw", "is_robot_indexable": true, "report_reasons": null, "author": "Hidimbaa", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qevdw/hr_screening_interview_for_half_an_hour/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qevdw/hr_screening_interview_for_half_an_hour/", "subreddit_subscribers": 875499, "created_utc": 1681803127.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hey r/datascience. \n\nI come from a business background and over the years have slowly made my way to data analysis and now moving to data science. However, one thing I noticed from other professionals that come from a computer science background is their more intricate knowledge of the tools and their interactions. Mid 2000's. after getting tired of Excel + VBA I started working with SQL. When programming languages became a necessity for my work, I learned Python (also some JavaScript, but that's not here nor there). after getting to the point I needed more number crunching and statistical approaches, I learned R. I don't consider myself an expert, but I at least understand the tools.... separately, at least. Now that I'm formally doing my masters, more than once I have been jumping from software to software, not to mention when doing collaborations (all my work so far was done by me and for me, only the insights and reports needed to be shared, so no one else ever worked on my codes), I have no idea on how to setup everything.   \n\nSo, I came here to ask: What is a good workflow and best practices to start with? Currently, most of my work is done either on PyCharm (for more complex coding), Jupiter (for EDA) and RStudio (for R). Regarding git and GitHub, I only ever used it through RStudio (other than the bash shell, of course). However, is there go-to approach where I can use the same tool for everything (or for most part of it)? I know how to do what I need, just not an efficient way to do it specially if I have to work with others.", "author_fullname": "t2_fna4qb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with workflow and best practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q9wxe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681791112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;I come from a business background and over the years have slowly made my way to data analysis and now moving to data science. However, one thing I noticed from other professionals that come from a computer science background is their more intricate knowledge of the tools and their interactions. Mid 2000&amp;#39;s. after getting tired of Excel + VBA I started working with SQL. When programming languages became a necessity for my work, I learned Python (also some JavaScript, but that&amp;#39;s not here nor there). after getting to the point I needed more number crunching and statistical approaches, I learned R. I don&amp;#39;t consider myself an expert, but I at least understand the tools.... separately, at least. Now that I&amp;#39;m formally doing my masters, more than once I have been jumping from software to software, not to mention when doing collaborations (all my work so far was done by me and for me, only the insights and reports needed to be shared, so no one else ever worked on my codes), I have no idea on how to setup everything.   &lt;/p&gt;\n\n&lt;p&gt;So, I came here to ask: What is a good workflow and best practices to start with? Currently, most of my work is done either on PyCharm (for more complex coding), Jupiter (for EDA) and RStudio (for R). Regarding git and GitHub, I only ever used it through RStudio (other than the bash shell, of course). However, is there go-to approach where I can use the same tool for everything (or for most part of it)? I know how to do what I need, just not an efficient way to do it specially if I have to work with others.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q9wxe", "is_robot_indexable": true, "report_reasons": null, "author": "rpcsanches", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q9wxe/help_with_workflow_and_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q9wxe/help_with_workflow_and_best_practices/", "subreddit_subscribers": 875499, "created_utc": 1681791112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in the middle of studying Economics outside the US (i.e. Brazil). I've studied Python, R and SQL for data science with more intensity since few months ago and increasing the study of statistics and math. I know that most data scientists are statisticians, mathematicians, etc. But I'm really interested in the field of data science. \n\nThen, I'm thinking of doing a master's degree in any field that will enhance my ability to become a data scientist and probably apply to a job in US in the future... \n\nWhat master's degree do I need to do after studying Economics, especially in my case (are there any senior economists that become a DS here to share their point of view?)? Should I start thinking about applying to any internship in data analysis to develop a good portfolio right now?\n\nAnyway, I'm open to suggestions. Tyvm :)", "author_fullname": "t2_e3lj119b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm a Economics Student", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q6gp8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681784565.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681783878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the middle of studying Economics outside the US (i.e. Brazil). I&amp;#39;ve studied Python, R and SQL for data science with more intensity since few months ago and increasing the study of statistics and math. I know that most data scientists are statisticians, mathematicians, etc. But I&amp;#39;m really interested in the field of data science. &lt;/p&gt;\n\n&lt;p&gt;Then, I&amp;#39;m thinking of doing a master&amp;#39;s degree in any field that will enhance my ability to become a data scientist and probably apply to a job in US in the future... &lt;/p&gt;\n\n&lt;p&gt;What master&amp;#39;s degree do I need to do after studying Economics, especially in my case (are there any senior economists that become a DS here to share their point of view?)? Should I start thinking about applying to any internship in data analysis to develop a good portfolio right now?&lt;/p&gt;\n\n&lt;p&gt;Anyway, I&amp;#39;m open to suggestions. Tyvm :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q6gp8", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic_Bite6696", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q6gp8/im_a_economics_student/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q6gp8/im_a_economics_student/", "subreddit_subscribers": 875499, "created_utc": 1681783878.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}