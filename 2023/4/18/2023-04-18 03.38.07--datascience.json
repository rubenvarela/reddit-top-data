{"kind": "Listing", "data": {"after": "t3_12pzfuy", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When a dataset has 27 features, how to start visualizing. Should i start from scratch or use correlation and see the relation or any other?", "author_fullname": "t2_jx6tumem", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to work on visualization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pa2uy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 72, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 72, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681725083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When a dataset has 27 features, how to start visualizing. Should i start from scratch or use correlation and see the relation or any other?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pa2uy", "is_robot_indexable": true, "report_reasons": null, "author": "DrummerSea4593", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pa2uy/how_to_work_on_visualization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pa2uy/how_to_work_on_visualization/", "subreddit_subscribers": 875216, "created_utc": 1681725083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey r/datascience!   \nI found [this ancient thread](https://www.reddit.com/r/datascience/comments/bx59cv/tool_for_integrating_sql_jupyter_seamlessly/) about Jupyter Notebooks and SQL queries.   \nI\u2019m wondering if:\n\n1. Are people here still running SQL from within the notebook?\n2. What best practices/tips do you have?\n3. What are the main use cases?\n\nI usually use it to connect to multiple sources, store the queries within the notebook, and then put the notebooks into version control. I also found pandas way slower from running a duckdb + jupysql when possible.", "author_fullname": "t2_sy01bb7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best practices around Jupyter and SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ptgo1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 64, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 64, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681759204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;!&lt;br/&gt;\nI found &lt;a href=\"https://www.reddit.com/r/datascience/comments/bx59cv/tool_for_integrating_sql_jupyter_seamlessly/\"&gt;this ancient thread&lt;/a&gt; about Jupyter Notebooks and SQL queries.&lt;br/&gt;\nI\u2019m wondering if:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Are people here still running SQL from within the notebook?&lt;/li&gt;\n&lt;li&gt;What best practices/tips do you have?&lt;/li&gt;\n&lt;li&gt;What are the main use cases?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I usually use it to connect to multiple sources, store the queries within the notebook, and then put the notebooks into version control. I also found pandas way slower from running a duckdb + jupysql when possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ptgo1", "is_robot_indexable": true, "report_reasons": null, "author": "idomic", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ptgo1/what_are_the_best_practices_around_jupyter_and_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ptgo1/what_are_the_best_practices_around_jupyter_and_sql/", "subreddit_subscribers": 875216, "created_utc": 1681759204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m going to start my first internship soon and I\u2019m going to be the only data scientist there, mainly working with sequential data.\n\nHas anyone tips when it comes to being the only data person?\n\nEdit: forgot to mention that it\u2019s a medtech startup", "author_fullname": "t2_6q7a2p0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tips about being the only data scientist in a startup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pc67k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681761655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681730090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m going to start my first internship soon and I\u2019m going to be the only data scientist there, mainly working with sequential data.&lt;/p&gt;\n\n&lt;p&gt;Has anyone tips when it comes to being the only data person?&lt;/p&gt;\n\n&lt;p&gt;Edit: forgot to mention that it\u2019s a medtech startup&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pc67k", "is_robot_indexable": true, "report_reasons": null, "author": "jeffrey_56", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pc67k/any_tips_about_being_the_only_data_scientist_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pc67k/any_tips_about_being_the_only_data_scientist_in_a/", "subreddit_subscribers": 875216, "created_utc": 1681730090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Apologies for a 2nd post here, but just trying to learn more about A/B testing and experimentation\n\nWhat is the \"harm\" in collecting more data or letting your experiment run longer\n\nFor example, let's assume we determine that we can reach sample size within a week for our primary metric CTR. But we need 3 weeks to measure retention, and so we determine that we must run this experiment for at least 3 weeks\n\nWhat is the harm in running the experiment for 4 weeks? or 5 weeks? Are there pros/cons to this?\n\nApologies for a dumb question again.", "author_fullname": "t2_133emd5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pros/cons of collecting more data in an A/B Test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12p7rxo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681719360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies for a 2nd post here, but just trying to learn more about A/B testing and experimentation&lt;/p&gt;\n\n&lt;p&gt;What is the &amp;quot;harm&amp;quot; in collecting more data or letting your experiment run longer&lt;/p&gt;\n\n&lt;p&gt;For example, let&amp;#39;s assume we determine that we can reach sample size within a week for our primary metric CTR. But we need 3 weeks to measure retention, and so we determine that we must run this experiment for at least 3 weeks&lt;/p&gt;\n\n&lt;p&gt;What is the harm in running the experiment for 4 weeks? or 5 weeks? Are there pros/cons to this?&lt;/p&gt;\n\n&lt;p&gt;Apologies for a dumb question again.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12p7rxo", "is_robot_indexable": true, "report_reasons": null, "author": "vatom14", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12p7rxo/proscons_of_collecting_more_data_in_an_ab_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12p7rxo/proscons_of_collecting_more_data_in_an_ab_test/", "subreddit_subscribers": 875216, "created_utc": 1681719360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I bought \"Practical Statistics for Data Scientists second edition\" and I believe it is fake. I was wondering if anyone has experienced this, or can help me confirm whether it is fake.\n\nThe pages are a light yellow instead of white, and the printing quality of the light grey (numbers in the code, and certain plots) is not good, other than this though, the book looks great. Is this the case with any copies you guys/gals have?\n\nIm not complaining too much though, it was $7 and for that price, it's a great bargain. \n\nThank you", "author_fullname": "t2_vdnydt7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "O REILLY fake textbooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12p8mez", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681721456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought &amp;quot;Practical Statistics for Data Scientists second edition&amp;quot; and I believe it is fake. I was wondering if anyone has experienced this, or can help me confirm whether it is fake.&lt;/p&gt;\n\n&lt;p&gt;The pages are a light yellow instead of white, and the printing quality of the light grey (numbers in the code, and certain plots) is not good, other than this though, the book looks great. Is this the case with any copies you guys/gals have?&lt;/p&gt;\n\n&lt;p&gt;Im not complaining too much though, it was $7 and for that price, it&amp;#39;s a great bargain. &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12p8mez", "is_robot_indexable": true, "report_reasons": null, "author": "ajplant", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12p8mez/o_reilly_fake_textbooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12p8mez/o_reilly_fake_textbooks/", "subreddit_subscribers": 875216, "created_utc": 1681721456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Fitter:  \n [cokelaer/fitter: Fit data to many distributions (github.com)](https://github.com/cokelaer/fitter)", "author_fullname": "t2_3op9qx89", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I recently discovered the python package 'fitter', which is a really nifty package for fitting various data distributions. Has anyone discovered any other cool packages that the field would find useful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ppj7g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681751794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fitter:&lt;br/&gt;\n &lt;a href=\"https://github.com/cokelaer/fitter\"&gt;cokelaer/fitter: Fit data to many distributions (github.com)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ppj7g", "is_robot_indexable": true, "report_reasons": null, "author": "LatterConcentrate6", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ppj7g/i_recently_discovered_the_python_package_fitter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ppj7g/i_recently_discovered_the_python_package_fitter/", "subreddit_subscribers": 875216, "created_utc": 1681751794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm training an xgboost model in R using the caret package. I added class weights to the train control because my binary outcome is very skewed. However, the model with weights has an AUROC of 0.49, whereas the model without the weights has an AUROC of 0.88. I have other models too including logistic regression, random forest, etc, and their AUROC increased after implementing the weights. So why does it decrease it so much for XGBoost, is it because XGB already gives bigger weight to wrongly predicted observations in previous iterations?", "author_fullname": "t2_ing7dag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about class weights in xgboost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12poilz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681749797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m training an xgboost model in R using the caret package. I added class weights to the train control because my binary outcome is very skewed. However, the model with weights has an AUROC of 0.49, whereas the model without the weights has an AUROC of 0.88. I have other models too including logistic regression, random forest, etc, and their AUROC increased after implementing the weights. So why does it decrease it so much for XGBoost, is it because XGB already gives bigger weight to wrongly predicted observations in previous iterations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12poilz", "is_robot_indexable": true, "report_reasons": null, "author": "Goliof", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12poilz/question_about_class_weights_in_xgboost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12poilz/question_about_class_weights_in_xgboost/", "subreddit_subscribers": 875216, "created_utc": 1681749797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear all, for my final thesis, I am doing market research into the German data verification market. I made a short list of 18 questions concerning the market and would like to ask everyone to participate to help me finish my bachelor's degree. I'm happy to share the research's results upon request. \n\nAnyone working in the FinTech, Flex work or healthcare industry  and people that are familiar with the data verification market or active in data science have a valuable opinion in this questionnaire.  \n \nfind the link to questionnaire here: https://form.jotform.com/230624379916362 \n\nKind regards,\nJaydey Braams", "author_fullname": "t2_6kr8y1qc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Market research", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ph0tv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681740080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear all, for my final thesis, I am doing market research into the German data verification market. I made a short list of 18 questions concerning the market and would like to ask everyone to participate to help me finish my bachelor&amp;#39;s degree. I&amp;#39;m happy to share the research&amp;#39;s results upon request. &lt;/p&gt;\n\n&lt;p&gt;Anyone working in the FinTech, Flex work or healthcare industry  and people that are familiar with the data verification market or active in data science have a valuable opinion in this questionnaire.  &lt;/p&gt;\n\n&lt;p&gt;find the link to questionnaire here: &lt;a href=\"https://form.jotform.com/230624379916362\"&gt;https://form.jotform.com/230624379916362&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Kind regards,\nJaydey Braams&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ph0tv", "is_robot_indexable": true, "report_reasons": null, "author": "ogjd020", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ph0tv/market_research/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ph0tv/market_research/", "subreddit_subscribers": 875216, "created_utc": 1681740080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'm trying to do a project which links customer value to there NPS score.\nIt's for a retail company with a focus on credit options, we don't have a CLV metric due to the credit reasons.\nI have tried to find a correlation between total amount spent in the previous 90 days from survey, churn, probability to shop in the next 10 days and average order freq.\nThe hightest was total spent with a correlation of 0.15.\n\nNot sure where to take this. Any advice?", "author_fullname": "t2_7427v7db", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pcywk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681731880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m trying to do a project which links customer value to there NPS score.\nIt&amp;#39;s for a retail company with a focus on credit options, we don&amp;#39;t have a CLV metric due to the credit reasons.\nI have tried to find a correlation between total amount spent in the previous 90 days from survey, churn, probability to shop in the next 10 days and average order freq.\nThe hightest was total spent with a correlation of 0.15.&lt;/p&gt;\n\n&lt;p&gt;Not sure where to take this. Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pcywk", "is_robot_indexable": true, "report_reasons": null, "author": "Grovesy158", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pcywk/project_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pcywk/project_help/", "subreddit_subscribers": 875216, "created_utc": 1681731880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As title, I understand the concept of market mix modeling from the analysis/modeling aspect, but once the model has been approved, how the media optimization works afterward?\n\nit utilizes the outputs/parameters from the model, and it can be done in linear and non linear, but that is about what I know.\n\nAnyone can shed some lights into this? TiA", "author_fullname": "t2_ul5y0kdu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Media Optimization in Marketing Mix Model project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q36b1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681777377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As title, I understand the concept of market mix modeling from the analysis/modeling aspect, but once the model has been approved, how the media optimization works afterward?&lt;/p&gt;\n\n&lt;p&gt;it utilizes the outputs/parameters from the model, and it can be done in linear and non linear, but that is about what I know.&lt;/p&gt;\n\n&lt;p&gt;Anyone can shed some lights into this? TiA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q36b1", "is_robot_indexable": true, "report_reasons": null, "author": "kyleireddit", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q36b1/media_optimization_in_marketing_mix_model_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q36b1/media_optimization_in_marketing_mix_model_project/", "subreddit_subscribers": 875216, "created_utc": 1681777377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi friends, I\u2019m working on a uni project where I have I have to attribute multiple factors (e.g. promotions, inventory levels, store closures, etc.) to a retail sales increase / decrease for a particular week. So like I want to say like \u201cgood weather was responsible for driving sales this week.\u201d\n\nWhat\u2019s the best type of causal model / lib to use in this case? I\u2019m thinking of using something like DoWhy, but not sure if there\u2019s other causal frameworks out there that could be more relevant? \n\nThanks!", "author_fullname": "t2_1blas9up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Retail Sales Attribution Models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pw7za", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681764497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends, I\u2019m working on a uni project where I have I have to attribute multiple factors (e.g. promotions, inventory levels, store closures, etc.) to a retail sales increase / decrease for a particular week. So like I want to say like \u201cgood weather was responsible for driving sales this week.\u201d&lt;/p&gt;\n\n&lt;p&gt;What\u2019s the best type of causal model / lib to use in this case? I\u2019m thinking of using something like DoWhy, but not sure if there\u2019s other causal frameworks out there that could be more relevant? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pw7za", "is_robot_indexable": true, "report_reasons": null, "author": "chocolate_bear95", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pw7za/retail_sales_attribution_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pw7za/retail_sales_attribution_models/", "subreddit_subscribers": 875216, "created_utc": 1681764497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hi! right now im looking to major in cs at georgia tech, and i'm not sure how much of a pipeline that leaves me out of undergrad. if i want to get in to data science out of undergrad, what might i need to do? does anyone have any experiences to share?\n\nim thinking of doing computational data analysis as a minor, infosystems and intelligence as \"subfocuses\" within my major, and i plan on joining some data science and ML bootcamps and clubs.... any other suggestions?\n\ni want to stick to a comp sci major, because i still want a good compsci foundation, just in case i dont end up enjoying ds. ", "author_fullname": "t2_5rc1mk09o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what might i need to get into data science as an undergrad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12q7dbo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681785696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi! right now im looking to major in cs at georgia tech, and i&amp;#39;m not sure how much of a pipeline that leaves me out of undergrad. if i want to get in to data science out of undergrad, what might i need to do? does anyone have any experiences to share?&lt;/p&gt;\n\n&lt;p&gt;im thinking of doing computational data analysis as a minor, infosystems and intelligence as &amp;quot;subfocuses&amp;quot; within my major, and i plan on joining some data science and ML bootcamps and clubs.... any other suggestions?&lt;/p&gt;\n\n&lt;p&gt;i want to stick to a comp sci major, because i still want a good compsci foundation, just in case i dont end up enjoying ds. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q7dbo", "is_robot_indexable": true, "report_reasons": null, "author": "desperate_DS_student", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q7dbo/what_might_i_need_to_get_into_data_science_as_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q7dbo/what_might_i_need_to_get_into_data_science_as_an/", "subreddit_subscribers": 875216, "created_utc": 1681785696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All\n\nI've been posting on here quite a bit and have been really enjoying the responses I've been getting and have been learning a ton.\n\nI had a question about A/B testing with CTR\n\nLet's assume we will run an experiment where CTR is our primary metric, and that our experiment will allocate/sample on a user-level\n\nThis means when we calculate sample size and power analysis, this should be done on a user-level, is that correct?\n\nWhat is the proper way to do this, given ad data is typically on an impression level?\n\nMy thoughts:\n\naggregate on a user-level, where columns are # of impressions, # of clicks, and ctr of each user\n\nyour metric is now continuous since it is ctr of each user, and you can calculate the weighted stdev/variance.\n\n&amp;#x200B;\n\nis this a valid approach?", "author_fullname": "t2_133emd5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A/B Test with CTR - User Level", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q3a13", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681777582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been posting on here quite a bit and have been really enjoying the responses I&amp;#39;ve been getting and have been learning a ton.&lt;/p&gt;\n\n&lt;p&gt;I had a question about A/B testing with CTR&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s assume we will run an experiment where CTR is our primary metric, and that our experiment will allocate/sample on a user-level&lt;/p&gt;\n\n&lt;p&gt;This means when we calculate sample size and power analysis, this should be done on a user-level, is that correct?&lt;/p&gt;\n\n&lt;p&gt;What is the proper way to do this, given ad data is typically on an impression level?&lt;/p&gt;\n\n&lt;p&gt;My thoughts:&lt;/p&gt;\n\n&lt;p&gt;aggregate on a user-level, where columns are # of impressions, # of clicks, and ctr of each user&lt;/p&gt;\n\n&lt;p&gt;your metric is now continuous since it is ctr of each user, and you can calculate the weighted stdev/variance.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;is this a valid approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q3a13", "is_robot_indexable": true, "report_reasons": null, "author": "vatom14", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q3a13/ab_test_with_ctr_user_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q3a13/ab_test_with_ctr_user_level/", "subreddit_subscribers": 875216, "created_utc": 1681777582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does it happen that you will be at Kubecon Europe 2023? We will be at **booth P15**, ready to talk about AI/ML, MLOps, open-source ML, Kubeflow, and more. There are a bunch of demos Ubuntu prepared and a fun keynote on secure MLOps. [Read more](https://medium.com/@andreeamihaelamunteanu/open-source-mlops-at-kubecon-with-ubuntu-870d06742b4f) and meet us there!", "author_fullname": "t2_3z4miuvs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kubecon Europe 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pzypd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681771222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does it happen that you will be at Kubecon Europe 2023? We will be at &lt;strong&gt;booth P15&lt;/strong&gt;, ready to talk about AI/ML, MLOps, open-source ML, Kubeflow, and more. There are a bunch of demos Ubuntu prepared and a fun keynote on secure MLOps. &lt;a href=\"https://medium.com/@andreeamihaelamunteanu/open-source-mlops-at-kubecon-with-ubuntu-870d06742b4f\"&gt;Read more&lt;/a&gt; and meet us there!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?auto=webp&amp;v=enabled&amp;s=77fa09475f5677298ce0f781605f8b30e3872c28", "width": 720, "height": 376}, "resolutions": [{"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df046630b5228d489c6666882cd309e9a7db6bad", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=951a9937f2949b1944ec19a4be60f600d93bf424", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4928ff7617de6e675af1ca549a2751852e323de4", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd34f0217fe410444e028ce9b2b455e5962469a7", "width": 640, "height": 334}], "variants": {}, "id": "nXaAxnhnc4JIZNk3qgMyfIBphHx3dRXGnYjGSFZKG2I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pzypd", "is_robot_indexable": true, "report_reasons": null, "author": "andreea-mun", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pzypd/kubecon_europe_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pzypd/kubecon_europe_2023/", "subreddit_subscribers": 875216, "created_utc": 1681771222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm thinking about a work problem and not sure if I am making a dumb mistake.\n\nLet's assume we are designing some A/B test, calculate the same sample size required and etc. Let's say sample size required for experiment is 100 users. Let's say the company get 1k users per day.\n\nWhat is the absolute minimum number of days required for the experiment? Can we not technically run the experiment in a day? \n\nOf course we would want to run it for maybe a week at least to capture any variation maybe throughout the week or something - but is the absolute minimum just 1 day or am i oversimplifying?", "author_fullname": "t2_133emd5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Minimum duration of an experiment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12p54le", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681712951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m thinking about a work problem and not sure if I am making a dumb mistake.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s assume we are designing some A/B test, calculate the same sample size required and etc. Let&amp;#39;s say sample size required for experiment is 100 users. Let&amp;#39;s say the company get 1k users per day.&lt;/p&gt;\n\n&lt;p&gt;What is the absolute minimum number of days required for the experiment? Can we not technically run the experiment in a day? &lt;/p&gt;\n\n&lt;p&gt;Of course we would want to run it for maybe a week at least to capture any variation maybe throughout the week or something - but is the absolute minimum just 1 day or am i oversimplifying?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12p54le", "is_robot_indexable": true, "report_reasons": null, "author": "vatom14", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12p54le/minimum_duration_of_an_experiment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12p54le/minimum_duration_of_an_experiment/", "subreddit_subscribers": 875216, "created_utc": 1681712951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 17 Apr, 2023 - 24 Apr, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12p185o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681704087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12p185o", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 7, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12p185o/weekly_entering_transitioning_thread_17_apr_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/12p185o/weekly_entering_transitioning_thread_17_apr_2023/", "subreddit_subscribers": 875216, "created_utc": 1681704087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in the middle of studying Economics outside the US (i.e. Brazil). I've studied Python, R and SQL for data science with more intensity since few months ago and increasing the study of statistics and math. I know that most data scientists are statisticians, mathematicians, etc. But I'm really interested in the field of data science. \n\nThen, I'm thinking of doing a master's degree in any field that will enhance my ability to become a data scientist and probably apply to a job in US in the future... \n\nWhat master's degree do I need to do after studying Economics, especially in my case (are there any senior economists that become a DS here to share their point of view?)? Should I start thinking about applying to any internship in data analysis to develop a good portfolio right now?\n\nAnyway, I'm open to suggestions. Tyvm :)", "author_fullname": "t2_e3lj119b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm a Economics Student", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12q6gp8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681784565.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681783878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the middle of studying Economics outside the US (i.e. Brazil). I&amp;#39;ve studied Python, R and SQL for data science with more intensity since few months ago and increasing the study of statistics and math. I know that most data scientists are statisticians, mathematicians, etc. But I&amp;#39;m really interested in the field of data science. &lt;/p&gt;\n\n&lt;p&gt;Then, I&amp;#39;m thinking of doing a master&amp;#39;s degree in any field that will enhance my ability to become a data scientist and probably apply to a job in US in the future... &lt;/p&gt;\n\n&lt;p&gt;What master&amp;#39;s degree do I need to do after studying Economics, especially in my case (are there any senior economists that become a DS here to share their point of view?)? Should I start thinking about applying to any internship in data analysis to develop a good portfolio right now?&lt;/p&gt;\n\n&lt;p&gt;Anyway, I&amp;#39;m open to suggestions. Tyvm :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q6gp8", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic_Bite6696", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q6gp8/im_a_economics_student/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q6gp8/im_a_economics_student/", "subreddit_subscribers": 875216, "created_utc": 1681783878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I can\u2019t find any information online on the process/timeline for a data scientist role. Was hoping someone would share their experience?", "author_fullname": "t2_5akq1mi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone interviewed with P&amp;G for a data science role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q07sb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681771696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can\u2019t find any information online on the process/timeline for a data scientist role. Was hoping someone would share their experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q07sb", "is_robot_indexable": true, "report_reasons": null, "author": "Dapper-Economy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q07sb/has_anyone_interviewed_with_pg_for_a_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q07sb/has_anyone_interviewed_with_pg_for_a_data_science/", "subreddit_subscribers": 875216, "created_utc": 1681771696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, \nI want to create a ml model in order to predict anomaly of my material. \nThe issue is that i have more than one node on my dataset (almost 2500 nodes and 3 millions logs) and m having troubles finding the right model to forecast. (my data is timestamp) timestamp + the value of load cpu at each time. The models depend on the node. Same model can work on a node and not be good for others. And ofc i can't train 2500 models manually. \nPls can anyone help me out with this?\nM still a beginner in the field (intern).", "author_fullname": "t2_9fzprsh0s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AiOps issue machine learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pvt7z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681764728.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681763741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, \nI want to create a ml model in order to predict anomaly of my material. \nThe issue is that i have more than one node on my dataset (almost 2500 nodes and 3 millions logs) and m having troubles finding the right model to forecast. (my data is timestamp) timestamp + the value of load cpu at each time. The models depend on the node. Same model can work on a node and not be good for others. And ofc i can&amp;#39;t train 2500 models manually. \nPls can anyone help me out with this?\nM still a beginner in the field (intern).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pvt7z", "is_robot_indexable": true, "report_reasons": null, "author": "Bearsalim", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pvt7z/aiops_issue_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pvt7z/aiops_issue_machine_learning/", "subreddit_subscribers": 875216, "created_utc": 1681763741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easy to Use Text Annotation Tool | Upload documents, start annotating, and create advanced NLP model in a few hours.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_12ps49p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_q9v3kbiq", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Pzv8FB5ZBU2PuFtg7UErZJE_cmIcHWC1TWB3kje4rJI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "deeplearning", "selftext": "Check out this new article about how few-shot learning is automating document labeling! \ud83e\udd16\ud83d\udcdd \n\nManual document labeling can be time-consuming and prone to errors, but recent advancements in machine learning, specifically few-shot learning, are changing the game. \n\nFew-shot learning is a machine learning technique that allows models to learn a specific task with just a few labeled examples. By providing concatenated training examples of the task at hand and asking the model to predict the output of a target text, the model can be fine-tuned to perform the task accurately.\n\nDiscover how this technology is revolutionizing the data labeling space and making document processing more efficient \ud83d\udcbb\ud83d\udd0d read the full article here :  https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling", "author_fullname": "t2_q9v3kbiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easy to Use Text Annotation Tool | Upload documents, start annotating, and create advanced NLP model in a few hours.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/deeplearning", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_12ps3bv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1681756553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ubiai.tools", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Check out this new article about how few-shot learning is automating document labeling! \ud83e\udd16\ud83d\udcdd &lt;/p&gt;\n\n&lt;p&gt;Manual document labeling can be time-consuming and prone to errors, but recent advancements in machine learning, specifically few-shot learning, are changing the game. &lt;/p&gt;\n\n&lt;p&gt;Few-shot learning is a machine learning technique that allows models to learn a specific task with just a few labeled examples. By providing concatenated training examples of the task at hand and asking the model to predict the output of a target text, the model can be fine-tuned to perform the task accurately.&lt;/p&gt;\n\n&lt;p&gt;Discover how this technology is revolutionizing the data labeling space and making document processing more efficient \ud83d\udcbb\ud83d\udd0d read the full article here :  &lt;a href=\"https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling\"&gt;https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?auto=webp&amp;v=enabled&amp;s=8589973933b8a3d98f94770efc6b03fc0bf51d9d", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08f5bda42462327fe951a5c9830a966264d78738", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2deb84eb43c25f5feea0e7ddc596ae839f806c22", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d26bf86ae373d50e6c92bea40edbc5ef4f8fa2b2", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91e8fdb39b0ecc15eee3b51c79d6b072ed337b57", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d9bb0c74ca7b008ca2d474ed86f7dc180ed0a98", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=636277a8dfc8f20e73200643c91121e4f74c5f02", "width": 1080, "height": 564}], "variants": {}, "id": "fTeOd0VyYPSKz6U0rOsuA68u5NR6-meqB9jGZ-AMOzw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2t5eh", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ps3bv", "is_robot_indexable": true, "report_reasons": null, "author": "Harvy_thomson87", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/deeplearning/comments/12ps3bv/easy_to_use_text_annotation_tool_upload_documents/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling", "subreddit_subscribers": 93177, "created_utc": 1681756553.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1681756602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ubiai.tools", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?auto=webp&amp;v=enabled&amp;s=8589973933b8a3d98f94770efc6b03fc0bf51d9d", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08f5bda42462327fe951a5c9830a966264d78738", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2deb84eb43c25f5feea0e7ddc596ae839f806c22", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d26bf86ae373d50e6c92bea40edbc5ef4f8fa2b2", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91e8fdb39b0ecc15eee3b51c79d6b072ed337b57", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d9bb0c74ca7b008ca2d474ed86f7dc180ed0a98", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/niVLMBR-FFCwOoBrO1wRm_NhgNgqjggEw-_Hagphz0M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=636277a8dfc8f20e73200643c91121e4f74c5f02", "width": 1080, "height": 564}], "variants": {}, "id": "fTeOd0VyYPSKz6U0rOsuA68u5NR6-meqB9jGZ-AMOzw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ps49p", "is_robot_indexable": true, "report_reasons": null, "author": "Harvy_thomson87", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12ps3bv", "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ps49p/easy_to_use_text_annotation_tool_upload_documents/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ubiai.tools/blog/article/How-Few-Shot-Learning-is-Automating-Document-Labeling", "subreddit_subscribers": 875216, "created_utc": 1681756602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am building an NLP project from reddit data where age and gender are very helpful indicators of what I am trying to classify. Many submissions have this type sequence \"I (M35)\" and etc but not necessarily this. I've thought of searching for the M(age), F(age) pattern and in case there are multiple in a submission to get the one nearest. Do you think it will work? Is there something better I haven't thought of? Also the majority of the rows will be NaN? Is it worth it?", "author_fullname": "t2_jnkopc1j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would I extract op's gender and age?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pgfob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681738968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am building an NLP project from reddit data where age and gender are very helpful indicators of what I am trying to classify. Many submissions have this type sequence &amp;quot;I (M35)&amp;quot; and etc but not necessarily this. I&amp;#39;ve thought of searching for the M(age), F(age) pattern and in case there are multiple in a submission to get the one nearest. Do you think it will work? Is there something better I haven&amp;#39;t thought of? Also the majority of the rows will be NaN? Is it worth it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pgfob", "is_robot_indexable": true, "report_reasons": null, "author": "Brilliant_Intern1588", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pgfob/how_would_i_extract_ops_gender_and_age/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pgfob/how_would_i_extract_ops_gender_and_age/", "subreddit_subscribers": 875216, "created_utc": 1681738968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How does the random forest model perform when it is built without any feature engineering using the following hyperparameters:\n\n&amp;#x200B;\n\nbootstrap=True\n\ncriterion='gini'\n\nmax\\_depth=3\n\nn\\_estimators=10\n\noob\\_score=True\n\nrandom\\_state=42\n\n \n\n&amp;#x200B;\n\nUse accuracy as the performance metric.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n1.The model has an accuracy greater than the accuracy of the dummy classifier (which predicts the most frequent class) on both the training and test sets. \n\n&amp;#x200B;\n\n2.The model has an accuracy smaller than the accuracy of the dummy classifier (which predicts the most frequent class) on both the training and test sets. \n\n&amp;#x200B;\n\n&amp;#x200B;\n\n3.The model performs well on the training set but poorly 3.on the test set.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n4.The model performs well on the test set but poorly on the training set\n\n&amp;#x200B;\n\nChoose from 1,2,3,4", "author_fullname": "t2_jwh9htoc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Random Forest", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12q6uid", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681784648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How does the random forest model perform when it is built without any feature engineering using the following hyperparameters:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;bootstrap=True&lt;/p&gt;\n\n&lt;p&gt;criterion=&amp;#39;gini&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;max_depth=3&lt;/p&gt;\n\n&lt;p&gt;n_estimators=10&lt;/p&gt;\n\n&lt;p&gt;oob_score=True&lt;/p&gt;\n\n&lt;p&gt;random_state=42&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Use accuracy as the performance metric.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;1.The model has an accuracy greater than the accuracy of the dummy classifier (which predicts the most frequent class) on both the training and test sets. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;2.The model has an accuracy smaller than the accuracy of the dummy classifier (which predicts the most frequent class) on both the training and test sets. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;3.The model performs well on the training set but poorly 3.on the test set.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;4.The model performs well on the test set but poorly on the training set&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Choose from 1,2,3,4&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q6uid", "is_robot_indexable": true, "report_reasons": null, "author": "Budding_Data_Scien", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q6uid/random_forest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q6uid/random_forest/", "subreddit_subscribers": 875216, "created_utc": 1681784648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all,\n\nI am interviewing at a job as Data Literacy Consultant at a branch of a major Non-profit. Role would be for 20 hours per week. I have no experience in data and this would be my first consultancy job. Based in the Netherlands.\n\nI have no idea of hourly rates for consultancy and would appreciate some guidance on this. Bearing in mind also that it is my first gig, I have no data experience and I woukd be working for a non-profit. What should I ask for per hour?", "author_fullname": "t2_9q4mq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommended hourly rates for a 1st time Data Literacy Consultant?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pbqtq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681729466.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681729114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I am interviewing at a job as Data Literacy Consultant at a branch of a major Non-profit. Role would be for 20 hours per week. I have no experience in data and this would be my first consultancy job. Based in the Netherlands.&lt;/p&gt;\n\n&lt;p&gt;I have no idea of hourly rates for consultancy and would appreciate some guidance on this. Bearing in mind also that it is my first gig, I have no data experience and I woukd be working for a non-profit. What should I ask for per hour?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pbqtq", "is_robot_indexable": true, "report_reasons": null, "author": "Commodore-Metal", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pbqtq/recommended_hourly_rates_for_a_1st_time_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pbqtq/recommended_hourly_rates_for_a_1st_time_data/", "subreddit_subscribers": 875216, "created_utc": 1681729114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently studying data science at a university and was wondering what criteria to look for in a company to apply for an intership", "author_fullname": "t2_29ek7oq0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tips for finding a great company for an internship during pursuing a bachelors degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ptxvh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681760148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently studying data science at a university and was wondering what criteria to look for in a company to apply for an intership&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ptxvh", "is_robot_indexable": true, "report_reasons": null, "author": "zyanaera", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ptxvh/any_tips_for_finding_a_great_company_for_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ptxvh/any_tips_for_finding_a_great_company_for_an/", "subreddit_subscribers": 875216, "created_utc": 1681760148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, \n\nI am looking for data concerning car crash tests for a machine learning project. It should contain physical 3d information about the crash tests and scores or sensory measurements of the crash result. Ideally, all crashes are indentical with only the car being changed. (Or at least distinct labels for crash test type)\n\nThanks a lot!", "author_fullname": "t2_nh5hq8wn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crash Test Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pzfuy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681770256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;I am looking for data concerning car crash tests for a machine learning project. It should contain physical 3d information about the crash tests and scores or sensory measurements of the crash result. Ideally, all crashes are indentical with only the car being changed. (Or at least distinct labels for crash test type)&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pzfuy", "is_robot_indexable": true, "report_reasons": null, "author": "just_another_ai_guy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pzfuy/crash_test_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pzfuy/crash_test_data/", "subreddit_subscribers": 875216, "created_utc": 1681770256.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}