{"kind": "Listing", "data": {"after": "t3_12pzy96", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My new org is entirely MS/Azure based, and I am pretty much a data team of one. They have no real data warehouse to speak of, just a few MS applications in the cloud and PowerBI. \n\nData volume is quite small (we have around 10k orders per year) and unlikely to grow significantly for at least a couple of years. Beyond Dynamics we have the normal suspects, socials, Google analytics and third party APIs.\n\nAny suggestions for a good solution for a DWH? Budget is tight so I would like to use meltano to dump raw data into the DWH and DBT core to build some gold level tables to serve into PowerBI.\n\nWould a simple MSSQL database do it? Or would a entry tier Synapse instance be a better place to start? Or perhaps even Snowflake?\n\nAny experiences very welcome.\n\nEDIT: amazed by the quality responses here, thanks so much folks.", "author_fullname": "t2_clh5r1ln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for a small DWH on Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pwc42", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681806417.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681764699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My new org is entirely MS/Azure based, and I am pretty much a data team of one. They have no real data warehouse to speak of, just a few MS applications in the cloud and PowerBI. &lt;/p&gt;\n\n&lt;p&gt;Data volume is quite small (we have around 10k orders per year) and unlikely to grow significantly for at least a couple of years. Beyond Dynamics we have the normal suspects, socials, Google analytics and third party APIs.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for a good solution for a DWH? Budget is tight so I would like to use meltano to dump raw data into the DWH and DBT core to build some gold level tables to serve into PowerBI.&lt;/p&gt;\n\n&lt;p&gt;Would a simple MSSQL database do it? Or would a entry tier Synapse instance be a better place to start? Or perhaps even Snowflake?&lt;/p&gt;\n\n&lt;p&gt;Any experiences very welcome.&lt;/p&gt;\n\n&lt;p&gt;EDIT: amazed by the quality responses here, thanks so much folks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12pwc42", "is_robot_indexable": true, "report_reasons": null, "author": "Far-Restaurant-9691", "discussion_type": null, "num_comments": 61, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pwc42/recommendations_for_a_small_dwh_on_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pwc42/recommendations_for_a_small_dwh_on_azure/", "subreddit_subscribers": 100225, "created_utc": 1681764699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve used PySpark for years. I\u2019m just getting into Scala and I already understand functional programming. What are good resources for going deep into Scala and extending my Spark capabilities via Scala?", "author_fullname": "t2_v98q7m1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From PySpark to Scala", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q5bi3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681781549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve used PySpark for years. I\u2019m just getting into Scala and I already understand functional programming. What are good resources for going deep into Scala and extending my Spark capabilities via Scala?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12q5bi3", "is_robot_indexable": true, "report_reasons": null, "author": "bryangoodrich", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12q5bi3/from_pyspark_to_scala/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12q5bi3/from_pyspark_to_scala/", "subreddit_subscribers": 100225, "created_utc": 1681781549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hot Takes on the Modern Data Stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_12qi81h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zZ-7CbC36WBUJqr3_HKyJNv3nkcWm-2lBw9OZsBeOQc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681812434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mattpalmer.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://mattpalmer.io/posts/hot-takes/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qSFsxKq_BlFRgIjKDPWSACdVRac4Sw9FpPgru3bFijQ.jpg?auto=webp&amp;v=enabled&amp;s=3b7b32b87771d38919e831492129a5a56d632014", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/qSFsxKq_BlFRgIjKDPWSACdVRac4Sw9FpPgru3bFijQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a07fd1ba6c6c77efc849d049c68146606eed77e5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/qSFsxKq_BlFRgIjKDPWSACdVRac4Sw9FpPgru3bFijQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d29efe0934ceec736da4e103b08796f8a4d58cfd", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/qSFsxKq_BlFRgIjKDPWSACdVRac4Sw9FpPgru3bFijQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1d6fdea8d58567bedb3e4876156f9598d74ef52b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/qSFsxKq_BlFRgIjKDPWSACdVRac4Sw9FpPgru3bFijQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0846248532357b4b940eb1f7b45654015796268", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/qSFsxKq_BlFRgIjKDPWSACdVRac4Sw9FpPgru3bFijQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31876b0f3c007e46a2f696e6288d6859f1f509be", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/qSFsxKq_BlFRgIjKDPWSACdVRac4Sw9FpPgru3bFijQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b264ce591b3e7e0aa032b439ec549196a9499aa", "width": 1080, "height": 567}], "variants": {}, "id": "A1mOJ6oZeDUrTFa7TvwsIw_R8wZDDIod3BQIdmWhuGw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12qi81h", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12qi81h/hot_takes_on_the_modern_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://mattpalmer.io/posts/hot-takes/", "subreddit_subscribers": 100225, "created_utc": 1681812434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHey /r/dataengineering!\n\nRecently retired as a data scientist/engineer.  I figured i ought to at least try to give back to the opensource community.  I've created a Docker app to help data scientists build data projects with pipelines in mind \\*from the start\\*, rather than as Jupyter notebook afterthoughts:\n\n[**https://github.com/jason-brian-anderson/pipeline\\_gen**](https://github.com/jason-brian-anderson/pipeline_gen)\n\nI suspect I wasn't the only one with no clue about good pipeline design principles.  I customized the base Airflow docker-compose to run data pipelines and on a dedicated GPU pytorch container. The repo is a git template, and was hoping ot might be useful to others beyond just my personal projects.\n\nI'd love to hear your thoughts. is it a good thing to encourage the data  science community to develop from the start with pipelines in mind?", "author_fullname": "t2_9g8u21p9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pipeline_gen: a project for simplified data pipeline design targeted at promoting good pipeline design principles among data scientists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q1ph9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681774539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/dataengineering\"&gt;/r/dataengineering&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;Recently retired as a data scientist/engineer.  I figured i ought to at least try to give back to the opensource community.  I&amp;#39;ve created a Docker app to help data scientists build data projects with pipelines in mind *from the start*, rather than as Jupyter notebook afterthoughts:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/jason-brian-anderson/pipeline_gen\"&gt;&lt;strong&gt;https://github.com/jason-brian-anderson/pipeline_gen&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I suspect I wasn&amp;#39;t the only one with no clue about good pipeline design principles.  I customized the base Airflow docker-compose to run data pipelines and on a dedicated GPU pytorch container. The repo is a git template, and was hoping ot might be useful to others beyond just my personal projects.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear your thoughts. is it a good thing to encourage the data  science community to develop from the start with pipelines in mind?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?auto=webp&amp;v=enabled&amp;s=c1c932cebe7ad6b7da6c3a8ac758b4c015430ecf", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c2796740d1577705d18ae732340ace1a8c9df09", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8958047e87ccd35586585709ff12371974101434", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80c63f6455dc4248592a3c23198d64640ea66dc4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53a58b1646243881e0d699983def42c4fa03a4f8", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c3b8887f6642e7774c502dbcb2e23d19f6fa96e", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5047f210faead4fc8e96855a837e4d910a6cd89e", "width": 1080, "height": 540}], "variants": {}, "id": "i_Png3iGB-feerTRQyTJZMNWOeqXHZunl3kMQORqODs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "12q1ph9", "is_robot_indexable": true, "report_reasons": null, "author": "airflowy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12q1ph9/pipeline_gen_a_project_for_simplified_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12q1ph9/pipeline_gen_a_project_for_simplified_data/", "subreddit_subscribers": 100225, "created_utc": 1681774539.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_owff7qyq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I got annoyed by writing and maintaining custom web scrapers, so I built an LLM-powered tool that can generate scrapers for any website.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": false, "name": "t3_12qldwc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/94zl2t59zmua1/DASH_720.mp4?source=fallback", "height": 720, "width": 1280, "scrubber_media_url": "https://v.redd.it/94zl2t59zmua1/DASH_96.mp4", "dash_url": "https://v.redd.it/94zl2t59zmua1/DASHPlaylist.mpd?a=1684424318%2CYzhmZWQ5MmUzYzU1YTU1MmYwOGI2ZWMwYjVhMmMxZGY2MTY2NTk5NTVhZDIzMGEwNDE1YWFiMGYyNTI2N2UxZA%3D%3D&amp;v=1&amp;f=sd", "duration": 52, "hls_url": "https://v.redd.it/94zl2t59zmua1/HLSPlaylist.m3u8?a=1684424318%2CY2IxYTA1NWFhZWM2ZjI1NzhkMDljZGU5YWE0YjY2NDU4Y2E0ZDg0NzgyMjAzMzZkZDFjZjk0MzMwMjlmMGFlZQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/wwRas42IcfRA9NPdQBWrlbeayvBkYy54ho1y_uAYDw8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681820832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/94zl2t59zmua1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/z47AabJKGbSgauCrhZo1bIj4oJvUZl82grNzJ47O1z4.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=76bd20fe45301d3339030bf8fd3c2609a3f41151", "width": 1280, "height": 769}, "resolutions": [{"url": "https://external-preview.redd.it/z47AabJKGbSgauCrhZo1bIj4oJvUZl82grNzJ47O1z4.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=ab647f47cb9fb4f890b4cc7bb1beb6201325ab06", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/z47AabJKGbSgauCrhZo1bIj4oJvUZl82grNzJ47O1z4.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5e571391b686b6c7b6807f2b7ba1c560f4ccd54f", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/z47AabJKGbSgauCrhZo1bIj4oJvUZl82grNzJ47O1z4.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=72dfcda6a2645cc7f45a7cc65ec07b43bc24b6e7", "width": 320, "height": 192}, {"url": "https://external-preview.redd.it/z47AabJKGbSgauCrhZo1bIj4oJvUZl82grNzJ47O1z4.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3d96700093eeba3fae717d409789aa2b5cc707c0", "width": 640, "height": 384}, {"url": "https://external-preview.redd.it/z47AabJKGbSgauCrhZo1bIj4oJvUZl82grNzJ47O1z4.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c976f7e6433242a0ccc7e64b12aa718440a5e45c", "width": 960, "height": 576}, {"url": "https://external-preview.redd.it/z47AabJKGbSgauCrhZo1bIj4oJvUZl82grNzJ47O1z4.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=4a65768c35c4ff3333c2e8e3685d0a4f54ee6d40", "width": 1080, "height": 648}], "variants": {}, "id": "5p_SP1eQrR4RSz0noxqkmVRezizkzGKFhjddpAwWt9k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12qldwc", "is_robot_indexable": true, "report_reasons": null, "author": "madredditscientist", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12qldwc/i_got_annoyed_by_writing_and_maintaining_custom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/94zl2t59zmua1", "subreddit_subscribers": 100225, "created_utc": 1681820832.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 2400, "fallback_url": "https://v.redd.it/94zl2t59zmua1/DASH_720.mp4?source=fallback", "height": 720, "width": 1280, "scrubber_media_url": "https://v.redd.it/94zl2t59zmua1/DASH_96.mp4", "dash_url": "https://v.redd.it/94zl2t59zmua1/DASHPlaylist.mpd?a=1684424318%2CYzhmZWQ5MmUzYzU1YTU1MmYwOGI2ZWMwYjVhMmMxZGY2MTY2NTk5NTVhZDIzMGEwNDE1YWFiMGYyNTI2N2UxZA%3D%3D&amp;v=1&amp;f=sd", "duration": 52, "hls_url": "https://v.redd.it/94zl2t59zmua1/HLSPlaylist.m3u8?a=1684424318%2CY2IxYTA1NWFhZWM2ZjI1NzhkMDljZGU5YWE0YjY2NDU4Y2E0ZDg0NzgyMjAzMzZkZDFjZjk0MzMwMjlmMGFlZQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, I\u00b4m currently interested in pursuing a master's degree around related to data engineering and analytics. I'd prefer an online program since I'd rather not wreck my bank account and destabilize my family life at the moment. Do you have any experience, recommendations or warnings towards any specific programs? I'm a Latin-American and know there are certain institutions that provide some sort of support, scholarships and/or related programs to fulfil a certain quota and, well, I wouldn't like to waste any opportunity at reach.\n\nThank you!", "author_fullname": "t2_wah5l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering and analytics Masters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12plhfd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681745436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I\u00b4m currently interested in pursuing a master&amp;#39;s degree around related to data engineering and analytics. I&amp;#39;d prefer an online program since I&amp;#39;d rather not wreck my bank account and destabilize my family life at the moment. Do you have any experience, recommendations or warnings towards any specific programs? I&amp;#39;m a Latin-American and know there are certain institutions that provide some sort of support, scholarships and/or related programs to fulfil a certain quota and, well, I wouldn&amp;#39;t like to waste any opportunity at reach.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12plhfd", "is_robot_indexable": true, "report_reasons": null, "author": "reborndu", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12plhfd/data_engineering_and_analytics_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12plhfd/data_engineering_and_analytics_masters/", "subreddit_subscribers": 100225, "created_utc": 1681745436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What do you think are some of the problems that the current Modern Data Stack (ETL + Analytics) tools are not able to solve?\n\nIs there a need for industry specific ETL tools so that they have a great deal of depth with data extraction tools specific to that industry? Example: Stitch solving for the fintech industry.", "author_fullname": "t2_a4d2j3fh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Data Stack tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q9am5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681789753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you think are some of the problems that the current Modern Data Stack (ETL + Analytics) tools are not able to solve?&lt;/p&gt;\n\n&lt;p&gt;Is there a need for industry specific ETL tools so that they have a great deal of depth with data extraction tools specific to that industry? Example: Stitch solving for the fintech industry.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12q9am5", "is_robot_indexable": true, "report_reasons": null, "author": "Living-Nobody-2727", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12q9am5/modern_data_stack_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12q9am5/modern_data_stack_tools/", "subreddit_subscribers": 100225, "created_utc": 1681789753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks!\n\nI started a newsletter called Simetrique about Data Engineering and Analytics Engineering. I am trying to make it not about latest news and trends (however it's impossible to avoid), but rather to write about topics that are interesting to myself. For example, interesting tools, approaches or articles. Also, sometimes I'm going to write about my personal experience with data and analytics.\n\nI'm currently an Analytics Engineer, and held a lot of analytical titles (such as data analyst, BI engineer and even a head of BI) for the past 10 year. So the data is my passion, especially its engineering part.\n\nFirst 4 issues are already published so you can go and check the type of content I'm going to post. Planning to make about 1 newsletter a week, so not going to spam you.\n\n[https://simetrique.substack.com/](https://simetrique.substack.com/)", "author_fullname": "t2_4679pe1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I started a newsletter about DE and AE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pyojl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681768904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks!&lt;/p&gt;\n\n&lt;p&gt;I started a newsletter called Simetrique about Data Engineering and Analytics Engineering. I am trying to make it not about latest news and trends (however it&amp;#39;s impossible to avoid), but rather to write about topics that are interesting to myself. For example, interesting tools, approaches or articles. Also, sometimes I&amp;#39;m going to write about my personal experience with data and analytics.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently an Analytics Engineer, and held a lot of analytical titles (such as data analyst, BI engineer and even a head of BI) for the past 10 year. So the data is my passion, especially its engineering part.&lt;/p&gt;\n\n&lt;p&gt;First 4 issues are already published so you can go and check the type of content I&amp;#39;m going to post. Planning to make about 1 newsletter a week, so not going to spam you.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://simetrique.substack.com/\"&gt;https://simetrique.substack.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AC0LWTaobZ0ozdKWOeI1XsHzyDYe9xbHmEp5oF2YNEU.jpg?auto=webp&amp;v=enabled&amp;s=eb7bdadcab12495fa1b1d88da290fa1a6840f15c", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/AC0LWTaobZ0ozdKWOeI1XsHzyDYe9xbHmEp5oF2YNEU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc3907b05bab8847a3f7f3c88ba9b13bcad063d5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/AC0LWTaobZ0ozdKWOeI1XsHzyDYe9xbHmEp5oF2YNEU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=239d599db4fd3341980de2498027e7f38769095f", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/AC0LWTaobZ0ozdKWOeI1XsHzyDYe9xbHmEp5oF2YNEU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e76eb1c53656e1b9161d28d095c21cbb2f89012", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/AC0LWTaobZ0ozdKWOeI1XsHzyDYe9xbHmEp5oF2YNEU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6edc9bfaa20abf1d71ef7ddf516df53075da38a8", "width": 640, "height": 333}], "variants": {}, "id": "h-2msyp46eyAeZx54uovglwbzRki6DsxoUVoQUBZbGk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12pyojl", "is_robot_indexable": true, "report_reasons": null, "author": "oleg_agapov", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pyojl/i_started_a_newsletter_about_de_and_ae/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pyojl/i_started_a_newsletter_about_de_and_ae/", "subreddit_subscribers": 100225, "created_utc": 1681768904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! I work on a very small Data team and have spent the last few months setting up a warehouse environment using Fivetran, dbt, and Snowflake. I'm very happy with these tools, and we're already seeing returns on them. Currently I just have a free account on dbt Cloud that is just running 'dbt run all' every night. I'm looking at setting up Dagster or something similar to handle the orchestration. On paper, it seems like it would integrate with everything and give me one place to handle all of these tools and catch errors, but I'm worried that it's unnecessary complexity at this point. We're not running ML models or anything like that at this point, just building data sources that feed BI tools. I am also looking for a way to generate dbt docs that our team can easily view and I think an orchestrator would help with that although we'd have to host them somewhere.\n\nI would appreciate anyone's thoughts on this if anyone has been in a similar situation. Thanks!", "author_fullname": "t2_7ljys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is an orchestrator like Dagster overkill?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pm6g0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681746347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I work on a very small Data team and have spent the last few months setting up a warehouse environment using Fivetran, dbt, and Snowflake. I&amp;#39;m very happy with these tools, and we&amp;#39;re already seeing returns on them. Currently I just have a free account on dbt Cloud that is just running &amp;#39;dbt run all&amp;#39; every night. I&amp;#39;m looking at setting up Dagster or something similar to handle the orchestration. On paper, it seems like it would integrate with everything and give me one place to handle all of these tools and catch errors, but I&amp;#39;m worried that it&amp;#39;s unnecessary complexity at this point. We&amp;#39;re not running ML models or anything like that at this point, just building data sources that feed BI tools. I am also looking for a way to generate dbt docs that our team can easily view and I think an orchestrator would help with that although we&amp;#39;d have to host them somewhere.&lt;/p&gt;\n\n&lt;p&gt;I would appreciate anyone&amp;#39;s thoughts on this if anyone has been in a similar situation. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12pm6g0", "is_robot_indexable": true, "report_reasons": null, "author": "tydor73", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pm6g0/is_an_orchestrator_like_dagster_overkill/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pm6g0/is_an_orchestrator_like_dagster_overkill/", "subreddit_subscribers": 100225, "created_utc": 1681746347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been a data engineer for almost 5 years, and I noticed that of the many data engineers I have worked with, almost all of them have stayed in data engineering.  They have either moved into more senior data engineering positions or became data engineering managers.\n\n\n\n\nMy friends who are software engineers have had more interesting career progressions.  For example, one engineer started out as a backend developer, moved into full stack development to pick up frontend skills, and is currently in devops.  I'm surprised my data engineering colleagues have not seen similar career progression since a lot of companies see us as specialized backend engineers, but for data.\n\n\n\n\nI enjoy data engineering, but I don't see myself doing this my whole career.  I would eventually enjoy going into devops or becoming a software reliability engineer.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does data engineering not have as much interesting career progression as other areas of engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qldg7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681820802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a data engineer for almost 5 years, and I noticed that of the many data engineers I have worked with, almost all of them have stayed in data engineering.  They have either moved into more senior data engineering positions or became data engineering managers.&lt;/p&gt;\n\n&lt;p&gt;My friends who are software engineers have had more interesting career progressions.  For example, one engineer started out as a backend developer, moved into full stack development to pick up frontend skills, and is currently in devops.  I&amp;#39;m surprised my data engineering colleagues have not seen similar career progression since a lot of companies see us as specialized backend engineers, but for data.&lt;/p&gt;\n\n&lt;p&gt;I enjoy data engineering, but I don&amp;#39;t see myself doing this my whole career.  I would eventually enjoy going into devops or becoming a software reliability engineer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12qldg7", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12qldg7/does_data_engineering_not_have_as_much/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12qldg7/does_data_engineering_not_have_as_much/", "subreddit_subscribers": 100225, "created_utc": 1681820802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Guys i was recently offered a azure data engineer role at a large company which I accepted (with 100% raise), and resigned at my current company where I work as a data engineer. Its been 2 weeks since I accepted the offer. \nThe guy from HR called in today and asked if I would be comfortable in changing my job title and entire jd to BI Developer (PowerBI) since they also find me suitable for that role. \n\nI showed concern and didn\u2019t agree so a Senior from BI team reached out and tried to convince me that there is a greater need in that domain and it is a better opportunity than this. I agreed to fulfill the business needs if necessary but asked to keep the same title and role.\n\nNote:\nI only accepted the offer because I was currently working in On-Prem servers and I wanted to shift to the cloud.\n\nPlease help me suggest what should I do", "author_fullname": "t2_t6pucw09", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice Needed!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qk7yh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681817768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Guys i was recently offered a azure data engineer role at a large company which I accepted (with 100% raise), and resigned at my current company where I work as a data engineer. Its been 2 weeks since I accepted the offer. \nThe guy from HR called in today and asked if I would be comfortable in changing my job title and entire jd to BI Developer (PowerBI) since they also find me suitable for that role. &lt;/p&gt;\n\n&lt;p&gt;I showed concern and didn\u2019t agree so a Senior from BI team reached out and tried to convince me that there is a greater need in that domain and it is a better opportunity than this. I agreed to fulfill the business needs if necessary but asked to keep the same title and role.&lt;/p&gt;\n\n&lt;p&gt;Note:\nI only accepted the offer because I was currently working in On-Prem servers and I wanted to shift to the cloud.&lt;/p&gt;\n\n&lt;p&gt;Please help me suggest what should I do&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12qk7yh", "is_robot_indexable": true, "report_reasons": null, "author": "Curious_Ad_7220", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12qk7yh/advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12qk7yh/advice_needed/", "subreddit_subscribers": 100225, "created_utc": 1681817768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am developing an app that will store that json that represents the state of an object, it will also record modifications made to that object -- think of it as an accounting ledger. It will be write heavy, but I would like to be able to read from it in a reasonable time. I think queries will use two - three columns for filtering\n\nThinking in terms of db columns, id need:\n\n    id &lt;uuid&gt;\n    type &lt;string&gt; -- the thing that was modified. user, location, noun, etc. I will need to be able to filter on this\n    type_id &lt;uuid&gt; -- luckily we use uuid everywhere. I will need to be able to filter on this\n    change &lt;string&gt; -- formatted json representing the modifications. I will not need to search in this (would be nice to in the future maybe)\n    timestamp &lt;time&gt; -- time that the modification happened. I will need to do some bounding based on this.\n\nI figured this would be simple as a single table that supported multiple types. \n\nMy original plan was a Postgres db, tune it as necessary and worry about it when I need to worry about it. Now im wondering if there are better solutions for what I want to do \n\nThanks", "author_fullname": "t2_c2o44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendation on potential storage for a changeling-type app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ppqcy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681752179.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am developing an app that will store that json that represents the state of an object, it will also record modifications made to that object -- think of it as an accounting ledger. It will be write heavy, but I would like to be able to read from it in a reasonable time. I think queries will use two - three columns for filtering&lt;/p&gt;\n\n&lt;p&gt;Thinking in terms of db columns, id need:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;id &amp;lt;uuid&amp;gt;\ntype &amp;lt;string&amp;gt; -- the thing that was modified. user, location, noun, etc. I will need to be able to filter on this\ntype_id &amp;lt;uuid&amp;gt; -- luckily we use uuid everywhere. I will need to be able to filter on this\nchange &amp;lt;string&amp;gt; -- formatted json representing the modifications. I will not need to search in this (would be nice to in the future maybe)\ntimestamp &amp;lt;time&amp;gt; -- time that the modification happened. I will need to do some bounding based on this.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I figured this would be simple as a single table that supported multiple types. &lt;/p&gt;\n\n&lt;p&gt;My original plan was a Postgres db, tune it as necessary and worry about it when I need to worry about it. Now im wondering if there are better solutions for what I want to do &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ppqcy", "is_robot_indexable": true, "report_reasons": null, "author": "needed_an_account", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ppqcy/recommendation_on_potential_storage_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ppqcy/recommendation_on_potential_storage_for_a/", "subreddit_subscribers": 100225, "created_utc": 1681752179.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow redditors. I am currently working on a project wihere i have to create a data quality framework. I am at the point where i have to implement a bunch of data quality checks/rules, be they simple rules such as checking nullity, uniqueness, or more complexe involving accuracy, consistency and validation (Rules checking if value X is present then Y must be present and have specific value + some coherence with dates). The metrics mentioned previously are 5 metrics of data quality in general (i know there are more but i am restrained  to those.\n\n  \nThe data quality is performed on raw data present in an oracle database and my technical constraints are as follow :\n\n1. No Proprietary solutions\n2. No Cloud (means no spark and no deequ)\n\nThe data range from 10 to 100 GB per table, and for the current table i am working on i have at least a 100 rules to implements (more to come). I made ***POC*** using python, implementing just a few rules which resulted in the following conclusions for each metric  (made an individual function for each metrics) :\n\n1. Completeness:  Getting the nulls for each columns, was easy to implement using pure sql.\n2. Uniqueness : Checking uniqueness for multiple columns, not hard to implement but needs optimization.\n3. Accuracy, Consistency, Validation : Necessity of manual if else like implementation, which would results in spaghetti code if more rules were added.\n4. Overall : Performance was ignored when implementing, but it became clear that more rules will lead to additionnal problems be it in performance or maintanability.\n\nThis lead me to search for an alternative solutions and a BRE seemed like one but there doesn't seem to be a standard of which tool to use in terms of data quality, and while i am not afraid of learning a new language like CLIPS (PYCLIPS), or Java (DROOLS) (already have some \"basics\" since i had some course in java for the sake of the OOP paradigms). I am lost as to what to tool to consider and invest my time in it, it would be quite painful to spend a few months in a language/framework, to finally notice it was a bad choice and non-standard.\n\n(I checked out Soda-core SodaCL but i lack the experience to tell if it is a good solution especially since it's recent and doesn't fully support my oracle database version)  \n\n\nCan anyone please orient me towards a language or set of tools that would allow me to achieve the desired results ? The current favorite is CLIPS as it would allow me full control on the engine but i am not sure if it is worth it. Also as it seems that all  the answers i could find were  either outdated or were outside any data quality topic, i will try to edit this post accordingly.  \nThis project is done during my data science internship.  \n\n\nThank you for your time.", "author_fullname": "t2_fcv4rhtp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Quality Checks, lack of a standard, complexity of BRMS.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qmg64", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681823112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow redditors. I am currently working on a project wihere i have to create a data quality framework. I am at the point where i have to implement a bunch of data quality checks/rules, be they simple rules such as checking nullity, uniqueness, or more complexe involving accuracy, consistency and validation (Rules checking if value X is present then Y must be present and have specific value + some coherence with dates). The metrics mentioned previously are 5 metrics of data quality in general (i know there are more but i am restrained  to those.&lt;/p&gt;\n\n&lt;p&gt;The data quality is performed on raw data present in an oracle database and my technical constraints are as follow :&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;No Proprietary solutions&lt;/li&gt;\n&lt;li&gt;No Cloud (means no spark and no deequ)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The data range from 10 to 100 GB per table, and for the current table i am working on i have at least a 100 rules to implements (more to come). I made &lt;strong&gt;&lt;em&gt;POC&lt;/em&gt;&lt;/strong&gt; using python, implementing just a few rules which resulted in the following conclusions for each metric  (made an individual function for each metrics) :&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Completeness:  Getting the nulls for each columns, was easy to implement using pure sql.&lt;/li&gt;\n&lt;li&gt;Uniqueness : Checking uniqueness for multiple columns, not hard to implement but needs optimization.&lt;/li&gt;\n&lt;li&gt;Accuracy, Consistency, Validation : Necessity of manual if else like implementation, which would results in spaghetti code if more rules were added.&lt;/li&gt;\n&lt;li&gt;Overall : Performance was ignored when implementing, but it became clear that more rules will lead to additionnal problems be it in performance or maintanability.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This lead me to search for an alternative solutions and a BRE seemed like one but there doesn&amp;#39;t seem to be a standard of which tool to use in terms of data quality, and while i am not afraid of learning a new language like CLIPS (PYCLIPS), or Java (DROOLS) (already have some &amp;quot;basics&amp;quot; since i had some course in java for the sake of the OOP paradigms). I am lost as to what to tool to consider and invest my time in it, it would be quite painful to spend a few months in a language/framework, to finally notice it was a bad choice and non-standard.&lt;/p&gt;\n\n&lt;p&gt;(I checked out Soda-core SodaCL but i lack the experience to tell if it is a good solution especially since it&amp;#39;s recent and doesn&amp;#39;t fully support my oracle database version)  &lt;/p&gt;\n\n&lt;p&gt;Can anyone please orient me towards a language or set of tools that would allow me to achieve the desired results ? The current favorite is CLIPS as it would allow me full control on the engine but i am not sure if it is worth it. Also as it seems that all  the answers i could find were  either outdated or were outside any data quality topic, i will try to edit this post accordingly.&lt;br/&gt;\nThis project is done during my data science internship.  &lt;/p&gt;\n\n&lt;p&gt;Thank you for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12qmg64", "is_robot_indexable": true, "report_reasons": null, "author": "Still-W1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12qmg64/data_quality_checks_lack_of_a_standard_complexity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12qmg64/data_quality_checks_lack_of_a_standard_complexity/", "subreddit_subscribers": 100225, "created_utc": 1681823112.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Last month, dbt somewhat quietly released a pretty important feature for dbt Cloud: Webhooks. Although seemingly small, this is a big deal for data teams for simplifying their stack. The number of tools you need to maintain is dropping slowly and things are consolidating under dbt Cloud.  \n\n\nhere is an introduction how to make use of webhooks using fal-serverless - [https://blog.fal.ai/dbt-cloud-webhooks/](https://blog.fal.ai/dbt-cloud-webhooks/)", "author_fullname": "t2_y15lw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One step closer to the orchestrator-less data stack - dbt cloud webhooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q9zaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.46, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681791258.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last month, dbt somewhat quietly released a pretty important feature for dbt Cloud: Webhooks. Although seemingly small, this is a big deal for data teams for simplifying their stack. The number of tools you need to maintain is dropping slowly and things are consolidating under dbt Cloud.  &lt;/p&gt;\n\n&lt;p&gt;here is an introduction how to make use of webhooks using fal-serverless - &lt;a href=\"https://blog.fal.ai/dbt-cloud-webhooks/\"&gt;https://blog.fal.ai/dbt-cloud-webhooks/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/y0j21BcBcPDByOOViYEnHviW3D7LsCFoljvx9QuNvAQ.jpg?auto=webp&amp;v=enabled&amp;s=1c4feafb757f2cb9e8d3a4cb3c030c124cb6d0bd", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/y0j21BcBcPDByOOViYEnHviW3D7LsCFoljvx9QuNvAQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ba966ec42959de788a534643fc24345151e6205", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/y0j21BcBcPDByOOViYEnHviW3D7LsCFoljvx9QuNvAQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0ff8a1211f60937c5915adedd301a82c6dfeb71", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/y0j21BcBcPDByOOViYEnHviW3D7LsCFoljvx9QuNvAQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75af832ff586da1d9d45fa5f996662522ad40ba3", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/y0j21BcBcPDByOOViYEnHviW3D7LsCFoljvx9QuNvAQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf08962ac3886060a9da97a43f3dd0f78d9f56ef", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/y0j21BcBcPDByOOViYEnHviW3D7LsCFoljvx9QuNvAQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e77b96d945ea259661a3f6a2cd0e33a4494ff5bf", "width": 960, "height": 960}], "variants": {}, "id": "_l4XhOa77zXw6MNF803areU5rwgdSbLMetldn_jVdb8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12q9zaj", "is_robot_indexable": true, "report_reasons": null, "author": "gorkemyurt", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12q9zaj/one_step_closer_to_the_orchestratorless_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12q9zaj/one_step_closer_to_the_orchestratorless_data/", "subreddit_subscribers": 100225, "created_utc": 1681791258.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Newbie here and apologize if this question has already been answered, but I\u2019m in a new role where Databricks autoloader is used for all data ingestion tasks\u2014whether the data is batch or streaming. We use the medallion architecture to load files from azure blob  to bronze, silver, and gold tables. I\u2019ve found that autoloader works great for appending data to bronze tables and works fine when simple merge operations are done from bronze to silver. But when we start to have edge cases, such as restated data, that requires a selective delete and append, we run into problems. Additionally, when trying to use autoloader to write business logic (aggregations, joins, filters, etc.) it quickly becomes a nightmare. \n\nCurious if anyone else has run into similar problems, and if so, what did you do to solve it? Does it even make sense to use autoloader for batch data processing?", "author_fullname": "t2_883tcd85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Autoloader for batch processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q8wp3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681788892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Newbie here and apologize if this question has already been answered, but I\u2019m in a new role where Databricks autoloader is used for all data ingestion tasks\u2014whether the data is batch or streaming. We use the medallion architecture to load files from azure blob  to bronze, silver, and gold tables. I\u2019ve found that autoloader works great for appending data to bronze tables and works fine when simple merge operations are done from bronze to silver. But when we start to have edge cases, such as restated data, that requires a selective delete and append, we run into problems. Additionally, when trying to use autoloader to write business logic (aggregations, joins, filters, etc.) it quickly becomes a nightmare. &lt;/p&gt;\n\n&lt;p&gt;Curious if anyone else has run into similar problems, and if so, what did you do to solve it? Does it even make sense to use autoloader for batch data processing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12q8wp3", "is_robot_indexable": true, "report_reasons": null, "author": "Basic_Cucumber_165", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12q8wp3/autoloader_for_batch_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12q8wp3/autoloader_for_batch_processing/", "subreddit_subscribers": 100225, "created_utc": 1681788892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to play around with some online tools such as secoda, mozart data etc for which i need a postgres instance. Rather than using any cloud provider i thought of using either my local postgres or postgres using docker. I am able to connect to the database using dbeaver in my local but not able to understand how to open it for remote access or have these third party tools access it. \n\nIt would be great for me to learn how to setup a postgres instance locally and use it for any development activities i wish. \n\nAdditionally if there is any website that i can allows a easy postgres/mysql db setup on cloud without much overhead and almost free then that would be great too. Few options i tried- neon.tech, elephantsql.", "author_fullname": "t2_81zlbrs6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help in setting up local postgres instance + allowing remote connections", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q6k8f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681784076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to play around with some online tools such as secoda, mozart data etc for which i need a postgres instance. Rather than using any cloud provider i thought of using either my local postgres or postgres using docker. I am able to connect to the database using dbeaver in my local but not able to understand how to open it for remote access or have these third party tools access it. &lt;/p&gt;\n\n&lt;p&gt;It would be great for me to learn how to setup a postgres instance locally and use it for any development activities i wish. &lt;/p&gt;\n\n&lt;p&gt;Additionally if there is any website that i can allows a easy postgres/mysql db setup on cloud without much overhead and almost free then that would be great too. Few options i tried- neon.tech, elephantsql.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12q6k8f", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPeanuts5237", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12q6k8f/need_help_in_setting_up_local_postgres_instance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12q6k8f/need_help_in_setting_up_local_postgres_instance/", "subreddit_subscribers": 100225, "created_utc": 1681784076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We store the queries that create tableau extracts in Github - we have a different folder for each query. \n\nI have started creating a subdirectory in the folder called tests where I put validation tests testing things like - the max\\_date year for this id should be no bigger than 2020. Or a report like \"10% of items are null\" for this result. \n\nThe problem is that these queries cannot run as is because they depend on the extract query and sql does not have file imports for instance. additionally it would be cool to run it as a test suite where I can determine if all 10 tests pass for instance after each change. Finally, the query sometimes takes a long time to run and I wish there was a way to use a temporary table. \n\nIm thinking of creating a python script to basically run this query and create a temporary table and then run each query as a test and output the results in a readable way. But is there something out there like this that I can just use? I know about dbt tests but I think its overkill just for each new tableau data source .", "author_fullname": "t2_b3n9i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool Recommendation for testing queries in a file?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ptpdx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681759687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We store the queries that create tableau extracts in Github - we have a different folder for each query. &lt;/p&gt;\n\n&lt;p&gt;I have started creating a subdirectory in the folder called tests where I put validation tests testing things like - the max_date year for this id should be no bigger than 2020. Or a report like &amp;quot;10% of items are null&amp;quot; for this result. &lt;/p&gt;\n\n&lt;p&gt;The problem is that these queries cannot run as is because they depend on the extract query and sql does not have file imports for instance. additionally it would be cool to run it as a test suite where I can determine if all 10 tests pass for instance after each change. Finally, the query sometimes takes a long time to run and I wish there was a way to use a temporary table. &lt;/p&gt;\n\n&lt;p&gt;Im thinking of creating a python script to basically run this query and create a temporary table and then run each query as a test and output the results in a readable way. But is there something out there like this that I can just use? I know about dbt tests but I think its overkill just for each new tableau data source .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ptpdx", "is_robot_indexable": true, "report_reasons": null, "author": "third_dude", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ptpdx/tool_recommendation_for_testing_queries_in_a_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ptpdx/tool_recommendation_for_testing_queries_in_a_file/", "subreddit_subscribers": 100225, "created_utc": 1681759687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/gastromatic/synchronizing-data-using-memphis-dev-a-case-study-2e6e9a7b5512](https://medium.com/gastromatic/synchronizing-data-using-memphis-dev-a-case-study-2e6e9a7b5512)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synchronizing data using a new message broker: A case study.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12plo5v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681745684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/gastromatic/synchronizing-data-using-memphis-dev-a-case-study-2e6e9a7b5512\"&gt;https://medium.com/gastromatic/synchronizing-data-using-memphis-dev-a-case-study-2e6e9a7b5512&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?auto=webp&amp;v=enabled&amp;s=e0dcf65745f8f81ca40c6232048eba40042bbf0a", "width": 1200, "height": 685}, "resolutions": [{"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5dd2916bdbf4df71087bc2fd4a81cfe569b85627", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c4e2e0bee9f7fe0ef25a3c7c898f283313a17d4", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b0c1d8204e15115c3870303acdc8ce061c110c1e", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55b7a318d94772320df353222cbe01861bf19c33", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10b85f5b8d4c343988c05c7fa7c79f5c754af917", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1183da065c5cf2cc73a5ff0fe7fe2e74be20a4a", "width": 1080, "height": 616}], "variants": {}, "id": "a2iUTeqWmkO2QfQFQh8Uti-nGge_UVR1rRhDsRSJ5sk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12plo5v", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12plo5v/synchronizing_data_using_a_new_message_broker_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12plo5v/synchronizing_data_using_a_new_message_broker_a/", "subreddit_subscribers": 100225, "created_utc": 1681745684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working doing data analyzation and visualization with one of my professors during my bachelors and really enjoyed the process of cleaning and working with data so I wanted to look more into data engineering. Does anyone have any good resources to start learning more skills for this field and help get my foot in the door? \n\nI was looking into IBM's courseera certificate to try and get exposed to the field more but are there better options out there?", "author_fullname": "t2_8vy0l4uv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to go after a BSc in CompSci", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qodfv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681827129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working doing data analyzation and visualization with one of my professors during my bachelors and really enjoyed the process of cleaning and working with data so I wanted to look more into data engineering. Does anyone have any good resources to start learning more skills for this field and help get my foot in the door? &lt;/p&gt;\n\n&lt;p&gt;I was looking into IBM&amp;#39;s courseera certificate to try and get exposed to the field more but are there better options out there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12qodfv", "is_robot_indexable": true, "report_reasons": null, "author": "BradP54", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12qodfv/where_to_go_after_a_bsc_in_compsci/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12qodfv/where_to_go_after_a_bsc_in_compsci/", "subreddit_subscribers": 100225, "created_utc": 1681827129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been tasked to start a CoE team for data within my organisation. Seems like I have  a starting problem \ud83d\ude15.\n\nHow does it usually start??\nBuild a vision for CoE\nStart building a team\nBest practices and architecture\nConfused where do I begin!", "author_fullname": "t2_6kmo2ecy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data CoE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q99n4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681789691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been tasked to start a CoE team for data within my organisation. Seems like I have  a starting problem \ud83d\ude15.&lt;/p&gt;\n\n&lt;p&gt;How does it usually start??\nBuild a vision for CoE\nStart building a team\nBest practices and architecture\nConfused where do I begin!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12q99n4", "is_robot_indexable": true, "report_reasons": null, "author": "soujoshi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12q99n4/data_coe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12q99n4/data_coe/", "subreddit_subscribers": 100225, "created_utc": 1681789691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What was the most challenging or the weirdest unstructured data preparation you've ever performed? What did you use for parsing/cleansing?", "author_fullname": "t2_1z5jdh5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The most challenging data preparation/ingestion of unstructured data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pxyjy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681767619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What was the most challenging or the weirdest unstructured data preparation you&amp;#39;ve ever performed? What did you use for parsing/cleansing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12pxyjy", "is_robot_indexable": true, "report_reasons": null, "author": "Greg_Z_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pxyjy/the_most_challenging_data_preparationingestion_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pxyjy/the_most_challenging_data_preparationingestion_of/", "subreddit_subscribers": 100225, "created_utc": 1681767619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Coming from a marketing analytics background I'm looking to specialise towards data engineering. AiCore looks to be a pretty comprehensive course to support this transition but I'm wondering if there's any other options I'm missing. Has anyone used AiCore before? Does anyone have any recommendations for data engineering courses?", "author_fullname": "t2_sqbpqte0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is AiCore my best option?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qo5ec", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681826690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Coming from a marketing analytics background I&amp;#39;m looking to specialise towards data engineering. AiCore looks to be a pretty comprehensive course to support this transition but I&amp;#39;m wondering if there&amp;#39;s any other options I&amp;#39;m missing. Has anyone used AiCore before? Does anyone have any recommendations for data engineering courses?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12qo5ec", "is_robot_indexable": true, "report_reasons": null, "author": "Pretty_Chemical4018", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12qo5ec/is_aicore_my_best_option/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12qo5ec/is_aicore_my_best_option/", "subreddit_subscribers": 100225, "created_utc": 1681826690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_81yu8ev", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Webinar - Running dbt core on Airflow in production - learnings from 2 years of battle scars", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_12pqntp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.44, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/v2cUNUuhL7O_rZWmg5pE4fJiGn_4K5TFCgXNw08wn-w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681753949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "operationalanalytics.club", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.operationalanalytics.club/events/running-dbt-core-on-airflow-in-production-learnings-from-2-years-of-battle-scars?ref=35499551", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?auto=webp&amp;v=enabled&amp;s=4ddf4c74086580fd6f7c3abe03787341c335f48e", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b0a737b3456b0c9617b5e5296ab4ad103d2a37d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8cc5bde8c1647cafccb5622c81f13dc182ba64b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1539678836218a354e83b3e6a78d14dbca0b811", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb38b9569dba052d500a37f287d47bea38aea21f", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2ffe9efaf51575ddd7e55625ff43de6f303d244", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98a8ddb78fafa82694c74c46f1afdbe6b8eeb72b", "width": 1080, "height": 565}], "variants": {}, "id": "zFQ3N50ROx6yVa7lCSV-VqnE2EVJ8YES1JgT95yllIU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12pqntp", "is_robot_indexable": true, "report_reasons": null, "author": "parzival1984", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pqntp/webinar_running_dbt_core_on_airflow_in_production/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.operationalanalytics.club/events/running-dbt-core-on-airflow-in-production-learnings-from-2-years-of-battle-scars?ref=35499551", "subreddit_subscribers": 100225, "created_utc": 1681753949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://jobs.cvshealth.com/job/17447961/lead-cloud-engineer-gcp-sql-python-devops-ai-ml-remote/\n\n\nHeard CVS (us employer) is spark / sql heavy so easy / medium leet code? Or coderpad.? Do they also ask extensive hour long case scenarios to solve(panel)?\n\nAnyone whose in this position or a similar one like sr DE? Tips?\n\nDoes the JD sound like they need devops guy too or assume devops knowledge should be there as it relates to ci cd cloud aws gcp etc?\n\nThanks \ud83d\ude0a", "author_fullname": "t2_1411ira9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to prepare for this position? See below", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qax7w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681793397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://jobs.cvshealth.com/job/17447961/lead-cloud-engineer-gcp-sql-python-devops-ai-ml-remote/\"&gt;https://jobs.cvshealth.com/job/17447961/lead-cloud-engineer-gcp-sql-python-devops-ai-ml-remote/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Heard CVS (us employer) is spark / sql heavy so easy / medium leet code? Or coderpad.? Do they also ask extensive hour long case scenarios to solve(panel)?&lt;/p&gt;\n\n&lt;p&gt;Anyone whose in this position or a similar one like sr DE? Tips?&lt;/p&gt;\n\n&lt;p&gt;Does the JD sound like they need devops guy too or assume devops knowledge should be there as it relates to ci cd cloud aws gcp etc?&lt;/p&gt;\n\n&lt;p&gt;Thanks \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Cx90UrVAA_Ce-prjOBJrVavrHPW3LHOoqjWxkoIq1VU.jpg?auto=webp&amp;v=enabled&amp;s=35cfd8278c5dc027d9e84502947f9d25bb572563", "width": 307, "height": 301}, "resolutions": [{"url": "https://external-preview.redd.it/Cx90UrVAA_Ce-prjOBJrVavrHPW3LHOoqjWxkoIq1VU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52fce6abaad0ef58c32fc60fd65b1667e720cf31", "width": 108, "height": 105}, {"url": "https://external-preview.redd.it/Cx90UrVAA_Ce-prjOBJrVavrHPW3LHOoqjWxkoIq1VU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd028943f5dc2a163ed867393c9af5f8270523b7", "width": 216, "height": 211}], "variants": {}, "id": "ISz3uhpPErEo_NVnFGH1tzrSJ9_t-uEnKKfJkw3EfEI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12qax7w", "is_robot_indexable": true, "report_reasons": null, "author": "wisegeek57", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12qax7w/how_to_prepare_for_this_position_see_below/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12qax7w/how_to_prepare_for_this_position_see_below/", "subreddit_subscribers": 100225, "created_utc": 1681793397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does it happen that you will be at Kubecon Europe 2023? We will be at **booth P15**, ready to talk about AI/ML, MLOps, open-source ML, Kubeflow, and more. There are a bunch of demos Ubuntu prepared and a fun keynote on secure MLOps. [Read more](https://medium.com/@andreeamihaelamunteanu/open-source-mlops-at-kubecon-with-ubuntu-870d06742b4f) and meet us there!", "author_fullname": "t2_3z4miuvs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kubecon Europe 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pzy96", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681771200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does it happen that you will be at Kubecon Europe 2023? We will be at &lt;strong&gt;booth P15&lt;/strong&gt;, ready to talk about AI/ML, MLOps, open-source ML, Kubeflow, and more. There are a bunch of demos Ubuntu prepared and a fun keynote on secure MLOps. &lt;a href=\"https://medium.com/@andreeamihaelamunteanu/open-source-mlops-at-kubecon-with-ubuntu-870d06742b4f\"&gt;Read more&lt;/a&gt; and meet us there!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?auto=webp&amp;v=enabled&amp;s=77fa09475f5677298ce0f781605f8b30e3872c28", "width": 720, "height": 376}, "resolutions": [{"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df046630b5228d489c6666882cd309e9a7db6bad", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=951a9937f2949b1944ec19a4be60f600d93bf424", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4928ff7617de6e675af1ca549a2751852e323de4", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd34f0217fe410444e028ce9b2b455e5962469a7", "width": 640, "height": 334}], "variants": {}, "id": "nXaAxnhnc4JIZNk3qgMyfIBphHx3dRXGnYjGSFZKG2I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12pzy96", "is_robot_indexable": true, "report_reasons": null, "author": "andreea-mun", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pzy96/kubecon_europe_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pzy96/kubecon_europe_2023/", "subreddit_subscribers": 100225, "created_utc": 1681771200.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}