{"kind": "Listing", "data": {"after": "t3_12qo3hx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey r/datascience!I found [this ancient thread](https://www.reddit.com/r/datascience/comments/bx59cv/tool_for_integrating_sql_jupyter_seamlessly/) about Jupyter Notebooks and SQL queries.I\u2019m wondering if:\n\n1. Are people here still running SQL from within the notebook?\n2. What best practices/tips do you have?\n3. What are the main use cases?\n\nI usually use it to connect to multiple sources, store the queries within the notebook, and then put the notebooks into version control. I also found pandas way slower from running a [duckdb](https://jupysql.ploomber.io/en/latest/integrations/duckdb.html) \\+ [jupysql](https://github.com/ploomber/jupysql) when possible.", "author_fullname": "t2_sy01bb7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best practices around Jupyter and SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ptgo1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 109, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 109, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681821067.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681759204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;!I found &lt;a href=\"https://www.reddit.com/r/datascience/comments/bx59cv/tool_for_integrating_sql_jupyter_seamlessly/\"&gt;this ancient thread&lt;/a&gt; about Jupyter Notebooks and SQL queries.I\u2019m wondering if:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Are people here still running SQL from within the notebook?&lt;/li&gt;\n&lt;li&gt;What best practices/tips do you have?&lt;/li&gt;\n&lt;li&gt;What are the main use cases?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I usually use it to connect to multiple sources, store the queries within the notebook, and then put the notebooks into version control. I also found pandas way slower from running a &lt;a href=\"https://jupysql.ploomber.io/en/latest/integrations/duckdb.html\"&gt;duckdb&lt;/a&gt; + &lt;a href=\"https://github.com/ploomber/jupysql\"&gt;jupysql&lt;/a&gt; when possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ptgo1", "is_robot_indexable": true, "report_reasons": null, "author": "idomic", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ptgo1/what_are_the_best_practices_around_jupyter_and_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ptgo1/what_are_the_best_practices_around_jupyter_and_sql/", "subreddit_subscribers": 875532, "created_utc": 1681759204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, let me preface this: **I understand this is a very general ask and therefore I can only expect very general responses.**\n\nI am most likely going to transition from my current data scientist role into a data analytics role because it aligns better with my interests and skillset. I know that generally speaking, the data scientist's salary is higher than that of the data analyst, but I also expect I will be able to leverage my experience to get a more senior role within data analytics that I am hoping will at least offset the difference.\n\nMy current role is an Associate-level Data Scientist, and my target role will be a Senior-level Data Analyst. Again, **I know there are a lot of variables at play here**, but in a very general sense, what do people think I should expect salary-wise? A slight decrease? Slight increase? Roughly the same?\n\nAny and all input is appreciated. Thanks all!", "author_fullname": "t2_ngcpuv32", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salary expectations moving from data science into data analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q8oaq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 76, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 76, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681788406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, let me preface this: &lt;strong&gt;I understand this is a very general ask and therefore I can only expect very general responses.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I am most likely going to transition from my current data scientist role into a data analytics role because it aligns better with my interests and skillset. I know that generally speaking, the data scientist&amp;#39;s salary is higher than that of the data analyst, but I also expect I will be able to leverage my experience to get a more senior role within data analytics that I am hoping will at least offset the difference.&lt;/p&gt;\n\n&lt;p&gt;My current role is an Associate-level Data Scientist, and my target role will be a Senior-level Data Analyst. Again, &lt;strong&gt;I know there are a lot of variables at play here&lt;/strong&gt;, but in a very general sense, what do people think I should expect salary-wise? A slight decrease? Slight increase? Roughly the same?&lt;/p&gt;\n\n&lt;p&gt;Any and all input is appreciated. Thanks all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q8oaq", "is_robot_indexable": true, "report_reasons": null, "author": "abnormal_oats", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q8oaq/salary_expectations_moving_from_data_science_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q8oaq/salary_expectations_moving_from_data_science_into/", "subreddit_subscribers": 875532, "created_utc": 1681788406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Fitter:  \n [cokelaer/fitter: Fit data to many distributions (github.com)](https://github.com/cokelaer/fitter)", "author_fullname": "t2_3op9qx89", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I recently discovered the python package 'fitter', which is a really nifty package for fitting various data distributions. Has anyone discovered any other cool packages that the field would find useful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ppj7g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681751794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fitter:&lt;br/&gt;\n &lt;a href=\"https://github.com/cokelaer/fitter\"&gt;cokelaer/fitter: Fit data to many distributions (github.com)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ppj7g", "is_robot_indexable": true, "report_reasons": null, "author": "LatterConcentrate6", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ppj7g/i_recently_discovered_the_python_package_fitter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ppj7g/i_recently_discovered_the_python_package_fitter/", "subreddit_subscribers": 875532, "created_utc": 1681751794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I will be starting my masters program in US from this fall. I would like to buy an new laptop for me to do projects. I guess we need nvdia gpu for cuda support. So please drop your suggestions", "author_fullname": "t2_7clcwm7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Laptop suggestions for ML/Data Science/CV projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qa0n0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681791341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I will be starting my masters program in US from this fall. I would like to buy an new laptop for me to do projects. I guess we need nvdia gpu for cuda support. So please drop your suggestions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qa0n0", "is_robot_indexable": true, "report_reasons": null, "author": "Southern-Acadia-3744", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qa0n0/laptop_suggestions_for_mldata_sciencecv_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qa0n0/laptop_suggestions_for_mldata_sciencecv_projects/", "subreddit_subscribers": 875532, "created_utc": 1681791341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am having a business problem, where we used to send some metrics Numbers each day, by putting them into excel sheet,  and send them to each stakeholders \n\nI have used Python to automate the numbers, and send the stakeholders daily mails using smtp lib.\n\nBut that doesn't  looks nice to present them to stakeholders like, CEO ,\n\nSo, I just wanna know, can we replicate this view using CSS/HTML or any other method,\n\nif yes, which method would work? I am data analyst So dont have any idea in css html or any other ,\n\n&amp;#x200B;\n\nhttps://preview.redd.it/yh9wlmk0xmua1.png?width=1073&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=245e3cb63690ed90500f7907803a01857d141144", "author_fullname": "t2_agvtvokn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replicating a sheet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"yh9wlmk0xmua1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 177, "x": 108, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ff7756410f3eff1a130b849b9733885d6cbbe71"}, {"y": 354, "x": 216, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a330aca0093670629bdfb7c2d8eea74925eb44e8"}, {"y": 525, "x": 320, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9cedccd7673911d2cb53e763715c91d52ef7a5b"}, {"y": 1050, "x": 640, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5278ca7cab7a0e72f6fce20abe0491ca5182860b"}, {"y": 1575, "x": 960, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd92b7bf8f9bf0b60daf7879c2010376c3209941"}], "s": {"y": 1761, "x": 1073, "u": "https://preview.redd.it/yh9wlmk0xmua1.png?width=1073&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=245e3cb63690ed90500f7907803a01857d141144"}, "id": "yh9wlmk0xmua1"}}, "name": "t3_12ql37a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CIVfGZm5nguI7lUIpCWOZ9xw4WgLmAzBMvYI162AuBM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681820093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am having a business problem, where we used to send some metrics Numbers each day, by putting them into excel sheet,  and send them to each stakeholders &lt;/p&gt;\n\n&lt;p&gt;I have used Python to automate the numbers, and send the stakeholders daily mails using smtp lib.&lt;/p&gt;\n\n&lt;p&gt;But that doesn&amp;#39;t  looks nice to present them to stakeholders like, CEO ,&lt;/p&gt;\n\n&lt;p&gt;So, I just wanna know, can we replicate this view using CSS/HTML or any other method,&lt;/p&gt;\n\n&lt;p&gt;if yes, which method would work? I am data analyst So dont have any idea in css html or any other ,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yh9wlmk0xmua1.png?width=1073&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=245e3cb63690ed90500f7907803a01857d141144\"&gt;https://preview.redd.it/yh9wlmk0xmua1.png?width=1073&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=245e3cb63690ed90500f7907803a01857d141144&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12ql37a", "is_robot_indexable": true, "report_reasons": null, "author": "chilly_tomato", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12ql37a/replicating_a_sheet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12ql37a/replicating_a_sheet/", "subreddit_subscribers": 875532, "created_utc": 1681820093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As title, I understand the concept of market mix modeling from the analysis/modeling aspect, but once the model has been approved, how the media optimization works afterward?\n\nit utilizes the outputs/parameters from the model, and it can be done in linear and non linear, but that is about what I know.\n\nAnyone can shed some lights into this? TiA", "author_fullname": "t2_ul5y0kdu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Media Optimization in Marketing Mix Model project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q36b1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681777377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As title, I understand the concept of market mix modeling from the analysis/modeling aspect, but once the model has been approved, how the media optimization works afterward?&lt;/p&gt;\n\n&lt;p&gt;it utilizes the outputs/parameters from the model, and it can be done in linear and non linear, but that is about what I know.&lt;/p&gt;\n\n&lt;p&gt;Anyone can shed some lights into this? TiA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q36b1", "is_robot_indexable": true, "report_reasons": null, "author": "kyleireddit", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q36b1/media_optimization_in_marketing_mix_model_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q36b1/media_optimization_in_marketing_mix_model_project/", "subreddit_subscribers": 875532, "created_utc": 1681777377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! I am currently writing a series of articles about the pre-processing steps for time series data.  \n\nIn the first article, I suggest the following order: \n\n1. Handle missing values \n2. Remove trend \n3. Remove seasonality \n4. Check for stationarity and make it stationary if necessary \n5. Normalize the data \n6. Remove outliers \n7. Smooth the data \n\nHowever, I know this order is not universal and can be changed depending on our data. Also, not all the steps are always required.  \n\nMy question is, which would be the \"standard\" order that you would suggest?  \n\nI leave the first part of these articles [here](https://mlpills.dev/time-series/clean-your-time-series-data-i/) and the second one [here](https://mlpills.dev/time-series/clean-your-time-series-data-ii/). The last two parts are written but not published yet :( \n\nI'd love to hear some feedback. :)\n\n Thanks!", "author_fullname": "t2_gvvf9r1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pre-processing order for time series data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qi9b4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681812524.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I am currently writing a series of articles about the pre-processing steps for time series data.  &lt;/p&gt;\n\n&lt;p&gt;In the first article, I suggest the following order: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Handle missing values &lt;/li&gt;\n&lt;li&gt;Remove trend &lt;/li&gt;\n&lt;li&gt;Remove seasonality &lt;/li&gt;\n&lt;li&gt;Check for stationarity and make it stationary if necessary &lt;/li&gt;\n&lt;li&gt;Normalize the data &lt;/li&gt;\n&lt;li&gt;Remove outliers &lt;/li&gt;\n&lt;li&gt;Smooth the data &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;However, I know this order is not universal and can be changed depending on our data. Also, not all the steps are always required.  &lt;/p&gt;\n\n&lt;p&gt;My question is, which would be the &amp;quot;standard&amp;quot; order that you would suggest?  &lt;/p&gt;\n\n&lt;p&gt;I leave the first part of these articles &lt;a href=\"https://mlpills.dev/time-series/clean-your-time-series-data-i/\"&gt;here&lt;/a&gt; and the second one &lt;a href=\"https://mlpills.dev/time-series/clean-your-time-series-data-ii/\"&gt;here&lt;/a&gt;. The last two parts are written but not published yet :( &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear some feedback. :)&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?auto=webp&amp;v=enabled&amp;s=2e987cc53a9606585b9baea3b9c3056362d77e3f", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b73276f3c7bed3898752484fca308aad5f66cc0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e2fa795d34a622e420f1f36e8388f25a2ac8789", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=358d8be8f2dd2edc85977a8aa927b07835df2b53", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b01d8de571f37cfff87ee9b58097cff988258d1", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0d9065265650f0e4234b339bc7f47411a7c790b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/cwrfoLVTPp530kQiNj_W-0Uhsl2AIrHhEZpn7VP7An8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8de1b636fa63a6391629a2acd3898bee1f5f405", "width": 1080, "height": 607}], "variants": {}, "id": "z2mUwpw_935DsBDU4V1KJzNU_rF0PEhxMVMa8oVerhk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qi9b4", "is_robot_indexable": true, "report_reasons": null, "author": "daansan-ml", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qi9b4/preprocessing_order_for_time_series_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qi9b4/preprocessing_order_for_time_series_data/", "subreddit_subscribers": 875532, "created_utc": 1681812524.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All\n\nI've been posting on here quite a bit and have been really enjoying the responses I've been getting and have been learning a ton.\n\nI had a question about A/B testing with CTR\n\nLet's assume we will run an experiment where CTR is our primary metric, and that our experiment will allocate/sample on a user-level\n\nThis means when we calculate sample size and power analysis, this should be done on a user-level, is that correct?\n\nWhat is the proper way to do this, given ad data is typically on an impression level?\n\nMy thoughts:\n\naggregate on a user-level, where columns are # of impressions, # of clicks, and ctr of each user\n\nyour metric is now continuous since it is ctr of each user, and you can calculate the weighted stdev/variance.\n\n&amp;#x200B;\n\nis this a valid approach?", "author_fullname": "t2_133emd5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A/B Test with CTR - User Level", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q3a13", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681777582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been posting on here quite a bit and have been really enjoying the responses I&amp;#39;ve been getting and have been learning a ton.&lt;/p&gt;\n\n&lt;p&gt;I had a question about A/B testing with CTR&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s assume we will run an experiment where CTR is our primary metric, and that our experiment will allocate/sample on a user-level&lt;/p&gt;\n\n&lt;p&gt;This means when we calculate sample size and power analysis, this should be done on a user-level, is that correct?&lt;/p&gt;\n\n&lt;p&gt;What is the proper way to do this, given ad data is typically on an impression level?&lt;/p&gt;\n\n&lt;p&gt;My thoughts:&lt;/p&gt;\n\n&lt;p&gt;aggregate on a user-level, where columns are # of impressions, # of clicks, and ctr of each user&lt;/p&gt;\n\n&lt;p&gt;your metric is now continuous since it is ctr of each user, and you can calculate the weighted stdev/variance.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;is this a valid approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q3a13", "is_robot_indexable": true, "report_reasons": null, "author": "vatom14", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q3a13/ab_test_with_ctr_user_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q3a13/ab_test_with_ctr_user_level/", "subreddit_subscribers": 875532, "created_utc": 1681777582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi friends, I\u2019m working on a uni project where I have I have to attribute multiple factors (e.g. promotions, inventory levels, store closures, etc.) to a retail sales increase / decrease for a particular week. So like I want to say like \u201cgood weather was responsible for driving sales this week.\u201d\n\nWhat\u2019s the best type of causal model / lib to use in this case? I\u2019m thinking of using something like DoWhy, but not sure if there\u2019s other causal frameworks out there that could be more relevant? \n\nThanks!", "author_fullname": "t2_1blas9up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Retail Sales Attribution Models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pw7za", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681764497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends, I\u2019m working on a uni project where I have I have to attribute multiple factors (e.g. promotions, inventory levels, store closures, etc.) to a retail sales increase / decrease for a particular week. So like I want to say like \u201cgood weather was responsible for driving sales this week.\u201d&lt;/p&gt;\n\n&lt;p&gt;What\u2019s the best type of causal model / lib to use in this case? I\u2019m thinking of using something like DoWhy, but not sure if there\u2019s other causal frameworks out there that could be more relevant? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pw7za", "is_robot_indexable": true, "report_reasons": null, "author": "chocolate_bear95", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12pw7za/retail_sales_attribution_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12pw7za/retail_sales_attribution_models/", "subreddit_subscribers": 875532, "created_utc": 1681764497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm training an xgboost model in R using the caret package. I added class weights to the train control because my binary outcome is very skewed. However, the model with weights has an AUROC of 0.49, whereas the model without the weights has an AUROC of 0.88. I have other models too including logistic regression, random forest, etc, and their AUROC increased after implementing the weights. So why does it decrease it so much for XGBoost, is it because XGB already gives bigger weight to wrongly predicted observations in previous iterations?", "author_fullname": "t2_ing7dag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about class weights in xgboost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12poilz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681749797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m training an xgboost model in R using the caret package. I added class weights to the train control because my binary outcome is very skewed. However, the model with weights has an AUROC of 0.49, whereas the model without the weights has an AUROC of 0.88. I have other models too including logistic regression, random forest, etc, and their AUROC increased after implementing the weights. So why does it decrease it so much for XGBoost, is it because XGB already gives bigger weight to wrongly predicted observations in previous iterations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12poilz", "is_robot_indexable": true, "report_reasons": null, "author": "Goliof", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12poilz/question_about_class_weights_in_xgboost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12poilz/question_about_class_weights_in_xgboost/", "subreddit_subscribers": 875532, "created_utc": 1681749797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As an aspiring professional aiming to commence a career in the multifaceted sphere of data science, I am actively seeking to gain valuable practical experience through internships. However, as I delve deeper into the nuances of this pursuit, I am compelled to pose an inquiry: What form of financial compensation, if any, is typically offered for such internships?", "author_fullname": "t2_c10jzyya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring Internship Remuneration in Data Science: A Novice's Query", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qpfg0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681829124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As an aspiring professional aiming to commence a career in the multifaceted sphere of data science, I am actively seeking to gain valuable practical experience through internships. However, as I delve deeper into the nuances of this pursuit, I am compelled to pose an inquiry: What form of financial compensation, if any, is typically offered for such internships?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qpfg0", "is_robot_indexable": true, "report_reasons": null, "author": "Doc_OM3GA", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qpfg0/exploring_internship_remuneration_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qpfg0/exploring_internship_remuneration_in_data_science/", "subreddit_subscribers": 875532, "created_utc": 1681829124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello veryone, I would like to know it's possible to deploy JupypterLab into Django app.  \nI want to manage my users for using this platform in out organization.  \nplease if you have any documentations about it , I'll be very thankfull   \nThanks !", "author_fullname": "t2_gnhzyiiu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploy JupyterLab into Django", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qpep4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681829085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello veryone, I would like to know it&amp;#39;s possible to deploy JupypterLab into Django app.&lt;br/&gt;\nI want to manage my users for using this platform in out organization.&lt;br/&gt;\nplease if you have any documentations about it , I&amp;#39;ll be very thankfull&lt;br/&gt;\nThanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qpep4", "is_robot_indexable": true, "report_reasons": null, "author": "hlama26", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qpep4/deploy_jupyterlab_into_django/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qpep4/deploy_jupyterlab_into_django/", "subreddit_subscribers": 875532, "created_utc": 1681829085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have run a backward feature selection model as follows:\n\nbackward\\_feature\\_selector=SequentialFeatureSelector(DecisionTreeClassifier(),\n\nk\\_features=6,\n\nforward=False,\n\nfloating=True,\n\nverbose=2,\n\nscoring=\"accuracy\",\n\ncv=5).fit(X\\_train,y\\_train)   \n\nfeat\\_names = list(backward\\_feature\\_selector.k\\_feature\\_names\\_)\n\n\n\n&amp;#x200B;\n\nprint(feat\\_names)\n\n&amp;#x200B;\n\nI get this:\n\n\\['0', '1', '2', '3', '9', '26'\\]\n\n&amp;#x200B;\n\n26 is not even in my column index range. Also, aren't they supposed to display the names of columns selected?", "author_fullname": "t2_atffdhh0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am unable to view my features in backward elimination model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qp70x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681828701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have run a backward feature selection model as follows:&lt;/p&gt;\n\n&lt;p&gt;backward_feature_selector=SequentialFeatureSelector(DecisionTreeClassifier(),&lt;/p&gt;\n\n&lt;p&gt;k_features=6,&lt;/p&gt;\n\n&lt;p&gt;forward=False,&lt;/p&gt;\n\n&lt;p&gt;floating=True,&lt;/p&gt;\n\n&lt;p&gt;verbose=2,&lt;/p&gt;\n\n&lt;p&gt;scoring=&amp;quot;accuracy&amp;quot;,&lt;/p&gt;\n\n&lt;p&gt;cv=5).fit(X_train,y_train)   &lt;/p&gt;\n\n&lt;p&gt;feat_names = list(backward_feature_selector.k_feature_names_)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;print(feat_names)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I get this:&lt;/p&gt;\n\n&lt;p&gt;[&amp;#39;0&amp;#39;, &amp;#39;1&amp;#39;, &amp;#39;2&amp;#39;, &amp;#39;3&amp;#39;, &amp;#39;9&amp;#39;, &amp;#39;26&amp;#39;]&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;26 is not even in my column index range. Also, aren&amp;#39;t they supposed to display the names of columns selected?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qp70x", "is_robot_indexable": true, "report_reasons": null, "author": "quilted_reader", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qp70x/i_am_unable_to_view_my_features_in_backward/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qp70x/i_am_unable_to_view_my_features_in_backward/", "subreddit_subscribers": 875532, "created_utc": 1681828701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it normal that companies are not serious about hiring, take very long time and getting an offer is just not common\n\nI\u2019m not talking about job boards. Is it normal that you find a lot of positions that have not been posted yet, through perhaps word of mouth or recommendations, those companies constantly say you\u2019re perfect for this, will send you an offer shortly, then just don\u2019t? \n\nI have not quite experienced this in other fields. Maybe it takes too much to be in this field, and it\u2019s better to pursue something else? I never heard of so much playing around, or not knowing what they want?  ( career level: experienced)\n\nThis happened 3 times in the last month. Basically you\u2019re the chosen candidate, there are  no other candidates, let me just draft up the papers, then nothing or rejection. Also no questions in interviews or tests? They just reiterate your resume to you and how they know you\u2019d be a perfect fit", "author_fullname": "t2_6h5h5k7v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hiring practices particular to this field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qp3p8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681828525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it normal that companies are not serious about hiring, take very long time and getting an offer is just not common&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not talking about job boards. Is it normal that you find a lot of positions that have not been posted yet, through perhaps word of mouth or recommendations, those companies constantly say you\u2019re perfect for this, will send you an offer shortly, then just don\u2019t? &lt;/p&gt;\n\n&lt;p&gt;I have not quite experienced this in other fields. Maybe it takes too much to be in this field, and it\u2019s better to pursue something else? I never heard of so much playing around, or not knowing what they want?  ( career level: experienced)&lt;/p&gt;\n\n&lt;p&gt;This happened 3 times in the last month. Basically you\u2019re the chosen candidate, there are  no other candidates, let me just draft up the papers, then nothing or rejection. Also no questions in interviews or tests? They just reiterate your resume to you and how they know you\u2019d be a perfect fit&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qp3p8", "is_robot_indexable": true, "report_reasons": null, "author": "DerpyOwlofParadise", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qp3p8/hiring_practices_particular_to_this_field/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qp3p8/hiring_practices_particular_to_this_field/", "subreddit_subscribers": 875532, "created_utc": 1681828525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "ClickHouse is one of the fastest SQL engines in the world. But installing and maintaining a Clickhouse server is not easy.\n\nNow, you can run complex SQL blazing fast with chDB which is an embedded Clickhouse engine in Python.\n\n# features\n\n* In-process SQL OLAP Engine, powered by ClickHouse\n* No need to install ClickHouse\n* Minimized data copy from C++ to Python with [python memoryview](https://docs.python.org/3/c-api/memoryview.html)\n* Input&amp;Output support Parquet, CSV, JSON, Arrow, ORC and [more](https://clickhouse.com/docs/en/interfaces/formats)\n\n# install\n```bash\npip install chdb\n```\n\n# examples\nRun any SQL in just one line\n```python\nimport chdb\nres = chdb.query('select * from file(\"data.parquet\", Parquet)', 'Dataframe')\nprint res\n```\n\n- PyPi: https://pypi.org/project/chdb/\n- GitHub: https://github.com/auxten/chdb\n\n&gt; Due to the size of the engine, the first SQL could be slow.", "author_fullname": "t2_5x6me", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Run SQL blazing fast with the embedded Clickhouse engine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qopcr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681827774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ClickHouse is one of the fastest SQL engines in the world. But installing and maintaining a Clickhouse server is not easy.&lt;/p&gt;\n\n&lt;p&gt;Now, you can run complex SQL blazing fast with chDB which is an embedded Clickhouse engine in Python.&lt;/p&gt;\n\n&lt;h1&gt;features&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;In-process SQL OLAP Engine, powered by ClickHouse&lt;/li&gt;\n&lt;li&gt;No need to install ClickHouse&lt;/li&gt;\n&lt;li&gt;Minimized data copy from C++ to Python with &lt;a href=\"https://docs.python.org/3/c-api/memoryview.html\"&gt;python memoryview&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Input&amp;amp;Output support Parquet, CSV, JSON, Arrow, ORC and &lt;a href=\"https://clickhouse.com/docs/en/interfaces/formats\"&gt;more&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;install&lt;/h1&gt;\n\n&lt;p&gt;&lt;code&gt;bash\npip install chdb\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;h1&gt;examples&lt;/h1&gt;\n\n&lt;p&gt;Run any SQL in just one line\n&lt;code&gt;python\nimport chdb\nres = chdb.query(&amp;#39;select * from file(&amp;quot;data.parquet&amp;quot;, Parquet)&amp;#39;, &amp;#39;Dataframe&amp;#39;)\nprint res\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;PyPi: &lt;a href=\"https://pypi.org/project/chdb/\"&gt;https://pypi.org/project/chdb/&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;GitHub: &lt;a href=\"https://github.com/auxten/chdb\"&gt;https://github.com/auxten/chdb&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Due to the size of the engine, the first SQL could be slow.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uQnwG5vj0W2B8UmXvnpbBF8bitWWN9ApOpjGDNFekLw.jpg?auto=webp&amp;v=enabled&amp;s=8cffb70177a255a5d273f49b07a192aae79dd5d1", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/uQnwG5vj0W2B8UmXvnpbBF8bitWWN9ApOpjGDNFekLw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00b81de315991e3643052ea46585a6ef9bd8c2d5", "width": 108, "height": 108}], "variants": {}, "id": "qsyApzksUdlxqY7z2ubJCNmhQilhXIOl25dSHcQQLB4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qopcr", "is_robot_indexable": true, "report_reasons": null, "author": "auxten", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qopcr/run_sql_blazing_fast_with_the_embedded_clickhouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qopcr/run_sql_blazing_fast_with_the_embedded_clickhouse/", "subreddit_subscribers": 875532, "created_utc": 1681827774.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone! At the Data-Centric AI Community, we're starting a small, beginner-friendly project on synthetic data. It\u2019s a US Government initiative and we\u2019re putting together a workgroup to apply as a team! \n\nFor those starting out in Data Science, it could be a cool opportunity to learn more in a low-pressure environment!\n\nHeres's our repository: \ud83d\ude80 ([https://github.com/Data-Centric-AI-Community/nist-crc-2023](https://github.com/Data-Centric-AI-Community/nist-crc-2023))", "author_fullname": "t2_tqj6pej3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synthetic Data Community Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qoh8v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681827331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! At the Data-Centric AI Community, we&amp;#39;re starting a small, beginner-friendly project on synthetic data. It\u2019s a US Government initiative and we\u2019re putting together a workgroup to apply as a team! &lt;/p&gt;\n\n&lt;p&gt;For those starting out in Data Science, it could be a cool opportunity to learn more in a low-pressure environment!&lt;/p&gt;\n\n&lt;p&gt;Heres&amp;#39;s our repository: \ud83d\ude80 (&lt;a href=\"https://github.com/Data-Centric-AI-Community/nist-crc-2023\"&gt;https://github.com/Data-Centric-AI-Community/nist-crc-2023&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/n0Fxpnry0O__eNfGur3TwHOlBvjb9knlrb9_NgV7k40.jpg?auto=webp&amp;v=enabled&amp;s=dfccdb51887bdc33a4fd6a2404b52d4324da9d23", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/n0Fxpnry0O__eNfGur3TwHOlBvjb9knlrb9_NgV7k40.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=85030c76fa8d2be3d0f80c2ee2717a340f1b9daa", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/n0Fxpnry0O__eNfGur3TwHOlBvjb9knlrb9_NgV7k40.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47ca5549d90542aacb2e8bde7c7d2e9762438291", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/n0Fxpnry0O__eNfGur3TwHOlBvjb9knlrb9_NgV7k40.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a9d386ab41ac6bea1c140cae728fa9a217d5c61", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/n0Fxpnry0O__eNfGur3TwHOlBvjb9knlrb9_NgV7k40.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c40bcc1046efe65d0e68fc79134662d34f9d10d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/n0Fxpnry0O__eNfGur3TwHOlBvjb9knlrb9_NgV7k40.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=305c1e116752b9a4b3f69f01e13b958acd5e2bba", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/n0Fxpnry0O__eNfGur3TwHOlBvjb9knlrb9_NgV7k40.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de1e117ce15ef0ac09ce70fbe3504338c0e09b1b", "width": 1080, "height": 540}], "variants": {}, "id": "r0uYCNFhz1TUj7gbzEcCfP87oZeyKm8m3teVZxQNiyw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qoh8v", "is_robot_indexable": true, "report_reasons": null, "author": "SeaEngineering9034", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qoh8v/synthetic_data_community_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qoh8v/synthetic_data_community_project/", "subreddit_subscribers": 875532, "created_utc": 1681827331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Please recommend data science/ml books for retail industry/supply chain with more practical implementations.", "author_fullname": "t2_aspf3blq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book recommendations: data science in retail, practical implementations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qnww7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681826205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please recommend data science/ml books for retail industry/supply chain with more practical implementations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qnww7", "is_robot_indexable": true, "report_reasons": null, "author": "Bayesian8", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qnww7/book_recommendations_data_science_in_retail/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qnww7/book_recommendations_data_science_in_retail/", "subreddit_subscribers": 875532, "created_utc": 1681826205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys! In 2 weeks I'm starting my new role as a data scientist. Since I come from another field and I'm still such a green bean, my new boss has decided to get me into a bootcamp. He suggested the one from DataScientest (~285 hours) unless I propose another one. To those of you in Europe: Have you guys heard anything of this bootcamp? Any good/bad experiences you can share about it?", "author_fullname": "t2_6xiu1hs9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataScientest bootcamp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qnwdf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681826173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys! In 2 weeks I&amp;#39;m starting my new role as a data scientist. Since I come from another field and I&amp;#39;m still such a green bean, my new boss has decided to get me into a bootcamp. He suggested the one from DataScientest (~285 hours) unless I propose another one. To those of you in Europe: Have you guys heard anything of this bootcamp? Any good/bad experiences you can share about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qnwdf", "is_robot_indexable": true, "report_reasons": null, "author": "Davidat0r", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qnwdf/datascientest_bootcamp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qnwdf/datascientest_bootcamp/", "subreddit_subscribers": 875532, "created_utc": 1681826173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For my work I\u2019m hunting a dataset that is:\nWestern companies doing their manufacturing of electronics specifically in China or Taiwan. \n\nI\u2019m having a tough time coming up with a comprehensive dataset or list of these companies. \n\nOnly thing I\u2019m able to find is the largest 50 companies from Google searches. Any advice? Thanks in advance!", "author_fullname": "t2_a7xiz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you find datasets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qnn5h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681825634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For my work I\u2019m hunting a dataset that is:\nWestern companies doing their manufacturing of electronics specifically in China or Taiwan. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m having a tough time coming up with a comprehensive dataset or list of these companies. &lt;/p&gt;\n\n&lt;p&gt;Only thing I\u2019m able to find is the largest 50 companies from Google searches. Any advice? Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qnn5h", "is_robot_indexable": true, "report_reasons": null, "author": "HomeStar182", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qnn5h/where_do_you_find_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qnn5h/where_do_you_find_datasets/", "subreddit_subscribers": 875532, "created_utc": 1681825634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m trying to back track from survival function down to hazard function which upon dividing by the partial hazard should give the same baseline hazard for any 2 example subjects. Unfortunately predict_hazard function in CoxPHFitter is throwing an error (doesn\u2019t have the attribute apparently, which is v weird). And if I manually get to a hazard function from the cumulative hazard function (not super sure of the calculation), the step after dividing by partial hazard is not the same i.e., 2 different baseline hazards. Any help appreciated.", "author_fullname": "t2_u3vhf5lz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Facing inconsistencies while trying to reconstruct Cox PH predictions by lifelines package", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qltap", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681821775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to back track from survival function down to hazard function which upon dividing by the partial hazard should give the same baseline hazard for any 2 example subjects. Unfortunately predict_hazard function in CoxPHFitter is throwing an error (doesn\u2019t have the attribute apparently, which is v weird). And if I manually get to a hazard function from the cumulative hazard function (not super sure of the calculation), the step after dividing by partial hazard is not the same i.e., 2 different baseline hazards. Any help appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qltap", "is_robot_indexable": true, "report_reasons": null, "author": "thesaintyouneed", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qltap/facing_inconsistencies_while_trying_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qltap/facing_inconsistencies_while_trying_to/", "subreddit_subscribers": 875532, "created_utc": 1681821775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Question to all the veterans out there:\n\n1. What are some of the most common problems that the current ML tools/startups are NOT able to solve?\n\n2. If given an option, hypothetically speaking, what all features would you have added in your favourite tool to make it 100% complete and a \"go-to\" software?", "author_fullname": "t2_a4d2j3fh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Problem with current ML tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12qfblm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681804454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Question to all the veterans out there:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;What are some of the most common problems that the current ML tools/startups are NOT able to solve?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;If given an option, hypothetically speaking, what all features would you have added in your favourite tool to make it 100% complete and a &amp;quot;go-to&amp;quot; software?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qfblm", "is_robot_indexable": true, "report_reasons": null, "author": "Living-Nobody-2727", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qfblm/problem_with_current_ml_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qfblm/problem_with_current_ml_tools/", "subreddit_subscribers": 875532, "created_utc": 1681804454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hi! right now im looking to major in cs at georgia tech, and i'm not sure how much of a pipeline that leaves me out of undergrad. if i want to get in to data science out of undergrad, what might i need to do? does anyone have any experiences to share?\n\nim thinking of doing computational data analysis as a minor, infosystems and intelligence as \"subfocuses\" within my major, and i plan on joining some data science and ML bootcamps and clubs.... any other suggestions?\n\ni want to stick to a comp sci major, because i still want a good compsci foundation, just in case i dont end up enjoying ds. ", "author_fullname": "t2_5rc1mk09o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what might i need to get into data science as an undergrad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q7dbo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681785696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi! right now im looking to major in cs at georgia tech, and i&amp;#39;m not sure how much of a pipeline that leaves me out of undergrad. if i want to get in to data science out of undergrad, what might i need to do? does anyone have any experiences to share?&lt;/p&gt;\n\n&lt;p&gt;im thinking of doing computational data analysis as a minor, infosystems and intelligence as &amp;quot;subfocuses&amp;quot; within my major, and i plan on joining some data science and ML bootcamps and clubs.... any other suggestions?&lt;/p&gt;\n\n&lt;p&gt;i want to stick to a comp sci major, because i still want a good compsci foundation, just in case i dont end up enjoying ds. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12q7dbo", "is_robot_indexable": true, "report_reasons": null, "author": "desperate_DS_student", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12q7dbo/what_might_i_need_to_get_into_data_science_as_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12q7dbo/what_might_i_need_to_get_into_data_science_as_an/", "subreddit_subscribers": 875532, "created_utc": 1681785696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83c\udf7c\ud83d\udd2c BabyDS: An AI powered Data Analysis pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qoi1i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_h2wdb", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "LangChain", "selftext": "Hey friends, wanted to share a project I've been working on. It's a langchain powered bot that performs data analysis and generates a report for a given objective. Just tell it what you want to achieve and point it to the dataset. Here's an excerpt from a test run that aimed to find fraud in an NYC public salaries dataset.\n\n&gt;Let's start with the good news: the average base salary for public employees in New York City has been on the rise. In 2018, the average base salary was $45,508.538, and by 2022, it had increased to $48,426.018. That's a modest increase, but it's still a positive trend.\n&gt;\n&gt;But when we look at the total other pay received by public employees, the numbers are truly staggering. In just ten fiscal years, the total other pay received by public employees in New York City has more than doubled. In 2014, the total other pay received was $1,149,076,637.61, and by 2022, it had increased to $2,740,086,013.70. That's a substantial increase, and it raises some important questions about how and why public employees are receiving so much more in other pay.\n\nI'm a senior data scientist in the industry and I would be proud of that one.\n\nHere's the Github link. Feel free to fork or submit pull request. Even better, reach out to chat. I'm excited about this space and I love hearing new perspectives \ud83d\ude80.\n\nhttps://github.com/Rock-River-Research/babyds", "author_fullname": "t2_h2wdb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83c\udf7c\ud83d\udd2c BabyDS: An AI powered Data Analysis pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/LangChain", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pm84l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681746407.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.LangChain", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey friends, wanted to share a project I&amp;#39;ve been working on. It&amp;#39;s a langchain powered bot that performs data analysis and generates a report for a given objective. Just tell it what you want to achieve and point it to the dataset. Here&amp;#39;s an excerpt from a test run that aimed to find fraud in an NYC public salaries dataset.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Let&amp;#39;s start with the good news: the average base salary for public employees in New York City has been on the rise. In 2018, the average base salary was $45,508.538, and by 2022, it had increased to $48,426.018. That&amp;#39;s a modest increase, but it&amp;#39;s still a positive trend.&lt;/p&gt;\n\n&lt;p&gt;But when we look at the total other pay received by public employees, the numbers are truly staggering. In just ten fiscal years, the total other pay received by public employees in New York City has more than doubled. In 2014, the total other pay received was $1,149,076,637.61, and by 2022, it had increased to $2,740,086,013.70. That&amp;#39;s a substantial increase, and it raises some important questions about how and why public employees are receiving so much more in other pay.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I&amp;#39;m a senior data scientist in the industry and I would be proud of that one.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the Github link. Feel free to fork or submit pull request. Even better, reach out to chat. I&amp;#39;m excited about this space and I love hearing new perspectives \ud83d\ude80.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/Rock-River-Research/babyds\"&gt;https://github.com/Rock-River-Research/babyds&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?auto=webp&amp;v=enabled&amp;s=890c7665edd994b06145d3bcce9ae833fcfc7d8d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73332687450fc338d1ed5f86d649380296d0b116", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76ec659a6b49595dcb78d22dff18685437402a0a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29b6bb02742003e0f93d3a8afdc39785f2a4fa44", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7285466efd4137ce723058b7c31bcf30633c3a6c", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ef386fa026234a6fdf083af02f5f7ab17945534", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c47106f2b43df934aa7dfd07cbc223a6daf74a9d", "width": 1080, "height": 540}], "variants": {}, "id": "kT0QpawmiPiniWfD0W9Dp0QyjE4Bm0ME2FS14ZTJHOY"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 400, "id": "award_5b39e8fd-7a58-4cbe-8ca0-bdedd5ed1f5a", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Updoot_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Updoot_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Updoot_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Updoot_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Updoot_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Updoot_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Sometimes you just got to dance with the doots.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Doot \ud83c\udfb5 Doot", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/yk6z2t12m4451_DootDoot-Static.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=971a951a74a385f02109ff6be77af0bf09c7bcff", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/yk6z2t12m4451_DootDoot-Static.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=73bc67b915ac5aa05272a74b069f380749d9302a", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/yk6z2t12m4451_DootDoot-Static.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=649116c94079c35981700d92a3513bde4d3dbae1", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/yk6z2t12m4451_DootDoot-Static.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=1eb39f55f119268a9710b1dfab9e367a12ed816a", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/yk6z2t12m4451_DootDoot-Static.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=66928fa901b765bf436449feebb4ad830cddb890", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 512, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/yk6z2t12m4451_DootDoot-Static.png"}], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_7tpn6r", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12pm84l", "is_robot_indexable": true, "report_reasons": null, "author": "KyleDrogo", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/LangChain/comments/12pm84l/babyds_an_ai_powered_data_analysis_pipeline/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/LangChain/comments/12pm84l/babyds_an_ai_powered_data_analysis_pipeline/", "subreddit_subscribers": 860, "created_utc": 1681746407.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1681827377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.LangChain", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/LangChain/comments/12pm84l/babyds_an_ai_powered_data_analysis_pipeline/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?auto=webp&amp;v=enabled&amp;s=890c7665edd994b06145d3bcce9ae833fcfc7d8d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73332687450fc338d1ed5f86d649380296d0b116", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76ec659a6b49595dcb78d22dff18685437402a0a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29b6bb02742003e0f93d3a8afdc39785f2a4fa44", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7285466efd4137ce723058b7c31bcf30633c3a6c", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ef386fa026234a6fdf083af02f5f7ab17945534", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/kpZI4UNpok8ymPk1jmxbciSeLFRlEof_R51LlXX8ViE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c47106f2b43df934aa7dfd07cbc223a6daf74a9d", "width": 1080, "height": 540}], "variants": {}, "id": "kT0QpawmiPiniWfD0W9Dp0QyjE4Bm0ME2FS14ZTJHOY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qoi1i", "is_robot_indexable": true, "report_reasons": null, "author": "KyleDrogo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12pm84l", "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qoi1i/babyds_an_ai_powered_data_analysis_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/LangChain/comments/12pm84l/babyds_an_ai_powered_data_analysis_pipeline/", "subreddit_subscribers": 875532, "created_utc": 1681827377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys, I need some advice for my career in the data field. I have data analytics exp of around 1.5 years. Recently, I got laid off due to company restructuring, and I have been trying to find a data analyst job. After 2 months and 100 applications, I still do not get any offers.\n\nNow, it looks like I have a high chance of getting an offer soon, but it is an ETL developer role. My guess is that it does align with data engineering a little bit. My question is that should I take this position or should I continue to invest in data analytics roles as I feel like the role is very saturated in my country and I don't get many interviews. However, the company seems to be urgently needed for this role to be filled hence the demand. It is a 6-month renewable contract, but there is a chance for full-time promotion. If I take this job, is there a chance for me to pivot back to data analytics? I have some budget left for search for a few more months. I like both data analytics and data engineering, but I have very little exp on ETL and data engineering side of thing. Need advice. Thank you in advance!", "author_fullname": "t2_1vykgam4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I take this job offer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12qoh0u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681827321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I need some advice for my career in the data field. I have data analytics exp of around 1.5 years. Recently, I got laid off due to company restructuring, and I have been trying to find a data analyst job. After 2 months and 100 applications, I still do not get any offers.&lt;/p&gt;\n\n&lt;p&gt;Now, it looks like I have a high chance of getting an offer soon, but it is an ETL developer role. My guess is that it does align with data engineering a little bit. My question is that should I take this position or should I continue to invest in data analytics roles as I feel like the role is very saturated in my country and I don&amp;#39;t get many interviews. However, the company seems to be urgently needed for this role to be filled hence the demand. It is a 6-month renewable contract, but there is a chance for full-time promotion. If I take this job, is there a chance for me to pivot back to data analytics? I have some budget left for search for a few more months. I like both data analytics and data engineering, but I have very little exp on ETL and data engineering side of thing. Need advice. Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qoh0u", "is_robot_indexable": true, "report_reasons": null, "author": "sunskung", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qoh0u/should_i_take_this_job_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12qoh0u/should_i_take_this_job_offer/", "subreddit_subscribers": 875532, "created_utc": 1681827321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2ju6xn4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u202aFound this inspiring. Are there any current database systems that transform natural language queries into SQL?\u202c", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_12qo3hx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kOEbs7vYaLoap9AKdH0bQz3hs0qNffXXnwqhMfg2cxc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681826581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1chuzepdgnua1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1chuzepdgnua1.jpg?auto=webp&amp;v=enabled&amp;s=2bdca876fc559a0bf94a223bbc5720cbd74f17d7", "width": 750, "height": 868}, "resolutions": [{"url": "https://preview.redd.it/1chuzepdgnua1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d731759c06c0e6ca63fd711d55b56afb3b20bf11", "width": 108, "height": 124}, {"url": "https://preview.redd.it/1chuzepdgnua1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8423ada8ac05088220a5f361239466a1a3ce586", "width": 216, "height": 249}, {"url": "https://preview.redd.it/1chuzepdgnua1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba94b588f04fb27112f3dc886ca223e19511cfcf", "width": 320, "height": 370}, {"url": "https://preview.redd.it/1chuzepdgnua1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3e42f0e958bb960cb5e28f5f933535bf6f33641", "width": 640, "height": 740}], "variants": {}, "id": "oFgUzF6gGGU-L6uiYyWIQ-AKPSRuNwJyQdSMCTeTvGE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12qo3hx", "is_robot_indexable": true, "report_reasons": null, "author": "Jebertian", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12qo3hx/found_this_inspiring_are_there_any_current/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1chuzepdgnua1.jpg", "subreddit_subscribers": 875532, "created_utc": 1681826581.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}