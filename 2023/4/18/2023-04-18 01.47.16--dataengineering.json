{"kind": "Listing", "data": {"after": "t3_12ph6g0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are building a collection of 20-30 ETL pipelines in Databricks foillowing the medallion architecture. These are each run in a Test and Prod environment.\n\nThe question we face now is whether to build a mono-repo with a strong folder structure, or build multi-repo with a repo per ETL pipeline.\n\nAs I see it\n\nMono-repo advantages:\n\n* Easier to manage all code in one place instead of separately configuring/cloning individual repos\n* Potential for code sharing/reuse\n\nMulti-repo advantages:\n\n* Easier to release individual pipelines to prod without having to release the entire repo\n* Cleaner separation of dependencies\n\nWhat is the conventional wisdom here?", "author_fullname": "t2_752zkmkm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mono-repo or multi-repo for collection of ETL pipelines in Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12p1uoq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681705420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are building a collection of 20-30 ETL pipelines in Databricks foillowing the medallion architecture. These are each run in a Test and Prod environment.&lt;/p&gt;\n\n&lt;p&gt;The question we face now is whether to build a mono-repo with a strong folder structure, or build multi-repo with a repo per ETL pipeline.&lt;/p&gt;\n\n&lt;p&gt;As I see it&lt;/p&gt;\n\n&lt;p&gt;Mono-repo advantages:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Easier to manage all code in one place instead of separately configuring/cloning individual repos&lt;/li&gt;\n&lt;li&gt;Potential for code sharing/reuse&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Multi-repo advantages:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Easier to release individual pipelines to prod without having to release the entire repo&lt;/li&gt;\n&lt;li&gt;Cleaner separation of dependencies&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What is the conventional wisdom here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12p1uoq", "is_robot_indexable": true, "report_reasons": null, "author": "brennybrennybrenbren", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12p1uoq/monorepo_or_multirepo_for_collection_of_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12p1uoq/monorepo_or_multirepo_for_collection_of_etl/", "subreddit_subscribers": 100089, "created_utc": 1681705420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently a DE and interested in building a basic working knowledge of machine learning/data science. I don't plan to make a switch to a DS role but see value in adding a basic working knowledge to my skill set.\n\nWhat are some good free/paid resources for this?\n\nThanks!", "author_fullname": "t2_2vuapfhl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for Current DE Interested in Learning Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pd2hk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681732098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a DE and interested in building a basic working knowledge of machine learning/data science. I don&amp;#39;t plan to make a switch to a DS role but see value in adding a basic working knowledge to my skill set.&lt;/p&gt;\n\n&lt;p&gt;What are some good free/paid resources for this?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12pd2hk", "is_robot_indexable": true, "report_reasons": null, "author": "TheShitStorms92", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pd2hk/resources_for_current_de_interested_in_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pd2hk/resources_for_current_de_interested_in_learning/", "subreddit_subscribers": 100089, "created_utc": 1681732098.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any use case where we would want to implement multiprocessing or multithreading within an Airflow DAG? If there is such a use case, why can't we simply instantiate a different task instance under the same DAG which runs in parallel? Does this choice also depend on the type of executor you are running Airflow on?\n\nI am asking because I see a lot of multiprocessing logic written in many airflow DAGs in my company (the task logic splits, say, N items among, say, K processes, and then each subprocess processes N/K data items) and I have never understood why it was implemented in the first place. We use the Kubernetes ~~operator~~ executor at our company and the CPU and memory requirements to execute the DAG (with just one task with multiprocessing implemented) are huge. Since only one task is executed, I am assuming the task gets executed on one node/instance with those huge requirements (I have limited knowledge of Kubernetes). My point is why can't we instantiate different task instances and let them run on smaller instances?\n\nOne reason that comes to my mind is that it makes the DAG script cleaner and assigns all the responsibility of splitting the data items to one task. But I am not able to think of anything else apart from this reason.\n\nIt would be great if someone can help me understand this. Thanks for reading.\n\nEDIT: Corrected operator to executor (please see the striked out word).", "author_fullname": "t2_uqx8q0b4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multiprocessing/multithreading in an Airflow DAG", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pc16r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681735088.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681729762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any use case where we would want to implement multiprocessing or multithreading within an Airflow DAG? If there is such a use case, why can&amp;#39;t we simply instantiate a different task instance under the same DAG which runs in parallel? Does this choice also depend on the type of executor you are running Airflow on?&lt;/p&gt;\n\n&lt;p&gt;I am asking because I see a lot of multiprocessing logic written in many airflow DAGs in my company (the task logic splits, say, N items among, say, K processes, and then each subprocess processes N/K data items) and I have never understood why it was implemented in the first place. We use the Kubernetes &lt;del&gt;operator&lt;/del&gt; executor at our company and the CPU and memory requirements to execute the DAG (with just one task with multiprocessing implemented) are huge. Since only one task is executed, I am assuming the task gets executed on one node/instance with those huge requirements (I have limited knowledge of Kubernetes). My point is why can&amp;#39;t we instantiate different task instances and let them run on smaller instances?&lt;/p&gt;\n\n&lt;p&gt;One reason that comes to my mind is that it makes the DAG script cleaner and assigns all the responsibility of splitting the data items to one task. But I am not able to think of anything else apart from this reason.&lt;/p&gt;\n\n&lt;p&gt;It would be great if someone can help me understand this. Thanks for reading.&lt;/p&gt;\n\n&lt;p&gt;EDIT: Corrected operator to executor (please see the striked out word).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12pc16r", "is_robot_indexable": true, "report_reasons": null, "author": "the-fake-me", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pc16r/multiprocessingmultithreading_in_an_airflow_dag/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pc16r/multiprocessingmultithreading_in_an_airflow_dag/", "subreddit_subscribers": 100089, "created_utc": 1681729762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My new org is entirely MS/Azure based, and I am pretty much a data team of one. They have no real data warehouse to speak of, just a few MS applications in the cloud and PowerBI. \n\nData volume is quite small (we have around 10k orders per year) and unlikely to grow significantly for at least a couple of years. Beyond Dynamics we have the normal suspects, socials, Google analytics and third party APIs.\n\nAny suggestions for a good solution for a DWH? Budget is tight so I would like to use meltano to dump raw data into the DWH and DBT core to build some gold level tables to serve into PowerBI.\n\nWould a simple MSSQL database do it? Or would a entry tier Synapse instance be a better place to start? Or perhaps even Snowflake?\n\nAny experiences very welcome.", "author_fullname": "t2_clh5r1ln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for a small DWH on Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pwc42", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681764699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My new org is entirely MS/Azure based, and I am pretty much a data team of one. They have no real data warehouse to speak of, just a few MS applications in the cloud and PowerBI. &lt;/p&gt;\n\n&lt;p&gt;Data volume is quite small (we have around 10k orders per year) and unlikely to grow significantly for at least a couple of years. Beyond Dynamics we have the normal suspects, socials, Google analytics and third party APIs.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for a good solution for a DWH? Budget is tight so I would like to use meltano to dump raw data into the DWH and DBT core to build some gold level tables to serve into PowerBI.&lt;/p&gt;\n\n&lt;p&gt;Would a simple MSSQL database do it? Or would a entry tier Synapse instance be a better place to start? Or perhaps even Snowflake?&lt;/p&gt;\n\n&lt;p&gt;Any experiences very welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12pwc42", "is_robot_indexable": true, "report_reasons": null, "author": "Far-Restaurant-9691", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pwc42/recommendations_for_a_small_dwh_on_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pwc42/recommendations_for_a_small_dwh_on_azure/", "subreddit_subscribers": 100089, "created_utc": 1681764699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, I\u00b4m currently interested in pursuing a master's degree around related to data engineering and analytics. I'd prefer an online program since I'd rather not wreck my bank account and destabilize my family life at the moment. Do you have any experience, recommendations or warnings towards any specific programs? I'm a Latin-American and know there are certain institutions that provide some sort of support, scholarships and/or related programs to fulfil a certain quota and, well, I wouldn't like to waste any opportunity at reach.\n\nThank you!", "author_fullname": "t2_wah5l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering and analytics Masters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12plhfd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681745436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I\u00b4m currently interested in pursuing a master&amp;#39;s degree around related to data engineering and analytics. I&amp;#39;d prefer an online program since I&amp;#39;d rather not wreck my bank account and destabilize my family life at the moment. Do you have any experience, recommendations or warnings towards any specific programs? I&amp;#39;m a Latin-American and know there are certain institutions that provide some sort of support, scholarships and/or related programs to fulfil a certain quota and, well, I wouldn&amp;#39;t like to waste any opportunity at reach.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12plhfd", "is_robot_indexable": true, "report_reasons": null, "author": "reborndu", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12plhfd/data_engineering_and_analytics_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12plhfd/data_engineering_and_analytics_masters/", "subreddit_subscribers": 100089, "created_utc": 1681745436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings,\n\nI'm a DE currently working on a project to set up a data lake architecture. My job is to create data pipelines using AWS Step Functions, Lambda functions, Glue jobs, and SQS for error notification. I'm facing a challenge of coding an extractor process using PySpark on Glue that can be reusable for different data sources.\n\nI initially tried using the ***spark.read.format(\"jdbc\").options*** method, which worked well, but it also meant setting up configuration files and jar files for each data source and apply some logic to fetch them.Then, I looked into using ***create\\_dynamic\\_frame\\_from\\_catalog*** or  ***create\\_dynamic\\_frame\\_from\\_options*** to let Glue manage the connections, and only pass the database and table as parameters. However, I couldn't filter the data before extraction since the source tables are not partitioned, so I couldn't use ***push\\_down\\_predicate*** either.\n\nShould I go back to the first approach?If anyone has experience with this kind of issue or suggestions on how to approach it, I would appreciate your help. Thank you!", "author_fullname": "t2_dpj60sgl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best approach for extracting data of a JDBC for a given date on Pyspark/AWS Glue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pj52l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1681742915.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681742540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a DE currently working on a project to set up a data lake architecture. My job is to create data pipelines using AWS Step Functions, Lambda functions, Glue jobs, and SQS for error notification. I&amp;#39;m facing a challenge of coding an extractor process using PySpark on Glue that can be reusable for different data sources.&lt;/p&gt;\n\n&lt;p&gt;I initially tried using the &lt;strong&gt;&lt;em&gt;spark.read.format(&amp;quot;jdbc&amp;quot;).options&lt;/em&gt;&lt;/strong&gt; method, which worked well, but it also meant setting up configuration files and jar files for each data source and apply some logic to fetch them.Then, I looked into using &lt;strong&gt;&lt;em&gt;create_dynamic_frame_from_catalog&lt;/em&gt;&lt;/strong&gt; or  &lt;strong&gt;&lt;em&gt;create_dynamic_frame_from_options&lt;/em&gt;&lt;/strong&gt; to let Glue manage the connections, and only pass the database and table as parameters. However, I couldn&amp;#39;t filter the data before extraction since the source tables are not partitioned, so I couldn&amp;#39;t use &lt;strong&gt;&lt;em&gt;push_down_predicate&lt;/em&gt;&lt;/strong&gt; either.&lt;/p&gt;\n\n&lt;p&gt;Should I go back to the first approach?If anyone has experience with this kind of issue or suggestions on how to approach it, I would appreciate your help. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12pj52l", "is_robot_indexable": true, "report_reasons": null, "author": "_unwin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pj52l/best_approach_for_extracting_data_of_a_jdbc_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pj52l/best_approach_for_extracting_data_of_a_jdbc_for_a/", "subreddit_subscribers": 100089, "created_utc": 1681742540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys,\n\n&amp;#x200B;\n\nI am trying to create some personal projects for my portofolio using stuff that I learned  &amp; used so far at my job like: API development, SQL, Postgres DB, Airflow, Terraform, data modelling, etc.\n\nI want to test and have those deployed somehow so they can be shown / tested (not mandatory, if there can be other ways) by others. The thing is I saw that most providers like GCP, Heroku only have trials / limited resources to use them for free. Considering that, what approaches i should think of or how do you proceed in this kind of situations where you really want to put your knowledge in some practical work and build a start-to-end processes? Any advice would help. \n\nThanks!", "author_fullname": "t2_b4ypm8ew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tools / Providers to develop personal running projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12paiuj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681726166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am trying to create some personal projects for my portofolio using stuff that I learned  &amp;amp; used so far at my job like: API development, SQL, Postgres DB, Airflow, Terraform, data modelling, etc.&lt;/p&gt;\n\n&lt;p&gt;I want to test and have those deployed somehow so they can be shown / tested (not mandatory, if there can be other ways) by others. The thing is I saw that most providers like GCP, Heroku only have trials / limited resources to use them for free. Considering that, what approaches i should think of or how do you proceed in this kind of situations where you really want to put your knowledge in some practical work and build a start-to-end processes? Any advice would help. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12paiuj", "is_robot_indexable": true, "report_reasons": null, "author": "Koxinfster", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12paiuj/tools_providers_to_develop_personal_running/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12paiuj/tools_providers_to_develop_personal_running/", "subreddit_subscribers": 100089, "created_utc": 1681726166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! I work on a very small Data team and have spent the last few months setting up a warehouse environment using Fivetran, dbt, and Snowflake. I'm very happy with these tools, and we're already seeing returns on them. Currently I just have a free account on dbt Cloud that is just running 'dbt run all' every night. I'm looking at setting up Dagster or something similar to handle the orchestration. On paper, it seems like it would integrate with everything and give me one place to handle all of these tools and catch errors, but I'm worried that it's unnecessary complexity at this point. We're not running ML models or anything like that at this point, just building data sources that feed BI tools. I am also looking for a way to generate dbt docs that our team can easily view and I think an orchestrator would help with that although we'd have to host them somewhere.\n\nI would appreciate anyone's thoughts on this if anyone has been in a similar situation. Thanks!", "author_fullname": "t2_7ljys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is an orchestrator like Dagster overkill?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pm6g0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681746347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I work on a very small Data team and have spent the last few months setting up a warehouse environment using Fivetran, dbt, and Snowflake. I&amp;#39;m very happy with these tools, and we&amp;#39;re already seeing returns on them. Currently I just have a free account on dbt Cloud that is just running &amp;#39;dbt run all&amp;#39; every night. I&amp;#39;m looking at setting up Dagster or something similar to handle the orchestration. On paper, it seems like it would integrate with everything and give me one place to handle all of these tools and catch errors, but I&amp;#39;m worried that it&amp;#39;s unnecessary complexity at this point. We&amp;#39;re not running ML models or anything like that at this point, just building data sources that feed BI tools. I am also looking for a way to generate dbt docs that our team can easily view and I think an orchestrator would help with that although we&amp;#39;d have to host them somewhere.&lt;/p&gt;\n\n&lt;p&gt;I would appreciate anyone&amp;#39;s thoughts on this if anyone has been in a similar situation. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12pm6g0", "is_robot_indexable": true, "report_reasons": null, "author": "tydor73", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pm6g0/is_an_orchestrator_like_dagster_overkill/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pm6g0/is_an_orchestrator_like_dagster_overkill/", "subreddit_subscribers": 100089, "created_utc": 1681746347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for a solution for bi-directional, continuous replication of data between Snowflake tables &amp; Databricks.\n\nSo far, I've found some SaaS solutions like CData &amp; Qlik which seem like they'd fit the bill.  I wanted to get some buy-in from you fine folks to see if you have faced the same requirement, if there were any build-vs-buy discussions, and the solution(s) you ultimately went with.", "author_fullname": "t2_u5xaz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solution for Continuous, bi-directional Data Replication between Snowflake &amp; Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12piwdp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681742263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a solution for bi-directional, continuous replication of data between Snowflake tables &amp;amp; Databricks.&lt;/p&gt;\n\n&lt;p&gt;So far, I&amp;#39;ve found some SaaS solutions like CData &amp;amp; Qlik which seem like they&amp;#39;d fit the bill.  I wanted to get some buy-in from you fine folks to see if you have faced the same requirement, if there were any build-vs-buy discussions, and the solution(s) you ultimately went with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12piwdp", "is_robot_indexable": true, "report_reasons": null, "author": "trevcatdangerous", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12piwdp/solution_for_continuous_bidirectional_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12piwdp/solution_for_continuous_bidirectional_data/", "subreddit_subscribers": 100089, "created_utc": 1681742263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "25F with 2.5yoe as a software developer on a data services team at a mid-size (old)fintech company and I\u2019m not sure what I want to do next.. \n\nMy official title is software developer but everyone on my team is considered a data engineer where we focus on ingesting &amp; migrating data to AWS &amp; Snowflake. I have experience migrating data, ETL stuff in AWS, creating reports, views, external tables, data mapping, pipelines, etc etc \n\nI feel confident in my AWS experience bc I use it constantly, I\u2019m also familiar with Quicksight, Elasticsearch, SQL Server, and in the last year we\u2019re using Snowflake as well which has been the main thing I\u2019ve been working.. \n\nI like what I do a lot but I\u2019m also not an expert at SQL nor Python yet (I consider myself mid in both languages) which stresses me out.. I\u2019m always hopping between all these tasks I find it hard to really increase my skill level significantly. Also, was definitely low balled with my current job but I just graduated college during spring 2020 and all of my peers had lost their jobs before they even started so I took my chances and grabbed the first job I got. \n\nI definitely prefer data engineering over regular swe work and I want to stay doing the same stuff but I\u2019m also curious about cloud engineering or devops? How would that overlap my current skill set? Is it worth switching from de? \n\nAlso if I want to get a real de job what should I do to get there and what\u2019s the most helpful cert I should get?", "author_fullname": "t2_w5gmp3et", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do I go from here??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12p165q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681703988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;25F with 2.5yoe as a software developer on a data services team at a mid-size (old)fintech company and I\u2019m not sure what I want to do next.. &lt;/p&gt;\n\n&lt;p&gt;My official title is software developer but everyone on my team is considered a data engineer where we focus on ingesting &amp;amp; migrating data to AWS &amp;amp; Snowflake. I have experience migrating data, ETL stuff in AWS, creating reports, views, external tables, data mapping, pipelines, etc etc &lt;/p&gt;\n\n&lt;p&gt;I feel confident in my AWS experience bc I use it constantly, I\u2019m also familiar with Quicksight, Elasticsearch, SQL Server, and in the last year we\u2019re using Snowflake as well which has been the main thing I\u2019ve been working.. &lt;/p&gt;\n\n&lt;p&gt;I like what I do a lot but I\u2019m also not an expert at SQL nor Python yet (I consider myself mid in both languages) which stresses me out.. I\u2019m always hopping between all these tasks I find it hard to really increase my skill level significantly. Also, was definitely low balled with my current job but I just graduated college during spring 2020 and all of my peers had lost their jobs before they even started so I took my chances and grabbed the first job I got. &lt;/p&gt;\n\n&lt;p&gt;I definitely prefer data engineering over regular swe work and I want to stay doing the same stuff but I\u2019m also curious about cloud engineering or devops? How would that overlap my current skill set? Is it worth switching from de? &lt;/p&gt;\n\n&lt;p&gt;Also if I want to get a real de job what should I do to get there and what\u2019s the most helpful cert I should get?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12p165q", "is_robot_indexable": true, "report_reasons": null, "author": "ColonelSmashburger", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12p165q/where_do_i_go_from_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12p165q/where_do_i_go_from_here/", "subreddit_subscribers": 100089, "created_utc": 1681703988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am developing an app that will store that json that represents the state of an object, it will also record modifications made to that object -- think of it as an accounting ledger. It will be write heavy, but I would like to be able to read from it in a reasonable time. I think queries will use two - three columns for filtering\n\nThinking in terms of db columns, id need:\n\n    id &lt;uuid&gt;\n    type &lt;string&gt; -- the thing that was modified. user, location, noun, etc. I will need to be able to filter on this\n    type_id &lt;uuid&gt; -- luckily we use uuid everywhere. I will need to be able to filter on this\n    change &lt;string&gt; -- formatted json representing the modifications. I will not need to search in this (would be nice to in the future maybe)\n    timestamp &lt;time&gt; -- time that the modification happened. I will need to do some bounding based on this.\n\nI figured this would be simple as a single table that supported multiple types. \n\nMy original plan was a Postgres db, tune it as necessary and worry about it when I need to worry about it. Now im wondering if there are better solutions for what I want to do \n\nThanks", "author_fullname": "t2_c2o44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendation on potential storage for a changeling-type app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ppqcy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681752179.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am developing an app that will store that json that represents the state of an object, it will also record modifications made to that object -- think of it as an accounting ledger. It will be write heavy, but I would like to be able to read from it in a reasonable time. I think queries will use two - three columns for filtering&lt;/p&gt;\n\n&lt;p&gt;Thinking in terms of db columns, id need:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;id &amp;lt;uuid&amp;gt;\ntype &amp;lt;string&amp;gt; -- the thing that was modified. user, location, noun, etc. I will need to be able to filter on this\ntype_id &amp;lt;uuid&amp;gt; -- luckily we use uuid everywhere. I will need to be able to filter on this\nchange &amp;lt;string&amp;gt; -- formatted json representing the modifications. I will not need to search in this (would be nice to in the future maybe)\ntimestamp &amp;lt;time&amp;gt; -- time that the modification happened. I will need to do some bounding based on this.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I figured this would be simple as a single table that supported multiple types. &lt;/p&gt;\n\n&lt;p&gt;My original plan was a Postgres db, tune it as necessary and worry about it when I need to worry about it. Now im wondering if there are better solutions for what I want to do &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12ppqcy", "is_robot_indexable": true, "report_reasons": null, "author": "needed_an_account", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ppqcy/recommendation_on_potential_storage_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ppqcy/recommendation_on_potential_storage_for_a/", "subreddit_subscribers": 100089, "created_utc": 1681752179.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks!\n\nI started a newsletter called Simetrique about Data Engineering and Analytics Engineering. I am trying to make it not about latest news and trends (however it's impossible to avoid), but rather to write about topics that are interesting to myself. For example, interesting tools, approaches or articles. Also, sometimes I'm going to write about my personal experience with data and analytics.\n\nI'm currently an Analytics Engineer, and held a lot of analytical titles (such as data analyst, BI engineer and even a head of BI) for the past 10 year. So the data is my passion, especially its engineering part.\n\nFirst 4 issues are already published so you can go and check the type of content I'm going to post. Planning to make about 1 newsletter a week, so not going to spam you.\n\n[https://simetrique.substack.com/](https://simetrique.substack.com/)", "author_fullname": "t2_4679pe1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I started a newsletter about DE and AE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pyojl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681768904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks!&lt;/p&gt;\n\n&lt;p&gt;I started a newsletter called Simetrique about Data Engineering and Analytics Engineering. I am trying to make it not about latest news and trends (however it&amp;#39;s impossible to avoid), but rather to write about topics that are interesting to myself. For example, interesting tools, approaches or articles. Also, sometimes I&amp;#39;m going to write about my personal experience with data and analytics.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently an Analytics Engineer, and held a lot of analytical titles (such as data analyst, BI engineer and even a head of BI) for the past 10 year. So the data is my passion, especially its engineering part.&lt;/p&gt;\n\n&lt;p&gt;First 4 issues are already published so you can go and check the type of content I&amp;#39;m going to post. Planning to make about 1 newsletter a week, so not going to spam you.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://simetrique.substack.com/\"&gt;https://simetrique.substack.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AC0LWTaobZ0ozdKWOeI1XsHzyDYe9xbHmEp5oF2YNEU.jpg?auto=webp&amp;v=enabled&amp;s=eb7bdadcab12495fa1b1d88da290fa1a6840f15c", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/AC0LWTaobZ0ozdKWOeI1XsHzyDYe9xbHmEp5oF2YNEU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc3907b05bab8847a3f7f3c88ba9b13bcad063d5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/AC0LWTaobZ0ozdKWOeI1XsHzyDYe9xbHmEp5oF2YNEU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=239d599db4fd3341980de2498027e7f38769095f", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/AC0LWTaobZ0ozdKWOeI1XsHzyDYe9xbHmEp5oF2YNEU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e76eb1c53656e1b9161d28d095c21cbb2f89012", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/AC0LWTaobZ0ozdKWOeI1XsHzyDYe9xbHmEp5oF2YNEU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6edc9bfaa20abf1d71ef7ddf516df53075da38a8", "width": 640, "height": 333}], "variants": {}, "id": "h-2msyp46eyAeZx54uovglwbzRki6DsxoUVoQUBZbGk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12pyojl", "is_robot_indexable": true, "report_reasons": null, "author": "oleg_agapov", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pyojl/i_started_a_newsletter_about_de_and_ae/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pyojl/i_started_a_newsletter_about_de_and_ae/", "subreddit_subscribers": 100089, "created_utc": 1681768904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We store the queries that create tableau extracts in Github - we have a different folder for each query. \n\nI have started creating a subdirectory in the folder called tests where I put validation tests testing things like - the max\\_date year for this id should be no bigger than 2020. Or a report like \"10% of items are null\" for this result. \n\nThe problem is that these queries cannot run as is because they depend on the extract query and sql does not have file imports for instance. additionally it would be cool to run it as a test suite where I can determine if all 10 tests pass for instance after each change. Finally, the query sometimes takes a long time to run and I wish there was a way to use a temporary table. \n\nIm thinking of creating a python script to basically run this query and create a temporary table and then run each query as a test and output the results in a readable way. But is there something out there like this that I can just use? I know about dbt tests but I think its overkill just for each new tableau data source .", "author_fullname": "t2_b3n9i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool Recommendation for testing queries in a file?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ptpdx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681759687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We store the queries that create tableau extracts in Github - we have a different folder for each query. &lt;/p&gt;\n\n&lt;p&gt;I have started creating a subdirectory in the folder called tests where I put validation tests testing things like - the max_date year for this id should be no bigger than 2020. Or a report like &amp;quot;10% of items are null&amp;quot; for this result. &lt;/p&gt;\n\n&lt;p&gt;The problem is that these queries cannot run as is because they depend on the extract query and sql does not have file imports for instance. additionally it would be cool to run it as a test suite where I can determine if all 10 tests pass for instance after each change. Finally, the query sometimes takes a long time to run and I wish there was a way to use a temporary table. &lt;/p&gt;\n\n&lt;p&gt;Im thinking of creating a python script to basically run this query and create a temporary table and then run each query as a test and output the results in a readable way. But is there something out there like this that I can just use? I know about dbt tests but I think its overkill just for each new tableau data source .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12ptpdx", "is_robot_indexable": true, "report_reasons": null, "author": "third_dude", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ptpdx/tool_recommendation_for_testing_queries_in_a_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ptpdx/tool_recommendation_for_testing_queries_in_a_file/", "subreddit_subscribers": 100089, "created_utc": 1681759687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/gastromatic/synchronizing-data-using-memphis-dev-a-case-study-2e6e9a7b5512](https://medium.com/gastromatic/synchronizing-data-using-memphis-dev-a-case-study-2e6e9a7b5512)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synchronizing data using a new message broker: A case study.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12plo5v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681745684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/gastromatic/synchronizing-data-using-memphis-dev-a-case-study-2e6e9a7b5512\"&gt;https://medium.com/gastromatic/synchronizing-data-using-memphis-dev-a-case-study-2e6e9a7b5512&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?auto=webp&amp;v=enabled&amp;s=e0dcf65745f8f81ca40c6232048eba40042bbf0a", "width": 1200, "height": 685}, "resolutions": [{"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5dd2916bdbf4df71087bc2fd4a81cfe569b85627", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c4e2e0bee9f7fe0ef25a3c7c898f283313a17d4", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b0c1d8204e15115c3870303acdc8ce061c110c1e", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55b7a318d94772320df353222cbe01861bf19c33", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10b85f5b8d4c343988c05c7fa7c79f5c754af917", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/8Gj87tbeVCk9Y6gv1XrD2JCIhSQPYF-TiAufDrQjRpo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1183da065c5cf2cc73a5ff0fe7fe2e74be20a4a", "width": 1080, "height": 616}], "variants": {}, "id": "a2iUTeqWmkO2QfQFQh8Uti-nGge_UVR1rRhDsRSJ5sk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12plo5v", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12plo5v/synchronizing_data_using_a_new_message_broker_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12plo5v/synchronizing_data_using_a_new_message_broker_a/", "subreddit_subscribers": 100089, "created_utc": 1681745684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, what's the best way to build streaming pipeline for video and audio files in gcp?\nThese files came via api for now. I want to move these files continuously to cloud storage. size of one file ranges from kb to mb.\nHas anyone ever done something similar to this. Pls help.", "author_fullname": "t2_vkmvzdm7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Video streaming pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pgl8v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681739264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, what&amp;#39;s the best way to build streaming pipeline for video and audio files in gcp?\nThese files came via api for now. I want to move these files continuously to cloud storage. size of one file ranges from kb to mb.\nHas anyone ever done something similar to this. Pls help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12pgl8v", "is_robot_indexable": true, "report_reasons": null, "author": "shaikh21", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pgl8v/video_streaming_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pgl8v/video_streaming_pipeline/", "subreddit_subscribers": 100089, "created_utc": 1681739264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been studying to land a data analyst role for a while, but an opportunity came up for this. The requirements included SQL and Tableau, which I\u2019m comfortable with\u2026so I decided to try my luck and apply. \n\nHowever, there\u2019s also a requirement for Linux and Hadoop or something similar, and I\u2019m a bit familiar with snowflake \n\nMy issue is, my knowledge on Linux is basic. What do I need to know about Linux to be able to do this interview? \n\nThanks in advance", "author_fullname": "t2_4o6zw556", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I got an interview for \u201cData Platform Engineer\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12paw9r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681727090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been studying to land a data analyst role for a while, but an opportunity came up for this. The requirements included SQL and Tableau, which I\u2019m comfortable with\u2026so I decided to try my luck and apply. &lt;/p&gt;\n\n&lt;p&gt;However, there\u2019s also a requirement for Linux and Hadoop or something similar, and I\u2019m a bit familiar with snowflake &lt;/p&gt;\n\n&lt;p&gt;My issue is, my knowledge on Linux is basic. What do I need to know about Linux to be able to do this interview? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12paw9r", "is_robot_indexable": true, "report_reasons": null, "author": "sshala061", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12paw9r/i_got_an_interview_for_data_platform_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12paw9r/i_got_an_interview_for_data_platform_engineer/", "subreddit_subscribers": 100089, "created_utc": 1681727090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am new to prefect and was wondering if there is any way to configure all parameters (including any custom parameters required for business logic) of a flow and it's task(s). I know we can achieve this by manually creating yaml and parsing it into dicts but is there a specific way to do it in prefect?\n\nAlso I configured the local project by linking it to prefect cloud workspace. So whenever I don't have interest connection it doesn't work, is there any workaround for that?", "author_fullname": "t2_k67gy2o3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Configuring prefect using yaml", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12p3kv9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681709348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am new to prefect and was wondering if there is any way to configure all parameters (including any custom parameters required for business logic) of a flow and it&amp;#39;s task(s). I know we can achieve this by manually creating yaml and parsing it into dicts but is there a specific way to do it in prefect?&lt;/p&gt;\n\n&lt;p&gt;Also I configured the local project by linking it to prefect cloud workspace. So whenever I don&amp;#39;t have interest connection it doesn&amp;#39;t work, is there any workaround for that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12p3kv9", "is_robot_indexable": true, "report_reasons": null, "author": "JackSparrow-_-", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12p3kv9/configuring_prefect_using_yaml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12p3kv9/configuring_prefect_using_yaml/", "subreddit_subscribers": 100089, "created_utc": 1681709348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHey /r/dataengineering!\n\nRecently retired as a data scientist/engineer.  I figured i ought to at least try to give back to the opensource community.  I've created a Docker app to help data scientists build data projects with pipelines in mind \\*from the start\\*, rather than as Jupyter notebook afterthoughts:\n\n[**https://github.com/jason-brian-anderson/pipeline\\_gen**](https://github.com/jason-brian-anderson/pipeline_gen)\n\nI suspect I wasn't the only one with no clue about good pipeline design principles.  I customized the base Airflow docker-compose to run data pipelines and on a dedicated GPU pytorch container. The repo is a git template, and was hoping ot might be useful to others beyond just my personal projects.\n\nI'd love to hear your thoughts. is it a good thing to encourage the data  science community to develop from the start with pipelines in mind?", "author_fullname": "t2_9g8u21p9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pipeline_gen: a project for simplified data pipeline design targeted at promoting good pipeline design principles among data scientists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12q1ph9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681774539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/dataengineering\"&gt;/r/dataengineering&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;Recently retired as a data scientist/engineer.  I figured i ought to at least try to give back to the opensource community.  I&amp;#39;ve created a Docker app to help data scientists build data projects with pipelines in mind *from the start*, rather than as Jupyter notebook afterthoughts:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/jason-brian-anderson/pipeline_gen\"&gt;&lt;strong&gt;https://github.com/jason-brian-anderson/pipeline_gen&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I suspect I wasn&amp;#39;t the only one with no clue about good pipeline design principles.  I customized the base Airflow docker-compose to run data pipelines and on a dedicated GPU pytorch container. The repo is a git template, and was hoping ot might be useful to others beyond just my personal projects.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear your thoughts. is it a good thing to encourage the data  science community to develop from the start with pipelines in mind?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?auto=webp&amp;v=enabled&amp;s=c1c932cebe7ad6b7da6c3a8ac758b4c015430ecf", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c2796740d1577705d18ae732340ace1a8c9df09", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8958047e87ccd35586585709ff12371974101434", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80c63f6455dc4248592a3c23198d64640ea66dc4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53a58b1646243881e0d699983def42c4fa03a4f8", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c3b8887f6642e7774c502dbcb2e23d19f6fa96e", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/qKizHP8ZahfJgXgg0AxjnWykExz_j3sOgNj78AiuO00.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5047f210faead4fc8e96855a837e4d910a6cd89e", "width": 1080, "height": 540}], "variants": {}, "id": "i_Png3iGB-feerTRQyTJZMNWOeqXHZunl3kMQORqODs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "12q1ph9", "is_robot_indexable": true, "report_reasons": null, "author": "airflowy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12q1ph9/pipeline_gen_a_project_for_simplified_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12q1ph9/pipeline_gen_a_project_for_simplified_data/", "subreddit_subscribers": 100089, "created_utc": 1681774539.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What was the most challenging or the weirdest unstructured data preparation you've ever performed? What did you use for parsing/cleansing?", "author_fullname": "t2_1z5jdh5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The most challenging data preparation/ingestion of unstructured data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pxyjy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681767619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What was the most challenging or the weirdest unstructured data preparation you&amp;#39;ve ever performed? What did you use for parsing/cleansing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12pxyjy", "is_robot_indexable": true, "report_reasons": null, "author": "Greg_Z_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pxyjy/the_most_challenging_data_preparationingestion_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pxyjy/the_most_challenging_data_preparationingestion_of/", "subreddit_subscribers": 100089, "created_utc": 1681767619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_81yu8ev", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Webinar - Running dbt core on Airflow in production - learnings from 2 years of battle scars", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_12pqntp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/v2cUNUuhL7O_rZWmg5pE4fJiGn_4K5TFCgXNw08wn-w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681753949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "operationalanalytics.club", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.operationalanalytics.club/events/running-dbt-core-on-airflow-in-production-learnings-from-2-years-of-battle-scars?ref=35499551", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?auto=webp&amp;v=enabled&amp;s=4ddf4c74086580fd6f7c3abe03787341c335f48e", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b0a737b3456b0c9617b5e5296ab4ad103d2a37d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8cc5bde8c1647cafccb5622c81f13dc182ba64b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1539678836218a354e83b3e6a78d14dbca0b811", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb38b9569dba052d500a37f287d47bea38aea21f", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2ffe9efaf51575ddd7e55625ff43de6f303d244", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/-5BBXhg-IdWkcKReEbkNtJFYlkG3hoBP7R-o9hg9c1A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98a8ddb78fafa82694c74c46f1afdbe6b8eeb72b", "width": 1080, "height": 565}], "variants": {}, "id": "zFQ3N50ROx6yVa7lCSV-VqnE2EVJ8YES1JgT95yllIU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12pqntp", "is_robot_indexable": true, "report_reasons": null, "author": "parzival1984", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pqntp/webinar_running_dbt_core_on_airflow_in_production/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.operationalanalytics.club/events/running-dbt-core-on-airflow-in-production-learnings-from-2-years-of-battle-scars?ref=35499551", "subreddit_subscribers": 100089, "created_utc": 1681753949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey first blog post for me, feeback appreciated: \n\n[https://dev.to/kumo/enable-https-only-on-your-s3-buckets-36eg](https://dev.to/kumo/enable-https-only-on-your-s3-buckets-36eg)", "author_fullname": "t2_55debeh5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Encrypt requests to S3 storage [AWS] [S3]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12p5w0v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681714787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey first blog post for me, feeback appreciated: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://dev.to/kumo/enable-https-only-on-your-s3-buckets-36eg\"&gt;https://dev.to/kumo/enable-https-only-on-your-s3-buckets-36eg&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GDvy1QTJ-7iDp2NA2ITTnsGKaaK-4ooAO6E8s9l3qD8.jpg?auto=webp&amp;v=enabled&amp;s=8176da62bbea1f51dc8dc8972967b43b7703c45a", "width": 1000, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/GDvy1QTJ-7iDp2NA2ITTnsGKaaK-4ooAO6E8s9l3qD8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f541faf5f6836dc91a853c260b924d028dd36586", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/GDvy1QTJ-7iDp2NA2ITTnsGKaaK-4ooAO6E8s9l3qD8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24d92fa36d1cf8c16feeab365cfe84029a31caad", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/GDvy1QTJ-7iDp2NA2ITTnsGKaaK-4ooAO6E8s9l3qD8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=201d87ae4ddbc011eaa35f8bfc82f094db739cef", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/GDvy1QTJ-7iDp2NA2ITTnsGKaaK-4ooAO6E8s9l3qD8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=abeede027459c1ffdd82316a238e006479815c13", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/GDvy1QTJ-7iDp2NA2ITTnsGKaaK-4ooAO6E8s9l3qD8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=09579bde04d5e098079ef71393fb3bfc257e7860", "width": 960, "height": 480}], "variants": {}, "id": "ORHJmTz955lt2YCixbuoQFGaJV5SsnzvlL0iUVr2-QY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12p5w0v", "is_robot_indexable": true, "report_reasons": null, "author": "vincelapinou", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12p5w0v/encrypt_requests_to_s3_storage_aws_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12p5w0v/encrypt_requests_to_s3_storage_aws_s3/", "subreddit_subscribers": 100089, "created_utc": 1681714787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does it happen that you will be at Kubecon Europe 2023? We will be at **booth P15**, ready to talk about AI/ML, MLOps, open-source ML, Kubeflow, and more. There are a bunch of demos Ubuntu prepared and a fun keynote on secure MLOps. [Read more](https://medium.com/@andreeamihaelamunteanu/open-source-mlops-at-kubecon-with-ubuntu-870d06742b4f) and meet us there!", "author_fullname": "t2_3z4miuvs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kubecon Europe 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pzy96", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681771200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does it happen that you will be at Kubecon Europe 2023? We will be at &lt;strong&gt;booth P15&lt;/strong&gt;, ready to talk about AI/ML, MLOps, open-source ML, Kubeflow, and more. There are a bunch of demos Ubuntu prepared and a fun keynote on secure MLOps. &lt;a href=\"https://medium.com/@andreeamihaelamunteanu/open-source-mlops-at-kubecon-with-ubuntu-870d06742b4f\"&gt;Read more&lt;/a&gt; and meet us there!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?auto=webp&amp;v=enabled&amp;s=77fa09475f5677298ce0f781605f8b30e3872c28", "width": 720, "height": 376}, "resolutions": [{"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df046630b5228d489c6666882cd309e9a7db6bad", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=951a9937f2949b1944ec19a4be60f600d93bf424", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4928ff7617de6e675af1ca549a2751852e323de4", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/eoVFZNSzPNEOGSbOriaNhtcnMaeaH14IHO_S3jnahIM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd34f0217fe410444e028ce9b2b455e5962469a7", "width": 640, "height": 334}], "variants": {}, "id": "nXaAxnhnc4JIZNk3qgMyfIBphHx3dRXGnYjGSFZKG2I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12pzy96", "is_robot_indexable": true, "report_reasons": null, "author": "andreea-mun", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pzy96/kubecon_europe_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pzy96/kubecon_europe_2023/", "subreddit_subscribers": 100089, "created_utc": 1681771200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everybody,\n\nIm here to express my  thoughts that are currently going on working as Data Engineer.  \nIm in the journey of promotion ladder process in my company. I feel Im stuck as Data Engineer, I need some tips to be a Senior Data Engineer.   \n\n\nIm looking for some mentorship programs online, I don't find anything suitable ( have you heard of [https://www.jointaro.com/](https://www.jointaro.com/) , any reviews? )\n\n&amp;#x200B;\n\nBackgroud: Im Data Engineer, working in DE-MLOps team. Work is more oriented to building the data pipeline for ML model, but most of my tasks would be on terraform. The queries, code would be written by Data scientist, All we have to do is take the code and build pipeline. It was interesting before, coz I was new to IaaC and cloud. Now I feel it as bit boring. How do I create an impact on projects like these which can help me to climd my career ladder.", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding mentors for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pb72z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681727794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everybody,&lt;/p&gt;\n\n&lt;p&gt;Im here to express my  thoughts that are currently going on working as Data Engineer.&lt;br/&gt;\nIm in the journey of promotion ladder process in my company. I feel Im stuck as Data Engineer, I need some tips to be a Senior Data Engineer.   &lt;/p&gt;\n\n&lt;p&gt;Im looking for some mentorship programs online, I don&amp;#39;t find anything suitable ( have you heard of &lt;a href=\"https://www.jointaro.com/\"&gt;https://www.jointaro.com/&lt;/a&gt; , any reviews? )&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Backgroud: Im Data Engineer, working in DE-MLOps team. Work is more oriented to building the data pipeline for ML model, but most of my tasks would be on terraform. The queries, code would be written by Data scientist, All we have to do is take the code and build pipeline. It was interesting before, coz I was new to IaaC and cloud. Now I feel it as bit boring. How do I create an impact on projects like these which can help me to climd my career ladder.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SwPUnYQsOskuAu3PULw5wMerw5pDfSZMyr6tH8n3mg8.jpg?auto=webp&amp;v=enabled&amp;s=f99e834293bcc81f1b18f6e46246a8943c844f66", "width": 2133, "height": 2133}, "resolutions": [{"url": "https://external-preview.redd.it/SwPUnYQsOskuAu3PULw5wMerw5pDfSZMyr6tH8n3mg8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a4ee1ce456c32dad6e6bdfa5bc1b0d9d04f684e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/SwPUnYQsOskuAu3PULw5wMerw5pDfSZMyr6tH8n3mg8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da97f0bce5a68e790265b96edf259265f30750d7", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/SwPUnYQsOskuAu3PULw5wMerw5pDfSZMyr6tH8n3mg8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c643a4d16cedc04ad6f32c4a21d6501086c3d1bf", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/SwPUnYQsOskuAu3PULw5wMerw5pDfSZMyr6tH8n3mg8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51d3653ed87dc9264c81034fc2030a76e08b04c2", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/SwPUnYQsOskuAu3PULw5wMerw5pDfSZMyr6tH8n3mg8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=795217252ccfd77a2963609a6fd4e7f4e42311be", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/SwPUnYQsOskuAu3PULw5wMerw5pDfSZMyr6tH8n3mg8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2e4a11f054f7e03b3024df84e79d95d8e2c21d2", "width": 1080, "height": 1080}], "variants": {}, "id": "tfE9IsMZrtTOTB0RQnP2-rEkWRa0usoB-5W9Q2de3Y0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12pb72z", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pb72z/finding_mentors_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pb72z/finding_mentors_for_data_engineering/", "subreddit_subscribers": 100089, "created_utc": 1681727794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, community!\r\n\r\nWe are working on a new CDP product. Our product is focused on data engineers. For example, Python support! :)\r\n\r\nOur concept is we give the platform you provide the code. \r\n\r\nDoes somebody have 15 minutes this week for a quick call? We need some feedback from the community!\r\n\r\nThanks!", "author_fullname": "t2_1mwhn72z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We need feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12pk6gn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681743777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, community!&lt;/p&gt;\n\n&lt;p&gt;We are working on a new CDP product. Our product is focused on data engineers. For example, Python support! :)&lt;/p&gt;\n\n&lt;p&gt;Our concept is we give the platform you provide the code. &lt;/p&gt;\n\n&lt;p&gt;Does somebody have 15 minutes this week for a quick call? We need some feedback from the community!&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12pk6gn", "is_robot_indexable": true, "report_reasons": null, "author": "pigri", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12pk6gn/we_need_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12pk6gn/we_need_feedback/", "subreddit_subscribers": 100089, "created_utc": 1681743777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_80zooswmi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modelling in Columnar Data Stores is different", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ph6g0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1681740367.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "link.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://link.medium.com/LHuqX42A4yb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12ph6g0", "is_robot_indexable": true, "report_reasons": null, "author": "Ordinary_Nobody5949", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ph6g0/data_modelling_in_columnar_data_stores_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://link.medium.com/LHuqX42A4yb", "subreddit_subscribers": 100089, "created_utc": 1681740367.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}