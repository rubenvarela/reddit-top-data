{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ejh5mwyx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Found this on an analyst position job ad on LinkedIn. Do you think the shade is reasonable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 12, "top_awarded_type": null, "hide_score": false, "name": "t3_12vl384", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 187, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 187, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VIyQtNBtJrlzs5p8QhPi68rYH3Th_PqRohiNlUxcV3U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682201044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/cxcftudodiva1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/cxcftudodiva1.png?auto=webp&amp;v=enabled&amp;s=6019ae5fdcf12dae0e88afef5f4b60d0d257be12", "width": 749, "height": 67}, "resolutions": [{"url": "https://preview.redd.it/cxcftudodiva1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b44887fa79ad7a9df108a5a870ae4b3bf26796e", "width": 108, "height": 9}, {"url": "https://preview.redd.it/cxcftudodiva1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6848f4463a05664270bd8aa2ff568568483dffc", "width": 216, "height": 19}, {"url": "https://preview.redd.it/cxcftudodiva1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e1f4013faf2c7648879cab698bfb6afc9466398", "width": 320, "height": 28}, {"url": "https://preview.redd.it/cxcftudodiva1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ec8019426ec49a746198e1567a9a074c289583f", "width": 640, "height": 57}], "variants": {}, "id": "pnDReaq2XX32Gbj1cUcCt8IkpgaLQf2jX1jVm98t2jM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vl384", "is_robot_indexable": true, "report_reasons": null, "author": "BiggusCinnamusRollus", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vl384/found_this_on_an_analyst_position_job_ad_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/cxcftudodiva1.png", "subreddit_subscribers": 878932, "created_utc": 1682201044.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekends are for extra-work for your job ;)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "name": "t3_12vt0k5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 158, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_y7l57", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 158, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zdyCsSfuAKY_yqmOpuXCvNSNPIO_ZLujKCHWV12FC9A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "LinkedInLunatics", "selftext": "", "author_fullname": "t2_54mif01sy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekends are for extra-work for your job ;)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/LinkedInLunatics", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "name": "t3_12vbhfr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 604, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 604, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zdyCsSfuAKY_yqmOpuXCvNSNPIO_ZLujKCHWV12FC9A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "created": 1682181492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/xqjqc8g89iva1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/xqjqc8g89iva1.jpg?auto=webp&amp;v=enabled&amp;s=6a57fc931f172822e5d5dc31b5a0197d142955fd", "width": 827, "height": 578}, "resolutions": [{"url": "https://preview.redd.it/xqjqc8g89iva1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca0e56cd6698f2b052c8442076fc4ffb8783bdff", "width": 108, "height": 75}, {"url": "https://preview.redd.it/xqjqc8g89iva1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5be4a436459aaf44c0f6dedc874149b6218a563f", "width": 216, "height": 150}, {"url": "https://preview.redd.it/xqjqc8g89iva1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=295735482d443cb8b0e9bd22216ed3a63bc0fed4", "width": 320, "height": 223}, {"url": "https://preview.redd.it/xqjqc8g89iva1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=070fa50599fd57483d62dd9dcbf40bee364b9a04", "width": 640, "height": 447}], "variants": {}, "id": "pAl7YiHZThrGqqeR8X7pEUejDhmmqWBOaQ7sE63qrlg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_25tcjz", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vbhfr", "is_robot_indexable": true, "report_reasons": null, "author": "Hairy-Long-8111", "discussion_type": null, "num_comments": 107, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/LinkedInLunatics/comments/12vbhfr/weekends_are_for_extrawork_for_your_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/xqjqc8g89iva1.jpg", "subreddit_subscribers": 266698, "created_utc": 1682181492.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1682218303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/xqjqc8g89iva1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/xqjqc8g89iva1.jpg?auto=webp&amp;v=enabled&amp;s=6a57fc931f172822e5d5dc31b5a0197d142955fd", "width": 827, "height": 578}, "resolutions": [{"url": "https://preview.redd.it/xqjqc8g89iva1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca0e56cd6698f2b052c8442076fc4ffb8783bdff", "width": 108, "height": 75}, {"url": "https://preview.redd.it/xqjqc8g89iva1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5be4a436459aaf44c0f6dedc874149b6218a563f", "width": 216, "height": 150}, {"url": "https://preview.redd.it/xqjqc8g89iva1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=295735482d443cb8b0e9bd22216ed3a63bc0fed4", "width": 320, "height": 223}, {"url": "https://preview.redd.it/xqjqc8g89iva1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=070fa50599fd57483d62dd9dcbf40bee364b9a04", "width": 640, "height": 447}], "variants": {}, "id": "pAl7YiHZThrGqqeR8X7pEUejDhmmqWBOaQ7sE63qrlg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vt0k5", "is_robot_indexable": true, "report_reasons": null, "author": "sonicking12", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12vbhfr", "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vt0k5/weekends_are_for_extrawork_for_your_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/xqjqc8g89iva1.jpg", "subreddit_subscribers": 878932, "created_utc": 1682218303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been working as a DS for the last 3 months in a government agency in the UK. A typical day of work is roughly &lt;1 hour of actual work, and since it is remote, I just play videogames or watch series the reminder 7 hs.\nI have tried to be proactive at work, come up with possible projects and contribute as much as I can, but there is only so much work and my boss prefers to keep me in 'stand by' in case an urgent request comes rather than to start whole new projects.\n\nSince I have only just started this job, I don't feel the urge to grind leetcode or get more certifications (since the pay is good enough, I'll most likely stay in this position for the next 2 years). Those in similar situations, what do you do to pass the time and avoid feeling you're collecting paychecks? Are there any good DS competitions or mentoring as to not get too rusty?", "author_fullname": "t2_2jaddzio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lots of downtime as a DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12v5j8e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 123, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 123, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682169095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working as a DS for the last 3 months in a government agency in the UK. A typical day of work is roughly &amp;lt;1 hour of actual work, and since it is remote, I just play videogames or watch series the reminder 7 hs.\nI have tried to be proactive at work, come up with possible projects and contribute as much as I can, but there is only so much work and my boss prefers to keep me in &amp;#39;stand by&amp;#39; in case an urgent request comes rather than to start whole new projects.&lt;/p&gt;\n\n&lt;p&gt;Since I have only just started this job, I don&amp;#39;t feel the urge to grind leetcode or get more certifications (since the pay is good enough, I&amp;#39;ll most likely stay in this position for the next 2 years). Those in similar situations, what do you do to pass the time and avoid feeling you&amp;#39;re collecting paychecks? Are there any good DS competitions or mentoring as to not get too rusty?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12v5j8e", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofme", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12v5j8e/lots_of_downtime_as_a_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12v5j8e/lots_of_downtime_as_a_ds/", "subreddit_subscribers": 878932, "created_utc": 1682169095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The reason I'm asking is because I see it near the top of like every \"Things to learn as a data scientist\" list. But I just can't convince myself to take the time to learn it without better understanding the use case.\n\nI'm a Data Scientist at a Saas company, and we have a fairly mature data science / ml team and Terabytes of data to play with. That being said, none of us have ever touched or even thought of touching Hadoop. It's not that we don't have lots of data -- but I'm just not seeing the use case. Most stuff you can just batch if the data is too large. Or spin up an AWS instance that's a little bigger. Compute just seems to be growing sufficiently fast that I'm not really into the Hadoop hype. Even things like, say a linear model where you really can't do the matrix inversion in batches you can just take a random sample of 100k data points and basically converge to the model.", "author_fullname": "t2_1zkrsyfq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone use Hadoop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vlt86", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682202515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The reason I&amp;#39;m asking is because I see it near the top of like every &amp;quot;Things to learn as a data scientist&amp;quot; list. But I just can&amp;#39;t convince myself to take the time to learn it without better understanding the use case.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a Data Scientist at a Saas company, and we have a fairly mature data science / ml team and Terabytes of data to play with. That being said, none of us have ever touched or even thought of touching Hadoop. It&amp;#39;s not that we don&amp;#39;t have lots of data -- but I&amp;#39;m just not seeing the use case. Most stuff you can just batch if the data is too large. Or spin up an AWS instance that&amp;#39;s a little bigger. Compute just seems to be growing sufficiently fast that I&amp;#39;m not really into the Hadoop hype. Even things like, say a linear model where you really can&amp;#39;t do the matrix inversion in batches you can just take a random sample of 100k data points and basically converge to the model.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vlt86", "is_robot_indexable": true, "report_reasons": null, "author": "Any-Fig-921", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vlt86/does_anyone_use_hadoop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vlt86/does_anyone_use_hadoop/", "subreddit_subscribers": 878932, "created_utc": 1682202515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was trying to evaluate different classification models on MNIST dataset.\n\nThere are two datasets provided : \\`train\\` - 42000 images, and \\`test\\` - 28000 images.\n\n&amp;#x200B;\n\nI first divided the original training dataset (42000 images) into a (80:20 split ) of \\`train\\_set\\` (33600) and \\`test\\_set\\` (8400) .\n\nI trained several models, from on \\`training set\\`, \\`cross-validated\\` them on the \\`training\\_set\\` only, and lastly evaluated the final model on the \\`test\\_set\\` for generalization error.\n\n&amp;#x200B;\n\nNow that my final model is ready to generate the \\`submission file\\` using the Kaggle provided \\`test\\` set, should I train my model on the whole Kaggle provided \\`training\\` set, ie \\`train\\_set + test\\_set\\` (ie the full 42000 images provided, instead of just 33600 images that I split), since Kaggle is going to evaluate my model on its own provided \\`test\\` set ?", "author_fullname": "t2_ehnipsvn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I train my final model on the (train+validation) set before final submission?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vcuj7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682184167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was trying to evaluate different classification models on MNIST dataset.&lt;/p&gt;\n\n&lt;p&gt;There are two datasets provided : `train` - 42000 images, and `test` - 28000 images.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I first divided the original training dataset (42000 images) into a (80:20 split ) of `train_set` (33600) and `test_set` (8400) .&lt;/p&gt;\n\n&lt;p&gt;I trained several models, from on `training set`, `cross-validated` them on the `training_set` only, and lastly evaluated the final model on the `test_set` for generalization error.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now that my final model is ready to generate the `submission file` using the Kaggle provided `test` set, should I train my model on the whole Kaggle provided `training` set, ie `train_set + test_set` (ie the full 42000 images provided, instead of just 33600 images that I split), since Kaggle is going to evaluate my model on its own provided `test` set ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vcuj7", "is_robot_indexable": true, "report_reasons": null, "author": "DietzscheNostoevsky", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vcuj7/should_i_train_my_final_model_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vcuj7/should_i_train_my_final_model_on_the/", "subreddit_subscribers": 878932, "created_utc": 1682184167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How much work does my resume need?\n\nhttps://preview.redd.it/fwsl6ynr5kva1.png?width=998&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8299a2a102fb345814fdf637bbb2488cc52f97ac", "author_fullname": "t2_7wt0cs0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reaching 500 Applications for Data Scientists or Data Analysts since February with 2 callbacks from Pharma companies, I want to work in Tech, Retail, or Finance in that order (Any or all feedback is appreciated!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"fwsl6ynr5kva1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/fwsl6ynr5kva1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a78361e4ad9d0609a4b90961c2d3eaff4c8d016e"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/fwsl6ynr5kva1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d98bddac0695ecd82d13359a2a8da33d3ecd728"}, {"y": 413, "x": 320, "u": "https://preview.redd.it/fwsl6ynr5kva1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5be2eb5872b95488cdcc0af0a08c47741abcc879"}, {"y": 827, "x": 640, "u": "https://preview.redd.it/fwsl6ynr5kva1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ce885fd22827af51ed74156a8ce35532c636a68"}, {"y": 1240, "x": 960, "u": "https://preview.redd.it/fwsl6ynr5kva1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfca0ecb02047fbae50bbd815ecc7f42f550f259"}], "s": {"y": 1290, "x": 998, "u": "https://preview.redd.it/fwsl6ynr5kva1.png?width=998&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8299a2a102fb345814fdf637bbb2488cc52f97ac"}, "id": "fwsl6ynr5kva1"}}, "name": "t3_12vuu7t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/c3OfWFpWHhARDMf8-DTrKTI84XwPxVJittprjbzDTB0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682222437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How much work does my resume need?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fwsl6ynr5kva1.png?width=998&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8299a2a102fb345814fdf637bbb2488cc52f97ac\"&gt;https://preview.redd.it/fwsl6ynr5kva1.png?width=998&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8299a2a102fb345814fdf637bbb2488cc52f97ac&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vuu7t", "is_robot_indexable": true, "report_reasons": null, "author": "subtract_it", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vuu7t/reaching_500_applications_for_data_scientists_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vuu7t/reaching_500_applications_for_data_scientists_or/", "subreddit_subscribers": 878932, "created_utc": 1682222437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently working as a DS where I develop models exclusively related to images and that is the only thing I ever did, creating ML models on image data. This includes SOTA segmentation, classification, training Linear simple models based on feature extraction of images.\n\nI got an offer recently whose Job description was\n\n* Work with large, complex datasets to identify trends, patterns, and insights that inform business decisions\n* Perform data cleaning, pre-processing, and feature engineering to prepare data foranalysis\n\nThe offer is attractive because it's WFH and better pay. However I feel this work would be more sought of building the company (it has only 2 DS members currently, a red flag??) and creating pipelines to deal with cumbersome data.My two concerns are:\n\n1. Is this is a back step in my career as I wont be working on anything related to computer vision and in the future companies might reject me saying 'the candidate is more of a text DS guy'. I did work on latest SOTA research papers but now it would just be about choosing correct tools and coding effectively (am I mistaken??).\n2. I have no experience with NLP/text data, how badly will I be effected in my new job.  \n\n\nEdit: I realise now the JD is more about tabular data than text data.", "author_fullname": "t2_5x4phu3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from computer vision to text heavy data science job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12w0k55", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682243372.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682236687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working as a DS where I develop models exclusively related to images and that is the only thing I ever did, creating ML models on image data. This includes SOTA segmentation, classification, training Linear simple models based on feature extraction of images.&lt;/p&gt;\n\n&lt;p&gt;I got an offer recently whose Job description was&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Work with large, complex datasets to identify trends, patterns, and insights that inform business decisions&lt;/li&gt;\n&lt;li&gt;Perform data cleaning, pre-processing, and feature engineering to prepare data foranalysis&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The offer is attractive because it&amp;#39;s WFH and better pay. However I feel this work would be more sought of building the company (it has only 2 DS members currently, a red flag??) and creating pipelines to deal with cumbersome data.My two concerns are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is this is a back step in my career as I wont be working on anything related to computer vision and in the future companies might reject me saying &amp;#39;the candidate is more of a text DS guy&amp;#39;. I did work on latest SOTA research papers but now it would just be about choosing correct tools and coding effectively (am I mistaken??).&lt;/li&gt;\n&lt;li&gt;I have no experience with NLP/text data, how badly will I be effected in my new job.&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Edit: I realise now the JD is more about tabular data than text data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12w0k55", "is_robot_indexable": true, "report_reasons": null, "author": "51times", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12w0k55/transitioning_from_computer_vision_to_text_heavy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12w0k55/transitioning_from_computer_vision_to_text_heavy/", "subreddit_subscribers": 878932, "created_utc": 1682236687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Ok so I had this idea when sipping on my creatine. Not sure if something like this already exists or is impossible. \nThis may work for other smaller neural networks but let's take time series neural network with a training period of 3 year as an example. \nWhen passing samples to our neural network, can we see which samples affect the gradient the most and isolate the most important features from that sample set to get an understanding of which samples have a great impact on the learning. This can give us an idea of real life feature set and how the model reacts to it. So when things either work or don't work we can refer to these sets and confirm the impact.\nI don't know if it makes sense but thought I would just put it here.", "author_fullname": "t2_5fdcznre", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Explainability of time series model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vcqth", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682183965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ok so I had this idea when sipping on my creatine. Not sure if something like this already exists or is impossible. \nThis may work for other smaller neural networks but let&amp;#39;s take time series neural network with a training period of 3 year as an example. \nWhen passing samples to our neural network, can we see which samples affect the gradient the most and isolate the most important features from that sample set to get an understanding of which samples have a great impact on the learning. This can give us an idea of real life feature set and how the model reacts to it. So when things either work or don&amp;#39;t work we can refer to these sets and confirm the impact.\nI don&amp;#39;t know if it makes sense but thought I would just put it here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vcqth", "is_robot_indexable": true, "report_reasons": null, "author": "KaaleenBaba", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vcqth/explainability_of_time_series_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vcqth/explainability_of_time_series_model/", "subreddit_subscribers": 878932, "created_utc": 1682183965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We are creating an Open Source  Project to customize a NLP model for the Energy Industry.  While open source is great, our year 2 and year 3 goal will also be for folks to be able to monetize it after by offering consulting services (you can set your own rates for this work).   We have obtained enough funding for two years of hosting fees and software/platform and have some end clients that have signed on (it is a win-win for them since they are not paying anything initially and get . We are almost done setting up a framework/infrastructure that will simplify the task using a tool similar to ML flow (but a lot more powerful/integrated with multiple data sets). We will not start officially until we have all the framework in place so we don't waste people's time but this is roughly around May 15 so we are starting to look for folks now. So far we have two folks on-board but we figure we would ideally like 10-20 contributors. \n\nSerious inquiries only please.", "author_fullname": "t2_71ikgu3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open Source Initiative- Join us!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vjh5l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682197914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are creating an Open Source  Project to customize a NLP model for the Energy Industry.  While open source is great, our year 2 and year 3 goal will also be for folks to be able to monetize it after by offering consulting services (you can set your own rates for this work).   We have obtained enough funding for two years of hosting fees and software/platform and have some end clients that have signed on (it is a win-win for them since they are not paying anything initially and get . We are almost done setting up a framework/infrastructure that will simplify the task using a tool similar to ML flow (but a lot more powerful/integrated with multiple data sets). We will not start officially until we have all the framework in place so we don&amp;#39;t waste people&amp;#39;s time but this is roughly around May 15 so we are starting to look for folks now. So far we have two folks on-board but we figure we would ideally like 10-20 contributors. &lt;/p&gt;\n\n&lt;p&gt;Serious inquiries only please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vjh5l", "is_robot_indexable": true, "report_reasons": null, "author": "SnooTangerines240", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vjh5l/open_source_initiative_join_us/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vjh5l/open_source_initiative_join_us/", "subreddit_subscribers": 878932, "created_utc": 1682197914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve noticed that we're seeing big advancements almost every day, but it feels like the quality of papers is going downhill when it comes to backing up their claims.\n\nAnyone else feel this way? Do you think it's just because of all the buzz around generative AI, or is this something that's here to stay?", "author_fullname": "t2_8l29q3sh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] What are your thoughts on the quality of papers recently?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12v98us", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682177089.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve noticed that we&amp;#39;re seeing big advancements almost every day, but it feels like the quality of papers is going downhill when it comes to backing up their claims.&lt;/p&gt;\n\n&lt;p&gt;Anyone else feel this way? Do you think it&amp;#39;s just because of all the buzz around generative AI, or is this something that&amp;#39;s here to stay?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12v98us", "is_robot_indexable": true, "report_reasons": null, "author": "spenny972", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12v98us/d_what_are_your_thoughts_on_the_quality_of_papers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12v98us/d_what_are_your_thoughts_on_the_quality_of_papers/", "subreddit_subscribers": 878932, "created_utc": 1682177089.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've watched loads of videos on SQL and excel to learn how to use them but finding it difficult to put it all into practice.", "author_fullname": "t2_w2wv5gc4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there YouTube videos of people using SQL and excel for data analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12w3b0m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682244269.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682243748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve watched loads of videos on SQL and excel to learn how to use them but finding it difficult to put it all into practice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12w3b0m", "is_robot_indexable": true, "report_reasons": null, "author": "Olive7222", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12w3b0m/are_there_youtube_videos_of_people_using_sql_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12w3b0m/are_there_youtube_videos_of_people_using_sql_and/", "subreddit_subscribers": 878932, "created_utc": 1682243748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR; I'm debating whether to complete an MS in Data Science at UW or an MEng at Duke. I wonder which degree will make me more employable and competent if I'm seeking future machine learning scientist jobs.\n\nHello everyone! I'm interested in becoming a machine learning scientist and got admitted to two masters programs: **MS in Data Science at the University of Washington (UW)** and **MEng in Artificial Intelligence at Duke University**. I'd love to get opinions on which would be a better program for me. For context, I completed my undergrad in data science but focused more on a career in product management so in both programs I'd be learning new things. I'm also an international student so employment opportunities post-graduation is very important to me.\n\n**UW Courses:** [https://www.washington.edu/datasciencemasters/course-descriptions/#d511](https://www.washington.edu/datasciencemasters/course-descriptions/#d511)  \nData Visualization, Probability and Statistics, Data Management, Software Design, Scalable Data Systems and Algorithms, Applied Statistics and Experimental Design, Statistical Machine Learning\n\nWhat I like about UW is that it would teach me solid, practical, and industry-relevant data science fundamentals. It's also an established program located in Seattle, which could mean a slight edge for finding a job in tech post-graduation. However, if I go for this degree I'd have to work on developing ML skills on my own (which is doable since I already have some experience building ML models), likely via lab assistantships (UW has great AI research groups) or personal projects. What I hear from people who say I should pick this degree is that advances in AI/ML happen quickly so ensuring that I have the fundamentals down and self-learning state-of-the-art ML is the way to go. Plus I know employers like to see proof of competency via projects the applicant has completed. Also, I can't help but wonder whether the best way to get into ML would be to work as a data scientist first and eventually transition into that role.\n\n**Duke Courses:** [https://ai.meng.duke.edu/courses](https://ai.meng.duke.edu/courses)  \nModeling Process &amp; Algorithms, Sourcing data for Analytics, Deep Learning Applications, Optimization in Practice, AI Ethics, MLOps, two electives (probably Data Analysis in The Cloud, Statistical Computing, and/or Design of Experiments).\n\nWhat I like about the Duke degree is that it focuses exactly on what I want: building AI/ML products. The prestige of Duke University is also a big appeal as well as its location (I've lived in the Midwest for the last few years and would love to be in warmer weather). Not having as much access to tech connections as in Seattle is a drawback. Furthermore, I feel like I'd walk away really knowing how to build ML models but would be lacking fundamental knowledge such as DB management and Software Design and this knowledge gap might narrow my job prospect to exclusively ML jobs which are highly competitive (again, as an international student, landing a job soon after graduation is very important to me).\n\nThanks for taking the time to read. Any kind of advice would be very much appreciated!\n\n[View Poll](https://www.reddit.com/poll/12vvi49)", "author_fullname": "t2_chlg3u8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MS in Data Science @ University of Washington vs. MEng in AI @ Duke University", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vvi49", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682223994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR; I&amp;#39;m debating whether to complete an MS in Data Science at UW or an MEng at Duke. I wonder which degree will make me more employable and competent if I&amp;#39;m seeking future machine learning scientist jobs.&lt;/p&gt;\n\n&lt;p&gt;Hello everyone! I&amp;#39;m interested in becoming a machine learning scientist and got admitted to two masters programs: &lt;strong&gt;MS in Data Science at the University of Washington (UW)&lt;/strong&gt; and &lt;strong&gt;MEng in Artificial Intelligence at Duke University&lt;/strong&gt;. I&amp;#39;d love to get opinions on which would be a better program for me. For context, I completed my undergrad in data science but focused more on a career in product management so in both programs I&amp;#39;d be learning new things. I&amp;#39;m also an international student so employment opportunities post-graduation is very important to me.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;UW Courses:&lt;/strong&gt; &lt;a href=\"https://www.washington.edu/datasciencemasters/course-descriptions/#d511\"&gt;https://www.washington.edu/datasciencemasters/course-descriptions/#d511&lt;/a&gt;&lt;br/&gt;\nData Visualization, Probability and Statistics, Data Management, Software Design, Scalable Data Systems and Algorithms, Applied Statistics and Experimental Design, Statistical Machine Learning&lt;/p&gt;\n\n&lt;p&gt;What I like about UW is that it would teach me solid, practical, and industry-relevant data science fundamentals. It&amp;#39;s also an established program located in Seattle, which could mean a slight edge for finding a job in tech post-graduation. However, if I go for this degree I&amp;#39;d have to work on developing ML skills on my own (which is doable since I already have some experience building ML models), likely via lab assistantships (UW has great AI research groups) or personal projects. What I hear from people who say I should pick this degree is that advances in AI/ML happen quickly so ensuring that I have the fundamentals down and self-learning state-of-the-art ML is the way to go. Plus I know employers like to see proof of competency via projects the applicant has completed. Also, I can&amp;#39;t help but wonder whether the best way to get into ML would be to work as a data scientist first and eventually transition into that role.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Duke Courses:&lt;/strong&gt; &lt;a href=\"https://ai.meng.duke.edu/courses\"&gt;https://ai.meng.duke.edu/courses&lt;/a&gt;&lt;br/&gt;\nModeling Process &amp;amp; Algorithms, Sourcing data for Analytics, Deep Learning Applications, Optimization in Practice, AI Ethics, MLOps, two electives (probably Data Analysis in The Cloud, Statistical Computing, and/or Design of Experiments).&lt;/p&gt;\n\n&lt;p&gt;What I like about the Duke degree is that it focuses exactly on what I want: building AI/ML products. The prestige of Duke University is also a big appeal as well as its location (I&amp;#39;ve lived in the Midwest for the last few years and would love to be in warmer weather). Not having as much access to tech connections as in Seattle is a drawback. Furthermore, I feel like I&amp;#39;d walk away really knowing how to build ML models but would be lacking fundamental knowledge such as DB management and Software Design and this knowledge gap might narrow my job prospect to exclusively ML jobs which are highly competitive (again, as an international student, landing a job soon after graduation is very important to me).&lt;/p&gt;\n\n&lt;p&gt;Thanks for taking the time to read. Any kind of advice would be very much appreciated!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/12vvi49\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "12vvi49", "is_robot_indexable": true, "report_reasons": null, "author": "mindstudio3", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": null, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vvi49/ms_in_data_science_university_of_washington_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/12vvi49/ms_in_data_science_university_of_washington_vs/", "subreddit_subscribers": 878932, "created_utc": 1682223994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How much work does my resume need\n\n[View Poll](https://www.reddit.com/poll/12vutya)", "author_fullname": "t2_7wt0cs0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reaching 500 Applications for Data Scientists or Data Analysts since February with 2 callbacks from Pharma companies, I want to work in Tech, Retail, or Finance in that order (Any or all feedback is appreciated!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vutya", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682222421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How much work does my resume need&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/12vutya\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "12vutya", "is_robot_indexable": true, "report_reasons": null, "author": "subtract_it", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": null, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vutya/reaching_500_applications_for_data_scientists_or/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/12vutya/reaching_500_applications_for_data_scientists_or/", "subreddit_subscribers": 878932, "created_utc": 1682222421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently a non tech Project Manager consultant who leads on Agile IT projects within banking and financial domain. I have management and financial domain experience but sometimes end up losing projects ( as a consultant) to those with few years of IT or Data Engineering experience.\n\nGoing through some confusion where one hand I want to study up courses on Data Science to atleast gain some edge  and deeper understanding of field , while other hand i feel i don't want  to end up wasting time if it is not fruitful. (*Also I feel as roles become more cross domain* *(I am currently a PRojM/BA/Prod Owner/Scrum Master) , eventually we may have to learn some CS &lt;distant future&gt;*)\n\nWhat are your thoughts and suggestions what/how to start?", "author_fullname": "t2_7vpadiuy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Data Science /Data Analysis for IT Project Manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vu2f9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682221056.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682220687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a non tech Project Manager consultant who leads on Agile IT projects within banking and financial domain. I have management and financial domain experience but sometimes end up losing projects ( as a consultant) to those with few years of IT or Data Engineering experience.&lt;/p&gt;\n\n&lt;p&gt;Going through some confusion where one hand I want to study up courses on Data Science to atleast gain some edge  and deeper understanding of field , while other hand i feel i don&amp;#39;t want  to end up wasting time if it is not fruitful. (&lt;em&gt;Also I feel as roles become more cross domain&lt;/em&gt; &lt;em&gt;(I am currently a PRojM/BA/Prod Owner/Scrum Master) , eventually we may have to learn some CS &amp;lt;distant future&amp;gt;&lt;/em&gt;)&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts and suggestions what/how to start?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vu2f9", "is_robot_indexable": true, "report_reasons": null, "author": "Firm-North-6146", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vu2f9/learning_data_science_data_analysis_for_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vu2f9/learning_data_science_data_analysis_for_it/", "subreddit_subscribers": 878932, "created_utc": 1682220687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey folks,\n\nToday is Earth Day, and it's time to do our part in protecting our planet's natural resources. One way you can contribute is by monitoring forests and trees to identify regions with high tree loss. And the good news is that you can do this in just 15 minutes, for free! Here is how: https://www.spacesense.ai/blog-posts/build-a-deforestation-monitoring-solution-using-satellite-imagery-in-15-minutes\n\nSpaceSense is a platform that allows you to do just that. It uses satellite imagery to help you identify areas with high tree loss. And when you share your findings with #datascientist4climate, you'll be making a significant contribution to the fight against climate change.\n\nSo, put on your nature hats, fire up SpaceSense, and start monitoring those trees! Let's all be heroes to the planet.\n\nregister for a free licence here: https://www.spacesense.ai/platform", "author_fullname": "t2_9rwjtia18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Happy Earth Day! Join the fight to protect our planet's forests and trees with SpaceSense and #datascientist4climatep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vjxs5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682198820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;Today is Earth Day, and it&amp;#39;s time to do our part in protecting our planet&amp;#39;s natural resources. One way you can contribute is by monitoring forests and trees to identify regions with high tree loss. And the good news is that you can do this in just 15 minutes, for free! Here is how: &lt;a href=\"https://www.spacesense.ai/blog-posts/build-a-deforestation-monitoring-solution-using-satellite-imagery-in-15-minutes\"&gt;https://www.spacesense.ai/blog-posts/build-a-deforestation-monitoring-solution-using-satellite-imagery-in-15-minutes&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;SpaceSense is a platform that allows you to do just that. It uses satellite imagery to help you identify areas with high tree loss. And when you share your findings with #datascientist4climate, you&amp;#39;ll be making a significant contribution to the fight against climate change.&lt;/p&gt;\n\n&lt;p&gt;So, put on your nature hats, fire up SpaceSense, and start monitoring those trees! Let&amp;#39;s all be heroes to the planet.&lt;/p&gt;\n\n&lt;p&gt;register for a free licence here: &lt;a href=\"https://www.spacesense.ai/platform\"&gt;https://www.spacesense.ai/platform&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?auto=webp&amp;v=enabled&amp;s=e64919c0ef67486fa3736cb8d803fb16da60bd8b", "width": 1920, "height": 1920}, "resolutions": [{"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc58e965c719d62e327aa6c09ce2642baa221f42", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=602bbf9640187d1e4da61a3bf811b8369f0f37ac", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d930e00d4880b7d3c1ffdaa05f9f1f07a376f6f4", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0716b184c23e57f3ab2da207d18aabaa47a32ced", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3fbd7dc0333a9b62c35ca59ec78dc4d256eb0d9a", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/-FBdukiW4_DLspgsInrpl7ZNEPATOQ1qD_EHOfNPzFI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=200824811fd64a2f52a74ce65be9ef77b890f2de", "width": 1080, "height": 1080}], "variants": {}, "id": "JJ-9SwnXzqvDvkPIN3BJrvthVJAb-LCanr5yn2nP3xM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vjxs5", "is_robot_indexable": true, "report_reasons": null, "author": "Space4earth", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vjxs5/happy_earth_day_join_the_fight_to_protect_our/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vjxs5/happy_earth_day_join_the_fight_to_protect_our/", "subreddit_subscribers": 878932, "created_utc": 1682198820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi!\n\nFor  my master's thesis, I am writing an algorithm that can predict which  books will become popular on Tiktok. Right now I am working on getting  the right labels for the dataset, based on the viewcounts of the books  on Tiktok. I have a large dataset with titles and viewcounts, and a list of 19 books that have done well on Tiktok, with their viewcounts (there are probably  more, but I had to make a list myself of what I know for sure are famous  books). I want to use their viewcounts to set a baseline for what is  considered popular on tiktok and what is not considered popular.  However, the viewcounts all lie pretty far apart. They are the following  numbers:66089172, 909551, 14159253, 5771561,  68456152, 20982050,  6767132, 61012995, 39505320, 1299157, 27307,  38193455, 34048345,  9830311, 87600000, 37921810, 88484025, 55764970,  108154.\n\nI  have considered using the mean or median, but since the numbers lie  pretty far apart and they aren't normally distributed, I don't think I  can use those. I then considered using the mean - 3 times the standard  deviation, but this gave me a lower bound of zero, meaning that all  books would be considered tiktok famous. I also tried using the 25  percentile - 1.5 times the interquartile range, but he same thing  happened.\n\nRight now I am thinking I  could just use the lowest number of the list, since I know that one is  Tiktok famous so ones with even slightly more views will be considered  famous as well, but this feels like it's very wrong, statistically  speaking, so I was wondering on your opinion on this, and if you had any  advice or recommendations?\n\nThank you so much in advance!", "author_fullname": "t2_2uua33bh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Q] [E] Question about finding the appropriate lower boundary for adding labels to my dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vj8yo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682197471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;For  my master&amp;#39;s thesis, I am writing an algorithm that can predict which  books will become popular on Tiktok. Right now I am working on getting  the right labels for the dataset, based on the viewcounts of the books  on Tiktok. I have a large dataset with titles and viewcounts, and a list of 19 books that have done well on Tiktok, with their viewcounts (there are probably  more, but I had to make a list myself of what I know for sure are famous  books). I want to use their viewcounts to set a baseline for what is  considered popular on tiktok and what is not considered popular.  However, the viewcounts all lie pretty far apart. They are the following  numbers:66089172, 909551, 14159253, 5771561,  68456152, 20982050,  6767132, 61012995, 39505320, 1299157, 27307,  38193455, 34048345,  9830311, 87600000, 37921810, 88484025, 55764970,  108154.&lt;/p&gt;\n\n&lt;p&gt;I  have considered using the mean or median, but since the numbers lie  pretty far apart and they aren&amp;#39;t normally distributed, I don&amp;#39;t think I  can use those. I then considered using the mean - 3 times the standard  deviation, but this gave me a lower bound of zero, meaning that all  books would be considered tiktok famous. I also tried using the 25  percentile - 1.5 times the interquartile range, but he same thing  happened.&lt;/p&gt;\n\n&lt;p&gt;Right now I am thinking I  could just use the lowest number of the list, since I know that one is  Tiktok famous so ones with even slightly more views will be considered  famous as well, but this feels like it&amp;#39;s very wrong, statistically  speaking, so I was wondering on your opinion on this, and if you had any  advice or recommendations?&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vj8yo", "is_robot_indexable": true, "report_reasons": null, "author": "Romcom1398", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vj8yo/q_e_question_about_finding_the_appropriate_lower/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vj8yo/q_e_question_about_finding_the_appropriate_lower/", "subreddit_subscribers": 878932, "created_utc": 1682197471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I've been working on a financial data set from where I've to classify early loan default among customers (binary Classification). Its a relatively smaller data set (about 3k rows) &amp; highly imbalanced class distribution and i've been trying to fit a XGB algo on it. But upon decile analysis gini is around 98 &amp; 97 % for test &amp; train respectively. Other than that f1, accuracy, recall all are 1.00 I found this to be very fishy. Can anybody help me out figuring what is going on ?", "author_fullname": "t2_8b1tcpps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overfitting in XGB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12veat4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682187232.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working on a financial data set from where I&amp;#39;ve to classify early loan default among customers (binary Classification). Its a relatively smaller data set (about 3k rows) &amp;amp; highly imbalanced class distribution and i&amp;#39;ve been trying to fit a XGB algo on it. But upon decile analysis gini is around 98 &amp;amp; 97 % for test &amp;amp; train respectively. Other than that f1, accuracy, recall all are 1.00 I found this to be very fishy. Can anybody help me out figuring what is going on ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12veat4", "is_robot_indexable": true, "report_reasons": null, "author": "MustBeHuman", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12veat4/overfitting_in_xgb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12veat4/overfitting_in_xgb/", "subreddit_subscribers": 878932, "created_utc": 1682187232.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello comrades, I am a data science enthusiastic and I'm learnig about managing the NaN values on my dataframe. I would like to know how do the statistics would be affected if I delete all the NaN values. Does it depend on the number of NaN values? How would I know? And last question, if my dataframe has too many NaN values, is it considered useless or could I still work with it? Thanks!", "author_fullname": "t2_6htfxyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing NaN values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vqhz0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682213004.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682212757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello comrades, I am a data science enthusiastic and I&amp;#39;m learnig about managing the NaN values on my dataframe. I would like to know how do the statistics would be affected if I delete all the NaN values. Does it depend on the number of NaN values? How would I know? And last question, if my dataframe has too many NaN values, is it considered useless or could I still work with it? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vqhz0", "is_robot_indexable": true, "report_reasons": null, "author": "mr_eriikr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vqhz0/managing_nan_values/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vqhz0/managing_nan_values/", "subreddit_subscribers": 878932, "created_utc": 1682212757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Any Good Data Science Global Certification You Have Done recently And Would Like To Recommend? \n\nBring it on!\nThanks", "author_fullname": "t2_usmthp9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Good Data Science Global Certification You Have Done And Would Like To Recommend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vz9vc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682233397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any Good Data Science Global Certification You Have Done recently And Would Like To Recommend? &lt;/p&gt;\n\n&lt;p&gt;Bring it on!\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vz9vc", "is_robot_indexable": true, "report_reasons": null, "author": "1st_human", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vz9vc/any_good_data_science_global_certification_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vz9vc/any_good_data_science_global_certification_you/", "subreddit_subscribers": 878932, "created_utc": 1682233397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I cannot seem to find a comprehensive set of this data anywhere. Maybe someone here has an idea where I can find or point me to where I can start scraping! Thanks!!", "author_fullname": "t2_fz1sc7fh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Balon D'or data complete with voting data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12vrh1k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682214925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I cannot seem to find a comprehensive set of this data anywhere. Maybe someone here has an idea where I can find or point me to where I can start scraping! Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vrh1k", "is_robot_indexable": true, "report_reasons": null, "author": "gunkshart", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vrh1k/balon_dor_data_complete_with_voting_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12vrh1k/balon_dor_data_complete_with_voting_data/", "subreddit_subscribers": 878932, "created_utc": 1682214925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8n5hmj1gq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Generate Fake Images that Look Real with Just a Few Lines of Code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_12vbzpp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FIIcfs6TlDzKM3DyRalK3CJDzrf31swn--55zwRPfrI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682182473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/p/1eaea5769e2c", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?auto=webp&amp;v=enabled&amp;s=6a7df6f8eef838e51cec0364000963a309cd0d5e", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ff9a527a6230bdf677f4552891883222cfd5564", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8645b8bb339c712d2ec5e7c0928d45158b01eab3", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b0eea5cd15fbfae11ed8cc3b2cbd3d7036ff4d5", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fe102408f1e91ca5d2414624faf2352e9a46d80", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89c27ec64d6598db41a503ba1264ad669e6033e9", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/UDOhFVzYfP__mKLjiCHW7m5Ejij81piPGfy_6Drqzkc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=903c1210ab1bb8647ce8320201602153752fa90a", "width": 1080, "height": 720}], "variants": {}, "id": "UjeJjO1zCxH5XvPNH0FUWokVc-iXNE9Q_HuclqbS980"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "12vbzpp", "is_robot_indexable": true, "report_reasons": null, "author": "MagazinePerfect9021", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12vbzpp/how_to_generate_fake_images_that_look_real_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/p/1eaea5769e2c", "subreddit_subscribers": 878932, "created_utc": 1682182473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm running a mentorship platform and trying to figure out what data scientists need a mentor for. If you are a data scientist, why would you want to talk to a mentor?", "author_fullname": "t2_kv63zgqt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do data scientists need mentorship about?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12v9xi7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682178416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m running a mentorship platform and trying to figure out what data scientists need a mentor for. If you are a data scientist, why would you want to talk to a mentor?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "12v9xi7", "is_robot_indexable": true, "report_reasons": null, "author": "mentordial", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/12v9xi7/what_do_data_scientists_need_mentorship_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/12v9xi7/what_do_data_scientists_need_mentorship_about/", "subreddit_subscribers": 878932, "created_utc": 1682178416.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}