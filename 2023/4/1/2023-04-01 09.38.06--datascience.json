{"kind": "Listing", "data": {"after": "t3_127m9ku", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Over the last year, I've noticed a drastic influx of how many Business Leaders/Managers and also Software Engineers refer to everyone in the data space as an analyst. Be it a machine learning engineer, data scientist, data analyst, data engineer, decision scientist, whatever - they're  all being labeled as analysts. \n\nThis is sticking out to me because previously people were better at making distinctions between the titles/roles. \n\nMakes me wonder a few things:\n* Am I the only one seeing this?\n* Could this be a result in how the overlap between the work of each of these roles has increased significantly? \n* Maybe this is just people getting tired of using more specific labels?\n* Could be toxic people trying to downplay data science, IE: \"Analytics is the new IT help desk:\n\nWhat do other people here think?\n\n\nEdit for claritifcation: I'm more specifically addressing situations where someone has the tittle/position of Data Scientist or Machine Learning Engineer but is then frequently refered to as an analyst in many internal communications.", "author_fullname": "t2_6xucvfham", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Noticing increase in frequency of DS/ MLE being called analysts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127p4tp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 104, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 104, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680280332.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680276700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Over the last year, I&amp;#39;ve noticed a drastic influx of how many Business Leaders/Managers and also Software Engineers refer to everyone in the data space as an analyst. Be it a machine learning engineer, data scientist, data analyst, data engineer, decision scientist, whatever - they&amp;#39;re  all being labeled as analysts. &lt;/p&gt;\n\n&lt;p&gt;This is sticking out to me because previously people were better at making distinctions between the titles/roles. &lt;/p&gt;\n\n&lt;p&gt;Makes me wonder a few things:\n* Am I the only one seeing this?\n* Could this be a result in how the overlap between the work of each of these roles has increased significantly? \n* Maybe this is just people getting tired of using more specific labels?\n* Could be toxic people trying to downplay data science, IE: &amp;quot;Analytics is the new IT help desk:&lt;/p&gt;\n\n&lt;p&gt;What do other people here think?&lt;/p&gt;\n\n&lt;p&gt;Edit for claritifcation: I&amp;#39;m more specifically addressing situations where someone has the tittle/position of Data Scientist or Machine Learning Engineer but is then frequently refered to as an analyst in many internal communications.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127p4tp", "is_robot_indexable": true, "report_reasons": null, "author": "aGuyAndHisWood", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127p4tp/noticing_increase_in_frequency_of_ds_mle_being/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127p4tp/noticing_increase_in_frequency_of_ds_mle_being/", "subreddit_subscribers": 865967, "created_utc": 1680276700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My manager is not from ML background, he is a chemical engineer. So when I present any ML algorithm e.g. random forest, he just go deeper how it works under the hood and keep going in till he understands the very minute details.this takes lots of my time to explain everything to him.\nIs it normal for all non ML people?", "author_fullname": "t2_lrllrd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is your manager learning from you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_128966f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680318058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My manager is not from ML background, he is a chemical engineer. So when I present any ML algorithm e.g. random forest, he just go deeper how it works under the hood and keep going in till he understands the very minute details.this takes lots of my time to explain everything to him.\nIs it normal for all non ML people?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "128966f", "is_robot_indexable": true, "report_reasons": null, "author": "vishal-vora", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/128966f/is_your_manager_learning_from_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/128966f/is_your_manager_learning_from_you/", "subreddit_subscribers": 865967, "created_utc": 1680318058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Choosing a platform that can scale, offer persistent flexibility, and support company operations is crucial as businesses embrace cloud computing. Leading cloud platforms, Databricks and Snowflake, enable businesses to consume, examine, and manage massive amounts of data.\n\nOrganizations need a mechanism to gather all the data they need to evaluate in one location where it can be ready for data mining as the amount of data to be studied grows gradually. Undoubtedly, the acclaimed cloud-based data systems Snowflake and Databricks are industry leaders. Which data platform, however, is ideal for your company? Let\u2019s compare various essential aspects of these platforms below:  \n\n\n[Databricks vs. Snowflake \\(2023\\)](https://preview.redd.it/zt044hotm2ra1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f8fe76b02307c1abdfc299e2472835bac89153a5)\n\nDespite Snowflake and Databricks having certain similarities, one is oriented towards data lakes while the other offers the viewpoint of a data warehouse. Snowflake offers the finest performance and is most suitable for business intelligence applications that resemble SQL. Contrarily, Databricks provides Delta Lake and support for various programming languages, enabling you to create your data science use cases using any tools and frameworks.Hope this helps!!!", "author_fullname": "t2_tq8la0cj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Top Data Platforms: Databricks vs. Snowflakes!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zt044hotm2ra1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 123, "x": 108, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=23d133e47c8fd1526a63fdfed8123df2db3001db"}, {"y": 247, "x": 216, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53c8b98ecdb9bcb63cf3446472b2e72e39a85088"}, {"y": 366, "x": 320, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea339b44efd8a4859b07cf8bbc02edc52cdc43f9"}, {"y": 733, "x": 640, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21823700369ccbb93c61d19037ea26dffde79f87"}, {"y": 1100, "x": 960, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19b8880ed14fafd94437ea9c7aa23abb3c4183b9"}, {"y": 1237, "x": 1080, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c541194082b02287e2ff445b340e1bba25d79c5e"}], "s": {"y": 2200, "x": 1920, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f8fe76b02307c1abdfc299e2472835bac89153a5"}, "id": "zt044hotm2ra1"}}, "name": "t3_127kh22", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/GQg0MfLRqzb3nHSYPv3bwX_BB217RRZ0xcDhS7O-pQ0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680267010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Choosing a platform that can scale, offer persistent flexibility, and support company operations is crucial as businesses embrace cloud computing. Leading cloud platforms, Databricks and Snowflake, enable businesses to consume, examine, and manage massive amounts of data.&lt;/p&gt;\n\n&lt;p&gt;Organizations need a mechanism to gather all the data they need to evaluate in one location where it can be ready for data mining as the amount of data to be studied grows gradually. Undoubtedly, the acclaimed cloud-based data systems Snowflake and Databricks are industry leaders. Which data platform, however, is ideal for your company? Let\u2019s compare various essential aspects of these platforms below:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zt044hotm2ra1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f8fe76b02307c1abdfc299e2472835bac89153a5\"&gt;Databricks vs. Snowflake (2023)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Despite Snowflake and Databricks having certain similarities, one is oriented towards data lakes while the other offers the viewpoint of a data warehouse. Snowflake offers the finest performance and is most suitable for business intelligence applications that resemble SQL. Contrarily, Databricks provides Delta Lake and support for various programming languages, enabling you to create your data science use cases using any tools and frameworks.Hope this helps!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127kh22", "is_robot_indexable": true, "report_reasons": null, "author": "StartupDriver", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127kh22/top_data_platforms_databricks_vs_snowflakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127kh22/top_data_platforms_databricks_vs_snowflakes/", "subreddit_subscribers": 865967, "created_utc": 1680267010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys,\n\nAt my job, we're working on a cross-selling model between different products, and we (between ds) have a different opinion on how to handle things and I haven't been able to find litterature to help with our problem.\n\nSo the thing is that I have the situation of our customers at different times (like every month).\n\nSituation is defined as : their age, if they bought something the last month, if they are premium customers or not, ... and so I only have binary data except for the age.\n\nSo in my dataset you have this situation and then our target variable 0 if they bought something in the next month, and 1 if they didn't. Thus in the whole dataset, if taken for a year, every customer appears 12 times (except those who joined in along but let's not care about this). The problem is highly unbalanced (many more target variables 0 than 1). The problem for my colleague is that people appear multiple times. For me, it's not a problem as we're not looking at specific individuals but rather learn from their behaviour. So my stance is that I remove complete duplicate observations of the same people (so if they're 23, they didn't buy anything in the last month, they're not premium and they didn't buy anything in the coming month, and then the next month it's the same, I only keep 1 record), but if their situation changes, then I keep the different records. The stance of my colleague is to keep every observation where the target is 1, then for the observations where the target is 0, for each customer you randomly select 1 observation, and keep it in your dataset. It doesn't sound good for me as you're discarding everything about the fact that the behaviour of people changes over time with respect to their situation ? So my colleague's saying that 'imagine that you're 30, and then in the next observation you're 31, it's not going to change anything', but it's actually the whole point if your target is correlated with the age ? I'm in a more junior position so I feel like people would rather listen to him but to me it just sounds bad ? I've never heard in my 6 years of Uni of anything like that, but then again I'm a junior so...\n\nOn the same page, in this model, the goal in the end is to launch a marketing campaign targeted to people who are more likely to buy. The marketing campaign takes 2 weeks to set up. So he wants us to look for the target variables not in the whole month but only in the last two weeks as for those that convert in the first two weeks after we've seen their situation, it'll be too late. I get the point, but then again, I've never heard of anything like that and when I search for this I don't find anything (he speaks of holdout periods but when you search for holdout in a dataset, that's not what it means). But in our case, it's too late if the customer converted elsewhere in the first two weeks, but other than that it's never \"too late\" (our products are not things that you buy often).\n\nAny opinion on this ? I'm not sure who's in the wrong there, it just doesn't feel right with me and I haven't found something very meaningful when looking it up on the Internet. If my colleague reads this, see you next week !", "author_fullname": "t2_89r3kr5fu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dealing with multiple observations of same people in your dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127tf4q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680285217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;At my job, we&amp;#39;re working on a cross-selling model between different products, and we (between ds) have a different opinion on how to handle things and I haven&amp;#39;t been able to find litterature to help with our problem.&lt;/p&gt;\n\n&lt;p&gt;So the thing is that I have the situation of our customers at different times (like every month).&lt;/p&gt;\n\n&lt;p&gt;Situation is defined as : their age, if they bought something the last month, if they are premium customers or not, ... and so I only have binary data except for the age.&lt;/p&gt;\n\n&lt;p&gt;So in my dataset you have this situation and then our target variable 0 if they bought something in the next month, and 1 if they didn&amp;#39;t. Thus in the whole dataset, if taken for a year, every customer appears 12 times (except those who joined in along but let&amp;#39;s not care about this). The problem is highly unbalanced (many more target variables 0 than 1). The problem for my colleague is that people appear multiple times. For me, it&amp;#39;s not a problem as we&amp;#39;re not looking at specific individuals but rather learn from their behaviour. So my stance is that I remove complete duplicate observations of the same people (so if they&amp;#39;re 23, they didn&amp;#39;t buy anything in the last month, they&amp;#39;re not premium and they didn&amp;#39;t buy anything in the coming month, and then the next month it&amp;#39;s the same, I only keep 1 record), but if their situation changes, then I keep the different records. The stance of my colleague is to keep every observation where the target is 1, then for the observations where the target is 0, for each customer you randomly select 1 observation, and keep it in your dataset. It doesn&amp;#39;t sound good for me as you&amp;#39;re discarding everything about the fact that the behaviour of people changes over time with respect to their situation ? So my colleague&amp;#39;s saying that &amp;#39;imagine that you&amp;#39;re 30, and then in the next observation you&amp;#39;re 31, it&amp;#39;s not going to change anything&amp;#39;, but it&amp;#39;s actually the whole point if your target is correlated with the age ? I&amp;#39;m in a more junior position so I feel like people would rather listen to him but to me it just sounds bad ? I&amp;#39;ve never heard in my 6 years of Uni of anything like that, but then again I&amp;#39;m a junior so...&lt;/p&gt;\n\n&lt;p&gt;On the same page, in this model, the goal in the end is to launch a marketing campaign targeted to people who are more likely to buy. The marketing campaign takes 2 weeks to set up. So he wants us to look for the target variables not in the whole month but only in the last two weeks as for those that convert in the first two weeks after we&amp;#39;ve seen their situation, it&amp;#39;ll be too late. I get the point, but then again, I&amp;#39;ve never heard of anything like that and when I search for this I don&amp;#39;t find anything (he speaks of holdout periods but when you search for holdout in a dataset, that&amp;#39;s not what it means). But in our case, it&amp;#39;s too late if the customer converted elsewhere in the first two weeks, but other than that it&amp;#39;s never &amp;quot;too late&amp;quot; (our products are not things that you buy often).&lt;/p&gt;\n\n&lt;p&gt;Any opinion on this ? I&amp;#39;m not sure who&amp;#39;s in the wrong there, it just doesn&amp;#39;t feel right with me and I haven&amp;#39;t found something very meaningful when looking it up on the Internet. If my colleague reads this, see you next week !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127tf4q", "is_robot_indexable": true, "report_reasons": null, "author": "somedsguy", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127tf4q/dealing_with_multiple_observations_of_same_people/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127tf4q/dealing_with_multiple_observations_of_same_people/", "subreddit_subscribers": 865967, "created_utc": 1680285217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How many hours a week are you in meetings, speaking with stakeholders or coworkers, or generally collaborating with them?", "author_fullname": "t2_ft3xv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much of your day is spent working with coworkers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127ty38", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680286241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How many hours a week are you in meetings, speaking with stakeholders or coworkers, or generally collaborating with them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127ty38", "is_robot_indexable": true, "report_reasons": null, "author": "ave416", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127ty38/how_much_of_your_day_is_spent_working_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127ty38/how_much_of_your_day_is_spent_working_with/", "subreddit_subscribers": 865967, "created_utc": 1680286241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Long story short: I decided to change careers because I enjoyed the data aspects of my psychology undegraduate program.", "author_fullname": "t2_2avd4wfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will having a BA in psychology hinder my chances of getting a data analyst/science job if I'm currently pursuing an MS in Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_128b2xm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680323242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short: I decided to change careers because I enjoyed the data aspects of my psychology undegraduate program.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "128b2xm", "is_robot_indexable": true, "report_reasons": null, "author": "Javilism", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/128b2xm/will_having_a_ba_in_psychology_hinder_my_chances/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/128b2xm/will_having_a_ba_in_psychology_hinder_my_chances/", "subreddit_subscribers": 865967, "created_utc": 1680323242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, thanks for any help on this!\n\nI'm doing a decent number of bespoke analyses with short shelf lives and fast turn-arounds. Most of my Python scripts are not reusable and tailored to the data and problem at hand. They marry multiple datasets and pass them through multiple calculation steps, sometimes using third-party services or optimization models, so there are many potential points of failure.\n\nI want to be confident in what I'm turning around and we don't have anyone available as an outside reviewer. Are there best practices or particular Python packages that I could turn to for better confidence in my results? I'm concerned about everything from data quality to fat-finger mistakes.\n\nThanks all for any and all suggestions!", "author_fullname": "t2_saoea", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing best practices for data analysis in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127p7ug", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680276866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, thanks for any help on this!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m doing a decent number of bespoke analyses with short shelf lives and fast turn-arounds. Most of my Python scripts are not reusable and tailored to the data and problem at hand. They marry multiple datasets and pass them through multiple calculation steps, sometimes using third-party services or optimization models, so there are many potential points of failure.&lt;/p&gt;\n\n&lt;p&gt;I want to be confident in what I&amp;#39;m turning around and we don&amp;#39;t have anyone available as an outside reviewer. Are there best practices or particular Python packages that I could turn to for better confidence in my results? I&amp;#39;m concerned about everything from data quality to fat-finger mistakes.&lt;/p&gt;\n\n&lt;p&gt;Thanks all for any and all suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127p7ug", "is_robot_indexable": true, "report_reasons": null, "author": "ultreian", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127p7ug/testing_best_practices_for_data_analysis_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127p7ug/testing_best_practices_for_data_analysis_in_python/", "subreddit_subscribers": 865967, "created_utc": 1680276866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am thinking in studying this, some say NLP will decrease as GPT can beat most of NLP tasks in a low cost. What do you say?", "author_fullname": "t2_w7ap5hsy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think NLP will increase with LLM models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1289p4d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680319457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thinking in studying this, some say NLP will decrease as GPT can beat most of NLP tasks in a low cost. What do you say?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1289p4d", "is_robot_indexable": true, "report_reasons": null, "author": "Muted_Standard175", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1289p4d/do_you_think_nlp_will_increase_with_llm_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1289p4d/do_you_think_nlp_will_increase_with_llm_models/", "subreddit_subscribers": 865967, "created_utc": 1680319457.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "News just released via [this Tweet](https://twitter.com/TwitterEng/status/1641872259320274944?t=OGxvSuB9SLO2nUmfA-esIA&amp;s=19).\n\nSource code here: https://github.com/twitter/the-algorithm\n\nI just listened to Elon Musk and Twitter Engineering talk about it on [this Twitter space](https://twitter.com/i/spaces/1jMJgLdenVjxL).", "author_fullname": "t2_8yxss60i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "News: Twitter algorithm now open source", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127xfhk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680293087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;News just released via &lt;a href=\"https://twitter.com/TwitterEng/status/1641872259320274944?t=OGxvSuB9SLO2nUmfA-esIA&amp;amp;s=19\"&gt;this Tweet&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Source code here: &lt;a href=\"https://github.com/twitter/the-algorithm\"&gt;https://github.com/twitter/the-algorithm&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I just listened to Elon Musk and Twitter Engineering talk about it on &lt;a href=\"https://twitter.com/i/spaces/1jMJgLdenVjxL\"&gt;this Twitter space&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WpPz8udYXLwrI7HEVMRxLGGIkcl58DT62-oa176dSEk.jpg?auto=webp&amp;v=enabled&amp;s=e6138600bd2e3b0b3f5e3d6b26cc4ffc8491a352", "width": 140, "height": 140}, "resolutions": [{"url": "https://external-preview.redd.it/WpPz8udYXLwrI7HEVMRxLGGIkcl58DT62-oa176dSEk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7934ffccafbc929e5465d6ddb4009847673137a", "width": 108, "height": 108}], "variants": {}, "id": "L5RrZHf601-ktBxxZ2Zqf9VG4ap_uQ5RXWhIuGDA25M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127xfhk", "is_robot_indexable": true, "report_reasons": null, "author": "John-The-Bomb-2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127xfhk/news_twitter_algorithm_now_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127xfhk/news_twitter_algorithm_now_open_source/", "subreddit_subscribers": 865967, "created_utc": 1680293087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nHow do you deal with interpreting/extracting feature importance when most of your features are engineered? \n\nFor instance one-hot encoding (Categorical feature A becomes A1, A2, A3, ...An where n is the number of values), feature importance would be A1, or A3 for example - do you interpret that as feature A is important, or just the specific value?\n\n\\*Same for other types of feature engineering, OHE was the easiest to demonstrate", "author_fullname": "t2_5hjxl4ya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature importance with feature engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127spfx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680283818.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;How do you deal with interpreting/extracting feature importance when most of your features are engineered? &lt;/p&gt;\n\n&lt;p&gt;For instance one-hot encoding (Categorical feature A becomes A1, A2, A3, ...An where n is the number of values), feature importance would be A1, or A3 for example - do you interpret that as feature A is important, or just the specific value?&lt;/p&gt;\n\n&lt;p&gt;*Same for other types of feature engineering, OHE was the easiest to demonstrate&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127spfx", "is_robot_indexable": true, "report_reasons": null, "author": "PlainPiano9", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127spfx/feature_importance_with_feature_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127spfx/feature_importance_with_feature_engineering/", "subreddit_subscribers": 865967, "created_utc": 1680283818.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI am a Ph.D Student at Arizona State University participating in a National Science Foundation innovation program designed to help us understand how businesses test and evaluate ML/ AI models in production. I am looking for ML Engineers / data scientists, analysts / product managers for a brief  15 minutes discussion. Please feel free to message me.\n\nThank you very much for your time and consideration.", "author_fullname": "t2_3erw4o06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ML test and evaluation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127x7u3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680292674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am a Ph.D Student at Arizona State University participating in a National Science Foundation innovation program designed to help us understand how businesses test and evaluate ML/ AI models in production. I am looking for ML Engineers / data scientists, analysts / product managers for a brief  15 minutes discussion. Please feel free to message me.&lt;/p&gt;\n\n&lt;p&gt;Thank you very much for your time and consideration.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127x7u3", "is_robot_indexable": true, "report_reasons": null, "author": "vineet0814", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127x7u3/ml_test_and_evaluation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127x7u3/ml_test_and_evaluation/", "subreddit_subscribers": 865967, "created_utc": 1680292674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Everyone\n\nI recently came across this wiki and github for Data Engineering - [https://dataengineering.wiki/Index](https://dataengineering.wiki/Index)\n\nIs there a similar one setup for Data Science and Machine Learning ? If so can anyone please send the links? Thank you!", "author_fullname": "t2_8441ts3p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wiki/Github for Data Science and Machine Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127kl35", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680267263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone&lt;/p&gt;\n\n&lt;p&gt;I recently came across this wiki and github for Data Engineering - &lt;a href=\"https://dataengineering.wiki/Index\"&gt;https://dataengineering.wiki/Index&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is there a similar one setup for Data Science and Machine Learning ? If so can anyone please send the links? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127kl35", "is_robot_indexable": true, "report_reasons": null, "author": "jest_123", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127kl35/wikigithub_for_data_science_and_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127kl35/wikigithub_for_data_science_and_machine_learning/", "subreddit_subscribers": 865967, "created_utc": 1680267263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey Data Scientists,\n\nSo I've searched this sub and only found a few posts concerning Jetbrain's IDE Dataspell. Mostly from when it was first released. Has anyone used it since? How is it for use in the domain it was built for compared to PyCharm and VS Code? I like using Jetbrain's IDEs and I'm working with a trial version but I would like to hear the community's opinion on it.\n\nThanks", "author_fullname": "t2_4b099", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is Dataspell for data engineering and analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1286qtp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680311771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Data Scientists,&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;ve searched this sub and only found a few posts concerning Jetbrain&amp;#39;s IDE Dataspell. Mostly from when it was first released. Has anyone used it since? How is it for use in the domain it was built for compared to PyCharm and VS Code? I like using Jetbrain&amp;#39;s IDEs and I&amp;#39;m working with a trial version but I would like to hear the community&amp;#39;s opinion on it.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1286qtp", "is_robot_indexable": true, "report_reasons": null, "author": "Eezyville", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1286qtp/how_is_dataspell_for_data_engineering_and_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1286qtp/how_is_dataspell_for_data_engineering_and_analysis/", "subreddit_subscribers": 865967, "created_utc": 1680311771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I will do a ML modeling take-home assignment for a bank. This is to test my tech- and clean-coding skills + ability to present a business case. It is a toy dataset, which doesn't require extensive DS or software skills, but I want to do my best. Do you have any advice on what to show off or focus on in both aspects?   \nhere is my thought dump so far:  \n\\- on the dev side: DVC, pre-commit hooks, readme, docstrings &amp; type hints, unit-tests (mock ups), OOP for working with the dataset   \n\\- for ML part: explorative analysis, checking collinearity, PCA, possibly data augmentation, exploring several models (xgb) , ROC curves, experiments tracking in tensorboard or local MLflow database  \n\\- for presentation: visualization with Dash, possibly deployed somewhere + regular pptx slides   \n\\- for business: use-case, solution, explain significant features, precision\\\\recall curves and their financial effect, potential improvements ideas\n\nAnything else you can think of? The role also assumes some cloud and DE knowledge, but for this task and dataset any orchestration, AutoML or Spark would be a huge overkill. Also, how to balance between technical and business aspects properly?  \nP.S.I was thinking if it is better to switch regular pptx to a jupyter notebook for reporting, but I am not a fan of those either, so better stay normal here.", "author_fullname": "t2_f3y80e7s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice what to focus on in a take-home assignment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_128fovr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680337208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will do a ML modeling take-home assignment for a bank. This is to test my tech- and clean-coding skills + ability to present a business case. It is a toy dataset, which doesn&amp;#39;t require extensive DS or software skills, but I want to do my best. Do you have any advice on what to show off or focus on in both aspects?&lt;br/&gt;\nhere is my thought dump so far:&lt;br/&gt;\n- on the dev side: DVC, pre-commit hooks, readme, docstrings &amp;amp; type hints, unit-tests (mock ups), OOP for working with the dataset&lt;br/&gt;\n- for ML part: explorative analysis, checking collinearity, PCA, possibly data augmentation, exploring several models (xgb) , ROC curves, experiments tracking in tensorboard or local MLflow database&lt;br/&gt;\n- for presentation: visualization with Dash, possibly deployed somewhere + regular pptx slides&lt;br/&gt;\n- for business: use-case, solution, explain significant features, precision\\recall curves and their financial effect, potential improvements ideas&lt;/p&gt;\n\n&lt;p&gt;Anything else you can think of? The role also assumes some cloud and DE knowledge, but for this task and dataset any orchestration, AutoML or Spark would be a huge overkill. Also, how to balance between technical and business aspects properly?&lt;br/&gt;\nP.S.I was thinking if it is better to switch regular pptx to a jupyter notebook for reporting, but I am not a fan of those either, so better stay normal here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "128fovr", "is_robot_indexable": true, "report_reasons": null, "author": "docoja1739", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/128fovr/advice_what_to_focus_on_in_a_takehome_assignment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/128fovr/advice_what_to_focus_on_in_a_takehome_assignment/", "subreddit_subscribers": 865967, "created_utc": 1680337208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am a newbie data analyst and am required to work with Prescriptions drug data for USA. I have checked CMS site and also know about IQVIA Xponent. Is there any other way to get data from? Any sort of guidance will help.\n\nThanks.", "author_fullname": "t2_8978bk8q5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to find publicly available datasets for Healthcare industry belonging to USA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_128dkpv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680330588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am a newbie data analyst and am required to work with Prescriptions drug data for USA. I have checked CMS site and also know about IQVIA Xponent. Is there any other way to get data from? Any sort of guidance will help.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "128dkpv", "is_robot_indexable": true, "report_reasons": null, "author": "sanabhatkar_dsml", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/128dkpv/where_to_find_publicly_available_datasets_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/128dkpv/where_to_find_publicly_available_datasets_for/", "subreddit_subscribers": 865967, "created_utc": 1680330588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, I'm trying to build a tool that uses a GPT model to generate queries based on my organization's data context. Some of our tables have pretty complicated schemas with similar column names. Also given some queries might be pretty complicated, the gpt-3 token limit could pose an issue. I've explored embeddings and storing them in a vector database, but I'm not too sure yet if the retrieved vectors make sense semantically when fed into the model. \nDoes anyone here have experience with using GPT-3 to create context-driven queries? Would love to hear your approaches.", "author_fullname": "t2_610eusu7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using GPT3 to create context driven queries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1288veo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680317254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I&amp;#39;m trying to build a tool that uses a GPT model to generate queries based on my organization&amp;#39;s data context. Some of our tables have pretty complicated schemas with similar column names. Also given some queries might be pretty complicated, the gpt-3 token limit could pose an issue. I&amp;#39;ve explored embeddings and storing them in a vector database, but I&amp;#39;m not too sure yet if the retrieved vectors make sense semantically when fed into the model. \nDoes anyone here have experience with using GPT-3 to create context-driven queries? Would love to hear your approaches.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1288veo", "is_robot_indexable": true, "report_reasons": null, "author": "moonwalker0202", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1288veo/using_gpt3_to_create_context_driven_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1288veo/using_gpt3_to_create_context_driven_queries/", "subreddit_subscribers": 865967, "created_utc": 1680317254.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im actually a \u201cbusiness\u201d analyst, not in data science or an IT org by any means. Ive been doing business analytics for about 5 years in various roles with the same company. My team specifically is pretty early in its analytic maturity and the need for more robust data cleaning to deal with shit inputs into source applications is only getting more painful as my greater department grows, bandaids old problems, and creates new ones.  \n\nIts becoming very obvious (at least to me) the need for tighter data controls and formalized ETLs into centralized databases, and becoming comfortable with direct API calls is basically required if we\u2019re going to grow. Here\u2019s the problem, im a business analyst and if any of this is going to be worked on I need to effectively \u201chire\u201d our central IT department to do any of the work. What I felt was going to be a slow build out of data pipelines and warehouses, by our team for our team, is actually a multi-year double comma budget project that im basically just writing requirement docs for and HOPING nothing on my end changes while IT resources are building the solution. \n\nSo I ask, r/DataScience, where does your team sit in this corporate ecosystem? Im actually dumb founded how any advanced analytics or long term efficiencies can be delivered if Im not able to have the flexibility to build my own pipelines and databases.", "author_fullname": "t2_9bpo6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where is your role in your organizations structure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1282v3l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680303640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im actually a \u201cbusiness\u201d analyst, not in data science or an IT org by any means. Ive been doing business analytics for about 5 years in various roles with the same company. My team specifically is pretty early in its analytic maturity and the need for more robust data cleaning to deal with shit inputs into source applications is only getting more painful as my greater department grows, bandaids old problems, and creates new ones.  &lt;/p&gt;\n\n&lt;p&gt;Its becoming very obvious (at least to me) the need for tighter data controls and formalized ETLs into centralized databases, and becoming comfortable with direct API calls is basically required if we\u2019re going to grow. Here\u2019s the problem, im a business analyst and if any of this is going to be worked on I need to effectively \u201chire\u201d our central IT department to do any of the work. What I felt was going to be a slow build out of data pipelines and warehouses, by our team for our team, is actually a multi-year double comma budget project that im basically just writing requirement docs for and HOPING nothing on my end changes while IT resources are building the solution. &lt;/p&gt;\n\n&lt;p&gt;So I ask, &lt;a href=\"/r/DataScience\"&gt;r/DataScience&lt;/a&gt;, where does your team sit in this corporate ecosystem? Im actually dumb founded how any advanced analytics or long term efficiencies can be delivered if Im not able to have the flexibility to build my own pipelines and databases.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1282v3l", "is_robot_indexable": true, "report_reasons": null, "author": "Rykios", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1282v3l/where_is_your_role_in_your_organizations_structure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1282v3l/where_is_your_role_in_your_organizations_structure/", "subreddit_subscribers": 865967, "created_utc": 1680303640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've done a paper survey of how well ChatGPT performs on various NLP tasks as reported in arXiv papers. I have found 19 papers where they compared ChatGPT with fine-tuned models, but they are being published practically daily now. It seems that for the most of the classical NLP tasks, ChatGPT is not actually that strong and smaller fine-tuned models are often much better. According to the API page, GPT-4 is not expected to be much stronger on tasks like these. I think it is an interesting perspective that shows that for many of the tasks we need to solve, GPT models are actually not the right tool.\n\nThe full survey is in my blog post: [http://opensamizdat.com/posts/chatgpt\\_survey/](http://opensamizdat.com/posts/chatgpt_survey/)\n\nAny feedback is welcomed.", "author_fullname": "t2_2lyqh3jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ChatGPT Survey: Performance on NLP datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127qs9h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680279976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve done a paper survey of how well ChatGPT performs on various NLP tasks as reported in arXiv papers. I have found 19 papers where they compared ChatGPT with fine-tuned models, but they are being published practically daily now. It seems that for the most of the classical NLP tasks, ChatGPT is not actually that strong and smaller fine-tuned models are often much better. According to the API page, GPT-4 is not expected to be much stronger on tasks like these. I think it is an interesting perspective that shows that for many of the tasks we need to solve, GPT models are actually not the right tool.&lt;/p&gt;\n\n&lt;p&gt;The full survey is in my blog post: &lt;a href=\"http://opensamizdat.com/posts/chatgpt_survey/\"&gt;http://opensamizdat.com/posts/chatgpt_survey/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any feedback is welcomed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127qs9h", "is_robot_indexable": true, "report_reasons": null, "author": "matus_pikuliak", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127qs9h/chatgpt_survey_performance_on_nlp_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127qs9h/chatgpt_survey_performance_on_nlp_datasets/", "subreddit_subscribers": 865967, "created_utc": 1680279976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Thanks in advance for the help!\n\nOur goal is to generate groups of participants based on their vowel systems. Their vowel systems contain two nested variables:\u00a0\n\n1. The vowel class itself (there are 14 types, which are represented by words containing the vowel type e.g. \"dress\" and \"thought\")\u00a0\n2. The vowel coordinates, represented by 2 frequencies in the bark scale (a linearization of Hertz)  \nWe would like to run this through a divisive clustering analysis algorithm. If we change our data from this format (with nested variables):\n\nWe would like to run this through a divisive clustering analysis algorithm. If we change our data format from 14 dimensions with 2 subdimensions to 28 non-linked dimensions and input that into a clustering algorithm, do we lose anything of significance? If so, is there another method you know of that we can use?\n\nThanks :)", "author_fullname": "t2_q2907eyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to sort participants into groups according to nested variables? Divisive Clustering analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127oj2m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680275498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thanks in advance for the help!&lt;/p&gt;\n\n&lt;p&gt;Our goal is to generate groups of participants based on their vowel systems. Their vowel systems contain two nested variables:\u00a0&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The vowel class itself (there are 14 types, which are represented by words containing the vowel type e.g. &amp;quot;dress&amp;quot; and &amp;quot;thought&amp;quot;)\u00a0&lt;/li&gt;\n&lt;li&gt;The vowel coordinates, represented by 2 frequencies in the bark scale (a linearization of Hertz)&lt;br/&gt;\nWe would like to run this through a divisive clustering analysis algorithm. If we change our data from this format (with nested variables):&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We would like to run this through a divisive clustering analysis algorithm. If we change our data format from 14 dimensions with 2 subdimensions to 28 non-linked dimensions and input that into a clustering algorithm, do we lose anything of significance? If so, is there another method you know of that we can use?&lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127oj2m", "is_robot_indexable": true, "report_reasons": null, "author": "kovidwithaK", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127oj2m/how_to_sort_participants_into_groups_according_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127oj2m/how_to_sort_participants_into_groups_according_to/", "subreddit_subscribers": 865967, "created_utc": 1680275498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hope you are doing well, I would be grateful if you could review my notebooks and give your constructive feedback.\n\n[https://www.kaggle.com/abmsayem/code](https://www.kaggle.com/abmsayem/code)", "author_fullname": "t2_4oeq7ean1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Review: Help me Improve my Notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_128cr9d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680328082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hope you are doing well, I would be grateful if you could review my notebooks and give your constructive feedback.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.kaggle.com/abmsayem/code\"&gt;https://www.kaggle.com/abmsayem/code&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "128cr9d", "is_robot_indexable": true, "report_reasons": null, "author": "abmsayem", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/128cr9d/looking_for_review_help_me_improve_my_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/128cr9d/looking_for_review_help_me_improve_my_notebooks/", "subreddit_subscribers": 865967, "created_utc": 1680328082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, apologies for any ignorance this post shows and if this may be an obvious or 'search engine' question as the rules state. If it is I will try to figure it out elsewhere.   \n\n\nThat said, I'd love to hear from people with a trove of experience in data science. I just graduated with a degree in Anthropology / archaeology, and while I did my degree I did quite a bit of work in GIS. I was able to skate by in my GIS courses and a grad GIS course with no coding skills (save for a few copy paste codes for a few diff models) but I understand that to really stand out as a GIS analyst or GIS technician.   \n\n\nI'd love to have the option of either having a GIS analyst career, or be more competitive in the field of archaeology with a GIS analyst skillset. Knowing those things, what path would you all suggest in terms of preparing for those career goals? I am getting an MSc in Digital Archaeology which has some GIS / data science components but is not strictly data science; is it possible to be competitive by pursuing certificates offered through universities?   \n\n\nThank you for any help!", "author_fullname": "t2_drm42vy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help figuring out what direction to go for building a data science skillset within the context of GIS analyses, please!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_128cfa7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680327076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, apologies for any ignorance this post shows and if this may be an obvious or &amp;#39;search engine&amp;#39; question as the rules state. If it is I will try to figure it out elsewhere.   &lt;/p&gt;\n\n&lt;p&gt;That said, I&amp;#39;d love to hear from people with a trove of experience in data science. I just graduated with a degree in Anthropology / archaeology, and while I did my degree I did quite a bit of work in GIS. I was able to skate by in my GIS courses and a grad GIS course with no coding skills (save for a few copy paste codes for a few diff models) but I understand that to really stand out as a GIS analyst or GIS technician.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to have the option of either having a GIS analyst career, or be more competitive in the field of archaeology with a GIS analyst skillset. Knowing those things, what path would you all suggest in terms of preparing for those career goals? I am getting an MSc in Digital Archaeology which has some GIS / data science components but is not strictly data science; is it possible to be competitive by pursuing certificates offered through universities?   &lt;/p&gt;\n\n&lt;p&gt;Thank you for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "128cfa7", "is_robot_indexable": true, "report_reasons": null, "author": "roy2roy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/128cfa7/help_figuring_out_what_direction_to_go_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/128cfa7/help_figuring_out_what_direction_to_go_for/", "subreddit_subscribers": 865967, "created_utc": 1680327076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi gurus,\n\nI came across this viz the other day &amp; really liked the presentation. It shows timeline of the data leaks in Australia and their sizes. Just wondering how would one create this chart? Thanks!  \n\n\nhttps://preview.redd.it/14ipljt1k7ra1.png?width=395&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=433c58e731707a84100cc260bf33cfa2290c57f6", "author_fullname": "t2_pv41s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to recreate this timeline/bubble chart?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"14ipljt1k7ra1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 185, "x": 108, "u": "https://preview.redd.it/14ipljt1k7ra1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adef128baf042c8d0cc7c21847338a730ee1168d"}, {"y": 370, "x": 216, "u": "https://preview.redd.it/14ipljt1k7ra1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2d1db6f765046c603e9aef20f64ffc773e513b83"}, {"y": 549, "x": 320, "u": "https://preview.redd.it/14ipljt1k7ra1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52d16f2adb7d3d10b696a1e7ba6668f55a610046"}], "s": {"y": 678, "x": 395, "u": "https://preview.redd.it/14ipljt1k7ra1.png?width=395&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=433c58e731707a84100cc260bf33cfa2290c57f6"}, "id": "14ipljt1k7ra1"}}, "name": "t3_128c9fk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9ImPbkyjnbu4avw1l1b356bn9CJN7RD3il23vZMwrMk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680326581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi gurus,&lt;/p&gt;\n\n&lt;p&gt;I came across this viz the other day &amp;amp; really liked the presentation. It shows timeline of the data leaks in Australia and their sizes. Just wondering how would one create this chart? Thanks!  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/14ipljt1k7ra1.png?width=395&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=433c58e731707a84100cc260bf33cfa2290c57f6\"&gt;https://preview.redd.it/14ipljt1k7ra1.png?width=395&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=433c58e731707a84100cc260bf33cfa2290c57f6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "128c9fk", "is_robot_indexable": true, "report_reasons": null, "author": "KooGuy3", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/128c9fk/how_to_recreate_this_timelinebubble_chart/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/128c9fk/how_to_recreate_this_timelinebubble_chart/", "subreddit_subscribers": 865967, "created_utc": 1680326581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_roxmtd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[R] P value in statistics explained under 5 min", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_128bhjy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/9QjYYGVwdAo?start=5&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"P value and hypothesis testing in statistics explained under 5 min!!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "P value and hypothesis testing in statistics explained under 5 min!!", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/9QjYYGVwdAo?start=5&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"P value and hypothesis testing in statistics explained under 5 min!!\"&gt;&lt;/iframe&gt;", "author_name": "Machine Learning With me", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/9QjYYGVwdAo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MLwithme1617"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/9QjYYGVwdAo?start=5&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"P value and hypothesis testing in statistics explained under 5 min!!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/128bhjy", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RfLbT9DRZ0hslUA9N-FO24GW7pB1U03aDwZOx42YB3s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680324390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=9QjYYGVwdAo&amp;t=5s", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZsSbJOD2bibyV0p9xqyWomXzllk4_IurYS4n430dpbQ.jpg?auto=webp&amp;v=enabled&amp;s=df9d76d791d984ee28c342621a51a47e01d327ef", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/ZsSbJOD2bibyV0p9xqyWomXzllk4_IurYS4n430dpbQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15da6a3b4c55b9832e58dbf89bb88e0c882e4a3b", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/ZsSbJOD2bibyV0p9xqyWomXzllk4_IurYS4n430dpbQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a88465e317969f17f278ebdf67cada19d0a0aa9", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/ZsSbJOD2bibyV0p9xqyWomXzllk4_IurYS4n430dpbQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fac9849eb2df6d802500619c072411097704e66", "width": 320, "height": 240}], "variants": {}, "id": "X9dBgppKj0NHlHYT8pHLNEG4e7DsiT5J0mgxJQZNwTw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "128bhjy", "is_robot_indexable": true, "report_reasons": null, "author": "MLwithMe1617", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/128bhjy/r_p_value_in_statistics_explained_under_5_min/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=9QjYYGVwdAo&amp;t=5s", "subreddit_subscribers": 865967, "created_utc": 1680324390.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "P value and hypothesis testing in statistics explained under 5 min!!", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/9QjYYGVwdAo?start=5&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"P value and hypothesis testing in statistics explained under 5 min!!\"&gt;&lt;/iframe&gt;", "author_name": "Machine Learning With me", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/9QjYYGVwdAo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MLwithme1617"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Somebody has some idea how to generate endpoints from unstructured text?", "author_fullname": "t2_89s519wzv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NLP endpoint generation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127t79t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680284787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Somebody has some idea how to generate endpoints from unstructured text?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127t79t", "is_robot_indexable": true, "report_reasons": null, "author": "Reasi98", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127t79t/nlp_endpoint_generation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127t79t/nlp_endpoint_generation/", "subreddit_subscribers": 865967, "created_utc": 1680284787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I get this error while loading an EBM model pickle file. Any hints and help to solve this error?", "author_fullname": "t2_85tjk7wh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't attribute EBMPreprocessor on", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127m9ku", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680270944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I get this error while loading an EBM model pickle file. Any hints and help to solve this error?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127m9ku", "is_robot_indexable": true, "report_reasons": null, "author": "Jebin1999", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127m9ku/cant_attribute_ebmpreprocessor_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127m9ku/cant_attribute_ebmpreprocessor_on/", "subreddit_subscribers": 865967, "created_utc": 1680270944.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}