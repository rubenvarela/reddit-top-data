{"kind": "Listing", "data": {"after": "t3_128bppl", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The pareto principle roughly states that you get 80% of value from 20% of the work. What jobs or skills in the data world get you the most income or monetary value?", "author_fullname": "t2_15k55n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What skills/jobs makes the most money in Data Science/Data Analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127fhc6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 208, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 208, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680253647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The pareto principle roughly states that you get 80% of value from 20% of the work. What jobs or skills in the data world get you the most income or monetary value?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127fhc6", "is_robot_indexable": true, "report_reasons": null, "author": "colouredzindagi", "discussion_type": null, "num_comments": 138, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127fhc6/what_skillsjobs_makes_the_most_money_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127fhc6/what_skillsjobs_makes_the_most_money_in_data/", "subreddit_subscribers": 865896, "created_utc": 1680253647.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Over the last year, I've noticed a drastic influx of how many Business Leaders/Managers and also Software Engineers refer to everyone in the data space as an analyst. Be it a machine learning engineer, data scientist, data analyst, data engineer, decision scientist, whatever - they're  all being labeled as analysts. \n\nThis is sticking out to me because previously people were better at making distinctions between the titles/roles. \n\nMakes me wonder a few things:\n* Am I the only one seeing this?\n* Could this be a result in how the overlap between the work of each of these roles has increased significantly? \n* Maybe this is just people getting tired of using more specific labels?\n* Could be toxic people trying to downplay data science, IE: \"Analytics is the new IT help desk:\n\nWhat do other people here think?\n\n\nEdit for claritifcation: I'm more specifically addressing situations where someone has the tittle/position of Data Scientist or Machine Learning Engineer but is then frequently refered to as an analyst in many internal communications.", "author_fullname": "t2_6xucvfham", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Noticing increase in frequency of DS/ MLE being called analysts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127p4tp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 92, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 92, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680280332.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680276700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Over the last year, I&amp;#39;ve noticed a drastic influx of how many Business Leaders/Managers and also Software Engineers refer to everyone in the data space as an analyst. Be it a machine learning engineer, data scientist, data analyst, data engineer, decision scientist, whatever - they&amp;#39;re  all being labeled as analysts. &lt;/p&gt;\n\n&lt;p&gt;This is sticking out to me because previously people were better at making distinctions between the titles/roles. &lt;/p&gt;\n\n&lt;p&gt;Makes me wonder a few things:\n* Am I the only one seeing this?\n* Could this be a result in how the overlap between the work of each of these roles has increased significantly? \n* Maybe this is just people getting tired of using more specific labels?\n* Could be toxic people trying to downplay data science, IE: &amp;quot;Analytics is the new IT help desk:&lt;/p&gt;\n\n&lt;p&gt;What do other people here think?&lt;/p&gt;\n\n&lt;p&gt;Edit for claritifcation: I&amp;#39;m more specifically addressing situations where someone has the tittle/position of Data Scientist or Machine Learning Engineer but is then frequently refered to as an analyst in many internal communications.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127p4tp", "is_robot_indexable": true, "report_reasons": null, "author": "aGuyAndHisWood", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127p4tp/noticing_increase_in_frequency_of_ds_mle_being/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127p4tp/noticing_increase_in_frequency_of_ds_mle_being/", "subreddit_subscribers": 865896, "created_utc": 1680276700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Choosing a platform that can scale, offer persistent flexibility, and support company operations is crucial as businesses embrace cloud computing. Leading cloud platforms, Databricks and Snowflake, enable businesses to consume, examine, and manage massive amounts of data.\n\nOrganizations need a mechanism to gather all the data they need to evaluate in one location where it can be ready for data mining as the amount of data to be studied grows gradually. Undoubtedly, the acclaimed cloud-based data systems Snowflake and Databricks are industry leaders. Which data platform, however, is ideal for your company? Let\u2019s compare various essential aspects of these platforms below:  \n\n\n[Databricks vs. Snowflake \\(2023\\)](https://preview.redd.it/zt044hotm2ra1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f8fe76b02307c1abdfc299e2472835bac89153a5)\n\nDespite Snowflake and Databricks having certain similarities, one is oriented towards data lakes while the other offers the viewpoint of a data warehouse. Snowflake offers the finest performance and is most suitable for business intelligence applications that resemble SQL. Contrarily, Databricks provides Delta Lake and support for various programming languages, enabling you to create your data science use cases using any tools and frameworks.Hope this helps!!!", "author_fullname": "t2_tq8la0cj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Top Data Platforms: Databricks vs. Snowflakes!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zt044hotm2ra1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 123, "x": 108, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=23d133e47c8fd1526a63fdfed8123df2db3001db"}, {"y": 247, "x": 216, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53c8b98ecdb9bcb63cf3446472b2e72e39a85088"}, {"y": 366, "x": 320, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea339b44efd8a4859b07cf8bbc02edc52cdc43f9"}, {"y": 733, "x": 640, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21823700369ccbb93c61d19037ea26dffde79f87"}, {"y": 1100, "x": 960, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19b8880ed14fafd94437ea9c7aa23abb3c4183b9"}, {"y": 1237, "x": 1080, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c541194082b02287e2ff445b340e1bba25d79c5e"}], "s": {"y": 2200, "x": 1920, "u": "https://preview.redd.it/zt044hotm2ra1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f8fe76b02307c1abdfc299e2472835bac89153a5"}, "id": "zt044hotm2ra1"}}, "name": "t3_127kh22", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/GQg0MfLRqzb3nHSYPv3bwX_BB217RRZ0xcDhS7O-pQ0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680267010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Choosing a platform that can scale, offer persistent flexibility, and support company operations is crucial as businesses embrace cloud computing. Leading cloud platforms, Databricks and Snowflake, enable businesses to consume, examine, and manage massive amounts of data.&lt;/p&gt;\n\n&lt;p&gt;Organizations need a mechanism to gather all the data they need to evaluate in one location where it can be ready for data mining as the amount of data to be studied grows gradually. Undoubtedly, the acclaimed cloud-based data systems Snowflake and Databricks are industry leaders. Which data platform, however, is ideal for your company? Let\u2019s compare various essential aspects of these platforms below:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zt044hotm2ra1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f8fe76b02307c1abdfc299e2472835bac89153a5\"&gt;Databricks vs. Snowflake (2023)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Despite Snowflake and Databricks having certain similarities, one is oriented towards data lakes while the other offers the viewpoint of a data warehouse. Snowflake offers the finest performance and is most suitable for business intelligence applications that resemble SQL. Contrarily, Databricks provides Delta Lake and support for various programming languages, enabling you to create your data science use cases using any tools and frameworks.Hope this helps!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127kh22", "is_robot_indexable": true, "report_reasons": null, "author": "StartupDriver", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127kh22/top_data_platforms_databricks_vs_snowflakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127kh22/top_data_platforms_databricks_vs_snowflakes/", "subreddit_subscribers": 865896, "created_utc": 1680267010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys,\n\nAt my job, we're working on a cross-selling model between different products, and we (between ds) have a different opinion on how to handle things and I haven't been able to find litterature to help with our problem.\n\nSo the thing is that I have the situation of our customers at different times (like every month).\n\nSituation is defined as : their age, if they bought something the last month, if they are premium customers or not, ... and so I only have binary data except for the age.\n\nSo in my dataset you have this situation and then our target variable 0 if they bought something in the next month, and 1 if they didn't. Thus in the whole dataset, if taken for a year, every customer appears 12 times (except those who joined in along but let's not care about this). The problem is highly unbalanced (many more target variables 0 than 1). The problem for my colleague is that people appear multiple times. For me, it's not a problem as we're not looking at specific individuals but rather learn from their behaviour. So my stance is that I remove complete duplicate observations of the same people (so if they're 23, they didn't buy anything in the last month, they're not premium and they didn't buy anything in the coming month, and then the next month it's the same, I only keep 1 record), but if their situation changes, then I keep the different records. The stance of my colleague is to keep every observation where the target is 1, then for the observations where the target is 0, for each customer you randomly select 1 observation, and keep it in your dataset. It doesn't sound good for me as you're discarding everything about the fact that the behaviour of people changes over time with respect to their situation ? So my colleague's saying that 'imagine that you're 30, and then in the next observation you're 31, it's not going to change anything', but it's actually the whole point if your target is correlated with the age ? I'm in a more junior position so I feel like people would rather listen to him but to me it just sounds bad ? I've never heard in my 6 years of Uni of anything like that, but then again I'm a junior so...\n\nOn the same page, in this model, the goal in the end is to launch a marketing campaign targeted to people who are more likely to buy. The marketing campaign takes 2 weeks to set up. So he wants us to look for the target variables not in the whole month but only in the last two weeks as for those that convert in the first two weeks after we've seen their situation, it'll be too late. I get the point, but then again, I've never heard of anything like that and when I search for this I don't find anything (he speaks of holdout periods but when you search for holdout in a dataset, that's not what it means). But in our case, it's too late if the customer converted elsewhere in the first two weeks, but other than that it's never \"too late\" (our products are not things that you buy often).\n\nAny opinion on this ? I'm not sure who's in the wrong there, it just doesn't feel right with me and I haven't found something very meaningful when looking it up on the Internet. If my colleague reads this, see you next week !", "author_fullname": "t2_89r3kr5fu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dealing with multiple observations of same people in your dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127tf4q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680285217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;At my job, we&amp;#39;re working on a cross-selling model between different products, and we (between ds) have a different opinion on how to handle things and I haven&amp;#39;t been able to find litterature to help with our problem.&lt;/p&gt;\n\n&lt;p&gt;So the thing is that I have the situation of our customers at different times (like every month).&lt;/p&gt;\n\n&lt;p&gt;Situation is defined as : their age, if they bought something the last month, if they are premium customers or not, ... and so I only have binary data except for the age.&lt;/p&gt;\n\n&lt;p&gt;So in my dataset you have this situation and then our target variable 0 if they bought something in the next month, and 1 if they didn&amp;#39;t. Thus in the whole dataset, if taken for a year, every customer appears 12 times (except those who joined in along but let&amp;#39;s not care about this). The problem is highly unbalanced (many more target variables 0 than 1). The problem for my colleague is that people appear multiple times. For me, it&amp;#39;s not a problem as we&amp;#39;re not looking at specific individuals but rather learn from their behaviour. So my stance is that I remove complete duplicate observations of the same people (so if they&amp;#39;re 23, they didn&amp;#39;t buy anything in the last month, they&amp;#39;re not premium and they didn&amp;#39;t buy anything in the coming month, and then the next month it&amp;#39;s the same, I only keep 1 record), but if their situation changes, then I keep the different records. The stance of my colleague is to keep every observation where the target is 1, then for the observations where the target is 0, for each customer you randomly select 1 observation, and keep it in your dataset. It doesn&amp;#39;t sound good for me as you&amp;#39;re discarding everything about the fact that the behaviour of people changes over time with respect to their situation ? So my colleague&amp;#39;s saying that &amp;#39;imagine that you&amp;#39;re 30, and then in the next observation you&amp;#39;re 31, it&amp;#39;s not going to change anything&amp;#39;, but it&amp;#39;s actually the whole point if your target is correlated with the age ? I&amp;#39;m in a more junior position so I feel like people would rather listen to him but to me it just sounds bad ? I&amp;#39;ve never heard in my 6 years of Uni of anything like that, but then again I&amp;#39;m a junior so...&lt;/p&gt;\n\n&lt;p&gt;On the same page, in this model, the goal in the end is to launch a marketing campaign targeted to people who are more likely to buy. The marketing campaign takes 2 weeks to set up. So he wants us to look for the target variables not in the whole month but only in the last two weeks as for those that convert in the first two weeks after we&amp;#39;ve seen their situation, it&amp;#39;ll be too late. I get the point, but then again, I&amp;#39;ve never heard of anything like that and when I search for this I don&amp;#39;t find anything (he speaks of holdout periods but when you search for holdout in a dataset, that&amp;#39;s not what it means). But in our case, it&amp;#39;s too late if the customer converted elsewhere in the first two weeks, but other than that it&amp;#39;s never &amp;quot;too late&amp;quot; (our products are not things that you buy often).&lt;/p&gt;\n\n&lt;p&gt;Any opinion on this ? I&amp;#39;m not sure who&amp;#39;s in the wrong there, it just doesn&amp;#39;t feel right with me and I haven&amp;#39;t found something very meaningful when looking it up on the Internet. If my colleague reads this, see you next week !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127tf4q", "is_robot_indexable": true, "report_reasons": null, "author": "somedsguy", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127tf4q/dealing_with_multiple_observations_of_same_people/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127tf4q/dealing_with_multiple_observations_of_same_people/", "subreddit_subscribers": 865896, "created_utc": 1680285217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello hello, I am rather new in this field and want to find faces using singular value decomposition. How can I find the marked spots in the given data? I have tried sums, means, var, std, and derivations. However, I cannot isolate these spots. Do you have any ideas how to achieve this?\n\n https://imgur.com/pj0d6Zv", "author_fullname": "t2_1zuw6vph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding points in graph", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127ck3u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680244736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello hello, I am rather new in this field and want to find faces using singular value decomposition. How can I find the marked spots in the given data? I have tried sums, means, var, std, and derivations. However, I cannot isolate these spots. Do you have any ideas how to achieve this?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/pj0d6Zv\"&gt;https://imgur.com/pj0d6Zv&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/osyZVv6x653xkRauK5n_5uBb9NPmfK3WlenqZn1_7LU.jpg?auto=webp&amp;v=enabled&amp;s=61c3249797ec43cd00122379174f2112347d8767", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/osyZVv6x653xkRauK5n_5uBb9NPmfK3WlenqZn1_7LU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24afd35fa558a04ca8f40a62332c0df00dff414e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/osyZVv6x653xkRauK5n_5uBb9NPmfK3WlenqZn1_7LU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94eb9dd5577962fef5e183de53f07cc882393f4a", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/osyZVv6x653xkRauK5n_5uBb9NPmfK3WlenqZn1_7LU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f15268c0e0cb354df7ed3fb26881595bedf53c7", "width": 320, "height": 168}], "variants": {}, "id": "MwUpKXHh_kQdSHwH-a2SSsjLJ9UQPbf4th26an2pN1o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127ck3u", "is_robot_indexable": true, "report_reasons": null, "author": "Ruebi1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127ck3u/finding_points_in_graph/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127ck3u/finding_points_in_graph/", "subreddit_subscribers": 865896, "created_utc": 1680244736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How many hours a week are you in meetings, speaking with stakeholders or coworkers, or generally collaborating with them?", "author_fullname": "t2_ft3xv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much of your day is spent working with coworkers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127ty38", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680286241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How many hours a week are you in meetings, speaking with stakeholders or coworkers, or generally collaborating with them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127ty38", "is_robot_indexable": true, "report_reasons": null, "author": "ave416", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127ty38/how_much_of_your_day_is_spent_working_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127ty38/how_much_of_your_day_is_spent_working_with/", "subreddit_subscribers": 865896, "created_utc": 1680286241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As the title says, I have a full-time job which is fully wfh. I just got admitted into Uni for part time study of 4 years. Has anyone in this group done this or are doing this? Keen to know how you\u2019re managing and if you have any tips for me.", "author_fullname": "t2_2wzyh796", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Part time Master of Data Science with a full-time job. Doable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127drw8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680247797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, I have a full-time job which is fully wfh. I just got admitted into Uni for part time study of 4 years. Has anyone in this group done this or are doing this? Keen to know how you\u2019re managing and if you have any tips for me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127drw8", "is_robot_indexable": true, "report_reasons": null, "author": "maceadi", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127drw8/part_time_master_of_data_science_with_a_fulltime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127drw8/part_time_master_of_data_science_with_a_fulltime/", "subreddit_subscribers": 865896, "created_utc": 1680247797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, thanks for any help on this!\n\nI'm doing a decent number of bespoke analyses with short shelf lives and fast turn-arounds. Most of my Python scripts are not reusable and tailored to the data and problem at hand. They marry multiple datasets and pass them through multiple calculation steps, sometimes using third-party services or optimization models, so there are many potential points of failure.\n\nI want to be confident in what I'm turning around and we don't have anyone available as an outside reviewer. Are there best practices or particular Python packages that I could turn to for better confidence in my results? I'm concerned about everything from data quality to fat-finger mistakes.\n\nThanks all for any and all suggestions!", "author_fullname": "t2_saoea", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing best practices for data analysis in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127p7ug", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680276866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, thanks for any help on this!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m doing a decent number of bespoke analyses with short shelf lives and fast turn-arounds. Most of my Python scripts are not reusable and tailored to the data and problem at hand. They marry multiple datasets and pass them through multiple calculation steps, sometimes using third-party services or optimization models, so there are many potential points of failure.&lt;/p&gt;\n\n&lt;p&gt;I want to be confident in what I&amp;#39;m turning around and we don&amp;#39;t have anyone available as an outside reviewer. Are there best practices or particular Python packages that I could turn to for better confidence in my results? I&amp;#39;m concerned about everything from data quality to fat-finger mistakes.&lt;/p&gt;\n\n&lt;p&gt;Thanks all for any and all suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127p7ug", "is_robot_indexable": true, "report_reasons": null, "author": "ultreian", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127p7ug/testing_best_practices_for_data_analysis_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127p7ug/testing_best_practices_for_data_analysis_in_python/", "subreddit_subscribers": 865896, "created_utc": 1680276866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nHow do you deal with interpreting/extracting feature importance when most of your features are engineered? \n\nFor instance one-hot encoding (Categorical feature A becomes A1, A2, A3, ...An where n is the number of values), feature importance would be A1, or A3 for example - do you interpret that as feature A is important, or just the specific value?\n\n\\*Same for other types of feature engineering, OHE was the easiest to demonstrate", "author_fullname": "t2_5hjxl4ya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature importance with feature engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127spfx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680283818.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;How do you deal with interpreting/extracting feature importance when most of your features are engineered? &lt;/p&gt;\n\n&lt;p&gt;For instance one-hot encoding (Categorical feature A becomes A1, A2, A3, ...An where n is the number of values), feature importance would be A1, or A3 for example - do you interpret that as feature A is important, or just the specific value?&lt;/p&gt;\n\n&lt;p&gt;*Same for other types of feature engineering, OHE was the easiest to demonstrate&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127spfx", "is_robot_indexable": true, "report_reasons": null, "author": "PlainPiano9", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127spfx/feature_importance_with_feature_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127spfx/feature_importance_with_feature_engineering/", "subreddit_subscribers": 865896, "created_utc": 1680283818.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI am a Ph.D Student at Arizona State University participating in a National Science Foundation innovation program designed to help us understand how businesses test and evaluate ML/ AI models in production. I am looking for ML Engineers / data scientists, analysts / product managers for a brief  15 minutes discussion. Please feel free to message me.\n\nThank you very much for your time and consideration.", "author_fullname": "t2_3erw4o06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ML test and evaluation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127x7u3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680292674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am a Ph.D Student at Arizona State University participating in a National Science Foundation innovation program designed to help us understand how businesses test and evaluate ML/ AI models in production. I am looking for ML Engineers / data scientists, analysts / product managers for a brief  15 minutes discussion. Please feel free to message me.&lt;/p&gt;\n\n&lt;p&gt;Thank you very much for your time and consideration.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127x7u3", "is_robot_indexable": true, "report_reasons": null, "author": "vineet0814", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127x7u3/ml_test_and_evaluation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127x7u3/ml_test_and_evaluation/", "subreddit_subscribers": 865896, "created_utc": 1680292674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My manager is not from ML background, he is a chemical engineer. So when I present any ML algorithm e.g. random forest, he just go deeper how it works under the hood and keep going in till he understands the very minute details.this takes lots of my time to explain everything to him.\nIs it normal for all non ML people?", "author_fullname": "t2_lrllrd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is your manager learning from you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_128966f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680318058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My manager is not from ML background, he is a chemical engineer. So when I present any ML algorithm e.g. random forest, he just go deeper how it works under the hood and keep going in till he understands the very minute details.this takes lots of my time to explain everything to him.\nIs it normal for all non ML people?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "128966f", "is_robot_indexable": true, "report_reasons": null, "author": "vishal-vora", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/128966f/is_your_manager_learning_from_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/128966f/is_your_manager_learning_from_you/", "subreddit_subscribers": 865896, "created_utc": 1680318058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey Data Scientists,\n\nSo I've searched this sub and only found a few posts concerning Jetbrain's IDE Dataspell. Mostly from when it was first released. Has anyone used it since? How is it for use in the domain it was built for compared to PyCharm and VS Code? I like using Jetbrain's IDEs and I'm working with a trial version but I would like to hear the community's opinion on it.\n\nThanks", "author_fullname": "t2_4b099", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is Dataspell for data engineering and analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1286qtp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680311771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Data Scientists,&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;ve searched this sub and only found a few posts concerning Jetbrain&amp;#39;s IDE Dataspell. Mostly from when it was first released. Has anyone used it since? How is it for use in the domain it was built for compared to PyCharm and VS Code? I like using Jetbrain&amp;#39;s IDEs and I&amp;#39;m working with a trial version but I would like to hear the community&amp;#39;s opinion on it.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1286qtp", "is_robot_indexable": true, "report_reasons": null, "author": "Eezyville", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1286qtp/how_is_dataspell_for_data_engineering_and_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1286qtp/how_is_dataspell_for_data_engineering_and_analysis/", "subreddit_subscribers": 865896, "created_utc": 1680311771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "News just released via [this Tweet](https://twitter.com/TwitterEng/status/1641872259320274944?t=OGxvSuB9SLO2nUmfA-esIA&amp;s=19).\n\nSource code here: https://github.com/twitter/the-algorithm\n\nI just listened to Elon Musk and Twitter Engineering talk about it on [this Twitter space](https://twitter.com/i/spaces/1jMJgLdenVjxL).", "author_fullname": "t2_8yxss60i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "News: Twitter algorithm now open source", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127xfhk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680293087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;News just released via &lt;a href=\"https://twitter.com/TwitterEng/status/1641872259320274944?t=OGxvSuB9SLO2nUmfA-esIA&amp;amp;s=19\"&gt;this Tweet&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Source code here: &lt;a href=\"https://github.com/twitter/the-algorithm\"&gt;https://github.com/twitter/the-algorithm&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I just listened to Elon Musk and Twitter Engineering talk about it on &lt;a href=\"https://twitter.com/i/spaces/1jMJgLdenVjxL\"&gt;this Twitter space&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WpPz8udYXLwrI7HEVMRxLGGIkcl58DT62-oa176dSEk.jpg?auto=webp&amp;v=enabled&amp;s=e6138600bd2e3b0b3f5e3d6b26cc4ffc8491a352", "width": 140, "height": 140}, "resolutions": [{"url": "https://external-preview.redd.it/WpPz8udYXLwrI7HEVMRxLGGIkcl58DT62-oa176dSEk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7934ffccafbc929e5465d6ddb4009847673137a", "width": 108, "height": 108}], "variants": {}, "id": "L5RrZHf601-ktBxxZ2Zqf9VG4ap_uQ5RXWhIuGDA25M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127xfhk", "is_robot_indexable": true, "report_reasons": null, "author": "John-The-Bomb-2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127xfhk/news_twitter_algorithm_now_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127xfhk/news_twitter_algorithm_now_open_source/", "subreddit_subscribers": 865896, "created_utc": 1680293087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've done a paper survey of how well ChatGPT performs on various NLP tasks as reported in arXiv papers. I have found 19 papers where they compared ChatGPT with fine-tuned models, but they are being published practically daily now. It seems that for the most of the classical NLP tasks, ChatGPT is not actually that strong and smaller fine-tuned models are often much better. According to the API page, GPT-4 is not expected to be much stronger on tasks like these. I think it is an interesting perspective that shows that for many of the tasks we need to solve, GPT models are actually not the right tool.\n\nThe full survey is in my blog post: [http://opensamizdat.com/posts/chatgpt\\_survey/](http://opensamizdat.com/posts/chatgpt_survey/)\n\nAny feedback is welcomed.", "author_fullname": "t2_2lyqh3jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ChatGPT Survey: Performance on NLP datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127qs9h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680279976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve done a paper survey of how well ChatGPT performs on various NLP tasks as reported in arXiv papers. I have found 19 papers where they compared ChatGPT with fine-tuned models, but they are being published practically daily now. It seems that for the most of the classical NLP tasks, ChatGPT is not actually that strong and smaller fine-tuned models are often much better. According to the API page, GPT-4 is not expected to be much stronger on tasks like these. I think it is an interesting perspective that shows that for many of the tasks we need to solve, GPT models are actually not the right tool.&lt;/p&gt;\n\n&lt;p&gt;The full survey is in my blog post: &lt;a href=\"http://opensamizdat.com/posts/chatgpt_survey/\"&gt;http://opensamizdat.com/posts/chatgpt_survey/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any feedback is welcomed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127qs9h", "is_robot_indexable": true, "report_reasons": null, "author": "matus_pikuliak", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127qs9h/chatgpt_survey_performance_on_nlp_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127qs9h/chatgpt_survey_performance_on_nlp_datasets/", "subreddit_subscribers": 865896, "created_utc": 1680279976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Long story short: I decided to change careers because I enjoyed the data aspects of my psychology undegraduate program.", "author_fullname": "t2_2avd4wfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will having a BA in psychology hinder my chances of getting a data analyst/science job if I'm currently pursuing an MS in Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_128b2xm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680323242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short: I decided to change careers because I enjoyed the data aspects of my psychology undegraduate program.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "128b2xm", "is_robot_indexable": true, "report_reasons": null, "author": "Javilism", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/128b2xm/will_having_a_ba_in_psychology_hinder_my_chances/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/128b2xm/will_having_a_ba_in_psychology_hinder_my_chances/", "subreddit_subscribers": 865896, "created_utc": 1680323242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am thinking in studying this, some say NLP will decrease as GPT can beat most of NLP tasks in a low cost. What do you say?", "author_fullname": "t2_w7ap5hsy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think NLP will increase with LLM models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1289p4d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680319457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thinking in studying this, some say NLP will decrease as GPT can beat most of NLP tasks in a low cost. What do you say?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1289p4d", "is_robot_indexable": true, "report_reasons": null, "author": "Muted_Standard175", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1289p4d/do_you_think_nlp_will_increase_with_llm_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1289p4d/do_you_think_nlp_will_increase_with_llm_models/", "subreddit_subscribers": 865896, "created_utc": 1680319457.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, I'm trying to build a tool that uses a GPT model to generate queries based on my organization's data context. Some of our tables have pretty complicated schemas with similar column names. Also given some queries might be pretty complicated, the gpt-3 token limit could pose an issue. I've explored embeddings and storing them in a vector database, but I'm not too sure yet if the retrieved vectors make sense semantically when fed into the model. \nDoes anyone here have experience with using GPT-3 to create context-driven queries? Would love to hear your approaches.", "author_fullname": "t2_610eusu7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using GPT3 to create context driven queries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1288veo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680317254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I&amp;#39;m trying to build a tool that uses a GPT model to generate queries based on my organization&amp;#39;s data context. Some of our tables have pretty complicated schemas with similar column names. Also given some queries might be pretty complicated, the gpt-3 token limit could pose an issue. I&amp;#39;ve explored embeddings and storing them in a vector database, but I&amp;#39;m not too sure yet if the retrieved vectors make sense semantically when fed into the model. \nDoes anyone here have experience with using GPT-3 to create context-driven queries? Would love to hear your approaches.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1288veo", "is_robot_indexable": true, "report_reasons": null, "author": "moonwalker0202", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1288veo/using_gpt3_to_create_context_driven_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1288veo/using_gpt3_to_create_context_driven_queries/", "subreddit_subscribers": 865896, "created_utc": 1680317254.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Thanks in advance for the help!\n\nOur goal is to generate groups of participants based on their vowel systems. Their vowel systems contain two nested variables:\u00a0\n\n1. The vowel class itself (there are 14 types, which are represented by words containing the vowel type e.g. \"dress\" and \"thought\")\u00a0\n2. The vowel coordinates, represented by 2 frequencies in the bark scale (a linearization of Hertz)  \nWe would like to run this through a divisive clustering analysis algorithm. If we change our data from this format (with nested variables):\n\nWe would like to run this through a divisive clustering analysis algorithm. If we change our data format from 14 dimensions with 2 subdimensions to 28 non-linked dimensions and input that into a clustering algorithm, do we lose anything of significance? If so, is there another method you know of that we can use?\n\nThanks :)", "author_fullname": "t2_q2907eyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to sort participants into groups according to nested variables? Divisive Clustering analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127oj2m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680275498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thanks in advance for the help!&lt;/p&gt;\n\n&lt;p&gt;Our goal is to generate groups of participants based on their vowel systems. Their vowel systems contain two nested variables:\u00a0&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The vowel class itself (there are 14 types, which are represented by words containing the vowel type e.g. &amp;quot;dress&amp;quot; and &amp;quot;thought&amp;quot;)\u00a0&lt;/li&gt;\n&lt;li&gt;The vowel coordinates, represented by 2 frequencies in the bark scale (a linearization of Hertz)&lt;br/&gt;\nWe would like to run this through a divisive clustering analysis algorithm. If we change our data from this format (with nested variables):&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We would like to run this through a divisive clustering analysis algorithm. If we change our data format from 14 dimensions with 2 subdimensions to 28 non-linked dimensions and input that into a clustering algorithm, do we lose anything of significance? If so, is there another method you know of that we can use?&lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127oj2m", "is_robot_indexable": true, "report_reasons": null, "author": "kovidwithaK", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127oj2m/how_to_sort_participants_into_groups_according_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127oj2m/how_to_sort_participants_into_groups_according_to/", "subreddit_subscribers": 865896, "created_utc": 1680275498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Everyone\n\nI recently came across this wiki and github for Data Engineering - [https://dataengineering.wiki/Index](https://dataengineering.wiki/Index)\n\nIs there a similar one setup for Data Science and Machine Learning ? If so can anyone please send the links? Thank you!", "author_fullname": "t2_8441ts3p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wiki/Github for Data Science and Machine Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127kl35", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680267263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone&lt;/p&gt;\n\n&lt;p&gt;I recently came across this wiki and github for Data Engineering - &lt;a href=\"https://dataengineering.wiki/Index\"&gt;https://dataengineering.wiki/Index&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is there a similar one setup for Data Science and Machine Learning ? If so can anyone please send the links? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127kl35", "is_robot_indexable": true, "report_reasons": null, "author": "jest_123", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127kl35/wikigithub_for_data_science_and_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127kl35/wikigithub_for_data_science_and_machine_learning/", "subreddit_subscribers": 865896, "created_utc": 1680267263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In a multi-class classification with Class A, B, C and rest of the class (Class D, E, F, G,H etc ) to be classified as \u201cOther/unclassified\u201d ;\n\n**Objective:** Objective is show the Confidence Level (by showcasing the probability) for every prediction, which gives clear indication to downstream system to rely on the prediction As you may know, Predict proba doesn\u2019t give the probability for each class, w.r.t boosting models (say LightGBM); there by probability calibration to be done\n\n**Ask :** Though we have done Multiclass - Probability Calibration (using Calibrated CV - Isotonic Regression), We cannot directly show the probability or confidence score per single prediction from LightGBM model (or any boosting model)\n\nWe want to show probability or confidence score per single prediction from LightGBM model (for both binary &amp; multiclass classification)\n\nAny suggestions shall help?", "author_fullname": "t2_3cua45hl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi-class Prediction using Probability for LightGBM (boosting models)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127f9q9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680252966.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In a multi-class classification with Class A, B, C and rest of the class (Class D, E, F, G,H etc ) to be classified as \u201cOther/unclassified\u201d ;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Objective:&lt;/strong&gt; Objective is show the Confidence Level (by showcasing the probability) for every prediction, which gives clear indication to downstream system to rely on the prediction As you may know, Predict proba doesn\u2019t give the probability for each class, w.r.t boosting models (say LightGBM); there by probability calibration to be done&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Ask :&lt;/strong&gt; Though we have done Multiclass - Probability Calibration (using Calibrated CV - Isotonic Regression), We cannot directly show the probability or confidence score per single prediction from LightGBM model (or any boosting model)&lt;/p&gt;\n\n&lt;p&gt;We want to show probability or confidence score per single prediction from LightGBM model (for both binary &amp;amp; multiclass classification)&lt;/p&gt;\n\n&lt;p&gt;Any suggestions shall help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127f9q9", "is_robot_indexable": true, "report_reasons": null, "author": "Balaji2v", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127f9q9/multiclass_prediction_using_probability_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127f9q9/multiclass_prediction_using_probability_for/", "subreddit_subscribers": 865896, "created_utc": 1680252966.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_roxmtd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[R] P value in statistics explained under 5 min", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_128bhjy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/9QjYYGVwdAo?start=5&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"P value and hypothesis testing in statistics explained under 5 min!!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"oembed": {"provider_url": "https://www.youtube.com/", "title": "P value and hypothesis testing in statistics explained under 5 min!!", "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/9QjYYGVwdAo?start=5&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"P value and hypothesis testing in statistics explained under 5 min!!\"&gt;&lt;/iframe&gt;", "thumbnail_width": 480, "height": 200, "width": 356, "version": "1.0", "author_name": "Machine Learning With me", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/9QjYYGVwdAo/hqdefault.jpg", "type": "video", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MLwithme1617"}, "type": "youtube.com"}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/9QjYYGVwdAo?start=5&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"P value and hypothesis testing in statistics explained under 5 min!!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/128bhjy", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RfLbT9DRZ0hslUA9N-FO24GW7pB1U03aDwZOx42YB3s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680324390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=9QjYYGVwdAo&amp;t=5s", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZsSbJOD2bibyV0p9xqyWomXzllk4_IurYS4n430dpbQ.jpg?auto=webp&amp;v=enabled&amp;s=df9d76d791d984ee28c342621a51a47e01d327ef", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/ZsSbJOD2bibyV0p9xqyWomXzllk4_IurYS4n430dpbQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15da6a3b4c55b9832e58dbf89bb88e0c882e4a3b", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/ZsSbJOD2bibyV0p9xqyWomXzllk4_IurYS4n430dpbQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a88465e317969f17f278ebdf67cada19d0a0aa9", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/ZsSbJOD2bibyV0p9xqyWomXzllk4_IurYS4n430dpbQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fac9849eb2df6d802500619c072411097704e66", "width": 320, "height": 240}], "variants": {}, "id": "X9dBgppKj0NHlHYT8pHLNEG4e7DsiT5J0mgxJQZNwTw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "128bhjy", "is_robot_indexable": true, "report_reasons": null, "author": "MLwithMe1617", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/128bhjy/r_p_value_in_statistics_explained_under_5_min/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=9QjYYGVwdAo&amp;t=5s", "subreddit_subscribers": 865896, "created_utc": 1680324390.0, "num_crossposts": 0, "media": {"oembed": {"provider_url": "https://www.youtube.com/", "title": "P value and hypothesis testing in statistics explained under 5 min!!", "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/9QjYYGVwdAo?start=5&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"P value and hypothesis testing in statistics explained under 5 min!!\"&gt;&lt;/iframe&gt;", "thumbnail_width": 480, "height": 200, "width": 356, "version": "1.0", "author_name": "Machine Learning With me", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/9QjYYGVwdAo/hqdefault.jpg", "type": "video", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MLwithme1617"}, "type": "youtube.com"}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im actually a \u201cbusiness\u201d analyst, not in data science or an IT org by any means. Ive been doing business analytics for about 5 years in various roles with the same company. My team specifically is pretty early in its analytic maturity and the need for more robust data cleaning to deal with shit inputs into source applications is only getting more painful as my greater department grows, bandaids old problems, and creates new ones.  \n\nIts becoming very obvious (at least to me) the need for tighter data controls and formalized ETLs into centralized databases, and becoming comfortable with direct API calls is basically required if we\u2019re going to grow. Here\u2019s the problem, im a business analyst and if any of this is going to be worked on I need to effectively \u201chire\u201d our central IT department to do any of the work. What I felt was going to be a slow build out of data pipelines and warehouses, by our team for our team, is actually a multi-year double comma budget project that im basically just writing requirement docs for and HOPING nothing on my end changes while IT resources are building the solution. \n\nSo I ask, r/DataScience, where does your team sit in this corporate ecosystem? Im actually dumb founded how any advanced analytics or long term efficiencies can be delivered if Im not able to have the flexibility to build my own pipelines and databases.", "author_fullname": "t2_9bpo6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where is your role in your organizations structure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1282v3l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680303640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im actually a \u201cbusiness\u201d analyst, not in data science or an IT org by any means. Ive been doing business analytics for about 5 years in various roles with the same company. My team specifically is pretty early in its analytic maturity and the need for more robust data cleaning to deal with shit inputs into source applications is only getting more painful as my greater department grows, bandaids old problems, and creates new ones.  &lt;/p&gt;\n\n&lt;p&gt;Its becoming very obvious (at least to me) the need for tighter data controls and formalized ETLs into centralized databases, and becoming comfortable with direct API calls is basically required if we\u2019re going to grow. Here\u2019s the problem, im a business analyst and if any of this is going to be worked on I need to effectively \u201chire\u201d our central IT department to do any of the work. What I felt was going to be a slow build out of data pipelines and warehouses, by our team for our team, is actually a multi-year double comma budget project that im basically just writing requirement docs for and HOPING nothing on my end changes while IT resources are building the solution. &lt;/p&gt;\n\n&lt;p&gt;So I ask, &lt;a href=\"/r/DataScience\"&gt;r/DataScience&lt;/a&gt;, where does your team sit in this corporate ecosystem? Im actually dumb founded how any advanced analytics or long term efficiencies can be delivered if Im not able to have the flexibility to build my own pipelines and databases.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1282v3l", "is_robot_indexable": true, "report_reasons": null, "author": "Rykios", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1282v3l/where_is_your_role_in_your_organizations_structure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1282v3l/where_is_your_role_in_your_organizations_structure/", "subreddit_subscribers": 865896, "created_utc": 1680303640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Somebody has some idea how to generate endpoints from unstructured text?", "author_fullname": "t2_89s519wzv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NLP endpoint generation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127t79t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680284787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Somebody has some idea how to generate endpoints from unstructured text?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127t79t", "is_robot_indexable": true, "report_reasons": null, "author": "Reasi98", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127t79t/nlp_endpoint_generation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127t79t/nlp_endpoint_generation/", "subreddit_subscribers": 865896, "created_utc": 1680284787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I get this error while loading an EBM model pickle file. Any hints and help to solve this error?", "author_fullname": "t2_85tjk7wh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't attribute EBMPreprocessor on", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_127m9ku", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680270944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I get this error while loading an EBM model pickle file. Any hints and help to solve this error?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "127m9ku", "is_robot_indexable": true, "report_reasons": null, "author": "Jebin1999", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/127m9ku/cant_attribute_ebmpreprocessor_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/127m9ku/cant_attribute_ebmpreprocessor_on/", "subreddit_subscribers": 865896, "created_utc": 1680270944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_hl4xrdbv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Data Analytics Online Courses Can Advance Your Career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_128bppl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z1-dbW7NFoOa4F05lgrW2S25eLR-OyqOFNYXfve8b6s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680325021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tealfeed.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://tealfeed.com/data-analytics-online-courses-advance-career-vyzax", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pEnV66UK1TP3EZmoZ-T0Bo-d2iU71kLPwEwtfnRZsgs.jpg?auto=webp&amp;v=enabled&amp;s=3fcc993e2f778e953b6087b57d30d113ef196873", "width": 1000, "height": 563}, "resolutions": [{"url": "https://external-preview.redd.it/pEnV66UK1TP3EZmoZ-T0Bo-d2iU71kLPwEwtfnRZsgs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90ad86aad6145e25c1e863d7a4566f2c0bd5c72b", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/pEnV66UK1TP3EZmoZ-T0Bo-d2iU71kLPwEwtfnRZsgs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b23fbaf73c27e96200d550d72a29eb6ecf07ef5", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/pEnV66UK1TP3EZmoZ-T0Bo-d2iU71kLPwEwtfnRZsgs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6fbc37a33b6f6aa7f684563a4f7eb22d83490d2", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/pEnV66UK1TP3EZmoZ-T0Bo-d2iU71kLPwEwtfnRZsgs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1064a5406584a4f9c917e0ddedcf8ddc5d9a9464", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/pEnV66UK1TP3EZmoZ-T0Bo-d2iU71kLPwEwtfnRZsgs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=880b0a5eeeab385acc9381fb17e06069b8fe0b15", "width": 960, "height": 540}], "variants": {}, "id": "HnM-oGH1GAzqRMxM2SUFIir57dbLysYjeenNMBVP1WY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "128bppl", "is_robot_indexable": true, "report_reasons": null, "author": "careereraeduportal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/128bppl/how_data_analytics_online_courses_can_advance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://tealfeed.com/data-analytics-online-courses-advance-career-vyzax", "subreddit_subscribers": 865896, "created_utc": 1680325021.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}