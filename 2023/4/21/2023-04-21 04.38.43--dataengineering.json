{"kind": "Listing", "data": {"after": "t3_12tc6mm", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_brkxjomi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "i just want sleep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_12t22p4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 613, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 613, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/puAii6Q8AsOEFaHLxJjsSBL38aa4ySlwKqI5jDo0IG8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682002372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/u3lx5ziwy1va1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/u3lx5ziwy1va1.png?auto=webp&amp;v=enabled&amp;s=30186be8b759a8da73bb9226aa07c8a3bf83868b", "width": 547, "height": 639}, "resolutions": [{"url": "https://preview.redd.it/u3lx5ziwy1va1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d2ce2c96d4b848dd6ba796d0bf61d8523c9b346", "width": 108, "height": 126}, {"url": "https://preview.redd.it/u3lx5ziwy1va1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c3936e9dabea6e813d8ab815ec0ec4e88e57475", "width": 216, "height": 252}, {"url": "https://preview.redd.it/u3lx5ziwy1va1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af3e05c51ffa43ace03ea6a384d7714a14250975", "width": 320, "height": 373}], "variants": {}, "id": "hxlTW6yoIMMT28J6sXq8l-WqTT8R86QOzETqRWsVIJA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "12t22p4", "is_robot_indexable": true, "report_reasons": null, "author": "Straight_House8628", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12t22p4/i_just_want_sleep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/u3lx5ziwy1va1.png", "subreddit_subscribers": 101011, "created_utc": 1682002372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anybody taken the Databricks Certified Data Engineer Professional certification exam and could share experiences?\n\nHow does it compare to Databricks Certified Data Engineer Associate?\n\nAre there free sample tests available?\n\nIn return, I will be happy to share experience from the Associate Developer for Apache Spark (Python) exam if you're interested. I've passed it lately.", "author_fullname": "t2_ti6b0o4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Certified Data Engineer Professional - experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sswj8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681983857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anybody taken the Databricks Certified Data Engineer Professional certification exam and could share experiences?&lt;/p&gt;\n\n&lt;p&gt;How does it compare to Databricks Certified Data Engineer Associate?&lt;/p&gt;\n\n&lt;p&gt;Are there free sample tests available?&lt;/p&gt;\n\n&lt;p&gt;In return, I will be happy to share experience from the Associate Developer for Apache Spark (Python) exam if you&amp;#39;re interested. I&amp;#39;ve passed it lately.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12sswj8", "is_robot_indexable": true, "report_reasons": null, "author": "user2401372", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12sswj8/databricks_certified_data_engineer_professional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12sswj8/databricks_certified_data_engineer_professional/", "subreddit_subscribers": 101011, "created_utc": 1681983857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I DESPISE live coding interviews. I\u2019m a good engineer and I can talk through skills and whiteboard and data model interview just fine. But seriously ask me a basic select statement in sql live and I barely remember how to do that. Panic sets in immediately and I barely make it through. I promise give me an hour to code something real and it will be done but just don\u2019t make me live code. I have almost 10 years experience and can barely write sql in a coding interview. It\u2019s just really rough.", "author_fullname": "t2_58wh4oyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Live coding interview hatred", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12th15p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682028930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I DESPISE live coding interviews. I\u2019m a good engineer and I can talk through skills and whiteboard and data model interview just fine. But seriously ask me a basic select statement in sql live and I barely remember how to do that. Panic sets in immediately and I barely make it through. I promise give me an hour to code something real and it will be done but just don\u2019t make me live code. I have almost 10 years experience and can barely write sql in a coding interview. It\u2019s just really rough.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "12th15p", "is_robot_indexable": true, "report_reasons": null, "author": "k-dani-b", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12th15p/live_coding_interview_hatred/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12th15p/live_coding_interview_hatred/", "subreddit_subscribers": 101011, "created_utc": 1682028930.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hey Data Engineers,\n\nA lot has happened since our last update and we wanted to keep you up to date with some recent and upcoming community changes.\n\n# TL;DR\n\n* We grew to 100K members\n* We\u2019re growing r/dataengineeringjobs for career Q&amp;A\n* 100% ChatGPT/Generative AI content is spam\n* We have an events page now for meetups/conferences\n* Minor improvements to the wiki\n* A newsletter to recap news, insights, and inspiration from the community\n\n# Community Updates\n\nLet\u2019s start with community updates. We recently reached 100,000 members and counting! \ud83d\udcaf\n\n**Fun stat:** In the past 30 days, almost 2 million people viewed our community. \ud83d\udc40\n\nThe sub has doubled in size almost every year and it\u2019s been challenging to grow this quickly but we\u2019re seeing people from all sorts of professions and walks of life take an interest in data engineering - the diversity is astounding. Thank you to all of you who are constantly sharing your knowledge, welcoming and helping other members, and reporting bad actors. \ud83d\ude4f\n\n# Policy updates\n\n**Career content**\n\nYou may have seen that resume reviews are no longer allowed. This is because there was already plenty of great advice/discussion around resumes and resume reviews alone aren\u2019t related to learning about data engineering which is why we\u2019re all here. You can still access older resume reviews using the flair as well as get advice from dedicated subreddits like r/resumes.\n\nFollowing the same line of reasoning, we are in the process of slowly incubating r/dataengineeringjobs for career content and will be encouraging career questions there instead. The career discussion is great and we\u2019ve been able to provide a lot of transparency with the salary threads - we want to keep it going and give it the space it deserves as a standalone topic for discussion.\n\n**Generative AI/ChatGPT content**\n\nSimilar to our contribution policy for the wiki, content that is exclusively created with generative AI will be considered spam and will be removed. This is because content generated by AI is often incorrect which leads to the spread of inaccurate information. Since this is a community dedicated to learning about data engineering, the use of generative AI in this way negatively impacts our desired community goals.\n\nThat does not mean we are banning generative AI usage entirely, but it must meet the following requirements:\n\n* AI-generated content is not used in an automated way\n* AI-generated content must still be edited and fact-checked by a human\n* AI-generated content must be helpful/give insight beyond what a Google search would give you\n* AI-generated content is not used to answer something already answered in the FAQ/wiki\n\nIf you\u2019re not sure whether or not your post violates the rule, please message us and we would be more than happy to provide guidance.\n\n# New events page\n\n&amp;#x200B;\n\n[Events widget in the sidebar](https://preview.redd.it/rcjho150syua1.png?width=330&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b97938287feb0084644548c40a9011d0bd3062d3)\n\nThanks to u/AdiPolak for the suggestion! You\u2019ll now see upcoming events in the sidebar widget and the [wiki](https://dataengineering.wiki/Community/Events).\n\nIf you\u2019d like to share an event with the community, [just fill out this form](https://dataengineering.wiki/Community/Events).\n\nWe encourage everyone to post events here going forward instead of the main feed.\n\n# Wiki updates\n\nThe [learning resources](https://dataengineering.wiki/Learning+Resources) links are now clickable again! Also, the site has been optimized for performance and should be much faster now.\n\n&amp;#x200B;\n\n[Google Lighthouse stats for the wiki](https://preview.redd.it/9kga4a25syua1.png?width=386&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3ab396ebcf089bc560446ac514fb7bdf264ce72a)\n\nWe\u2019ve also added a way to give feedback on any page. You can give a thumbs up/thumbs down as well as leave a comment to let us know about any opportunities for improvement.\n\n&amp;#x200B;\n\n[Feedback form on the wiki footer](https://preview.redd.it/qwgc14w7syua1.png?width=319&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=08ad0f7191a641f97e6373d650ffd8b90c8b8b7e)\n\nIf you\u2019re more of a hands-on kind of person, don\u2019t forget that the wiki is entirely [open source](https://github.com/data-engineering-community/data-engineering-wiki) and you can make edits via GitHub or by clicking on **Edit in GitHub** at the bottom of any page.\n\nShout out to all of our contributors and those who have sponsored the development of the wiki!\n\n&amp;#x200B;\n\n[Wiki contributors - thank you!](https://preview.redd.it/epgko7ebsyua1.png?width=294&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9d8f562a6a12de188e6709f26a79f1d6ba952ab7)\n\n# Community Newsletter\n\nWe are experimenting with a [monthly newsletter](https://dataengineeringcommunity.substack.com/) that will round up all of the best content from the community as well as highlight events. As the community grows it may feel harder to keep up to date with everything that's happening and this newsletter is meant to help with that. It will always be free and open, we are using substack simply because it allows us to send it for free regardless of subscriber count.\n\n[Subscribe here](https://dataengineeringcommunity.substack.com/) to get the first edition which will send on 4/30/23.\n\n[Please let us know](https://www.reddit.com/message/compose?to=/r/dataengineering) if you\u2019d like to contribute to this project or have ideas.\n\n\\--\n\nAs always, feedback is welcome and encouraged. Tell us in the comments one thing you like and one thing you'd like to see improved!", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Community Updates 4/20/23", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"epgko7ebsyua1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 45, "x": 108, "u": "https://preview.redd.it/epgko7ebsyua1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9d73ac23d1b79b9fd1c90c0d2abf66d47fd92c4"}, {"y": 90, "x": 216, "u": "https://preview.redd.it/epgko7ebsyua1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0a6ded4a4ef255249a8d70f63524107674f78f9"}], "s": {"y": 123, "x": 294, "u": "https://preview.redd.it/epgko7ebsyua1.png?width=294&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9d8f562a6a12de188e6709f26a79f1d6ba952ab7"}, "id": "epgko7ebsyua1"}, "9kga4a25syua1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 37, "x": 108, "u": "https://preview.redd.it/9kga4a25syua1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=594ca221c0e78f471e6c25c0b28a250f7f1c8129"}, {"y": 74, "x": 216, "u": "https://preview.redd.it/9kga4a25syua1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6acd332757f49f20e5ebf88f316506982cfe47c5"}, {"y": 111, "x": 320, "u": "https://preview.redd.it/9kga4a25syua1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be6182c4a11726851c3a5e0b964feade569f82f9"}], "s": {"y": 134, "x": 386, "u": "https://preview.redd.it/9kga4a25syua1.png?width=386&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3ab396ebcf089bc560446ac514fb7bdf264ce72a"}, "id": "9kga4a25syua1"}, "rcjho150syua1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 136, "x": 108, "u": "https://preview.redd.it/rcjho150syua1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=27ff0acd7bb90401db88bcda960c7a95cce9d215"}, {"y": 272, "x": 216, "u": "https://preview.redd.it/rcjho150syua1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=274605ad2918f59c287bd8338b0b4ad8fcbd0fa6"}, {"y": 403, "x": 320, "u": "https://preview.redd.it/rcjho150syua1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76c2e12dcf5262982e2e17725e98308fe126784b"}], "s": {"y": 416, "x": 330, "u": "https://preview.redd.it/rcjho150syua1.png?width=330&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b97938287feb0084644548c40a9011d0bd3062d3"}, "id": "rcjho150syua1"}, "qwgc14w7syua1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/qwgc14w7syua1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=050b90ee8721e5925b204480841381d858f00a22"}, {"y": 110, "x": 216, "u": "https://preview.redd.it/qwgc14w7syua1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=acec9778eeb0594c024dae11663bf2d182aad8d5"}], "s": {"y": 163, "x": 319, "u": "https://preview.redd.it/qwgc14w7syua1.png?width=319&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=08ad0f7191a641f97e6373d650ffd8b90c8b8b7e"}, "id": "qwgc14w7syua1"}}, "name": "t3_12swb7a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/vmKWNKckw81v3CDsLx823uDlh5lSQPBbuzNap5JTGpA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1681992128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Data Engineers,&lt;/p&gt;\n\n&lt;p&gt;A lot has happened since our last update and we wanted to keep you up to date with some recent and upcoming community changes.&lt;/p&gt;\n\n&lt;h1&gt;TL;DR&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We grew to 100K members&lt;/li&gt;\n&lt;li&gt;We\u2019re growing &lt;a href=\"/r/dataengineeringjobs\"&gt;r/dataengineeringjobs&lt;/a&gt; for career Q&amp;amp;A&lt;/li&gt;\n&lt;li&gt;100% ChatGPT/Generative AI content is spam&lt;/li&gt;\n&lt;li&gt;We have an events page now for meetups/conferences&lt;/li&gt;\n&lt;li&gt;Minor improvements to the wiki&lt;/li&gt;\n&lt;li&gt;A newsletter to recap news, insights, and inspiration from the community&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Community Updates&lt;/h1&gt;\n\n&lt;p&gt;Let\u2019s start with community updates. We recently reached 100,000 members and counting! \ud83d\udcaf&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Fun stat:&lt;/strong&gt; In the past 30 days, almost 2 million people viewed our community. \ud83d\udc40&lt;/p&gt;\n\n&lt;p&gt;The sub has doubled in size almost every year and it\u2019s been challenging to grow this quickly but we\u2019re seeing people from all sorts of professions and walks of life take an interest in data engineering - the diversity is astounding. Thank you to all of you who are constantly sharing your knowledge, welcoming and helping other members, and reporting bad actors. \ud83d\ude4f&lt;/p&gt;\n\n&lt;h1&gt;Policy updates&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;Career content&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;You may have seen that resume reviews are no longer allowed. This is because there was already plenty of great advice/discussion around resumes and resume reviews alone aren\u2019t related to learning about data engineering which is why we\u2019re all here. You can still access older resume reviews using the flair as well as get advice from dedicated subreddits like &lt;a href=\"/r/resumes\"&gt;r/resumes&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Following the same line of reasoning, we are in the process of slowly incubating &lt;a href=\"/r/dataengineeringjobs\"&gt;r/dataengineeringjobs&lt;/a&gt; for career content and will be encouraging career questions there instead. The career discussion is great and we\u2019ve been able to provide a lot of transparency with the salary threads - we want to keep it going and give it the space it deserves as a standalone topic for discussion.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Generative AI/ChatGPT content&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Similar to our contribution policy for the wiki, content that is exclusively created with generative AI will be considered spam and will be removed. This is because content generated by AI is often incorrect which leads to the spread of inaccurate information. Since this is a community dedicated to learning about data engineering, the use of generative AI in this way negatively impacts our desired community goals.&lt;/p&gt;\n\n&lt;p&gt;That does not mean we are banning generative AI usage entirely, but it must meet the following requirements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;AI-generated content is not used in an automated way&lt;/li&gt;\n&lt;li&gt;AI-generated content must still be edited and fact-checked by a human&lt;/li&gt;\n&lt;li&gt;AI-generated content must be helpful/give insight beyond what a Google search would give you&lt;/li&gt;\n&lt;li&gt;AI-generated content is not used to answer something already answered in the FAQ/wiki&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you\u2019re not sure whether or not your post violates the rule, please message us and we would be more than happy to provide guidance.&lt;/p&gt;\n\n&lt;h1&gt;New events page&lt;/h1&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rcjho150syua1.png?width=330&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=b97938287feb0084644548c40a9011d0bd3062d3\"&gt;Events widget in the sidebar&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks to &lt;a href=\"/u/AdiPolak\"&gt;u/AdiPolak&lt;/a&gt; for the suggestion! You\u2019ll now see upcoming events in the sidebar widget and the &lt;a href=\"https://dataengineering.wiki/Community/Events\"&gt;wiki&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;If you\u2019d like to share an event with the community, &lt;a href=\"https://dataengineering.wiki/Community/Events\"&gt;just fill out this form&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;We encourage everyone to post events here going forward instead of the main feed.&lt;/p&gt;\n\n&lt;h1&gt;Wiki updates&lt;/h1&gt;\n\n&lt;p&gt;The &lt;a href=\"https://dataengineering.wiki/Learning+Resources\"&gt;learning resources&lt;/a&gt; links are now clickable again! Also, the site has been optimized for performance and should be much faster now.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9kga4a25syua1.png?width=386&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=3ab396ebcf089bc560446ac514fb7bdf264ce72a\"&gt;Google Lighthouse stats for the wiki&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We\u2019ve also added a way to give feedback on any page. You can give a thumbs up/thumbs down as well as leave a comment to let us know about any opportunities for improvement.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qwgc14w7syua1.png?width=319&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=08ad0f7191a641f97e6373d650ffd8b90c8b8b7e\"&gt;Feedback form on the wiki footer&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you\u2019re more of a hands-on kind of person, don\u2019t forget that the wiki is entirely &lt;a href=\"https://github.com/data-engineering-community/data-engineering-wiki\"&gt;open source&lt;/a&gt; and you can make edits via GitHub or by clicking on &lt;strong&gt;Edit in GitHub&lt;/strong&gt; at the bottom of any page.&lt;/p&gt;\n\n&lt;p&gt;Shout out to all of our contributors and those who have sponsored the development of the wiki!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/epgko7ebsyua1.png?width=294&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9d8f562a6a12de188e6709f26a79f1d6ba952ab7\"&gt;Wiki contributors - thank you!&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Community Newsletter&lt;/h1&gt;\n\n&lt;p&gt;We are experimenting with a &lt;a href=\"https://dataengineeringcommunity.substack.com/\"&gt;monthly newsletter&lt;/a&gt; that will round up all of the best content from the community as well as highlight events. As the community grows it may feel harder to keep up to date with everything that&amp;#39;s happening and this newsletter is meant to help with that. It will always be free and open, we are using substack simply because it allows us to send it for free regardless of subscriber count.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://dataengineeringcommunity.substack.com/\"&gt;Subscribe here&lt;/a&gt; to get the first edition which will send on 4/30/23.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/message/compose?to=/r/dataengineering\"&gt;Please let us know&lt;/a&gt; if you\u2019d like to contribute to this project or have ideas.&lt;/p&gt;\n\n&lt;p&gt;--&lt;/p&gt;\n\n&lt;p&gt;As always, feedback is welcome and encouraged. Tell us in the comments one thing you like and one thing you&amp;#39;d like to see improved!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tURCIEMpGxhqJTMJmozjdramqt4eGfSAG84Gxss9XCE.jpg?auto=webp&amp;v=enabled&amp;s=4b36899b010594944b23ef03f103bbae77d0b4e3", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/tURCIEMpGxhqJTMJmozjdramqt4eGfSAG84Gxss9XCE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=862d090700be11aabac0afa724fc1258f70a3898", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/tURCIEMpGxhqJTMJmozjdramqt4eGfSAG84Gxss9XCE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7de487ff28a51744279af90abeaefcbf64d4116", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/tURCIEMpGxhqJTMJmozjdramqt4eGfSAG84Gxss9XCE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6c43dd1f2805c74a7285675b1d869f88f4469de", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/tURCIEMpGxhqJTMJmozjdramqt4eGfSAG84Gxss9XCE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c46344c4b30ffaa6fcf72115ea655e3862ccf740", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/tURCIEMpGxhqJTMJmozjdramqt4eGfSAG84Gxss9XCE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83e495b8d8b3ffc04ab851fc75e8ebfc1faf48b7", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/tURCIEMpGxhqJTMJmozjdramqt4eGfSAG84Gxss9XCE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e2f5fe2f8cc079fc2b0e58c8c5bc23c089d24f8", "width": 1080, "height": 567}], "variants": {}, "id": "14uUMV_JWMzigH7TH0_vVdEx8CBMDuXayw_FnAn_87o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5d8a87e8-a952-11eb-9a8a-0e3979f03641", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "12swb7a", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12swb7a/community_updates_42023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/12swb7a/community_updates_42023/", "subreddit_subscribers": 101011, "created_utc": 1681992128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all:\n\nSo I've been given the vague task of 'how do we analyze and visualize our long-term data'? I've been collecting logs from different sources for the past year or so and did the hard work of figuring out the schema and setting up a pipeline to output them in parquet. I don't want to do the 'analysis' on-prem so I've started sending sample data to a S3 bucket. I naively thought that it would be as easy as registering with tableau-cloud or [preset.io](https://preset.io) and they could read json or parquet natively and directly from the s3 bucket. It seems that I need a connector to make this happen and was wondering if anyone has a recommendation (paid or not) so I can move this project forward?\n\n&amp;#x200B;\n\nThanks!", "author_fullname": "t2_4ryiru1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Visualizing parquet in s3 bucket for data analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sxihg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1681994732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all:&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;ve been given the vague task of &amp;#39;how do we analyze and visualize our long-term data&amp;#39;? I&amp;#39;ve been collecting logs from different sources for the past year or so and did the hard work of figuring out the schema and setting up a pipeline to output them in parquet. I don&amp;#39;t want to do the &amp;#39;analysis&amp;#39; on-prem so I&amp;#39;ve started sending sample data to a S3 bucket. I naively thought that it would be as easy as registering with tableau-cloud or &lt;a href=\"https://preset.io\"&gt;preset.io&lt;/a&gt; and they could read json or parquet natively and directly from the s3 bucket. It seems that I need a connector to make this happen and was wondering if anyone has a recommendation (paid or not) so I can move this project forward?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7HCwrY6WbrJr4gvoAseAlWmiuaowUmXwpks1nlIKBls.jpg?auto=webp&amp;v=enabled&amp;s=ceedf327d772db6d45176aceaa66d07fc2f1ca6a", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/7HCwrY6WbrJr4gvoAseAlWmiuaowUmXwpks1nlIKBls.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6fcec64c71372f5c5cb40085ec499b383e193c4", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/7HCwrY6WbrJr4gvoAseAlWmiuaowUmXwpks1nlIKBls.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7e8fe713464c7b4459153721e46485cb7dba1aa", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/7HCwrY6WbrJr4gvoAseAlWmiuaowUmXwpks1nlIKBls.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f9151eb51e74f37d2ae0782ae1837fcd79021ca", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/7HCwrY6WbrJr4gvoAseAlWmiuaowUmXwpks1nlIKBls.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ecdc2246cd4b2f10d12ee5d623d617c8b24f6803", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/7HCwrY6WbrJr4gvoAseAlWmiuaowUmXwpks1nlIKBls.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83b96681564df3fb2beafed26724d77de539c2bd", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/7HCwrY6WbrJr4gvoAseAlWmiuaowUmXwpks1nlIKBls.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=982c6640af95d62b1b3a9b814d0a98518a1b0f5d", "width": 1080, "height": 607}], "variants": {}, "id": "__YqDw1NGDgPEwaBIWRMCVKQmM6RcFOpg1dAbXa6-Ns"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12sxihg", "is_robot_indexable": true, "report_reasons": null, "author": "hahadonthinkso", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12sxihg/visualizing_parquet_in_s3_bucket_for_data_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12sxihg/visualizing_parquet_in_s3_bucket_for_data_analysis/", "subreddit_subscribers": 101011, "created_utc": 1681994732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_73355zm3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Create your own data catalog and data quality center using open-source tools like dbt documentation, re_data, great_expectations, and more. Explore our sandbox here:", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12sw1lw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1681991564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "demo.getre.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://demo.getre.io/#/dashboard", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12sw1lw", "is_robot_indexable": true, "report_reasons": null, "author": "mateusz_klimek", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12sw1lw/create_your_own_data_catalog_and_data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://demo.getre.io/#/dashboard", "subreddit_subscribers": 101011, "created_utc": 1681991564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a massive 11,000+ word blog put together by my colleagues here at StarTree re: these three open source real-time analytics (OLAP) databases. Would love to hear anyone's feedback.\n\nSee more: [https://startree.ai/blog/a-tale-of-three-real-time-olap-databases](https://startree.ai/blog/a-tale-of-three-real-time-olap-databases)", "author_fullname": "t2_jt32w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Tale of Three Real-Time OLAP Databases: Apache Pinot, Apache Druid, and ClickHouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12ta6lj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682014501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a massive 11,000+ word blog put together by my colleagues here at StarTree re: these three open source real-time analytics (OLAP) databases. Would love to hear anyone&amp;#39;s feedback.&lt;/p&gt;\n\n&lt;p&gt;See more: &lt;a href=\"https://startree.ai/blog/a-tale-of-three-real-time-olap-databases\"&gt;https://startree.ai/blog/a-tale-of-three-real-time-olap-databases&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/J8MqGe3QKvcsgh5tj2WYfKftzd-_Yx59tNSCPMaXORY.jpg?auto=webp&amp;v=enabled&amp;s=900d83cd5f59066e8a997ca05e5dd401b65aa563", "width": 2880, "height": 1620}, "resolutions": [{"url": "https://external-preview.redd.it/J8MqGe3QKvcsgh5tj2WYfKftzd-_Yx59tNSCPMaXORY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1fd7d9a8c0ef829fae0ad30f6452699455eb1b1e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/J8MqGe3QKvcsgh5tj2WYfKftzd-_Yx59tNSCPMaXORY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f1535da5d7d68a15334670c8cb48b82cde3cc61", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/J8MqGe3QKvcsgh5tj2WYfKftzd-_Yx59tNSCPMaXORY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf51b4f14df330739b3572a0dd0e79cfaa787317", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/J8MqGe3QKvcsgh5tj2WYfKftzd-_Yx59tNSCPMaXORY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b3f795497aad444876dfde9daeddd7d7a656780", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/J8MqGe3QKvcsgh5tj2WYfKftzd-_Yx59tNSCPMaXORY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4aa07c438b37cde774b65c4a6d7445c4373b6e1", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/J8MqGe3QKvcsgh5tj2WYfKftzd-_Yx59tNSCPMaXORY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea90ea7cc15158a64cc12d0bd087278e7feed305", "width": 1080, "height": 607}], "variants": {}, "id": "wD1aiR5D-SqApZ0bRwMaKKr7L8tLMnpHn28caOSDhAk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12ta6lj", "is_robot_indexable": true, "report_reasons": null, "author": "PeterCorless", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12ta6lj/a_tale_of_three_realtime_olap_databases_apache/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12ta6lj/a_tale_of_three_realtime_olap_databases_apache/", "subreddit_subscribers": 101011, "created_utc": 1682014501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nQuick career question, I currently work at a fortune 500 as a azure data engineer and we also utilize databricks. \n\nI recently received 2 offers: \n\nOne from Accenture federal services as a azure data engineer (25,000 more than I make now)\n\nOne from a smaller company as a data engineer using palantir foundry (15,000$ more than I make now)\n\nAt my current company I will get to that 25,000 more salary within 3 years. \n\nIs there even a market for palantir foundry ? \n\nAnyone have any experience at Accenture or the WLB?\n\nWhat would you guys do?", "author_fullname": "t2_uf4ne7uq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12tmyym", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682042730.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Quick career question, I currently work at a fortune 500 as a azure data engineer and we also utilize databricks. &lt;/p&gt;\n\n&lt;p&gt;I recently received 2 offers: &lt;/p&gt;\n\n&lt;p&gt;One from Accenture federal services as a azure data engineer (25,000 more than I make now)&lt;/p&gt;\n\n&lt;p&gt;One from a smaller company as a data engineer using palantir foundry (15,000$ more than I make now)&lt;/p&gt;\n\n&lt;p&gt;At my current company I will get to that 25,000 more salary within 3 years. &lt;/p&gt;\n\n&lt;p&gt;Is there even a market for palantir foundry ? &lt;/p&gt;\n\n&lt;p&gt;Anyone have any experience at Accenture or the WLB?&lt;/p&gt;\n\n&lt;p&gt;What would you guys do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12tmyym", "is_robot_indexable": true, "report_reasons": null, "author": "NipsAhoy2", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12tmyym/career_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12tmyym/career_question/", "subreddit_subscribers": 101011, "created_utc": 1682042730.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to do a career introspection sort of thing and see how good I am at my job. I have a senior title but I don\u2019t deserve it. Are there some online tests or something I could do to vet myself (revolving around data engineering)?", "author_fullname": "t2_7gpue71ag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reality check career wise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12syoqs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1681997284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to do a career introspection sort of thing and see how good I am at my job. I have a senior title but I don\u2019t deserve it. Are there some online tests or something I could do to vet myself (revolving around data engineering)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12syoqs", "is_robot_indexable": true, "report_reasons": null, "author": "Annual_Anxiety_4457", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12syoqs/reality_check_career_wise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12syoqs/reality_check_career_wise/", "subreddit_subscribers": 101011, "created_utc": 1681997284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why dbt Labs acquired Transform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "name": "t3_12sy3ti", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/i3ifxGFu8MG5qmXwVQlAEaRShg50Y27BDZx6jQ-h5xo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681996111.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "thdpth.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://thdpth.substack.com/p/why-dbt-labs-acquired-transform", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Uppzyv1qSkvwTXfiY09IHJKShCskeW9s1HTvM09JoS4.jpg?auto=webp&amp;v=enabled&amp;s=324c5dc8fa31730520864b87ae30294d808ffcef", "width": 1183, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Uppzyv1qSkvwTXfiY09IHJKShCskeW9s1HTvM09JoS4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5eaeb12f020e136ae7b88f791917d0e9e754f56", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Uppzyv1qSkvwTXfiY09IHJKShCskeW9s1HTvM09JoS4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=79d317f57da53afc1247abcabecf1b82e4a16693", "width": 216, "height": 109}, {"url": "https://external-preview.redd.it/Uppzyv1qSkvwTXfiY09IHJKShCskeW9s1HTvM09JoS4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad3b098cf1f9c48b96ec444dfb4ec23ea883571b", "width": 320, "height": 162}, {"url": "https://external-preview.redd.it/Uppzyv1qSkvwTXfiY09IHJKShCskeW9s1HTvM09JoS4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c91faaefc28fa38b99b02b90e281622f402010b", "width": 640, "height": 324}, {"url": "https://external-preview.redd.it/Uppzyv1qSkvwTXfiY09IHJKShCskeW9s1HTvM09JoS4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29865d63276a5f0f57af332bf095ba66aae2a41f", "width": 960, "height": 486}, {"url": "https://external-preview.redd.it/Uppzyv1qSkvwTXfiY09IHJKShCskeW9s1HTvM09JoS4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=97f0965e6c7e9d64897857e2aa93e068d13b82e2", "width": 1080, "height": 547}], "variants": {}, "id": "nRdZ_4mtWRG4hYwmp0kn3SaHv393CsdFviA4OMyz3WE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12sy3ti", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12sy3ti/why_dbt_labs_acquired_transform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://thdpth.substack.com/p/why-dbt-labs-acquired-transform", "subreddit_subscribers": 101011, "created_utc": 1681996111.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Applied for a few new opportunities, including some small or mid-size company. Some job *description* specifically asks for experience about data engineering 'on cloud', gcp/aws for example. But  we mainly make data pipeline in our own platform that are built by the department in charge of clusters and data storage, computation (Hadoop, Spark, Hive and other open-source componments mostly). When I told them such, I got rejected.\n\nI only worked in this one single company. Pertty big in the industry Mainly doing data warehouse, inner data products and analysis. Don't really know why 'On-Cloud' experience is such a must. Because from what I see it's just other kind of big data technology used instead of hadoop or spark. For data engineer, tasks are still the same: Making and optimizing data pipelines to transit, build or query using SQL or scripts. The logic beneath is still the same.", "author_fullname": "t2_oorup", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's so special about on-cloud data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12tockx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682046143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Applied for a few new opportunities, including some small or mid-size company. Some job &lt;em&gt;description&lt;/em&gt; specifically asks for experience about data engineering &amp;#39;on cloud&amp;#39;, gcp/aws for example. But  we mainly make data pipeline in our own platform that are built by the department in charge of clusters and data storage, computation (Hadoop, Spark, Hive and other open-source componments mostly). When I told them such, I got rejected.&lt;/p&gt;\n\n&lt;p&gt;I only worked in this one single company. Pertty big in the industry Mainly doing data warehouse, inner data products and analysis. Don&amp;#39;t really know why &amp;#39;On-Cloud&amp;#39; experience is such a must. Because from what I see it&amp;#39;s just other kind of big data technology used instead of hadoop or spark. For data engineer, tasks are still the same: Making and optimizing data pipelines to transit, build or query using SQL or scripts. The logic beneath is still the same.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12tockx", "is_robot_indexable": true, "report_reasons": null, "author": "GeForceKawaiiyo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12tockx/whats_so_special_about_oncloud_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12tockx/whats_so_special_about_oncloud_data_engineering/", "subreddit_subscribers": 101011, "created_utc": 1682046143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I would appreciate any experienced feedback here.\n\nI am currently building a data lake using delta tables, but without Databricks. \n\nI have some Spark pipelines that periodically partitionally write, compact, `vacuum`, `z-order`, `analize` and this works quite fine for upserting purposes and I wouldn't change it.\n\nAlso, I have a single node client that reads data directly from the data lake and exposes it to some https endpoints with FastAPI. So far I needed Spark to leverage predicate pushdown and delta metadata (lots of partitions and hundreds of GBs, can't afford to read all the data at once).\n\nRead performances are okay-ish, but not perfect. Especially because I would like to provide pagination and no Databricks means no Delta caching.\n\nI have no experience with Polars whatsoever, how would it compare in a read-only scenario considering that it does support delta tables? \n\nWould it be reasonable to think it may overspeed pyspark for filter-only queries meant to retrieve page-sized chunk of data (i.e., 100-1000 rows at the time)?\n\nThe APIs only expose `SELECT * FROM &lt;&gt; WHERE &lt;&gt;`\nkind of queries, where the conditions uses either partition or z-ordered columns.\n\nWould appreciate any feedback here, thanks in advance.", "author_fullname": "t2_31fa566d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Read-only queries on delta tables. Polars or Spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12tebg8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682022965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I would appreciate any experienced feedback here.&lt;/p&gt;\n\n&lt;p&gt;I am currently building a data lake using delta tables, but without Databricks. &lt;/p&gt;\n\n&lt;p&gt;I have some Spark pipelines that periodically partitionally write, compact, &lt;code&gt;vacuum&lt;/code&gt;, &lt;code&gt;z-order&lt;/code&gt;, &lt;code&gt;analize&lt;/code&gt; and this works quite fine for upserting purposes and I wouldn&amp;#39;t change it.&lt;/p&gt;\n\n&lt;p&gt;Also, I have a single node client that reads data directly from the data lake and exposes it to some https endpoints with FastAPI. So far I needed Spark to leverage predicate pushdown and delta metadata (lots of partitions and hundreds of GBs, can&amp;#39;t afford to read all the data at once).&lt;/p&gt;\n\n&lt;p&gt;Read performances are okay-ish, but not perfect. Especially because I would like to provide pagination and no Databricks means no Delta caching.&lt;/p&gt;\n\n&lt;p&gt;I have no experience with Polars whatsoever, how would it compare in a read-only scenario considering that it does support delta tables? &lt;/p&gt;\n\n&lt;p&gt;Would it be reasonable to think it may overspeed pyspark for filter-only queries meant to retrieve page-sized chunk of data (i.e., 100-1000 rows at the time)?&lt;/p&gt;\n\n&lt;p&gt;The APIs only expose &lt;code&gt;SELECT * FROM &amp;lt;&amp;gt; WHERE &amp;lt;&amp;gt;&lt;/code&gt;\nkind of queries, where the conditions uses either partition or z-ordered columns.&lt;/p&gt;\n\n&lt;p&gt;Would appreciate any feedback here, thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12tebg8", "is_robot_indexable": true, "report_reasons": null, "author": "Perfecy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12tebg8/readonly_queries_on_delta_tables_polars_or_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12tebg8/readonly_queries_on_delta_tables_polars_or_spark/", "subreddit_subscribers": 101011, "created_utc": 1682022965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_14v3ms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The False Promise of dbt Contracts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12t4hf0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1682004488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tobikodata.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://tobikodata.com/the-false-promise-of-dbt-contracts.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12t4hf0", "is_robot_indexable": true, "report_reasons": null, "author": "s0ck_r4w", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12t4hf0/the_false_promise_of_dbt_contracts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://tobikodata.com/the-false-promise-of-dbt-contracts.html", "subreddit_subscribers": 101011, "created_utc": 1682004488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently Migration from PowerCenter to IICS, but wanting to look into alternatives. \n\n&amp;#x200B;\n\nHas anyone migrated from IICS to Fivetran? What issues did you face. How does the billing compare?", "author_fullname": "t2_hz1s0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opinions on Fivetran vs IICS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12t0s01", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682001303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently Migration from PowerCenter to IICS, but wanting to look into alternatives. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Has anyone migrated from IICS to Fivetran? What issues did you face. How does the billing compare?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12t0s01", "is_robot_indexable": true, "report_reasons": null, "author": "DenverLittle", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12t0s01/opinions_on_fivetran_vs_iics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12t0s01/opinions_on_fivetran_vs_iics/", "subreddit_subscribers": 101011, "created_utc": 1682001303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What would you recommend and why... I am planning to transform JSON to CSV and then  CSV to SQL server. Based on your experience what would you recommend ?\n\nThe reason of having a staging if for quality conformance", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "JSON -&gt; Staging -&gt; AZURE SQL Recommendations for file format in staging layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12t0qkf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682001270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What would you recommend and why... I am planning to transform JSON to CSV and then  CSV to SQL server. Based on your experience what would you recommend ?&lt;/p&gt;\n\n&lt;p&gt;The reason of having a staging if for quality conformance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12t0qkf", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12t0qkf/json_staging_azure_sql_recommendations_for_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12t0qkf/json_staging_azure_sql_recommendations_for_file/", "subreddit_subscribers": 101011, "created_utc": 1682001270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_oy8bkrnq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A FOSS mock data stream generator for your next project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_12sz1fd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mAHH3c62Nmc-6tSi605KQsAyR0zqaZGocEjtaObZ6pw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681997987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tinybird.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.tinybird.co/blog-posts/mockingbird-announcement-mock-data-generator", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gN72XGjQvJSdXmjLOV4ru3-MoSeq3XQ2hKCsMqPHUPU.jpg?auto=webp&amp;v=enabled&amp;s=24c1be25dc601837ac225ce9ae4f257ec88b3bc8", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/gN72XGjQvJSdXmjLOV4ru3-MoSeq3XQ2hKCsMqPHUPU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a005ed9cf55f0d1eedc521cab484c2bd49b026b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/gN72XGjQvJSdXmjLOV4ru3-MoSeq3XQ2hKCsMqPHUPU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6db396da245c7a322cbfa28a90748f8c6fd9d00", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/gN72XGjQvJSdXmjLOV4ru3-MoSeq3XQ2hKCsMqPHUPU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53231ae1e362e9a96465bf05e8ed0b1752f6134c", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/gN72XGjQvJSdXmjLOV4ru3-MoSeq3XQ2hKCsMqPHUPU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=62bb3109453d25747f9e0d301319d4b7e2bb2bbd", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/gN72XGjQvJSdXmjLOV4ru3-MoSeq3XQ2hKCsMqPHUPU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d75933dcee66b10af6a8b95c6ace793e139c953", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/gN72XGjQvJSdXmjLOV4ru3-MoSeq3XQ2hKCsMqPHUPU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ecf254613d0013b6e891f937e94f8b86274df3ff", "width": 1080, "height": 567}], "variants": {}, "id": "Fia2mHnLqXlFTAqSEO_uu_s6Yc4rqN9zIjLiN0zKuvw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "12sz1fd", "is_robot_indexable": true, "report_reasons": null, "author": "tinybirdco", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12sz1fd/a_foss_mock_data_stream_generator_for_your_next/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.tinybird.co/blog-posts/mockingbird-announcement-mock-data-generator", "subreddit_subscribers": 101011, "created_utc": 1681997987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "my current data engineering position mostly involves data and systems that aren\u2019t very exciting to me (e.g. financial data). but this spaceX launch has me thinking about how interesting it would be to work on the streaming pipelines for SpaceX rocket telemetry. What other unique and interesting data engineering roles like that exist?", "author_fullname": "t2_8e3c179e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "the most interesting data engineering positions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12tpa3u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682048591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;my current data engineering position mostly involves data and systems that aren\u2019t very exciting to me (e.g. financial data). but this spaceX launch has me thinking about how interesting it would be to work on the streaming pipelines for SpaceX rocket telemetry. What other unique and interesting data engineering roles like that exist?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12tpa3u", "is_robot_indexable": true, "report_reasons": null, "author": "jaredfromspacecamp", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12tpa3u/the_most_interesting_data_engineering_positions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12tpa3u/the_most_interesting_data_engineering_positions/", "subreddit_subscribers": 101011, "created_utc": 1682048591.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Could be fundamental or trending", "author_fullname": "t2_40cnwzjv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What skills will help you to survive in some scenario like layoff?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12togfc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682046416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could be fundamental or trending&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "12togfc", "is_robot_indexable": true, "report_reasons": null, "author": "zbox1415", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12togfc/what_skills_will_help_you_to_survive_in_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12togfc/what_skills_will_help_you_to_survive_in_some/", "subreddit_subscribers": 101011, "created_utc": 1682046416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a use case to store (ingest) telemetry data that is formatted as json.  Each message is about 1K.  Data comes in over Kafka.  When the data is stored, I need to query the data (I can use SQL or NoSQL, I am flexible in the interface).\n\nMy architect is asking me to store this data into a mongo cluster.  From what I understand, Druid does the same thing as well.  What do you guys recommend?  What are the pros and cons?", "author_fullname": "t2_bluzq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache druid vs Mongo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12tlwyl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682040214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a use case to store (ingest) telemetry data that is formatted as json.  Each message is about 1K.  Data comes in over Kafka.  When the data is stored, I need to query the data (I can use SQL or NoSQL, I am flexible in the interface).&lt;/p&gt;\n\n&lt;p&gt;My architect is asking me to store this data into a mongo cluster.  From what I understand, Druid does the same thing as well.  What do you guys recommend?  What are the pros and cons?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12tlwyl", "is_robot_indexable": true, "report_reasons": null, "author": "Beertimeanytime", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12tlwyl/apache_druid_vs_mongo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12tlwyl/apache_druid_vs_mongo/", "subreddit_subscribers": 101011, "created_utc": 1682040214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to run a web scraping python script that generates json files on EC2 instance then connect the instance to Kinesis.\n\nI can't wrap my head on how to do this. \n\nI need some resources that could help me do this. Something like a guided project for example. \n\nI need some help please.", "author_fullname": "t2_1f15w5lz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EC2 with Kinesis Data streams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12tlhsq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682039242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to run a web scraping python script that generates json files on EC2 instance then connect the instance to Kinesis.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t wrap my head on how to do this. &lt;/p&gt;\n\n&lt;p&gt;I need some resources that could help me do this. Something like a guided project for example. &lt;/p&gt;\n\n&lt;p&gt;I need some help please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12tlhsq", "is_robot_indexable": true, "report_reasons": null, "author": "I-am_Not_Sure", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12tlhsq/ec2_with_kinesis_data_streams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12tlhsq/ec2_with_kinesis_data_streams/", "subreddit_subscribers": 101011, "created_utc": 1682039242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone worked with the \"Operational Data Layer\" architecture? The idea is to have an offload layer of mainframe data in the cloud for transactional consumption via APIs, not for analytical.\n\nRef: https://www.mongodb.com/collateral/implementing-an-operational-data-layer", "author_fullname": "t2_z4ea7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Operational Data Layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12tj6ly", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682033804.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone worked with the &amp;quot;Operational Data Layer&amp;quot; architecture? The idea is to have an offload layer of mainframe data in the cloud for transactional consumption via APIs, not for analytical.&lt;/p&gt;\n\n&lt;p&gt;Ref: &lt;a href=\"https://www.mongodb.com/collateral/implementing-an-operational-data-layer\"&gt;https://www.mongodb.com/collateral/implementing-an-operational-data-layer&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iIXCbGZ5mGkuRyTFnyoaeSmeTEQ-s_hXbSA2TI3W05w.jpg?auto=webp&amp;v=enabled&amp;s=4d0e5122de6d4ad87574f5c31c130c2f0816e5ea", "width": 1200, "height": 601}, "resolutions": [{"url": "https://external-preview.redd.it/iIXCbGZ5mGkuRyTFnyoaeSmeTEQ-s_hXbSA2TI3W05w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e50bf9f8ae0b10c2550f9ee3eac6b6788e725d58", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/iIXCbGZ5mGkuRyTFnyoaeSmeTEQ-s_hXbSA2TI3W05w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=22acd42800e34b60c780f8e454a502f68a5e1b80", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/iIXCbGZ5mGkuRyTFnyoaeSmeTEQ-s_hXbSA2TI3W05w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=62ee96dc5c7ee55560cb8e18e03dc7954f7d9e3c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/iIXCbGZ5mGkuRyTFnyoaeSmeTEQ-s_hXbSA2TI3W05w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78985a472e163338ceefd97e75a5fc3e2e6937bd", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/iIXCbGZ5mGkuRyTFnyoaeSmeTEQ-s_hXbSA2TI3W05w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73b969be08b7028fdd476f5e48e8cd8b0d712cc9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/iIXCbGZ5mGkuRyTFnyoaeSmeTEQ-s_hXbSA2TI3W05w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f989646a090537bac16869c3f68e36c658baa0b0", "width": 1080, "height": 540}], "variants": {}, "id": "9cMT5a0hMRy5J7cG3lurHYe3JYa222Qg02VNunMDa60"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12tj6ly", "is_robot_indexable": true, "report_reasons": null, "author": "aleebit", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12tj6ly/operational_data_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12tj6ly/operational_data_layer/", "subreddit_subscribers": 101011, "created_utc": 1682033804.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2bhtmk4t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introduction to Data Quality with Apache Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 95, "top_awarded_type": null, "hide_score": false, "name": "t3_12thpih", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ma6jemfxkJhO7PBZlyCf9prP2PIAq3CX435QBjT8PIc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682030443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ssmertin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ssmertin.com/articles/into-to-data-quality-with-apache-spark/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fqkzaI4T2FudgP00zsOVI36AqllpjU5e0GQVtDI3MDk.jpg?auto=webp&amp;v=enabled&amp;s=d3f75f8fb2b7b466ac5387f5eb8e2138515fd21a", "width": 956, "height": 650}, "resolutions": [{"url": "https://external-preview.redd.it/fqkzaI4T2FudgP00zsOVI36AqllpjU5e0GQVtDI3MDk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=084a6b0fa0f0dce1526f171fc30a06be309563ff", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/fqkzaI4T2FudgP00zsOVI36AqllpjU5e0GQVtDI3MDk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8be8319f0804dc32bd9f64fedcfd89c088e01d38", "width": 216, "height": 146}, {"url": "https://external-preview.redd.it/fqkzaI4T2FudgP00zsOVI36AqllpjU5e0GQVtDI3MDk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30daca78d1685d6c8fa9df505d49dd0f96e7fb28", "width": 320, "height": 217}, {"url": "https://external-preview.redd.it/fqkzaI4T2FudgP00zsOVI36AqllpjU5e0GQVtDI3MDk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53fa18a4763425e8da48dc6e1c3e40ffdd7dd5e0", "width": 640, "height": 435}], "variants": {}, "id": "L1Yb0PtWmCThbzzDwWEupJeJQaMgNhDypG04WFeckl4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "12thpih", "is_robot_indexable": true, "report_reasons": null, "author": "nf_x", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12thpih/introduction_to_data_quality_with_apache_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ssmertin.com/articles/into-to-data-quality-with-apache-spark/", "subreddit_subscribers": 101011, "created_utc": 1682030443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, this is my first post here and I'm a little bit excited.\n\nWhen I first started working with column-oriented DBMS ClickHouse, I struggled to find a tool (other than the one built into the [ClickHouse Cloud](https://clickhouse.cloud/) web-UI) that would create the necessary table with the required columns and data types based on a CSV file or Pandas dataframe. Neither clickhouse-connect nor clickhouse-driver had this functionality, such as the `to_sql` method in SQLAlchemy.\n\nI wanted to load my favorite dataset of open-wheel Formula 1 racing world championship results into ClickHouse, but manually creating 15 tables was too time-consuming.\n\nWhen I previously familiared with PySpark,  I noticed that many data professionals use Pandas to define the data  schema before loading CSV files into PySpark. And I thought, why not use Pandas to define the data types by columns?\n\nThis is how [this script](https://github.com/pvl-k/csv2clickhouse) was born, which I want to share. I hope it saves you some time, and it will give me the opportunity to receive a couple of feedbacks and ideas from you for improvement.\n\nI'm not sure about the complete compatibility of data types between Pandas and ClickHouse: quick research gave conflicting results, so please correct me if you find any discrepancies.\n\nAnd be careful with the `replace_flag` \\- when set to True, the script will recreate tables with the same name if they already exist, so you may lose existing data in your database. To avoid this, but also prevent data duplication, I recommend specifying a non-existent database name as the `database_name`. When set to False in the `replace_flag`, data from your CSV files will be added to existing tables with the same name (of course, the number of columns and their data types must match).", "author_fullname": "t2_hmsnetde", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fast way to upload several CSV files -&gt; ClickHouse with create a database and tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12tfq8h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682026033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, this is my first post here and I&amp;#39;m a little bit excited.&lt;/p&gt;\n\n&lt;p&gt;When I first started working with column-oriented DBMS ClickHouse, I struggled to find a tool (other than the one built into the &lt;a href=\"https://clickhouse.cloud/\"&gt;ClickHouse Cloud&lt;/a&gt; web-UI) that would create the necessary table with the required columns and data types based on a CSV file or Pandas dataframe. Neither clickhouse-connect nor clickhouse-driver had this functionality, such as the &lt;code&gt;to_sql&lt;/code&gt; method in SQLAlchemy.&lt;/p&gt;\n\n&lt;p&gt;I wanted to load my favorite dataset of open-wheel Formula 1 racing world championship results into ClickHouse, but manually creating 15 tables was too time-consuming.&lt;/p&gt;\n\n&lt;p&gt;When I previously familiared with PySpark,  I noticed that many data professionals use Pandas to define the data  schema before loading CSV files into PySpark. And I thought, why not use Pandas to define the data types by columns?&lt;/p&gt;\n\n&lt;p&gt;This is how &lt;a href=\"https://github.com/pvl-k/csv2clickhouse\"&gt;this script&lt;/a&gt; was born, which I want to share. I hope it saves you some time, and it will give me the opportunity to receive a couple of feedbacks and ideas from you for improvement.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure about the complete compatibility of data types between Pandas and ClickHouse: quick research gave conflicting results, so please correct me if you find any discrepancies.&lt;/p&gt;\n\n&lt;p&gt;And be careful with the &lt;code&gt;replace_flag&lt;/code&gt; - when set to True, the script will recreate tables with the same name if they already exist, so you may lose existing data in your database. To avoid this, but also prevent data duplication, I recommend specifying a non-existent database name as the &lt;code&gt;database_name&lt;/code&gt;. When set to False in the &lt;code&gt;replace_flag&lt;/code&gt;, data from your CSV files will be added to existing tables with the same name (of course, the number of columns and their data types must match).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "12tfq8h", "is_robot_indexable": true, "report_reasons": null, "author": "Pavel_K0", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12tfq8h/fast_way_to_upload_several_csv_files_clickhouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12tfq8h/fast_way_to_upload_several_csv_files_clickhouse/", "subreddit_subscribers": 101011, "created_utc": 1682026033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working with S3 and my team has just tasked me with figuring out how to track versioning of the objects. For example, say that one of the files has a monthly upload, but sometimes those monthly uploads are changed with a new version. So we want the latest version of the \"January\" upload. \n\nI'm looking at the Data Cataglog that comes with S3 and writing metadata when the object is uploaded but there doesn't seem to be any clear cut resources to implement the following: \n\n1) Create an entry in a data catalog with the month upload and version.   \n2) Pull the object  URI from the data catalog based a query of month and latest version  \n3) Bonus points if when a new version is uploaded it can alert downstream consumers (email?) that a new version has been uploaded\n\nApologize if this is a simple ask and/or it is stated poorly. I'm very new to AWS.", "author_fullname": "t2_1yn5o9p2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tracking Objects in a Data Lake - Help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12te2as", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682022430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working with S3 and my team has just tasked me with figuring out how to track versioning of the objects. For example, say that one of the files has a monthly upload, but sometimes those monthly uploads are changed with a new version. So we want the latest version of the &amp;quot;January&amp;quot; upload. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking at the Data Cataglog that comes with S3 and writing metadata when the object is uploaded but there doesn&amp;#39;t seem to be any clear cut resources to implement the following: &lt;/p&gt;\n\n&lt;p&gt;1) Create an entry in a data catalog with the month upload and version.&lt;br/&gt;\n2) Pull the object  URI from the data catalog based a query of month and latest version&lt;br/&gt;\n3) Bonus points if when a new version is uploaded it can alert downstream consumers (email?) that a new version has been uploaded&lt;/p&gt;\n\n&lt;p&gt;Apologize if this is a simple ask and/or it is stated poorly. I&amp;#39;m very new to AWS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12te2as", "is_robot_indexable": true, "report_reasons": null, "author": "10002Hours", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12te2as/tracking_objects_in_a_data_lake_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12te2as/tracking_objects_in_a_data_lake_help/", "subreddit_subscribers": 101011, "created_utc": 1682022430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone -\n\n&amp;#x200B;\n\ni am running a pipeline that consumes data from continously scheduled api calls, returning json files. These json files are written as rawdata to a datalake, where they get picked up by a script that does some transformations and writes them out as parquet files. This happens on a per file basis, i.e.\n\ndata1001.json -&gt; data1001\\_00000.parquet\n\ndata1002.json -&gt; data1002\\_00000.parquet\n\netc.\n\nSince there are plenty of small files, this results in a bit of an IO mess, as doing it this way results in lots and lots of rather small parquet files. Therefore i have added a subsequent spark job here that reads all the files, repartions them (by a 'type' and 'product' column present in the data) and writes them back to the datalake, now with fewer files but larger file size. In order to keep these repartitioned files up to date, this spark job is run daily and processes the entire dataset.\n\nI was wondering if there was a more effective pipeline architecture that doesn't require re-loading the entire dataset into spark every day, repartitioning it and writing it back to the datalake, but rather performs some sort of upsert, to add new entries and update potentially changed rows", "author_fullname": "t2_11cqnxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "partitioned parquet files upserts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12tc6mm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682018492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone -&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;i am running a pipeline that consumes data from continously scheduled api calls, returning json files. These json files are written as rawdata to a datalake, where they get picked up by a script that does some transformations and writes them out as parquet files. This happens on a per file basis, i.e.&lt;/p&gt;\n\n&lt;p&gt;data1001.json -&amp;gt; data1001_00000.parquet&lt;/p&gt;\n\n&lt;p&gt;data1002.json -&amp;gt; data1002_00000.parquet&lt;/p&gt;\n\n&lt;p&gt;etc.&lt;/p&gt;\n\n&lt;p&gt;Since there are plenty of small files, this results in a bit of an IO mess, as doing it this way results in lots and lots of rather small parquet files. Therefore i have added a subsequent spark job here that reads all the files, repartions them (by a &amp;#39;type&amp;#39; and &amp;#39;product&amp;#39; column present in the data) and writes them back to the datalake, now with fewer files but larger file size. In order to keep these repartitioned files up to date, this spark job is run daily and processes the entire dataset.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if there was a more effective pipeline architecture that doesn&amp;#39;t require re-loading the entire dataset into spark every day, repartitioning it and writing it back to the datalake, but rather performs some sort of upsert, to add new entries and update potentially changed rows&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12tc6mm", "is_robot_indexable": true, "report_reasons": null, "author": "nihi_", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12tc6mm/partitioned_parquet_files_upserts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12tc6mm/partitioned_parquet_files_upserts/", "subreddit_subscribers": 101011, "created_utc": 1682018492.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}