{"kind": "Listing", "data": {"after": "t3_12xnk4q", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_24u5cpux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The ESA archive in Italy. Didn't know that they had 1TB \"DVD\" in the '80!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_12xe9vw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 114, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2t0LvMn8_G4?start=1213&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"L&amp;#39;incredibile evoluzione tecnologica dei dati satellitari\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "L'incredibile evoluzione tecnologica dei dati satellitari", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2t0LvMn8_G4?start=1213&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"L&amp;#39;incredibile evoluzione tecnologica dei dati satellitari\"&gt;&lt;/iframe&gt;", "author_name": "Barbascura eXtra", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/2t0LvMn8_G4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@BarbascuraEXtra"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2t0LvMn8_G4?start=1213&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"L&amp;#39;incredibile evoluzione tecnologica dei dati satellitari\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/12xe9vw", "height": 200}, "link_flair_text": "News", "can_mod_post": false, "score": 114, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/El-dBFQ1gkEkGXB0eauJ1aBJFs8iZI8u09WE8USnw7A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1682339808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=2t0LvMn8_G4&amp;t=1213s", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nVBQpuaS9IFLpJLo-a5oOamPN0le3nAq9GaNKrp_9K8.jpg?auto=webp&amp;v=enabled&amp;s=9798b06123fd4227b595a28ffa5da560c8e25f8e", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/nVBQpuaS9IFLpJLo-a5oOamPN0le3nAq9GaNKrp_9K8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4077e1b71231e314e3359d6fa6929d8564b2b087", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/nVBQpuaS9IFLpJLo-a5oOamPN0le3nAq9GaNKrp_9K8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b08e427d78b01370123b5dec86fcec424e9dc4c4", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/nVBQpuaS9IFLpJLo-a5oOamPN0le3nAq9GaNKrp_9K8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7448adf522399626cfd62cd049ed4cc39611f6d8", "width": 320, "height": 240}], "variants": {}, "id": "oXfq-fGx6Ivp58OHX9jpZpSYBSoZ-AvvyVhTT6GIxzM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xe9vw", "is_robot_indexable": true, "report_reasons": null, "author": "TopdeckIsSkill", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xe9vw/the_esa_archive_in_italy_didnt_know_that_they_had/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=2t0LvMn8_G4&amp;t=1213s", "subreddit_subscribers": 679687, "created_utc": 1682339808.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "L'incredibile evoluzione tecnologica dei dati satellitari", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2t0LvMn8_G4?start=1213&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"L&amp;#39;incredibile evoluzione tecnologica dei dati satellitari\"&gt;&lt;/iframe&gt;", "author_name": "Barbascura eXtra", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/2t0LvMn8_G4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@BarbascuraEXtra"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "At 8th of January of 2023, the Pra\u00e7a dos Tr\u00eas Poderes (the political nuclei of the capital of Brazil) suffered an invasion by terrorists.\n\nSkipping (maybe) unwanted details, **the part of the government for the buildings and it's recordings, released the relative ones as a OneDrive folder (here: https://drive.presidencia.gov.br/public/615ba7), as stated in [this Reddit post](https://www.reddit.com/r/brasil/comments/12wcheo/ricardo_cappelli_chefe_interino_do_gsi_compatilha/).**\n\nSo, I ask for help keeping these files alive, as the Brazilian government is knowingly prone to hacker attacks in order to share private information, or **destroy public data**.\n\nIn my part, I downloaded some of the folders (just what my SSD can hold besides my normal use, as it's all I have) and created a torrent file, and will be sharing it.\n\nFrom your part, I ask to **teach me** on **what else can I do** to preserve these recordings, as this community knows how to do it.\n\nThank you all for your time.\n\n\\*The file can be found at https://file.io/lABKMFAZCwL6\n\nEditing log: Fixed File.io link. I should search for another file hoster...", "author_fullname": "t2_5lsk2df0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oficial recordings of the invasion of the Brazilian capital at 8th of January of 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12x0oqo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682336686.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682305236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At 8th of January of 2023, the Pra\u00e7a dos Tr\u00eas Poderes (the political nuclei of the capital of Brazil) suffered an invasion by terrorists.&lt;/p&gt;\n\n&lt;p&gt;Skipping (maybe) unwanted details, &lt;strong&gt;the part of the government for the buildings and it&amp;#39;s recordings, released the relative ones as a OneDrive folder (here: &lt;a href=\"https://drive.presidencia.gov.br/public/615ba7\"&gt;https://drive.presidencia.gov.br/public/615ba7&lt;/a&gt;), as stated in &lt;a href=\"https://www.reddit.com/r/brasil/comments/12wcheo/ricardo_cappelli_chefe_interino_do_gsi_compatilha/\"&gt;this Reddit post&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;So, I ask for help keeping these files alive, as the Brazilian government is knowingly prone to hacker attacks in order to share private information, or &lt;strong&gt;destroy public data&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;In my part, I downloaded some of the folders (just what my SSD can hold besides my normal use, as it&amp;#39;s all I have) and created a torrent file, and will be sharing it.&lt;/p&gt;\n\n&lt;p&gt;From your part, I ask to &lt;strong&gt;teach me&lt;/strong&gt; on &lt;strong&gt;what else can I do&lt;/strong&gt; to preserve these recordings, as this community knows how to do it.&lt;/p&gt;\n\n&lt;p&gt;Thank you all for your time.&lt;/p&gt;\n\n&lt;p&gt;*The file can be found at &lt;a href=\"https://file.io/lABKMFAZCwL6\"&gt;https://file.io/lABKMFAZCwL6&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Editing log: Fixed File.io link. I should search for another file hoster...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Blockchains? I save my data on torrents.", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12x0oqo", "is_robot_indexable": true, "report_reasons": null, "author": "zekkious", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12x0oqo/oficial_recordings_of_the_invasion_of_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12x0oqo/oficial_recordings_of_the_invasion_of_the/", "subreddit_subscribers": 679687, "created_utc": 1682305236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I haven't seen such a product but I was wondering if there was some integrated automatic seamless solution to my requirements. \n\nI have baby pictures of my daughter that are worth all the treasures of the world that I want to protect. \n\nI am looking for something like an external hard-drive, which has two seperate hard-drives within it. One hard-drive automatically back-ups onto the second hard-drive with a mirror image. The idea being if one hard-drive fails, the second is good to go. \n\nI really want this to be easy and automatic. I don't really want to set up a NAS. Not really looking to overcomplicate things. I just want something that is consumer grade, works out of the box and idiot proof with minimal set up or ongoing maintenance. Ideally, it is using some reputable company that stands by their product. I am not too worried about budget, as long as it achieves these requirements. \n\nFrom some research, seems like NAS/DAS solutions are still a little too involved for my liking. \n\nI don't need a huge amount of storage, no more than 4TB for each mirror (8TB total?)\n\nEdit: Thank you all for your comments and assistance. I hear you loud and clear about the risk still in this type of solution. I still think it's a better solution than my current messy disorganized solution, of once in a blue moon remembering to copy onto different hard drives I have laying around. I think the Synology NAS might be a good option, which then I can maybe give access to family and ask if they can copy a version across to themselves??", "author_fullname": "t2_7r9ya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Consumer grade external hard-drive with multiple seperate internal hard-drives that automatically create mirror back-ups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12x1cil", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682369185.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682306642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I haven&amp;#39;t seen such a product but I was wondering if there was some integrated automatic seamless solution to my requirements. &lt;/p&gt;\n\n&lt;p&gt;I have baby pictures of my daughter that are worth all the treasures of the world that I want to protect. &lt;/p&gt;\n\n&lt;p&gt;I am looking for something like an external hard-drive, which has two seperate hard-drives within it. One hard-drive automatically back-ups onto the second hard-drive with a mirror image. The idea being if one hard-drive fails, the second is good to go. &lt;/p&gt;\n\n&lt;p&gt;I really want this to be easy and automatic. I don&amp;#39;t really want to set up a NAS. Not really looking to overcomplicate things. I just want something that is consumer grade, works out of the box and idiot proof with minimal set up or ongoing maintenance. Ideally, it is using some reputable company that stands by their product. I am not too worried about budget, as long as it achieves these requirements. &lt;/p&gt;\n\n&lt;p&gt;From some research, seems like NAS/DAS solutions are still a little too involved for my liking. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t need a huge amount of storage, no more than 4TB for each mirror (8TB total?)&lt;/p&gt;\n\n&lt;p&gt;Edit: Thank you all for your comments and assistance. I hear you loud and clear about the risk still in this type of solution. I still think it&amp;#39;s a better solution than my current messy disorganized solution, of once in a blue moon remembering to copy onto different hard drives I have laying around. I think the Synology NAS might be a good option, which then I can maybe give access to family and ask if they can copy a version across to themselves??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12x1cil", "is_robot_indexable": true, "report_reasons": null, "author": "andrew_bolkonski", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12x1cil/consumer_grade_external_harddrive_with_multiple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12x1cil/consumer_grade_external_harddrive_with_multiple/", "subreddit_subscribers": 679687, "created_utc": 1682306642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was trying to get RedditDownloader to work which seemed promising: https://shadowmoose.github.io/RedditDownloader/Getting_Started/Sources/\n\nI want to scrape the content from each post. I tried getting this to work in the command line but I'm having some difficulties because the `psaw` python package is deprecated and the downloader repo seems to be unmaintained. I tried replacing the `psaw` packages with the `pmaw` ones but no luck.", "author_fullname": "t2_594701l5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solution for mass download of GDPR saved_posts.csv?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xats9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682331534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was trying to get RedditDownloader to work which seemed promising: &lt;a href=\"https://shadowmoose.github.io/RedditDownloader/Getting_Started/Sources/\"&gt;https://shadowmoose.github.io/RedditDownloader/Getting_Started/Sources/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I want to scrape the content from each post. I tried getting this to work in the command line but I&amp;#39;m having some difficulties because the &lt;code&gt;psaw&lt;/code&gt; python package is deprecated and the downloader repo seems to be unmaintained. I tried replacing the &lt;code&gt;psaw&lt;/code&gt; packages with the &lt;code&gt;pmaw&lt;/code&gt; ones but no luck.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xats9", "is_robot_indexable": true, "report_reasons": null, "author": "agw_sommelier", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xats9/solution_for_mass_download_of_gdpr_saved_postscsv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xats9/solution_for_mass_download_of_gdpr_saved_postscsv/", "subreddit_subscribers": 679687, "created_utc": 1682331534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "their site has been virtually useless for almost a month now. i have 2 rmas i would like to initiate since early april, and i preferred to buy drives directly from them when the price was right, so i have been waiting to do that for a while now, too. im starting to see OOS on a few drive WD models across retailers. \n\nim not seeing the situation discussed around here much, which surprises me. also, while ive tried to look at news for the situation, i guess there is not much to say. most recently article i have found of any substance was a week ago. im shocked i guess. i dont remember the last time a company this big was brought to its knees so badly and for so long. in an industry with realistically only two major players its getting disturbing just how crippled WD seems to be, nevermind user data probably ending up compromised, too. \n\ndoes anybody have any hint when they are going to get it together? i would just like to get a discussion about it and get your thoughts.", "author_fullname": "t2_w9er1ost", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anybody else getting concerned about this situation with Western Digital?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12xwtsy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682371024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;their site has been virtually useless for almost a month now. i have 2 rmas i would like to initiate since early april, and i preferred to buy drives directly from them when the price was right, so i have been waiting to do that for a while now, too. im starting to see OOS on a few drive WD models across retailers. &lt;/p&gt;\n\n&lt;p&gt;im not seeing the situation discussed around here much, which surprises me. also, while ive tried to look at news for the situation, i guess there is not much to say. most recently article i have found of any substance was a week ago. im shocked i guess. i dont remember the last time a company this big was brought to its knees so badly and for so long. in an industry with realistically only two major players its getting disturbing just how crippled WD seems to be, nevermind user data probably ending up compromised, too. &lt;/p&gt;\n\n&lt;p&gt;does anybody have any hint when they are going to get it together? i would just like to get a discussion about it and get your thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "11TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "12xwtsy", "is_robot_indexable": true, "report_reasons": null, "author": "year2041", "discussion_type": null, "num_comments": 7, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12xwtsy/is_anybody_else_getting_concerned_about_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xwtsy/is_anybody_else_getting_concerned_about_this/", "subreddit_subscribers": 679687, "created_utc": 1682371024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI have a collection of thousands of CDs.  I re-ripped them at 320kbps into MusicBee (approx. 2-3 yrs ago) with their onboard ripping software.  I initially didn't bother with their capability to verify with accurip, but now am regretting that decision as some discs do seem to have some popping/background noise.\n\nIs there a way to verify these files with accurip after the fact, or would I have to re-rip all my CDs to do this?\n\nThanks in advance for the input.", "author_fullname": "t2_8jcci1qb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you verify the rip accuracy of a CD after ripping is completed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12wtpvi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682290990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have a collection of thousands of CDs.  I re-ripped them at 320kbps into MusicBee (approx. 2-3 yrs ago) with their onboard ripping software.  I initially didn&amp;#39;t bother with their capability to verify with accurip, but now am regretting that decision as some discs do seem to have some popping/background noise.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to verify these files with accurip after the fact, or would I have to re-rip all my CDs to do this?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for the input.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12wtpvi", "is_robot_indexable": true, "report_reasons": null, "author": "MKdebunker", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12wtpvi/can_you_verify_the_rip_accuracy_of_a_cd_after/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12wtpvi/can_you_verify_the_rip_accuracy_of_a_cd_after/", "subreddit_subscribers": 679687, "created_utc": 1682290990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'd love to get some help recovering about 100Gb of personal photos. I've tried DiskDrill and it found the files but it has a 100GB price for the pro version that is needed to recover more than 500MB. Anyone know how else I could do it?\n\nEdit: tried and as far as i can tell successfully used photorec - problem was there was no way as far as i could tell to specify which folders and even though i restricted the file types it still recovered far more than needed. In the end i caved and bought the damn thing (PhotoDrill) and I'll see how it goes...\n\nEdit 2: DiskDrill did it's job and successfully recovered the files.", "author_fullname": "t2_e4s9sogc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lost 97GB of photos. need help recovering.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xt820", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682373757.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682364073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d love to get some help recovering about 100Gb of personal photos. I&amp;#39;ve tried DiskDrill and it found the files but it has a 100GB price for the pro version that is needed to recover more than 500MB. Anyone know how else I could do it?&lt;/p&gt;\n\n&lt;p&gt;Edit: tried and as far as i can tell successfully used photorec - problem was there was no way as far as i could tell to specify which folders and even though i restricted the file types it still recovered far more than needed. In the end i caved and bought the damn thing (PhotoDrill) and I&amp;#39;ll see how it goes...&lt;/p&gt;\n\n&lt;p&gt;Edit 2: DiskDrill did it&amp;#39;s job and successfully recovered the files.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xt820", "is_robot_indexable": true, "report_reasons": null, "author": "no_comment_336", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xt820/lost_97gb_of_photos_need_help_recovering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xt820/lost_97gb_of_photos_need_help_recovering/", "subreddit_subscribers": 679687, "created_utc": 1682364073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/nvv95xkapvva1.png?width=2798&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=70b482135504b1593396550eddb1083ce484286d\n\n**TL;DR**\n\n1. **Is being flagged for bot-like behavior happening to users of other programs?**\n2. **Do you have alternatives other than Instaloader?**\n\n\\---------\n\nHello everyone!\n\nNot sure how many of you scrape IG stories or posts, but we're having a bit of a problem over at /r/4kdownloadapps. Basically IG has flagged users for bot-like behavior, and users of 4KStogram are\n\n* getting their accounts suspended (worst-case scenario) or\n* forcibly logged out (good-case scenario, but makes it impossible to continue using the program until we login again).\n\nThis is upsetting to those of us who use the program, but to be expected, I suppose. You can find more information here: [https://www.reddit.com/r/4kdownloadapps/comments/12vrmsd/ig\\_knows\\_4k\\_stogram\\_is\\_a\\_bot\\_pic\\_1\\_notice\\_how\\_it/](https://www.reddit.com/r/4kdownloadapps/comments/12vrmsd/ig_knows_4k_stogram_is_a_bot_pic_1_notice_how_it/)\n\nI know some of you use Instaloader. Has this problem popped up lately? It's only been happening in the last 2 weeks or so.\n\n[Raider](https://github.com/AssetKid/raider) is now defunct, so that's not a good option to use right now.\n\nAnyway, I'm looking for an alternative that doesn't face this issue, but I need it to be semi-automated. I don't mind having to click things/type something once every hour or so, but I can't manually type 1000+ account names each time or manually download each post, or that would take forever.\n\nThanks!", "author_fullname": "t2_pvdlv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Instagram Scraper Alternative to 4KStogram", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"nvv95xkapvva1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 64, "x": 108, "u": "https://preview.redd.it/nvv95xkapvva1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0f2fac313252e785ea9a287acb8271a9bc7d3d28"}, {"y": 128, "x": 216, "u": "https://preview.redd.it/nvv95xkapvva1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4737c55011c5a730a074a6c334c7186679e90ea"}, {"y": 190, "x": 320, "u": "https://preview.redd.it/nvv95xkapvva1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8e7587bee6ca21411b7db37b22962171f72a2db"}, {"y": 381, "x": 640, "u": "https://preview.redd.it/nvv95xkapvva1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29dbc8273cb87eae085eb35e0e8100adbb083f0a"}, {"y": 572, "x": 960, "u": "https://preview.redd.it/nvv95xkapvva1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=124c1caa308e44ce0d89edd867a3419e811d3310"}, {"y": 643, "x": 1080, "u": "https://preview.redd.it/nvv95xkapvva1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a7d8e20adb6303e1db67d35f9095959ec653f7d9"}], "s": {"y": 1668, "x": 2798, "u": "https://preview.redd.it/nvv95xkapvva1.png?width=2798&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=70b482135504b1593396550eddb1083ce484286d"}, "id": "nvv95xkapvva1"}}, "name": "t3_12xsiof", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/VCJPOUi2tGiFJPpNrH_EDVRajs7QVCRM2GbaFHC_ae0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1682362564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nvv95xkapvva1.png?width=2798&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=70b482135504b1593396550eddb1083ce484286d\"&gt;https://preview.redd.it/nvv95xkapvva1.png?width=2798&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=70b482135504b1593396550eddb1083ce484286d&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Is being flagged for bot-like behavior happening to users of other programs?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Do you have alternatives other than Instaloader?&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;---------&lt;/p&gt;\n\n&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;Not sure how many of you scrape IG stories or posts, but we&amp;#39;re having a bit of a problem over at &lt;a href=\"/r/4kdownloadapps\"&gt;/r/4kdownloadapps&lt;/a&gt;. Basically IG has flagged users for bot-like behavior, and users of 4KStogram are&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;getting their accounts suspended (worst-case scenario) or&lt;/li&gt;\n&lt;li&gt;forcibly logged out (good-case scenario, but makes it impossible to continue using the program until we login again).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This is upsetting to those of us who use the program, but to be expected, I suppose. You can find more information here: &lt;a href=\"https://www.reddit.com/r/4kdownloadapps/comments/12vrmsd/ig_knows_4k_stogram_is_a_bot_pic_1_notice_how_it/\"&gt;https://www.reddit.com/r/4kdownloadapps/comments/12vrmsd/ig_knows_4k_stogram_is_a_bot_pic_1_notice_how_it/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I know some of you use Instaloader. Has this problem popped up lately? It&amp;#39;s only been happening in the last 2 weeks or so.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/AssetKid/raider\"&gt;Raider&lt;/a&gt; is now defunct, so that&amp;#39;s not a good option to use right now.&lt;/p&gt;\n\n&lt;p&gt;Anyway, I&amp;#39;m looking for an alternative that doesn&amp;#39;t face this issue, but I need it to be semi-automated. I don&amp;#39;t mind having to click things/type something once every hour or so, but I can&amp;#39;t manually type 1000+ account names each time or manually download each post, or that would take forever.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-gyYu-25JcJu-ZekgGJmjl1gOkAw-rNAKHgRNS9QIR8.jpg?auto=webp&amp;v=enabled&amp;s=2ebf6354791b91a9be41935b20da4029cda5cf99", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/-gyYu-25JcJu-ZekgGJmjl1gOkAw-rNAKHgRNS9QIR8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78d01240424bd3045840cfd43be4c06065a6dd5c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/-gyYu-25JcJu-ZekgGJmjl1gOkAw-rNAKHgRNS9QIR8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6aa610010acbcd8e0e1e4d0ea898e1388ba7d6f5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/-gyYu-25JcJu-ZekgGJmjl1gOkAw-rNAKHgRNS9QIR8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a3f49b2fee9a5d55493900bb754c6664a8e6a93", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/-gyYu-25JcJu-ZekgGJmjl1gOkAw-rNAKHgRNS9QIR8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa2b5f40c02437e14b3984c1d8421be28cd33fc6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/-gyYu-25JcJu-ZekgGJmjl1gOkAw-rNAKHgRNS9QIR8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d9a9814b6a32216ca4ed7b5ace41eda4afaf804", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/-gyYu-25JcJu-ZekgGJmjl1gOkAw-rNAKHgRNS9QIR8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b90ff2e92ef2795ff508f62666802494c9103a7", "width": 1080, "height": 540}], "variants": {}, "id": "5Cu_THJoTSti2XjylUhVjxKQPmALVy3_e70fZJIOc9c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xsiof", "is_robot_indexable": true, "report_reasons": null, "author": "throwawayawerty", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xsiof/instagram_scraper_alternative_to_4kstogram/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xsiof/instagram_scraper_alternative_to_4kstogram/", "subreddit_subscribers": 679687, "created_utc": 1682362564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm slowly getting more drives, both HDDs and SSDs, for backing up all my files. These things are power hungry, though, and I want to be able to connect quite a few at once eventually. Does anyone know a reliable, externally powered USB hub with several ports? Not one of those with two USBs and a few other formats taking up space, but a big, powered, purely USB 3.0 hub. Any suggestions?", "author_fullname": "t2_37nwdqwm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for a large, powered USB hub?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12xwj6m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682370449.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m slowly getting more drives, both HDDs and SSDs, for backing up all my files. These things are power hungry, though, and I want to be able to connect quite a few at once eventually. Does anyone know a reliable, externally powered USB hub with several ports? Not one of those with two USBs and a few other formats taking up space, but a big, powered, purely USB 3.0 hub. Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xwj6m", "is_robot_indexable": true, "report_reasons": null, "author": "GetCrazyWCheeseWhiz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xwj6m/suggestions_for_a_large_powered_usb_hub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xwj6m/suggestions_for_a_large_powered_usb_hub/", "subreddit_subscribers": 679687, "created_utc": 1682370449.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi is there anyone that can help me . I have 3 external hard drives connected to laptop for plex. I'm looking at a 4 or 5 bay sabrent enclosire to hold the hard drives . I'm reading alot of bad reviews and any I look at to do with the fans being to loud . The chosen  enclosure will be kept in the same room as I watch TV. Is there anyone that has a 4 bay enclosure or above that uses it 24 7 that isn't to loud to be kept in the same room . Here is the one I'm thinking of purchasing.   But again rewies ain't good to do with noise . \n\nhttps://sabrent.com/products/ds-sc5b\n\n I'm not an advanced user and don't want a nas as  only play local for me and my family . Any help or advice is much appreciated.", "author_fullname": "t2_oxcfkreb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gard drive enclosure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xks8u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682349689.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi is there anyone that can help me . I have 3 external hard drives connected to laptop for plex. I&amp;#39;m looking at a 4 or 5 bay sabrent enclosire to hold the hard drives . I&amp;#39;m reading alot of bad reviews and any I look at to do with the fans being to loud . The chosen  enclosure will be kept in the same room as I watch TV. Is there anyone that has a 4 bay enclosure or above that uses it 24 7 that isn&amp;#39;t to loud to be kept in the same room . Here is the one I&amp;#39;m thinking of purchasing.   But again rewies ain&amp;#39;t good to do with noise . &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://sabrent.com/products/ds-sc5b\"&gt;https://sabrent.com/products/ds-sc5b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not an advanced user and don&amp;#39;t want a nas as  only play local for me and my family . Any help or advice is much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aDkw1z5r_9vfdiL5WaKjJRi7WXAQgI95me_fTeeI5zE.jpg?auto=webp&amp;v=enabled&amp;s=1149c43d360accacd879e224a9649fe2c8696084", "width": 600, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/aDkw1z5r_9vfdiL5WaKjJRi7WXAQgI95me_fTeeI5zE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b335d89b82051787e162a7759bcea888291e4c1", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/aDkw1z5r_9vfdiL5WaKjJRi7WXAQgI95me_fTeeI5zE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cce5b043dd02e91ee540038a04d34cc9a302d464", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/aDkw1z5r_9vfdiL5WaKjJRi7WXAQgI95me_fTeeI5zE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=baf5b7cd4c01bac58dffdfdbd1c93670288097d9", "width": 320, "height": 320}], "variants": {}, "id": "pisZgOOwraKE5C0B2gI9SRWA2zOQ26z9rZQm16GEbrM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xks8u", "is_robot_indexable": true, "report_reasons": null, "author": "Sparrowavfc", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xks8u/gard_drive_enclosure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xks8u/gard_drive_enclosure/", "subreddit_subscribers": 679687, "created_utc": 1682349689.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "looking at the 4tb T7 shield, reviews look good and i have the T5 ssd and its never failed me but need to upgrade on space.", "author_fullname": "t2_2o8t3n2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "anyone have a T7 shield SSD? im looking to buy one", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12xxzrb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682373360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;looking at the 4tb T7 shield, reviews look good and i have the T5 ssd and its never failed me but need to upgrade on space.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xxzrb", "is_robot_indexable": true, "report_reasons": null, "author": "QualitySound96", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xxzrb/anyone_have_a_t7_shield_ssd_im_looking_to_buy_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xxzrb/anyone_have_a_t7_shield_ssd_im_looking_to_buy_one/", "subreddit_subscribers": 679687, "created_utc": 1682373360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am thinking I need 2 18TB or larger disks!\n\n(two copies of the data - connected by 2 usb 3.0 devices! (not trusting my qnap nas)) \n\nWhich drive are the most recommended, based upon size, price and life!\n\nSince I no longer trust my old supplier, Looking for recommended sellers in the USA!\n\nAs always thanks - you hoarders are fantastic!\n\nCheers", "author_fullname": "t2_kz3sxo9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting back into my data clean up project: Looking for advise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12xx9m4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682371899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thinking I need 2 18TB or larger disks!&lt;/p&gt;\n\n&lt;p&gt;(two copies of the data - connected by 2 usb 3.0 devices! (not trusting my qnap nas)) &lt;/p&gt;\n\n&lt;p&gt;Which drive are the most recommended, based upon size, price and life!&lt;/p&gt;\n\n&lt;p&gt;Since I no longer trust my old supplier, Looking for recommended sellers in the USA!&lt;/p&gt;\n\n&lt;p&gt;As always thanks - you hoarders are fantastic!&lt;/p&gt;\n\n&lt;p&gt;Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xx9m4", "is_robot_indexable": true, "report_reasons": null, "author": "jmclaugmi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xx9m4/getting_back_into_my_data_clean_up_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xx9m4/getting_back_into_my_data_clean_up_project/", "subreddit_subscribers": 679687, "created_utc": 1682371899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Apologies for the ignorant question. Perhaps some folks here can chime in\n\nI have an old 2.5\" fire wire hard drive that used to be in an enclosure. I took it out because I no longer had a way to connect to it. So, I connected a usb c to sata cable and the drive is not recognized by windows or mac. Both OS' want it to be initialized for use.\n\nI was convinced this had someething to do with bypassing the firewire, so I reluctantly bought a bunch of hardware so I can use the firewire interface. Plugged the sata to firewire PCB back into the drive and now it mounts and works perfectly.\n\nWhat exactly is the technical aspect here that I don't understand about how drives mount / work?\n\nTrying to learn and just curious. Thanks everyone!", "author_fullname": "t2_jxmu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why would a drive not mount with a sata, but will with firewire?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12xw8ii", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682369920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies for the ignorant question. Perhaps some folks here can chime in&lt;/p&gt;\n\n&lt;p&gt;I have an old 2.5&amp;quot; fire wire hard drive that used to be in an enclosure. I took it out because I no longer had a way to connect to it. So, I connected a usb c to sata cable and the drive is not recognized by windows or mac. Both OS&amp;#39; want it to be initialized for use.&lt;/p&gt;\n\n&lt;p&gt;I was convinced this had someething to do with bypassing the firewire, so I reluctantly bought a bunch of hardware so I can use the firewire interface. Plugged the sata to firewire PCB back into the drive and now it mounts and works perfectly.&lt;/p&gt;\n\n&lt;p&gt;What exactly is the technical aspect here that I don&amp;#39;t understand about how drives mount / work?&lt;/p&gt;\n\n&lt;p&gt;Trying to learn and just curious. Thanks everyone!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xw8ii", "is_robot_indexable": true, "report_reasons": null, "author": "kevstiller", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xw8ii/why_would_a_drive_not_mount_with_a_sata_but_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xw8ii/why_would_a_drive_not_mount_with_a_sata_but_will/", "subreddit_subscribers": 679687, "created_utc": 1682369920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been looking at quite a few options including SK Hynix P41, WD 850x, but most of these fast drives seem aimed towards gamers...but I don't game.\n\nMy board is new intel (Z790 chipset) I figured I'd take advantage of having Gen4 compatability since none of my m.2 slots (4) are shared and save my Motherboard's SATA connections for spinning drives until I get/need an LSI 9208-i. Not sure if the LSI card is actually more reliable than my motherboard's SATA connections. In that case I should probably be looking into 2.5\" SSD's. \n\nAnyways, thing is I want something reliable for OS and writing temporary files including transferring files to, not from my HDD's and the most \"endurance\" rated NVME's appear to be NAS NVME's. Not sure if they are fine for a desktop PC or not. What would you recommend?", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing a durable NVME for boot drive and temp file storage for new build (NVME Gen 4)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12xw61r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682369794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been looking at quite a few options including SK Hynix P41, WD 850x, but most of these fast drives seem aimed towards gamers...but I don&amp;#39;t game.&lt;/p&gt;\n\n&lt;p&gt;My board is new intel (Z790 chipset) I figured I&amp;#39;d take advantage of having Gen4 compatability since none of my m.2 slots (4) are shared and save my Motherboard&amp;#39;s SATA connections for spinning drives until I get/need an LSI 9208-i. Not sure if the LSI card is actually more reliable than my motherboard&amp;#39;s SATA connections. In that case I should probably be looking into 2.5&amp;quot; SSD&amp;#39;s. &lt;/p&gt;\n\n&lt;p&gt;Anyways, thing is I want something reliable for OS and writing temporary files including transferring files to, not from my HDD&amp;#39;s and the most &amp;quot;endurance&amp;quot; rated NVME&amp;#39;s appear to be NAS NVME&amp;#39;s. Not sure if they are fine for a desktop PC or not. What would you recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "72TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xw61r", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12xw61r/choosing_a_durable_nvme_for_boot_drive_and_temp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xw61r/choosing_a_durable_nvme_for_boot_drive_and_temp/", "subreddit_subscribers": 679687, "created_utc": 1682369794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I have sent this post over [TrueNAS](https://www.reddit.com/r/truenas/comments/12vgwbv/getting_qbittorrent_working_with_smb_dataset/) sub a few days ago but I couldn't get anywhere. Perhaps this community is more active being datahoarders and all.\n\nI am trying to install and use qbittorrent in my SMB shared dataset.\n\nUnfortunately  when I add a torrent it says it is read-only filesystem. Even if I set  apps group and user to have modify access or set my own, custom user  which I use for SMB and is definitely not read-only and has full access  to the dataset.\n\nSame dataset works fine with Emby. Is there any way around this?", "author_fullname": "t2_v3zgudb9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting qbittorrent Working with SMB Dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xrmrk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682360685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have sent this post over &lt;a href=\"https://www.reddit.com/r/truenas/comments/12vgwbv/getting_qbittorrent_working_with_smb_dataset/\"&gt;TrueNAS&lt;/a&gt; sub a few days ago but I couldn&amp;#39;t get anywhere. Perhaps this community is more active being datahoarders and all.&lt;/p&gt;\n\n&lt;p&gt;I am trying to install and use qbittorrent in my SMB shared dataset.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately  when I add a torrent it says it is read-only filesystem. Even if I set  apps group and user to have modify access or set my own, custom user  which I use for SMB and is definitely not read-only and has full access  to the dataset.&lt;/p&gt;\n\n&lt;p&gt;Same dataset works fine with Emby. Is there any way around this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xrmrk", "is_robot_indexable": true, "report_reasons": null, "author": "CitizenPixeler", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xrmrk/getting_qbittorrent_working_with_smb_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xrmrk/getting_qbittorrent_working_with_smb_dataset/", "subreddit_subscribers": 679687, "created_utc": 1682360685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I know this question has been asked a lot and I've done a fair amount of research on the topic already, but I was wondering if anyone could point me in the right direction for my specific use case. I'd like to back up my important folders (don't care about a complete HDD copy or image copy) to some sort of cloud service automatically on a regular basis, and I only want the data to flow one way from my computer to the destination. i.e. I don't care about automatically syncing files from the cloud to my computer as I've heard some horror stories about OneDrive.\n\nHere are some more details on what I'm looking for:\n\n* I want to be able to mark the folders I want to back up which will all be included in the backup process (or at least store the deltas from the new versions)\n* Have it upload to a popular cloud service like Google Drive and Backblaze (though apparently there are API costs with this?)\n* I want the program to have a scheduled task system or at least be runnable via the command line so I can set up the task myself\n* When it runs the task, it'd be great if it could manage multiple versions within the cloud service, i.e. store the past 3 backups or so and delete the oldest one when a new one comes in\n* I don't care about encryption and don't care if Google can see my files, and a bonus might be not needing the same program to get the data out. It'd be nice to just go into Google Drive and pick out the archive/manually download from another computer if I had to. Though I realize conforming to their file structure makes deltas kind of impossible\n* Since I'd be managing a list of folders that will get included in the backup, having a GUI is preferable for ease of use and hopefully something that has a clean design/is straightforward\n* Preferably free &amp; open source as I'd like to know that I can always get the program back or compile it myself, though if it's worth it I'm also willing to pay. I figure this kind of program has a somewhat specific use case but someone has to have thought of it already :')\n\nFrom what I've seen the closest program that matches these requirements might be [Duplicati](https://www.duplicati.com/), though it kind of seems like overkill with all its encryption features(?). [RClone](https://rclone.org/drive/) seems to be able to send folders to the cloud, however since it's CLI there's a world of complications there and I don't think it tracks a list of folders so I'd have to create my own script to do more than one at a time. There do seem to be GUI wrappers for RClone but no idea where to begin there. I've heard of Macrium and Veeam but those seem to be overkill enterprise solutions. Finally, there's [FreeFileSync](https://freefilesync.org/) but it's a little outdated and doesn't go straight to cloud services I believe. If anyone has suggestions working with these I can take another look but figured it'd be good to ask before diving in.\n\nI'm also considering just making this kind of program myself if there's a gap here, though I'm probably underestimating how complicated that would be haha. Thank you to anyone that recommend more programs or give more info on how I can set something up with these requirements!", "author_fullname": "t2_hnuut", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for a modern &amp; one-way backup program for Windows 10?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xq3g0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682357587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I know this question has been asked a lot and I&amp;#39;ve done a fair amount of research on the topic already, but I was wondering if anyone could point me in the right direction for my specific use case. I&amp;#39;d like to back up my important folders (don&amp;#39;t care about a complete HDD copy or image copy) to some sort of cloud service automatically on a regular basis, and I only want the data to flow one way from my computer to the destination. i.e. I don&amp;#39;t care about automatically syncing files from the cloud to my computer as I&amp;#39;ve heard some horror stories about OneDrive.&lt;/p&gt;\n\n&lt;p&gt;Here are some more details on what I&amp;#39;m looking for:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I want to be able to mark the folders I want to back up which will all be included in the backup process (or at least store the deltas from the new versions)&lt;/li&gt;\n&lt;li&gt;Have it upload to a popular cloud service like Google Drive and Backblaze (though apparently there are API costs with this?)&lt;/li&gt;\n&lt;li&gt;I want the program to have a scheduled task system or at least be runnable via the command line so I can set up the task myself&lt;/li&gt;\n&lt;li&gt;When it runs the task, it&amp;#39;d be great if it could manage multiple versions within the cloud service, i.e. store the past 3 backups or so and delete the oldest one when a new one comes in&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t care about encryption and don&amp;#39;t care if Google can see my files, and a bonus might be not needing the same program to get the data out. It&amp;#39;d be nice to just go into Google Drive and pick out the archive/manually download from another computer if I had to. Though I realize conforming to their file structure makes deltas kind of impossible&lt;/li&gt;\n&lt;li&gt;Since I&amp;#39;d be managing a list of folders that will get included in the backup, having a GUI is preferable for ease of use and hopefully something that has a clean design/is straightforward&lt;/li&gt;\n&lt;li&gt;Preferably free &amp;amp; open source as I&amp;#39;d like to know that I can always get the program back or compile it myself, though if it&amp;#39;s worth it I&amp;#39;m also willing to pay. I figure this kind of program has a somewhat specific use case but someone has to have thought of it already :&amp;#39;)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;From what I&amp;#39;ve seen the closest program that matches these requirements might be &lt;a href=\"https://www.duplicati.com/\"&gt;Duplicati&lt;/a&gt;, though it kind of seems like overkill with all its encryption features(?). &lt;a href=\"https://rclone.org/drive/\"&gt;RClone&lt;/a&gt; seems to be able to send folders to the cloud, however since it&amp;#39;s CLI there&amp;#39;s a world of complications there and I don&amp;#39;t think it tracks a list of folders so I&amp;#39;d have to create my own script to do more than one at a time. There do seem to be GUI wrappers for RClone but no idea where to begin there. I&amp;#39;ve heard of Macrium and Veeam but those seem to be overkill enterprise solutions. Finally, there&amp;#39;s &lt;a href=\"https://freefilesync.org/\"&gt;FreeFileSync&lt;/a&gt; but it&amp;#39;s a little outdated and doesn&amp;#39;t go straight to cloud services I believe. If anyone has suggestions working with these I can take another look but figured it&amp;#39;d be good to ask before diving in.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also considering just making this kind of program myself if there&amp;#39;s a gap here, though I&amp;#39;m probably underestimating how complicated that would be haha. Thank you to anyone that recommend more programs or give more info on how I can set something up with these requirements!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Sddq76jOuzX1z0l1ZHWi_2SjLw6mvfRyaWycvQou2AY.jpg?auto=webp&amp;v=enabled&amp;s=d1971911135a2f3c57137ca83e944e4959e3e753", "width": 512, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/Sddq76jOuzX1z0l1ZHWi_2SjLw6mvfRyaWycvQou2AY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7bd07c952c215954d1b94e583950954470fc299d", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/Sddq76jOuzX1z0l1ZHWi_2SjLw6mvfRyaWycvQou2AY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5630b768798c299259a8dfa2d62c39f6b10609cd", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/Sddq76jOuzX1z0l1ZHWi_2SjLw6mvfRyaWycvQou2AY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4acd08f2ff1681d3a4fbf7253f0480458263c845", "width": 320, "height": 320}], "variants": {}, "id": "vm9ErG4MA1q6pmDvSbM0tITzDf5pZ22J75oNcNinRnk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xq3g0", "is_robot_indexable": true, "report_reasons": null, "author": "SomeGuy322", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xq3g0/recommendations_for_a_modern_oneway_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xq3g0/recommendations_for_a_modern_oneway_backup/", "subreddit_subscribers": 679687, "created_utc": 1682357587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://imgur.com/a/HbO4yuj](https://imgur.com/a/HbO4yuj)  \n\n\nThis is what I get when starting the computer sometimes. But if I use Hard disk Sentinel or other applications, they all tell me that the current health of the disk is fine.  \n\n\nSuggestions?", "author_fullname": "t2_5b8mkfvq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Smart telling me hard disk is failing on boot, but Hard disk sentinel tells otherwise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xpkuu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682356493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://imgur.com/a/HbO4yuj\"&gt;https://imgur.com/a/HbO4yuj&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;This is what I get when starting the computer sometimes. But if I use Hard disk Sentinel or other applications, they all tell me that the current health of the disk is fine.  &lt;/p&gt;\n\n&lt;p&gt;Suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yh_UDWSLQlP6IQiEVChOu1AS5lxC95LMtgELdaevZBs.jpg?auto=webp&amp;v=enabled&amp;s=29c200e5389e8b00429a1a95fa2719159b8167c6", "width": 2001, "height": 433}, "resolutions": [{"url": "https://external-preview.redd.it/yh_UDWSLQlP6IQiEVChOu1AS5lxC95LMtgELdaevZBs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8121abb565a8bea93c2d9f39507c30707f5e659e", "width": 108, "height": 23}, {"url": "https://external-preview.redd.it/yh_UDWSLQlP6IQiEVChOu1AS5lxC95LMtgELdaevZBs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cbc3d807dc4c2cd5a689303e3da7525190ca4a19", "width": 216, "height": 46}, {"url": "https://external-preview.redd.it/yh_UDWSLQlP6IQiEVChOu1AS5lxC95LMtgELdaevZBs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6d378afae27d62d7419620f95d59295157bcd09", "width": 320, "height": 69}, {"url": "https://external-preview.redd.it/yh_UDWSLQlP6IQiEVChOu1AS5lxC95LMtgELdaevZBs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9079af4f16a44ac992cb4009cedd7aa8dcbb93b", "width": 640, "height": 138}, {"url": "https://external-preview.redd.it/yh_UDWSLQlP6IQiEVChOu1AS5lxC95LMtgELdaevZBs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72bdff2e8d4ec4a115676809b70cf872a993280c", "width": 960, "height": 207}, {"url": "https://external-preview.redd.it/yh_UDWSLQlP6IQiEVChOu1AS5lxC95LMtgELdaevZBs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=acdf5c2d9217625f9c606f3ea755d5c1846d2f83", "width": 1080, "height": 233}], "variants": {}, "id": "wkNShwzxQIn14F5_aAcrc1Kij0cOOlV8byDXF13oPao"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xpkuu", "is_robot_indexable": true, "report_reasons": null, "author": "Extra-Big1990", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xpkuu/smart_telling_me_hard_disk_is_failing_on_boot_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xpkuu/smart_telling_me_hard_disk_is_failing_on_boot_but/", "subreddit_subscribers": 679687, "created_utc": 1682356493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have folders of files going back many years. I do a backup. Backup is happy. \n\nThen, a drive fails. I restore from backup. However, for some reason, a bunch of files is corrupted in the backup. So, I lose files. \n\nHow do I ensure that files are full and complete? NTFS seems to be happy to overwrite a good file on a disk with a corrupt or blank file from a backup. I have thousand and thousands of personal photos in my archive that I don't want to lose more of due to whatever kind of error might exist. \n\nthanks\n\nPS. I know I can \"verify backup\" or \"test\" the backup, but I can't view 100,000 photos and watch 10,000 hours of video to test/verify.", "author_fullname": "t2_1ecy02l6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to ensure file integrity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xpg85", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682356215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have folders of files going back many years. I do a backup. Backup is happy. &lt;/p&gt;\n\n&lt;p&gt;Then, a drive fails. I restore from backup. However, for some reason, a bunch of files is corrupted in the backup. So, I lose files. &lt;/p&gt;\n\n&lt;p&gt;How do I ensure that files are full and complete? NTFS seems to be happy to overwrite a good file on a disk with a corrupt or blank file from a backup. I have thousand and thousands of personal photos in my archive that I don&amp;#39;t want to lose more of due to whatever kind of error might exist. &lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n\n&lt;p&gt;PS. I know I can &amp;quot;verify backup&amp;quot; or &amp;quot;test&amp;quot; the backup, but I can&amp;#39;t view 100,000 photos and watch 10,000 hours of video to test/verify.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xpg85", "is_robot_indexable": true, "report_reasons": null, "author": "roastshadow", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xpg85/how_to_ensure_file_integrity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xpg85/how_to_ensure_file_integrity/", "subreddit_subscribers": 679687, "created_utc": 1682356215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Recently got a mediasonic 4-bay DAS system that I intend to store my movies and shows on and simply wanted to know the most $$/TB drive out there currently, searching on my own feels futile as theres just so many choices im pretty much 70% blindspot when im searching that way. for the record no this is not going to be for back ups, im well aware that a DAS is not appropriate for backups, this is just for storing things im ok with potentially losing, not to jinx myself or anything. any and all help is greatly appreciated!", "author_fullname": "t2_3bskimmc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Currently setting up a DAS, best hard drive options?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xl09j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682349885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently got a mediasonic 4-bay DAS system that I intend to store my movies and shows on and simply wanted to know the most $$/TB drive out there currently, searching on my own feels futile as theres just so many choices im pretty much 70% blindspot when im searching that way. for the record no this is not going to be for back ups, im well aware that a DAS is not appropriate for backups, this is just for storing things im ok with potentially losing, not to jinx myself or anything. any and all help is greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xl09j", "is_robot_indexable": true, "report_reasons": null, "author": "TheRealKuthooloo", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xl09j/currently_setting_up_a_das_best_hard_drive_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xl09j/currently_setting_up_a_das_best_hard_drive_options/", "subreddit_subscribers": 679687, "created_utc": 1682349885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone know of a way to see how often a drive spins up/wakes up? Like a log of when it turns on or off? I hope this is an appropriate place to post this....\n\n&amp;#x200B;\n\n Thanks.", "author_fullname": "t2_dygvgzcg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "See when HDD spins up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xfbgj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682341910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know of a way to see how often a drive spins up/wakes up? Like a log of when it turns on or off? I hope this is an appropriate place to post this....&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xfbgj", "is_robot_indexable": true, "report_reasons": null, "author": "cjb0011", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xfbgj/see_when_hdd_spins_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xfbgj/see_when_hdd_spins_up/", "subreddit_subscribers": 679687, "created_utc": 1682341910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Lots of social media sites (e.g. Twitter, Reddit, etc.) have a scrolling feature where the content out of the viewport gets erased. So even if your scroll bar is quite far down, all the stuff above is blank. This is an issue when I try to Save-As or Print a webpage from these websites to archive it, since I'll get this long HTML page or long PDF which is 95% blank, except for where I happen to be viewing the page when I hit the save/print commands. \n\nHow can I save/print a complete webpage if it has this behavior? For a test, you can try to get a complete download of the r/popular front page (e.g. produce a &gt;20 page pdf with all the text/photos visible if one were to scroll through by hand).", "author_fullname": "t2_3tj54e1x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Saving the complete contents of a scrolling social media webpage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12wygue", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682300578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lots of social media sites (e.g. Twitter, Reddit, etc.) have a scrolling feature where the content out of the viewport gets erased. So even if your scroll bar is quite far down, all the stuff above is blank. This is an issue when I try to Save-As or Print a webpage from these websites to archive it, since I&amp;#39;ll get this long HTML page or long PDF which is 95% blank, except for where I happen to be viewing the page when I hit the save/print commands. &lt;/p&gt;\n\n&lt;p&gt;How can I save/print a complete webpage if it has this behavior? For a test, you can try to get a complete download of the &lt;a href=\"/r/popular\"&gt;r/popular&lt;/a&gt; front page (e.g. produce a &amp;gt;20 page pdf with all the text/photos visible if one were to scroll through by hand).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12wygue", "is_robot_indexable": true, "report_reasons": null, "author": "dnrlk", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12wygue/saving_the_complete_contents_of_a_scrolling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12wygue/saving_the_complete_contents_of_a_scrolling/", "subreddit_subscribers": 679687, "created_utc": 1682300578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got two mapped drives and I'd like Macrium to be able to backup one of the volumes on my NAS to another volume on my NAS. I can select the backup volume in Macrium, but the source mapped drive isn't showing up on MR, only the \"physical\" drives are seen and able to be ticked.\n\nQNAP's various backup software offerings that I've tried so far have been ridiculous, and MR just works. I've been using it for about a year before I got my NAS and I'd like to keep using it, since I paid for it.\n\nIt's the simplest thing, really. I have a volume on my NAS with all my data, and I have another volume on the NAS that I want to use for backups of that data. I just want something that will copy all of the data over from the data volume to the backup volume, once every few days, and update the backup to be the same as the data volume. \n\nHow can I get MR to do this?", "author_fullname": "t2_96z9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Macrium Reflect: Ability to backup from a mapped NAS source to a mapped NAS destination?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12wwlvo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682296707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got two mapped drives and I&amp;#39;d like Macrium to be able to backup one of the volumes on my NAS to another volume on my NAS. I can select the backup volume in Macrium, but the source mapped drive isn&amp;#39;t showing up on MR, only the &amp;quot;physical&amp;quot; drives are seen and able to be ticked.&lt;/p&gt;\n\n&lt;p&gt;QNAP&amp;#39;s various backup software offerings that I&amp;#39;ve tried so far have been ridiculous, and MR just works. I&amp;#39;ve been using it for about a year before I got my NAS and I&amp;#39;d like to keep using it, since I paid for it.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s the simplest thing, really. I have a volume on my NAS with all my data, and I have another volume on the NAS that I want to use for backups of that data. I just want something that will copy all of the data over from the data volume to the backup volume, once every few days, and update the backup to be the same as the data volume. &lt;/p&gt;\n\n&lt;p&gt;How can I get MR to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "16TB RAID0 SSD / 16TB RAID1", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12wwlvo", "is_robot_indexable": true, "report_reasons": null, "author": "ultranothing", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/12wwlvo/macrium_reflect_ability_to_backup_from_a_mapped/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12wwlvo/macrium_reflect_ability_to_backup_from_a_mapped/", "subreddit_subscribers": 679687, "created_utc": 1682296707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "TL;DR Is it possible to partition the 8TB drive so I can use it as storage?\n\nI have avoided setting up an NAS, maybe it is time.\n\nHere is what I have at work.\n\nBackground. My wife and I run a newspaper and an insurance agency out of the office that is next door to our house in a town of 495 population. Been doing Ins for 22 yrs and newspaper since 2015. Me and my wife are the only people that work in our office, no employees. We do have three chihuahuas that stay at work with us most days. In the front office, (one big room), we have two pcs. In the news room we have two pc's. We have desks side by side and build newspaper pages together every week. Everything is networked, hardwire, ethernet.\n\nNot that you had to know any of that, really.\n\nThe two news computers have the most data to store. Both are Dell T5500 Towers, each running Raid 1 on 1TB drives, running Win 7 Pro. Why don't we upgrade to Win 10 you ask? We are running legacy Adobe software -- Indesign CS3 with forever license. We don't want to be on Adobe's subscription services. That's the Why we are using Win 7. Bought two 8TB internal HDDs to put in these two machines, for storage only. Now you have the background.\n\nI installed the 8TB HDD but Win 7 says it is 1.3TB. My Bios is A15 version.\n\nIs it possible to partition the 8TB drive so I can use it as storage?\n\nEdit: added TL;DR at top", "author_fullname": "t2_ab522p09", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using 8TB HDD for storage on Win 7 Pro Dell T5500, Boot Drive is Raid 1 - Two 1TB HDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12wso3w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682289957.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682288869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR Is it possible to partition the 8TB drive so I can use it as storage?&lt;/p&gt;\n\n&lt;p&gt;I have avoided setting up an NAS, maybe it is time.&lt;/p&gt;\n\n&lt;p&gt;Here is what I have at work.&lt;/p&gt;\n\n&lt;p&gt;Background. My wife and I run a newspaper and an insurance agency out of the office that is next door to our house in a town of 495 population. Been doing Ins for 22 yrs and newspaper since 2015. Me and my wife are the only people that work in our office, no employees. We do have three chihuahuas that stay at work with us most days. In the front office, (one big room), we have two pcs. In the news room we have two pc&amp;#39;s. We have desks side by side and build newspaper pages together every week. Everything is networked, hardwire, ethernet.&lt;/p&gt;\n\n&lt;p&gt;Not that you had to know any of that, really.&lt;/p&gt;\n\n&lt;p&gt;The two news computers have the most data to store. Both are Dell T5500 Towers, each running Raid 1 on 1TB drives, running Win 7 Pro. Why don&amp;#39;t we upgrade to Win 10 you ask? We are running legacy Adobe software -- Indesign CS3 with forever license. We don&amp;#39;t want to be on Adobe&amp;#39;s subscription services. That&amp;#39;s the Why we are using Win 7. Bought two 8TB internal HDDs to put in these two machines, for storage only. Now you have the background.&lt;/p&gt;\n\n&lt;p&gt;I installed the 8TB HDD but Win 7 says it is 1.3TB. My Bios is A15 version.&lt;/p&gt;\n\n&lt;p&gt;Is it possible to partition the 8TB drive so I can use it as storage?&lt;/p&gt;\n\n&lt;p&gt;Edit: added TL;DR at top&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12wso3w", "is_robot_indexable": true, "report_reasons": null, "author": "Glass-Result-2739", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12wso3w/using_8tb_hdd_for_storage_on_win_7_pro_dell_t5500/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12wso3w/using_8tb_hdd_for_storage_on_win_7_pro_dell_t5500/", "subreddit_subscribers": 679687, "created_utc": 1682288869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am considering BB B2 as my third backup. My local discs are encrypted. The primary is LUKS  and is ZFS. The backup is ZFS encryption. I want the B2 data to be encrypted as well.\n\nConceptually,  I can do a dd and upload the whole disk as an image. But practically, this is challenging as it would require yet another disk to hold the image, not even considering wasteful upload on my puny 20 Mbps uplink (hopefully will increase to 100) and deleting the old backup image.\n\nI want to update my third back every month as it is not critical - i.e. if it is gone, it won't ruin me. Suggestions please.", "author_fullname": "t2_2lugimc5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Uploading encrypted zfs volume to cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xsucr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1682363239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am considering BB B2 as my third backup. My local discs are encrypted. The primary is LUKS  and is ZFS. The backup is ZFS encryption. I want the B2 data to be encrypted as well.&lt;/p&gt;\n\n&lt;p&gt;Conceptually,  I can do a dd and upload the whole disk as an image. But practically, this is challenging as it would require yet another disk to hold the image, not even considering wasteful upload on my puny 20 Mbps uplink (hopefully will increase to 100) and deleting the old backup image.&lt;/p&gt;\n\n&lt;p&gt;I want to update my third back every month as it is not critical - i.e. if it is gone, it won&amp;#39;t ruin me. Suggestions please.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xsucr", "is_robot_indexable": true, "report_reasons": null, "author": "logicalcliff", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xsucr/uploading_encrypted_zfs_volume_to_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12xsucr/uploading_encrypted_zfs_volume_to_cloud/", "subreddit_subscribers": 679687, "created_utc": 1682363239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on New Build and Upgrade Path (cross-posting here to hopefully get an opinion from a different audience)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12xnk4q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_177kb8i2", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "homelab", "selftext": "After over a decade with an Asus C60M1 and 3x 4TB as a TrueNAS solution, I've decided it's time to build something more robust as my storage, compute, and budget have evolved.\n\nMy requirements are to stick with mITX, and run Proxmox on an affordable motherboard/cpu that supports ECC memory that will last. Here is what I have at a cost of about $550(+tax):\n\n|Part|Price|Link|\n|:-|:-|:-|\n|Intel Xeon E-2144G 3.6 GHz 4 Core|$85.97|[https://www.ebay.com/itm/334788923881](https://www.ebay.com/itm/334788923881)|\n|9211-8i|$43.99|[https://www.ebay.com/itm/155042469639](https://www.ebay.com/itm/155042469639)|\n|Supermicro MBD-X11SCL-IF-O|$249.00|[https://www.amazon.com/gp/product/B07NSLBGG1/](https://www.amazon.com/gp/product/B07NSLBGG1/)|\n|A-Tech Server 32GB 2Rx8|$129.99|[https://www.amazon.com/gp/product/B0BQB42HC1/](https://www.amazon.com/gp/product/B0BQB42HC1/)|\n\nComparing the processor's synthetic benchmarks with my existing desktop and NAS reveals significant improvement gains (of course): [https://www.cpubenchmark.net/compare/3399vs2744vs244/Intel-Xeon-E-2144G-vs-AMD-A10-7890K-vs-AMD-C-60-APU](https://www.cpubenchmark.net/compare/3399vs2744vs244/Intel-Xeon-E-2144G-vs-AMD-A10-7890K-vs-AMD-C-60-APU)\n\nI'm also getting just one stick of 32GB memory to give myself room for a second stick if I need one in the future. The processor includes built-in graphics to allow for potential hardware transcoding. Just to start I plan to import my existing disks, but I plan to replace them with 3x 16TB HC550 which is selling renewed for $170 ([https://www.amazon.com/Ultrastar-HC550-7200RPM-3-5-Inch-Enterprise/dp/B09HVGDBYB/](https://www.amazon.com/Ultrastar-HC550-7200RPM-3-5-Inch-Enterprise/dp/B09HVGDBYB/)) or 3x 14TB HC530 renewed at $120 each for a cheaper build.\n\nI have an existing SK Hynix P31 I will use for the Proxmox system drive. With this, I plan to run TrueNAS with PCI passthrough, Home Assistant, Frigate, along with a few other containers, a linux server, and eventually a virtual Windows workstation.\n\nAny feedback on whether or not this will work and is sustainable for the next 5-7 years? Does the LSI card look genuine, and will the 32GB memory work (as one user reported an error 2F with this board)? Any risk with using renewed drives from Amazon?\n\nAppreciate any help; thanks in advance!", "author_fullname": "t2_177kb8i2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on New Build and Upgrade Path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/homelab", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12x7ms1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1682322306.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1682322035.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.homelab", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After over a decade with an Asus C60M1 and 3x 4TB as a TrueNAS solution, I&amp;#39;ve decided it&amp;#39;s time to build something more robust as my storage, compute, and budget have evolved.&lt;/p&gt;\n\n&lt;p&gt;My requirements are to stick with mITX, and run Proxmox on an affordable motherboard/cpu that supports ECC memory that will last. Here is what I have at a cost of about $550(+tax):&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Part&lt;/th&gt;\n&lt;th align=\"left\"&gt;Price&lt;/th&gt;\n&lt;th align=\"left\"&gt;Link&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Intel Xeon E-2144G 3.6 GHz 4 Core&lt;/td&gt;\n&lt;td align=\"left\"&gt;$85.97&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://www.ebay.com/itm/334788923881\"&gt;https://www.ebay.com/itm/334788923881&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;9211-8i&lt;/td&gt;\n&lt;td align=\"left\"&gt;$43.99&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://www.ebay.com/itm/155042469639\"&gt;https://www.ebay.com/itm/155042469639&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Supermicro MBD-X11SCL-IF-O&lt;/td&gt;\n&lt;td align=\"left\"&gt;$249.00&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://www.amazon.com/gp/product/B07NSLBGG1/\"&gt;https://www.amazon.com/gp/product/B07NSLBGG1/&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;A-Tech Server 32GB 2Rx8&lt;/td&gt;\n&lt;td align=\"left\"&gt;$129.99&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://www.amazon.com/gp/product/B0BQB42HC1/\"&gt;https://www.amazon.com/gp/product/B0BQB42HC1/&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Comparing the processor&amp;#39;s synthetic benchmarks with my existing desktop and NAS reveals significant improvement gains (of course): &lt;a href=\"https://www.cpubenchmark.net/compare/3399vs2744vs244/Intel-Xeon-E-2144G-vs-AMD-A10-7890K-vs-AMD-C-60-APU\"&gt;https://www.cpubenchmark.net/compare/3399vs2744vs244/Intel-Xeon-E-2144G-vs-AMD-A10-7890K-vs-AMD-C-60-APU&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also getting just one stick of 32GB memory to give myself room for a second stick if I need one in the future. The processor includes built-in graphics to allow for potential hardware transcoding. Just to start I plan to import my existing disks, but I plan to replace them with 3x 16TB HC550 which is selling renewed for $170 (&lt;a href=\"https://www.amazon.com/Ultrastar-HC550-7200RPM-3-5-Inch-Enterprise/dp/B09HVGDBYB/\"&gt;https://www.amazon.com/Ultrastar-HC550-7200RPM-3-5-Inch-Enterprise/dp/B09HVGDBYB/&lt;/a&gt;) or 3x 14TB HC530 renewed at $120 each for a cheaper build.&lt;/p&gt;\n\n&lt;p&gt;I have an existing SK Hynix P31 I will use for the Proxmox system drive. With this, I plan to run TrueNAS with PCI passthrough, Home Assistant, Frigate, along with a few other containers, a linux server, and eventually a virtual Windows workstation.&lt;/p&gt;\n\n&lt;p&gt;Any feedback on whether or not this will work and is sustainable for the next 5-7 years? Does the LSI card look genuine, and will the 32GB memory work (as one user reported an error 2F with this board)? Any risk with using renewed drives from Amazon?&lt;/p&gt;\n\n&lt;p&gt;Appreciate any help; thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_AMUyrKcQ6ngJN8IYoQNDrpJKxWP0qOVYdwf_7ZGB5w.jpg?auto=webp&amp;v=enabled&amp;s=8331e92a1fb2dee55521753fd6a97cb14b718e43", "width": 500, "height": 375}, "resolutions": [{"url": "https://external-preview.redd.it/_AMUyrKcQ6ngJN8IYoQNDrpJKxWP0qOVYdwf_7ZGB5w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8aa2583217784da9239bb1a015f058249284368", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/_AMUyrKcQ6ngJN8IYoQNDrpJKxWP0qOVYdwf_7ZGB5w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=361dce0e717dae4db1ef7a75be7603d01fcdff78", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/_AMUyrKcQ6ngJN8IYoQNDrpJKxWP0qOVYdwf_7ZGB5w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=775add97556ae1b0eff96b4a7e896bfa86a2ef7c", "width": 320, "height": 240}], "variants": {}, "id": "CkOMwFie1oH1onflHarbud5NQiv6D78JjL-aNg71T14"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "664a26e4-322a-11e6-80ae-0e0378709321", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2ubz7", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff6347", "id": "12x7ms1", "is_robot_indexable": true, "report_reasons": null, "author": "bchang02", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/homelab/comments/12x7ms1/feedback_on_new_build_and_upgrade_path/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/homelab/comments/12x7ms1/feedback_on_new_build_and_upgrade_path/", "subreddit_subscribers": 567349, "created_utc": 1682322035.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1682352326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.homelab", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/homelab/comments/12x7ms1/feedback_on_new_build_and_upgrade_path/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_AMUyrKcQ6ngJN8IYoQNDrpJKxWP0qOVYdwf_7ZGB5w.jpg?auto=webp&amp;v=enabled&amp;s=8331e92a1fb2dee55521753fd6a97cb14b718e43", "width": 500, "height": 375}, "resolutions": [{"url": "https://external-preview.redd.it/_AMUyrKcQ6ngJN8IYoQNDrpJKxWP0qOVYdwf_7ZGB5w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8aa2583217784da9239bb1a015f058249284368", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/_AMUyrKcQ6ngJN8IYoQNDrpJKxWP0qOVYdwf_7ZGB5w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=361dce0e717dae4db1ef7a75be7603d01fcdff78", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/_AMUyrKcQ6ngJN8IYoQNDrpJKxWP0qOVYdwf_7ZGB5w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=775add97556ae1b0eff96b4a7e896bfa86a2ef7c", "width": 320, "height": 240}], "variants": {}, "id": "CkOMwFie1oH1onflHarbud5NQiv6D78JjL-aNg71T14"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12xnk4q", "is_robot_indexable": true, "report_reasons": null, "author": "bchang02", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12x7ms1", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12xnk4q/feedback_on_new_build_and_upgrade_path/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/homelab/comments/12x7ms1/feedback_on_new_build_and_upgrade_path/", "subreddit_subscribers": 679687, "created_utc": 1682352326.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}