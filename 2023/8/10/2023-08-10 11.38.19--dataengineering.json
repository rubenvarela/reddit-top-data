{"kind": "Listing", "data": {"after": "t3_15n58ik", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just started a new job and am shocked at the state of the dbt project. I've no idea whether I am used to too high standards and I am overreacting. Would appreciate to hear some other stories of dbt at your company!\n\nSo why it is so bad, we're two analytics engineers and 1 data engineer. The data engineer mainly manages airflow and databricks so they hardly work with dbt. So it's basically two people. And we have the following:\n\n- 600+ models\n\n- no tests for most of the models\n\n- lineage is a mess. One of the core tables has 55 parents and 150 children. (Edit: wrong wording I mean rejoining of upstream concepts) Circular references all over the place.\n\n- everything in the mart is materialized as a table. They run those tables multiple times a day. Costs have been increasing at a steady pace ofcourse.\n\n- they use schemas to denote topics. The project.yml contains configs for each folder to materialize it to the correct schema. The file is 200+ lines long as a consequence.\n\nBtw they managed to get to this state in less than a year :p\n\nOh and they are migrating to a new bi tool with deadline end of October. Work hasn't even started on that. So should I run? :P\n\nEdit: fixed formatting", "author_fullname": "t2_2ol209b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is our dbt project as bad as I think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mhunt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 73, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 73, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": 1691610850.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691593433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started a new job and am shocked at the state of the dbt project. I&amp;#39;ve no idea whether I am used to too high standards and I am overreacting. Would appreciate to hear some other stories of dbt at your company!&lt;/p&gt;\n\n&lt;p&gt;So why it is so bad, we&amp;#39;re two analytics engineers and 1 data engineer. The data engineer mainly manages airflow and databricks so they hardly work with dbt. So it&amp;#39;s basically two people. And we have the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;600+ models&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;no tests for most of the models&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;lineage is a mess. One of the core tables has 55 parents and 150 children. (Edit: wrong wording I mean rejoining of upstream concepts) Circular references all over the place.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;everything in the mart is materialized as a table. They run those tables multiple times a day. Costs have been increasing at a steady pace ofcourse.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;they use schemas to denote topics. The project.yml contains configs for each folder to materialize it to the correct schema. The file is 200+ lines long as a consequence.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Btw they managed to get to this state in less than a year :p&lt;/p&gt;\n\n&lt;p&gt;Oh and they are migrating to a new bi tool with deadline end of October. Work hasn&amp;#39;t even started on that. So should I run? :P&lt;/p&gt;\n\n&lt;p&gt;Edit: fixed formatting&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mhunt", "is_robot_indexable": true, "report_reasons": null, "author": "snackeloni", "discussion_type": null, "num_comments": 116, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mhunt/is_our_dbt_project_as_bad_as_i_think/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mhunt/is_our_dbt_project_as_bad_as_i_think/", "subreddit_subscribers": 121916, "created_utc": 1691593433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My manager thinks we can get/train data engineers to be \"full stack\", that is, write AWS Python lambdas to grab data from EventBridge and load to our DW dimensional models, and have them design those models, and be able to create Power BI reports.  And be able to write good DAX and efficient datasets as well.  Do you think that is too much to ask?", "author_fullname": "t2_j15uu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Too much to expect from a data engineer? Python + Dimensional Modeling + Power BI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mpm60", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691610864.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My manager thinks we can get/train data engineers to be &amp;quot;full stack&amp;quot;, that is, write AWS Python lambdas to grab data from EventBridge and load to our DW dimensional models, and have them design those models, and be able to create Power BI reports.  And be able to write good DAX and efficient datasets as well.  Do you think that is too much to ask?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mpm60", "is_robot_indexable": true, "report_reasons": null, "author": "jbrune", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mpm60/too_much_to_expect_from_a_data_engineer_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mpm60/too_much_to_expect_from_a_data_engineer_python/", "subreddit_subscribers": 121916, "created_utc": 1691610864.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there! \n\nI am just wondering if you noticed shift in current jobs market position. Big companies seem to be back in green numbers. \n\nDo you think situation will change soon and new DE positions will be open soon?", "author_fullname": "t2_46l1zqd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is job market still dead?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mpcoh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691610275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there! &lt;/p&gt;\n\n&lt;p&gt;I am just wondering if you noticed shift in current jobs market position. Big companies seem to be back in green numbers. &lt;/p&gt;\n\n&lt;p&gt;Do you think situation will change soon and new DE positions will be open soon?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15mpcoh", "is_robot_indexable": true, "report_reasons": null, "author": "pyzo_ryzo", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mpcoh/is_job_market_still_dead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mpcoh/is_job_market_still_dead/", "subreddit_subscribers": 121916, "created_utc": 1691610275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got placed on a Data engineering team as a part of a rotational development program at my company. \n\nI\u2019m noticing that everyone on my team has years of experience (5-20) and that the least experienced people have 5-7 YOE. \n\nI\u2019m just starting out in tech, with only 6 months of professional backend engineering experience (JVM, Kafka, Postgres etc). My bachelor degree is non-CS engineering. \n\nAm I going to have a really difficult time making a career in DE because I don\u2019t have other SWE experience?\n\nI\u2019m willing to work hard and master the fundamentals in my own time outside of work, but I\u2019m scared that if I lose my current job, no other company will hire me for DE roles as junior positions are very rare. \n\nAt the same time, DE feels so niche. I don\u2019t know if the skills I develop here will apply to other backend dev jobs. What can I do to stay broadly employable?\n\nShould I pursue some cloud certification?", "author_fullname": "t2_vmcasqim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE wrong path for beginners?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mlhz8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691601657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got placed on a Data engineering team as a part of a rotational development program at my company. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m noticing that everyone on my team has years of experience (5-20) and that the least experienced people have 5-7 YOE. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m just starting out in tech, with only 6 months of professional backend engineering experience (JVM, Kafka, Postgres etc). My bachelor degree is non-CS engineering. &lt;/p&gt;\n\n&lt;p&gt;Am I going to have a really difficult time making a career in DE because I don\u2019t have other SWE experience?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m willing to work hard and master the fundamentals in my own time outside of work, but I\u2019m scared that if I lose my current job, no other company will hire me for DE roles as junior positions are very rare. &lt;/p&gt;\n\n&lt;p&gt;At the same time, DE feels so niche. I don\u2019t know if the skills I develop here will apply to other backend dev jobs. What can I do to stay broadly employable?&lt;/p&gt;\n\n&lt;p&gt;Should I pursue some cloud certification?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15mlhz8", "is_robot_indexable": true, "report_reasons": null, "author": "aaloo_chaat", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mlhz8/de_wrong_path_for_beginners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mlhz8/de_wrong_path_for_beginners/", "subreddit_subscribers": 121916, "created_utc": 1691601657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve recently been working on standing up a prototype analytics database at work utilizing Starrocks and Iceberg. I have access to a GCP instance and wanted to explore managed services that would make this setup easier to maintain. When I came across Dataproc Metastore, it sounded like a huge value add to have it serverless, self-healing, and we\u2019ll integrated with the rest of GCP if we want to lock ourselves in. But then read it costs $3.42/hr?? Seems like we\u2019d need to be running at some pretty serious volume for that to make any financial sense. Is anyone actually using this efficiently?", "author_fullname": "t2_ahqse5d9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Dataproc Metastore Worth $30k/yr?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mymv1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691632262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently been working on standing up a prototype analytics database at work utilizing Starrocks and Iceberg. I have access to a GCP instance and wanted to explore managed services that would make this setup easier to maintain. When I came across Dataproc Metastore, it sounded like a huge value add to have it serverless, self-healing, and we\u2019ll integrated with the rest of GCP if we want to lock ourselves in. But then read it costs $3.42/hr?? Seems like we\u2019d need to be running at some pretty serious volume for that to make any financial sense. Is anyone actually using this efficiently?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mymv1", "is_robot_indexable": true, "report_reasons": null, "author": "Express-Comb8675", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mymv1/is_dataproc_metastore_worth_30kyr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mymv1/is_dataproc_metastore_worth_30kyr/", "subreddit_subscribers": 121916, "created_utc": 1691632262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you want to know why I really don't like Tableau? They don't support the simplest bugs. For example, the problem where filter titles get cut off, an issue that is know since at least 2014 (https://community.tableau.com/s/idea/0874T000000H9yAQAS/detail). \nI came to my company when they already used Tableau everywhere, even though nobody liked it. And I want us to start using a different BI tool. \n\nI heard about Superset which looks nice, any other ideas? \nWhat we're looking for is something that supports sql queries and is able to present dashboards online for in house monitoring. \n\n(don't even get me started on how expensive tableau is...)", "author_fullname": "t2_zbab4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to stop using Tableau", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15moa22", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691607823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you want to know why I really don&amp;#39;t like Tableau? They don&amp;#39;t support the simplest bugs. For example, the problem where filter titles get cut off, an issue that is know since at least 2014 (&lt;a href=\"https://community.tableau.com/s/idea/0874T000000H9yAQAS/detail\"&gt;https://community.tableau.com/s/idea/0874T000000H9yAQAS/detail&lt;/a&gt;). \nI came to my company when they already used Tableau everywhere, even though nobody liked it. And I want us to start using a different BI tool. &lt;/p&gt;\n\n&lt;p&gt;I heard about Superset which looks nice, any other ideas? \nWhat we&amp;#39;re looking for is something that supports sql queries and is able to present dashboards online for in house monitoring. &lt;/p&gt;\n\n&lt;p&gt;(don&amp;#39;t even get me started on how expensive tableau is...)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15moa22", "is_robot_indexable": true, "report_reasons": null, "author": "chenvili", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15moa22/i_want_to_stop_using_tableau/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15moa22/i_want_to_stop_using_tableau/", "subreddit_subscribers": 121916, "created_utc": 1691607823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fwerb2uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Virtual Data Builds: A data warehouse environment for every Git commit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15mctop", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nR_BTR4yVxasfkKNa10X80MIwQ7aeeJ3Q6MG2-BSWBI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691581102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "y42.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.y42.com/blog/virtual-data-builds-one-data-warehouse-environment-for-every-git-commit/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?auto=webp&amp;s=dfe5baa7e55b0fdeafdd8e55ceea1f41e8bb2575", "width": 2160, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=220afd6e3120c0aad0c5a461d4b5772d0ab8243d", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d14cb37959937ca4fb686bd8de2b82c6fcf496e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2a51dfa134189b445a11664b6909846abde9a9a8", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8eac2eeda830983ca6b8fbf6f41969c9ea7a3259", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dc76ee53527828db8c839c838aaebe3675c5dc52", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a941f122abdb5a72cbe93bfb04a56e7bd369c808", "width": 1080, "height": 720}], "variants": {}, "id": "TE7uqwVe35pQ_NYMKSpfU5YX8jXz0cwr0p_FDEMXmYs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15mctop", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant-Guidance599", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mctop/virtual_data_builds_a_data_warehouse_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.y42.com/blog/virtual-data-builds-one-data-warehouse-environment-for-every-git-commit/", "subreddit_subscribers": 121916, "created_utc": 1691581102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_167vnb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datafold VS Code Extension: data diffing made easy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15mooqj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MFp6ddsuwu9S9POOQyVuH9vTmdZk0kMeqczY9i56rwE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691608777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "marketplace.visualstudio.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://marketplace.visualstudio.com/items?itemName=Datafold.datafold-vscode&amp;ssr=false#overview", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jlWbxa_RX5TSL1jGYvmtjw0kg65QwgI6Bza6xxgzl5U.jpg?auto=webp&amp;s=d53e3a099a7e9e3e0946121f050292bc4abb38b9", "width": 256, "height": 256}, "resolutions": [{"url": "https://external-preview.redd.it/jlWbxa_RX5TSL1jGYvmtjw0kg65QwgI6Bza6xxgzl5U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b6afe2191bed6185d84a0f3c0eb0474b936dfb2", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/jlWbxa_RX5TSL1jGYvmtjw0kg65QwgI6Bza6xxgzl5U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b80bc50c9c32840327a2ca4f9dc77b6e5ef3b501", "width": 216, "height": 216}], "variants": {}, "id": "yoohlCjhWZNKHvjfg4Cr6e7gi8UTyTHdjzDPPJM7bQg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15mooqj", "is_robot_indexable": true, "report_reasons": null, "author": "just_sung", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mooqj/datafold_vs_code_extension_data_diffing_made_easy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://marketplace.visualstudio.com/items?itemName=Datafold.datafold-vscode&amp;ssr=false#overview", "subreddit_subscribers": 121916, "created_utc": 1691608777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My organization uses SQL Server as our OLTP database for our applications. Unfortunately, there was very little foresight to accommodate historical business analytics. As such, I just scheduled a monthly job to run a stored proc that essentially just runs a variety of queries and appends the results to historical tables. \n\nAnyone know if this is an issue? Our DB is small (like 100GB). Our operations exec suggested contracting with a data warehouse service like Snowflake, but that seems like overkill and a cost we don\u2019t need to bear given our size.\n\nAnyone else ever have to do something like this for a small organization? I\u2019m trying to save costs but I don\u2019t want this to spiral out of control or bog down our server. Thus far, it seems to be working fine, as I\u2019ve made an effort to tune the queries as best I can.", "author_fullname": "t2_6hsp2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OLTP to OLAP ETL process for Small Organization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mtv8s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691620580.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691620387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My organization uses SQL Server as our OLTP database for our applications. Unfortunately, there was very little foresight to accommodate historical business analytics. As such, I just scheduled a monthly job to run a stored proc that essentially just runs a variety of queries and appends the results to historical tables. &lt;/p&gt;\n\n&lt;p&gt;Anyone know if this is an issue? Our DB is small (like 100GB). Our operations exec suggested contracting with a data warehouse service like Snowflake, but that seems like overkill and a cost we don\u2019t need to bear given our size.&lt;/p&gt;\n\n&lt;p&gt;Anyone else ever have to do something like this for a small organization? I\u2019m trying to save costs but I don\u2019t want this to spiral out of control or bog down our server. Thus far, it seems to be working fine, as I\u2019ve made an effort to tune the queries as best I can.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mtv8s", "is_robot_indexable": true, "report_reasons": null, "author": "suitupyo", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mtv8s/oltp_to_olap_etl_process_for_small_organization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mtv8s/oltp_to_olap_etl_process_for_small_organization/", "subreddit_subscribers": 121916, "created_utc": 1691620387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all.\n\nWe have kind of a unique situation.\n\nWe are a startup company that is basically running electricity power flow simulation software models. These models are CPU intensive, and require multiple computers in a cluster to calculate things effectively.\n\nOur software is extremely bespoke, and has been recommended by the vendor to use on-prem hardware for the actual computation piece of the software.\n\nThe specific hardware they are recommending are i9-13900k or ryzen 7950x, effectively 3ghz minimum CPU's with high clock speeds (5ghz+).\n\nHOWEVER, the only issue with this is that the data from the software is read from a microsoft SQL server environment and the forecasts and written back into the same SQL server database.\n\nWe are a small shop with zero DBA's, so we really have no idea on how to maintain on-prem databases (especially SQL server). We are looking at Azure Database or Amazon RDS as an option instead.\n\nOur software inserts probably 10-20mm records/night into this database environment, and we will probably have 1 functional account (data visualization tool) pulling data as well as 2-3 people querying per day, so I'd imagine compute is light.\n\nI know the best thing is to go cloud-cloud or on-prem on-prem, but the equivalent cloud compute for i9-13900k for 3 instances is like 1.5-2k a month while the physical hardware is like 2k for the whole computer. Physical hardware payback is like 3-4 months!\n\nAlternatively, nobody knows how to actually maintain an on-prem installation for MS Sql Server, and I feel like hiring a DBA would be substantially more expensive than using a service like Azure SQL Server.\n\nAny thoughts here? Would the latency/topology seriously be SO bad that bulk inserts for 10-20mm records would take substantially longer going into a cloud DB vs on-prem like the computers doing the software compute?", "author_fullname": "t2_92xmo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On-prem compute for software that inserts into cloud database - how stupid is this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15n2een", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691642979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all.&lt;/p&gt;\n\n&lt;p&gt;We have kind of a unique situation.&lt;/p&gt;\n\n&lt;p&gt;We are a startup company that is basically running electricity power flow simulation software models. These models are CPU intensive, and require multiple computers in a cluster to calculate things effectively.&lt;/p&gt;\n\n&lt;p&gt;Our software is extremely bespoke, and has been recommended by the vendor to use on-prem hardware for the actual computation piece of the software.&lt;/p&gt;\n\n&lt;p&gt;The specific hardware they are recommending are i9-13900k or ryzen 7950x, effectively 3ghz minimum CPU&amp;#39;s with high clock speeds (5ghz+).&lt;/p&gt;\n\n&lt;p&gt;HOWEVER, the only issue with this is that the data from the software is read from a microsoft SQL server environment and the forecasts and written back into the same SQL server database.&lt;/p&gt;\n\n&lt;p&gt;We are a small shop with zero DBA&amp;#39;s, so we really have no idea on how to maintain on-prem databases (especially SQL server). We are looking at Azure Database or Amazon RDS as an option instead.&lt;/p&gt;\n\n&lt;p&gt;Our software inserts probably 10-20mm records/night into this database environment, and we will probably have 1 functional account (data visualization tool) pulling data as well as 2-3 people querying per day, so I&amp;#39;d imagine compute is light.&lt;/p&gt;\n\n&lt;p&gt;I know the best thing is to go cloud-cloud or on-prem on-prem, but the equivalent cloud compute for i9-13900k for 3 instances is like 1.5-2k a month while the physical hardware is like 2k for the whole computer. Physical hardware payback is like 3-4 months!&lt;/p&gt;\n\n&lt;p&gt;Alternatively, nobody knows how to actually maintain an on-prem installation for MS Sql Server, and I feel like hiring a DBA would be substantially more expensive than using a service like Azure SQL Server.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts here? Would the latency/topology seriously be SO bad that bulk inserts for 10-20mm records would take substantially longer going into a cloud DB vs on-prem like the computers doing the software compute?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15n2een", "is_robot_indexable": true, "report_reasons": null, "author": "preciseman", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15n2een/onprem_compute_for_software_that_inserts_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15n2een/onprem_compute_for_software_that_inserts_into/", "subreddit_subscribers": 121916, "created_utc": 1691642979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a6it0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wrote a VSCode extension for exploring Parquet with SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15n1sez", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1691641114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "marketplace.visualstudio.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://marketplace.visualstudio.com/items?itemName=AdamViola.parquet-explorer", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "15n1sez", "is_robot_indexable": true, "report_reasons": null, "author": "supersmartypants", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15n1sez/i_wrote_a_vscode_extension_for_exploring_parquet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://marketplace.visualstudio.com/items?itemName=AdamViola.parquet-explorer", "subreddit_subscribers": 121916, "created_utc": 1691641114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am 17 and an intern at a finch company in England, I have been given a task to create a 'slack watchdog' in which messages for help to a slack channel will be monitored and if no response within an hour an automatic reply will tag a member of the appropriate response team asking them to take a look at the message. Is it possible for any of you to give me a brief overview of how I would do this and/or point me in the direction of some useful things to search (detailed things for search). \n\nThe tools I am using are Airflow and VSCode in python, as in my actual task is to create a DAG which sends these automatic assignment responses.\n\nAny help greatly appreciated!", "author_fullname": "t2_eqvikdnq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overview of how to tackle project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mirqn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691595550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am 17 and an intern at a finch company in England, I have been given a task to create a &amp;#39;slack watchdog&amp;#39; in which messages for help to a slack channel will be monitored and if no response within an hour an automatic reply will tag a member of the appropriate response team asking them to take a look at the message. Is it possible for any of you to give me a brief overview of how I would do this and/or point me in the direction of some useful things to search (detailed things for search). &lt;/p&gt;\n\n&lt;p&gt;The tools I am using are Airflow and VSCode in python, as in my actual task is to create a DAG which sends these automatic assignment responses.&lt;/p&gt;\n\n&lt;p&gt;Any help greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mirqn", "is_robot_indexable": true, "report_reasons": null, "author": "McSteamy06", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mirqn/overview_of_how_to_tackle_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mirqn/overview_of_how_to_tackle_project/", "subreddit_subscribers": 121916, "created_utc": 1691595550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How does community identifies if a requirement coming from business is an analytical or transactional ie to be run against an OLTP database or OLAP database.\n\nSecond question is that what is the best way to make business understand that business requirement is served best with right nature of data modeling within a database or tool.\n\nFor example, we have postgresql as OLTP database for our app and ClickHouse as OLAP engine however a requirement is/should not be running against its indifferent database/tool.", "author_fullname": "t2_3fc3u012", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Identify if a business requirement is an analytical or transactional in its technical nature within data warehouse/datalake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mfrwr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691588701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How does community identifies if a requirement coming from business is an analytical or transactional ie to be run against an OLTP database or OLAP database.&lt;/p&gt;\n\n&lt;p&gt;Second question is that what is the best way to make business understand that business requirement is served best with right nature of data modeling within a database or tool.&lt;/p&gt;\n\n&lt;p&gt;For example, we have postgresql as OLTP database for our app and ClickHouse as OLAP engine however a requirement is/should not be running against its indifferent database/tool.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mfrwr", "is_robot_indexable": true, "report_reasons": null, "author": "youareafakenews", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mfrwr/identify_if_a_business_requirement_is_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mfrwr/identify_if_a_business_requirement_is_an/", "subreddit_subscribers": 121916, "created_utc": 1691588701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "have been working as a junior data engineer at this small startup for almost 8 months( part-time). During that time, I have brushed up my python skills, SQL skills, Excel skills, and can proficiently use various GCP products( BQ, GCS, Dataflow, Cloud Functions). I also cleared the Google cloud certified professional D.E exam during that period and worked on multiple data focused projects; mainly ETL stuff. \nMy bachelor's degree will be wrapped up by the end of this month, so, I will be switching to a full-time role. Let's assume that my current salary, that hasn't changed since I joined this company, is INR 30000 per month. What would be a justifiable salary demand for me?\nThis is my first job so I don't really know the market too well. Plus, the company doesn't really have too many data-focused projects going on. So, I am no too sure that they are going to go out of their way and pay fancy wages to a D.E.", "author_fullname": "t2_eo907yrs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "D.E promotion, salary discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mmqnr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691604366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;have been working as a junior data engineer at this small startup for almost 8 months( part-time). During that time, I have brushed up my python skills, SQL skills, Excel skills, and can proficiently use various GCP products( BQ, GCS, Dataflow, Cloud Functions). I also cleared the Google cloud certified professional D.E exam during that period and worked on multiple data focused projects; mainly ETL stuff. \nMy bachelor&amp;#39;s degree will be wrapped up by the end of this month, so, I will be switching to a full-time role. Let&amp;#39;s assume that my current salary, that hasn&amp;#39;t changed since I joined this company, is INR 30000 per month. What would be a justifiable salary demand for me?\nThis is my first job so I don&amp;#39;t really know the market too well. Plus, the company doesn&amp;#39;t really have too many data-focused projects going on. So, I am no too sure that they are going to go out of their way and pay fancy wages to a D.E.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15mmqnr", "is_robot_indexable": true, "report_reasons": null, "author": "avg_ali", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mmqnr/de_promotion_salary_discussion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mmqnr/de_promotion_salary_discussion/", "subreddit_subscribers": 121916, "created_utc": 1691604366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "guys of dataengineering, my company laid off 70 percent of their workforce this june. i have been applying for relevant positions since then and i am not getting a single reply back honestly. I have a year of exp working as a Data Engineer. Where are all the jobs right now? I understand market is tough or whatever, but seriously, why are companies being such dicks? I NEED A BASIC ENTRY LEVEL JOB WHY TF IS THAT SO DIFFICULT? ", "author_fullname": "t2_v0a5cy3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "entry level jobs in usa", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15n76ia", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691658671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;guys of dataengineering, my company laid off 70 percent of their workforce this june. i have been applying for relevant positions since then and i am not getting a single reply back honestly. I have a year of exp working as a Data Engineer. Where are all the jobs right now? I understand market is tough or whatever, but seriously, why are companies being such dicks? I NEED A BASIC ENTRY LEVEL JOB WHY TF IS THAT SO DIFFICULT? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15n76ia", "is_robot_indexable": true, "report_reasons": null, "author": "CompetitiveWealth503", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15n76ia/entry_level_jobs_in_usa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15n76ia/entry_level_jobs_in_usa/", "subreddit_subscribers": 121916, "created_utc": 1691658671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a very simple pipeline on GCP which pulls data from an API, formats it into a pandas dataframe and then loads that into a GCS bucket as a CSV. The CSV is then loaded into a BigQuery table that powers some looker studio reports and Google Sheets analysis. \n\nCurrently the whole thing is done within a python Cloud Function and is scheduled to run daily via cloud scheduler. \n\nLooking to migrate this over to Airflow / Cloud composer and was wondering about the best way to structure it. Is it better to have all the work done within DAGs (downloading the data from the API, sending it to GCS/BigQuery)? Or is airflow meant to take the place of Cloud Scheduler and just trigger the Cloud Function which does that work? Or is there another way entirely that I should consider structuring this?\n\nAny advice is appreciated.\n\nThanks!   ", "author_fullname": "t2_5p737", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Airflow - Looking for some guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mqzvt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691613980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a very simple pipeline on GCP which pulls data from an API, formats it into a pandas dataframe and then loads that into a GCS bucket as a CSV. The CSV is then loaded into a BigQuery table that powers some looker studio reports and Google Sheets analysis. &lt;/p&gt;\n\n&lt;p&gt;Currently the whole thing is done within a python Cloud Function and is scheduled to run daily via cloud scheduler. &lt;/p&gt;\n\n&lt;p&gt;Looking to migrate this over to Airflow / Cloud composer and was wondering about the best way to structure it. Is it better to have all the work done within DAGs (downloading the data from the API, sending it to GCS/BigQuery)? Or is airflow meant to take the place of Cloud Scheduler and just trigger the Cloud Function which does that work? Or is there another way entirely that I should consider structuring this?&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks!   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mqzvt", "is_robot_indexable": true, "report_reasons": null, "author": "Frodi", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mqzvt/learning_airflow_looking_for_some_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mqzvt/learning_airflow_looking_for_some_guidance/", "subreddit_subscribers": 121916, "created_utc": 1691613980.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am a fresh university graduate student with a data science degree and hoping to move into the industry. Since I have no experience on working as a data engineer before, I was hoping to find an intern position to work. but I'm really curious whether I can apply for the junior data engineer position as well.\u00a0\n\nSo what could be the difference between an intern and a junior data engineer position? Would that be okay to apply for the junior position even though I have no working experience in the industry level?\n\nAny help would be greatly appreciated!!", "author_fullname": "t2_94z2yiq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the difference between an intern and a junior data engineer position?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mpyx6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691611626.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am a fresh university graduate student with a data science degree and hoping to move into the industry. Since I have no experience on working as a data engineer before, I was hoping to find an intern position to work. but I&amp;#39;m really curious whether I can apply for the junior data engineer position as well.\u00a0&lt;/p&gt;\n\n&lt;p&gt;So what could be the difference between an intern and a junior data engineer position? Would that be okay to apply for the junior position even though I have no working experience in the industry level?&lt;/p&gt;\n\n&lt;p&gt;Any help would be greatly appreciated!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15mpyx6", "is_robot_indexable": true, "report_reasons": null, "author": "LengthOld9943", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mpyx6/what_is_the_difference_between_an_intern_and_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mpyx6/what_is_the_difference_between_an_intern_and_a/", "subreddit_subscribers": 121916, "created_utc": 1691611626.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone here joined any professional organizations like ACM, SWE etc? \nAny groups focusing on DE?", "author_fullname": "t2_vmcasqim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Professional organizations for DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mmf0q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691603665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone here joined any professional organizations like ACM, SWE etc? \nAny groups focusing on DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mmf0q", "is_robot_indexable": true, "report_reasons": null, "author": "aaloo_chaat", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mmf0q/professional_organizations_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mmf0q/professional_organizations_for_de/", "subreddit_subscribers": 121916, "created_utc": 1691603665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to generate new column on a SQL table dynamically as per the incoming CSV file scheme change? \n\nFor ex: today I get a CSV file with 10 columns, tomorrow I will be getting 12 columns.. wants to design ADF dataflow to handle this situation without any code change \n\nWanted get this newly available 2 columns in the CSV to be created in SQL table dynamically, any examples / video links appreciated", "author_fullname": "t2_va6si3w6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADF - Schema drift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mlukv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691602422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to generate new column on a SQL table dynamically as per the incoming CSV file scheme change? &lt;/p&gt;\n\n&lt;p&gt;For ex: today I get a CSV file with 10 columns, tomorrow I will be getting 12 columns.. wants to design ADF dataflow to handle this situation without any code change &lt;/p&gt;\n\n&lt;p&gt;Wanted get this newly available 2 columns in the CSV to be created in SQL table dynamically, any examples / video links appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mlukv", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Pick_8431", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mlukv/adf_schema_drift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mlukv/adf_schema_drift/", "subreddit_subscribers": 121916, "created_utc": 1691602422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vx67of8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ultimate dbt Cheat Sheet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15mfqhr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BmZfuPSMpmqPfBK7jVJy46GPbMOEEFEJ9hHM_wRgggk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691588601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datacoves.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://datacoves.com/post/dbt-cheatsheet", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?auto=webp&amp;s=877a8990290912f27a3e8fe27fff96f255bd9585", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77fde2d67be961affcbcc1dbedcee7598f0bd58e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=60df194bcaf3fcf84d4c60322752d92b096ccca3", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2bfa708d8ceebc172620fe49d04ba92f0eeb8f0", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d7caf3fb816aa85080b86ed1a7c9e96cb405a5b", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7201f30b7b60df4c14725cd45646e2fbfab2a8aa", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=97adbe1a5fe1ac04f88e5356202fd6eb9cdccbd5", "width": 1080, "height": 564}], "variants": {}, "id": "_rzD2Rrp77lU7pyoKi6-K0j0h-KIeL9rC__uODDWLuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15mfqhr", "is_robot_indexable": true, "report_reasons": null, "author": "Hot_Map_7868", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mfqhr/ultimate_dbt_cheat_sheet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://datacoves.com/post/dbt-cheatsheet", "subreddit_subscribers": 121916, "created_utc": 1691588601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9k0sxzns1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use Pyo3 to build my first rust app with python binding", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15mebov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Pnc_aqRqNPlPm6MdUHCWiIRfjVrUqiS5H-XrYwXzHPg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691585170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/hkpeaks/pypeaks/tree/main", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?auto=webp&amp;s=7b0c87123c08733216896d673deaddc4e11e264d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cdac72e22e82bdd8ad97b5fb67ab4365ee970362", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a81c143d718186d915b3f49e964b48df132bd6f8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=143ef35cc695738a40645c5e68cbf89202f8a3fd", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9868a6857844a61bf6964cc06403eaace531a082", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0770c58302b234d263e054f40710f38745fd7977", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0ac52e2c770d89d026272478960b8d4a33062efc", "width": 1080, "height": 540}], "variants": {}, "id": "ireCSNiGeP5e7QYWH35eQ5_Ey3lAZ2TCtqaDhLhtyFY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15mebov", "is_robot_indexable": true, "report_reasons": null, "author": "100GB-CSV", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mebov/use_pyo3_to_build_my_first_rust_app_with_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/hkpeaks/pypeaks/tree/main", "subreddit_subscribers": 121916, "created_utc": 1691585170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm currently designing a data warehouse in snowflake and just wanted to get some thoughts on it.\n\n**Background:**  \nThe data will be replicated from a source system, and the boss wants it to be in data mart form that will be consumed by a BI tool.\n\n**Approach:**  \nMy thoughts are to use a replication tool to do incremental loads into a raw layer in snowflake, then use snowflake streams to update/insert into fact &amp; dim tables, as well as do some fact aggregation tables (maybe in materialized views?). \n\nUp to this point I think I'm on the right track, but as to the next step I'm unclear on what the data mart layer should look like - Should I be using views for these data marts? Or should these be loaded incrementally into perm tables as well?\n\nFrom these data marts I'm thinking of a view for each dashboard to ease users in creating dashboards by only providing the necessary info to them (Dashboard requirements are already available, but concern on the potential views on views situation)\n\n&amp;#x200B;\n\nJust wanted to get some comments on the thought process, would appreciate any comments!\n\n\\**Newly promoted Senior DE (current process is using python to do transformations and connecting to BI)*\n\n&amp;#x200B;", "author_fullname": "t2_tjyvggbp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Designing a data warehouse in snowflake using star schema and data marts (Best practices?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15n88wn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691662153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m currently designing a data warehouse in snowflake and just wanted to get some thoughts on it.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;br/&gt;\nThe data will be replicated from a source system, and the boss wants it to be in data mart form that will be consumed by a BI tool.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Approach:&lt;/strong&gt;&lt;br/&gt;\nMy thoughts are to use a replication tool to do incremental loads into a raw layer in snowflake, then use snowflake streams to update/insert into fact &amp;amp; dim tables, as well as do some fact aggregation tables (maybe in materialized views?). &lt;/p&gt;\n\n&lt;p&gt;Up to this point I think I&amp;#39;m on the right track, but as to the next step I&amp;#39;m unclear on what the data mart layer should look like - Should I be using views for these data marts? Or should these be loaded incrementally into perm tables as well?&lt;/p&gt;\n\n&lt;p&gt;From these data marts I&amp;#39;m thinking of a view for each dashboard to ease users in creating dashboards by only providing the necessary info to them (Dashboard requirements are already available, but concern on the potential views on views situation)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Just wanted to get some comments on the thought process, would appreciate any comments!&lt;/p&gt;\n\n&lt;p&gt;*&lt;em&gt;Newly promoted Senior DE (current process is using python to do transformations and connecting to BI)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15n88wn", "is_robot_indexable": true, "report_reasons": null, "author": "Winter-Hold-6208", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15n88wn/designing_a_data_warehouse_in_snowflake_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15n88wn/designing_a_data_warehouse_in_snowflake_using/", "subreddit_subscribers": 121916, "created_utc": 1691662153.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2zmbp5vx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finally, Automation Testing for Power BI | Boost Report Quality &amp; Efficiency", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_15n7slh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zgnF4UBR1SpymVNgZr-xsEfsMHIR9NW3rC4EHmnvmFo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691660709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/att-israel/finally-automation-testing-for-power-bi-4cbda6f81c26", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qLuGULy0ZqUL1KWPwwN6nQjcVdG14o9-9P-2xfR9UMM.jpg?auto=webp&amp;s=aa970043f608db69a67981b512a6aa101e5698a4", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/qLuGULy0ZqUL1KWPwwN6nQjcVdG14o9-9P-2xfR9UMM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c17cd328ecf9610c7aa7c4bd9a45bc572c352593", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/qLuGULy0ZqUL1KWPwwN6nQjcVdG14o9-9P-2xfR9UMM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ffc95b2e01cd1a715730839cfcd66fbf15e34fad", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/qLuGULy0ZqUL1KWPwwN6nQjcVdG14o9-9P-2xfR9UMM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a3064e263e4651fc06326cc932abd9023a281a18", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/qLuGULy0ZqUL1KWPwwN6nQjcVdG14o9-9P-2xfR9UMM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=789e1a1e72d58bf1912b3573015118f7750fd23b", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/qLuGULy0ZqUL1KWPwwN6nQjcVdG14o9-9P-2xfR9UMM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cef7dcec16ce4766aaf6fb589a5cdb0b8cf0d68", "width": 960, "height": 960}], "variants": {}, "id": "74-mQ_x-krfbs1Uq9H76fO2GiveTXsP4pBkSeyd2Aog"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15n7slh", "is_robot_indexable": true, "report_reasons": null, "author": "HallStrange", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15n7slh/finally_automation_testing_for_power_bi_boost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/att-israel/finally-automation-testing-for-power-bi-4cbda6f81c26", "subreddit_subscribers": 121916, "created_utc": 1691660709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello data scientists! Does anyone know any python package I can use to validate a SQL code?\n\nFor example, I want to check if a certain table `T` is used, and a certain field `F` in `T` is used, then I want to **check that a certain transformation is applied to** `F` \u2013 e.g. `cast F as DECIMAL` or `F * 100`.\n\nSimilarly, I also want to check if a certain table `T` is used, and a certain field `F` in `T` is used, then I want to check that a **certain filter (WHERE clause) is applied on** `F`. For example `WHERE F &gt; 100`.\n\nI've looked at `sqlglot` and it looks promising but because it's very general purpose, there's a lot of work to be done to attain what I want (although I have barely scratched the surface of `sqlglot` if I'm being honest). Just so that I don't risk reinventing the wheel, is there any python package that can help me achieve these SQL checks?", "author_fullname": "t2_1bodd6y3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Validating SQL fields and filters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15n7ipg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691659806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello data scientists! Does anyone know any python package I can use to validate a SQL code?&lt;/p&gt;\n\n&lt;p&gt;For example, I want to check if a certain table &lt;code&gt;T&lt;/code&gt; is used, and a certain field &lt;code&gt;F&lt;/code&gt; in &lt;code&gt;T&lt;/code&gt; is used, then I want to &lt;strong&gt;check that a certain transformation is applied to&lt;/strong&gt; &lt;code&gt;F&lt;/code&gt; \u2013 e.g. &lt;code&gt;cast F as DECIMAL&lt;/code&gt; or &lt;code&gt;F * 100&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Similarly, I also want to check if a certain table &lt;code&gt;T&lt;/code&gt; is used, and a certain field &lt;code&gt;F&lt;/code&gt; in &lt;code&gt;T&lt;/code&gt; is used, then I want to check that a &lt;strong&gt;certain filter (WHERE clause) is applied on&lt;/strong&gt; &lt;code&gt;F&lt;/code&gt;. For example &lt;code&gt;WHERE F &amp;gt; 100&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve looked at &lt;code&gt;sqlglot&lt;/code&gt; and it looks promising but because it&amp;#39;s very general purpose, there&amp;#39;s a lot of work to be done to attain what I want (although I have barely scratched the surface of &lt;code&gt;sqlglot&lt;/code&gt; if I&amp;#39;m being honest). Just so that I don&amp;#39;t risk reinventing the wheel, is there any python package that can help me achieve these SQL checks?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15n7ipg", "is_robot_indexable": true, "report_reasons": null, "author": "iamdeviance", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15n7ipg/validating_sql_fields_and_filters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15n7ipg/validating_sql_fields_and_filters/", "subreddit_subscribers": 121916, "created_utc": 1691659806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone. I need a open source pipeline tool like jenkins. but my boss want more visual tool like etl tools(drag and drop kinda thing). I searched some jenkins plugins but i could not find something like that. is there any free tool like this?", "author_fullname": "t2_5gqwki25", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need pipeline tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15n58ik", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691652034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. I need a open source pipeline tool like jenkins. but my boss want more visual tool like etl tools(drag and drop kinda thing). I searched some jenkins plugins but i could not find something like that. is there any free tool like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15n58ik", "is_robot_indexable": true, "report_reasons": null, "author": "nordic-jesus", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15n58ik/need_pipeline_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15n58ik/need_pipeline_tool/", "subreddit_subscribers": 121916, "created_utc": 1691652034.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}