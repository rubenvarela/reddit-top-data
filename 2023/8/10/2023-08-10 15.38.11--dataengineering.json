{"kind": "Listing", "data": {"after": "t3_15ncho1", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just started a new job and am shocked at the state of the dbt project. I've no idea whether I am used to too high standards and I am overreacting. Would appreciate to hear some other stories of dbt at your company!\n\nSo why it is so bad, we're two analytics engineers and 1 data engineer. The data engineer mainly manages airflow and databricks so they hardly work with dbt. So it's basically two people. And we have the following:\n\n- 600+ models\n\n- no tests for most of the models\n\n- lineage is a mess. One of the core tables has 55 parents and 150 children. (Edit: wrong wording I mean rejoining of upstream concepts) Circular references all over the place.\n\n- everything in the mart is materialized as a table. They run those tables multiple times a day. Costs have been increasing at a steady pace ofcourse.\n\n- they use schemas to denote topics. The project.yml contains configs for each folder to materialize it to the correct schema. The file is 200+ lines long as a consequence.\n\nBtw they managed to get to this state in less than a year :p\n\nOh and they are migrating to a new bi tool with deadline end of October. Work hasn't even started on that. So should I run? :P\n\nEdit: fixed formatting", "author_fullname": "t2_2ol209b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is our dbt project as bad as I think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mhunt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 74, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 74, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": 1691610850.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691593433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started a new job and am shocked at the state of the dbt project. I&amp;#39;ve no idea whether I am used to too high standards and I am overreacting. Would appreciate to hear some other stories of dbt at your company!&lt;/p&gt;\n\n&lt;p&gt;So why it is so bad, we&amp;#39;re two analytics engineers and 1 data engineer. The data engineer mainly manages airflow and databricks so they hardly work with dbt. So it&amp;#39;s basically two people. And we have the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;600+ models&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;no tests for most of the models&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;lineage is a mess. One of the core tables has 55 parents and 150 children. (Edit: wrong wording I mean rejoining of upstream concepts) Circular references all over the place.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;everything in the mart is materialized as a table. They run those tables multiple times a day. Costs have been increasing at a steady pace ofcourse.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;they use schemas to denote topics. The project.yml contains configs for each folder to materialize it to the correct schema. The file is 200+ lines long as a consequence.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Btw they managed to get to this state in less than a year :p&lt;/p&gt;\n\n&lt;p&gt;Oh and they are migrating to a new bi tool with deadline end of October. Work hasn&amp;#39;t even started on that. So should I run? :P&lt;/p&gt;\n\n&lt;p&gt;Edit: fixed formatting&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mhunt", "is_robot_indexable": true, "report_reasons": null, "author": "snackeloni", "discussion_type": null, "num_comments": 116, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mhunt/is_our_dbt_project_as_bad_as_i_think/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mhunt/is_our_dbt_project_as_bad_as_i_think/", "subreddit_subscribers": 121957, "created_utc": 1691593433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My manager thinks we can get/train data engineers to be \"full stack\", that is, write AWS Python lambdas to grab data from EventBridge and load to our DW dimensional models, and have them design those models, and be able to create Power BI reports.  And be able to write good DAX and efficient datasets as well.  Do you think that is too much to ask?", "author_fullname": "t2_j15uu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Too much to expect from a data engineer? Python + Dimensional Modeling + Power BI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mpm60", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691610864.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My manager thinks we can get/train data engineers to be &amp;quot;full stack&amp;quot;, that is, write AWS Python lambdas to grab data from EventBridge and load to our DW dimensional models, and have them design those models, and be able to create Power BI reports.  And be able to write good DAX and efficient datasets as well.  Do you think that is too much to ask?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mpm60", "is_robot_indexable": true, "report_reasons": null, "author": "jbrune", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mpm60/too_much_to_expect_from_a_data_engineer_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mpm60/too_much_to_expect_from_a_data_engineer_python/", "subreddit_subscribers": 121957, "created_utc": 1691610864.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there! \n\nI am just wondering if you noticed shift in current jobs market position. Big companies seem to be back in green numbers. \n\nDo you think situation will change soon and new DE positions will be open soon?", "author_fullname": "t2_46l1zqd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is job market still dead?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mpcoh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691610275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there! &lt;/p&gt;\n\n&lt;p&gt;I am just wondering if you noticed shift in current jobs market position. Big companies seem to be back in green numbers. &lt;/p&gt;\n\n&lt;p&gt;Do you think situation will change soon and new DE positions will be open soon?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15mpcoh", "is_robot_indexable": true, "report_reasons": null, "author": "pyzo_ryzo", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mpcoh/is_job_market_still_dead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mpcoh/is_job_market_still_dead/", "subreddit_subscribers": 121957, "created_utc": 1691610275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got placed on a Data engineering team as a part of a rotational development program at my company. \n\nI\u2019m noticing that everyone on my team has years of experience (5-20) and that the least experienced people have 5-7 YOE. \n\nI\u2019m just starting out in tech, with only 6 months of professional backend engineering experience (JVM, Kafka, Postgres etc). My bachelor degree is non-CS engineering. \n\nAm I going to have a really difficult time making a career in DE because I don\u2019t have other SWE experience?\n\nI\u2019m willing to work hard and master the fundamentals in my own time outside of work, but I\u2019m scared that if I lose my current job, no other company will hire me for DE roles as junior positions are very rare. \n\nAt the same time, DE feels so niche. I don\u2019t know if the skills I develop here will apply to other backend dev jobs. What can I do to stay broadly employable?\n\nShould I pursue some cloud certification?", "author_fullname": "t2_vmcasqim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE wrong path for beginners?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mlhz8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691601657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got placed on a Data engineering team as a part of a rotational development program at my company. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m noticing that everyone on my team has years of experience (5-20) and that the least experienced people have 5-7 YOE. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m just starting out in tech, with only 6 months of professional backend engineering experience (JVM, Kafka, Postgres etc). My bachelor degree is non-CS engineering. &lt;/p&gt;\n\n&lt;p&gt;Am I going to have a really difficult time making a career in DE because I don\u2019t have other SWE experience?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m willing to work hard and master the fundamentals in my own time outside of work, but I\u2019m scared that if I lose my current job, no other company will hire me for DE roles as junior positions are very rare. &lt;/p&gt;\n\n&lt;p&gt;At the same time, DE feels so niche. I don\u2019t know if the skills I develop here will apply to other backend dev jobs. What can I do to stay broadly employable?&lt;/p&gt;\n\n&lt;p&gt;Should I pursue some cloud certification?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15mlhz8", "is_robot_indexable": true, "report_reasons": null, "author": "aaloo_chaat", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mlhz8/de_wrong_path_for_beginners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mlhz8/de_wrong_path_for_beginners/", "subreddit_subscribers": 121957, "created_utc": 1691601657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hjo8koz9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Labs to add usage-based pricing on top of their seat costs for dbt Cloud. $0.01 per model after free tier.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_15nbhzf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VOZK9PPnf5QCFLMFLu-vvLSpDJzxccPPEL-pAx9iQwc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691671419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getdbt.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getdbt.com/blog/consumption-based-pricing-and-the-future-of-dbt-cloud/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?auto=webp&amp;s=edabdd18634aef29128ecc0d5693053ba1a95f6e", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5df6a50eec64ce3d126f3a47e1746feaf267cebb", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d02b260d5dddd4e2e7c80420970b653c3cdddab", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa646e05e744be5f524016d4c775b326ef90c2d1", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e29469bfc58fee1f76e41ce74322e006445b9bb6", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f7b72e416c6ef27bd12b9f3a5a19ef15ad9e8249", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=285b785bfdba2ba6f0da014cf261fbe2d5f57f3d", "width": 1080, "height": 607}], "variants": {}, "id": "1atsLEhqeX9kFaissrSt8acZk9ienTNBpjUXMcidAMU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15nbhzf", "is_robot_indexable": true, "report_reasons": null, "author": "PandaUnicornAlbatros", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nbhzf/dbt_labs_to_add_usagebased_pricing_on_top_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getdbt.com/blog/consumption-based-pricing-and-the-future-of-dbt-cloud/", "subreddit_subscribers": 121957, "created_utc": 1691671419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you want to know why I really don't like Tableau? They don't support the simplest bugs. For example, the problem where filter titles get cut off, an issue that is know since at least 2014 (https://community.tableau.com/s/idea/0874T000000H9yAQAS/detail). \nI came to my company when they already used Tableau everywhere, even though nobody liked it. And I want us to start using a different BI tool. \n\nI heard about Superset which looks nice, any other ideas? \nWhat we're looking for is something that supports sql queries and is able to present dashboards online for in house monitoring. \n\n(don't even get me started on how expensive tableau is...)", "author_fullname": "t2_zbab4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to stop using Tableau", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15moa22", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691607823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you want to know why I really don&amp;#39;t like Tableau? They don&amp;#39;t support the simplest bugs. For example, the problem where filter titles get cut off, an issue that is know since at least 2014 (&lt;a href=\"https://community.tableau.com/s/idea/0874T000000H9yAQAS/detail\"&gt;https://community.tableau.com/s/idea/0874T000000H9yAQAS/detail&lt;/a&gt;). \nI came to my company when they already used Tableau everywhere, even though nobody liked it. And I want us to start using a different BI tool. &lt;/p&gt;\n\n&lt;p&gt;I heard about Superset which looks nice, any other ideas? \nWhat we&amp;#39;re looking for is something that supports sql queries and is able to present dashboards online for in house monitoring. &lt;/p&gt;\n\n&lt;p&gt;(don&amp;#39;t even get me started on how expensive tableau is...)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15moa22", "is_robot_indexable": true, "report_reasons": null, "author": "chenvili", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15moa22/i_want_to_stop_using_tableau/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15moa22/i_want_to_stop_using_tableau/", "subreddit_subscribers": 121957, "created_utc": 1691607823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve recently been working on standing up a prototype analytics database at work utilizing Starrocks and Iceberg. I have access to a GCP instance and wanted to explore managed services that would make this setup easier to maintain. When I came across Dataproc Metastore, it sounded like a huge value add to have it serverless, self-healing, and we\u2019ll integrated with the rest of GCP if we want to lock ourselves in. But then read it costs $3.42/hr?? Seems like we\u2019d need to be running at some pretty serious volume for that to make any financial sense. Is anyone actually using this efficiently?", "author_fullname": "t2_ahqse5d9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Dataproc Metastore Worth $30k/yr?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mymv1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691632262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently been working on standing up a prototype analytics database at work utilizing Starrocks and Iceberg. I have access to a GCP instance and wanted to explore managed services that would make this setup easier to maintain. When I came across Dataproc Metastore, it sounded like a huge value add to have it serverless, self-healing, and we\u2019ll integrated with the rest of GCP if we want to lock ourselves in. But then read it costs $3.42/hr?? Seems like we\u2019d need to be running at some pretty serious volume for that to make any financial sense. Is anyone actually using this efficiently?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mymv1", "is_robot_indexable": true, "report_reasons": null, "author": "Express-Comb8675", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mymv1/is_dataproc_metastore_worth_30kyr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mymv1/is_dataproc_metastore_worth_30kyr/", "subreddit_subscribers": 121957, "created_utc": 1691632262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_167vnb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datafold VS Code Extension: data diffing made easy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15mooqj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MFp6ddsuwu9S9POOQyVuH9vTmdZk0kMeqczY9i56rwE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691608777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "marketplace.visualstudio.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://marketplace.visualstudio.com/items?itemName=Datafold.datafold-vscode&amp;ssr=false#overview", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jlWbxa_RX5TSL1jGYvmtjw0kg65QwgI6Bza6xxgzl5U.jpg?auto=webp&amp;s=d53e3a099a7e9e3e0946121f050292bc4abb38b9", "width": 256, "height": 256}, "resolutions": [{"url": "https://external-preview.redd.it/jlWbxa_RX5TSL1jGYvmtjw0kg65QwgI6Bza6xxgzl5U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b6afe2191bed6185d84a0f3c0eb0474b936dfb2", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/jlWbxa_RX5TSL1jGYvmtjw0kg65QwgI6Bza6xxgzl5U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b80bc50c9c32840327a2ca4f9dc77b6e5ef3b501", "width": 216, "height": 216}], "variants": {}, "id": "yoohlCjhWZNKHvjfg4Cr6e7gi8UTyTHdjzDPPJM7bQg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15mooqj", "is_robot_indexable": true, "report_reasons": null, "author": "just_sung", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mooqj/datafold_vs_code_extension_data_diffing_made_easy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://marketplace.visualstudio.com/items?itemName=Datafold.datafold-vscode&amp;ssr=false#overview", "subreddit_subscribers": 121957, "created_utc": 1691608777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "guys of dataengineering, my company laid off 70 percent of their workforce this june. i have been applying for relevant positions since then and i am not getting a single reply back honestly. I have a year of exp working as a Data Engineer. Where are all the jobs right now? I understand market is tough or whatever, but seriously, why are companies being such dicks? I NEED A BASIC ENTRY LEVEL JOB WHY TF IS THAT SO DIFFICULT? ", "author_fullname": "t2_v0a5cy3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "entry level jobs in usa", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15n76ia", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691658671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;guys of dataengineering, my company laid off 70 percent of their workforce this june. i have been applying for relevant positions since then and i am not getting a single reply back honestly. I have a year of exp working as a Data Engineer. Where are all the jobs right now? I understand market is tough or whatever, but seriously, why are companies being such dicks? I NEED A BASIC ENTRY LEVEL JOB WHY TF IS THAT SO DIFFICULT? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15n76ia", "is_robot_indexable": true, "report_reasons": null, "author": "CompetitiveWealth503", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15n76ia/entry_level_jobs_in_usa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15n76ia/entry_level_jobs_in_usa/", "subreddit_subscribers": 121957, "created_utc": 1691658671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a6it0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wrote a VSCode extension for exploring Parquet with SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15n1sez", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1691641114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "marketplace.visualstudio.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://marketplace.visualstudio.com/items?itemName=AdamViola.parquet-explorer", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15n1sez", "is_robot_indexable": true, "report_reasons": null, "author": "supersmartypants", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15n1sez/i_wrote_a_vscode_extension_for_exploring_parquet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://marketplace.visualstudio.com/items?itemName=AdamViola.parquet-explorer", "subreddit_subscribers": 121957, "created_utc": 1691641114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My organization uses SQL Server as our OLTP database for our applications. Unfortunately, there was very little foresight to accommodate historical business analytics. As such, I just scheduled a monthly job to run a stored proc that essentially just runs a variety of queries and appends the results to historical tables. \n\nAnyone know if this is an issue? Our DB is small (like 100GB). Our operations exec suggested contracting with a data warehouse service like Snowflake, but that seems like overkill and a cost we don\u2019t need to bear given our size.\n\nAnyone else ever have to do something like this for a small organization? I\u2019m trying to save costs but I don\u2019t want this to spiral out of control or bog down our server. Thus far, it seems to be working fine, as I\u2019ve made an effort to tune the queries as best I can.", "author_fullname": "t2_6hsp2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OLTP to OLAP ETL process for Small Organization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mtv8s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691620580.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691620387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My organization uses SQL Server as our OLTP database for our applications. Unfortunately, there was very little foresight to accommodate historical business analytics. As such, I just scheduled a monthly job to run a stored proc that essentially just runs a variety of queries and appends the results to historical tables. &lt;/p&gt;\n\n&lt;p&gt;Anyone know if this is an issue? Our DB is small (like 100GB). Our operations exec suggested contracting with a data warehouse service like Snowflake, but that seems like overkill and a cost we don\u2019t need to bear given our size.&lt;/p&gt;\n\n&lt;p&gt;Anyone else ever have to do something like this for a small organization? I\u2019m trying to save costs but I don\u2019t want this to spiral out of control or bog down our server. Thus far, it seems to be working fine, as I\u2019ve made an effort to tune the queries as best I can.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mtv8s", "is_robot_indexable": true, "report_reasons": null, "author": "suitupyo", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mtv8s/oltp_to_olap_etl_process_for_small_organization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mtv8s/oltp_to_olap_etl_process_for_small_organization/", "subreddit_subscribers": 121957, "created_utc": 1691620387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all.\n\nWe have kind of a unique situation.\n\nWe are a startup company that is basically running electricity power flow simulation software models. These models are CPU intensive, and require multiple computers in a cluster to calculate things effectively.\n\nOur software is extremely bespoke, and has been recommended by the vendor to use on-prem hardware for the actual computation piece of the software.\n\nThe specific hardware they are recommending are i9-13900k or ryzen 7950x, effectively 3ghz minimum CPU's with high clock speeds (5ghz+).\n\nHOWEVER, the only issue with this is that the data from the software is read from a microsoft SQL server environment and the forecasts and written back into the same SQL server database.\n\nWe are a small shop with zero DBA's, so we really have no idea on how to maintain on-prem databases (especially SQL server). We are looking at Azure Database or Amazon RDS as an option instead.\n\nOur software inserts probably 10-20mm records/night into this database environment, and we will probably have 1 functional account (data visualization tool) pulling data as well as 2-3 people querying per day, so I'd imagine compute is light.\n\nI know the best thing is to go cloud-cloud or on-prem on-prem, but the equivalent cloud compute for i9-13900k for 3 instances is like 1.5-2k a month while the physical hardware is like 2k for the whole computer. Physical hardware payback is like 3-4 months!\n\nAlternatively, nobody knows how to actually maintain an on-prem installation for MS Sql Server, and I feel like hiring a DBA would be substantially more expensive than using a service like Azure SQL Server.\n\nAny thoughts here? Would the latency/topology seriously be SO bad that bulk inserts for 10-20mm records would take substantially longer going into a cloud DB vs on-prem like the computers doing the software compute?", "author_fullname": "t2_92xmo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On-prem compute for software that inserts into cloud database - how stupid is this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15n2een", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691642979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all.&lt;/p&gt;\n\n&lt;p&gt;We have kind of a unique situation.&lt;/p&gt;\n\n&lt;p&gt;We are a startup company that is basically running electricity power flow simulation software models. These models are CPU intensive, and require multiple computers in a cluster to calculate things effectively.&lt;/p&gt;\n\n&lt;p&gt;Our software is extremely bespoke, and has been recommended by the vendor to use on-prem hardware for the actual computation piece of the software.&lt;/p&gt;\n\n&lt;p&gt;The specific hardware they are recommending are i9-13900k or ryzen 7950x, effectively 3ghz minimum CPU&amp;#39;s with high clock speeds (5ghz+).&lt;/p&gt;\n\n&lt;p&gt;HOWEVER, the only issue with this is that the data from the software is read from a microsoft SQL server environment and the forecasts and written back into the same SQL server database.&lt;/p&gt;\n\n&lt;p&gt;We are a small shop with zero DBA&amp;#39;s, so we really have no idea on how to maintain on-prem databases (especially SQL server). We are looking at Azure Database or Amazon RDS as an option instead.&lt;/p&gt;\n\n&lt;p&gt;Our software inserts probably 10-20mm records/night into this database environment, and we will probably have 1 functional account (data visualization tool) pulling data as well as 2-3 people querying per day, so I&amp;#39;d imagine compute is light.&lt;/p&gt;\n\n&lt;p&gt;I know the best thing is to go cloud-cloud or on-prem on-prem, but the equivalent cloud compute for i9-13900k for 3 instances is like 1.5-2k a month while the physical hardware is like 2k for the whole computer. Physical hardware payback is like 3-4 months!&lt;/p&gt;\n\n&lt;p&gt;Alternatively, nobody knows how to actually maintain an on-prem installation for MS Sql Server, and I feel like hiring a DBA would be substantially more expensive than using a service like Azure SQL Server.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts here? Would the latency/topology seriously be SO bad that bulk inserts for 10-20mm records would take substantially longer going into a cloud DB vs on-prem like the computers doing the software compute?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15n2een", "is_robot_indexable": true, "report_reasons": null, "author": "preciseman", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15n2een/onprem_compute_for_software_that_inserts_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15n2een/onprem_compute_for_software_that_inserts_into/", "subreddit_subscribers": 121957, "created_utc": 1691642979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am 17 and an intern at a finch company in England, I have been given a task to create a 'slack watchdog' in which messages for help to a slack channel will be monitored and if no response within an hour an automatic reply will tag a member of the appropriate response team asking them to take a look at the message. Is it possible for any of you to give me a brief overview of how I would do this and/or point me in the direction of some useful things to search (detailed things for search). \n\nThe tools I am using are Airflow and VSCode in python, as in my actual task is to create a DAG which sends these automatic assignment responses.\n\nAny help greatly appreciated!", "author_fullname": "t2_eqvikdnq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overview of how to tackle project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mirqn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691595550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am 17 and an intern at a finch company in England, I have been given a task to create a &amp;#39;slack watchdog&amp;#39; in which messages for help to a slack channel will be monitored and if no response within an hour an automatic reply will tag a member of the appropriate response team asking them to take a look at the message. Is it possible for any of you to give me a brief overview of how I would do this and/or point me in the direction of some useful things to search (detailed things for search). &lt;/p&gt;\n\n&lt;p&gt;The tools I am using are Airflow and VSCode in python, as in my actual task is to create a DAG which sends these automatic assignment responses.&lt;/p&gt;\n\n&lt;p&gt;Any help greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mirqn", "is_robot_indexable": true, "report_reasons": null, "author": "McSteamy06", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mirqn/overview_of_how_to_tackle_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mirqn/overview_of_how_to_tackle_project/", "subreddit_subscribers": 121957, "created_utc": 1691595550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TL;DR - Are certifications the best move for me right now? What's my next job title on the path to Data Engineer?\n\n\\---\n\n2019 - Graduated with humanities degree from top university. Interned at Medical Nonprofit as a translator, general admin guy, and writer.\n\n2020 - Hired as a Research Coordinator and Data Analyst for its research team under a different job title. Worked with R for data viz and basic analysis, basic SQL to retrieve data.\n\n2021 - Became a full time student online to take math courses, as I thought I wanted to pursue a PhD in Biostatistics. Went up through Real Analysis, A's. I continued doing the data analysis work for the research projects but for free. Second author on one publication with another pending.\n\n2022-early 2023 - Eventually decided I was more interested in engineering over analysis and statistics. Looked into Data Engineering and did a 6 month bootcamp in the Fall (Bash, Python, SQL, basic GCP, DBT, Airflow). Built ETL projects and a portfolio website. Through the connections of the Bootcamp founder, I interned for about month at a small cloud consulting outfit using AWS, then got a contract using scraping and ChatGPT for an individual client.\n\nCurrent - Landed a one year \"Data Engineering Fellowship\" at a non-profit tech consultancy, consulting for other non-profits and government agencies. Pay is pretty good for LCOL area ($70k). But in my first 2 months here I've been doing a lot of non-technical tasks which have eaten into my technical skill-building time. My most technical projects currently are to deploy an API-driven workflow in the cloud and to design and implement a new data model for a client in Snowflake.  Both of these are in very early stages.\n\nMay 2024 - Fellowship ends with possibility of extension or being hired.\n\n\\---\n\n1.) What should I be doing to maximize my chances of getting a job when this program ends?\n\n* I feel like I need more foundational CS knowledge and to obtain a formal degree. So I am taking an EDx course in Java OOP from GT to prepare for their OMSCS. OTOH,  I could obtain some kind of certification(s) (e.g. AWS/Azure, Snowflake/Databricks) and build projects leveraging those technologies. This could pay off more quickly for me career-wise, and so I'm wondering if I should delay the MS preparation. I believe have till 2025 before my math credits start to become outdated for the application.\n\n2.) What sorts of job titles should I be targeting? At what kinds of companies? I realize now that Data Engineer is not an entry-level position, so while I would love to become one, I don't know if that's realistic for my first job come June of next year.", "author_fullname": "t2_qn652con", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unusual early-career trajectory with some experience - seeking advice on how to land first \"real\" job on path to DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nbs07", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691672154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR - Are certifications the best move for me right now? What&amp;#39;s my next job title on the path to Data Engineer?&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;2019 - Graduated with humanities degree from top university. Interned at Medical Nonprofit as a translator, general admin guy, and writer.&lt;/p&gt;\n\n&lt;p&gt;2020 - Hired as a Research Coordinator and Data Analyst for its research team under a different job title. Worked with R for data viz and basic analysis, basic SQL to retrieve data.&lt;/p&gt;\n\n&lt;p&gt;2021 - Became a full time student online to take math courses, as I thought I wanted to pursue a PhD in Biostatistics. Went up through Real Analysis, A&amp;#39;s. I continued doing the data analysis work for the research projects but for free. Second author on one publication with another pending.&lt;/p&gt;\n\n&lt;p&gt;2022-early 2023 - Eventually decided I was more interested in engineering over analysis and statistics. Looked into Data Engineering and did a 6 month bootcamp in the Fall (Bash, Python, SQL, basic GCP, DBT, Airflow). Built ETL projects and a portfolio website. Through the connections of the Bootcamp founder, I interned for about month at a small cloud consulting outfit using AWS, then got a contract using scraping and ChatGPT for an individual client.&lt;/p&gt;\n\n&lt;p&gt;Current - Landed a one year &amp;quot;Data Engineering Fellowship&amp;quot; at a non-profit tech consultancy, consulting for other non-profits and government agencies. Pay is pretty good for LCOL area ($70k). But in my first 2 months here I&amp;#39;ve been doing a lot of non-technical tasks which have eaten into my technical skill-building time. My most technical projects currently are to deploy an API-driven workflow in the cloud and to design and implement a new data model for a client in Snowflake.  Both of these are in very early stages.&lt;/p&gt;\n\n&lt;p&gt;May 2024 - Fellowship ends with possibility of extension or being hired.&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;1.) What should I be doing to maximize my chances of getting a job when this program ends?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I feel like I need more foundational CS knowledge and to obtain a formal degree. So I am taking an EDx course in Java OOP from GT to prepare for their OMSCS. OTOH,  I could obtain some kind of certification(s) (e.g. AWS/Azure, Snowflake/Databricks) and build projects leveraging those technologies. This could pay off more quickly for me career-wise, and so I&amp;#39;m wondering if I should delay the MS preparation. I believe have till 2025 before my math credits start to become outdated for the application.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;2.) What sorts of job titles should I be targeting? At what kinds of companies? I realize now that Data Engineer is not an entry-level position, so while I would love to become one, I don&amp;#39;t know if that&amp;#39;s realistic for my first job come June of next year.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15nbs07", "is_robot_indexable": true, "report_reasons": null, "author": "aksandros", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nbs07/unusual_earlycareer_trajectory_with_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nbs07/unusual_earlycareer_trajectory_with_some/", "subreddit_subscribers": 121957, "created_utc": 1691672154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was disappointed (but not shocked) by dbt's new release coupling their new semantic layer to their cloud product. Every \"semantic layer\" or \"metrics layer\" that I'm aware of couples metrics definition to a specific product or service that requires its own server. This is unsurprising from a vendor perspective, but I think it leaves a basic gap in open-source functionality: a metrics layer could exist entirely as config files that generate SQL views (materialized or not) with different grouping sets. I think this could handle joins as well, but as a basic MVP I think just different grouping sets would cover a variety of simple use cases.\n\nIs there a dbt package that already exists that does this kind of thing? (One config file -&gt; multiple SQL views with different groupings) ", "author_fullname": "t2_3rnvqshi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simple, decoupled config -&gt; SQL metrics layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15na07t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691667429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was disappointed (but not shocked) by dbt&amp;#39;s new release coupling their new semantic layer to their cloud product. Every &amp;quot;semantic layer&amp;quot; or &amp;quot;metrics layer&amp;quot; that I&amp;#39;m aware of couples metrics definition to a specific product or service that requires its own server. This is unsurprising from a vendor perspective, but I think it leaves a basic gap in open-source functionality: a metrics layer could exist entirely as config files that generate SQL views (materialized or not) with different grouping sets. I think this could handle joins as well, but as a basic MVP I think just different grouping sets would cover a variety of simple use cases.&lt;/p&gt;\n\n&lt;p&gt;Is there a dbt package that already exists that does this kind of thing? (One config file -&amp;gt; multiple SQL views with different groupings) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15na07t", "is_robot_indexable": true, "report_reasons": null, "author": "PaginatedSalmon", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15na07t/simple_decoupled_config_sql_metrics_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15na07t/simple_decoupled_config_sql_metrics_layer/", "subreddit_subscribers": 121957, "created_utc": 1691667429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "have been working as a junior data engineer at this small startup for almost 8 months( part-time). During that time, I have brushed up my python skills, SQL skills, Excel skills, and can proficiently use various GCP products( BQ, GCS, Dataflow, Cloud Functions). I also cleared the Google cloud certified professional D.E exam during that period and worked on multiple data focused projects; mainly ETL stuff. \nMy bachelor's degree will be wrapped up by the end of this month, so, I will be switching to a full-time role. Let's assume that my current salary, that hasn't changed since I joined this company, is INR 30000 per month. What would be a justifiable salary demand for me?\nThis is my first job so I don't really know the market too well. Plus, the company doesn't really have too many data-focused projects going on. So, I am no too sure that they are going to go out of their way and pay fancy wages to a D.E.", "author_fullname": "t2_eo907yrs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "D.E promotion, salary discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mmqnr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691604366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;have been working as a junior data engineer at this small startup for almost 8 months( part-time). During that time, I have brushed up my python skills, SQL skills, Excel skills, and can proficiently use various GCP products( BQ, GCS, Dataflow, Cloud Functions). I also cleared the Google cloud certified professional D.E exam during that period and worked on multiple data focused projects; mainly ETL stuff. \nMy bachelor&amp;#39;s degree will be wrapped up by the end of this month, so, I will be switching to a full-time role. Let&amp;#39;s assume that my current salary, that hasn&amp;#39;t changed since I joined this company, is INR 30000 per month. What would be a justifiable salary demand for me?\nThis is my first job so I don&amp;#39;t really know the market too well. Plus, the company doesn&amp;#39;t really have too many data-focused projects going on. So, I am no too sure that they are going to go out of their way and pay fancy wages to a D.E.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15mmqnr", "is_robot_indexable": true, "report_reasons": null, "author": "avg_ali", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mmqnr/de_promotion_salary_discussion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mmqnr/de_promotion_salary_discussion/", "subreddit_subscribers": 121957, "created_utc": 1691604366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone here joined any professional organizations like ACM, SWE etc? \nAny groups focusing on DE?", "author_fullname": "t2_vmcasqim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Professional organizations for DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mmf0q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691603665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone here joined any professional organizations like ACM, SWE etc? \nAny groups focusing on DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mmf0q", "is_robot_indexable": true, "report_reasons": null, "author": "aaloo_chaat", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mmf0q/professional_organizations_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mmf0q/professional_organizations_for_de/", "subreddit_subscribers": 121957, "created_utc": 1691603665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2zmbp5vx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finally, Automation Testing for Power BI | Boost Report Quality &amp; Efficiency", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15n7slh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zgnF4UBR1SpymVNgZr-xsEfsMHIR9NW3rC4EHmnvmFo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691660709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/att-israel/finally-automation-testing-for-power-bi-4cbda6f81c26", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qLuGULy0ZqUL1KWPwwN6nQjcVdG14o9-9P-2xfR9UMM.jpg?auto=webp&amp;s=aa970043f608db69a67981b512a6aa101e5698a4", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/qLuGULy0ZqUL1KWPwwN6nQjcVdG14o9-9P-2xfR9UMM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c17cd328ecf9610c7aa7c4bd9a45bc572c352593", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/qLuGULy0ZqUL1KWPwwN6nQjcVdG14o9-9P-2xfR9UMM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ffc95b2e01cd1a715730839cfcd66fbf15e34fad", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/qLuGULy0ZqUL1KWPwwN6nQjcVdG14o9-9P-2xfR9UMM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a3064e263e4651fc06326cc932abd9023a281a18", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/qLuGULy0ZqUL1KWPwwN6nQjcVdG14o9-9P-2xfR9UMM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=789e1a1e72d58bf1912b3573015118f7750fd23b", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/qLuGULy0ZqUL1KWPwwN6nQjcVdG14o9-9P-2xfR9UMM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cef7dcec16ce4766aaf6fb589a5cdb0b8cf0d68", "width": 960, "height": 960}], "variants": {}, "id": "74-mQ_x-krfbs1Uq9H76fO2GiveTXsP4pBkSeyd2Aog"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15n7slh", "is_robot_indexable": true, "report_reasons": null, "author": "HallStrange", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15n7slh/finally_automation_testing_for_power_bi_boost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/att-israel/finally-automation-testing-for-power-bi-4cbda6f81c26", "subreddit_subscribers": 121957, "created_utc": 1691660709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a very simple pipeline on GCP which pulls data from an API, formats it into a pandas dataframe and then loads that into a GCS bucket as a CSV. The CSV is then loaded into a BigQuery table that powers some looker studio reports and Google Sheets analysis. \n\nCurrently the whole thing is done within a python Cloud Function and is scheduled to run daily via cloud scheduler. \n\nLooking to migrate this over to Airflow / Cloud composer and was wondering about the best way to structure it. Is it better to have all the work done within DAGs (downloading the data from the API, sending it to GCS/BigQuery)? Or is airflow meant to take the place of Cloud Scheduler and just trigger the Cloud Function which does that work? Or is there another way entirely that I should consider structuring this?\n\nAny advice is appreciated.\n\nThanks!   ", "author_fullname": "t2_5p737", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Airflow - Looking for some guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mqzvt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691613980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a very simple pipeline on GCP which pulls data from an API, formats it into a pandas dataframe and then loads that into a GCS bucket as a CSV. The CSV is then loaded into a BigQuery table that powers some looker studio reports and Google Sheets analysis. &lt;/p&gt;\n\n&lt;p&gt;Currently the whole thing is done within a python Cloud Function and is scheduled to run daily via cloud scheduler. &lt;/p&gt;\n\n&lt;p&gt;Looking to migrate this over to Airflow / Cloud composer and was wondering about the best way to structure it. Is it better to have all the work done within DAGs (downloading the data from the API, sending it to GCS/BigQuery)? Or is airflow meant to take the place of Cloud Scheduler and just trigger the Cloud Function which does that work? Or is there another way entirely that I should consider structuring this?&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks!   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mqzvt", "is_robot_indexable": true, "report_reasons": null, "author": "Frodi", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mqzvt/learning_airflow_looking_for_some_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mqzvt/learning_airflow_looking_for_some_guidance/", "subreddit_subscribers": 121957, "created_utc": 1691613980.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am a fresh university graduate student with a data science degree and hoping to move into the industry. Since I have no experience on working as a data engineer before, I was hoping to find an intern position to work. but I'm really curious whether I can apply for the junior data engineer position as well.\u00a0\n\nSo what could be the difference between an intern and a junior data engineer position? Would that be okay to apply for the junior position even though I have no working experience in the industry level?\n\nAny help would be greatly appreciated!!", "author_fullname": "t2_94z2yiq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the difference between an intern and a junior data engineer position?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mpyx6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691611626.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am a fresh university graduate student with a data science degree and hoping to move into the industry. Since I have no experience on working as a data engineer before, I was hoping to find an intern position to work. but I&amp;#39;m really curious whether I can apply for the junior data engineer position as well.\u00a0&lt;/p&gt;\n\n&lt;p&gt;So what could be the difference between an intern and a junior data engineer position? Would that be okay to apply for the junior position even though I have no working experience in the industry level?&lt;/p&gt;\n\n&lt;p&gt;Any help would be greatly appreciated!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15mpyx6", "is_robot_indexable": true, "report_reasons": null, "author": "LengthOld9943", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mpyx6/what_is_the_difference_between_an_intern_and_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mpyx6/what_is_the_difference_between_an_intern_and_a/", "subreddit_subscribers": 121957, "created_utc": 1691611626.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to generate new column on a SQL table dynamically as per the incoming CSV file scheme change? \n\nFor ex: today I get a CSV file with 10 columns, tomorrow I will be getting 12 columns.. wants to design ADF dataflow to handle this situation without any code change \n\nWanted get this newly available 2 columns in the CSV to be created in SQL table dynamically, any examples / video links appreciated", "author_fullname": "t2_va6si3w6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADF - Schema drift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mlukv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691602422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to generate new column on a SQL table dynamically as per the incoming CSV file scheme change? &lt;/p&gt;\n\n&lt;p&gt;For ex: today I get a CSV file with 10 columns, tomorrow I will be getting 12 columns.. wants to design ADF dataflow to handle this situation without any code change &lt;/p&gt;\n\n&lt;p&gt;Wanted get this newly available 2 columns in the CSV to be created in SQL table dynamically, any examples / video links appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mlukv", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Pick_8431", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mlukv/adf_schema_drift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mlukv/adf_schema_drift/", "subreddit_subscribers": 121957, "created_utc": 1691602422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! I'm new to this sub so if this isn't quite the right place for my question, please let me know :) \n\nSo, I've been trying to learn SQL off and on for a while now, and I've been wondering ***why*** you can have a primary key that is just an increasing integer, and how you know that John Doe bought 3 cheese pizzas from Pizza Hut, but John Smith only bought 1 pepperoni (assuming customers and orders are two separate tables).\n\nCan you take the increasing integer as gospel for keeping things straight because the rows of both tables are populated based off of when a customer purchases something? That's the only thing I can come up with and it feels obvious, but I don't have anyone I can double-check that assumption with. Am I missing anything, or is it just that? \n\nThanks in advance! ", "author_fullname": "t2_5fj363pz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Data Pipeline and Databases Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15neh3p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691678706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I&amp;#39;m new to this sub so if this isn&amp;#39;t quite the right place for my question, please let me know :) &lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;ve been trying to learn SQL off and on for a while now, and I&amp;#39;ve been wondering &lt;strong&gt;&lt;em&gt;why&lt;/em&gt;&lt;/strong&gt; you can have a primary key that is just an increasing integer, and how you know that John Doe bought 3 cheese pizzas from Pizza Hut, but John Smith only bought 1 pepperoni (assuming customers and orders are two separate tables).&lt;/p&gt;\n\n&lt;p&gt;Can you take the increasing integer as gospel for keeping things straight because the rows of both tables are populated based off of when a customer purchases something? That&amp;#39;s the only thing I can come up with and it feels obvious, but I don&amp;#39;t have anyone I can double-check that assumption with. Am I missing anything, or is it just that? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15neh3p", "is_robot_indexable": true, "report_reasons": null, "author": "ChocodilesAxolotls", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15neh3p/beginner_data_pipeline_and_databases_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15neh3p/beginner_data_pipeline_and_databases_question/", "subreddit_subscribers": 121957, "created_utc": 1691678706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello we have a transaction dataset that's partitioned by date/month and is joined to a hierarchy. For a daily batch run, we can just do a delete insert followed by a join. \n\nThe hierarchies comes in as a parent child relationship and we flatten them. Sometimes hierarchies can be updated at any arbitrary node. The child at the deepest level should be unique. We will also insert duplicates to ensure no matter how long the path is, all columns for be filled. \n\nFor example, with a deepest level of 4, \nA &gt; B &gt; C becomes A &gt; B &gt; C &gt; C, and A &gt; B &gt; C &gt; D stay as is. \n\nOne way I thought about is doing a data change capture on the flattened hierarchies. Doing a concatenated string of all levels and using that to figure out: for each node at the deepest level, which had their path changed. Then using that to perform a delete insert on historical data. \n\nThe Hierarchies changes in worst cases can occur on the order of weekly basis, and the biggest ones when flattened are roughly 20k rows. A partition by date/month make sense for us for the daily run and for the occasion when we need to update past transaction data. What other partitioning/indexing should I consider? The files consumed are flat files. \n\nThanks", "author_fullname": "t2_8lbog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to rejoin historical data against a hierarchy that has changed in Spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15ne3hr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691677813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello we have a transaction dataset that&amp;#39;s partitioned by date/month and is joined to a hierarchy. For a daily batch run, we can just do a delete insert followed by a join. &lt;/p&gt;\n\n&lt;p&gt;The hierarchies comes in as a parent child relationship and we flatten them. Sometimes hierarchies can be updated at any arbitrary node. The child at the deepest level should be unique. We will also insert duplicates to ensure no matter how long the path is, all columns for be filled. &lt;/p&gt;\n\n&lt;p&gt;For example, with a deepest level of 4, \nA &amp;gt; B &amp;gt; C becomes A &amp;gt; B &amp;gt; C &amp;gt; C, and A &amp;gt; B &amp;gt; C &amp;gt; D stay as is. &lt;/p&gt;\n\n&lt;p&gt;One way I thought about is doing a data change capture on the flattened hierarchies. Doing a concatenated string of all levels and using that to figure out: for each node at the deepest level, which had their path changed. Then using that to perform a delete insert on historical data. &lt;/p&gt;\n\n&lt;p&gt;The Hierarchies changes in worst cases can occur on the order of weekly basis, and the biggest ones when flattened are roughly 20k rows. A partition by date/month make sense for us for the daily run and for the occasion when we need to update past transaction data. What other partitioning/indexing should I consider? The files consumed are flat files. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ne3hr", "is_robot_indexable": true, "report_reasons": null, "author": "AUGcodon", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ne3hr/whats_the_best_way_to_rejoin_historical_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ne3hr/whats_the_best_way_to_rejoin_historical_data/", "subreddit_subscribers": 121957, "created_utc": 1691677813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Community. \n\nI am seeking a technical help here.\n\nI am loading excels file in my cluster using pandas\n\ndf_pandas = pd.read_excel(\u2018mys3path\u2019, encoding = \u2018UTF-8\u2019)\n\ndf_pandas = df_pandas.astype(str) # converting all data to string\n\nNow i am converting it to spark data frame.\n\ndf_spark = spark.createDataFrame(df_pandas)\n # now both the dataframes show data perfectly fine in cli. But when i write it to s3 and then athena picks up in external table, most of the columns are showing as null. But when i read the s3 parquet file again i am able to see the data in cli ( pyspark shell ).\n\nThis is a very strange issue which i have not encountered. If any idea please reach out.", "author_fullname": "t2_rlmb337f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Excel data loan in spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15nd8hp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691675752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Community. &lt;/p&gt;\n\n&lt;p&gt;I am seeking a technical help here.&lt;/p&gt;\n\n&lt;p&gt;I am loading excels file in my cluster using pandas&lt;/p&gt;\n\n&lt;p&gt;df_pandas = pd.read_excel(\u2018mys3path\u2019, encoding = \u2018UTF-8\u2019)&lt;/p&gt;\n\n&lt;p&gt;df_pandas = df_pandas.astype(str) # converting all data to string&lt;/p&gt;\n\n&lt;p&gt;Now i am converting it to spark data frame.&lt;/p&gt;\n\n&lt;p&gt;df_spark = spark.createDataFrame(df_pandas)\n # now both the dataframes show data perfectly fine in cli. But when i write it to s3 and then athena picks up in external table, most of the columns are showing as null. But when i read the s3 parquet file again i am able to see the data in cli ( pyspark shell ).&lt;/p&gt;\n\n&lt;p&gt;This is a very strange issue which i have not encountered. If any idea please reach out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15nd8hp", "is_robot_indexable": true, "report_reasons": null, "author": "xdutsuay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nd8hp/excel_data_loan_in_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nd8hp/excel_data_loan_in_spark/", "subreddit_subscribers": 121957, "created_utc": 1691675752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A project has fallen into my lap to provide some consulting work for a small company that has five daily external data sources that are either full drop and replace (full refresh) each day, or append daily. The company is currently leveraging a managed service to provide all of the ETL work in their database, but the SOW for database license/managed service is both prohibitively expensive and coming to an end at end of this year (it was tied to other projects but business has changed dramatically and has slimmed since then). The company owns all of the data, they just outsource all of the data management.\n\nThe company has asked if I can be their consultant and set up a new database and can intake and store these five daily data sources automatically (currently sent via SFTP), perform ETL, and then replicate their analytic views so that their Tableau dashboards can continue to run, but just be pointed to a new database.\n\nDoes this thread have any recommended tools for low cost database and ETL tools that are simple to implement and build? Also any suggestions for SFTP site that are easy to setup?\n\nFor context, a friend is a VP in this small company and has asked me if I could do this but I am usually the person that builds analytic views and analyzes data vs. building data engineering processes upstream.\n\nThanks in advance!", "author_fullname": "t2_7nj41", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project Advice - Low Cost and Simple Database, ETL, SFTP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ncho1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691673930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A project has fallen into my lap to provide some consulting work for a small company that has five daily external data sources that are either full drop and replace (full refresh) each day, or append daily. The company is currently leveraging a managed service to provide all of the ETL work in their database, but the SOW for database license/managed service is both prohibitively expensive and coming to an end at end of this year (it was tied to other projects but business has changed dramatically and has slimmed since then). The company owns all of the data, they just outsource all of the data management.&lt;/p&gt;\n\n&lt;p&gt;The company has asked if I can be their consultant and set up a new database and can intake and store these five daily data sources automatically (currently sent via SFTP), perform ETL, and then replicate their analytic views so that their Tableau dashboards can continue to run, but just be pointed to a new database.&lt;/p&gt;\n\n&lt;p&gt;Does this thread have any recommended tools for low cost database and ETL tools that are simple to implement and build? Also any suggestions for SFTP site that are easy to setup?&lt;/p&gt;\n\n&lt;p&gt;For context, a friend is a VP in this small company and has asked me if I could do this but I am usually the person that builds analytic views and analyzes data vs. building data engineering processes upstream.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ncho1", "is_robot_indexable": true, "report_reasons": null, "author": "jroddaman", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ncho1/project_advice_low_cost_and_simple_database_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ncho1/project_advice_low_cost_and_simple_database_etl/", "subreddit_subscribers": 121957, "created_utc": 1691673930.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}