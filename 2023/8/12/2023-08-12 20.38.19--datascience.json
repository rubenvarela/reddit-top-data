{"kind": "Listing", "data": {"after": "t3_15p6fda", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "On LinkedIn I always see 100+ applicants for each position. Is this because the field is over saturated or is there is not much hiring right now? Are DS jobs normally that competitive to get?", "author_fullname": "t2_2sf6re48", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data science/data engineering over saturated?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p8n46", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691857001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On LinkedIn I always see 100+ applicants for each position. Is this because the field is over saturated or is there is not much hiring right now? Are DS jobs normally that competitive to get?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p8n46", "is_robot_indexable": true, "report_reasons": null, "author": "unluckyowl4", "discussion_type": null, "num_comments": 107, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p8n46/is_data_sciencedata_engineering_over_saturated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p8n46/is_data_sciencedata_engineering_over_saturated/", "subreddit_subscribers": 983812, "created_utc": 1691857001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to solve a specific problem and will use it to articulate a more general concept. I am trying to predict horse races (i.e. which horse will win.) Let's say that for each race, I have 140 features - 10 features for each of the maximum 14 running horses. In my dataset, half the races only have 7 runners. Therefore, for half the datapoints/races, at least half of the features are \"empty\". I choose the word \"empty\" because it is not that the data is \"missing\" due to, for example, an issue with data extraction.\n\nFor context, I am currently using an XGBoost model. Is this a common problem? Are there any best practices? Or, am I phrasing the problem poorly? Maybe I should train a model that predicts whether each horse will win independently? I'd appreciate some advise on how to reframe the problem/solve \"empty\" data. Cheers", "author_fullname": "t2_xfx8ms4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle empty, not missing, features", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oxs5q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691824776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to solve a specific problem and will use it to articulate a more general concept. I am trying to predict horse races (i.e. which horse will win.) Let&amp;#39;s say that for each race, I have 140 features - 10 features for each of the maximum 14 running horses. In my dataset, half the races only have 7 runners. Therefore, for half the datapoints/races, at least half of the features are &amp;quot;empty&amp;quot;. I choose the word &amp;quot;empty&amp;quot; because it is not that the data is &amp;quot;missing&amp;quot; due to, for example, an issue with data extraction.&lt;/p&gt;\n\n&lt;p&gt;For context, I am currently using an XGBoost model. Is this a common problem? Are there any best practices? Or, am I phrasing the problem poorly? Maybe I should train a model that predicts whether each horse will win independently? I&amp;#39;d appreciate some advise on how to reframe the problem/solve &amp;quot;empty&amp;quot; data. Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oxs5q", "is_robot_indexable": true, "report_reasons": null, "author": "HStuart18", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oxs5q/how_to_handle_empty_not_missing_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oxs5q/how_to_handle_empty_not_missing_features/", "subreddit_subscribers": 983812, "created_utc": 1691824776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi could anyone guide me in the right direction for my project. I have just over a month to get it done which would be perfectly fine but I'm very stuck and my supervisor is away and I couldn't get help on stack overflow. \n\nMy data is attached below. This is a sample, I have 66 players who have full data from 2015 to 2023. My intention was to use python to train a model to train with the player statistics from 2015-22, and predict 2023s points per minute and test against that. I have tried for a long time on python and got nowhere, is my task possible? Can someone point me in the right direction please? I am allowed to use any software or techniques. \n\nhttps://preview.redd.it/nua1pnsq1lhb1.png?width=2852&amp;format=png&amp;auto=webp&amp;s=ec26caf8078a29de79241ce74eb46ad2c6478704", "author_fullname": "t2_helqwmszk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NBA Player Data prediction help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "media_metadata": {"nua1pnsq1lhb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5f6a6f82cb504647f24802a38e182bf9f485da54"}, {"y": 103, "x": 216, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d83aa87130252968240ddc5246a1ce9a31dc2f3"}, {"y": 153, "x": 320, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9873e1d51992c0c16692ac32420e28748ca13b03"}, {"y": 306, "x": 640, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d501ec2dcbc9541d5c1bd750ea81fbec63bc94a2"}, {"y": 460, "x": 960, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=adb02ed48378b70c0a3337a5ef7143b91932aaf2"}, {"y": 517, "x": 1080, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1b1e747cc76ff35091a25198755375f592ceff91"}], "s": {"y": 1367, "x": 2852, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=2852&amp;format=png&amp;auto=webp&amp;s=ec26caf8078a29de79241ce74eb46ad2c6478704"}, "id": "nua1pnsq1lhb1"}}, "name": "t3_15or8be", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vJV_w5OykkEASRkhcS_9UJ1GcqlqaB-n_MsfWciLP7Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691804198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi could anyone guide me in the right direction for my project. I have just over a month to get it done which would be perfectly fine but I&amp;#39;m very stuck and my supervisor is away and I couldn&amp;#39;t get help on stack overflow. &lt;/p&gt;\n\n&lt;p&gt;My data is attached below. This is a sample, I have 66 players who have full data from 2015 to 2023. My intention was to use python to train a model to train with the player statistics from 2015-22, and predict 2023s points per minute and test against that. I have tried for a long time on python and got nowhere, is my task possible? Can someone point me in the right direction please? I am allowed to use any software or techniques. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nua1pnsq1lhb1.png?width=2852&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec26caf8078a29de79241ce74eb46ad2c6478704\"&gt;https://preview.redd.it/nua1pnsq1lhb1.png?width=2852&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec26caf8078a29de79241ce74eb46ad2c6478704&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15or8be", "is_robot_indexable": true, "report_reasons": null, "author": "Tiny_Musician1844", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15or8be/nba_player_data_prediction_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15or8be/nba_player_data_prediction_help/", "subreddit_subscribers": 983812, "created_utc": 1691804198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been self-learning data science and ML for the past two years and have also worked on many portfolio projects. However, I have found myself stuck in a cycle of continuous learning. I understand that ML is a wide field and demands continuous learning for personal growth, but I think I should be learning by working hands-on in the field rather than being caught endlessly in this learning phase.\n\nI have now considered taking up freelance projects related to DS and ML to gain some hands-on experience. Despite this intention, I feel extremely overwhelmed and unconfident about whether or not I will be able to do the projects on my own. I want to kill this hesitation and start working. I am at a crossroads and would greatly appreciate some guidance from the community.", "author_fullname": "t2_6oagcr1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am stuck in a \"Learning\" loop (Seeking Guidance to Break Free)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p9qng", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691860046.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691859789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been self-learning data science and ML for the past two years and have also worked on many portfolio projects. However, I have found myself stuck in a cycle of continuous learning. I understand that ML is a wide field and demands continuous learning for personal growth, but I think I should be learning by working hands-on in the field rather than being caught endlessly in this learning phase.&lt;/p&gt;\n\n&lt;p&gt;I have now considered taking up freelance projects related to DS and ML to gain some hands-on experience. Despite this intention, I feel extremely overwhelmed and unconfident about whether or not I will be able to do the projects on my own. I want to kill this hesitation and start working. I am at a crossroads and would greatly appreciate some guidance from the community.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p9qng", "is_robot_indexable": true, "report_reasons": null, "author": "hashirbhatti", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p9qng/i_am_stuck_in_a_learning_loop_seeking_guidance_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p9qng/i_am_stuck_in_a_learning_loop_seeking_guidance_to/", "subreddit_subscribers": 983812, "created_utc": 1691859789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As a data scientist I have worked on projects ranging from classic ml to computer vision.\nI always think as a DS or ML engineer we should also be aware about mlops tech stacks, best practices in model evaluation, deployment, monitoring and continual training. So I want to understand from folks who are working as DS , \nwhat is the most preferred tech stacks for MLops?\nAre companies using single cloud service providers like azure/aws for end to end developments or they prefer open-source mlops tools?", "author_fullname": "t2_ifsmh8cn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "mlops landscape in industry.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p4csj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691846142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a data scientist I have worked on projects ranging from classic ml to computer vision.\nI always think as a DS or ML engineer we should also be aware about mlops tech stacks, best practices in model evaluation, deployment, monitoring and continual training. So I want to understand from folks who are working as DS , \nwhat is the most preferred tech stacks for MLops?\nAre companies using single cloud service providers like azure/aws for end to end developments or they prefer open-source mlops tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p4csj", "is_robot_indexable": true, "report_reasons": null, "author": "Quest_to_peace", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p4csj/mlops_landscape_in_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p4csj/mlops_landscape_in_industry/", "subreddit_subscribers": 983812, "created_utc": 1691846142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm 29, currently in a masters program for Data Science, and I don't think I really enjoy it all that much. I got into the field because I thought it would be a lot of coding and developing, which in my previous undergrad and grad courses, I loved. I just don't think I really enjoy, or have a good grasp on, statistics. Since this field is so heavily based on that, I don't know if it's something I want to spend my life on. \n\nI was wondering if anyone in here has experience doing both of these fields, particularly in software engineering/development. That's the field that I think I'd like to go into, and would focus my electives on that field. If anyone has any stories about their life changing one way or the other, and how much they enjoy the career they're in, I'd really appreciate it!", "author_fullname": "t2_4g7bbvw2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thinking about changing masters program from data science to computer science, thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15pddwy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691868846.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m 29, currently in a masters program for Data Science, and I don&amp;#39;t think I really enjoy it all that much. I got into the field because I thought it would be a lot of coding and developing, which in my previous undergrad and grad courses, I loved. I just don&amp;#39;t think I really enjoy, or have a good grasp on, statistics. Since this field is so heavily based on that, I don&amp;#39;t know if it&amp;#39;s something I want to spend my life on. &lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone in here has experience doing both of these fields, particularly in software engineering/development. That&amp;#39;s the field that I think I&amp;#39;d like to go into, and would focus my electives on that field. If anyone has any stories about their life changing one way or the other, and how much they enjoy the career they&amp;#39;re in, I&amp;#39;d really appreciate it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15pddwy", "is_robot_indexable": true, "report_reasons": null, "author": "bigmoist469", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15pddwy/thinking_about_changing_masters_program_from_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15pddwy/thinking_about_changing_masters_program_from_data/", "subreddit_subscribers": 983812, "created_utc": 1691868846.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So as a project and for practice I'm building a customer churn prediction model. I was getting very high results for my metrics, so I did some googling and realized I had allowed data leakage since I was doing data preprocessing before splitting the data into training and testing sets. So I went back and split my dataset first, then started binning and converting my categorical columns into numerical form, but only on the training set. But then I ran into another problem; the training dataset had undergone data preprocessing whereas the testing set hadn't, so after fitting the model and then attempting to use the sklearn predict method to evaluate the model via metrics, I ran into an error which basically told me that the training set and testing set did not have the same features.  However, I'm wary about preprocessing the testing set because it seems to me like that would be the same as what I was doing earlier. So, I wanted to ask, what's best in this situation? \n\nThanks.", "author_fullname": "t2_3yvdmdyj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this still count as overfitting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15pakn1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691861902.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So as a project and for practice I&amp;#39;m building a customer churn prediction model. I was getting very high results for my metrics, so I did some googling and realized I had allowed data leakage since I was doing data preprocessing before splitting the data into training and testing sets. So I went back and split my dataset first, then started binning and converting my categorical columns into numerical form, but only on the training set. But then I ran into another problem; the training dataset had undergone data preprocessing whereas the testing set hadn&amp;#39;t, so after fitting the model and then attempting to use the sklearn predict method to evaluate the model via metrics, I ran into an error which basically told me that the training set and testing set did not have the same features.  However, I&amp;#39;m wary about preprocessing the testing set because it seems to me like that would be the same as what I was doing earlier. So, I wanted to ask, what&amp;#39;s best in this situation? &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15pakn1", "is_robot_indexable": true, "report_reasons": null, "author": "aye_hus_that", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15pakn1/does_this_still_count_as_overfitting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15pakn1/does_this_still_count_as_overfitting/", "subreddit_subscribers": 983812, "created_utc": 1691861902.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working on a portfolio project to add to my website, and in the project I use some plotting functions from a haggle time series course. I am currently going back and adding comments and wonder if I should say where the code came from (ex: plotting code from Maggie time series course). Thanks!", "author_fullname": "t2_6nwrovjl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Credit borrowed code portfolio project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p7eaa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691853869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a portfolio project to add to my website, and in the project I use some plotting functions from a haggle time series course. I am currently going back and adding comments and wonder if I should say where the code came from (ex: plotting code from Maggie time series course). Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p7eaa", "is_robot_indexable": true, "report_reasons": null, "author": "Tedward-Roosevelt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p7eaa/credit_borrowed_code_portfolio_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p7eaa/credit_borrowed_code_portfolio_project/", "subreddit_subscribers": 983812, "created_utc": 1691853869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Trivia question: what is your purpose in life? \n\nAnswer: \u2728creating shareholder value\u2728  You don't exist to enjoy life, your only purpose is to work, and outside of work hours you should be spending time and money to improve yourself for our benefit. \n\nThanks, \n\nManagement", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Friendly reminder: you only exist to create shareholder value!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p9yr8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691860356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trivia question: what is your purpose in life? &lt;/p&gt;\n\n&lt;p&gt;Answer: \u2728creating shareholder value\u2728  You don&amp;#39;t exist to enjoy life, your only purpose is to work, and outside of work hours you should be spending time and money to improve yourself for our benefit. &lt;/p&gt;\n\n&lt;p&gt;Thanks, &lt;/p&gt;\n\n&lt;p&gt;Management&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p9yr8", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p9yr8/friendly_reminder_you_only_exist_to_create/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p9yr8/friendly_reminder_you_only_exist_to_create/", "subreddit_subscribers": 983812, "created_utc": 1691860356.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I have a newbie question on the process of time series forecasting in the real-world. Does one take a series of data point and curve fit some polynomial to it?\n\nWhat bothers me in reading the time series forecasting books is that the book do not consider cases where the underlying process changes. Also, the series on data points do not necessarily provide an understanding of the underlying generating process.", "author_fullname": "t2_95p57065", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Process of practical time series forecasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p90el", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691857924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have a newbie question on the process of time series forecasting in the real-world. Does one take a series of data point and curve fit some polynomial to it?&lt;/p&gt;\n\n&lt;p&gt;What bothers me in reading the time series forecasting books is that the book do not consider cases where the underlying process changes. Also, the series on data points do not necessarily provide an understanding of the underlying generating process.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p90el", "is_robot_indexable": true, "report_reasons": null, "author": "SqueezDeezNutz69", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p90el/process_of_practical_time_series_forecasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p90el/process_of_practical_time_series_forecasting/", "subreddit_subscribers": 983812, "created_utc": 1691857924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im working on a project and have been using chat gpt to generate larger and larger sections of code, especially since I don't understand a lot of the libraries Im using, or even the algorithems behind the code. I just want to get the project finished but at the same time I'd feel like a fraud if I didn't mention the code was not generated by me. What should I do? I'm using this project as portfolio piece to send alongside my CV for data analyst positions.\n\nIs there even any value to a project which:\n\n1. isn't demonstrating the true level of my skills\n2. isn't really helping me learn anything (perhaps only 10% python syntax and a broad overview of D.S algorithms )\n\nAlso I feel like this project has spiralled more into data science territory more than analysis, as I'm using NLP, Doc2Vec and things like that to do my analysis. So I feel like im venturing into deeply unknown territory and giving a false impression of my understanding.", "author_fullname": "t2_381zkha4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I used GPT to write my code: Should I mention it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p69sn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691851087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im working on a project and have been using chat gpt to generate larger and larger sections of code, especially since I don&amp;#39;t understand a lot of the libraries Im using, or even the algorithems behind the code. I just want to get the project finished but at the same time I&amp;#39;d feel like a fraud if I didn&amp;#39;t mention the code was not generated by me. What should I do? I&amp;#39;m using this project as portfolio piece to send alongside my CV for data analyst positions.&lt;/p&gt;\n\n&lt;p&gt;Is there even any value to a project which:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;isn&amp;#39;t demonstrating the true level of my skills&lt;/li&gt;\n&lt;li&gt;isn&amp;#39;t really helping me learn anything (perhaps only 10% python syntax and a broad overview of D.S algorithms )&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Also I feel like this project has spiralled more into data science territory more than analysis, as I&amp;#39;m using NLP, Doc2Vec and things like that to do my analysis. So I feel like im venturing into deeply unknown territory and giving a false impression of my understanding.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p69sn", "is_robot_indexable": true, "report_reasons": null, "author": "bigjungus11", "discussion_type": null, "num_comments": 72, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p69sn/i_used_gpt_to_write_my_code_should_i_mention_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p69sn/i_used_gpt_to_write_my_code_should_i_mention_it/", "subreddit_subscribers": 983812, "created_utc": 1691851087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am completing an internship at a small Fintech company and I have received an offer for a junior data scientist position. On the other hand there's an offer from a big 4 Company for a trainee role. I have really enjoyed my internship and I have learnt a lot. The Big 4  salary offer is slightly higher than the startup's. Is it worth leaving the startup for a Big 4 role? ( The problem with the Fintech company is that it is very hard to grow into senior roles as the current juniors have been telling me)", "author_fullname": "t2_atkfvp00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fintech company or Big 4 Offer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oxg7e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691823642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am completing an internship at a small Fintech company and I have received an offer for a junior data scientist position. On the other hand there&amp;#39;s an offer from a big 4 Company for a trainee role. I have really enjoyed my internship and I have learnt a lot. The Big 4  salary offer is slightly higher than the startup&amp;#39;s. Is it worth leaving the startup for a Big 4 role? ( The problem with the Fintech company is that it is very hard to grow into senior roles as the current juniors have been telling me)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oxg7e", "is_robot_indexable": true, "report_reasons": null, "author": "LogicalBenefit7410", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oxg7e/fintech_company_or_big_4_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oxg7e/fintech_company_or_big_4_offer/", "subreddit_subscribers": 983812, "created_utc": 1691823642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been diving deep into the realm of data labeling solutions for enterprise contexts, specifically focusing on SageMaker Data Labeling (including Ground Truth and Ground Truth Plus) and V7 Labs.   \nWhether you've found success, faced challenges, or discovered unique features in either solution, I'm eager to tap into the collective expertise of this community and glean insights from those who possess hands-on experience with either of these platforms.\n\nI'm particularly interested in hearing y'all's opinions on the following aspects:\n\n1. **Ease of Use**: How user-friendly are these platforms? Was one more intuitive than the other?\n2. **Labeling Quality**: What about the quality of labels generated by SageMaker vs. V7 Labs? Any notable differences?\n3. **Customization and Flexibility**: Which platform offers better options for tailoring the labeling process to your specific needs?\n4. **Scalability**: How well did these solutions scale as labeling demands increased?\n5. **Integration and Compatibility**: How seamlessly do SageMaker and V7 Labs integrate with your existing data science workflows and tools?\n6. **Cost Considerations**: Were there significant differences in pricing structures or overall cost-effectiveness between the two?\n7. **Documentation Quality**: Any thoughts on the comprehensiveness and effectiveness of documentation provided by both SageMaker and V7 Labs?\n8. **Unique Capabilities**: What distinct functionalities set SageMaker and V7 Labs apart? Are there specific tasks that one platform excels at that the other might struggle with?\n\nPlease feel free to share experiences, anecdotes, or any insights you believe could contribute to this comparison. I feel this community's unique insights and perspectives can provide invaluable guidance in shaping a well-rounded perspective.", "author_fullname": "t2_chp44bhd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Comparison of SageMaker Data Labeling and V7 Labs for Enterprise Labeling Solutions - Seeking Insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ou2g0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691812564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been diving deep into the realm of data labeling solutions for enterprise contexts, specifically focusing on SageMaker Data Labeling (including Ground Truth and Ground Truth Plus) and V7 Labs.&lt;br/&gt;\nWhether you&amp;#39;ve found success, faced challenges, or discovered unique features in either solution, I&amp;#39;m eager to tap into the collective expertise of this community and glean insights from those who possess hands-on experience with either of these platforms.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m particularly interested in hearing y&amp;#39;all&amp;#39;s opinions on the following aspects:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Ease of Use&lt;/strong&gt;: How user-friendly are these platforms? Was one more intuitive than the other?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Labeling Quality&lt;/strong&gt;: What about the quality of labels generated by SageMaker vs. V7 Labs? Any notable differences?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Customization and Flexibility&lt;/strong&gt;: Which platform offers better options for tailoring the labeling process to your specific needs?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: How well did these solutions scale as labeling demands increased?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Integration and Compatibility&lt;/strong&gt;: How seamlessly do SageMaker and V7 Labs integrate with your existing data science workflows and tools?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Cost Considerations&lt;/strong&gt;: Were there significant differences in pricing structures or overall cost-effectiveness between the two?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Documentation Quality&lt;/strong&gt;: Any thoughts on the comprehensiveness and effectiveness of documentation provided by both SageMaker and V7 Labs?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Unique Capabilities&lt;/strong&gt;: What distinct functionalities set SageMaker and V7 Labs apart? Are there specific tasks that one platform excels at that the other might struggle with?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Please feel free to share experiences, anecdotes, or any insights you believe could contribute to this comparison. I feel this community&amp;#39;s unique insights and perspectives can provide invaluable guidance in shaping a well-rounded perspective.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ou2g0", "is_robot_indexable": true, "report_reasons": null, "author": "fizix00", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ou2g0/a_comparison_of_sagemaker_data_labeling_and_v7/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ou2g0/a_comparison_of_sagemaker_data_labeling_and_v7/", "subreddit_subscribers": 983812, "created_utc": 1691812564.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve got a database that pretty much can be described like this:  \n\n1. There are commanders that have synergy scores for about ~300 cards each.  \n2. Each commander has a text box that might say things like \u201cWhenever you cast a Snake spell, draw a card\u201d and other properties like color, card type (creature, enchantment, artifact etc) type line, power toughness, etc.   \n3. Each card, from a dataset of 30,000 cards has those same properties as well.  \n\nI\u2019d like to use the synergy scores that I\u2019ve already calculated as a positive reinforcement where you can substitute either a card in the deck or the deck\u2019s commander and recalculate synergy scores.\n\nI\u2019ve heard of word2vec, but reading about it makes it seem like it\u2019s more about auto completion, when really what I\u2019m looking for is a way to turn each card\u2019s text box into something that a ML model can work with. I\u2019m not sure if the word ordering matters a whole ton and if I could just use a bag of words technique.\n\nHere\u2019s a card for example:\nhttps://scryfall.com/card/mh1/75/urza-lord-high-artificer\n\nFor some different commanders, different properties will matter more - maybe power/toughness for some, creature types for others, and others where any mention of +1/+1 counters in the text box is a bonus.\n\nCurrently the synergy score is \u201chow many times more frequently does {cardname} appear in {commander}\u2019s decks than the average deck of {commander}\u2019s color identity\u201d, but I\u2019d like to learn/predict it so that it works with custom/new cards as well.\n\nHit \u201cRandom commander\u201d here to see what that looks like here: https://www.cardcognition.com", "author_fullname": "t2_6wdbzop4d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to convert MtG Card text to vector?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15pdmht", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691869695.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691869443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve got a database that pretty much can be described like this:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;There are commanders that have synergy scores for about ~300 cards each.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Each commander has a text box that might say things like \u201cWhenever you cast a Snake spell, draw a card\u201d and other properties like color, card type (creature, enchantment, artifact etc) type line, power toughness, etc.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Each card, from a dataset of 30,000 cards has those same properties as well.&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I\u2019d like to use the synergy scores that I\u2019ve already calculated as a positive reinforcement where you can substitute either a card in the deck or the deck\u2019s commander and recalculate synergy scores.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve heard of word2vec, but reading about it makes it seem like it\u2019s more about auto completion, when really what I\u2019m looking for is a way to turn each card\u2019s text box into something that a ML model can work with. I\u2019m not sure if the word ordering matters a whole ton and if I could just use a bag of words technique.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s a card for example:\n&lt;a href=\"https://scryfall.com/card/mh1/75/urza-lord-high-artificer\"&gt;https://scryfall.com/card/mh1/75/urza-lord-high-artificer&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For some different commanders, different properties will matter more - maybe power/toughness for some, creature types for others, and others where any mention of +1/+1 counters in the text box is a bonus.&lt;/p&gt;\n\n&lt;p&gt;Currently the synergy score is \u201chow many times more frequently does {cardname} appear in {commander}\u2019s decks than the average deck of {commander}\u2019s color identity\u201d, but I\u2019d like to learn/predict it so that it works with custom/new cards as well.&lt;/p&gt;\n\n&lt;p&gt;Hit \u201cRandom commander\u201d here to see what that looks like here: &lt;a href=\"https://www.cardcognition.com\"&gt;https://www.cardcognition.com&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NUlBI0G454N_YJrGBLsvzk9WhfL-0Wg1abSUkVesvhM.jpg?auto=webp&amp;s=a6bce4fbe3e02776472ef2fa7db408ca8643b488", "width": 672, "height": 936}, "resolutions": [{"url": "https://external-preview.redd.it/NUlBI0G454N_YJrGBLsvzk9WhfL-0Wg1abSUkVesvhM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf4d7d1f4a87a0aeb853ce360cb657f089edca95", "width": 108, "height": 150}, {"url": "https://external-preview.redd.it/NUlBI0G454N_YJrGBLsvzk9WhfL-0Wg1abSUkVesvhM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e8197433bb70e77a3502276c4e42cb66f832f86d", "width": 216, "height": 300}, {"url": "https://external-preview.redd.it/NUlBI0G454N_YJrGBLsvzk9WhfL-0Wg1abSUkVesvhM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1f7170f1c93a010a56f8c6175fc7db2d2a56fd3a", "width": 320, "height": 445}, {"url": "https://external-preview.redd.it/NUlBI0G454N_YJrGBLsvzk9WhfL-0Wg1abSUkVesvhM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f94b0a137e6cf745cd2c07a869a15809801a248d", "width": 640, "height": 891}], "variants": {}, "id": "l_r1QcZj58D4Ow-tqfEROxv7d_xXrH0G5hb7FJCFjs4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15pdmht", "is_robot_indexable": true, "report_reasons": null, "author": "AcrobaticDependent35", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15pdmht/how_to_convert_mtg_card_text_to_vector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15pdmht/how_to_convert_mtg_card_text_to_vector/", "subreddit_subscribers": 983812, "created_utc": 1691869443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nAm new to data science and R. Was doing an analysis using the K-function/Ripley's K, but I ended up getting an overblown legend which covers half the graph (as shown in the picture).\n\nHow do i rectify this? Is there code to help remedy the issue or can I somehow change it using R devtools?\n\nAny and all help is welcome.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/a3bqg1j16qhb1.png?width=1169&amp;format=png&amp;auto=webp&amp;s=59efb4e247b6817c5e8bfbb96d646896c730d9cd", "author_fullname": "t2_598w3ao9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "help with K-function formatting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": true, "media_metadata": {"a3bqg1j16qhb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/a3bqg1j16qhb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=be2e015553df2864aef0626a7d9157b985610d31"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/a3bqg1j16qhb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ca1bf9006777039f016293ebbc8fb5b47e518586"}, {"y": 212, "x": 320, "u": "https://preview.redd.it/a3bqg1j16qhb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa8559e4e768a3ef539c315c7d6918e86f54167b"}, {"y": 425, "x": 640, "u": "https://preview.redd.it/a3bqg1j16qhb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=201d9793e4d87972a7e2c6be0a86a79369481097"}, {"y": 638, "x": 960, "u": "https://preview.redd.it/a3bqg1j16qhb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=669adc91ac9ccdcb79f4f24e9c304922b9ea0106"}, {"y": 717, "x": 1080, "u": "https://preview.redd.it/a3bqg1j16qhb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=deeaf217a584856a9db921ab7fe641c4cfa925d4"}], "s": {"y": 777, "x": 1169, "u": "https://preview.redd.it/a3bqg1j16qhb1.png?width=1169&amp;format=png&amp;auto=webp&amp;s=59efb4e247b6817c5e8bfbb96d646896c730d9cd"}, "id": "a3bqg1j16qhb1"}}, "name": "t3_15pc7i7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6sM8svGi3FwTEcqkTmHb1uNpUlG6WmKE_h6qv7zCA4Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691865950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Am new to data science and R. Was doing an analysis using the K-function/Ripley&amp;#39;s K, but I ended up getting an overblown legend which covers half the graph (as shown in the picture).&lt;/p&gt;\n\n&lt;p&gt;How do i rectify this? Is there code to help remedy the issue or can I somehow change it using R devtools?&lt;/p&gt;\n\n&lt;p&gt;Any and all help is welcome.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/a3bqg1j16qhb1.png?width=1169&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=59efb4e247b6817c5e8bfbb96d646896c730d9cd\"&gt;https://preview.redd.it/a3bqg1j16qhb1.png?width=1169&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=59efb4e247b6817c5e8bfbb96d646896c730d9cd&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15pc7i7", "is_robot_indexable": true, "report_reasons": null, "author": "InternationalSmile7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15pc7i7/help_with_kfunction_formatting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15pc7i7/help_with_kfunction_formatting/", "subreddit_subscribers": 983812, "created_utc": 1691865950.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, first time poster here.\nI\u2019m studying a masters that is highly related to remote sensing/ computational science (and ds ml ofc), and i\u2019m wondering what you guys think of the job prospects of the sector.\n\nI see that ds positions r super oversaturated, so does studying this degree give me any advantage \nat all? Are the careers as lucrative as ds?", "author_fullname": "t2_jf2wstqu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are remote sensing/ computational science careers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15pb7uf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691865479.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691863490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, first time poster here.\nI\u2019m studying a masters that is highly related to remote sensing/ computational science (and ds ml ofc), and i\u2019m wondering what you guys think of the job prospects of the sector.&lt;/p&gt;\n\n&lt;p&gt;I see that ds positions r super oversaturated, so does studying this degree give me any advantage \nat all? Are the careers as lucrative as ds?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15pb7uf", "is_robot_indexable": true, "report_reasons": null, "author": "Tree8282", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15pb7uf/how_are_remote_sensing_computational_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15pb7uf/how_are_remote_sensing_computational_science/", "subreddit_subscribers": 983812, "created_utc": 1691863490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am facing quite a lot of anxiety about the DS field right now. I am a data scientist on paper, but for the past few years doing \u201cfull-stack\u201d ML developments. This means from building feature stores, predictive models, inference endpoints and retraining pipelines. \n\nOver the recent months I saw so many organizations expanding their DS teams with the intention of integrate AI into their products, seemingly solely out of hype from the business execs or investors. Many of these AI features don\u2019t seem to generate enough business value compared to the cost of building them. I\u2019m sure at one point the businesses will notice this too. Obviously I know not all of DS is ML, but a huge portion of the job demands out there have that expectation.\n\nAt the same time, this field is getting so damn saturated. 3 out of 5 people I met last week are persuing/has attained a masters in DS/ML. (Tbf it was a non-academic event at a university) I don\u2019t think I want to be here in a few years when we get 23 masters degree holders competing for one junior DS position.\n\nAll these could be just my anxiety speaking, so please correct me if I\u2019m mistaken about the current situation. However, my guts is telling me to make the jump to data engineering, which is the closest thing to what currently do, but my degree was in Stats and not CS. \n\nWhat is the best way to make this transition? Is there a middle ground between DS and DE which I can explore? Any book or article recommendations will greatly appreciated.", "author_fullname": "t2_2kh4l8ej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering as fallback once the LLM hype dies down?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15pb4rq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691863292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am facing quite a lot of anxiety about the DS field right now. I am a data scientist on paper, but for the past few years doing \u201cfull-stack\u201d ML developments. This means from building feature stores, predictive models, inference endpoints and retraining pipelines. &lt;/p&gt;\n\n&lt;p&gt;Over the recent months I saw so many organizations expanding their DS teams with the intention of integrate AI into their products, seemingly solely out of hype from the business execs or investors. Many of these AI features don\u2019t seem to generate enough business value compared to the cost of building them. I\u2019m sure at one point the businesses will notice this too. Obviously I know not all of DS is ML, but a huge portion of the job demands out there have that expectation.&lt;/p&gt;\n\n&lt;p&gt;At the same time, this field is getting so damn saturated. 3 out of 5 people I met last week are persuing/has attained a masters in DS/ML. (Tbf it was a non-academic event at a university) I don\u2019t think I want to be here in a few years when we get 23 masters degree holders competing for one junior DS position.&lt;/p&gt;\n\n&lt;p&gt;All these could be just my anxiety speaking, so please correct me if I\u2019m mistaken about the current situation. However, my guts is telling me to make the jump to data engineering, which is the closest thing to what currently do, but my degree was in Stats and not CS. &lt;/p&gt;\n\n&lt;p&gt;What is the best way to make this transition? Is there a middle ground between DS and DE which I can explore? Any book or article recommendations will greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15pb4rq", "is_robot_indexable": true, "report_reasons": null, "author": "supper_ham", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15pb4rq/data_engineering_as_fallback_once_the_llm_hype/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15pb4rq/data_engineering_as_fallback_once_the_llm_hype/", "subreddit_subscribers": 983812, "created_utc": 1691863292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm using Plotly in Jupyter Notebook and am looking to build some simple web apps to show data to others. Dash is supposedly a pretty simple and yet powerful way to present Plotly interactively on the web.\n\nI've read many threads and blogposts about the hosting aspect and I'm curious if some of you have experience hosting on your own server? I use the provider NordicWay which uses Cpanel. Is it possible to rather simply set up an environment, a bit similar to some pip installs on a local machine?\n\nIt might very well be that it's more of a hassle and therefore makes the most sense to use something like Heroku and only make the switch to ones own server if it becomes necessary down the line.", "author_fullname": "t2_fjvk5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting out with Dash apps - has anyone hosted Dash on their own server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p96ld", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691858356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using Plotly in Jupyter Notebook and am looking to build some simple web apps to show data to others. Dash is supposedly a pretty simple and yet powerful way to present Plotly interactively on the web.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read many threads and blogposts about the hosting aspect and I&amp;#39;m curious if some of you have experience hosting on your own server? I use the provider NordicWay which uses Cpanel. Is it possible to rather simply set up an environment, a bit similar to some pip installs on a local machine?&lt;/p&gt;\n\n&lt;p&gt;It might very well be that it&amp;#39;s more of a hassle and therefore makes the most sense to use something like Heroku and only make the switch to ones own server if it becomes necessary down the line.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p96ld", "is_robot_indexable": true, "report_reasons": null, "author": "supertexter", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p96ld/starting_out_with_dash_apps_has_anyone_hosted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p96ld/starting_out_with_dash_apps_has_anyone_hosted/", "subreddit_subscribers": 983812, "created_utc": 1691858356.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is there an app you know of that can look at a photograph of a bunch of data points sitting on an axis, and output their coordinates relative to the axes that they sit on?\n\nI set up a controlled study to see the impact my org's performing arts classes have on student mood and energy. Students will stick a magnet with their name on it onto a magnetized board with different high/low energy and positive/negative emotions. I'm collecting data from 3,500 students weekly for a year and would love to be able to track their individual changes in mood/energy over time in an automated way. \n\nI can add a unique identifier (QR code?) to each student's magnet to make it possible to track their data individually. \n\nThanks!", "author_fullname": "t2_vy4ye55w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mapping datapoints from a photograph", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15omwja", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691793005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there an app you know of that can look at a photograph of a bunch of data points sitting on an axis, and output their coordinates relative to the axes that they sit on?&lt;/p&gt;\n\n&lt;p&gt;I set up a controlled study to see the impact my org&amp;#39;s performing arts classes have on student mood and energy. Students will stick a magnet with their name on it onto a magnetized board with different high/low energy and positive/negative emotions. I&amp;#39;m collecting data from 3,500 students weekly for a year and would love to be able to track their individual changes in mood/energy over time in an automated way. &lt;/p&gt;\n\n&lt;p&gt;I can add a unique identifier (QR code?) to each student&amp;#39;s magnet to make it possible to track their data individually. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15omwja", "is_robot_indexable": true, "report_reasons": null, "author": "Illapatayta", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15omwja/mapping_datapoints_from_a_photograph/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15omwja/mapping_datapoints_from_a_photograph/", "subreddit_subscribers": 983812, "created_utc": 1691793005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Most of the data science job descriptions require a Bachelors/Masters in Economics, Operations, Statistics, CS, Engineering. \n\nDo interviews test us on DSA, or will programming and data manipulation in SQL and Python suffice? \n\nThanks!", "author_fullname": "t2_muzoa5tk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Structures &amp; Algorithms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ompqy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691792557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of the data science job descriptions require a Bachelors/Masters in Economics, Operations, Statistics, CS, Engineering. &lt;/p&gt;\n\n&lt;p&gt;Do interviews test us on DSA, or will programming and data manipulation in SQL and Python suffice? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ompqy", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate-Box-7", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ompqy/data_structures_algorithms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ompqy/data_structures_algorithms/", "subreddit_subscribers": 983812, "created_utc": 1691792557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9vyd42ki5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IBM Data Science Professional Certificate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15oz9cr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_vaK5g7pcJrKLB9b_LatzhX3U5dwHd65b6L3hMr48zg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691829852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "imp.i384100.net", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://imp.i384100.net/YgYndj", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?auto=webp&amp;s=4528d4dacf007db1a2853bd0c3fa928802c9f37d", "width": 1772, "height": 928}, "resolutions": [{"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8160986c0285b26bb24a19052dca847848f377af", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fdb17a1ffdad7333f5335b7ed49e85c1f3b29d20", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=02bdce13bb1899e2a547756d4cef7702e9b2480c", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c1af862b7681fad183a57ad9a4a007d3cfd16be2", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a6093d69e3e6907ce14b5a9003dd0115f046caab", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=847879f8efd9ab153056585563382e1a318316d7", "width": 1080, "height": 565}], "variants": {}, "id": "iM3wgjxKZ2QDakFEHPdOiRjj5__Tw2diEHESmNLA04E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oz9cr", "is_robot_indexable": true, "report_reasons": null, "author": "Farahhossam112", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oz9cr/ibm_data_science_professional_certificate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://imp.i384100.net/YgYndj", "subreddit_subscribers": 983812, "created_utc": 1691829852.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am looking for the repo or similar repo for this project https://youtu.be/wvsE8jm1GzE", "author_fullname": "t2_7wkh6o3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to find the google t-sne notebook in the video", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ojp5f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691785660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for the repo or similar repo for this project &lt;a href=\"https://youtu.be/wvsE8jm1GzE\"&gt;https://youtu.be/wvsE8jm1GzE&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Hk-y1Z47t2FkR556fmOKa5NLO4ZUmTYv4mZBSJAkJ68.jpg?auto=webp&amp;s=45519c0e3a5fe4a2a1eacfbef43ff32a4dd3ecb0", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/Hk-y1Z47t2FkR556fmOKa5NLO4ZUmTYv4mZBSJAkJ68.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3b48d9a0a78662351c3fdbc1bb91596c791a8452", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Hk-y1Z47t2FkR556fmOKa5NLO4ZUmTYv4mZBSJAkJ68.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bc84273280a4f8680eb2f13c29bebfabf9b16e70", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Hk-y1Z47t2FkR556fmOKa5NLO4ZUmTYv4mZBSJAkJ68.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7237a3362e8f3945ef173bc4a4d2355f60310acd", "width": 320, "height": 240}], "variants": {}, "id": "zwolOIr7Q4zXmsOXwQR6Od4wHKHc_aHVa-pI3BYyubE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ojp5f", "is_robot_indexable": true, "report_reasons": null, "author": "weluuu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ojp5f/where_to_find_the_google_tsne_notebook_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ojp5f/where_to_find_the_google_tsne_notebook_in_the/", "subreddit_subscribers": 983812, "created_utc": 1691785660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the past, I have always encountered problems when data from one source doesn't match data from another. And for me, the solution was data integration. So i want to share with you some data integration strategies that helped my company.\n\n&amp;#x200B;\n\n**ETL (Extract, Transform, Load):** ETL is the backbone of many integration projects. It involves pulling data, reshaping it to fit, and storing it in its new home, usually a data warehouse. The best part? ETL automates the nitty-gritty, ensuring consistency and paving the way for better decision-making.\n\n&amp;#x200B;\n\n**ELT (Extract, Load, Transform):** If ETL is the backbone, ELT is the muscle for handling bulky data sets. It's about collecting data, moving it directly to its target, and making tweaks there. I love it for its agility, especially when dealing with vast amounts of data in real time.\n\n&amp;#x200B;\n\n**Change Data Capture (CDC):** Picture CDC as the ever-watchful sentinel, tracking database changes. It keeps an eye out for alterations, documents them, and ensures they reach where they need to. Its edge? Near real-time data integration, light touch on source systems, and a knack for preserving data history.\n\n&amp;#x200B;\n\n**A Nod to Data Replication**\n\nWith data replication, it's about redundancy for safety. You create backup copies of your data, ensuring continuous access and faster decision-making. Plus, distributing data means potential data losses are a thing of the past.\n\n&amp;#x200B;\n\n**The Magic of Data Virtualization**\n\nHere's a fun one: What if you didn't need a new repository for all your data sources? Data virtualization virtually combines data for a unified view. It offers real-time access and is a cost-effective alternative to traditional storage. From my experience, it also greatly improves data quality and reliability.\n\n&amp;#x200B;\n\nIn my journey, I've learned the importance of handpicking the right tools for the job. They need to gel with your data sources, scale with your needs, and offer efficient infrastructure. \n\nIf you want to dive deeper in topics like this, check out my blog: [https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm\\_source=linkedin&amp;utm\\_medium=social&amp;utm\\_campaign=hfs\\_research&amp;utm\\_content=integration\\_strategy&amp;utm\\_term=socialmedia](https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm_source=linkedin&amp;utm_medium=social&amp;utm_campaign=hfs_research&amp;utm_content=integration_strategy&amp;utm_term=socialmedia) \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_ct09rz3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data integration strategies that work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p1fs4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691837350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the past, I have always encountered problems when data from one source doesn&amp;#39;t match data from another. And for me, the solution was data integration. So i want to share with you some data integration strategies that helped my company.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;ETL (Extract, Transform, Load):&lt;/strong&gt; ETL is the backbone of many integration projects. It involves pulling data, reshaping it to fit, and storing it in its new home, usually a data warehouse. The best part? ETL automates the nitty-gritty, ensuring consistency and paving the way for better decision-making.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;ELT (Extract, Load, Transform):&lt;/strong&gt; If ETL is the backbone, ELT is the muscle for handling bulky data sets. It&amp;#39;s about collecting data, moving it directly to its target, and making tweaks there. I love it for its agility, especially when dealing with vast amounts of data in real time.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Change Data Capture (CDC):&lt;/strong&gt; Picture CDC as the ever-watchful sentinel, tracking database changes. It keeps an eye out for alterations, documents them, and ensures they reach where they need to. Its edge? Near real-time data integration, light touch on source systems, and a knack for preserving data history.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;A Nod to Data Replication&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;With data replication, it&amp;#39;s about redundancy for safety. You create backup copies of your data, ensuring continuous access and faster decision-making. Plus, distributing data means potential data losses are a thing of the past.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Magic of Data Virtualization&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a fun one: What if you didn&amp;#39;t need a new repository for all your data sources? Data virtualization virtually combines data for a unified view. It offers real-time access and is a cost-effective alternative to traditional storage. From my experience, it also greatly improves data quality and reliability.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In my journey, I&amp;#39;ve learned the importance of handpicking the right tools for the job. They need to gel with your data sources, scale with your needs, and offer efficient infrastructure. &lt;/p&gt;\n\n&lt;p&gt;If you want to dive deeper in topics like this, check out my blog: &lt;a href=\"https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=hfs_research&amp;amp;utm_content=integration_strategy&amp;amp;utm_term=socialmedia\"&gt;https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=hfs_research&amp;amp;utm_content=integration_strategy&amp;amp;utm_term=socialmedia&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I3xJj8ELsQOmy2H-NeHKFmGnh2tKVfHX1i7SJ1O1qwE.jpg?auto=webp&amp;s=8a29f85fd320507a70ec9694b971f494352d2655", "width": 79, "height": 86}, "resolutions": [], "variants": {}, "id": "fKkAw45B6Aa1K9gfC0CvmXNzCjb0F-J2wvKUvaKf1Vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p1fs4", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Speech36", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p1fs4/data_integration_strategies_that_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p1fs4/data_integration_strategies_that_work/", "subreddit_subscribers": 983812, "created_utc": 1691837350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi community, I have a dissertation project with a short deadline. I have collected data from 964 participants, each ranking their beliefs in conspiracy theories on a scale of 1-7 (1 being strongly disagree, 4 being neither disagree nor agree and 7 being strongly disagree). Along with Conspiracy beliefs, we have other beliefs as well like, paranormal beliefs, populist attitudes, supernatural beliefs, etc. I have gone with conspiracy beliefs and paranormal beliefs and I am thinking about showing the correlation between them and making a prediction model for it. I struggling very hard to make one and I need your guidance on the process and which algorithm to choose. Please consider me a newbie. Thanks.", "author_fullname": "t2_9hf9h12l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Urgent help with a project is needed!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15opys7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691800737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi community, I have a dissertation project with a short deadline. I have collected data from 964 participants, each ranking their beliefs in conspiracy theories on a scale of 1-7 (1 being strongly disagree, 4 being neither disagree nor agree and 7 being strongly disagree). Along with Conspiracy beliefs, we have other beliefs as well like, paranormal beliefs, populist attitudes, supernatural beliefs, etc. I have gone with conspiracy beliefs and paranormal beliefs and I am thinking about showing the correlation between them and making a prediction model for it. I struggling very hard to make one and I need your guidance on the process and which algorithm to choose. Please consider me a newbie. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15opys7", "is_robot_indexable": true, "report_reasons": null, "author": "More-Tone1339", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15opys7/urgent_help_with_a_project_is_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15opys7/urgent_help_with_a_project_is_needed/", "subreddit_subscribers": 983812, "created_utc": 1691800737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_cf9y2em2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many certification courses do I need to do before getting an job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p6fda", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.23, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691851488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p6fda", "is_robot_indexable": true, "report_reasons": null, "author": "Longjumping-Drop7526", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p6fda/how_many_certification_courses_do_i_need_to_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p6fda/how_many_certification_courses_do_i_need_to_do/", "subreddit_subscribers": 983812, "created_utc": 1691851488.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}