{"kind": "Listing", "data": {"after": "t3_15omwja", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am looking for the name of this type of chart so I can find an example of how they are built.", "author_fullname": "t2_ai7tb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "What are these type of charts called?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2qe26cbmqhhb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/2qe26cbmqhhb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ef26e5f4d60705bb13c5a301b1d5fe356bb2aabd"}, {"y": 155, "x": 216, "u": "https://preview.redd.it/2qe26cbmqhhb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3749ac104d161f4602be9dfb15757ffe95ed9293"}, {"y": 231, "x": 320, "u": "https://preview.redd.it/2qe26cbmqhhb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=969c390afe2f17bdc2fc933d1a41bb498ce72179"}, {"y": 462, "x": 640, "u": "https://preview.redd.it/2qe26cbmqhhb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fbade1935fac1721e8c6d47367eed8a4a839c89f"}], "s": {"y": 462, "x": 640, "u": "https://preview.redd.it/2qe26cbmqhhb1.jpg?width=640&amp;format=pjpg&amp;auto=webp&amp;s=09161254c189ea39239971b5570634a393391255"}, "id": "2qe26cbmqhhb1"}, "y2lewabmqhhb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/y2lewabmqhhb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c1b38db98c25cdacdf28a9005b23edca2da3c741"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/y2lewabmqhhb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=012052577660b27b9cf111763825ef61cc155986"}], "s": {"y": 182, "x": 274, "u": "https://preview.redd.it/y2lewabmqhhb1.jpg?width=274&amp;format=pjpg&amp;auto=webp&amp;s=4ba7b57a14ce7dc7bf6e5e0b40ab9dd5cd5b12eb"}, "id": "y2lewabmqhhb1"}, "ihnvbabmqhhb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/ihnvbabmqhhb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eca0f807effd3748179c50bdc575c1007afa4b30"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/ihnvbabmqhhb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=17d5decd03a0abd0a29bcfb18c421f09527465eb"}], "s": {"y": 224, "x": 224, "u": "https://preview.redd.it/ihnvbabmqhhb1.jpg?width=224&amp;format=pjpg&amp;auto=webp&amp;s=d890c73ef92792a088165a47dc122f274f1a626b"}, "id": "ihnvbabmqhhb1"}, "fy51dbbmqhhb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/fy51dbbmqhhb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b887d60bbd7806c211e2a8db89df34d762bb62f"}, {"y": 160, "x": 216, "u": "https://preview.redd.it/fy51dbbmqhhb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cee4b6cd29c95e1cdcfdb9384ce36440770b9b36"}, {"y": 238, "x": 320, "u": "https://preview.redd.it/fy51dbbmqhhb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b4e6ac35ddfc7364574588e6a2b28d4a439606dd"}, {"y": 477, "x": 640, "u": "https://preview.redd.it/fy51dbbmqhhb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3c7dfc8176706370158b38c34abd1c15be06e48a"}], "s": {"y": 477, "x": 640, "u": "https://preview.redd.it/fy51dbbmqhhb1.jpg?width=640&amp;format=pjpg&amp;auto=webp&amp;s=937f7bb152d58ee59b6dac21b518e1c5668fb6b3"}, "id": "fy51dbbmqhhb1"}, "etbr9sbmqhhb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/etbr9sbmqhhb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7dc2dd45473ca5b4bf99c37ddd2f797ddb5e34f7"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/etbr9sbmqhhb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b361c0813740c03b275c273de9a7668ac46c256"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/etbr9sbmqhhb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f9ce02a6d18e55340c0d9a8f8e552493d5353d3"}, {"y": 640, "x": 640, "u": "https://preview.redd.it/etbr9sbmqhhb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5f5ca2c679ed2bf8c31b940e18d9f8ffd4b35189"}, {"y": 960, "x": 960, "u": "https://preview.redd.it/etbr9sbmqhhb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f09ee139921619c6c5ab3afb926b69409beacd8b"}, {"y": 1080, "x": 1080, "u": "https://preview.redd.it/etbr9sbmqhhb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=99096df0852edda635f44e1eee509bbb02d0c537"}], "s": {"y": 1200, "x": 1200, "u": "https://preview.redd.it/etbr9sbmqhhb1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=22a01f932a64fb298088c4dbae6a3d59eef8393f"}, "id": "etbr9sbmqhhb1"}, "i2uw7abmqhhb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 91, "x": 108, "u": "https://preview.redd.it/i2uw7abmqhhb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=32966ecc0e2ade198f8ab16aa9aa61a2253244f6"}, {"y": 182, "x": 216, "u": "https://preview.redd.it/i2uw7abmqhhb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4dc6347ac8e4366250e7638dd6a08b7f93800a97"}], "s": {"y": 206, "x": 244, "u": "https://preview.redd.it/i2uw7abmqhhb1.jpg?width=244&amp;format=pjpg&amp;auto=webp&amp;s=880f74f5f150c3b6f6376668bd5247328fb75d3f"}, "id": "i2uw7abmqhhb1"}}, "name": "t3_15oacmi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 162, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "fy51dbbmqhhb1", "id": 314022631}, {"media_id": "y2lewabmqhhb1", "id": 314022632}, {"media_id": "i2uw7abmqhhb1", "id": 314022633}, {"media_id": "2qe26cbmqhhb1", "id": 314022634}, {"media_id": "ihnvbabmqhhb1", "id": 314022635}, {"media_id": "etbr9sbmqhhb1", "id": 314022636}]}, "link_flair_text": "Projects", "can_mod_post": false, "score": 162, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z_2FG3ZYDNLPwGT20fVaiCuWBcW7PC5dnjdlJqvc2Ac.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691763889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for the name of this type of chart so I can find an example of how they are built.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/15oacmi", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "15oacmi", "is_robot_indexable": true, "report_reasons": null, "author": "soil_nerd", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oacmi/what_are_these_type_of_charts_called/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/15oacmi", "subreddit_subscribers": 983228, "created_utc": 1691763889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "You won't be given any handouts. Data collection and research are mandatory basics for this role\n\nThis includes things as simple as -\n\n1) Google! Always Google first , no your dataset requirement for your college project isn't so unique that it's not on kaggle. \n\n\n2) read the subs rules - you're new here , sure, read the wiki/pinned thread to get an idea of the sub , do not make assumptions \n\n\n3) use the search functionality - there are very few topics that haven't been discussed. Some might be stale , sure. Link back to that posts findings and ask specific questions that weren't covered \n\n\n4) don't ask open ended questions with 0 background assuming everyone here knows what you know , things like, which model is good for me - ab or xy? I mean come on.\n\n\nThis is not a rant per se , but the culture of expecting people to solve your issues while you do 0 work is not gonna set you up well for a career. \n\nSpecific questions have a better chance of getting a response than a general open ended one .", "author_fullname": "t2_mloui", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Controversial opinion- If you want to be a data scientist, you should be able to do basic research", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ohmb0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 136, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 136, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691781868.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691780828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You won&amp;#39;t be given any handouts. Data collection and research are mandatory basics for this role&lt;/p&gt;\n\n&lt;p&gt;This includes things as simple as -&lt;/p&gt;\n\n&lt;p&gt;1) Google! Always Google first , no your dataset requirement for your college project isn&amp;#39;t so unique that it&amp;#39;s not on kaggle. &lt;/p&gt;\n\n&lt;p&gt;2) read the subs rules - you&amp;#39;re new here , sure, read the wiki/pinned thread to get an idea of the sub , do not make assumptions &lt;/p&gt;\n\n&lt;p&gt;3) use the search functionality - there are very few topics that haven&amp;#39;t been discussed. Some might be stale , sure. Link back to that posts findings and ask specific questions that weren&amp;#39;t covered &lt;/p&gt;\n\n&lt;p&gt;4) don&amp;#39;t ask open ended questions with 0 background assuming everyone here knows what you know , things like, which model is good for me - ab or xy? I mean come on.&lt;/p&gt;\n\n&lt;p&gt;This is not a rant per se , but the culture of expecting people to solve your issues while you do 0 work is not gonna set you up well for a career. &lt;/p&gt;\n\n&lt;p&gt;Specific questions have a better chance of getting a response than a general open ended one .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ohmb0", "is_robot_indexable": true, "report_reasons": null, "author": "Asshaisin", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ohmb0/controversial_opinion_if_you_want_to_be_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ohmb0/controversial_opinion_if_you_want_to_be_a_data/", "subreddit_subscribers": 983228, "created_utc": 1691780828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Everytime I am working on a dataset performing EDA and feature engineering I will turn my notebooks into a complete mess, save csvs multiple times, open new notebooks, go back and forth with my code, until it is something usable. \n\nLater than, I comeback organizing and documenting. Also making a pipeline with all the transformations I just made, and pickle my file GG EZ.\n\nSometimes I think this is unprofessional and I should be going with the pipeline approach first.\n\nWhat's is the data exploration process for you guys?", "author_fullname": "t2_67oqkl0p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this how other people also work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ohgr8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691780484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Everytime I am working on a dataset performing EDA and feature engineering I will turn my notebooks into a complete mess, save csvs multiple times, open new notebooks, go back and forth with my code, until it is something usable. &lt;/p&gt;\n\n&lt;p&gt;Later than, I comeback organizing and documenting. Also making a pipeline with all the transformations I just made, and pickle my file GG EZ.&lt;/p&gt;\n\n&lt;p&gt;Sometimes I think this is unprofessional and I should be going with the pipeline approach first.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s is the data exploration process for you guys?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ohgr8", "is_robot_indexable": true, "report_reasons": null, "author": "dick_veganas", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ohgr8/is_this_how_other_people_also_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ohgr8/is_this_how_other_people_also_work/", "subreddit_subscribers": 983228, "created_utc": 1691780484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Am I the only one?", "author_fullname": "t2_b63krvaxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many of you do not use A/B testing in your jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15odbqj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691770927.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Am I the only one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15odbqj", "is_robot_indexable": true, "report_reasons": null, "author": "ExcuseNo6720", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15odbqj/how_many_of_you_do_not_use_ab_testing_in_your_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15odbqj/how_many_of_you_do_not_use_ab_testing_in_your_jobs/", "subreddit_subscribers": 983228, "created_utc": 1691770927.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I recently graduated with a CS degree and in my final year wrote a well received dissertation about using Autoencoders for Fraud Detection in Banks. So I am well versed in Python (and its libraries like Scikit learn and Pandas), SQL, some R, Statistics and Probability. I also started using Tableau as a visualisation tool (beginner level stuff). \n\nFinding a job was hard but I got contacted by a very interesting startup and wanted to honestly just get a chance at anything and then move on. But the problem is that this company is very new and the product they are releasing has very little data to work with. This was literally a position they just created and I feel like I was recruited by luck. What should I, as a Data Analyst, be doing? What kind of programs should I be using or are there any processes that I should be automating? Do I need to use Machine Learning or just evaluate whatever they give and write reports? As the first person of this kind at this place, do I need to establish any standards or policies? This is literally my first job in the corporate world and I have no idea what I should do. ", "author_fullname": "t2_ittve9rh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should I prepare for as the only and first Data Analyst at a startup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15odltr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691771589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I recently graduated with a CS degree and in my final year wrote a well received dissertation about using Autoencoders for Fraud Detection in Banks. So I am well versed in Python (and its libraries like Scikit learn and Pandas), SQL, some R, Statistics and Probability. I also started using Tableau as a visualisation tool (beginner level stuff). &lt;/p&gt;\n\n&lt;p&gt;Finding a job was hard but I got contacted by a very interesting startup and wanted to honestly just get a chance at anything and then move on. But the problem is that this company is very new and the product they are releasing has very little data to work with. This was literally a position they just created and I feel like I was recruited by luck. What should I, as a Data Analyst, be doing? What kind of programs should I be using or are there any processes that I should be automating? Do I need to use Machine Learning or just evaluate whatever they give and write reports? As the first person of this kind at this place, do I need to establish any standards or policies? This is literally my first job in the corporate world and I have no idea what I should do. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15odltr", "is_robot_indexable": true, "report_reasons": null, "author": "frosted_thoughts", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15odltr/what_should_i_prepare_for_as_the_only_and_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15odltr/what_should_i_prepare_for_as_the_only_and_first/", "subreddit_subscribers": 983228, "created_utc": 1691771589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been working for a public university for 18 months. I've had 2 years of internship experience prior to my current role as well. I have a B.S. in Data Science and I am enrolled in another analytics master's program. I've been looking to switch jobs for the past 3 months and not having much luck with getting interviews. Starting to get frustrated and I can't wait to leave my current job as it's moving into Data Engineering and I want to be more analytics focused. How do I keep pushing and not completely give up on data and move to project management.", "author_fullname": "t2_ko07z6n0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Frustrated - 0 interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o9oai", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691762286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working for a public university for 18 months. I&amp;#39;ve had 2 years of internship experience prior to my current role as well. I have a B.S. in Data Science and I am enrolled in another analytics master&amp;#39;s program. I&amp;#39;ve been looking to switch jobs for the past 3 months and not having much luck with getting interviews. Starting to get frustrated and I can&amp;#39;t wait to leave my current job as it&amp;#39;s moving into Data Engineering and I want to be more analytics focused. How do I keep pushing and not completely give up on data and move to project management.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15o9oai", "is_robot_indexable": true, "report_reasons": null, "author": "OEAnalyst", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15o9oai/frustrated_0_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15o9oai/frustrated_0_interviews/", "subreddit_subscribers": 983228, "created_utc": 1691762286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi could anyone guide me in the right direction for my project. I have just over a month to get it done which would be perfectly fine but I'm very stuck and my supervisor is away and I couldn't get help on stack overflow. \n\nMy data is attached below. This is a sample, I have 66 players who have full data from 2015 to 2023. My intention was to use python to train a model to train with the player statistics from 2015-22, and predict 2023s points per minute and test against that. I have tried for a long time on python and got nowhere, is my task possible? Can someone point me in the right direction please? I am allowed to use any software or techniques. \n\nhttps://preview.redd.it/nua1pnsq1lhb1.png?width=2852&amp;format=png&amp;auto=webp&amp;s=ec26caf8078a29de79241ce74eb46ad2c6478704", "author_fullname": "t2_helqwmszk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NBA Player Data prediction help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "media_metadata": {"nua1pnsq1lhb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5f6a6f82cb504647f24802a38e182bf9f485da54"}, {"y": 103, "x": 216, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d83aa87130252968240ddc5246a1ce9a31dc2f3"}, {"y": 153, "x": 320, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9873e1d51992c0c16692ac32420e28748ca13b03"}, {"y": 306, "x": 640, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d501ec2dcbc9541d5c1bd750ea81fbec63bc94a2"}, {"y": 460, "x": 960, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=adb02ed48378b70c0a3337a5ef7143b91932aaf2"}, {"y": 517, "x": 1080, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1b1e747cc76ff35091a25198755375f592ceff91"}], "s": {"y": 1367, "x": 2852, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=2852&amp;format=png&amp;auto=webp&amp;s=ec26caf8078a29de79241ce74eb46ad2c6478704"}, "id": "nua1pnsq1lhb1"}}, "name": "t3_15or8be", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vJV_w5OykkEASRkhcS_9UJ1GcqlqaB-n_MsfWciLP7Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691804198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi could anyone guide me in the right direction for my project. I have just over a month to get it done which would be perfectly fine but I&amp;#39;m very stuck and my supervisor is away and I couldn&amp;#39;t get help on stack overflow. &lt;/p&gt;\n\n&lt;p&gt;My data is attached below. This is a sample, I have 66 players who have full data from 2015 to 2023. My intention was to use python to train a model to train with the player statistics from 2015-22, and predict 2023s points per minute and test against that. I have tried for a long time on python and got nowhere, is my task possible? Can someone point me in the right direction please? I am allowed to use any software or techniques. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nua1pnsq1lhb1.png?width=2852&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec26caf8078a29de79241ce74eb46ad2c6478704\"&gt;https://preview.redd.it/nua1pnsq1lhb1.png?width=2852&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec26caf8078a29de79241ce74eb46ad2c6478704&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15or8be", "is_robot_indexable": true, "report_reasons": null, "author": "Tiny_Musician1844", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15or8be/nba_player_data_prediction_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15or8be/nba_player_data_prediction_help/", "subreddit_subscribers": 983228, "created_utc": 1691804198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In September I will start my 2 year Masters in Finance, in the second year I can specialise in Data Analytics. \n\nHowever I would like to have more insight on a day in the life of a Data Scientist/ Data Analyst. \n\nAnd would you also recommend it to a current student?\n\nThank you in advance for your contributions!", "author_fullname": "t2_fson3ve4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientists/Analysts in Financial Institutions, How is your day in the life?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oa3sd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691763303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In September I will start my 2 year Masters in Finance, in the second year I can specialise in Data Analytics. &lt;/p&gt;\n\n&lt;p&gt;However I would like to have more insight on a day in the life of a Data Scientist/ Data Analyst. &lt;/p&gt;\n\n&lt;p&gt;And would you also recommend it to a current student?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your contributions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oa3sd", "is_robot_indexable": true, "report_reasons": null, "author": "DapperLifeStyle", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oa3sd/data_scientistsanalysts_in_financial_institutions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oa3sd/data_scientistsanalysts_in_financial_institutions/", "subreddit_subscribers": 983228, "created_utc": 1691763303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to solve a specific problem and will use it to articulate a more general concept. I am trying to predict horse races (i.e. which horse will win.) Let's say that for each race, I have 140 features - 10 features for each of the maximum 14 running horses. In my dataset, half the races only have 7 runners. Therefore, for half the datapoints/races, at least half of the features are \"empty\". I choose the word \"empty\" because it is not that the data is \"missing\" due to, for example, an issue with data extraction.\n\nFor context, I am currently using an XGBoost model. Is this a common problem? Are there any best practices? Or, am I phrasing the problem poorly? Maybe I should train a model that predicts whether each horse will win independently? I'd appreciate some advise on how to reframe the problem/solve \"empty\" data. Cheers", "author_fullname": "t2_xfx8ms4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle empty, not missing, features", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oxs5q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691824776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to solve a specific problem and will use it to articulate a more general concept. I am trying to predict horse races (i.e. which horse will win.) Let&amp;#39;s say that for each race, I have 140 features - 10 features for each of the maximum 14 running horses. In my dataset, half the races only have 7 runners. Therefore, for half the datapoints/races, at least half of the features are &amp;quot;empty&amp;quot;. I choose the word &amp;quot;empty&amp;quot; because it is not that the data is &amp;quot;missing&amp;quot; due to, for example, an issue with data extraction.&lt;/p&gt;\n\n&lt;p&gt;For context, I am currently using an XGBoost model. Is this a common problem? Are there any best practices? Or, am I phrasing the problem poorly? Maybe I should train a model that predicts whether each horse will win independently? I&amp;#39;d appreciate some advise on how to reframe the problem/solve &amp;quot;empty&amp;quot; data. Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oxs5q", "is_robot_indexable": true, "report_reasons": null, "author": "HStuart18", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oxs5q/how_to_handle_empty_not_missing_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oxs5q/how_to_handle_empty_not_missing_features/", "subreddit_subscribers": 983228, "created_utc": 1691824776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am completing an internship at a small Fintech company and I have received an offer for a junior data scientist position. On the other hand there's an offer from a big 4 Company for a trainee role. I have really enjoyed my internship and I have learnt a lot. The Big 4  salary offer is slightly higher than the startup's. Is it worth leaving the startup for a Big 4 role? ( The problem with the Fintech company is that it is very hard to grow into senior roles as the current juniors have been telling me)", "author_fullname": "t2_atkfvp00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fintech company or Big 4 Offer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oxg7e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691823642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am completing an internship at a small Fintech company and I have received an offer for a junior data scientist position. On the other hand there&amp;#39;s an offer from a big 4 Company for a trainee role. I have really enjoyed my internship and I have learnt a lot. The Big 4  salary offer is slightly higher than the startup&amp;#39;s. Is it worth leaving the startup for a Big 4 role? ( The problem with the Fintech company is that it is very hard to grow into senior roles as the current juniors have been telling me)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oxg7e", "is_robot_indexable": true, "report_reasons": null, "author": "LogicalBenefit7410", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oxg7e/fintech_company_or_big_4_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oxg7e/fintech_company_or_big_4_offer/", "subreddit_subscribers": 983228, "created_utc": 1691823642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I often read complaints here from some people who are disappointed to find out that most if not all of their data science work is just \u201cSQL monkey\u201d work, or that the higher ups never actually listen to the conclusions drawn from data. \n\nSo I was wondering what big companies actually value data science or deliver data science as their product?\n\nI\u2019ve heard Google, Amazon, and Walmart value their data science teams.", "author_fullname": "t2_2ghr4f2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Examples of actual data-driven companies/companies that value data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15od4vd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691770478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I often read complaints here from some people who are disappointed to find out that most if not all of their data science work is just \u201cSQL monkey\u201d work, or that the higher ups never actually listen to the conclusions drawn from data. &lt;/p&gt;\n\n&lt;p&gt;So I was wondering what big companies actually value data science or deliver data science as their product?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve heard Google, Amazon, and Walmart value their data science teams.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15od4vd", "is_robot_indexable": true, "report_reasons": null, "author": "X-Gun-Z", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15od4vd/examples_of_actual_datadriven_companiescompanies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15od4vd/examples_of_actual_datadriven_companiescompanies/", "subreddit_subscribers": 983228, "created_utc": 1691770478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm 31 years old, pursuing a BSDS I should complete in a year, but the more I look at jobs and duties the more I accept its not really what I want to do. I really would have liked to complete a degree in Mech Eng but it would take me 3 years as opposed one for data science. I wish I had known the field of study I wanted to major in was ME but I suppose thats water under the bridge now. To be honest, my talents/strengths lay in design/arts/taIent management. Im technically inclined, but im fooling myself to think I would be happy coding or something. I have a billion dollar idea that I trademarked but I dont have the capital to really get it off the ground. Im pretty smart but when it comes to real-world decision making, Im not very bright...so what do you all think, should I just work hella hard and raiss the money myself or should I pursue an internship/job in a field I know I don't want to do?", "author_fullname": "t2_cpnrlgmy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Should I Do", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15p21z0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691839300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m 31 years old, pursuing a BSDS I should complete in a year, but the more I look at jobs and duties the more I accept its not really what I want to do. I really would have liked to complete a degree in Mech Eng but it would take me 3 years as opposed one for data science. I wish I had known the field of study I wanted to major in was ME but I suppose thats water under the bridge now. To be honest, my talents/strengths lay in design/arts/taIent management. Im technically inclined, but im fooling myself to think I would be happy coding or something. I have a billion dollar idea that I trademarked but I dont have the capital to really get it off the ground. Im pretty smart but when it comes to real-world decision making, Im not very bright...so what do you all think, should I just work hella hard and raiss the money myself or should I pursue an internship/job in a field I know I don&amp;#39;t want to do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p21z0", "is_robot_indexable": true, "report_reasons": null, "author": "saheedallen1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p21z0/what_should_i_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p21z0/what_should_i_do/", "subreddit_subscribers": 983228, "created_utc": 1691839300.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CIA, I Need Your Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15p1qiv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_hfk5h0fn1", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "personalfinance", "selftext": "[removed]", "author_fullname": "t2_hfk5h0fn1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CIA, I Need Your Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/personalfinance", "hidden": false, "pwls": 6, "link_flair_css_class": "r1", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15p1pv8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": "", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "R1: Submission guidelines", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691838254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": "moderator", "banned_by": null, "author_flair_type": "text", "domain": "self.personalfinance", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3234d726-3c04-11eb-bd09-0e8ac0a2168f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "\u200b", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qstm", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#bb1111", "id": "15p1pv8", "is_robot_indexable": false, "report_reasons": null, "author": "CIA44", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/personalfinance/comments/15p1pv8/cia_i_need_your_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/personalfinance/comments/15p1pv8/cia_i_need_your_help/", "subreddit_subscribers": 18016382, "created_utc": 1691838254.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1691838314.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.personalfinance", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/personalfinance/comments/15p1pv8/cia_i_need_your_help/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p1qiv", "is_robot_indexable": true, "report_reasons": null, "author": "CIA44", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_15p1pv8", "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p1qiv/cia_i_need_your_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/personalfinance/comments/15p1pv8/cia_i_need_your_help/", "subreddit_subscribers": 983228, "created_utc": 1691838314.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the past, I have always encountered problems when data from one source doesn't match data from another. And for me, the solution was data integration. So i want to share with you some data integration strategies that helped my company.\n\n&amp;#x200B;\n\n**ETL (Extract, Transform, Load):** ETL is the backbone of many integration projects. It involves pulling data, reshaping it to fit, and storing it in its new home, usually a data warehouse. The best part? ETL automates the nitty-gritty, ensuring consistency and paving the way for better decision-making.\n\n&amp;#x200B;\n\n**ELT (Extract, Load, Transform):** If ETL is the backbone, ELT is the muscle for handling bulky data sets. It's about collecting data, moving it directly to its target, and making tweaks there. I love it for its agility, especially when dealing with vast amounts of data in real time.\n\n&amp;#x200B;\n\n**Change Data Capture (CDC):** Picture CDC as the ever-watchful sentinel, tracking database changes. It keeps an eye out for alterations, documents them, and ensures they reach where they need to. Its edge? Near real-time data integration, light touch on source systems, and a knack for preserving data history.\n\n&amp;#x200B;\n\n**A Nod to Data Replication**\n\nWith data replication, it's about redundancy for safety. You create backup copies of your data, ensuring continuous access and faster decision-making. Plus, distributing data means potential data losses are a thing of the past.\n\n&amp;#x200B;\n\n**The Magic of Data Virtualization**\n\nHere's a fun one: What if you didn't need a new repository for all your data sources? Data virtualization virtually combines data for a unified view. It offers real-time access and is a cost-effective alternative to traditional storage. From my experience, it also greatly improves data quality and reliability.\n\n&amp;#x200B;\n\nIn my journey, I've learned the importance of handpicking the right tools for the job. They need to gel with your data sources, scale with your needs, and offer efficient infrastructure. \n\nIf you want to dive deeper in topics like this, check out my blog: [https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm\\_source=linkedin&amp;utm\\_medium=social&amp;utm\\_campaign=hfs\\_research&amp;utm\\_content=integration\\_strategy&amp;utm\\_term=socialmedia](https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm_source=linkedin&amp;utm_medium=social&amp;utm_campaign=hfs_research&amp;utm_content=integration_strategy&amp;utm_term=socialmedia) \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_ct09rz3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data integration strategies that work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15p1fs4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691837350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the past, I have always encountered problems when data from one source doesn&amp;#39;t match data from another. And for me, the solution was data integration. So i want to share with you some data integration strategies that helped my company.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;ETL (Extract, Transform, Load):&lt;/strong&gt; ETL is the backbone of many integration projects. It involves pulling data, reshaping it to fit, and storing it in its new home, usually a data warehouse. The best part? ETL automates the nitty-gritty, ensuring consistency and paving the way for better decision-making.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;ELT (Extract, Load, Transform):&lt;/strong&gt; If ETL is the backbone, ELT is the muscle for handling bulky data sets. It&amp;#39;s about collecting data, moving it directly to its target, and making tweaks there. I love it for its agility, especially when dealing with vast amounts of data in real time.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Change Data Capture (CDC):&lt;/strong&gt; Picture CDC as the ever-watchful sentinel, tracking database changes. It keeps an eye out for alterations, documents them, and ensures they reach where they need to. Its edge? Near real-time data integration, light touch on source systems, and a knack for preserving data history.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;A Nod to Data Replication&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;With data replication, it&amp;#39;s about redundancy for safety. You create backup copies of your data, ensuring continuous access and faster decision-making. Plus, distributing data means potential data losses are a thing of the past.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Magic of Data Virtualization&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a fun one: What if you didn&amp;#39;t need a new repository for all your data sources? Data virtualization virtually combines data for a unified view. It offers real-time access and is a cost-effective alternative to traditional storage. From my experience, it also greatly improves data quality and reliability.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In my journey, I&amp;#39;ve learned the importance of handpicking the right tools for the job. They need to gel with your data sources, scale with your needs, and offer efficient infrastructure. &lt;/p&gt;\n\n&lt;p&gt;If you want to dive deeper in topics like this, check out my blog: &lt;a href=\"https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=hfs_research&amp;amp;utm_content=integration_strategy&amp;amp;utm_term=socialmedia\"&gt;https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=hfs_research&amp;amp;utm_content=integration_strategy&amp;amp;utm_term=socialmedia&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I3xJj8ELsQOmy2H-NeHKFmGnh2tKVfHX1i7SJ1O1qwE.jpg?auto=webp&amp;s=8a29f85fd320507a70ec9694b971f494352d2655", "width": 79, "height": 86}, "resolutions": [], "variants": {}, "id": "fKkAw45B6Aa1K9gfC0CvmXNzCjb0F-J2wvKUvaKf1Vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p1fs4", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Speech36", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p1fs4/data_integration_strategies_that_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p1fs4/data_integration_strategies_that_work/", "subreddit_subscribers": 983228, "created_utc": 1691837350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been diving deep into the realm of data labeling solutions for enterprise contexts, specifically focusing on SageMaker Data Labeling (including Ground Truth and Ground Truth Plus) and V7 Labs.   \nWhether you've found success, faced challenges, or discovered unique features in either solution, I'm eager to tap into the collective expertise of this community and glean insights from those who possess hands-on experience with either of these platforms.\n\nI'm particularly interested in hearing y'all's opinions on the following aspects:\n\n1. **Ease of Use**: How user-friendly are these platforms? Was one more intuitive than the other?\n2. **Labeling Quality**: What about the quality of labels generated by SageMaker vs. V7 Labs? Any notable differences?\n3. **Customization and Flexibility**: Which platform offers better options for tailoring the labeling process to your specific needs?\n4. **Scalability**: How well did these solutions scale as labeling demands increased?\n5. **Integration and Compatibility**: How seamlessly do SageMaker and V7 Labs integrate with your existing data science workflows and tools?\n6. **Cost Considerations**: Were there significant differences in pricing structures or overall cost-effectiveness between the two?\n7. **Documentation Quality**: Any thoughts on the comprehensiveness and effectiveness of documentation provided by both SageMaker and V7 Labs?\n8. **Unique Capabilities**: What distinct functionalities set SageMaker and V7 Labs apart? Are there specific tasks that one platform excels at that the other might struggle with?\n\nPlease feel free to share experiences, anecdotes, or any insights you believe could contribute to this comparison. I feel this community's unique insights and perspectives can provide invaluable guidance in shaping a well-rounded perspective.", "author_fullname": "t2_chp44bhd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Comparison of SageMaker Data Labeling and V7 Labs for Enterprise Labeling Solutions - Seeking Insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ou2g0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691812564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been diving deep into the realm of data labeling solutions for enterprise contexts, specifically focusing on SageMaker Data Labeling (including Ground Truth and Ground Truth Plus) and V7 Labs.&lt;br/&gt;\nWhether you&amp;#39;ve found success, faced challenges, or discovered unique features in either solution, I&amp;#39;m eager to tap into the collective expertise of this community and glean insights from those who possess hands-on experience with either of these platforms.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m particularly interested in hearing y&amp;#39;all&amp;#39;s opinions on the following aspects:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Ease of Use&lt;/strong&gt;: How user-friendly are these platforms? Was one more intuitive than the other?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Labeling Quality&lt;/strong&gt;: What about the quality of labels generated by SageMaker vs. V7 Labs? Any notable differences?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Customization and Flexibility&lt;/strong&gt;: Which platform offers better options for tailoring the labeling process to your specific needs?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: How well did these solutions scale as labeling demands increased?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Integration and Compatibility&lt;/strong&gt;: How seamlessly do SageMaker and V7 Labs integrate with your existing data science workflows and tools?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Cost Considerations&lt;/strong&gt;: Were there significant differences in pricing structures or overall cost-effectiveness between the two?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Documentation Quality&lt;/strong&gt;: Any thoughts on the comprehensiveness and effectiveness of documentation provided by both SageMaker and V7 Labs?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Unique Capabilities&lt;/strong&gt;: What distinct functionalities set SageMaker and V7 Labs apart? Are there specific tasks that one platform excels at that the other might struggle with?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Please feel free to share experiences, anecdotes, or any insights you believe could contribute to this comparison. I feel this community&amp;#39;s unique insights and perspectives can provide invaluable guidance in shaping a well-rounded perspective.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ou2g0", "is_robot_indexable": true, "report_reasons": null, "author": "fizix00", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ou2g0/a_comparison_of_sagemaker_data_labeling_and_v7/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ou2g0/a_comparison_of_sagemaker_data_labeling_and_v7/", "subreddit_subscribers": 983228, "created_utc": 1691812564.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Most of the data science job descriptions require a Bachelors/Masters in Economics, Operations, Statistics, CS, Engineering. \n\nDo interviews test us on DSA, or will programming and data manipulation in SQL and Python suffice? \n\nThanks!", "author_fullname": "t2_muzoa5tk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Structures &amp; Algorithms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ompqy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691792557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of the data science job descriptions require a Bachelors/Masters in Economics, Operations, Statistics, CS, Engineering. &lt;/p&gt;\n\n&lt;p&gt;Do interviews test us on DSA, or will programming and data manipulation in SQL and Python suffice? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ompqy", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate-Box-7", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ompqy/data_structures_algorithms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ompqy/data_structures_algorithms/", "subreddit_subscribers": 983228, "created_utc": 1691792557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Community!\n\nI'm working in a complex (I believe so) data science project.\n\nIt is a multioutput regression problem, but we have a limited amount of data, and high dimensionality:\n\n**70 records, 300 predictors, and at least 45 dependent variables.**\n\n&amp;#x200B;\n\nAny advise regarding the approach?\n\n&amp;#x200B;\n\nThanks", "author_fullname": "t2_ejy2ermj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High Dimensionality Multi-output regression Probelm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oirop", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691783509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Community!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working in a complex (I believe so) data science project.&lt;/p&gt;\n\n&lt;p&gt;It is a multioutput regression problem, but we have a limited amount of data, and high dimensionality:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;70 records, 300 predictors, and at least 45 dependent variables.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any advise regarding the approach?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oirop", "is_robot_indexable": true, "report_reasons": null, "author": "InterestingDiver1584", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oirop/high_dimensionality_multioutput_regression_probelm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oirop/high_dimensionality_multioutput_regression_probelm/", "subreddit_subscribers": 983228, "created_utc": 1691783509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "And another question, what are the best data science companies or companies that have a great data science department in the middle east. Thanks.", "author_fullname": "t2_b9udmqrg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best courses that i can benefit from as a data dcience major (im a 2nd year student)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oi516", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691782035.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;And another question, what are the best data science companies or companies that have a great data science department in the middle east. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oi516", "is_robot_indexable": true, "report_reasons": null, "author": "Fun_Hurry_968", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oi516/what_are_the_best_courses_that_i_can_benefit_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oi516/what_are_the_best_courses_that_i_can_benefit_from/", "subreddit_subscribers": 983228, "created_utc": 1691782035.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "my organization gives us $500 to spend on professional development days. i am looking to shift from data analytics to data science. Can anyone recommend courses or books for the same? I already have a udemy membership.", "author_fullname": "t2_3cn6ylzl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Books/Courses Recommendation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oi1s2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691781827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;my organization gives us $500 to spend on professional development days. i am looking to shift from data analytics to data science. Can anyone recommend courses or books for the same? I already have a udemy membership.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oi1s2", "is_robot_indexable": true, "report_reasons": null, "author": "Awkward_Sign_1191", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oi1s2/bookscourses_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oi1s2/bookscourses_recommendation/", "subreddit_subscribers": 983228, "created_utc": 1691781827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I've been working on an app that enables Snowflake users to query live data from their google sheets.\n\nBasically this:\n\n    select *    \n    from table(snowsheets.functions.sheet(      \n      '1tlySRbYD8nqx5_9QJ...',\n      'Sheet1',\n      'A1:C6'\n    ));\n\n[https://www.snowsheets.app](https://www.snowsheets.app/)\n\nWould anyone be interested in joining a beta test for the app? If you'd like to try it out I'd be happy to share some usage credits in exchange.\n\nThe app is also technically up and running and you can sign up and test it out, although I'm waiting on Google to approve the OAuth setup in order to remove the scary warning text when signing up. There's a short demo video on the site as well (sorry for my bad mic, I'll work on the video quality soon.)\n\nI built the app because I felt it could be useful to enable analysts to load and iterate on small \"seed\" data files when they're using Snowflake, without needing to go through the more complex loading processes I've seen at most companies. The trade-off of course is there's no governance around the content of these sheets, so I wouldn't use this tool as part of any mission critical pipelines.\n\nIf you have any feedback / thoughts about the app as well, would be happy to hear them!", "author_fullname": "t2_h80cpvbds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for beta testers for a \"micro saas\" - query live Google Sheets data from inside Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15of8zy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691775405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;ve been working on an app that enables Snowflake users to query live data from their google sheets.&lt;/p&gt;\n\n&lt;p&gt;Basically this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;select *    \nfrom table(snowsheets.functions.sheet(      \n  &amp;#39;1tlySRbYD8nqx5_9QJ...&amp;#39;,\n  &amp;#39;Sheet1&amp;#39;,\n  &amp;#39;A1:C6&amp;#39;\n));\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.snowsheets.app/\"&gt;https://www.snowsheets.app&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Would anyone be interested in joining a beta test for the app? If you&amp;#39;d like to try it out I&amp;#39;d be happy to share some usage credits in exchange.&lt;/p&gt;\n\n&lt;p&gt;The app is also technically up and running and you can sign up and test it out, although I&amp;#39;m waiting on Google to approve the OAuth setup in order to remove the scary warning text when signing up. There&amp;#39;s a short demo video on the site as well (sorry for my bad mic, I&amp;#39;ll work on the video quality soon.)&lt;/p&gt;\n\n&lt;p&gt;I built the app because I felt it could be useful to enable analysts to load and iterate on small &amp;quot;seed&amp;quot; data files when they&amp;#39;re using Snowflake, without needing to go through the more complex loading processes I&amp;#39;ve seen at most companies. The trade-off of course is there&amp;#39;s no governance around the content of these sheets, so I wouldn&amp;#39;t use this tool as part of any mission critical pipelines.&lt;/p&gt;\n\n&lt;p&gt;If you have any feedback / thoughts about the app as well, would be happy to hear them!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15of8zy", "is_robot_indexable": true, "report_reasons": null, "author": "johnbarnettt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15of8zy/looking_for_beta_testers_for_a_micro_saas_query/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15of8zy/looking_for_beta_testers_for_a_micro_saas_query/", "subreddit_subscribers": 983228, "created_utc": 1691775405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a research assistant and lately I've been processing and analyzing resting state fMRI data. Essentially, this means that I process and analyze a multivariate time-series dataset. This has involved researching and implementing methods for clustering them into repeating graphs and methods for processing them into a time series of successive of graphs. I then analyze the topology of those graphs to learn how they evolve over time as well as the topology of any transition matrices I can glean from the dataset when it is clustered. With this, I have learned how groups within my dataset differ. \n\nRecently, it occurred to me that the skills and know-how I developed for this project may be transferable to other fields that involve multivariate time-series datasets. Is this true? If so, what are some fields I could look into (beyond neuroscience) that involve this kind of dataset and would be friendly to my approach. \n\nI'm strapped for cash right now (research assistants get paid poverty wages), so I'm definitely curious about what's out there. ", "author_fullname": "t2_2ve4vyvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a market for graph theory processing and analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15od0tz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691770213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a research assistant and lately I&amp;#39;ve been processing and analyzing resting state fMRI data. Essentially, this means that I process and analyze a multivariate time-series dataset. This has involved researching and implementing methods for clustering them into repeating graphs and methods for processing them into a time series of successive of graphs. I then analyze the topology of those graphs to learn how they evolve over time as well as the topology of any transition matrices I can glean from the dataset when it is clustered. With this, I have learned how groups within my dataset differ. &lt;/p&gt;\n\n&lt;p&gt;Recently, it occurred to me that the skills and know-how I developed for this project may be transferable to other fields that involve multivariate time-series datasets. Is this true? If so, what are some fields I could look into (beyond neuroscience) that involve this kind of dataset and would be friendly to my approach. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m strapped for cash right now (research assistants get paid poverty wages), so I&amp;#39;m definitely curious about what&amp;#39;s out there. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15od0tz", "is_robot_indexable": true, "report_reasons": null, "author": "statius9", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15od0tz/is_there_a_market_for_graph_theory_processing_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15od0tz/is_there_a_market_for_graph_theory_processing_and/", "subreddit_subscribers": 983228, "created_utc": 1691770213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have run 10 object detection models including yolov8 but the AP values I get are in range of 0 to 1 which makes sense. But in the paper it mentions mAP with the values of 80 and 90. \nWhy is it so high? mAP is just the average so how did it go from decimals to tens place?", "author_fullname": "t2_ktkqp3a2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Average Precision", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15obuuv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691767437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have run 10 object detection models including yolov8 but the AP values I get are in range of 0 to 1 which makes sense. But in the paper it mentions mAP with the values of 80 and 90. \nWhy is it so high? mAP is just the average so how did it go from decimals to tens place?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15obuuv", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Bluebird9777", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15obuuv/average_precision/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15obuuv/average_precision/", "subreddit_subscribers": 983228, "created_utc": 1691767437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'll like to study Data science in canada for masters degree. Can you please recommend school that has application open for Winter or Spring semester.", "author_fullname": "t2_uemqmje2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Canada university recommendations for masters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oauuy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691765125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll like to study Data science in canada for masters degree. Can you please recommend school that has application open for Winter or Spring semester.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oauuy", "is_robot_indexable": true, "report_reasons": null, "author": "Progbro1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oauuy/canada_university_recommendations_for_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oauuy/canada_university_recommendations_for_masters/", "subreddit_subscribers": 983228, "created_utc": 1691765125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9vyd42ki5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IBM Data Science Professional Certificate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15oz9cr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_vaK5g7pcJrKLB9b_LatzhX3U5dwHd65b6L3hMr48zg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691829852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "imp.i384100.net", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://imp.i384100.net/YgYndj", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?auto=webp&amp;s=4528d4dacf007db1a2853bd0c3fa928802c9f37d", "width": 1772, "height": 928}, "resolutions": [{"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8160986c0285b26bb24a19052dca847848f377af", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fdb17a1ffdad7333f5335b7ed49e85c1f3b29d20", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=02bdce13bb1899e2a547756d4cef7702e9b2480c", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c1af862b7681fad183a57ad9a4a007d3cfd16be2", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a6093d69e3e6907ce14b5a9003dd0115f046caab", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=847879f8efd9ab153056585563382e1a318316d7", "width": 1080, "height": 565}], "variants": {}, "id": "iM3wgjxKZ2QDakFEHPdOiRjj5__Tw2diEHESmNLA04E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oz9cr", "is_robot_indexable": true, "report_reasons": null, "author": "Farahhossam112", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oz9cr/ibm_data_science_professional_certificate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://imp.i384100.net/YgYndj", "subreddit_subscribers": 983228, "created_utc": 1691829852.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is there an app you know of that can look at a photograph of a bunch of data points sitting on an axis, and output their coordinates relative to the axes that they sit on?\n\nI set up a controlled study to see the impact my org's performing arts classes have on student mood and energy. Students will stick a magnet with their name on it onto a magnetized board with different high/low energy and positive/negative emotions. I'm collecting data from 3,500 students weekly for a year and would love to be able to track their individual changes in mood/energy over time in an automated way. \n\nI can add a unique identifier (QR code?) to each student's magnet to make it possible to track their data individually. \n\nThanks!", "author_fullname": "t2_vy4ye55w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mapping datapoints from a photograph", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15omwja", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691793005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there an app you know of that can look at a photograph of a bunch of data points sitting on an axis, and output their coordinates relative to the axes that they sit on?&lt;/p&gt;\n\n&lt;p&gt;I set up a controlled study to see the impact my org&amp;#39;s performing arts classes have on student mood and energy. Students will stick a magnet with their name on it onto a magnetized board with different high/low energy and positive/negative emotions. I&amp;#39;m collecting data from 3,500 students weekly for a year and would love to be able to track their individual changes in mood/energy over time in an automated way. &lt;/p&gt;\n\n&lt;p&gt;I can add a unique identifier (QR code?) to each student&amp;#39;s magnet to make it possible to track their data individually. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15omwja", "is_robot_indexable": true, "report_reasons": null, "author": "Illapatayta", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15omwja/mapping_datapoints_from_a_photograph/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15omwja/mapping_datapoints_from_a_photograph/", "subreddit_subscribers": 983228, "created_utc": 1691793005.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}