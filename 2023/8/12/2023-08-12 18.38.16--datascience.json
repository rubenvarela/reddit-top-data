{"kind": "Listing", "data": {"after": "t3_15opys7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "You won't be given any handouts. Data collection and research are mandatory basics for this role\n\nThis includes things as simple as -\n\n1) Google! Always Google first , no your dataset requirement for your college project isn't so unique that it's not on kaggle. \n\n\n2) read the subs rules - you're new here , sure, read the wiki/pinned thread to get an idea of the sub , do not make assumptions \n\n\n3) use the search functionality - there are very few topics that haven't been discussed. Some might be stale , sure. Link back to that posts findings and ask specific questions that weren't covered \n\n\n4) don't ask open ended questions with 0 background assuming everyone here knows what you know , things like, which model is good for me - ab or xy? I mean come on.\n\n\nThis is not a rant per se , but the culture of expecting people to solve your issues while you do 0 work is not gonna set you up well for a career. \n\nSpecific questions have a better chance of getting a response than a general open ended one .", "author_fullname": "t2_mloui", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Controversial opinion- If you want to be a data scientist, you should be able to do basic research", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ohmb0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 175, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 175, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691781868.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691780828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You won&amp;#39;t be given any handouts. Data collection and research are mandatory basics for this role&lt;/p&gt;\n\n&lt;p&gt;This includes things as simple as -&lt;/p&gt;\n\n&lt;p&gt;1) Google! Always Google first , no your dataset requirement for your college project isn&amp;#39;t so unique that it&amp;#39;s not on kaggle. &lt;/p&gt;\n\n&lt;p&gt;2) read the subs rules - you&amp;#39;re new here , sure, read the wiki/pinned thread to get an idea of the sub , do not make assumptions &lt;/p&gt;\n\n&lt;p&gt;3) use the search functionality - there are very few topics that haven&amp;#39;t been discussed. Some might be stale , sure. Link back to that posts findings and ask specific questions that weren&amp;#39;t covered &lt;/p&gt;\n\n&lt;p&gt;4) don&amp;#39;t ask open ended questions with 0 background assuming everyone here knows what you know , things like, which model is good for me - ab or xy? I mean come on.&lt;/p&gt;\n\n&lt;p&gt;This is not a rant per se , but the culture of expecting people to solve your issues while you do 0 work is not gonna set you up well for a career. &lt;/p&gt;\n\n&lt;p&gt;Specific questions have a better chance of getting a response than a general open ended one .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ohmb0", "is_robot_indexable": true, "report_reasons": null, "author": "Asshaisin", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ohmb0/controversial_opinion_if_you_want_to_be_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ohmb0/controversial_opinion_if_you_want_to_be_a_data/", "subreddit_subscribers": 983678, "created_utc": 1691780828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Everytime I am working on a dataset performing EDA and feature engineering I will turn my notebooks into a complete mess, save csvs multiple times, open new notebooks, go back and forth with my code, until it is something usable. \n\nLater than, I comeback organizing and documenting. Also making a pipeline with all the transformations I just made, and pickle my file GG EZ.\n\nSometimes I think this is unprofessional and I should be going with the pipeline approach first.\n\nWhat's is the data exploration process for you guys?", "author_fullname": "t2_67oqkl0p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this how other people also work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ohgr8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691780484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Everytime I am working on a dataset performing EDA and feature engineering I will turn my notebooks into a complete mess, save csvs multiple times, open new notebooks, go back and forth with my code, until it is something usable. &lt;/p&gt;\n\n&lt;p&gt;Later than, I comeback organizing and documenting. Also making a pipeline with all the transformations I just made, and pickle my file GG EZ.&lt;/p&gt;\n\n&lt;p&gt;Sometimes I think this is unprofessional and I should be going with the pipeline approach first.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s is the data exploration process for you guys?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ohgr8", "is_robot_indexable": true, "report_reasons": null, "author": "dick_veganas", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ohgr8/is_this_how_other_people_also_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ohgr8/is_this_how_other_people_also_work/", "subreddit_subscribers": 983678, "created_utc": 1691780484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "On LinkedIn I always see 100+ applicants for each position. Is this because the field is over saturated or is there is not much hiring right now? Are DS jobs normally that competitive to get?", "author_fullname": "t2_2sf6re48", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data science/data engineering over saturated?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p8n46", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691857001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On LinkedIn I always see 100+ applicants for each position. Is this because the field is over saturated or is there is not much hiring right now? Are DS jobs normally that competitive to get?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p8n46", "is_robot_indexable": true, "report_reasons": null, "author": "unluckyowl4", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p8n46/is_data_sciencedata_engineering_over_saturated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p8n46/is_data_sciencedata_engineering_over_saturated/", "subreddit_subscribers": 983678, "created_utc": 1691857001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to solve a specific problem and will use it to articulate a more general concept. I am trying to predict horse races (i.e. which horse will win.) Let's say that for each race, I have 140 features - 10 features for each of the maximum 14 running horses. In my dataset, half the races only have 7 runners. Therefore, for half the datapoints/races, at least half of the features are \"empty\". I choose the word \"empty\" because it is not that the data is \"missing\" due to, for example, an issue with data extraction.\n\nFor context, I am currently using an XGBoost model. Is this a common problem? Are there any best practices? Or, am I phrasing the problem poorly? Maybe I should train a model that predicts whether each horse will win independently? I'd appreciate some advise on how to reframe the problem/solve \"empty\" data. Cheers", "author_fullname": "t2_xfx8ms4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle empty, not missing, features", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oxs5q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691824776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to solve a specific problem and will use it to articulate a more general concept. I am trying to predict horse races (i.e. which horse will win.) Let&amp;#39;s say that for each race, I have 140 features - 10 features for each of the maximum 14 running horses. In my dataset, half the races only have 7 runners. Therefore, for half the datapoints/races, at least half of the features are &amp;quot;empty&amp;quot;. I choose the word &amp;quot;empty&amp;quot; because it is not that the data is &amp;quot;missing&amp;quot; due to, for example, an issue with data extraction.&lt;/p&gt;\n\n&lt;p&gt;For context, I am currently using an XGBoost model. Is this a common problem? Are there any best practices? Or, am I phrasing the problem poorly? Maybe I should train a model that predicts whether each horse will win independently? I&amp;#39;d appreciate some advise on how to reframe the problem/solve &amp;quot;empty&amp;quot; data. Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oxs5q", "is_robot_indexable": true, "report_reasons": null, "author": "HStuart18", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oxs5q/how_to_handle_empty_not_missing_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oxs5q/how_to_handle_empty_not_missing_features/", "subreddit_subscribers": 983678, "created_utc": 1691824776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi could anyone guide me in the right direction for my project. I have just over a month to get it done which would be perfectly fine but I'm very stuck and my supervisor is away and I couldn't get help on stack overflow. \n\nMy data is attached below. This is a sample, I have 66 players who have full data from 2015 to 2023. My intention was to use python to train a model to train with the player statistics from 2015-22, and predict 2023s points per minute and test against that. I have tried for a long time on python and got nowhere, is my task possible? Can someone point me in the right direction please? I am allowed to use any software or techniques. \n\nhttps://preview.redd.it/nua1pnsq1lhb1.png?width=2852&amp;format=png&amp;auto=webp&amp;s=ec26caf8078a29de79241ce74eb46ad2c6478704", "author_fullname": "t2_helqwmszk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NBA Player Data prediction help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "media_metadata": {"nua1pnsq1lhb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5f6a6f82cb504647f24802a38e182bf9f485da54"}, {"y": 103, "x": 216, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d83aa87130252968240ddc5246a1ce9a31dc2f3"}, {"y": 153, "x": 320, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9873e1d51992c0c16692ac32420e28748ca13b03"}, {"y": 306, "x": 640, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d501ec2dcbc9541d5c1bd750ea81fbec63bc94a2"}, {"y": 460, "x": 960, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=adb02ed48378b70c0a3337a5ef7143b91932aaf2"}, {"y": 517, "x": 1080, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1b1e747cc76ff35091a25198755375f592ceff91"}], "s": {"y": 1367, "x": 2852, "u": "https://preview.redd.it/nua1pnsq1lhb1.png?width=2852&amp;format=png&amp;auto=webp&amp;s=ec26caf8078a29de79241ce74eb46ad2c6478704"}, "id": "nua1pnsq1lhb1"}}, "name": "t3_15or8be", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vJV_w5OykkEASRkhcS_9UJ1GcqlqaB-n_MsfWciLP7Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691804198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi could anyone guide me in the right direction for my project. I have just over a month to get it done which would be perfectly fine but I&amp;#39;m very stuck and my supervisor is away and I couldn&amp;#39;t get help on stack overflow. &lt;/p&gt;\n\n&lt;p&gt;My data is attached below. This is a sample, I have 66 players who have full data from 2015 to 2023. My intention was to use python to train a model to train with the player statistics from 2015-22, and predict 2023s points per minute and test against that. I have tried for a long time on python and got nowhere, is my task possible? Can someone point me in the right direction please? I am allowed to use any software or techniques. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nua1pnsq1lhb1.png?width=2852&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec26caf8078a29de79241ce74eb46ad2c6478704\"&gt;https://preview.redd.it/nua1pnsq1lhb1.png?width=2852&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec26caf8078a29de79241ce74eb46ad2c6478704&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15or8be", "is_robot_indexable": true, "report_reasons": null, "author": "Tiny_Musician1844", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15or8be/nba_player_data_prediction_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15or8be/nba_player_data_prediction_help/", "subreddit_subscribers": 983678, "created_utc": 1691804198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been self-learning data science and ML for the past two years and have also worked on many portfolio projects. However, I have found myself stuck in a cycle of continuous learning. I understand that ML is a wide field and demands continuous learning for personal growth, but I think I should be learning by working hands-on in the field rather than being caught endlessly in this learning phase.\n\nI have now considered taking up freelance projects related to DS and ML to gain some hands-on experience. Despite this intention, I feel extremely overwhelmed and unconfident about whether or not I will be able to do the projects on my own. I want to kill this hesitation and start working. I am at a crossroads and would greatly appreciate some guidance from the community.", "author_fullname": "t2_6oagcr1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am stuck in a \"Learning\" loop (Seeking Guidance to Break Free)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15p9qng", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691860046.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691859789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been self-learning data science and ML for the past two years and have also worked on many portfolio projects. However, I have found myself stuck in a cycle of continuous learning. I understand that ML is a wide field and demands continuous learning for personal growth, but I think I should be learning by working hands-on in the field rather than being caught endlessly in this learning phase.&lt;/p&gt;\n\n&lt;p&gt;I have now considered taking up freelance projects related to DS and ML to gain some hands-on experience. Despite this intention, I feel extremely overwhelmed and unconfident about whether or not I will be able to do the projects on my own. I want to kill this hesitation and start working. I am at a crossroads and would greatly appreciate some guidance from the community.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p9qng", "is_robot_indexable": true, "report_reasons": null, "author": "hashirbhatti", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p9qng/i_am_stuck_in_a_learning_loop_seeking_guidance_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p9qng/i_am_stuck_in_a_learning_loop_seeking_guidance_to/", "subreddit_subscribers": 983678, "created_utc": 1691859789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As a data scientist I have worked on projects ranging from classic ml to computer vision.\nI always think as a DS or ML engineer we should also be aware about mlops tech stacks, best practices in model evaluation, deployment, monitoring and continual training. So I want to understand from folks who are working as DS , \nwhat is the most preferred tech stacks for MLops?\nAre companies using single cloud service providers like azure/aws for end to end developments or they prefer open-source mlops tools?", "author_fullname": "t2_ifsmh8cn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "mlops landscape in industry.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p4csj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691846142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a data scientist I have worked on projects ranging from classic ml to computer vision.\nI always think as a DS or ML engineer we should also be aware about mlops tech stacks, best practices in model evaluation, deployment, monitoring and continual training. So I want to understand from folks who are working as DS , \nwhat is the most preferred tech stacks for MLops?\nAre companies using single cloud service providers like azure/aws for end to end developments or they prefer open-source mlops tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p4csj", "is_robot_indexable": true, "report_reasons": null, "author": "Quest_to_peace", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p4csj/mlops_landscape_in_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p4csj/mlops_landscape_in_industry/", "subreddit_subscribers": 983678, "created_utc": 1691846142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working on a portfolio project to add to my website, and in the project I use some plotting functions from a haggle time series course. I am currently going back and adding comments and wonder if I should say where the code came from (ex: plotting code from Maggie time series course). Thanks!", "author_fullname": "t2_6nwrovjl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Credit borrowed code portfolio project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p7eaa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691853869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a portfolio project to add to my website, and in the project I use some plotting functions from a haggle time series course. I am currently going back and adding comments and wonder if I should say where the code came from (ex: plotting code from Maggie time series course). Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p7eaa", "is_robot_indexable": true, "report_reasons": null, "author": "Tedward-Roosevelt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p7eaa/credit_borrowed_code_portfolio_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p7eaa/credit_borrowed_code_portfolio_project/", "subreddit_subscribers": 983678, "created_utc": 1691853869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I have a newbie question on the process of time series forecasting in the real-world. Does one take a series of data point and curve fit some polynomial to it?\n\nWhat bothers me in reading the time series forecasting books is that the book do not consider cases where the underlying process changes. Also, the series on data points do not necessarily provide an understanding of the underlying generating process.", "author_fullname": "t2_95p57065", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Process of practical time series forecasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p90el", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691857924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have a newbie question on the process of time series forecasting in the real-world. Does one take a series of data point and curve fit some polynomial to it?&lt;/p&gt;\n\n&lt;p&gt;What bothers me in reading the time series forecasting books is that the book do not consider cases where the underlying process changes. Also, the series on data points do not necessarily provide an understanding of the underlying generating process.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p90el", "is_robot_indexable": true, "report_reasons": null, "author": "SqueezDeezNutz69", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p90el/process_of_practical_time_series_forecasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p90el/process_of_practical_time_series_forecasting/", "subreddit_subscribers": 983678, "created_utc": 1691857924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am completing an internship at a small Fintech company and I have received an offer for a junior data scientist position. On the other hand there's an offer from a big 4 Company for a trainee role. I have really enjoyed my internship and I have learnt a lot. The Big 4  salary offer is slightly higher than the startup's. Is it worth leaving the startup for a Big 4 role? ( The problem with the Fintech company is that it is very hard to grow into senior roles as the current juniors have been telling me)", "author_fullname": "t2_atkfvp00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fintech company or Big 4 Offer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oxg7e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691823642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am completing an internship at a small Fintech company and I have received an offer for a junior data scientist position. On the other hand there&amp;#39;s an offer from a big 4 Company for a trainee role. I have really enjoyed my internship and I have learnt a lot. The Big 4  salary offer is slightly higher than the startup&amp;#39;s. Is it worth leaving the startup for a Big 4 role? ( The problem with the Fintech company is that it is very hard to grow into senior roles as the current juniors have been telling me)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oxg7e", "is_robot_indexable": true, "report_reasons": null, "author": "LogicalBenefit7410", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oxg7e/fintech_company_or_big_4_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oxg7e/fintech_company_or_big_4_offer/", "subreddit_subscribers": 983678, "created_utc": 1691823642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been diving deep into the realm of data labeling solutions for enterprise contexts, specifically focusing on SageMaker Data Labeling (including Ground Truth and Ground Truth Plus) and V7 Labs.   \nWhether you've found success, faced challenges, or discovered unique features in either solution, I'm eager to tap into the collective expertise of this community and glean insights from those who possess hands-on experience with either of these platforms.\n\nI'm particularly interested in hearing y'all's opinions on the following aspects:\n\n1. **Ease of Use**: How user-friendly are these platforms? Was one more intuitive than the other?\n2. **Labeling Quality**: What about the quality of labels generated by SageMaker vs. V7 Labs? Any notable differences?\n3. **Customization and Flexibility**: Which platform offers better options for tailoring the labeling process to your specific needs?\n4. **Scalability**: How well did these solutions scale as labeling demands increased?\n5. **Integration and Compatibility**: How seamlessly do SageMaker and V7 Labs integrate with your existing data science workflows and tools?\n6. **Cost Considerations**: Were there significant differences in pricing structures or overall cost-effectiveness between the two?\n7. **Documentation Quality**: Any thoughts on the comprehensiveness and effectiveness of documentation provided by both SageMaker and V7 Labs?\n8. **Unique Capabilities**: What distinct functionalities set SageMaker and V7 Labs apart? Are there specific tasks that one platform excels at that the other might struggle with?\n\nPlease feel free to share experiences, anecdotes, or any insights you believe could contribute to this comparison. I feel this community's unique insights and perspectives can provide invaluable guidance in shaping a well-rounded perspective.", "author_fullname": "t2_chp44bhd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Comparison of SageMaker Data Labeling and V7 Labs for Enterprise Labeling Solutions - Seeking Insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ou2g0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691812564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been diving deep into the realm of data labeling solutions for enterprise contexts, specifically focusing on SageMaker Data Labeling (including Ground Truth and Ground Truth Plus) and V7 Labs.&lt;br/&gt;\nWhether you&amp;#39;ve found success, faced challenges, or discovered unique features in either solution, I&amp;#39;m eager to tap into the collective expertise of this community and glean insights from those who possess hands-on experience with either of these platforms.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m particularly interested in hearing y&amp;#39;all&amp;#39;s opinions on the following aspects:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Ease of Use&lt;/strong&gt;: How user-friendly are these platforms? Was one more intuitive than the other?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Labeling Quality&lt;/strong&gt;: What about the quality of labels generated by SageMaker vs. V7 Labs? Any notable differences?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Customization and Flexibility&lt;/strong&gt;: Which platform offers better options for tailoring the labeling process to your specific needs?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: How well did these solutions scale as labeling demands increased?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Integration and Compatibility&lt;/strong&gt;: How seamlessly do SageMaker and V7 Labs integrate with your existing data science workflows and tools?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Cost Considerations&lt;/strong&gt;: Were there significant differences in pricing structures or overall cost-effectiveness between the two?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Documentation Quality&lt;/strong&gt;: Any thoughts on the comprehensiveness and effectiveness of documentation provided by both SageMaker and V7 Labs?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Unique Capabilities&lt;/strong&gt;: What distinct functionalities set SageMaker and V7 Labs apart? Are there specific tasks that one platform excels at that the other might struggle with?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Please feel free to share experiences, anecdotes, or any insights you believe could contribute to this comparison. I feel this community&amp;#39;s unique insights and perspectives can provide invaluable guidance in shaping a well-rounded perspective.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ou2g0", "is_robot_indexable": true, "report_reasons": null, "author": "fizix00", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ou2g0/a_comparison_of_sagemaker_data_labeling_and_v7/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ou2g0/a_comparison_of_sagemaker_data_labeling_and_v7/", "subreddit_subscribers": 983678, "created_utc": 1691812564.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am facing quite a lot of anxiety about the DS field right now. I am a data scientist on paper, but for the past few years doing \u201cfull-stack\u201d ML developments. This means from building feature stores, predictive models, inference endpoints and retraining pipelines. \n\nOver the recent months I saw so many organizations expanding their DS teams with the intention of integrate AI into their products, seemingly solely out of hype from the business execs or investors. Many of these AI features don\u2019t seem to generate enough business value compared to the cost of building them. I\u2019m sure at one point the businesses will notice this too. Obviously I know not all of DS is ML, but a huge portion of the job demands out there have that expectation.\n\nAt the same time, this field is getting so damn saturated. 3 out of 5 people I met last week are persuing/has attained a masters in DS/ML. (Tbf it was a non-academic event at a university) I don\u2019t think I want to be here in a few years when we get 23 masters degree holders competing for one junior DS position.\n\nAll these could be just my anxiety speaking, so please correct me if I\u2019m mistaken about the current situation. However, my guts is telling me to make the jump to data engineering, which is the closest thing to what currently do, but my degree was in Stats and not CS. \n\nWhat is the best way to make this transition? Is there a middle ground between DS and DE which I can explore? Any book or article recommendations will greatly appreciated.", "author_fullname": "t2_2kh4l8ej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering as fallback once the LLM hype dies down?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15pb4rq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691863292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am facing quite a lot of anxiety about the DS field right now. I am a data scientist on paper, but for the past few years doing \u201cfull-stack\u201d ML developments. This means from building feature stores, predictive models, inference endpoints and retraining pipelines. &lt;/p&gt;\n\n&lt;p&gt;Over the recent months I saw so many organizations expanding their DS teams with the intention of integrate AI into their products, seemingly solely out of hype from the business execs or investors. Many of these AI features don\u2019t seem to generate enough business value compared to the cost of building them. I\u2019m sure at one point the businesses will notice this too. Obviously I know not all of DS is ML, but a huge portion of the job demands out there have that expectation.&lt;/p&gt;\n\n&lt;p&gt;At the same time, this field is getting so damn saturated. 3 out of 5 people I met last week are persuing/has attained a masters in DS/ML. (Tbf it was a non-academic event at a university) I don\u2019t think I want to be here in a few years when we get 23 masters degree holders competing for one junior DS position.&lt;/p&gt;\n\n&lt;p&gt;All these could be just my anxiety speaking, so please correct me if I\u2019m mistaken about the current situation. However, my guts is telling me to make the jump to data engineering, which is the closest thing to what currently do, but my degree was in Stats and not CS. &lt;/p&gt;\n\n&lt;p&gt;What is the best way to make this transition? Is there a middle ground between DS and DE which I can explore? Any book or article recommendations will greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15pb4rq", "is_robot_indexable": true, "report_reasons": null, "author": "supper_ham", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15pb4rq/data_engineering_as_fallback_once_the_llm_hype/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15pb4rq/data_engineering_as_fallback_once_the_llm_hype/", "subreddit_subscribers": 983678, "created_utc": 1691863292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So as a project and for practice I'm building a customer churn prediction model. I was getting very high results for my metrics, so I did some googling and realized I had allowed data leakage since I was doing data preprocessing before splitting the data into training and testing sets. So I went back and split my dataset first, then started binning and converting my categorical columns into numerical form, but only on the training set. But then I ran into another problem; the training dataset had undergone data preprocessing whereas the testing set hadn't, so after fitting the model and then attempting to use the sklearn predict method to evaluate the model via metrics, I ran into an error which basically told me that the training set and testing set did not have the same features.  However, I'm wary about preprocessing the testing set because it seems to me like that would be the same as what I was doing earlier. So, I wanted to ask, what's best in this situation? \n\nThanks.", "author_fullname": "t2_3yvdmdyj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this still count as overfitting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15pakn1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691861902.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So as a project and for practice I&amp;#39;m building a customer churn prediction model. I was getting very high results for my metrics, so I did some googling and realized I had allowed data leakage since I was doing data preprocessing before splitting the data into training and testing sets. So I went back and split my dataset first, then started binning and converting my categorical columns into numerical form, but only on the training set. But then I ran into another problem; the training dataset had undergone data preprocessing whereas the testing set hadn&amp;#39;t, so after fitting the model and then attempting to use the sklearn predict method to evaluate the model via metrics, I ran into an error which basically told me that the training set and testing set did not have the same features.  However, I&amp;#39;m wary about preprocessing the testing set because it seems to me like that would be the same as what I was doing earlier. So, I wanted to ask, what&amp;#39;s best in this situation? &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15pakn1", "is_robot_indexable": true, "report_reasons": null, "author": "aye_hus_that", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15pakn1/does_this_still_count_as_overfitting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15pakn1/does_this_still_count_as_overfitting/", "subreddit_subscribers": 983678, "created_utc": 1691861902.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Trivia question: what is your purpose in life? \n\nAnswer: \u2728creating shareholder value\u2728  You don't exist to enjoy life, your only purpose is to work, and outside of work hours you should be spending time and money to improve yourself for our benefit. \n\nThanks, \n\nManagement", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Friendly reminder: you only exist to create shareholder value!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15p9yr8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691860356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trivia question: what is your purpose in life? &lt;/p&gt;\n\n&lt;p&gt;Answer: \u2728creating shareholder value\u2728  You don&amp;#39;t exist to enjoy life, your only purpose is to work, and outside of work hours you should be spending time and money to improve yourself for our benefit. &lt;/p&gt;\n\n&lt;p&gt;Thanks, &lt;/p&gt;\n\n&lt;p&gt;Management&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p9yr8", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p9yr8/friendly_reminder_you_only_exist_to_create/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p9yr8/friendly_reminder_you_only_exist_to_create/", "subreddit_subscribers": 983678, "created_utc": 1691860356.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im working on a project and have been using chat gpt to generate larger and larger sections of code, especially since I don't understand a lot of the libraries Im using, or even the algorithems behind the code. I just want to get the project finished but at the same time I'd feel like a fraud if I didn't mention the code was not generated by me. What should I do? I'm using this project as portfolio piece to send alongside my CV for data analyst positions.\n\nIs there even any value to a project which:\n\n1. isn't demonstrating the true level of my skills\n2. isn't really helping me learn anything (perhaps only 10% python syntax and a broad overview of D.S algorithms )\n\nAlso I feel like this project has spiralled more into data science territory more than analysis, as I'm using NLP, Doc2Vec and things like that to do my analysis. So I feel like im venturing into deeply unknown territory and giving a false impression of my understanding.", "author_fullname": "t2_381zkha4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I used GPT to write my code: Should I mention it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p69sn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.52, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691851087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im working on a project and have been using chat gpt to generate larger and larger sections of code, especially since I don&amp;#39;t understand a lot of the libraries Im using, or even the algorithems behind the code. I just want to get the project finished but at the same time I&amp;#39;d feel like a fraud if I didn&amp;#39;t mention the code was not generated by me. What should I do? I&amp;#39;m using this project as portfolio piece to send alongside my CV for data analyst positions.&lt;/p&gt;\n\n&lt;p&gt;Is there even any value to a project which:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;isn&amp;#39;t demonstrating the true level of my skills&lt;/li&gt;\n&lt;li&gt;isn&amp;#39;t really helping me learn anything (perhaps only 10% python syntax and a broad overview of D.S algorithms )&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Also I feel like this project has spiralled more into data science territory more than analysis, as I&amp;#39;m using NLP, Doc2Vec and things like that to do my analysis. So I feel like im venturing into deeply unknown territory and giving a false impression of my understanding.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p69sn", "is_robot_indexable": true, "report_reasons": null, "author": "bigjungus11", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p69sn/i_used_gpt_to_write_my_code_should_i_mention_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p69sn/i_used_gpt_to_write_my_code_should_i_mention_it/", "subreddit_subscribers": 983678, "created_utc": 1691851087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Community!\n\nI'm working in a complex (I believe so) data science project.\n\nIt is a multioutput regression problem, but we have a limited amount of data, and high dimensionality:\n\n**70 records, 300 predictors, and at least 45 dependent variables.**\n\n&amp;#x200B;\n\nAny advise regarding the approach?\n\n&amp;#x200B;\n\nThanks", "author_fullname": "t2_ejy2ermj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High Dimensionality Multi-output regression Probelm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oirop", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691783509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Community!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working in a complex (I believe so) data science project.&lt;/p&gt;\n\n&lt;p&gt;It is a multioutput regression problem, but we have a limited amount of data, and high dimensionality:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;70 records, 300 predictors, and at least 45 dependent variables.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any advise regarding the approach?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oirop", "is_robot_indexable": true, "report_reasons": null, "author": "InterestingDiver1584", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oirop/high_dimensionality_multioutput_regression_probelm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oirop/high_dimensionality_multioutput_regression_probelm/", "subreddit_subscribers": 983678, "created_utc": 1691783509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm using Plotly in Jupyter Notebook and am looking to build some simple web apps to show data to others. Dash is supposedly a pretty simple and yet powerful way to present Plotly interactively on the web.\n\nI've read many threads and blogposts about the hosting aspect and I'm curious if some of you have experience hosting on your own server? I use the provider NordicWay which uses Cpanel. Is it possible to rather simply set up an environment, a bit similar to some pip installs on a local machine?\n\nIt might very well be that it's more of a hassle and therefore makes the most sense to use something like Heroku and only make the switch to ones own server if it becomes necessary down the line.", "author_fullname": "t2_fjvk5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting out with Dash apps - has anyone hosted Dash on their own server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15p96ld", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691858356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using Plotly in Jupyter Notebook and am looking to build some simple web apps to show data to others. Dash is supposedly a pretty simple and yet powerful way to present Plotly interactively on the web.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read many threads and blogposts about the hosting aspect and I&amp;#39;m curious if some of you have experience hosting on your own server? I use the provider NordicWay which uses Cpanel. Is it possible to rather simply set up an environment, a bit similar to some pip installs on a local machine?&lt;/p&gt;\n\n&lt;p&gt;It might very well be that it&amp;#39;s more of a hassle and therefore makes the most sense to use something like Heroku and only make the switch to ones own server if it becomes necessary down the line.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p96ld", "is_robot_indexable": true, "report_reasons": null, "author": "supertexter", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p96ld/starting_out_with_dash_apps_has_anyone_hosted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p96ld/starting_out_with_dash_apps_has_anyone_hosted/", "subreddit_subscribers": 983678, "created_utc": 1691858356.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9vyd42ki5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IBM Data Science Professional Certificate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15oz9cr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_vaK5g7pcJrKLB9b_LatzhX3U5dwHd65b6L3hMr48zg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691829852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "imp.i384100.net", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://imp.i384100.net/YgYndj", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?auto=webp&amp;s=4528d4dacf007db1a2853bd0c3fa928802c9f37d", "width": 1772, "height": 928}, "resolutions": [{"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8160986c0285b26bb24a19052dca847848f377af", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fdb17a1ffdad7333f5335b7ed49e85c1f3b29d20", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=02bdce13bb1899e2a547756d4cef7702e9b2480c", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c1af862b7681fad183a57ad9a4a007d3cfd16be2", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a6093d69e3e6907ce14b5a9003dd0115f046caab", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/ITw2l3jcUR5jT-xS1zIEzks-GkoeLB8643KmkfSdzIA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=847879f8efd9ab153056585563382e1a318316d7", "width": 1080, "height": 565}], "variants": {}, "id": "iM3wgjxKZ2QDakFEHPdOiRjj5__Tw2diEHESmNLA04E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oz9cr", "is_robot_indexable": true, "report_reasons": null, "author": "Farahhossam112", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oz9cr/ibm_data_science_professional_certificate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://imp.i384100.net/YgYndj", "subreddit_subscribers": 983678, "created_utc": 1691829852.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is there an app you know of that can look at a photograph of a bunch of data points sitting on an axis, and output their coordinates relative to the axes that they sit on?\n\nI set up a controlled study to see the impact my org's performing arts classes have on student mood and energy. Students will stick a magnet with their name on it onto a magnetized board with different high/low energy and positive/negative emotions. I'm collecting data from 3,500 students weekly for a year and would love to be able to track their individual changes in mood/energy over time in an automated way. \n\nI can add a unique identifier (QR code?) to each student's magnet to make it possible to track their data individually. \n\nThanks!", "author_fullname": "t2_vy4ye55w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mapping datapoints from a photograph", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15omwja", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691793005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there an app you know of that can look at a photograph of a bunch of data points sitting on an axis, and output their coordinates relative to the axes that they sit on?&lt;/p&gt;\n\n&lt;p&gt;I set up a controlled study to see the impact my org&amp;#39;s performing arts classes have on student mood and energy. Students will stick a magnet with their name on it onto a magnetized board with different high/low energy and positive/negative emotions. I&amp;#39;m collecting data from 3,500 students weekly for a year and would love to be able to track their individual changes in mood/energy over time in an automated way. &lt;/p&gt;\n\n&lt;p&gt;I can add a unique identifier (QR code?) to each student&amp;#39;s magnet to make it possible to track their data individually. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15omwja", "is_robot_indexable": true, "report_reasons": null, "author": "Illapatayta", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15omwja/mapping_datapoints_from_a_photograph/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15omwja/mapping_datapoints_from_a_photograph/", "subreddit_subscribers": 983678, "created_utc": 1691793005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Most of the data science job descriptions require a Bachelors/Masters in Economics, Operations, Statistics, CS, Engineering. \n\nDo interviews test us on DSA, or will programming and data manipulation in SQL and Python suffice? \n\nThanks!", "author_fullname": "t2_muzoa5tk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Structures &amp; Algorithms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ompqy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691792557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of the data science job descriptions require a Bachelors/Masters in Economics, Operations, Statistics, CS, Engineering. &lt;/p&gt;\n\n&lt;p&gt;Do interviews test us on DSA, or will programming and data manipulation in SQL and Python suffice? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ompqy", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate-Box-7", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ompqy/data_structures_algorithms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ompqy/data_structures_algorithms/", "subreddit_subscribers": 983678, "created_utc": 1691792557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "And another question, what are the best data science companies or companies that have a great data science department in the middle east. Thanks.", "author_fullname": "t2_b9udmqrg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best courses that i can benefit from as a data dcience major (im a 2nd year student)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oi516", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691782035.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;And another question, what are the best data science companies or companies that have a great data science department in the middle east. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oi516", "is_robot_indexable": true, "report_reasons": null, "author": "Fun_Hurry_968", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oi516/what_are_the_best_courses_that_i_can_benefit_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oi516/what_are_the_best_courses_that_i_can_benefit_from/", "subreddit_subscribers": 983678, "created_utc": 1691782035.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "my organization gives us $500 to spend on professional development days. i am looking to shift from data analytics to data science. Can anyone recommend courses or books for the same? I already have a udemy membership.", "author_fullname": "t2_3cn6ylzl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Books/Courses Recommendation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oi1s2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691781827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;my organization gives us $500 to spend on professional development days. i am looking to shift from data analytics to data science. Can anyone recommend courses or books for the same? I already have a udemy membership.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15oi1s2", "is_robot_indexable": true, "report_reasons": null, "author": "Awkward_Sign_1191", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15oi1s2/bookscourses_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15oi1s2/bookscourses_recommendation/", "subreddit_subscribers": 983678, "created_utc": 1691781827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am looking for the repo or similar repo for this project https://youtu.be/wvsE8jm1GzE", "author_fullname": "t2_7wkh6o3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to find the google t-sne notebook in the video", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ojp5f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691785660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for the repo or similar repo for this project &lt;a href=\"https://youtu.be/wvsE8jm1GzE\"&gt;https://youtu.be/wvsE8jm1GzE&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Hk-y1Z47t2FkR556fmOKa5NLO4ZUmTYv4mZBSJAkJ68.jpg?auto=webp&amp;s=45519c0e3a5fe4a2a1eacfbef43ff32a4dd3ecb0", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/Hk-y1Z47t2FkR556fmOKa5NLO4ZUmTYv4mZBSJAkJ68.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3b48d9a0a78662351c3fdbc1bb91596c791a8452", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Hk-y1Z47t2FkR556fmOKa5NLO4ZUmTYv4mZBSJAkJ68.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bc84273280a4f8680eb2f13c29bebfabf9b16e70", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Hk-y1Z47t2FkR556fmOKa5NLO4ZUmTYv4mZBSJAkJ68.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7237a3362e8f3945ef173bc4a4d2355f60310acd", "width": 320, "height": 240}], "variants": {}, "id": "zwolOIr7Q4zXmsOXwQR6Od4wHKHc_aHVa-pI3BYyubE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ojp5f", "is_robot_indexable": true, "report_reasons": null, "author": "weluuu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ojp5f/where_to_find_the_google_tsne_notebook_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ojp5f/where_to_find_the_google_tsne_notebook_in_the/", "subreddit_subscribers": 983678, "created_utc": 1691785660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the past, I have always encountered problems when data from one source doesn't match data from another. And for me, the solution was data integration. So i want to share with you some data integration strategies that helped my company.\n\n&amp;#x200B;\n\n**ETL (Extract, Transform, Load):** ETL is the backbone of many integration projects. It involves pulling data, reshaping it to fit, and storing it in its new home, usually a data warehouse. The best part? ETL automates the nitty-gritty, ensuring consistency and paving the way for better decision-making.\n\n&amp;#x200B;\n\n**ELT (Extract, Load, Transform):** If ETL is the backbone, ELT is the muscle for handling bulky data sets. It's about collecting data, moving it directly to its target, and making tweaks there. I love it for its agility, especially when dealing with vast amounts of data in real time.\n\n&amp;#x200B;\n\n**Change Data Capture (CDC):** Picture CDC as the ever-watchful sentinel, tracking database changes. It keeps an eye out for alterations, documents them, and ensures they reach where they need to. Its edge? Near real-time data integration, light touch on source systems, and a knack for preserving data history.\n\n&amp;#x200B;\n\n**A Nod to Data Replication**\n\nWith data replication, it's about redundancy for safety. You create backup copies of your data, ensuring continuous access and faster decision-making. Plus, distributing data means potential data losses are a thing of the past.\n\n&amp;#x200B;\n\n**The Magic of Data Virtualization**\n\nHere's a fun one: What if you didn't need a new repository for all your data sources? Data virtualization virtually combines data for a unified view. It offers real-time access and is a cost-effective alternative to traditional storage. From my experience, it also greatly improves data quality and reliability.\n\n&amp;#x200B;\n\nIn my journey, I've learned the importance of handpicking the right tools for the job. They need to gel with your data sources, scale with your needs, and offer efficient infrastructure. \n\nIf you want to dive deeper in topics like this, check out my blog: [https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm\\_source=linkedin&amp;utm\\_medium=social&amp;utm\\_campaign=hfs\\_research&amp;utm\\_content=integration\\_strategy&amp;utm\\_term=socialmedia](https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm_source=linkedin&amp;utm_medium=social&amp;utm_campaign=hfs_research&amp;utm_content=integration_strategy&amp;utm_term=socialmedia) \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_ct09rz3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data integration strategies that work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15p1fs4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691837350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the past, I have always encountered problems when data from one source doesn&amp;#39;t match data from another. And for me, the solution was data integration. So i want to share with you some data integration strategies that helped my company.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;ETL (Extract, Transform, Load):&lt;/strong&gt; ETL is the backbone of many integration projects. It involves pulling data, reshaping it to fit, and storing it in its new home, usually a data warehouse. The best part? ETL automates the nitty-gritty, ensuring consistency and paving the way for better decision-making.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;ELT (Extract, Load, Transform):&lt;/strong&gt; If ETL is the backbone, ELT is the muscle for handling bulky data sets. It&amp;#39;s about collecting data, moving it directly to its target, and making tweaks there. I love it for its agility, especially when dealing with vast amounts of data in real time.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Change Data Capture (CDC):&lt;/strong&gt; Picture CDC as the ever-watchful sentinel, tracking database changes. It keeps an eye out for alterations, documents them, and ensures they reach where they need to. Its edge? Near real-time data integration, light touch on source systems, and a knack for preserving data history.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;A Nod to Data Replication&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;With data replication, it&amp;#39;s about redundancy for safety. You create backup copies of your data, ensuring continuous access and faster decision-making. Plus, distributing data means potential data losses are a thing of the past.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Magic of Data Virtualization&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a fun one: What if you didn&amp;#39;t need a new repository for all your data sources? Data virtualization virtually combines data for a unified view. It offers real-time access and is a cost-effective alternative to traditional storage. From my experience, it also greatly improves data quality and reliability.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In my journey, I&amp;#39;ve learned the importance of handpicking the right tools for the job. They need to gel with your data sources, scale with your needs, and offer efficient infrastructure. &lt;/p&gt;\n\n&lt;p&gt;If you want to dive deeper in topics like this, check out my blog: &lt;a href=\"https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=hfs_research&amp;amp;utm_content=integration_strategy&amp;amp;utm_term=socialmedia\"&gt;https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=hfs_research&amp;amp;utm_content=integration_strategy&amp;amp;utm_term=socialmedia&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I3xJj8ELsQOmy2H-NeHKFmGnh2tKVfHX1i7SJ1O1qwE.jpg?auto=webp&amp;s=8a29f85fd320507a70ec9694b971f494352d2655", "width": 79, "height": 86}, "resolutions": [], "variants": {}, "id": "fKkAw45B6Aa1K9gfC0CvmXNzCjb0F-J2wvKUvaKf1Vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15p1fs4", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Speech36", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15p1fs4/data_integration_strategies_that_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15p1fs4/data_integration_strategies_that_work/", "subreddit_subscribers": 983678, "created_utc": 1691837350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi community, I have a dissertation project with a short deadline. I have collected data from 964 participants, each ranking their beliefs in conspiracy theories on a scale of 1-7 (1 being strongly disagree, 4 being neither disagree nor agree and 7 being strongly disagree). Along with Conspiracy beliefs, we have other beliefs as well like, paranormal beliefs, populist attitudes, supernatural beliefs, etc. I have gone with conspiracy beliefs and paranormal beliefs and I am thinking about showing the correlation between them and making a prediction model for it. I struggling very hard to make one and I need your guidance on the process and which algorithm to choose. Please consider me a newbie. Thanks.", "author_fullname": "t2_9hf9h12l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Urgent help with a project is needed!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15opys7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691800737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi community, I have a dissertation project with a short deadline. I have collected data from 964 participants, each ranking their beliefs in conspiracy theories on a scale of 1-7 (1 being strongly disagree, 4 being neither disagree nor agree and 7 being strongly disagree). Along with Conspiracy beliefs, we have other beliefs as well like, paranormal beliefs, populist attitudes, supernatural beliefs, etc. I have gone with conspiracy beliefs and paranormal beliefs and I am thinking about showing the correlation between them and making a prediction model for it. I struggling very hard to make one and I need your guidance on the process and which algorithm to choose. Please consider me a newbie. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15opys7", "is_robot_indexable": true, "report_reasons": null, "author": "More-Tone1339", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15opys7/urgent_help_with_a_project_is_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15opys7/urgent_help_with_a_project_is_needed/", "subreddit_subscribers": 983678, "created_utc": 1691800737.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}