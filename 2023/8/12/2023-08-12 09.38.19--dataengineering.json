{"kind": "Listing", "data": {"after": "t3_15o8ltv", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I did not work extensively with dbt, but it always seemed less appealing than having a databricks based pyspark/spark sql workflow + some orchestrator and some internal python libs to make things smooth. Sure data models and lineage are alright with dbt, but they can get out of hand with analysts chiming in. Maybe my DWH/etl usecases were not big enough for them not to be managed via an a priori sketched out data model, decent PKs and FKs, good naming conventions and job structure.\n\nMaking things performant and cost effective just seem more straight forward in databricks.\n\nMaybe I just did not get the vibe. dbt cloud also kinda feels like the myriad of other scammy \"modern data tools\".\n\nCurious about other perspectives!", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is dbt popular for the transformation step?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oc8z5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 84, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 84, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691768369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I did not work extensively with dbt, but it always seemed less appealing than having a databricks based pyspark/spark sql workflow + some orchestrator and some internal python libs to make things smooth. Sure data models and lineage are alright with dbt, but they can get out of hand with analysts chiming in. Maybe my DWH/etl usecases were not big enough for them not to be managed via an a priori sketched out data model, decent PKs and FKs, good naming conventions and job structure.&lt;/p&gt;\n\n&lt;p&gt;Making things performant and cost effective just seem more straight forward in databricks.&lt;/p&gt;\n\n&lt;p&gt;Maybe I just did not get the vibe. dbt cloud also kinda feels like the myriad of other scammy &amp;quot;modern data tools&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Curious about other perspectives!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15oc8z5", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oc8z5/why_is_dbt_popular_for_the_transformation_step/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oc8z5/why_is_dbt_popular_for_the_transformation_step/", "subreddit_subscribers": 122271, "created_utc": 1691768369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7lbbuuh58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I couldn't find any detailed comparison between dataframe tools so I wrote one: this post compares Polars, DuckDB, Pandas, Modin, Ponder, Fugue, Daft, and more", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o5q7l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1691751543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kestra.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://kestra.io/blogs/2023-08-11-dataframes", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15o5q7l", "is_robot_indexable": true, "report_reasons": null, "author": "Round-Following1532", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o5q7l/i_couldnt_find_any_detailed_comparison_between/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://kestra.io/blogs/2023-08-11-dataframes", "subreddit_subscribers": 122271, "created_utc": 1691751543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Community,\n\nHope you are doing well.\n\nI want to improve the existing Git flow for my projects -\n\nCurrently the Git flow that we have in place, works as below -\n\n1. Create a new feature branch from **Develop** using the naming convention: **feature/issue#\\_&lt;name&gt;**.\n2. When development is complete, open a PR targeting **Develop**. Upon approval, merge using the \"Squash and Merge\" option. Delete the feature branch afterward if it's no longer needed.\n3. To introduce changes into pre-production, initiate a PR from **Develop** to **Master**. Utilize the \"Create Merge Commit\" strategy for merging (without deleting the **Develop** branch, of course).\n4. For deployment to production, create a release branch from **Master**. Tag the commit with the desired deployment version.\n5. After verifying that the deployment is successful, merge the release branch into **Master** using the regular merge strategy.\n6. Subsequently, make an additional commit on the release branch to update the version (increment the minor version and append \"dev\"). Finally, open a PR targeting **Develop**.\n\n**For HotFix -**\n\n1. Create a branch based on the most recent deployed commit, which is the merge from the last release branch.\n2. Adjust the patch version and apply your changes.\n3. Submit a PR to the **master** branch. After getting approval, tag your commit and initiate deployment.\n4. Complete the merge into **master.**\n5. Sync the version with that of the **develop** branch and raise a PR for **develop**.\n\n\\---\n\nI want to improve the below points -\n\n* 3rd point - how will you know if the new feature is ready to push to pre-production. Currently, we manually running the ETL pipeline, once all the tests are successful, we mention everything on PR ( including test cases )\n* how to align the master and develop after the release in the production / HotFix.\n\nAre there any other git flow are you following, please share your experience.", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Git flow for Data Engineering projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o4h68", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691747549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Community,&lt;/p&gt;\n\n&lt;p&gt;Hope you are doing well.&lt;/p&gt;\n\n&lt;p&gt;I want to improve the existing Git flow for my projects -&lt;/p&gt;\n\n&lt;p&gt;Currently the Git flow that we have in place, works as below -&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create a new feature branch from &lt;strong&gt;Develop&lt;/strong&gt; using the naming convention: &lt;strong&gt;feature/issue#_&amp;lt;name&amp;gt;&lt;/strong&gt;.&lt;/li&gt;\n&lt;li&gt;When development is complete, open a PR targeting &lt;strong&gt;Develop&lt;/strong&gt;. Upon approval, merge using the &amp;quot;Squash and Merge&amp;quot; option. Delete the feature branch afterward if it&amp;#39;s no longer needed.&lt;/li&gt;\n&lt;li&gt;To introduce changes into pre-production, initiate a PR from &lt;strong&gt;Develop&lt;/strong&gt; to &lt;strong&gt;Master&lt;/strong&gt;. Utilize the &amp;quot;Create Merge Commit&amp;quot; strategy for merging (without deleting the &lt;strong&gt;Develop&lt;/strong&gt; branch, of course).&lt;/li&gt;\n&lt;li&gt;For deployment to production, create a release branch from &lt;strong&gt;Master&lt;/strong&gt;. Tag the commit with the desired deployment version.&lt;/li&gt;\n&lt;li&gt;After verifying that the deployment is successful, merge the release branch into &lt;strong&gt;Master&lt;/strong&gt; using the regular merge strategy.&lt;/li&gt;\n&lt;li&gt;Subsequently, make an additional commit on the release branch to update the version (increment the minor version and append &amp;quot;dev&amp;quot;). Finally, open a PR targeting &lt;strong&gt;Develop&lt;/strong&gt;.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;For HotFix -&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create a branch based on the most recent deployed commit, which is the merge from the last release branch.&lt;/li&gt;\n&lt;li&gt;Adjust the patch version and apply your changes.&lt;/li&gt;\n&lt;li&gt;Submit a PR to the &lt;strong&gt;master&lt;/strong&gt; branch. After getting approval, tag your commit and initiate deployment.&lt;/li&gt;\n&lt;li&gt;Complete the merge into &lt;strong&gt;master.&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Sync the version with that of the &lt;strong&gt;develop&lt;/strong&gt; branch and raise a PR for &lt;strong&gt;develop&lt;/strong&gt;.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;I want to improve the below points -&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;3rd point - how will you know if the new feature is ready to push to pre-production. Currently, we manually running the ETL pipeline, once all the tests are successful, we mention everything on PR ( including test cases )&lt;/li&gt;\n&lt;li&gt;how to align the master and develop after the release in the production / HotFix.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Are there any other git flow are you following, please share your experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15o4h68", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15o4h68/git_flow_for_data_engineering_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o4h68/git_flow_for_data_engineering_projects/", "subreddit_subscribers": 122271, "created_utc": 1691747549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Please tell me why you have chosen data engineering and not any other work like data analysis, dba, swe, devops, etc.", "author_fullname": "t2_ahz5xwuw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are u doing data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15olmmq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691790092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please tell me why you have chosen data engineering and not any other work like data analysis, dba, swe, devops, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15olmmq", "is_robot_indexable": true, "report_reasons": null, "author": "Similar_Assignment59", "discussion_type": null, "num_comments": 94, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15olmmq/why_are_u_doing_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15olmmq/why_are_u_doing_data_engineering/", "subreddit_subscribers": 122271, "created_utc": 1691790092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Maybe a better question would be \"what does your workplace do and how BIG is your data\"?\n\nBut mostly just curious.\n\nI wanna know how Big your \"Big Data\" is?", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How big is your Data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oe2wu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691772720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe a better question would be &amp;quot;what does your workplace do and how BIG is your data&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;But mostly just curious.&lt;/p&gt;\n\n&lt;p&gt;I wanna know how Big your &amp;quot;Big Data&amp;quot; is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "15oe2wu", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oe2wu/how_big_is_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oe2wu/how_big_is_your_data/", "subreddit_subscribers": 122271, "created_utc": 1691772720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says, we need to talk about cloud.\n\nThe DW implementations already have been abstracted by all the clouds, but what about Hive? No one uses it anymore? What is the concept of big data? 3 V's, 5V's? When an on-premise server is better than a cloud server?\n\nMost data engineers don't use more than 300tb of transaction data/year and don't have more than 20tb of data on S3/GCS. Most of this data comes from NoSQL databases which seems to be \"lightweight\", but when it comes to OLAP server all the fu#$ings \"value:  another\\_shit: {...}\" make the OLAP cube go from 5gb to 100gb in a hit.\n\nIn your company, all data architects already have tried to cut costs by implementing an on-premise cluster rather than on the cloud? Cloud seems more than expensive, but impracticable in some cases.\n\nLast but not least, how many of you guys use streaming data on kafka?", "author_fullname": "t2_82em8pzs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We \"really\" need to talk about cloud!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ouct2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691822212.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691813413.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, we need to talk about cloud.&lt;/p&gt;\n\n&lt;p&gt;The DW implementations already have been abstracted by all the clouds, but what about Hive? No one uses it anymore? What is the concept of big data? 3 V&amp;#39;s, 5V&amp;#39;s? When an on-premise server is better than a cloud server?&lt;/p&gt;\n\n&lt;p&gt;Most data engineers don&amp;#39;t use more than 300tb of transaction data/year and don&amp;#39;t have more than 20tb of data on S3/GCS. Most of this data comes from NoSQL databases which seems to be &amp;quot;lightweight&amp;quot;, but when it comes to OLAP server all the fu#$ings &amp;quot;value:  another_shit: {...}&amp;quot; make the OLAP cube go from 5gb to 100gb in a hit.&lt;/p&gt;\n\n&lt;p&gt;In your company, all data architects already have tried to cut costs by implementing an on-premise cluster rather than on the cloud? Cloud seems more than expensive, but impracticable in some cases.&lt;/p&gt;\n\n&lt;p&gt;Last but not least, how many of you guys use streaming data on kafka?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ouct2", "is_robot_indexable": true, "report_reasons": null, "author": "hanari1", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ouct2/we_really_need_to_talk_about_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ouct2/we_really_need_to_talk_about_cloud/", "subreddit_subscribers": 122271, "created_utc": 1691813413.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not actively thinking about leaving my job because it is my first, and I have been there for just under a year. Is there any harm in talking to the recruiters in your inbox on LinkedIn?", "author_fullname": "t2_23fntgb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Harm from hearing out recruiters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oheb8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691780339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not actively thinking about leaving my job because it is my first, and I have been there for just under a year. Is there any harm in talking to the recruiters in your inbox on LinkedIn?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15oheb8", "is_robot_indexable": true, "report_reasons": null, "author": "LoudSphinx517", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oheb8/harm_from_hearing_out_recruiters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oheb8/harm_from_hearing_out_recruiters/", "subreddit_subscribers": 122271, "created_utc": 1691780339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Assumption: There are some data team managers here.\n\nI got an offer for data analytics lead from another firm and currently, I am a senior analyst I am interested to know what are your biggest challenges as a data analyst lead/manager so I can decide if this is for me or not. I know the technical side but want to understand the management's point of view. Thanks for your help.", "author_fullname": "t2_dogbygvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your biggest challenge as a data analyst lead/manager?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ooo20", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691797381.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Assumption: There are some data team managers here.&lt;/p&gt;\n\n&lt;p&gt;I got an offer for data analytics lead from another firm and currently, I am a senior analyst I am interested to know what are your biggest challenges as a data analyst lead/manager so I can decide if this is for me or not. I know the technical side but want to understand the management&amp;#39;s point of view. Thanks for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ooo20", "is_robot_indexable": true, "report_reasons": null, "author": "vinayak_singh_k", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ooo20/what_is_your_biggest_challenge_as_a_data_analyst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ooo20/what_is_your_biggest_challenge_as_a_data_analyst/", "subreddit_subscribers": 122271, "created_utc": 1691797381.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does my computer's CPU really matter that much for some typical DE tasks such as:\n\n\\-querying in BQ\n\n\\-building and running airflow dags\n\n\\-compiling/running/testing in dbt labs\n\n&amp;#x200B;\n\nFairly new to DE &amp; was curious if it's worth asking IT for a laptop upgrade. I assume it's all in the cloud and my wifi speed is the most important part for me?", "author_fullname": "t2_6getu85y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CPU for Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oq1e4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691800930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does my computer&amp;#39;s CPU really matter that much for some typical DE tasks such as:&lt;/p&gt;\n\n&lt;p&gt;-querying in BQ&lt;/p&gt;\n\n&lt;p&gt;-building and running airflow dags&lt;/p&gt;\n\n&lt;p&gt;-compiling/running/testing in dbt labs&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Fairly new to DE &amp;amp; was curious if it&amp;#39;s worth asking IT for a laptop upgrade. I assume it&amp;#39;s all in the cloud and my wifi speed is the most important part for me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15oq1e4", "is_robot_indexable": true, "report_reasons": null, "author": "chippewa_falls", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oq1e4/cpu_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oq1e4/cpu_for_data_engineering/", "subreddit_subscribers": 122271, "created_utc": 1691800930.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone :)\n\nI have a lambda function that extracts from a postgres ddbb using awswrangler, but the dataset appears to be too large to keep in memory even when reading in chunks so the lambda timed out.\n\nI searched and found the glue ray scripts and their integration with awswrangler, so I tried setting up a simple script like below. It was convinient since the transformations where all done in pandas already so I didn't need to refactor the code.\n\n    import awswrangler as wr\n    print(f\"Execution Engine: {wr.engine.get()}\")\n    print(f\"Memory Format: {wr.memory_format.get()}\")\n    \n    df = wr.s3.read_parquet(\n        path=path,\n        dataset=True,\n        path_suffix='.parquet'\n    )\n    \n    #perform some transformations\n    \n    dtypes = {...}\n    \n    wr.athena.to_iceberg(\n        df=df,\n        database='&lt;database&gt;',\n        table='&lt;table_name&gt;',\n        temp_path='&lt;temp_path&gt;',\n        index=False,\n        table_location='&lt;table_location&gt;',\n        partition_cols=&lt;partition_cols&gt;,\n        keep_files=False,\n        dtype=dtypes\n    )\n\nThe job parameteres are the following:\n\nhttps://preview.redd.it/c5doul9pjihb1.png?width=785&amp;format=png&amp;auto=webp&amp;s=4adfafe143afbaa264c262f4678ed7ed333ae34a\n\nThe csv files i'm reading are \\~4gb on memory,  the job executed for almost 12 min and \\~10 of them where for initializing the ray instance.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/a611ijm1kihb1.png?width=1467&amp;format=png&amp;auto=webp&amp;s=e3d40e396665d9ef3cfd8d61d2f4efe5b13d0074\n\nIs this duration normal? Is it correct that it initializes an instance for every execution? [https://aws-sdk-pandas.readthedocs.io/en/stable/scale.html#getting-started](https://aws-sdk-pandas.readthedocs.io/en/stable/scale.html#getting-started)\n\nAlso is it possible to run the existing code (using awswrangler and pd but with slight necessary adjustments) on a spark glue job?", "author_fullname": "t2_dpj60sgl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue Ray script long startup time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"a611ijm1kihb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 40, "x": 108, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=743b05c4d3e02335610d161e436bee870d59bae4"}, {"y": 81, "x": 216, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c8379cfadf84a489848dbd1b65c5d85423e87697"}, {"y": 120, "x": 320, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d68811b42627f004b0e7085ef1f68d8a441f211e"}, {"y": 240, "x": 640, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=593e2539f4720cf140ab5a61f968036878497ef2"}, {"y": 361, "x": 960, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=63d18aaea588606324437f6019b2d058545d6c86"}, {"y": 406, "x": 1080, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3711933400a6ac96ea76b90eb0a896e374aec025"}], "s": {"y": 552, "x": 1467, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=1467&amp;format=png&amp;auto=webp&amp;s=e3d40e396665d9ef3cfd8d61d2f4efe5b13d0074"}, "id": "a611ijm1kihb1"}, "c5doul9pjihb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 125, "x": 108, "u": "https://preview.redd.it/c5doul9pjihb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b4b3df445f1f65efe37f45dac575b73600b6af8"}, {"y": 250, "x": 216, "u": "https://preview.redd.it/c5doul9pjihb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a667cbf218fca0a9ccf68d9e1dae0ef5af2b8d9"}, {"y": 371, "x": 320, "u": "https://preview.redd.it/c5doul9pjihb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9e5982a883a6e012b0002d9120f4e04b66a79c9d"}, {"y": 743, "x": 640, "u": "https://preview.redd.it/c5doul9pjihb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=718b3ccf21436b056e647128266d1e19fc11960b"}], "s": {"y": 912, "x": 785, "u": "https://preview.redd.it/c5doul9pjihb1.png?width=785&amp;format=png&amp;auto=webp&amp;s=4adfafe143afbaa264c262f4678ed7ed333ae34a"}, "id": "c5doul9pjihb1"}}, "name": "t3_15oepxu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/DDQUlN5PPe9fegmj6Ut4i6hhnp8pWhNrALsnk_QlMa8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691774194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone :)&lt;/p&gt;\n\n&lt;p&gt;I have a lambda function that extracts from a postgres ddbb using awswrangler, but the dataset appears to be too large to keep in memory even when reading in chunks so the lambda timed out.&lt;/p&gt;\n\n&lt;p&gt;I searched and found the glue ray scripts and their integration with awswrangler, so I tried setting up a simple script like below. It was convinient since the transformations where all done in pandas already so I didn&amp;#39;t need to refactor the code.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import awswrangler as wr\nprint(f&amp;quot;Execution Engine: {wr.engine.get()}&amp;quot;)\nprint(f&amp;quot;Memory Format: {wr.memory_format.get()}&amp;quot;)\n\ndf = wr.s3.read_parquet(\n    path=path,\n    dataset=True,\n    path_suffix=&amp;#39;.parquet&amp;#39;\n)\n\n#perform some transformations\n\ndtypes = {...}\n\nwr.athena.to_iceberg(\n    df=df,\n    database=&amp;#39;&amp;lt;database&amp;gt;&amp;#39;,\n    table=&amp;#39;&amp;lt;table_name&amp;gt;&amp;#39;,\n    temp_path=&amp;#39;&amp;lt;temp_path&amp;gt;&amp;#39;,\n    index=False,\n    table_location=&amp;#39;&amp;lt;table_location&amp;gt;&amp;#39;,\n    partition_cols=&amp;lt;partition_cols&amp;gt;,\n    keep_files=False,\n    dtype=dtypes\n)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The job parameteres are the following:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/c5doul9pjihb1.png?width=785&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4adfafe143afbaa264c262f4678ed7ed333ae34a\"&gt;https://preview.redd.it/c5doul9pjihb1.png?width=785&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4adfafe143afbaa264c262f4678ed7ed333ae34a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The csv files i&amp;#39;m reading are ~4gb on memory,  the job executed for almost 12 min and ~10 of them where for initializing the ray instance.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/a611ijm1kihb1.png?width=1467&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e3d40e396665d9ef3cfd8d61d2f4efe5b13d0074\"&gt;https://preview.redd.it/a611ijm1kihb1.png?width=1467&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e3d40e396665d9ef3cfd8d61d2f4efe5b13d0074&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is this duration normal? Is it correct that it initializes an instance for every execution? &lt;a href=\"https://aws-sdk-pandas.readthedocs.io/en/stable/scale.html#getting-started\"&gt;https://aws-sdk-pandas.readthedocs.io/en/stable/scale.html#getting-started&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Also is it possible to run the existing code (using awswrangler and pd but with slight necessary adjustments) on a spark glue job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15oepxu", "is_robot_indexable": true, "report_reasons": null, "author": "_unwin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oepxu/aws_glue_ray_script_long_startup_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oepxu/aws_glue_ray_script_long_startup_time/", "subreddit_subscribers": 122271, "created_utc": 1691774194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, folks I'm 27 years old and working as an IAM engineer I wouldn't say I like this role much as it's dull and there is nothing new to learn I don't see growth, I also have a love towards data so have planned to switch to data domain but my biggest question is should I first get into data analyst and then transition into data engineer?\n\nOr the right way to jump into data engineering need your help folks I so confused ", "author_fullname": "t2_494n4hlc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need suggestions on career transformation from IAM Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oeciu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691773339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, folks I&amp;#39;m 27 years old and working as an IAM engineer I wouldn&amp;#39;t say I like this role much as it&amp;#39;s dull and there is nothing new to learn I don&amp;#39;t see growth, I also have a love towards data so have planned to switch to data domain but my biggest question is should I first get into data analyst and then transition into data engineer?&lt;/p&gt;\n\n&lt;p&gt;Or the right way to jump into data engineering need your help folks I so confused &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15oeciu", "is_robot_indexable": true, "report_reasons": null, "author": "callmesasi", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oeciu/need_suggestions_on_career_transformation_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oeciu/need_suggestions_on_career_transformation_from/", "subreddit_subscribers": 122271, "created_utc": 1691773339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data analyst with two years of relevant experience. I am trying to get a data engineer position internally but failed to see any openings on workday. I recently came across an opening for a big data developer. Should I try this opportunity? In the job description they mentioned about familiarity with different file formats, compression types, Hadoop and SQL. I am not sure if I should wait for a good opportunity and till then continue with my data analyst job or I should try for this position.\nPS. I have started to learn data engineering. I have good command over python and SQL. I have also taught myself spark, hive and little bit of data factory and data bricks. But, I am not confident as I don't have much hands on experience and I fear that I might just superficial knowledge about it. So I seek your help. \n\nThanks", "author_fullname": "t2_t09x3o4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I take an internal position as a big data developer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oeaqp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691773237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data analyst with two years of relevant experience. I am trying to get a data engineer position internally but failed to see any openings on workday. I recently came across an opening for a big data developer. Should I try this opportunity? In the job description they mentioned about familiarity with different file formats, compression types, Hadoop and SQL. I am not sure if I should wait for a good opportunity and till then continue with my data analyst job or I should try for this position.\nPS. I have started to learn data engineering. I have good command over python and SQL. I have also taught myself spark, hive and little bit of data factory and data bricks. But, I am not confident as I don&amp;#39;t have much hands on experience and I fear that I might just superficial knowledge about it. So I seek your help. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15oeaqp", "is_robot_indexable": true, "report_reasons": null, "author": "frustratedhu", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oeaqp/should_i_take_an_internal_position_as_a_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oeaqp/should_i_take_an_internal_position_as_a_big_data/", "subreddit_subscribers": 122271, "created_utc": 1691773237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm looking at automating a process for uploading data to a SQL server DB using a python script which loops through CSVs in a SharePoint location, does some validation on the columns and values and then inserts the data to the existing dB. \n\nMy plan is to open the file, create a staging table from the corresponding df and then insert that into the main table.\n\nBut I'm not sure on the exact syntax for inserting the data into the table especially cause I need it to parameterised in case there are more files.\n\nDoes anybody have any advice on either the Syntax or if there's a better way of doing this?\n\nThis is entirely new to me and I'm sure I'm missing something fairly simple. \n\nThanks in advance", "author_fullname": "t2_44gx5087", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Importing from CSV to SQL server DB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ob1vi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691765585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking at automating a process for uploading data to a SQL server DB using a python script which loops through CSVs in a SharePoint location, does some validation on the columns and values and then inserts the data to the existing dB. &lt;/p&gt;\n\n&lt;p&gt;My plan is to open the file, create a staging table from the corresponding df and then insert that into the main table.&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m not sure on the exact syntax for inserting the data into the table especially cause I need it to parameterised in case there are more files.&lt;/p&gt;\n\n&lt;p&gt;Does anybody have any advice on either the Syntax or if there&amp;#39;s a better way of doing this?&lt;/p&gt;\n\n&lt;p&gt;This is entirely new to me and I&amp;#39;m sure I&amp;#39;m missing something fairly simple. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ob1vi", "is_robot_indexable": true, "report_reasons": null, "author": "rogerbarario", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ob1vi/importing_from_csv_to_sql_server_db/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ob1vi/importing_from_csv_to_sql_server_db/", "subreddit_subscribers": 122271, "created_utc": 1691765585.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Assuming no airflow and just serverless.( or AWS native services ). maybe lambda and something else\n\nWhat would be the easiest way for a newbie DE as I need to POC based on the suggestion provided.\n\nRequirement\n\n\\- api need to be looped based on date\n\n\\- definitely lambda limit of 15mins would not be able to do it\n\n\\- need to backfill the past 365 days\n\nIf you an idea, maybe a youtube or URL that I can follow through.\n\nThanks", "author_fullname": "t2_ecope", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to backfill data using AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o92y7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691760812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Assuming no airflow and just serverless.( or AWS native services ). maybe lambda and something else&lt;/p&gt;\n\n&lt;p&gt;What would be the easiest way for a newbie DE as I need to POC based on the suggestion provided.&lt;/p&gt;\n\n&lt;p&gt;Requirement&lt;/p&gt;\n\n&lt;p&gt;- api need to be looped based on date&lt;/p&gt;\n\n&lt;p&gt;- definitely lambda limit of 15mins would not be able to do it&lt;/p&gt;\n\n&lt;p&gt;- need to backfill the past 365 days&lt;/p&gt;\n\n&lt;p&gt;If you an idea, maybe a youtube or URL that I can follow through.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15o92y7", "is_robot_indexable": true, "report_reasons": null, "author": "snip3r77", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o92y7/how_to_backfill_data_using_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o92y7/how_to_backfill_data_using_aws/", "subreddit_subscribers": 122271, "created_utc": 1691760812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello All, \n\nMy boss is asking to have a demo or presentation created around database risiliency methods both around on premise and cloud font for our dev team. While i do have understanding on the methods like backups, snapshots, physical standby, replications etc. It can be the case of any disaster(fire, earthquake etc) or may be the case of simple maintenance activity, the service should be available. And \"High availability' and \"disaster recovery\" solutions are both part of this based on the required RTO and RPO as per business need.\n\nI need some suggestion from experts on how to put it in a consolidated way so as keep it simple and make all understand the details around it. Or any sample document/blog which is there and has the details around it and can be followed to get more clarity around it?", "author_fullname": "t2_vvsk9e6n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on database availability", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15oyvw4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691828542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All, &lt;/p&gt;\n\n&lt;p&gt;My boss is asking to have a demo or presentation created around database risiliency methods both around on premise and cloud font for our dev team. While i do have understanding on the methods like backups, snapshots, physical standby, replications etc. It can be the case of any disaster(fire, earthquake etc) or may be the case of simple maintenance activity, the service should be available. And &amp;quot;High availability&amp;#39; and &amp;quot;disaster recovery&amp;quot; solutions are both part of this based on the required RTO and RPO as per business need.&lt;/p&gt;\n\n&lt;p&gt;I need some suggestion from experts on how to put it in a consolidated way so as keep it simple and make all understand the details around it. Or any sample document/blog which is there and has the details around it and can be followed to get more clarity around it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15oyvw4", "is_robot_indexable": true, "report_reasons": null, "author": "ConsiderationLazy956", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oyvw4/question_on_database_availability/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oyvw4/question_on_database_availability/", "subreddit_subscribers": 122271, "created_utc": 1691828542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,  \nI am thinking of doing an open source project using Youtube API. I am considering ideas for the same. I am thinking of making a project that involves getting data using API, storing it in a cloud database and making a pipeline for it . I am also thinking of making a real time dashboard as well that will involve streaming data as well. I am new to data engineering but I have good Python experience especially in the ML/DS side.  \n\n\nI have a rough outline for the project but nothing concrete till now. I would really appreciate it if  anyone can please help me narrow down on what to make in this project.   \n\n\nThe purpose of this project is to learn main tools that are used in the data engineering domain. I know there are a large number of tools available but if I can cover the most commonly used ones, that would be really great.", "author_fullname": "t2_5k8jiyvl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Youtube API Project ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oxqcm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691824597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;br/&gt;\nI am thinking of doing an open source project using Youtube API. I am considering ideas for the same. I am thinking of making a project that involves getting data using API, storing it in a cloud database and making a pipeline for it . I am also thinking of making a real time dashboard as well that will involve streaming data as well. I am new to data engineering but I have good Python experience especially in the ML/DS side.  &lt;/p&gt;\n\n&lt;p&gt;I have a rough outline for the project but nothing concrete till now. I would really appreciate it if  anyone can please help me narrow down on what to make in this project.   &lt;/p&gt;\n\n&lt;p&gt;The purpose of this project is to learn main tools that are used in the data engineering domain. I know there are a large number of tools available but if I can cover the most commonly used ones, that would be really great.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15oxqcm", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable-Act401", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oxqcm/youtube_api_project_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oxqcm/youtube_api_project_ideas/", "subreddit_subscribers": 122271, "created_utc": 1691824597.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a little stuck on what  \"technical\" work to focus on as of now to really advance myself to the next level. Here's my experience right now as an \"Analytics Engineer II\" (4 years)\n\n\\- AWS - the obvious stuff like writing ETLs in SQL over Redshift, ad-hoc querying in Athena, Hive, creating PySpark ETLs (getting data from Dynamo DB/Document DB or Postgres brining over to S3/Glue Catalog etc.) deploying with CI/CD. Working with Lambda (sometimes doing transforms with pandas) .\n\n\\- G-Cloud - Worked a lot with BigQuery, mainly scheduling jobs or creating ad-hoc reports.\n\nBI Viz - Have pretty good experience with Looker, Tableau, Quicksight, Mode etc.\n\nStuff that I haven't touched much: VPNs, Backend, Microservices, Kafka/streaming, any other big services like Azure or Snowflake, also DBT.\n\nWhat type of projects should I be focusing on outside of work?", "author_fullname": "t2_h9grrinuz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best pathway for becoming a \"senior\" data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15osdo1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691807469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a little stuck on what  &amp;quot;technical&amp;quot; work to focus on as of now to really advance myself to the next level. Here&amp;#39;s my experience right now as an &amp;quot;Analytics Engineer II&amp;quot; (4 years)&lt;/p&gt;\n\n&lt;p&gt;- AWS - the obvious stuff like writing ETLs in SQL over Redshift, ad-hoc querying in Athena, Hive, creating PySpark ETLs (getting data from Dynamo DB/Document DB or Postgres brining over to S3/Glue Catalog etc.) deploying with CI/CD. Working with Lambda (sometimes doing transforms with pandas) .&lt;/p&gt;\n\n&lt;p&gt;- G-Cloud - Worked a lot with BigQuery, mainly scheduling jobs or creating ad-hoc reports.&lt;/p&gt;\n\n&lt;p&gt;BI Viz - Have pretty good experience with Looker, Tableau, Quicksight, Mode etc.&lt;/p&gt;\n\n&lt;p&gt;Stuff that I haven&amp;#39;t touched much: VPNs, Backend, Microservices, Kafka/streaming, any other big services like Azure or Snowflake, also DBT.&lt;/p&gt;\n\n&lt;p&gt;What type of projects should I be focusing on outside of work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15osdo1", "is_robot_indexable": true, "report_reasons": null, "author": "anabaranamarana", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15osdo1/whats_the_best_pathway_for_becoming_a_senior_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15osdo1/whats_the_best_pathway_for_becoming_a_senior_data/", "subreddit_subscribers": 122271, "created_utc": 1691807469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any recommended course/courses for statistical data analysis &amp; Interpretation that have good theory and practical examples to solidify knowledge?\nI\u2019m looking to increase my skillset in extracting insights &amp; trends from the data I have with the right mathematical methods.", "author_fullname": "t2_5i2tn33k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Interpretation &amp; Analysis courses", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15omvsr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691792954.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any recommended course/courses for statistical data analysis &amp;amp; Interpretation that have good theory and practical examples to solidify knowledge?\nI\u2019m looking to increase my skillset in extracting insights &amp;amp; trends from the data I have with the right mathematical methods.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15omvsr", "is_robot_indexable": true, "report_reasons": null, "author": "Head-Opportunity7328", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15omvsr/data_interpretation_analysis_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15omvsr/data_interpretation_analysis_courses/", "subreddit_subscribers": 122271, "created_utc": 1691792954.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My boss is super hyped about how they promise to automagically rewrite the ETL from an Informatica/Oracle platform we have and have it work on a cloud data platform.  We had a small demo of the product and the little bit of code I saw looked messy, but no idea what that was from.  Besides the fact that we are also migrating our tech debt, any other impressions from this process?  Did you just get code spit out with no reference to where it came from in the source application?  Did finding the last 10% of stuff that didn't work take you more time than rewriting from scratch?  I am pretty skeptical on these kinds of things so any feedback is appreciated.", "author_fullname": "t2_117fpt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody done a migration with Leaplogic?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ok195", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691786421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My boss is super hyped about how they promise to automagically rewrite the ETL from an Informatica/Oracle platform we have and have it work on a cloud data platform.  We had a small demo of the product and the little bit of code I saw looked messy, but no idea what that was from.  Besides the fact that we are also migrating our tech debt, any other impressions from this process?  Did you just get code spit out with no reference to where it came from in the source application?  Did finding the last 10% of stuff that didn&amp;#39;t work take you more time than rewriting from scratch?  I am pretty skeptical on these kinds of things so any feedback is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ok195", "is_robot_indexable": true, "report_reasons": null, "author": "Gators1992", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ok195/anybody_done_a_migration_with_leaplogic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ok195/anybody_done_a_migration_with_leaplogic/", "subreddit_subscribers": 122271, "created_utc": 1691786421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pretty much the title, I recently started looking into vector databases and it's flowing over my head what even is a multidimensional space and how do you represent it in a computer let alone calculate it's vector\n\nWould be great if someone can provide a link to a simpler explanation because the ones on YouTube just say it's data stored in multidimensional space I want to know what is that multidimensional space how do you represent it etc", "author_fullname": "t2_clgl2jqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I can't wrap my head around multidimensional space and vector databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oi6cf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691782115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much the title, I recently started looking into vector databases and it&amp;#39;s flowing over my head what even is a multidimensional space and how do you represent it in a computer let alone calculate it&amp;#39;s vector&lt;/p&gt;\n\n&lt;p&gt;Would be great if someone can provide a link to a simpler explanation because the ones on YouTube just say it&amp;#39;s data stored in multidimensional space I want to know what is that multidimensional space how do you represent it etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15oi6cf", "is_robot_indexable": true, "report_reasons": null, "author": "BadKarma-18", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oi6cf/i_cant_wrap_my_head_around_multidimensional_space/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oi6cf/i_cant_wrap_my_head_around_multidimensional_space/", "subreddit_subscribers": 122271, "created_utc": 1691782115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have some AWS data related books and resources that involve the Amazon reviews dataset at s3://amazon-reviews-pds, and I'm certain that I've been able to access it in the past. \n\nHowever, now when I try to access it I am getting access errors:\n\n    aws s3 ls s3://amazon-reviews-pds/tsv/\n    \n    An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied\n\nIs this the Mandela effect and I'm misremembering this dataset being there and available?", "author_fullname": "t2_wxoh8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trouble accessing the Amazon reviews dataset in S3. s3://amazon-reviews-pds", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ohj6q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691780631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some AWS data related books and resources that involve the Amazon reviews dataset at s3://amazon-reviews-pds, and I&amp;#39;m certain that I&amp;#39;ve been able to access it in the past. &lt;/p&gt;\n\n&lt;p&gt;However, now when I try to access it I am getting access errors:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;aws s3 ls s3://amazon-reviews-pds/tsv/\n\nAn error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Is this the Mandela effect and I&amp;#39;m misremembering this dataset being there and available?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ohj6q", "is_robot_indexable": true, "report_reasons": null, "author": "tylerjaywood", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ohj6q/trouble_accessing_the_amazon_reviews_dataset_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ohj6q/trouble_accessing_the_amazon_reviews_dataset_in/", "subreddit_subscribers": 122271, "created_utc": 1691780631.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If anyone has experience with data warehouse projects failures and would like to fill in my survey for my thesis. Its only 3 questions and takes only 1 min. Appreciate it! [https://www.survio.com/survey/d/P3N6I3S8J9X2Y4D9U](https://www.survio.com/survey/d/P3N6I3S8J9X2Y4D9U)", "author_fullname": "t2_8mte9pyz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Survey datawarehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oh9na", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691780029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If anyone has experience with data warehouse projects failures and would like to fill in my survey for my thesis. Its only 3 questions and takes only 1 min. Appreciate it! &lt;a href=\"https://www.survio.com/survey/d/P3N6I3S8J9X2Y4D9U\"&gt;https://www.survio.com/survey/d/P3N6I3S8J9X2Y4D9U&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?auto=webp&amp;s=d32302597e6a051095d42ddc6d6bd40738960c3f", "width": 1080, "height": 568}, "resolutions": [{"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d840b37f36aedc3f632442ab76e16f6f4dda566", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3d7e30c2155ef32e3f4381bea1b3e92b6aaf6000", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2e71ad07247492bfafee64085292868956c28352", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4a580e96ba6c79fae1c84757913f869f9164f886", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=667c725db06552318bc67b5f192602dd5280045a", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7d3f863501d04e71f77244864f8ff7faba0b291e", "width": 1080, "height": 568}], "variants": {}, "id": "2xHCw5zDPJw0O7yNG6syCApB7a03gAosm458RLMNPwk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15oh9na", "is_robot_indexable": true, "report_reasons": null, "author": "SnowEcstatic", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oh9na/survey_datawarehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oh9na/survey_datawarehouse/", "subreddit_subscribers": 122271, "created_utc": 1691780029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "On-Prem\n\n\nHello folks \n\nI'm currently working with a data pipeline that involves:\n\nA CentOS system with Docker container running Airflow. Every day, several DAGs execute at dawn, connecting to a PostgreSQL database via API to extract data.\n\nThis data is subsequently transformed using Python scripts which perform various business-related computations, ultimately producing multiple xlsx and csv files stored in directories on CentOS.\n\nIn the morning, several PowerBI dashboards access these files via a Windows VM gateway for publication.\n\nGiven the above, I'm contemplating the need to transition from file-based storage to a more professional setup like a data lake or data warehouse. Due to budget constraints, cloud solutions are off the table. The entire setup is on-premises.\n\nAre there on-premises data lake or data warehouse solutions that would integrate well with the described scenario?\n\nI was thinking about put this files in another postgree containers or minIO maybe, \n\nAnd perhaps I'm over engineering, since it works right now as it is.. \n\n\nThank you for your insights.", "author_fullname": "t2_5rgphe3z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL doubt for improvement On-Prem Data Storage Options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oeqe2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691774224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On-Prem&lt;/p&gt;\n\n&lt;p&gt;Hello folks &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working with a data pipeline that involves:&lt;/p&gt;\n\n&lt;p&gt;A CentOS system with Docker container running Airflow. Every day, several DAGs execute at dawn, connecting to a PostgreSQL database via API to extract data.&lt;/p&gt;\n\n&lt;p&gt;This data is subsequently transformed using Python scripts which perform various business-related computations, ultimately producing multiple xlsx and csv files stored in directories on CentOS.&lt;/p&gt;\n\n&lt;p&gt;In the morning, several PowerBI dashboards access these files via a Windows VM gateway for publication.&lt;/p&gt;\n\n&lt;p&gt;Given the above, I&amp;#39;m contemplating the need to transition from file-based storage to a more professional setup like a data lake or data warehouse. Due to budget constraints, cloud solutions are off the table. The entire setup is on-premises.&lt;/p&gt;\n\n&lt;p&gt;Are there on-premises data lake or data warehouse solutions that would integrate well with the described scenario?&lt;/p&gt;\n\n&lt;p&gt;I was thinking about put this files in another postgree containers or minIO maybe, &lt;/p&gt;\n\n&lt;p&gt;And perhaps I&amp;#39;m over engineering, since it works right now as it is.. &lt;/p&gt;\n\n&lt;p&gt;Thank you for your insights.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15oeqe2", "is_robot_indexable": true, "report_reasons": null, "author": "rafaellelero", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oeqe2/etl_doubt_for_improvement_onprem_data_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oeqe2/etl_doubt_for_improvement_onprem_data_storage/", "subreddit_subscribers": 122271, "created_utc": 1691774224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 2.5+ years of exp in a service based company mainly migrating data from legacy SAS system to big data environment for a financial client using Dataiku. Now the client is offering me an opportunity to switch to client company for a permanent role and continue the project. We are using SparkSQL for data transformations and little amount of Python for data flow automation(date manipulation and flow run). I think I will get low technical guidance as most of the senior developers have less experience with big data technologies.\nFinancially it's a good opportunity but I will not get chance to work on other DE/cloud technologies and I think i will not get good feedbacks on mistakes I am doing from a technical perspective.\nThis is the first time I will switch my job so getting nervous about making a wrong decision.\nI am pursuing IBM data engineering professional course from Coursera and planning to do GCP certifications after this course.\nCould you please advice me if I should go for this offer or wait for better opportunity", "author_fullname": "t2_bnjs6erc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on job offer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oannq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691764638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 2.5+ years of exp in a service based company mainly migrating data from legacy SAS system to big data environment for a financial client using Dataiku. Now the client is offering me an opportunity to switch to client company for a permanent role and continue the project. We are using SparkSQL for data transformations and little amount of Python for data flow automation(date manipulation and flow run). I think I will get low technical guidance as most of the senior developers have less experience with big data technologies.\nFinancially it&amp;#39;s a good opportunity but I will not get chance to work on other DE/cloud technologies and I think i will not get good feedbacks on mistakes I am doing from a technical perspective.\nThis is the first time I will switch my job so getting nervous about making a wrong decision.\nI am pursuing IBM data engineering professional course from Coursera and planning to do GCP certifications after this course.\nCould you please advice me if I should go for this offer or wait for better opportunity&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15oannq", "is_robot_indexable": true, "report_reasons": null, "author": "HearingMajor", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15oannq/need_advice_on_job_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oannq/need_advice_on_job_offer/", "subreddit_subscribers": 122271, "created_utc": 1691764638.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_73d9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TerminusDB vs Neo4j - Graph Database Performance Benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15o8ltv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dIozhhfha_5n1E8nMD6lYz9O8jkAtKYjzovznIySB9o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691759588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "terminusdb.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://terminusdb.com/blog/graph-database-performance-benchmark/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?auto=webp&amp;s=bff1f3fcca8a981f1127eae785c69a5e2c590a4b", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b6aa938e31850a8f289e3e852367ebe23c474809", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7f7b42256ca55c46c8acab2f0002e5aafbb2ae52", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=26f3fc7bd297d3c4d7afaae42e6584eaa51ef1b4", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4e3284e9b725de75aa43525886bb637c4fe39db", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9c196340fa508fe4413688b43dffee7a807abff5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=07dcaaf8b61bef9cbeeeb6cc96abbebe74f0f6c4", "width": 1080, "height": 567}], "variants": {}, "id": "QAkbE8lTgs4X_xITut4Ph_jglvAUljTec3N-pGtmQ1E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15o8ltv", "is_robot_indexable": true, "report_reasons": null, "author": "GavinMendelGleason", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o8ltv/terminusdb_vs_neo4j_graph_database_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://terminusdb.com/blog/graph-database-performance-benchmark/", "subreddit_subscribers": 122271, "created_utc": 1691759588.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}