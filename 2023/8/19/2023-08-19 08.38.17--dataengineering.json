{"kind": "Listing", "data": {"after": "t3_15v8im4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been a Data Engineer for some years now and wondering what kind of career possibilities there are from here onwards.\n\nThe way I am thinking myself is that I have two possible paths, (1) go towards a more architect role in a consulting company, meaning more of a technical sales role including tech selection, drawing archtecture blueprints and not participating so much in the actual coding/implementation. The other path (2) I see is to transition into a more business-focused inhouse product owner role including working closer with business to identify and suggest new use-cases for analytics and linking those investments and activities to actual business value.\n\nWhat experiences does others have and would you rather go with option 1 or 2? Or are there other options I am not considering?", "author_fullname": "t2_ves1in2k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does the career go from Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15umpgh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 59, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 59, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692370336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a Data Engineer for some years now and wondering what kind of career possibilities there are from here onwards.&lt;/p&gt;\n\n&lt;p&gt;The way I am thinking myself is that I have two possible paths, (1) go towards a more architect role in a consulting company, meaning more of a technical sales role including tech selection, drawing archtecture blueprints and not participating so much in the actual coding/implementation. The other path (2) I see is to transition into a more business-focused inhouse product owner role including working closer with business to identify and suggest new use-cases for analytics and linking those investments and activities to actual business value.&lt;/p&gt;\n\n&lt;p&gt;What experiences does others have and would you rather go with option 1 or 2? Or are there other options I am not considering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15umpgh", "is_robot_indexable": true, "report_reasons": null, "author": "EzPzData", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15umpgh/where_does_the_career_go_from_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15umpgh/where_does_the_career_go_from_data_engineering/", "subreddit_subscribers": 123536, "created_utc": 1692370336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been a data engineer for almost 5 years, with 2 of those years at a well known tech company.  Every now and then, I check the job postings in my city and I'm still seeing very few data engineering job postings compared to the last time I was looking for a job.\n\n\n\n\nRight now, what jobs are out there for an experienced data engineer?  I work a lot in python, SQL, and I'm pretty experienced in using one of the major cloud providers.  I also am pretty interested in devops work, but I'm not seeing a lot of job postings.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What jobs are out there for an experienced data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ui4jj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692358702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been a data engineer for almost 5 years, with 2 of those years at a well known tech company.  Every now and then, I check the job postings in my city and I&amp;#39;m still seeing very few data engineering job postings compared to the last time I was looking for a job.&lt;/p&gt;\n\n&lt;p&gt;Right now, what jobs are out there for an experienced data engineer?  I work a lot in python, SQL, and I&amp;#39;m pretty experienced in using one of the major cloud providers.  I also am pretty interested in devops work, but I&amp;#39;m not seeing a lot of job postings.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ui4jj", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15ui4jj/what_jobs_are_out_there_for_an_experienced_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ui4jj/what_jobs_are_out_there_for_an_experienced_data/", "subreddit_subscribers": 123536, "created_utc": 1692358702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With the modern data stack brimming with new tools every month, it's hard to keep a track which one to use for what. The lack of comparative PoVs make selecting the right one quite challenging.\n\nHere's my attempt at weighing the four popular options for doing \"EL\" in \"ELT\" with code examples.  \nHope it's useful to you! Feedback is most welcome.\n\nLink: [https://rxhl.notion.site/Decoding-the-EL-in-ELT-f3f56ed7e2d947c0b1618b5bee293256](https://rxhl.notion.site/Decoding-the-EL-in-ELT-f3f56ed7e2d947c0b1618b5bee293256)  \n\n\n*PS: I understand Prefect and Dagster are technically orchestrators*", "author_fullname": "t2_46gk0vfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing Fivetran, Airbyte, Prefect, and Dagster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uivp5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692360756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the modern data stack brimming with new tools every month, it&amp;#39;s hard to keep a track which one to use for what. The lack of comparative PoVs make selecting the right one quite challenging.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my attempt at weighing the four popular options for doing &amp;quot;EL&amp;quot; in &amp;quot;ELT&amp;quot; with code examples.&lt;br/&gt;\nHope it&amp;#39;s useful to you! Feedback is most welcome.&lt;/p&gt;\n\n&lt;p&gt;Link: &lt;a href=\"https://rxhl.notion.site/Decoding-the-EL-in-ELT-f3f56ed7e2d947c0b1618b5bee293256\"&gt;https://rxhl.notion.site/Decoding-the-EL-in-ELT-f3f56ed7e2d947c0b1618b5bee293256&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;PS: I understand Prefect and Dagster are technically orchestrators&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?auto=webp&amp;s=c1af0b249d3ef4189279de5b5cd862c886e5c5dc", "width": 2000, "height": 463}, "resolutions": [{"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d9d4f8c84e113e6e9aae61a2a95a49ca18f52325", "width": 108, "height": 25}, {"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba293fbb2879aa5ca778d34a3781d22f2bd8f8b6", "width": 216, "height": 50}, {"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f45e08630ee0763daa062512ac0ff16f04aed3fb", "width": 320, "height": 74}, {"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9db5b40b75633aeaf1ebb7ca15cc8ecf6aadb3a5", "width": 640, "height": 148}, {"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5d1ca2841466b21c5bd7d382d662461d772ad9b0", "width": 960, "height": 222}, {"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=451acd01268e0baa2e2d0d66dda4826eb40e4db9", "width": 1080, "height": 250}], "variants": {}, "id": "MJbpc4tdeHmtiE-0bcjDlr6KfXicV1XSF4U91jtzuPU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15uivp5", "is_robot_indexable": true, "report_reasons": null, "author": "AllDayIDreamOfSummer", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15uivp5/comparing_fivetran_airbyte_prefect_and_dagster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15uivp5/comparing_fivetran_airbyte_prefect_and_dagster/", "subreddit_subscribers": 123536, "created_utc": 1692360756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building an Outbound Reporting Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15up7sr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KpdEBteMhLBi2hUJqWWdAd6v5gFIcVo9eEdj1frzrcs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692376069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dagster.io/blog/outbound-reporting-pipeline", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?auto=webp&amp;s=72686767b15662368d9ec84f59112f99d4f8441a", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f4154a23b820b0e890ed552392c4510a6456803", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=00116f5c39ba0a0166baf31af916325bce4839fa", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c66a979c278aeb7c2dbcfd99768d6ec1e3e7d70", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aef3397f43259c21ebf7543947175d0934dca9e7", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ed0385ddc94bd27576176462fc888987215f3a78", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9217417879a433c66abeccf74505f3db658104ed", "width": 1080, "height": 567}], "variants": {}, "id": "xiZFgMkTRczsuWo35ju_Nk4QMlxc6g6KqwxkL2EmCuU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15up7sr", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15up7sr/building_an_outbound_reporting_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dagster.io/blog/outbound-reporting-pipeline", "subreddit_subscribers": 123536, "created_utc": 1692376069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are you able to fully rebuild the various layers of data models that your team has built from raw data that you still have access to? \n\nHow do you handle data from source systems that ~~get delivered from outside sources but overwritten that are outside of your teams control?~~ you are unable to capture full data-change events for?", "author_fullname": "t2_ofoc42j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is your EDW fully rebuildable from stored raw data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ulynz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692386807.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692368572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are you able to fully rebuild the various layers of data models that your team has built from raw data that you still have access to? &lt;/p&gt;\n\n&lt;p&gt;How do you handle data from source systems that &lt;del&gt;get delivered from outside sources but overwritten that are outside of your teams control?&lt;/del&gt; you are unable to capture full data-change events for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ulynz", "is_robot_indexable": true, "report_reasons": null, "author": "PangeanPrawn", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ulynz/is_your_edw_fully_rebuildable_from_stored_raw_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ulynz/is_your_edw_fully_rebuildable_from_stored_raw_data/", "subreddit_subscribers": 123536, "created_utc": 1692368572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've about 1 year experience as software engineer working on data migration projects in an consulting company. Although have 6 months experience as machine learning engineer, but that mostly focus on monitor and maintaining the ETL pipeline on docker containers.\n\nI've never work on big data infrastructure before, so not familiar with framework like Spark, Hadoop and cloud services like GCP &amp; AWS. Neither do I master in data modeling and data warehouse design.\n\nFrom my work experience, the only related experience is the data migration part, and I've taken some few DE interview before, other than the working experience questions, mostly they asked is SQL and DSA questions.\n\n&amp;#x200B;\n\nSQL questions I could prepare myself, and I'm studying DSA with the course on Leetcode, I believe these 2 coding questions is essential for any DE interview. As for other DE knowledge questions like data modeling, data  warehousing design and data architecture concept, I decide to take study those fundementals after I starting to send applications.\n\nI think since I may not be able to master actual DE experiences, focus more on hard skills like DSA and SQL, and study basics on DE knowledges.\n\n&amp;#x200B;\n\nWould that get me a chance to get a DE job?\n\nWould DE interviews take serious on DE fundemental knowledges? Would it be sufficient to pass an interview if I perform well on coding questions?\n\n&amp;#x200B;\n\nThanks for any advice and sharing!", "author_fullname": "t2_11cquw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is DSA and SQL sufficient for preparing an DE interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15v50wk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692415688.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve about 1 year experience as software engineer working on data migration projects in an consulting company. Although have 6 months experience as machine learning engineer, but that mostly focus on monitor and maintaining the ETL pipeline on docker containers.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve never work on big data infrastructure before, so not familiar with framework like Spark, Hadoop and cloud services like GCP &amp;amp; AWS. Neither do I master in data modeling and data warehouse design.&lt;/p&gt;\n\n&lt;p&gt;From my work experience, the only related experience is the data migration part, and I&amp;#39;ve taken some few DE interview before, other than the working experience questions, mostly they asked is SQL and DSA questions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;SQL questions I could prepare myself, and I&amp;#39;m studying DSA with the course on Leetcode, I believe these 2 coding questions is essential for any DE interview. As for other DE knowledge questions like data modeling, data  warehousing design and data architecture concept, I decide to take study those fundementals after I starting to send applications.&lt;/p&gt;\n\n&lt;p&gt;I think since I may not be able to master actual DE experiences, focus more on hard skills like DSA and SQL, and study basics on DE knowledges.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Would that get me a chance to get a DE job?&lt;/p&gt;\n\n&lt;p&gt;Would DE interviews take serious on DE fundemental knowledges? Would it be sufficient to pass an interview if I perform well on coding questions?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for any advice and sharing!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15v50wk", "is_robot_indexable": true, "report_reasons": null, "author": "Laurence-Lin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15v50wk/is_dsa_and_sql_sufficient_for_preparing_an_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15v50wk/is_dsa_and_sql_sufficient_for_preparing_an_de/", "subreddit_subscribers": 123536, "created_utc": 1692415688.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sort of a niche question for this subreddit but I'm curious. To preface, I recently was reached out to by a local company and went through a couple rounds of interviews for a DE position I thought would be a great fit and provide me some growth. Each round went really well, the final round even went an extra half hour because we ended up having a great conversation about my experience. After the final round I was told I should hear something within 2 days. It's now been 4 days and I'm anxious wondering if anything will materialize or not. According to the recruiter, all info regarding my interviews has been pushed up to Senior level management and we're just waiting now. It's been my experience that when a company wants to hire you they don't wait long after the final interview to issue an offer. What have others experienced?", "author_fullname": "t2_556jqozb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Typically how long after a final interview have you waited to hear back regarding an offer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ul6fx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692366716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sort of a niche question for this subreddit but I&amp;#39;m curious. To preface, I recently was reached out to by a local company and went through a couple rounds of interviews for a DE position I thought would be a great fit and provide me some growth. Each round went really well, the final round even went an extra half hour because we ended up having a great conversation about my experience. After the final round I was told I should hear something within 2 days. It&amp;#39;s now been 4 days and I&amp;#39;m anxious wondering if anything will materialize or not. According to the recruiter, all info regarding my interviews has been pushed up to Senior level management and we&amp;#39;re just waiting now. It&amp;#39;s been my experience that when a company wants to hire you they don&amp;#39;t wait long after the final interview to issue an offer. What have others experienced?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ul6fx", "is_robot_indexable": true, "report_reasons": null, "author": "MasterKluch", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ul6fx/typically_how_long_after_a_final_interview_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ul6fx/typically_how_long_after_a_final_interview_have/", "subreddit_subscribers": 123536, "created_utc": 1692366716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're in the midst of integrating GitLab with our MS SQL database, and we've come across a critical decision point - our branching strategy.\n\nWe have two options:\n\n1. **Task-based branching**: a separate branch for each individual task or feature.\n2. **Engineer-based branching**: a separate branch for each data engineer on our team\n\nWhich approach do you believe is the best and why? \n\nCheers!\n\n&amp;#x200B;", "author_fullname": "t2_8u34pgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "git Branching approach", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ukyqw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692366199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re in the midst of integrating GitLab with our MS SQL database, and we&amp;#39;ve come across a critical decision point - our branching strategy.&lt;/p&gt;\n\n&lt;p&gt;We have two options:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Task-based branching&lt;/strong&gt;: a separate branch for each individual task or feature.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Engineer-based branching&lt;/strong&gt;: a separate branch for each data engineer on our team&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Which approach do you believe is the best and why? &lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ukyqw", "is_robot_indexable": true, "report_reasons": null, "author": "Sa1kon", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ukyqw/git_branching_approach/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ukyqw/git_branching_approach/", "subreddit_subscribers": 123536, "created_utc": 1692366199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recently got an interview with a company that is looking for Azure DevOps Release Engineer. They want someone with DevOps background as well as Azure Synapse. \n\nI have basic understanding of DevOps and I\u2019ve set up Azure CI/CD for my organization but outside of that I\u2019m totally clueless on how to even prepare for this interview or what a DevOps/Data Engineer does on a day to day. \n\nMy understanding is they are looking for someone to manage their infrastructure and help migrate to Azure Synapse. Would this be more DataOps? \n\nIf someone can guide me to books or resources; I\u2019d appreciate it!", "author_fullname": "t2_27dn3kh3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone do DevOps as a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uljw3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692367570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently got an interview with a company that is looking for Azure DevOps Release Engineer. They want someone with DevOps background as well as Azure Synapse. &lt;/p&gt;\n\n&lt;p&gt;I have basic understanding of DevOps and I\u2019ve set up Azure CI/CD for my organization but outside of that I\u2019m totally clueless on how to even prepare for this interview or what a DevOps/Data Engineer does on a day to day. &lt;/p&gt;\n\n&lt;p&gt;My understanding is they are looking for someone to manage their infrastructure and help migrate to Azure Synapse. Would this be more DataOps? &lt;/p&gt;\n\n&lt;p&gt;If someone can guide me to books or resources; I\u2019d appreciate it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15uljw3", "is_robot_indexable": true, "report_reasons": null, "author": "LackToesToddlerAnts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15uljw3/anyone_do_devops_as_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15uljw3/anyone_do_devops_as_a_data_engineer/", "subreddit_subscribers": 123536, "created_utc": 1692367570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My data developers team develops data products for the organization's external customers - errors in data in production are a serious problem and we want to create more confidence in that matter.\nIn terms of the stack today we use Snowflake, airflow.\n\nIn the last few weeks we came to the conclusion that we want to add another layer of tests as part of the ETL process before we push the job to production.\nWe are trying to understand if there is a way to produce automatic tests that verify the written logic as well as the data content.\nHas anyone managed to implement/build a similar tool? And can shed some light on do and don't?The tools you use? The types of tests you make?\nThanks", "author_fullname": "t2_5soahcizy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Test Data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15utyy7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692387173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My data developers team develops data products for the organization&amp;#39;s external customers - errors in data in production are a serious problem and we want to create more confidence in that matter.\nIn terms of the stack today we use Snowflake, airflow.&lt;/p&gt;\n\n&lt;p&gt;In the last few weeks we came to the conclusion that we want to add another layer of tests as part of the ETL process before we push the job to production.\nWe are trying to understand if there is a way to produce automatic tests that verify the written logic as well as the data content.\nHas anyone managed to implement/build a similar tool? And can shed some light on do and don&amp;#39;t?The tools you use? The types of tests you make?\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15utyy7", "is_robot_indexable": true, "report_reasons": null, "author": "Classic-Interview503", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15utyy7/how_to_test_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15utyy7/how_to_test_data/", "subreddit_subscribers": 123536, "created_utc": 1692387173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been working as a data engineer for the past 3 years and still don\u2019t know how to do this \ud83d\ude48", "author_fullname": "t2_j33i3nha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best way to learn how to optimize ETL pipelines and complex queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uqltg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692379292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been working as a data engineer for the past 3 years and still don\u2019t know how to do this \ud83d\ude48&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15uqltg", "is_robot_indexable": true, "report_reasons": null, "author": "CS_throwaway_DE", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15uqltg/what_is_the_best_way_to_learn_how_to_optimize_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15uqltg/what_is_the_best_way_to_learn_how_to_optimize_etl/", "subreddit_subscribers": 123536, "created_utc": 1692379292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m starting a new position as a data engineer and my manager wants me to implement data quality in all data pipelines. We have a cloud data lake that uses landing-bronze-silver-gold layers.   \n\n\nInitially I thought of doing this from landing layer to bronze layer using DeeQu.\n\nWhat other tools do you suggest for use? Or what approaches do you use when doing data quality?", "author_fullname": "t2_ei3tpd4w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tools to use for data quality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ulop6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692367885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m starting a new position as a data engineer and my manager wants me to implement data quality in all data pipelines. We have a cloud data lake that uses landing-bronze-silver-gold layers.   &lt;/p&gt;\n\n&lt;p&gt;Initially I thought of doing this from landing layer to bronze layer using DeeQu.&lt;/p&gt;\n\n&lt;p&gt;What other tools do you suggest for use? Or what approaches do you use when doing data quality?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ulop6", "is_robot_indexable": true, "report_reasons": null, "author": "OdiumPura", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ulop6/tools_to_use_for_data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ulop6/tools_to_use_for_data_quality/", "subreddit_subscribers": 123536, "created_utc": 1692367885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Data Fellows, I've been working my side hustle on a series of projects where I handle data collection, ETL, and visualization for various clients. Until now, my workflow has been straightforward: I collect data via applications, store it in Google Sheets, and then visualize it using Google Data Studio. However, as the number of projects increases each month, I realize that this approach might not be scalable in the long run.\n\n**Background**:\n\n* I predominantly work with smaller datasets, usually ranging from 1000 to 5000 rows of data annually per project.\n* My primary coding language is Python.\n* I am familiar with cloud platforms like AWS and GCP and am open to migrating between them or adopting new ones if it provides a better solution.\n* **Budget**: I am willing to invest $100-200 per month to streamline and scale my projects, especially as they grow in volume.\n\n**Current Workflow**:\n\n1. Data Collection: Using platforms like AppSheet to gather data.\n2. Data Storage: Store data in Google Sheets.\n3. ETL: Minor transformations, mostly within Google Sheets itself.\n4. Visualization: Use Google Data Studio to create dashboards from the Google Sheets data.\n\n**Goals**:\n\n1. Automate and scale the ETL process, especially given the increasing volume of projects.\n2. Explore better storage solutions that are more scalable than Google Sheets.\n3. Maintain or improve the ease of creating dashboards.\n4. Leverage Python and cloud platforms to streamline the process.\n\nGiven this context and my budget constraints, I'd love to hear any recommendations or best practices you all might have. Specifically, what tools or platforms would best serve my needs without breaking the bank? How can I make the entire process more scalable and efficient? If you want any more information about the project, feel free to ask.", "author_fullname": "t2_akunr53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on scaling and automating my data pipeline &amp; dashboard projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15v74f9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692422413.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Data Fellows, I&amp;#39;ve been working my side hustle on a series of projects where I handle data collection, ETL, and visualization for various clients. Until now, my workflow has been straightforward: I collect data via applications, store it in Google Sheets, and then visualize it using Google Data Studio. However, as the number of projects increases each month, I realize that this approach might not be scalable in the long run.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I predominantly work with smaller datasets, usually ranging from 1000 to 5000 rows of data annually per project.&lt;/li&gt;\n&lt;li&gt;My primary coding language is Python.&lt;/li&gt;\n&lt;li&gt;I am familiar with cloud platforms like AWS and GCP and am open to migrating between them or adopting new ones if it provides a better solution.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Budget&lt;/strong&gt;: I am willing to invest $100-200 per month to streamline and scale my projects, especially as they grow in volume.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Current Workflow&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Collection: Using platforms like AppSheet to gather data.&lt;/li&gt;\n&lt;li&gt;Data Storage: Store data in Google Sheets.&lt;/li&gt;\n&lt;li&gt;ETL: Minor transformations, mostly within Google Sheets itself.&lt;/li&gt;\n&lt;li&gt;Visualization: Use Google Data Studio to create dashboards from the Google Sheets data.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Goals&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Automate and scale the ETL process, especially given the increasing volume of projects.&lt;/li&gt;\n&lt;li&gt;Explore better storage solutions that are more scalable than Google Sheets.&lt;/li&gt;\n&lt;li&gt;Maintain or improve the ease of creating dashboards.&lt;/li&gt;\n&lt;li&gt;Leverage Python and cloud platforms to streamline the process.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Given this context and my budget constraints, I&amp;#39;d love to hear any recommendations or best practices you all might have. Specifically, what tools or platforms would best serve my needs without breaking the bank? How can I make the entire process more scalable and efficient? If you want any more information about the project, feel free to ask.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15v74f9", "is_robot_indexable": true, "report_reasons": null, "author": "north_pr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15v74f9/need_advice_on_scaling_and_automating_my_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15v74f9/need_advice_on_scaling_and_automating_my_data/", "subreddit_subscribers": 123536, "created_utc": 1692422413.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone, \n\nI wanted to ask the community here if anyone has got recommendations for database management tools that integrates well with DevOps pipeline. I have used schemachange for Snowflake where we deployed warehouses, roles, databases and few tables using schemachange.   \nThe problem with schemachange that I felt was that the definition of an object could potentially end up spanning multiple files. For example, a warehouse initially defined as XS in V1.1 and then an update to M in V1.2 and so on. The way i see it is that this could become s a nightmare of mess of files when managing a large data platform.   \nI'm looking to find a tool where if I can update definitions in one place and the tool does the magic of detecting if the warehouse already exists and if yes, automatically run the alter command rather than me having to write an alter command. This logic should be extensible to alter other objects too. I'm thinking something closer to CloudFormation or TF like tool for SQL.   \nI have tried TF for Snowflake and found myself writing heaps of HCL code for something that can be done in relatively few lines of SQL. \n\nAlso, if there is anyone who thinks there is no use case for a tool, why is that, IWTL? ", "author_fullname": "t2_dv4ply58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL tool for Infrastructure as Code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15v1jap", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692405639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, &lt;/p&gt;\n\n&lt;p&gt;I wanted to ask the community here if anyone has got recommendations for database management tools that integrates well with DevOps pipeline. I have used schemachange for Snowflake where we deployed warehouses, roles, databases and few tables using schemachange.&lt;br/&gt;\nThe problem with schemachange that I felt was that the definition of an object could potentially end up spanning multiple files. For example, a warehouse initially defined as XS in V1.1 and then an update to M in V1.2 and so on. The way i see it is that this could become s a nightmare of mess of files when managing a large data platform.&lt;br/&gt;\nI&amp;#39;m looking to find a tool where if I can update definitions in one place and the tool does the magic of detecting if the warehouse already exists and if yes, automatically run the alter command rather than me having to write an alter command. This logic should be extensible to alter other objects too. I&amp;#39;m thinking something closer to CloudFormation or TF like tool for SQL.&lt;br/&gt;\nI have tried TF for Snowflake and found myself writing heaps of HCL code for something that can be done in relatively few lines of SQL. &lt;/p&gt;\n\n&lt;p&gt;Also, if there is anyone who thinks there is no use case for a tool, why is that, IWTL? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15v1jap", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous_Apple_420", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15v1jap/sql_tool_for_infrastructure_as_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15v1jap/sql_tool_for_infrastructure_as_code/", "subreddit_subscribers": 123536, "created_utc": 1692405639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\ud83d\udce3 We've just released Apache Airflow 2.7.0 \ud83c\udf89\n\n&amp;#x200B;\n\nhttps://preview.redd.it/i7jgql03swib1.jpg?width=1828&amp;format=pjpg&amp;auto=webp&amp;s=73d8a21c04b7bc1d72a8e75f61319f04310e7043\n\n&amp;#x200B;\n\nhttps://preview.redd.it/btzg9no3swib1.png?width=1263&amp;format=png&amp;auto=webp&amp;s=64e2a7ae8d560632bc5c5d644db877864fae254b\n\nNew features include:\n\n\u2705 Setup and Teardown tasks\n\n\u2705 Cluster Activity UI\n\n\u2705 Built-in integration\u00a0for OpenLineage\n\n\u2705 Allow Enable deferrable mode by default for all deferable tasks\n\n&amp;#x200B;\n\n\ud83d\udce6 PyPI:  [https://pypi.org/project/apache-airflow/2.7.0/](https://pypi.org/project/apache-airflow/2.7.0/)\n\n\ud83d\udcda Docs:\u00a0[https://airflow.apache.org/docs/apache-airflow/2.7.0/](https://airflow.apache.org/docs/apache-airflow/2.7.0/)\n\n\ud83d\udee0 Release Notes: [https://airflow.apache.org/docs/apache-airflow/2.7.0/release\\_notes.html](https://airflow.apache.org/docs/apache-airflow/2.7.0/release_notes.html)\n\n\ud83d\udc33 Docker Image: \"docker pull apache/airflow:2.7.0\"\n\n\ud83d\udcc3 Blog Post: [https://airflow.apache.org/blog/airflow-2.7.0/](https://airflow.apache.org/blog/airflow-2.7.0/)", "author_fullname": "t2_178qu6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Airflow 2.7.0", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"btzg9no3swib1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/btzg9no3swib1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a1520fbad3473d0667abeef72864764cfe351bad"}, {"y": 174, "x": 216, "u": "https://preview.redd.it/btzg9no3swib1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6059df679eeaed1d55b03d0472094cd2e5853e7c"}, {"y": 258, "x": 320, "u": "https://preview.redd.it/btzg9no3swib1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d66b085120762bdad7a59cfa8cc4edfb8984d7cc"}, {"y": 516, "x": 640, "u": "https://preview.redd.it/btzg9no3swib1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aeda4a88bd33fbcdf06ada8879624a280e5c25ef"}, {"y": 775, "x": 960, "u": "https://preview.redd.it/btzg9no3swib1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3958e5c7df70129524f5a12ebcc80d568d3788ae"}, {"y": 872, "x": 1080, "u": "https://preview.redd.it/btzg9no3swib1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=15b1d129b574ba64e39567f33816fbdcf584f858"}], "s": {"y": 1020, "x": 1263, "u": "https://preview.redd.it/btzg9no3swib1.png?width=1263&amp;format=png&amp;auto=webp&amp;s=64e2a7ae8d560632bc5c5d644db877864fae254b"}, "id": "btzg9no3swib1"}, "i7jgql03swib1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f8131b71e0f4c2c54d87c9f605b3553a0cd2f3b8"}, {"y": 111, "x": 216, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e529b2688ac002fd47fd942780ad024b90f9de18"}, {"y": 164, "x": 320, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1050c5976b8719cb21057402ab5e4a0c2044e36e"}, {"y": 329, "x": 640, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=964c2a238d54141041b8d966972c7663053d15d2"}, {"y": 493, "x": 960, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=31ecddf54a80d530144c0295898ef0a052be6bf9"}, {"y": 555, "x": 1080, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8f0d3bf351664a336332e13a1a954922b9b8916d"}], "s": {"y": 940, "x": 1828, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=1828&amp;format=pjpg&amp;auto=webp&amp;s=73d8a21c04b7bc1d72a8e75f61319f04310e7043"}, "id": "i7jgql03swib1"}}, "name": "t3_15urns3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/t6MfV7G0gvk5my6aRqwWugcSdtroL217KNERnWjeDag.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692381772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\ud83d\udce3 We&amp;#39;ve just released Apache Airflow 2.7.0 \ud83c\udf89&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/i7jgql03swib1.jpg?width=1828&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=73d8a21c04b7bc1d72a8e75f61319f04310e7043\"&gt;https://preview.redd.it/i7jgql03swib1.jpg?width=1828&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=73d8a21c04b7bc1d72a8e75f61319f04310e7043&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/btzg9no3swib1.png?width=1263&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=64e2a7ae8d560632bc5c5d644db877864fae254b\"&gt;https://preview.redd.it/btzg9no3swib1.png?width=1263&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=64e2a7ae8d560632bc5c5d644db877864fae254b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;New features include:&lt;/p&gt;\n\n&lt;p&gt;\u2705 Setup and Teardown tasks&lt;/p&gt;\n\n&lt;p&gt;\u2705 Cluster Activity UI&lt;/p&gt;\n\n&lt;p&gt;\u2705 Built-in integration\u00a0for OpenLineage&lt;/p&gt;\n\n&lt;p&gt;\u2705 Allow Enable deferrable mode by default for all deferable tasks&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udce6 PyPI:  &lt;a href=\"https://pypi.org/project/apache-airflow/2.7.0/\"&gt;https://pypi.org/project/apache-airflow/2.7.0/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcda Docs:\u00a0&lt;a href=\"https://airflow.apache.org/docs/apache-airflow/2.7.0/\"&gt;https://airflow.apache.org/docs/apache-airflow/2.7.0/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udee0 Release Notes: &lt;a href=\"https://airflow.apache.org/docs/apache-airflow/2.7.0/release_notes.html\"&gt;https://airflow.apache.org/docs/apache-airflow/2.7.0/release_notes.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udc33 Docker Image: &amp;quot;docker pull apache/airflow:2.7.0&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcc3 Blog Post: &lt;a href=\"https://airflow.apache.org/blog/airflow-2.7.0/\"&gt;https://airflow.apache.org/blog/airflow-2.7.0/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15urns3", "is_robot_indexable": true, "report_reasons": null, "author": "kaxil_naik", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15urns3/apache_airflow_270/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15urns3/apache_airflow_270/", "subreddit_subscribers": 123536, "created_utc": 1692381772.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently manage a data analytics team at a tech company. Our Data Engineering team is practically non existent as a support function (in my opinion - b/c anytime I ask for support, they send me google how to articles and expect us to figure it out) to our team so we end up building our own schema, building data marts, maintaining and documenting them, etc.  My team primarily uses SQL, Python, DBT, Tableau and Tableau Prep for all of our work.\n\nAs of recent, there has been a push from leadership to expand and focus on data engineering more and my team has been a fly on the wall in the interview process.\n\nI'm not sure if I'm just not familiar enough with Data Engineering or if my thoughts are justified here but it strikes me that these interviews are searching for the absolute perfect candidate with all of these technical experiences / skills (which I doubt they even use all of those tools) and are hyper critical of the smallest flaw in a candidate.  As a downstream consumer of the Data Engineering team, the bar is so low that I personally wouldn't be hyper critical on the lack of a technical skill but rather a personality type / willingness to learn.\n\nThey have passed up on numerous candidates and I feel like I'm spending half of my time just watching these very dry and technical focused interviews when all we need is some basic data modeling skills and common sense in my opinion.\n\nAny time I voice this opinion, there is definitely a response in the realm of \"you are not a Data Engineer so you don't understand why we're asking all of this\" which can get a bit frustrating.\n\nHas anyone else experienced this before?", "author_fullname": "t2_75f7qjfw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Curious about DE Jobs vs. Interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ul93m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692366898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently manage a data analytics team at a tech company. Our Data Engineering team is practically non existent as a support function (in my opinion - b/c anytime I ask for support, they send me google how to articles and expect us to figure it out) to our team so we end up building our own schema, building data marts, maintaining and documenting them, etc.  My team primarily uses SQL, Python, DBT, Tableau and Tableau Prep for all of our work.&lt;/p&gt;\n\n&lt;p&gt;As of recent, there has been a push from leadership to expand and focus on data engineering more and my team has been a fly on the wall in the interview process.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if I&amp;#39;m just not familiar enough with Data Engineering or if my thoughts are justified here but it strikes me that these interviews are searching for the absolute perfect candidate with all of these technical experiences / skills (which I doubt they even use all of those tools) and are hyper critical of the smallest flaw in a candidate.  As a downstream consumer of the Data Engineering team, the bar is so low that I personally wouldn&amp;#39;t be hyper critical on the lack of a technical skill but rather a personality type / willingness to learn.&lt;/p&gt;\n\n&lt;p&gt;They have passed up on numerous candidates and I feel like I&amp;#39;m spending half of my time just watching these very dry and technical focused interviews when all we need is some basic data modeling skills and common sense in my opinion.&lt;/p&gt;\n\n&lt;p&gt;Any time I voice this opinion, there is definitely a response in the realm of &amp;quot;you are not a Data Engineer so you don&amp;#39;t understand why we&amp;#39;re asking all of this&amp;quot; which can get a bit frustrating.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else experienced this before?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ul93m", "is_robot_indexable": true, "report_reasons": null, "author": "Snoo-74514", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ul93m/curious_about_de_jobs_vs_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ul93m/curious_about_de_jobs_vs_interviews/", "subreddit_subscribers": 123536, "created_utc": 1692366898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently the framework that exists is doing a full load of data into our environment from a lot of different external databases. How can I implement increments to this?. (any specific guides/tutorials)", "author_fullname": "t2_dpc2z7ubu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to implement delta/increments to a table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15v3dhg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692410807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently the framework that exists is doing a full load of data into our environment from a lot of different external databases. How can I implement increments to this?. (any specific guides/tutorials)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15v3dhg", "is_robot_indexable": true, "report_reasons": null, "author": "cyamnihc", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15v3dhg/how_to_implement_deltaincrements_to_a_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15v3dhg/how_to_implement_deltaincrements_to_a_table/", "subreddit_subscribers": 123536, "created_utc": 1692410807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2rku02rf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MotherDuck: Beyond Storing Data: How to Use DuckDB, MotherDuck and Kestra for ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_15uxeb5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pdMJa4YArLpPjjtWRx3A-qKjBMrfT6aW4l0l3dTV9zY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692395230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "motherduck.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://motherduck.com/blog/motherduck-kestra-etl-pipelines/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/42-0Io_nKyqTg_5Y_5otKfEXpAP5qumJtBiAAaF5_Fg.jpg?auto=webp&amp;s=d26c7f2653666ec82242ecc3301d9f1701adad6e", "width": 720, "height": 405}, "resolutions": [{"url": "https://external-preview.redd.it/42-0Io_nKyqTg_5Y_5otKfEXpAP5qumJtBiAAaF5_Fg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0df082023eb53a261a3cf8552f54e3406a40647d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/42-0Io_nKyqTg_5Y_5otKfEXpAP5qumJtBiAAaF5_Fg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=18f05c5e823b114a1e11f10be67d4246ef2ce887", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/42-0Io_nKyqTg_5Y_5otKfEXpAP5qumJtBiAAaF5_Fg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4fb705af81f4e3cb6095620c73cff4171f5356d9", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/42-0Io_nKyqTg_5Y_5otKfEXpAP5qumJtBiAAaF5_Fg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=62cbcf679849fadc3fdbd1b6aa562eda7f52e8df", "width": 640, "height": 360}], "variants": {}, "id": "nOsFKI0KbhqtjcAlrPpqawpLGBzPyf_5-DtQnasRBP8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15uxeb5", "is_robot_indexable": true, "report_reasons": null, "author": "tchiotludo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15uxeb5/motherduck_beyond_storing_data_how_to_use_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://motherduck.com/blog/motherduck-kestra-etl-pipelines/", "subreddit_subscribers": 123536, "created_utc": 1692395230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm using Databricks and I have a job running 100 tasks of the same notebook, but just with a different parameter. For some reason, some tasks fail trying to do a sql query (with 4 retries with a timeout of 1 hr each). I'm confused why it takes so long because the tables it is querying is small (10mb, 1 file, 440k rows) while it takes similar tables only a few seconds. I'm using a 156gb driver and 20gb worker cluster.  \n\n\nCode:\n\ntableName = '...' # taken from job task parameter\n\nminDateDF = spark.sql('select case when min(date) = current\\_date() THEN True ELSE False End as test from test.' + tableName)\n\nminDate = [minDateDF.select](https://minDateDF.select)('test').collect()\\[0\\]\\[0\\]  \n\n\nIs there a better way to query these tables? From the spark ui it says it fails at the minDateDF line. I'm not sure if I'm describing this problem well enough because I can't find a solution online.", "author_fullname": "t2_j4kzc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the appropriate way to get values from a delta table as a variable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uwhns", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692393091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using Databricks and I have a job running 100 tasks of the same notebook, but just with a different parameter. For some reason, some tasks fail trying to do a sql query (with 4 retries with a timeout of 1 hr each). I&amp;#39;m confused why it takes so long because the tables it is querying is small (10mb, 1 file, 440k rows) while it takes similar tables only a few seconds. I&amp;#39;m using a 156gb driver and 20gb worker cluster.  &lt;/p&gt;\n\n&lt;p&gt;Code:&lt;/p&gt;\n\n&lt;p&gt;tableName = &amp;#39;...&amp;#39; # taken from job task parameter&lt;/p&gt;\n\n&lt;p&gt;minDateDF = spark.sql(&amp;#39;select case when min(date) = current_date() THEN True ELSE False End as test from test.&amp;#39; + tableName)&lt;/p&gt;\n\n&lt;p&gt;minDate = &lt;a href=\"https://minDateDF.select\"&gt;minDateDF.select&lt;/a&gt;(&amp;#39;test&amp;#39;).collect()[0][0]  &lt;/p&gt;\n\n&lt;p&gt;Is there a better way to query these tables? From the spark ui it says it fails at the minDateDF line. I&amp;#39;m not sure if I&amp;#39;m describing this problem well enough because I can&amp;#39;t find a solution online.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15uwhns", "is_robot_indexable": true, "report_reasons": null, "author": "bongdong42O", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15uwhns/what_is_the_appropriate_way_to_get_values_from_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15uwhns/what_is_the_appropriate_way_to_get_values_from_a/", "subreddit_subscribers": 123536, "created_utc": 1692393091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vk94wnpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Top 5 questions Data Engineers should ask before joining a startup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15uk91q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/5GRba3S29GvapoSu-84rLfN7PzBMJodGKq0PSKDUIb0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692364393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@jeff.b.chou/top-5-questions-data-engineers-should-ask-before-joining-a-startup-1950ab326250", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?auto=webp&amp;s=b5c572c904e5bfe6ec7f64264a583558fc676188", "width": 1124, "height": 750}, "resolutions": [{"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9dbe8ef3590579b840ab0812520efca6c316d7f3", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4c1d67eaf9d880a91712ff269c752f15b38dcf26", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe02c90ff6976a70d62504961366c5d3c34e73d7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fa6096cc3e8636138eb9a4ced4afc7fddd068264", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=24fe2cbf436c6d684004612aa4a42e7d2666c163", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=68b0a3d64c46c307321f93770b11ddeaa818c3c1", "width": 1080, "height": 720}], "variants": {}, "id": "4qXAzV1KWd3IOdizYWBiIev5U87yEQ98ITv9jJoqIfQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15uk91q", "is_robot_indexable": true, "report_reasons": null, "author": "sync_jeff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15uk91q/top_5_questions_data_engineers_should_ask_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@jeff.b.chou/top-5-questions-data-engineers-should-ask-before-joining-a-startup-1950ab326250", "subreddit_subscribers": 123536, "created_utc": 1692364393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Several people told me the best way to load data from sap to snowflake is Kafka.\nWhy should I do that?\nIsn't a direct connection between sap and snowflake easier?", "author_fullname": "t2_9pyk5rj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why should I use Kafka to load from sap to snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uiqhh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692363236.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692360359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Several people told me the best way to load data from sap to snowflake is Kafka.\nWhy should I do that?\nIsn&amp;#39;t a direct connection between sap and snowflake easier?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15uiqhh", "is_robot_indexable": true, "report_reasons": null, "author": "seayk", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15uiqhh/why_should_i_use_kafka_to_load_from_sap_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15uiqhh/why_should_i_use_kafka_to_load_from_sap_to/", "subreddit_subscribers": 123536, "created_utc": 1692360359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello! Somewhat new to data engineering here :)\n\nI am working on calculating the client's lifetime value. Every day, a batch process loads new events (ex: from the previous day, such as client purchases, calls, etc.), applies some filters and rules, calculates the cost or income arising from each event, allocates it to a financial account and saves the results.\n\nI have a relational OLTP database where the value model is parametrized (what filters to apply, what accounts exist, parent-child relationships, what unit costs should be applied, to what type of events, and so on). This is important because these parameters change and business people are going to maintain them along time (through a front-end connected to this database).\n\nSo far, this seems to work; but it is not clear to me where things should live in practice. Where should I save the results (i.e.: millions of rows containing the events, their calculated value and foreign key references to parameters - such as account key, unit costs, etc.)? This data would be used for aggregation and reporting, so I feel that results should end in a distinct OLAP database, in our Data Warehouse. But then, would parameters and results be in separate databases? This does not make much sense, because analysts need to know info about the account associated to a given event value, as well as the unit costs considered, filters, rules, and so on.\n\nI think I have the following choices:\n\n1. Store parameters and save (millions) of results in the OLTP database. Every day incrementally copy everything to OLAP database for analytics purposes. I end with two exact copies;\n2. Store parameters in OLTP database and save results directly in OLAP. Every day incrementally copy parameters from OLTP to OLAP. I risk consistency problems...\n3. Store parameters in OLTP database and save results directly in OLAP, but include unfolded parameter data (ex: account name, unit costs used for computation, filters, etc) in each result record, instead of foreign keys;\n\nWhat do you guys think? I think 1. is safest, but somehow I feel like it's a \"waste\" to have millions of rows replicated in two databases, especially because the million rows in OLTP serve no purpose except being there to be copied. Option 2. also seems interesting, but if something goes wrong, and parameters are not synched, I may get consistency conflicts.\n\nAny ideas are appreciated!", "author_fullname": "t2_3xswxksvc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to store configuration and results, if both are needed for reporting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ugkal", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692354024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! Somewhat new to data engineering here :)&lt;/p&gt;\n\n&lt;p&gt;I am working on calculating the client&amp;#39;s lifetime value. Every day, a batch process loads new events (ex: from the previous day, such as client purchases, calls, etc.), applies some filters and rules, calculates the cost or income arising from each event, allocates it to a financial account and saves the results.&lt;/p&gt;\n\n&lt;p&gt;I have a relational OLTP database where the value model is parametrized (what filters to apply, what accounts exist, parent-child relationships, what unit costs should be applied, to what type of events, and so on). This is important because these parameters change and business people are going to maintain them along time (through a front-end connected to this database).&lt;/p&gt;\n\n&lt;p&gt;So far, this seems to work; but it is not clear to me where things should live in practice. Where should I save the results (i.e.: millions of rows containing the events, their calculated value and foreign key references to parameters - such as account key, unit costs, etc.)? This data would be used for aggregation and reporting, so I feel that results should end in a distinct OLAP database, in our Data Warehouse. But then, would parameters and results be in separate databases? This does not make much sense, because analysts need to know info about the account associated to a given event value, as well as the unit costs considered, filters, rules, and so on.&lt;/p&gt;\n\n&lt;p&gt;I think I have the following choices:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Store parameters and save (millions) of results in the OLTP database. Every day incrementally copy everything to OLAP database for analytics purposes. I end with two exact copies;&lt;/li&gt;\n&lt;li&gt;Store parameters in OLTP database and save results directly in OLAP. Every day incrementally copy parameters from OLTP to OLAP. I risk consistency problems...&lt;/li&gt;\n&lt;li&gt;Store parameters in OLTP database and save results directly in OLAP, but include unfolded parameter data (ex: account name, unit costs used for computation, filters, etc) in each result record, instead of foreign keys;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What do you guys think? I think 1. is safest, but somehow I feel like it&amp;#39;s a &amp;quot;waste&amp;quot; to have millions of rows replicated in two databases, especially because the million rows in OLTP serve no purpose except being there to be copied. Option 2. also seems interesting, but if something goes wrong, and parameters are not synched, I may get consistency conflicts.&lt;/p&gt;\n\n&lt;p&gt;Any ideas are appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ugkal", "is_robot_indexable": true, "report_reasons": null, "author": "Sure-Examination-824", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ugkal/how_to_store_configuration_and_results_if_both/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ugkal/how_to_store_configuration_and_results_if_both/", "subreddit_subscribers": 123536, "created_utc": 1692354024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im curious to know what all are the optimise techniques for improving SQL databases performance ( not the query alone )?\n\nFew of them would be came to my mind - \n\n1. Partitioning / Sharding\n2. Selecting the right indexes ( BTree )\n3. Optimising the SQL query execution\n\nAnything else that can be added?\n\n&amp;#x200B;", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Database optimisation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uewl7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692348476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im curious to know what all are the optimise techniques for improving SQL databases performance ( not the query alone )?&lt;/p&gt;\n\n&lt;p&gt;Few of them would be came to my mind - &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Partitioning / Sharding&lt;/li&gt;\n&lt;li&gt;Selecting the right indexes ( BTree )&lt;/li&gt;\n&lt;li&gt;Optimising the SQL query execution&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Anything else that can be added?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15uewl7", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15uewl7/sql_database_optimisation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15uewl7/sql_database_optimisation/", "subreddit_subscribers": 123536, "created_utc": 1692348476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Or SWE.\n\nMy field is a bit weird, but I\u2019d probably consider it to be IT work. I\u2019m a consultant and I have a CS degree. I\u2019m sticking with my current job, but I can always move into another contract with a different title like SWE or DE, but I need demonstrated experience and I am unsure if what I am currently doing would qualify as that.\n\nMy team receives tickets with 2 or more record IDs that are associated with people. These record IDs appear to belong to be duplicates by some characteristics, but there are inconsistencies between them. We query those records using an internal web-based tool and compare and determine what data is worth keeping. The tool generates the script for us after all comparisons are done, but sometimes requires some editing. We then submit those scripts so the change can be made. \n\nUsing the web tool is absolutely unbearable, so I created an app using python/flask, JavaScript, and web sockets that rendered ticket information from our excel sheet of tickets and automated everything with selenium aside from the analysis work. Also automated was the transfer of generated sql files, reading the result, and reporting the ticket as completed. What I made pretty much cut out all of the grunt work and doubled my output. \n\nI probably could\u2019ve just done it all in UIPath or Power Automate, but I didn\u2019t want to incur that expense, personally.", "author_fullname": "t2_4w3jkf9z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019m a data analyst doing more app development at work than work. Can I use this to move into DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15v9qn0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692431259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Or SWE.&lt;/p&gt;\n\n&lt;p&gt;My field is a bit weird, but I\u2019d probably consider it to be IT work. I\u2019m a consultant and I have a CS degree. I\u2019m sticking with my current job, but I can always move into another contract with a different title like SWE or DE, but I need demonstrated experience and I am unsure if what I am currently doing would qualify as that.&lt;/p&gt;\n\n&lt;p&gt;My team receives tickets with 2 or more record IDs that are associated with people. These record IDs appear to belong to be duplicates by some characteristics, but there are inconsistencies between them. We query those records using an internal web-based tool and compare and determine what data is worth keeping. The tool generates the script for us after all comparisons are done, but sometimes requires some editing. We then submit those scripts so the change can be made. &lt;/p&gt;\n\n&lt;p&gt;Using the web tool is absolutely unbearable, so I created an app using python/flask, JavaScript, and web sockets that rendered ticket information from our excel sheet of tickets and automated everything with selenium aside from the analysis work. Also automated was the transfer of generated sql files, reading the result, and reporting the ticket as completed. What I made pretty much cut out all of the grunt work and doubled my output. &lt;/p&gt;\n\n&lt;p&gt;I probably could\u2019ve just done it all in UIPath or Power Automate, but I didn\u2019t want to incur that expense, personally.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15v9qn0", "is_robot_indexable": true, "report_reasons": null, "author": "verus54", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15v9qn0/im_a_data_analyst_doing_more_app_development_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15v9qn0/im_a_data_analyst_doing_more_app_development_at/", "subreddit_subscribers": 123536, "created_utc": 1692431259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I been thinking about switching to DE from being a software developer.  I done software development for over 20 years in the Microsoft/Windows stack (C#, ASP.NET, MVC, APIs, SQL Server).  I am decent with SQL, but haven't had a need to do anything complex beyond CTEs.  I only recently started gaining cloud experience in Azure (it took me a long time to an on-the-job cloud role).  I never heard of DE five years ago.  Now, it seems like it is everywhere.  Honestly, I bored especially with the Microsoft stack.\n\nCurrently, I am trying get more familar with Linux, Bash and Advance SQL.  Is DE worth the switch for a long term career?  What tech should I focus on?", "author_fullname": "t2_cr65h2a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is switching to DE worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15v8im4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692427072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I been thinking about switching to DE from being a software developer.  I done software development for over 20 years in the Microsoft/Windows stack (C#, ASP.NET, MVC, APIs, SQL Server).  I am decent with SQL, but haven&amp;#39;t had a need to do anything complex beyond CTEs.  I only recently started gaining cloud experience in Azure (it took me a long time to an on-the-job cloud role).  I never heard of DE five years ago.  Now, it seems like it is everywhere.  Honestly, I bored especially with the Microsoft stack.&lt;/p&gt;\n\n&lt;p&gt;Currently, I am trying get more familar with Linux, Bash and Advance SQL.  Is DE worth the switch for a long term career?  What tech should I focus on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15v8im4", "is_robot_indexable": true, "report_reasons": null, "author": "blackdev17", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15v8im4/is_switching_to_de_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15v8im4/is_switching_to_de_worth_it/", "subreddit_subscribers": 123536, "created_utc": 1692427072.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}