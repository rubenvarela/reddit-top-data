{"kind": "Listing", "data": {"after": "t3_15v1jap", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been a Data Engineer for some years now and wondering what kind of career possibilities there are from here onwards.\n\nThe way I am thinking myself is that I have two possible paths, (1) go towards a more architect role in a consulting company, meaning more of a technical sales role including tech selection, drawing archtecture blueprints and not participating so much in the actual coding/implementation. The other path (2) I see is to transition into a more business-focused inhouse product owner role including working closer with business to identify and suggest new use-cases for analytics and linking those investments and activities to actual business value.\n\nWhat experiences does others have and would you rather go with option 1 or 2? Or are there other options I am not considering?", "author_fullname": "t2_ves1in2k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does the career go from Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15umpgh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692370336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a Data Engineer for some years now and wondering what kind of career possibilities there are from here onwards.&lt;/p&gt;\n\n&lt;p&gt;The way I am thinking myself is that I have two possible paths, (1) go towards a more architect role in a consulting company, meaning more of a technical sales role including tech selection, drawing archtecture blueprints and not participating so much in the actual coding/implementation. The other path (2) I see is to transition into a more business-focused inhouse product owner role including working closer with business to identify and suggest new use-cases for analytics and linking those investments and activities to actual business value.&lt;/p&gt;\n\n&lt;p&gt;What experiences does others have and would you rather go with option 1 or 2? Or are there other options I am not considering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15umpgh", "is_robot_indexable": true, "report_reasons": null, "author": "EzPzData", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15umpgh/where_does_the_career_go_from_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15umpgh/where_does_the_career_go_from_data_engineering/", "subreddit_subscribers": 123498, "created_utc": 1692370336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been a data engineer for almost 5 years, with 2 of those years at a well known tech company.  Every now and then, I check the job postings in my city and I'm still seeing very few data engineering job postings compared to the last time I was looking for a job.\n\n\n\n\nRight now, what jobs are out there for an experienced data engineer?  I work a lot in python, SQL, and I'm pretty experienced in using one of the major cloud providers.  I also am pretty interested in devops work, but I'm not seeing a lot of job postings.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What jobs are out there for an experienced data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ui4jj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692358702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been a data engineer for almost 5 years, with 2 of those years at a well known tech company.  Every now and then, I check the job postings in my city and I&amp;#39;m still seeing very few data engineering job postings compared to the last time I was looking for a job.&lt;/p&gt;\n\n&lt;p&gt;Right now, what jobs are out there for an experienced data engineer?  I work a lot in python, SQL, and I&amp;#39;m pretty experienced in using one of the major cloud providers.  I also am pretty interested in devops work, but I&amp;#39;m not seeing a lot of job postings.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ui4jj", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15ui4jj/what_jobs_are_out_there_for_an_experienced_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ui4jj/what_jobs_are_out_there_for_an_experienced_data/", "subreddit_subscribers": 123498, "created_utc": 1692358702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With the modern data stack brimming with new tools every month, it's hard to keep a track which one to use for what. The lack of comparative PoVs make selecting the right one quite challenging.\n\nHere's my attempt at weighing the four popular options for doing \"EL\" in \"ELT\" with code examples.  \nHope it's useful to you! Feedback is most welcome.\n\nLink: [https://rxhl.notion.site/Decoding-the-EL-in-ELT-f3f56ed7e2d947c0b1618b5bee293256](https://rxhl.notion.site/Decoding-the-EL-in-ELT-f3f56ed7e2d947c0b1618b5bee293256)  \n\n\n*PS: I understand Prefect and Dagster are technically orchestrators*", "author_fullname": "t2_46gk0vfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing Fivetran, Airbyte, Prefect, and Dagster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uivp5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692360756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the modern data stack brimming with new tools every month, it&amp;#39;s hard to keep a track which one to use for what. The lack of comparative PoVs make selecting the right one quite challenging.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my attempt at weighing the four popular options for doing &amp;quot;EL&amp;quot; in &amp;quot;ELT&amp;quot; with code examples.&lt;br/&gt;\nHope it&amp;#39;s useful to you! Feedback is most welcome.&lt;/p&gt;\n\n&lt;p&gt;Link: &lt;a href=\"https://rxhl.notion.site/Decoding-the-EL-in-ELT-f3f56ed7e2d947c0b1618b5bee293256\"&gt;https://rxhl.notion.site/Decoding-the-EL-in-ELT-f3f56ed7e2d947c0b1618b5bee293256&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;PS: I understand Prefect and Dagster are technically orchestrators&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?auto=webp&amp;s=c1af0b249d3ef4189279de5b5cd862c886e5c5dc", "width": 2000, "height": 463}, "resolutions": [{"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d9d4f8c84e113e6e9aae61a2a95a49ca18f52325", "width": 108, "height": 25}, {"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba293fbb2879aa5ca778d34a3781d22f2bd8f8b6", "width": 216, "height": 50}, {"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f45e08630ee0763daa062512ac0ff16f04aed3fb", "width": 320, "height": 74}, {"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9db5b40b75633aeaf1ebb7ca15cc8ecf6aadb3a5", "width": 640, "height": 148}, {"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5d1ca2841466b21c5bd7d382d662461d772ad9b0", "width": 960, "height": 222}, {"url": "https://external-preview.redd.it/zzfPjVG32xkqyA_S0pBJrzitb10N4pEvzSSuF9h11Dk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=451acd01268e0baa2e2d0d66dda4826eb40e4db9", "width": 1080, "height": 250}], "variants": {}, "id": "MJbpc4tdeHmtiE-0bcjDlr6KfXicV1XSF4U91jtzuPU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15uivp5", "is_robot_indexable": true, "report_reasons": null, "author": "AllDayIDreamOfSummer", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15uivp5/comparing_fivetran_airbyte_prefect_and_dagster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15uivp5/comparing_fivetran_airbyte_prefect_and_dagster/", "subreddit_subscribers": 123498, "created_utc": 1692360756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building an Outbound Reporting Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15up7sr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KpdEBteMhLBi2hUJqWWdAd6v5gFIcVo9eEdj1frzrcs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692376069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dagster.io/blog/outbound-reporting-pipeline", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?auto=webp&amp;s=72686767b15662368d9ec84f59112f99d4f8441a", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f4154a23b820b0e890ed552392c4510a6456803", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=00116f5c39ba0a0166baf31af916325bce4839fa", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c66a979c278aeb7c2dbcfd99768d6ec1e3e7d70", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aef3397f43259c21ebf7543947175d0934dca9e7", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ed0385ddc94bd27576176462fc888987215f3a78", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/TpjNnrQvajZ1U2ciVySW3fUK9uns6oY2RE9ib9088h4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9217417879a433c66abeccf74505f3db658104ed", "width": 1080, "height": 567}], "variants": {}, "id": "xiZFgMkTRczsuWo35ju_Nk4QMlxc6g6KqwxkL2EmCuU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15up7sr", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15up7sr/building_an_outbound_reporting_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dagster.io/blog/outbound-reporting-pipeline", "subreddit_subscribers": 123498, "created_utc": 1692376069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are you able to fully rebuild the various layers of data models that your team has built from raw data that you still have access to? \n\nHow do you handle data from source systems that ~~get delivered from outside sources but overwritten that are outside of your teams control?~~ you are unable to capture full data-change events for?", "author_fullname": "t2_ofoc42j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is your EDW fully rebuildable from stored raw data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ulynz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692386807.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692368572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are you able to fully rebuild the various layers of data models that your team has built from raw data that you still have access to? &lt;/p&gt;\n\n&lt;p&gt;How do you handle data from source systems that &lt;del&gt;get delivered from outside sources but overwritten that are outside of your teams control?&lt;/del&gt; you are unable to capture full data-change events for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ulynz", "is_robot_indexable": true, "report_reasons": null, "author": "PangeanPrawn", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ulynz/is_your_edw_fully_rebuildable_from_stored_raw_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ulynz/is_your_edw_fully_rebuildable_from_stored_raw_data/", "subreddit_subscribers": 123498, "created_utc": 1692368572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have started my journey with GCP, I use AWS at work but decided to learn and get certifications for GCP. As for now I have loved the interface and how user friendly it is. Now my question is, why is GCP not so adapted in the market? Will it change in the future ?", "author_fullname": "t2_7sxdmzpt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Started with GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u7o76", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692325880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have started my journey with GCP, I use AWS at work but decided to learn and get certifications for GCP. As for now I have loved the interface and how user friendly it is. Now my question is, why is GCP not so adapted in the market? Will it change in the future ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15u7o76", "is_robot_indexable": true, "report_reasons": null, "author": "felipeHernandez19", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15u7o76/started_with_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15u7o76/started_with_gcp/", "subreddit_subscribers": 123498, "created_utc": 1692325880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sort of a niche question for this subreddit but I'm curious. To preface, I recently was reached out to by a local company and went through a couple rounds of interviews for a DE position I thought would be a great fit and provide me some growth. Each round went really well, the final round even went an extra half hour because we ended up having a great conversation about my experience. After the final round I was told I should hear something within 2 days. It's now been 4 days and I'm anxious wondering if anything will materialize or not. According to the recruiter, all info regarding my interviews has been pushed up to Senior level management and we're just waiting now. It's been my experience that when a company wants to hire you they don't wait long after the final interview to issue an offer. What have others experienced?", "author_fullname": "t2_556jqozb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Typically how long after a final interview have you waited to hear back regarding an offer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ul6fx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692366716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sort of a niche question for this subreddit but I&amp;#39;m curious. To preface, I recently was reached out to by a local company and went through a couple rounds of interviews for a DE position I thought would be a great fit and provide me some growth. Each round went really well, the final round even went an extra half hour because we ended up having a great conversation about my experience. After the final round I was told I should hear something within 2 days. It&amp;#39;s now been 4 days and I&amp;#39;m anxious wondering if anything will materialize or not. According to the recruiter, all info regarding my interviews has been pushed up to Senior level management and we&amp;#39;re just waiting now. It&amp;#39;s been my experience that when a company wants to hire you they don&amp;#39;t wait long after the final interview to issue an offer. What have others experienced?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ul6fx", "is_robot_indexable": true, "report_reasons": null, "author": "MasterKluch", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ul6fx/typically_how_long_after_a_final_interview_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ul6fx/typically_how_long_after_a_final_interview_have/", "subreddit_subscribers": 123498, "created_utc": 1692366716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recently got an interview with a company that is looking for Azure DevOps Release Engineer. They want someone with DevOps background as well as Azure Synapse. \n\nI have basic understanding of DevOps and I\u2019ve set up Azure CI/CD for my organization but outside of that I\u2019m totally clueless on how to even prepare for this interview or what a DevOps/Data Engineer does on a day to day. \n\nMy understanding is they are looking for someone to manage their infrastructure and help migrate to Azure Synapse. Would this be more DataOps? \n\nIf someone can guide me to books or resources; I\u2019d appreciate it!", "author_fullname": "t2_27dn3kh3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone do DevOps as a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uljw3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692367570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently got an interview with a company that is looking for Azure DevOps Release Engineer. They want someone with DevOps background as well as Azure Synapse. &lt;/p&gt;\n\n&lt;p&gt;I have basic understanding of DevOps and I\u2019ve set up Azure CI/CD for my organization but outside of that I\u2019m totally clueless on how to even prepare for this interview or what a DevOps/Data Engineer does on a day to day. &lt;/p&gt;\n\n&lt;p&gt;My understanding is they are looking for someone to manage their infrastructure and help migrate to Azure Synapse. Would this be more DataOps? &lt;/p&gt;\n\n&lt;p&gt;If someone can guide me to books or resources; I\u2019d appreciate it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15uljw3", "is_robot_indexable": true, "report_reasons": null, "author": "LackToesToddlerAnts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15uljw3/anyone_do_devops_as_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15uljw3/anyone_do_devops_as_a_data_engineer/", "subreddit_subscribers": 123498, "created_utc": 1692367570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m starting a new position as a data engineer and my manager wants me to implement data quality in all data pipelines. We have a cloud data lake that uses landing-bronze-silver-gold layers.   \n\n\nInitially I thought of doing this from landing layer to bronze layer using DeeQu.\n\nWhat other tools do you suggest for use? Or what approaches do you use when doing data quality?", "author_fullname": "t2_ei3tpd4w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tools to use for data quality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ulop6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692367885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m starting a new position as a data engineer and my manager wants me to implement data quality in all data pipelines. We have a cloud data lake that uses landing-bronze-silver-gold layers.   &lt;/p&gt;\n\n&lt;p&gt;Initially I thought of doing this from landing layer to bronze layer using DeeQu.&lt;/p&gt;\n\n&lt;p&gt;What other tools do you suggest for use? Or what approaches do you use when doing data quality?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ulop6", "is_robot_indexable": true, "report_reasons": null, "author": "OdiumPura", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ulop6/tools_to_use_for_data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ulop6/tools_to_use_for_data_quality/", "subreddit_subscribers": 123498, "created_utc": 1692367885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're in the midst of integrating GitLab with our MS SQL database, and we've come across a critical decision point - our branching strategy.\n\nWe have two options:\n\n1. **Task-based branching**: a separate branch for each individual task or feature.\n2. **Engineer-based branching**: a separate branch for each data engineer on our team\n\nWhich approach do you believe is the best and why? \n\nCheers!\n\n&amp;#x200B;", "author_fullname": "t2_8u34pgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "git Branching approach", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ukyqw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692366199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re in the midst of integrating GitLab with our MS SQL database, and we&amp;#39;ve come across a critical decision point - our branching strategy.&lt;/p&gt;\n\n&lt;p&gt;We have two options:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Task-based branching&lt;/strong&gt;: a separate branch for each individual task or feature.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Engineer-based branching&lt;/strong&gt;: a separate branch for each data engineer on our team&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Which approach do you believe is the best and why? &lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ukyqw", "is_robot_indexable": true, "report_reasons": null, "author": "Sa1kon", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ukyqw/git_branching_approach/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ukyqw/git_branching_approach/", "subreddit_subscribers": 123498, "created_utc": 1692366199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My data developers team develops data products for the organization's external customers - errors in data in production are a serious problem and we want to create more confidence in that matter.\nIn terms of the stack today we use Snowflake, airflow.\n\nIn the last few weeks we came to the conclusion that we want to add another layer of tests as part of the ETL process before we push the job to production.\nWe are trying to understand if there is a way to produce automatic tests that verify the written logic as well as the data content.\nHas anyone managed to implement/build a similar tool? And can shed some light on do and don't?The tools you use? The types of tests you make?\nThanks", "author_fullname": "t2_5soahcizy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Test Data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15utyy7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692387173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My data developers team develops data products for the organization&amp;#39;s external customers - errors in data in production are a serious problem and we want to create more confidence in that matter.\nIn terms of the stack today we use Snowflake, airflow.&lt;/p&gt;\n\n&lt;p&gt;In the last few weeks we came to the conclusion that we want to add another layer of tests as part of the ETL process before we push the job to production.\nWe are trying to understand if there is a way to produce automatic tests that verify the written logic as well as the data content.\nHas anyone managed to implement/build a similar tool? And can shed some light on do and don&amp;#39;t?The tools you use? The types of tests you make?\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15utyy7", "is_robot_indexable": true, "report_reasons": null, "author": "Classic-Interview503", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15utyy7/how_to_test_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15utyy7/how_to_test_data/", "subreddit_subscribers": 123498, "created_utc": 1692387173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\ud83d\udce3 We've just released Apache Airflow 2.7.0 \ud83c\udf89\n\n&amp;#x200B;\n\nhttps://preview.redd.it/i7jgql03swib1.jpg?width=1828&amp;format=pjpg&amp;auto=webp&amp;s=73d8a21c04b7bc1d72a8e75f61319f04310e7043\n\n&amp;#x200B;\n\nhttps://preview.redd.it/btzg9no3swib1.png?width=1263&amp;format=png&amp;auto=webp&amp;s=64e2a7ae8d560632bc5c5d644db877864fae254b\n\nNew features include:\n\n\u2705 Setup and Teardown tasks\n\n\u2705 Cluster Activity UI\n\n\u2705 Built-in integration\u00a0for OpenLineage\n\n\u2705 Allow Enable deferrable mode by default for all deferable tasks\n\n&amp;#x200B;\n\n\ud83d\udce6 PyPI:  [https://pypi.org/project/apache-airflow/2.7.0/](https://pypi.org/project/apache-airflow/2.7.0/)\n\n\ud83d\udcda Docs:\u00a0[https://airflow.apache.org/docs/apache-airflow/2.7.0/](https://airflow.apache.org/docs/apache-airflow/2.7.0/)\n\n\ud83d\udee0 Release Notes: [https://airflow.apache.org/docs/apache-airflow/2.7.0/release\\_notes.html](https://airflow.apache.org/docs/apache-airflow/2.7.0/release_notes.html)\n\n\ud83d\udc33 Docker Image: \"docker pull apache/airflow:2.7.0\"\n\n\ud83d\udcc3 Blog Post: [https://airflow.apache.org/blog/airflow-2.7.0/](https://airflow.apache.org/blog/airflow-2.7.0/)", "author_fullname": "t2_178qu6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Airflow 2.7.0", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"btzg9no3swib1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/btzg9no3swib1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a1520fbad3473d0667abeef72864764cfe351bad"}, {"y": 174, "x": 216, "u": "https://preview.redd.it/btzg9no3swib1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6059df679eeaed1d55b03d0472094cd2e5853e7c"}, {"y": 258, "x": 320, "u": "https://preview.redd.it/btzg9no3swib1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d66b085120762bdad7a59cfa8cc4edfb8984d7cc"}, {"y": 516, "x": 640, "u": "https://preview.redd.it/btzg9no3swib1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aeda4a88bd33fbcdf06ada8879624a280e5c25ef"}, {"y": 775, "x": 960, "u": "https://preview.redd.it/btzg9no3swib1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3958e5c7df70129524f5a12ebcc80d568d3788ae"}, {"y": 872, "x": 1080, "u": "https://preview.redd.it/btzg9no3swib1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=15b1d129b574ba64e39567f33816fbdcf584f858"}], "s": {"y": 1020, "x": 1263, "u": "https://preview.redd.it/btzg9no3swib1.png?width=1263&amp;format=png&amp;auto=webp&amp;s=64e2a7ae8d560632bc5c5d644db877864fae254b"}, "id": "btzg9no3swib1"}, "i7jgql03swib1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f8131b71e0f4c2c54d87c9f605b3553a0cd2f3b8"}, {"y": 111, "x": 216, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e529b2688ac002fd47fd942780ad024b90f9de18"}, {"y": 164, "x": 320, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1050c5976b8719cb21057402ab5e4a0c2044e36e"}, {"y": 329, "x": 640, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=964c2a238d54141041b8d966972c7663053d15d2"}, {"y": 493, "x": 960, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=31ecddf54a80d530144c0295898ef0a052be6bf9"}, {"y": 555, "x": 1080, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8f0d3bf351664a336332e13a1a954922b9b8916d"}], "s": {"y": 940, "x": 1828, "u": "https://preview.redd.it/i7jgql03swib1.jpg?width=1828&amp;format=pjpg&amp;auto=webp&amp;s=73d8a21c04b7bc1d72a8e75f61319f04310e7043"}, "id": "i7jgql03swib1"}}, "name": "t3_15urns3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/t6MfV7G0gvk5my6aRqwWugcSdtroL217KNERnWjeDag.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692381772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\ud83d\udce3 We&amp;#39;ve just released Apache Airflow 2.7.0 \ud83c\udf89&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/i7jgql03swib1.jpg?width=1828&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=73d8a21c04b7bc1d72a8e75f61319f04310e7043\"&gt;https://preview.redd.it/i7jgql03swib1.jpg?width=1828&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=73d8a21c04b7bc1d72a8e75f61319f04310e7043&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/btzg9no3swib1.png?width=1263&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=64e2a7ae8d560632bc5c5d644db877864fae254b\"&gt;https://preview.redd.it/btzg9no3swib1.png?width=1263&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=64e2a7ae8d560632bc5c5d644db877864fae254b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;New features include:&lt;/p&gt;\n\n&lt;p&gt;\u2705 Setup and Teardown tasks&lt;/p&gt;\n\n&lt;p&gt;\u2705 Cluster Activity UI&lt;/p&gt;\n\n&lt;p&gt;\u2705 Built-in integration\u00a0for OpenLineage&lt;/p&gt;\n\n&lt;p&gt;\u2705 Allow Enable deferrable mode by default for all deferable tasks&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udce6 PyPI:  &lt;a href=\"https://pypi.org/project/apache-airflow/2.7.0/\"&gt;https://pypi.org/project/apache-airflow/2.7.0/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcda Docs:\u00a0&lt;a href=\"https://airflow.apache.org/docs/apache-airflow/2.7.0/\"&gt;https://airflow.apache.org/docs/apache-airflow/2.7.0/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udee0 Release Notes: &lt;a href=\"https://airflow.apache.org/docs/apache-airflow/2.7.0/release_notes.html\"&gt;https://airflow.apache.org/docs/apache-airflow/2.7.0/release_notes.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udc33 Docker Image: &amp;quot;docker pull apache/airflow:2.7.0&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcc3 Blog Post: &lt;a href=\"https://airflow.apache.org/blog/airflow-2.7.0/\"&gt;https://airflow.apache.org/blog/airflow-2.7.0/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15urns3", "is_robot_indexable": true, "report_reasons": null, "author": "kaxil_naik", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15urns3/apache_airflow_270/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15urns3/apache_airflow_270/", "subreddit_subscribers": 123498, "created_utc": 1692381772.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been working as a data engineer for the past 3 years and still don\u2019t know how to do this \ud83d\ude48", "author_fullname": "t2_j33i3nha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best way to learn how to optimize ETL pipelines and complex queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uqltg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692379292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been working as a data engineer for the past 3 years and still don\u2019t know how to do this \ud83d\ude48&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15uqltg", "is_robot_indexable": true, "report_reasons": null, "author": "CS_throwaway_DE", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15uqltg/what_is_the_best_way_to_learn_how_to_optimize_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15uqltg/what_is_the_best_way_to_learn_how_to_optimize_etl/", "subreddit_subscribers": 123498, "created_utc": 1692379292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI'm trying to implement a data warehouse with the Kimball methodology, using dagster &amp; dbt.\n\nI'd like to snapshot my source tables to retain historic reporting accuracy. For example, my sales fact will have a customer\\_key, joining on my customer\\_dim. \n\nThe customer\\_dim needs to be built from various tables from my ERP source, i.e. customer master data, customer group, account manager, territory, etc. All of which are separate tables in my source ERP.\n\nSince territories, account managers, customer groups etc. may change over time,  I figured I'd snapshot those and combine the resulting snapshots with my customer master data, so we can (for example) calculate the sales per territory over the period where the territory was assigned at invoice date. \n\nI came across [this blog](https://docs.getdbt.com/blog/joining-snapshot-complexity) on dbt that explains a way of joining snapshotted tables. In essence this comes down to deduplicating, snapshotting, replacing dbt\\_valid\\_to null values with '9999-12-31' and joining the tables and finally cleaning up the resulting tables.\n\nThis means for a final customer\\_dim with customer master, group, account manager and territory, I'd need:\n\n* customer\\_master\\_raw -&gt; customer\\_master\\_scd -&gt; customer\\_master\\_replace\\_valid\\_to\n* customer\\_group\\_raw -&gt; customer\\_group\\_scd -&gt; customer\\_group\\_replace\\_valid\\_to\n* customer\\_acc\\_mgr\\_raw -&gt; customer\\_acc\\_mgr\\_scd -&gt; customer\\_acc\\_mgr\\_replace\\_valid\\_to\n* customer\\_territory\\_raw -&gt; customer\\_territory\\_scd -&gt; customer\\_territory\\_replace\\_valid\\_to\n\nFollowed by (since the article recommends only doing one snapshot join at a time):\n\n* A) join customer\\_master\\_replace\\_valid\\_to on customer\\_group\\_replace\\_valid\\_to\n* B) join A) on customer\\_acc\\_mgr\\_replace\\_valid\\_to\n* C) join B) on customer\\_territory\\_replace\\_valid\\_to\n\nAnd finally: clean up C) and select only the columns I need. This feels 'messy' to me although I don't have a better solution. \n\nAlthough I can modify the macro in the article in such a way that it won't cost me much time to create these joins, it seems like a lot of steps to get to a final customer\\_dim and even more if we decide to include more source tables for the customer dim like assigned team, customer branch, customer type, etc. \n\nAm I on the right track here, is this a commonly seen pattern or am I missing something obvious? ", "author_fullname": "t2_ko2ybcf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Combining snapshotted dimension tables (dbt)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15udyqu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692345280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to implement a data warehouse with the Kimball methodology, using dagster &amp;amp; dbt.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to snapshot my source tables to retain historic reporting accuracy. For example, my sales fact will have a customer_key, joining on my customer_dim. &lt;/p&gt;\n\n&lt;p&gt;The customer_dim needs to be built from various tables from my ERP source, i.e. customer master data, customer group, account manager, territory, etc. All of which are separate tables in my source ERP.&lt;/p&gt;\n\n&lt;p&gt;Since territories, account managers, customer groups etc. may change over time,  I figured I&amp;#39;d snapshot those and combine the resulting snapshots with my customer master data, so we can (for example) calculate the sales per territory over the period where the territory was assigned at invoice date. &lt;/p&gt;\n\n&lt;p&gt;I came across &lt;a href=\"https://docs.getdbt.com/blog/joining-snapshot-complexity\"&gt;this blog&lt;/a&gt; on dbt that explains a way of joining snapshotted tables. In essence this comes down to deduplicating, snapshotting, replacing dbt_valid_to null values with &amp;#39;9999-12-31&amp;#39; and joining the tables and finally cleaning up the resulting tables.&lt;/p&gt;\n\n&lt;p&gt;This means for a final customer_dim with customer master, group, account manager and territory, I&amp;#39;d need:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;customer_master_raw -&amp;gt; customer_master_scd -&amp;gt; customer_master_replace_valid_to&lt;/li&gt;\n&lt;li&gt;customer_group_raw -&amp;gt; customer_group_scd -&amp;gt; customer_group_replace_valid_to&lt;/li&gt;\n&lt;li&gt;customer_acc_mgr_raw -&amp;gt; customer_acc_mgr_scd -&amp;gt; customer_acc_mgr_replace_valid_to&lt;/li&gt;\n&lt;li&gt;customer_territory_raw -&amp;gt; customer_territory_scd -&amp;gt; customer_territory_replace_valid_to&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Followed by (since the article recommends only doing one snapshot join at a time):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A) join customer_master_replace_valid_to on customer_group_replace_valid_to&lt;/li&gt;\n&lt;li&gt;B) join A) on customer_acc_mgr_replace_valid_to&lt;/li&gt;\n&lt;li&gt;C) join B) on customer_territory_replace_valid_to&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And finally: clean up C) and select only the columns I need. This feels &amp;#39;messy&amp;#39; to me although I don&amp;#39;t have a better solution. &lt;/p&gt;\n\n&lt;p&gt;Although I can modify the macro in the article in such a way that it won&amp;#39;t cost me much time to create these joins, it seems like a lot of steps to get to a final customer_dim and even more if we decide to include more source tables for the customer dim like assigned team, customer branch, customer type, etc. &lt;/p&gt;\n\n&lt;p&gt;Am I on the right track here, is this a commonly seen pattern or am I missing something obvious? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Jc7Bwo70Vspr8swTKLEwUZGoroiGSARihT_F4cWI5DU.jpg?auto=webp&amp;s=b3e577308f7c1e349a6e8e26f2033cfe3e408335", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Jc7Bwo70Vspr8swTKLEwUZGoroiGSARihT_F4cWI5DU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f22727568160e775a1f0d013038b229cd3b61044", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Jc7Bwo70Vspr8swTKLEwUZGoroiGSARihT_F4cWI5DU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9c0be008ef80e63a267164298f0eeded2cfe689f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Jc7Bwo70Vspr8swTKLEwUZGoroiGSARihT_F4cWI5DU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=16881f8672d58d234a0e4451c493c6557ad0fe21", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Jc7Bwo70Vspr8swTKLEwUZGoroiGSARihT_F4cWI5DU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=34d144730e813e9b2707f2bde37f4e1220ce2e19", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Jc7Bwo70Vspr8swTKLEwUZGoroiGSARihT_F4cWI5DU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e1b5ced5af4495fc8d2ae4f287f0156cb73f6032", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Jc7Bwo70Vspr8swTKLEwUZGoroiGSARihT_F4cWI5DU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=40d27acfe42cfbffa9fdcfdea8cebfa9d43dfa28", "width": 1080, "height": 567}], "variants": {}, "id": "KBohsdqrfvkRxfqADmI_uqtotFtqgZjYu8NQbRpJlaE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15udyqu", "is_robot_indexable": true, "report_reasons": null, "author": "nl_dhh", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15udyqu/combining_snapshotted_dimension_tables_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15udyqu/combining_snapshotted_dimension_tables_dbt/", "subreddit_subscribers": 123498, "created_utc": 1692345280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my SWEs decided it was best to use Fivetran to connect to Sage Intacct because of some distinct challenges with the authentication methods used by Sage Intacct. This was decided largely because we had previously configured Fivetran for another connector and it would be quite easy to build upon that work. Didn\u2019t think twice about it at the time. \n\nFast forward a while and we\u2019ve come to realize there are a litany of data issues present with Fivetran\u2019s Sage Intacct connector. \n\nAs best as I can tell, Fivetran is attempting to use a batch CDC for their incremental sync by syncing with an events log table. But, it appears the joke is one Fivetran as the underlying source of their transactional data (gl_data) is not a materialized table and therefore does not have DML actions logged. I\u2019ve been trying to explain this to them with very little progress made. \n\nAnyone else have experience with Fivetran, specifically with their Sage Intacct connector? If so, what are your thoughts on sticking with them versus building a native connector? Any other third party connectors that you might have had success with for Sage Intacct?\n\nThanks in advance.", "author_fullname": "t2_ibioowgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran Sage Intacct Connector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ucztt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "8cf4f390-e787-11ed-81a4-ca7b65282907", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692341920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my SWEs decided it was best to use Fivetran to connect to Sage Intacct because of some distinct challenges with the authentication methods used by Sage Intacct. This was decided largely because we had previously configured Fivetran for another connector and it would be quite easy to build upon that work. Didn\u2019t think twice about it at the time. &lt;/p&gt;\n\n&lt;p&gt;Fast forward a while and we\u2019ve come to realize there are a litany of data issues present with Fivetran\u2019s Sage Intacct connector. &lt;/p&gt;\n\n&lt;p&gt;As best as I can tell, Fivetran is attempting to use a batch CDC for their incremental sync by syncing with an events log table. But, it appears the joke is one Fivetran as the underlying source of their transactional data (gl_data) is not a materialized table and therefore does not have DML actions logged. I\u2019ve been trying to explain this to them with very little progress made. &lt;/p&gt;\n\n&lt;p&gt;Anyone else have experience with Fivetran, specifically with their Sage Intacct connector? If so, what are your thoughts on sticking with them versus building a native connector? Any other third party connectors that you might have had success with for Sage Intacct?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Staff Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ucztt", "is_robot_indexable": true, "report_reasons": null, "author": "SDFP-A", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15ucztt/fivetran_sage_intacct_connector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ucztt/fivetran_sage_intacct_connector/", "subreddit_subscribers": 123498, "created_utc": 1692341920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Note: I said r/dataengineer  \\*not\\* r/dataengineering ! \n\nr/dataengineer  is a bloody nuisance.  I always end up there by mistake and wonder, \"where's all the good stuff\"?  ", "author_fullname": "t2_7yk2o6hxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can we get rid of r/dataengineer ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ub0px", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692335541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Note: I said &lt;a href=\"/r/dataengineer\"&gt;r/dataengineer&lt;/a&gt;  *not* &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; ! &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"/r/dataengineer\"&gt;r/dataengineer&lt;/a&gt;  is a bloody nuisance.  I always end up there by mistake and wonder, &amp;quot;where&amp;#39;s all the good stuff&amp;quot;?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ub0px", "is_robot_indexable": true, "report_reasons": null, "author": "grahamdietz", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ub0px/can_we_get_rid_of_rdataengineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ub0px/can_we_get_rid_of_rdataengineer/", "subreddit_subscribers": 123498, "created_utc": 1692335541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2rku02rf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MotherDuck: Beyond Storing Data: How to Use DuckDB, MotherDuck and Kestra for ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_15uxeb5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pdMJa4YArLpPjjtWRx3A-qKjBMrfT6aW4l0l3dTV9zY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692395230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "motherduck.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://motherduck.com/blog/motherduck-kestra-etl-pipelines/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/42-0Io_nKyqTg_5Y_5otKfEXpAP5qumJtBiAAaF5_Fg.jpg?auto=webp&amp;s=d26c7f2653666ec82242ecc3301d9f1701adad6e", "width": 720, "height": 405}, "resolutions": [{"url": "https://external-preview.redd.it/42-0Io_nKyqTg_5Y_5otKfEXpAP5qumJtBiAAaF5_Fg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0df082023eb53a261a3cf8552f54e3406a40647d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/42-0Io_nKyqTg_5Y_5otKfEXpAP5qumJtBiAAaF5_Fg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=18f05c5e823b114a1e11f10be67d4246ef2ce887", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/42-0Io_nKyqTg_5Y_5otKfEXpAP5qumJtBiAAaF5_Fg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4fb705af81f4e3cb6095620c73cff4171f5356d9", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/42-0Io_nKyqTg_5Y_5otKfEXpAP5qumJtBiAAaF5_Fg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=62cbcf679849fadc3fdbd1b6aa562eda7f52e8df", "width": 640, "height": 360}], "variants": {}, "id": "nOsFKI0KbhqtjcAlrPpqawpLGBzPyf_5-DtQnasRBP8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15uxeb5", "is_robot_indexable": true, "report_reasons": null, "author": "tchiotludo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15uxeb5/motherduck_beyond_storing_data_how_to_use_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://motherduck.com/blog/motherduck-kestra-etl-pipelines/", "subreddit_subscribers": 123498, "created_utc": 1692395230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm using Databricks and I have a job running 100 tasks of the same notebook, but just with a different parameter. For some reason, some tasks fail trying to do a sql query (with 4 retries with a timeout of 1 hr each). I'm confused why it takes so long because the tables it is querying is small (10mb, 1 file, 440k rows) while it takes similar tables only a few seconds. I'm using a 156gb driver and 20gb worker cluster.  \n\n\nCode:\n\ntableName = '...' # taken from job task parameter\n\nminDateDF = spark.sql('select case when min(date) = current\\_date() THEN True ELSE False End as test from test.' + tableName)\n\nminDate = [minDateDF.select](https://minDateDF.select)('test').collect()\\[0\\]\\[0\\]  \n\n\nIs there a better way to query these tables? From the spark ui it says it fails at the minDateDF line. I'm not sure if I'm describing this problem well enough because I can't find a solution online.", "author_fullname": "t2_j4kzc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the appropriate way to get values from a delta table as a variable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uwhns", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692393091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using Databricks and I have a job running 100 tasks of the same notebook, but just with a different parameter. For some reason, some tasks fail trying to do a sql query (with 4 retries with a timeout of 1 hr each). I&amp;#39;m confused why it takes so long because the tables it is querying is small (10mb, 1 file, 440k rows) while it takes similar tables only a few seconds. I&amp;#39;m using a 156gb driver and 20gb worker cluster.  &lt;/p&gt;\n\n&lt;p&gt;Code:&lt;/p&gt;\n\n&lt;p&gt;tableName = &amp;#39;...&amp;#39; # taken from job task parameter&lt;/p&gt;\n\n&lt;p&gt;minDateDF = spark.sql(&amp;#39;select case when min(date) = current_date() THEN True ELSE False End as test from test.&amp;#39; + tableName)&lt;/p&gt;\n\n&lt;p&gt;minDate = &lt;a href=\"https://minDateDF.select\"&gt;minDateDF.select&lt;/a&gt;(&amp;#39;test&amp;#39;).collect()[0][0]  &lt;/p&gt;\n\n&lt;p&gt;Is there a better way to query these tables? From the spark ui it says it fails at the minDateDF line. I&amp;#39;m not sure if I&amp;#39;m describing this problem well enough because I can&amp;#39;t find a solution online.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15uwhns", "is_robot_indexable": true, "report_reasons": null, "author": "bongdong42O", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15uwhns/what_is_the_appropriate_way_to_get_values_from_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15uwhns/what_is_the_appropriate_way_to_get_values_from_a/", "subreddit_subscribers": 123498, "created_utc": 1692393091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently manage a data analytics team at a tech company. Our Data Engineering team is practically non existent as a support function (in my opinion - b/c anytime I ask for support, they send me google how to articles and expect us to figure it out) to our team so we end up building our own schema, building data marts, maintaining and documenting them, etc.  My team primarily uses SQL, Python, DBT, Tableau and Tableau Prep for all of our work.\n\nAs of recent, there has been a push from leadership to expand and focus on data engineering more and my team has been a fly on the wall in the interview process.\n\nI'm not sure if I'm just not familiar enough with Data Engineering or if my thoughts are justified here but it strikes me that these interviews are searching for the absolute perfect candidate with all of these technical experiences / skills (which I doubt they even use all of those tools) and are hyper critical of the smallest flaw in a candidate.  As a downstream consumer of the Data Engineering team, the bar is so low that I personally wouldn't be hyper critical on the lack of a technical skill but rather a personality type / willingness to learn.\n\nThey have passed up on numerous candidates and I feel like I'm spending half of my time just watching these very dry and technical focused interviews when all we need is some basic data modeling skills and common sense in my opinion.\n\nAny time I voice this opinion, there is definitely a response in the realm of \"you are not a Data Engineer so you don't understand why we're asking all of this\" which can get a bit frustrating.\n\nHas anyone else experienced this before?", "author_fullname": "t2_75f7qjfw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Curious about DE Jobs vs. Interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ul93m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692366898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently manage a data analytics team at a tech company. Our Data Engineering team is practically non existent as a support function (in my opinion - b/c anytime I ask for support, they send me google how to articles and expect us to figure it out) to our team so we end up building our own schema, building data marts, maintaining and documenting them, etc.  My team primarily uses SQL, Python, DBT, Tableau and Tableau Prep for all of our work.&lt;/p&gt;\n\n&lt;p&gt;As of recent, there has been a push from leadership to expand and focus on data engineering more and my team has been a fly on the wall in the interview process.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if I&amp;#39;m just not familiar enough with Data Engineering or if my thoughts are justified here but it strikes me that these interviews are searching for the absolute perfect candidate with all of these technical experiences / skills (which I doubt they even use all of those tools) and are hyper critical of the smallest flaw in a candidate.  As a downstream consumer of the Data Engineering team, the bar is so low that I personally wouldn&amp;#39;t be hyper critical on the lack of a technical skill but rather a personality type / willingness to learn.&lt;/p&gt;\n\n&lt;p&gt;They have passed up on numerous candidates and I feel like I&amp;#39;m spending half of my time just watching these very dry and technical focused interviews when all we need is some basic data modeling skills and common sense in my opinion.&lt;/p&gt;\n\n&lt;p&gt;Any time I voice this opinion, there is definitely a response in the realm of &amp;quot;you are not a Data Engineer so you don&amp;#39;t understand why we&amp;#39;re asking all of this&amp;quot; which can get a bit frustrating.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else experienced this before?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ul93m", "is_robot_indexable": true, "report_reasons": null, "author": "Snoo-74514", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ul93m/curious_about_de_jobs_vs_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ul93m/curious_about_de_jobs_vs_interviews/", "subreddit_subscribers": 123498, "created_utc": 1692366898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vk94wnpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Top 5 questions Data Engineers should ask before joining a startup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15uk91q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/5GRba3S29GvapoSu-84rLfN7PzBMJodGKq0PSKDUIb0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692364393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@jeff.b.chou/top-5-questions-data-engineers-should-ask-before-joining-a-startup-1950ab326250", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?auto=webp&amp;s=b5c572c904e5bfe6ec7f64264a583558fc676188", "width": 1124, "height": 750}, "resolutions": [{"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9dbe8ef3590579b840ab0812520efca6c316d7f3", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4c1d67eaf9d880a91712ff269c752f15b38dcf26", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe02c90ff6976a70d62504961366c5d3c34e73d7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fa6096cc3e8636138eb9a4ced4afc7fddd068264", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=24fe2cbf436c6d684004612aa4a42e7d2666c163", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/WGJtSvvKx-Ng10ZjVgF_j7B2zmrI33udA8A6qUgwbOU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=68b0a3d64c46c307321f93770b11ddeaa818c3c1", "width": 1080, "height": 720}], "variants": {}, "id": "4qXAzV1KWd3IOdizYWBiIev5U87yEQ98ITv9jJoqIfQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15uk91q", "is_robot_indexable": true, "report_reasons": null, "author": "sync_jeff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15uk91q/top_5_questions_data_engineers_should_ask_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@jeff.b.chou/top-5-questions-data-engineers-should-ask-before-joining-a-startup-1950ab326250", "subreddit_subscribers": 123498, "created_utc": 1692364393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Several people told me the best way to load data from sap to snowflake is Kafka.\nWhy should I do that?\nIsn't a direct connection between sap and snowflake easier?", "author_fullname": "t2_9pyk5rj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why should I use Kafka to load from sap to snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uiqhh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692363236.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692360359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Several people told me the best way to load data from sap to snowflake is Kafka.\nWhy should I do that?\nIsn&amp;#39;t a direct connection between sap and snowflake easier?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15uiqhh", "is_robot_indexable": true, "report_reasons": null, "author": "seayk", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15uiqhh/why_should_i_use_kafka_to_load_from_sap_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15uiqhh/why_should_i_use_kafka_to_load_from_sap_to/", "subreddit_subscribers": 123498, "created_utc": 1692360359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello! Somewhat new to data engineering here :)\n\nI am working on calculating the client's lifetime value. Every day, a batch process loads new events (ex: from the previous day, such as client purchases, calls, etc.), applies some filters and rules, calculates the cost or income arising from each event, allocates it to a financial account and saves the results.\n\nI have a relational OLTP database where the value model is parametrized (what filters to apply, what accounts exist, parent-child relationships, what unit costs should be applied, to what type of events, and so on). This is important because these parameters change and business people are going to maintain them along time (through a front-end connected to this database).\n\nSo far, this seems to work; but it is not clear to me where things should live in practice. Where should I save the results (i.e.: millions of rows containing the events, their calculated value and foreign key references to parameters - such as account key, unit costs, etc.)? This data would be used for aggregation and reporting, so I feel that results should end in a distinct OLAP database, in our Data Warehouse. But then, would parameters and results be in separate databases? This does not make much sense, because analysts need to know info about the account associated to a given event value, as well as the unit costs considered, filters, rules, and so on.\n\nI think I have the following choices:\n\n1. Store parameters and save (millions) of results in the OLTP database. Every day incrementally copy everything to OLAP database for analytics purposes. I end with two exact copies;\n2. Store parameters in OLTP database and save results directly in OLAP. Every day incrementally copy parameters from OLTP to OLAP. I risk consistency problems...\n3. Store parameters in OLTP database and save results directly in OLAP, but include unfolded parameter data (ex: account name, unit costs used for computation, filters, etc) in each result record, instead of foreign keys;\n\nWhat do you guys think? I think 1. is safest, but somehow I feel like it's a \"waste\" to have millions of rows replicated in two databases, especially because the million rows in OLTP serve no purpose except being there to be copied. Option 2. also seems interesting, but if something goes wrong, and parameters are not synched, I may get consistency conflicts.\n\nAny ideas are appreciated!", "author_fullname": "t2_3xswxksvc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to store configuration and results, if both are needed for reporting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ugkal", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692354024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! Somewhat new to data engineering here :)&lt;/p&gt;\n\n&lt;p&gt;I am working on calculating the client&amp;#39;s lifetime value. Every day, a batch process loads new events (ex: from the previous day, such as client purchases, calls, etc.), applies some filters and rules, calculates the cost or income arising from each event, allocates it to a financial account and saves the results.&lt;/p&gt;\n\n&lt;p&gt;I have a relational OLTP database where the value model is parametrized (what filters to apply, what accounts exist, parent-child relationships, what unit costs should be applied, to what type of events, and so on). This is important because these parameters change and business people are going to maintain them along time (through a front-end connected to this database).&lt;/p&gt;\n\n&lt;p&gt;So far, this seems to work; but it is not clear to me where things should live in practice. Where should I save the results (i.e.: millions of rows containing the events, their calculated value and foreign key references to parameters - such as account key, unit costs, etc.)? This data would be used for aggregation and reporting, so I feel that results should end in a distinct OLAP database, in our Data Warehouse. But then, would parameters and results be in separate databases? This does not make much sense, because analysts need to know info about the account associated to a given event value, as well as the unit costs considered, filters, rules, and so on.&lt;/p&gt;\n\n&lt;p&gt;I think I have the following choices:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Store parameters and save (millions) of results in the OLTP database. Every day incrementally copy everything to OLAP database for analytics purposes. I end with two exact copies;&lt;/li&gt;\n&lt;li&gt;Store parameters in OLTP database and save results directly in OLAP. Every day incrementally copy parameters from OLTP to OLAP. I risk consistency problems...&lt;/li&gt;\n&lt;li&gt;Store parameters in OLTP database and save results directly in OLAP, but include unfolded parameter data (ex: account name, unit costs used for computation, filters, etc) in each result record, instead of foreign keys;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What do you guys think? I think 1. is safest, but somehow I feel like it&amp;#39;s a &amp;quot;waste&amp;quot; to have millions of rows replicated in two databases, especially because the million rows in OLTP serve no purpose except being there to be copied. Option 2. also seems interesting, but if something goes wrong, and parameters are not synched, I may get consistency conflicts.&lt;/p&gt;\n\n&lt;p&gt;Any ideas are appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ugkal", "is_robot_indexable": true, "report_reasons": null, "author": "Sure-Examination-824", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ugkal/how_to_store_configuration_and_results_if_both/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ugkal/how_to_store_configuration_and_results_if_both/", "subreddit_subscribers": 123498, "created_utc": 1692354024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im curious to know what all are the optimise techniques for improving SQL databases performance ( not the query alone )?\n\nFew of them would be came to my mind - \n\n1. Partitioning / Sharding\n2. Selecting the right indexes ( BTree )\n3. Optimising the SQL query execution\n\nAnything else that can be added?\n\n&amp;#x200B;", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Database optimisation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uewl7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692348476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im curious to know what all are the optimise techniques for improving SQL databases performance ( not the query alone )?&lt;/p&gt;\n\n&lt;p&gt;Few of them would be came to my mind - &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Partitioning / Sharding&lt;/li&gt;\n&lt;li&gt;Selecting the right indexes ( BTree )&lt;/li&gt;\n&lt;li&gt;Optimising the SQL query execution&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Anything else that can be added?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15uewl7", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15uewl7/sql_database_optimisation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15uewl7/sql_database_optimisation/", "subreddit_subscribers": 123498, "created_utc": 1692348476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thought some people might find this comparison interesting. \n\nShould you migrate your big data workflows from Spark to Snowpark? Are you wondering what all the fuss is about? You\u2019ve come to the right place.\n\nIn this article, Snowpark and Spark go head-to-head as we compare their crucial features. We\u2019ll discuss the tradeoffs between the two tools, backing our claims with evidence from a benchmarking analysis.\n\n[https://www.keboola.com/blog/snowpark-vs-spark](https://www.keboola.com/blog/snowpark-vs-spark)", "author_fullname": "t2_opyjpm1x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparison: Snowpark vs Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ucsst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692341230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thought some people might find this comparison interesting. &lt;/p&gt;\n\n&lt;p&gt;Should you migrate your big data workflows from Spark to Snowpark? Are you wondering what all the fuss is about? You\u2019ve come to the right place.&lt;/p&gt;\n\n&lt;p&gt;In this article, Snowpark and Spark go head-to-head as we compare their crucial features. We\u2019ll discuss the tradeoffs between the two tools, backing our claims with evidence from a benchmarking analysis.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.keboola.com/blog/snowpark-vs-spark\"&gt;https://www.keboola.com/blog/snowpark-vs-spark&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/A_XyuVF8L_XDjFwMP17VYz56YWwRI3Nn267ojce0PAQ.jpg?auto=webp&amp;s=7a695c3c06478867b1f412fad850aef6762ce9d0", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/A_XyuVF8L_XDjFwMP17VYz56YWwRI3Nn267ojce0PAQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7c27df8c0600da7a16ac0fc146b8dcd6abd63c18", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/A_XyuVF8L_XDjFwMP17VYz56YWwRI3Nn267ojce0PAQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b69873968c9409f648ae5b852fdb48429d65fe1a", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/A_XyuVF8L_XDjFwMP17VYz56YWwRI3Nn267ojce0PAQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=deb9fac6e19b9dc798507028c0080e53c59a57f6", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/A_XyuVF8L_XDjFwMP17VYz56YWwRI3Nn267ojce0PAQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=55f2a927737658aadf8afb704067dab4353bb099", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/A_XyuVF8L_XDjFwMP17VYz56YWwRI3Nn267ojce0PAQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a42308f25a909ff89e9940b17b93784bf3ce3444", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/A_XyuVF8L_XDjFwMP17VYz56YWwRI3Nn267ojce0PAQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=818a2d04767497730df05f424bdb4a78dc0a231f", "width": 1080, "height": 565}], "variants": {}, "id": "jUwuJrq_9RXwXesK-I8yb0wc7_oICXXEesfRAcdb2i0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ucsst", "is_robot_indexable": true, "report_reasons": null, "author": "CalleKeboola", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ucsst/comparison_snowpark_vs_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ucsst/comparison_snowpark_vs_spark/", "subreddit_subscribers": 123498, "created_utc": 1692341230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone, \n\nI wanted to ask the community here if anyone has got recommendations for database management tools that integrates well with DevOps pipeline. I have used schemachange for Snowflake where we deployed warehouses, roles, databases and few tables using schemachange.   \nThe problem with schemachange that I felt was that the definition of an object could potentially end up spanning multiple files. For example, a warehouse initially defined as XS in V1.1 and then an update to M in V1.2 and so on. The way i see it is that this could become s a nightmare of mess of files when managing a large data platform.   \nI'm looking to find a tool where if I can update definitions in one place and the tool does the magic of detecting if the warehouse already exists and if yes, automatically run the alter command rather than me having to write an alter command. This logic should be extensible to alter other objects too. I'm thinking something closer to CloudFormation or TF like tool for SQL.   \nI have tried TF for Snowflake and found myself writing heaps of HCL code for something that can be done in relatively few lines of SQL. \n\nAlso, if there is anyone who thinks there is no use case for a tool, why is that, IWTL? ", "author_fullname": "t2_dv4ply58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL tool for Infrastructure as Code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15v1jap", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692405639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, &lt;/p&gt;\n\n&lt;p&gt;I wanted to ask the community here if anyone has got recommendations for database management tools that integrates well with DevOps pipeline. I have used schemachange for Snowflake where we deployed warehouses, roles, databases and few tables using schemachange.&lt;br/&gt;\nThe problem with schemachange that I felt was that the definition of an object could potentially end up spanning multiple files. For example, a warehouse initially defined as XS in V1.1 and then an update to M in V1.2 and so on. The way i see it is that this could become s a nightmare of mess of files when managing a large data platform.&lt;br/&gt;\nI&amp;#39;m looking to find a tool where if I can update definitions in one place and the tool does the magic of detecting if the warehouse already exists and if yes, automatically run the alter command rather than me having to write an alter command. This logic should be extensible to alter other objects too. I&amp;#39;m thinking something closer to CloudFormation or TF like tool for SQL.&lt;br/&gt;\nI have tried TF for Snowflake and found myself writing heaps of HCL code for something that can be done in relatively few lines of SQL. &lt;/p&gt;\n\n&lt;p&gt;Also, if there is anyone who thinks there is no use case for a tool, why is that, IWTL? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15v1jap", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous_Apple_420", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15v1jap/sql_tool_for_infrastructure_as_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15v1jap/sql_tool_for_infrastructure_as_code/", "subreddit_subscribers": 123498, "created_utc": 1692405639.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}