{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4vivm0fq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone shucked a SanDisk Professional G-Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_165mptw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 127, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 127, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-vAwe6OBM7fQ2zgvgL9LHvM86j-l0f_I-FfrT9PKICk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693420380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/9wyqd4t6kalb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/9wyqd4t6kalb1.png?auto=webp&amp;s=19dbf61de6653e037848e055bc84af102241a373", "width": 1680, "height": 1680}, "resolutions": [{"url": "https://preview.redd.it/9wyqd4t6kalb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3cebfd7aed11f8e50a45bdfd801a3bcf356be97e", "width": 108, "height": 108}, {"url": "https://preview.redd.it/9wyqd4t6kalb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=32026f5bfbec512e715b48a46e9bb755cc995ef6", "width": 216, "height": 216}, {"url": "https://preview.redd.it/9wyqd4t6kalb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=daef75dd2141d5ba8ff768a2e76cb795198dab96", "width": 320, "height": 320}, {"url": "https://preview.redd.it/9wyqd4t6kalb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2127be63150f0d71a4fb718b04a32e1a64900120", "width": 640, "height": 640}, {"url": "https://preview.redd.it/9wyqd4t6kalb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=494fde0b9bf252de947920be9759a4fb83202553", "width": 960, "height": 960}, {"url": "https://preview.redd.it/9wyqd4t6kalb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cdab03fe5078ea5ab16e91ab53f58927530cb1d0", "width": 1080, "height": 1080}], "variants": {}, "id": "cCShSR_vxONEVA_e2CP7CQrWii__wvETazPTt20Xlf0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165mptw", "is_robot_indexable": true, "report_reasons": null, "author": "HerbalDreamin1", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165mptw/has_anyone_shucked_a_sandisk_professional_gdrive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/9wyqd4t6kalb1.png", "subreddit_subscribers": 700866, "created_utc": 1693420380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So you have your storage system set. Before you use those TBs in your personal/professional production, do you format and add encryption (veracrypt, bit locker, etc)?\n\nIf you do, and you have some type of RAID systems, can you share your experience in rebuilding your setup with the drive(s) after disk(s) failure, having encryption on the system?\n\nUpdate: thank you very much for those who are sharing!\n\nUpdate 2: it seems that most of you have the following rules: no encryption for at-home/in-house location, and put encryption for offsite/cloud/external location.", "author_fullname": "t2_68nf1a8tt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you put encryption on your storage system?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165m45e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693460113.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693418995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So you have your storage system set. Before you use those TBs in your personal/professional production, do you format and add encryption (veracrypt, bit locker, etc)?&lt;/p&gt;\n\n&lt;p&gt;If you do, and you have some type of RAID systems, can you share your experience in rebuilding your setup with the drive(s) after disk(s) failure, having encryption on the system?&lt;/p&gt;\n\n&lt;p&gt;Update: thank you very much for those who are sharing!&lt;/p&gt;\n\n&lt;p&gt;Update 2: it seems that most of you have the following rules: no encryption for at-home/in-house location, and put encryption for offsite/cloud/external location.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165m45e", "is_robot_indexable": true, "report_reasons": null, "author": "kammay1977", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165m45e/do_you_put_encryption_on_your_storage_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165m45e/do_you_put_encryption_on_your_storage_system/", "subreddit_subscribers": 700866, "created_utc": 1693418995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Raid 10?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 139, "top_awarded_type": null, "hide_score": true, "name": "t3_1661dqf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_yglg3", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Editable Flair", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/o4CTwrjH46GS-_VVm9tVO25Oy6UeVmZFRGGTnyhIB3E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "pcmasterrace", "selftext": "Need to transfer files to like 100usb. Anyway I can do this faster without daisy chaining usb hubs?", "author_fullname": "t2_8wq6m159", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a better way than this?", "link_flair_richtext": [{"e": "text", "t": "Discussion"}], "subreddit_name_prefixed": "r/pcmasterrace", "hidden": false, "pwls": 6, "link_flair_css_class": "blue", "downs": 0, "thumbnail_height": 139, "top_awarded_type": null, "hide_score": false, "name": "t3_165n3g6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": "#4c9bee", "ups": 3207, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "43c8cca4-832d-11e9-9b24-0eb45b446254", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3207, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/o4CTwrjH46GS-_VVm9tVO25Oy6UeVmZFRGGTnyhIB3E.jpg", "edited": false, "author_flair_css_class": "color-pcmr icon-windows7 text-pcmr", "author_flair_richtext": [{"a": ":windows7:", "e": "emoji", "u": "https://emoji.redditmedia.com/7te4qsnmef131_t5_2sgp1/windows7"}, {"e": "text", "t": " PC Master Race"}], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693421230.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "richtext", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need to transfer files to like 100usb. Anyway I can do this faster without daisy chaining usb hubs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ter3vlpqmalb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?auto=webp&amp;s=718514db38e61dfe8837303c23aac6d4281704e9", "width": 3024, "height": 3008}, "resolutions": [{"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b50d96ebb659d7f8d6c119e56ad2fe622ad875f7", "width": 108, "height": 107}, {"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e9c865fe4524a881c9750cb2b02433a072e94bc3", "width": 216, "height": 214}, {"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=babbae8a11d9c57491cc4405455a65feb641ddbb", "width": 320, "height": 318}, {"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=470a121af18b2d5122b00b7c3c2f444149ed08c8", "width": 640, "height": 636}, {"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d8f9065ee08de0b040f81347db81d83104df2d9f", "width": 960, "height": 954}, {"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=062fea939c8cb0b73336bb37fd283c7d3ed8d87d", "width": 1080, "height": 1074}], "variants": {}, "id": "-2wgvrKwWLrpXFJIZ81jUSoeCogAwbxfUoN6yQaZccc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2bef65aa-c51b-11e3-b700-12313b0d38eb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": ":windows7: PC Master Race", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sgp1", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0000ff", "id": "165n3g6", "is_robot_indexable": true, "report_reasons": null, "author": "False-Canary-3088", "discussion_type": null, "num_comments": 499, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/pcmasterrace/comments/165n3g6/is_there_a_better_way_than_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ter3vlpqmalb1.jpg", "subreddit_subscribers": 8559587, "created_utc": 1693421230.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1693457428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ter3vlpqmalb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?auto=webp&amp;s=718514db38e61dfe8837303c23aac6d4281704e9", "width": 3024, "height": 3008}, "resolutions": [{"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b50d96ebb659d7f8d6c119e56ad2fe622ad875f7", "width": 108, "height": 107}, {"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e9c865fe4524a881c9750cb2b02433a072e94bc3", "width": 216, "height": 214}, {"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=babbae8a11d9c57491cc4405455a65feb641ddbb", "width": 320, "height": 318}, {"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=470a121af18b2d5122b00b7c3c2f444149ed08c8", "width": 640, "height": 636}, {"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d8f9065ee08de0b040f81347db81d83104df2d9f", "width": 960, "height": 954}, {"url": "https://preview.redd.it/ter3vlpqmalb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=062fea939c8cb0b73336bb37fd283c7d3ed8d87d", "width": 1080, "height": 1074}], "variants": {}, "id": "-2wgvrKwWLrpXFJIZ81jUSoeCogAwbxfUoN6yQaZccc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1661dqf", "is_robot_indexable": true, "report_reasons": null, "author": "JaKami99", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_165n3g6", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1661dqf/raid_10/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ter3vlpqmalb1.jpg", "subreddit_subscribers": 700866, "created_utc": 1693457428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My first DAS was a Promise Pegasus R4, back when 4x4TB drives seemed like a lot of storage. Several times a year a drive would fail and I would replace it. This got so tiresome that I contacted Promise and they sent me a new R4, which didn't change much. \n\nTwo years ago I replaced the R4 with an OWC Thunderbay 4, and I put 4 brand new 16TB drives inside it. Again, several times a year a drive would fail or there would be some other issue. Often a drive would be marked as faulty but then after a few restarts it would show as ok again. Currently the whole thing is somehow marked 'read only' because things are failing again. \n\nI am by no means a power user. I'm a photographer and the RAID is where I store my archive. Current work lives on my MBP's internal SSD and gets backed up to an external SSD. Only finished projects gets stored to the RAID archive. This is a few projects a month, ranging from 20GB for small photo projects to up to 400GB for larger video projects. Every now and then I need to access one of these projects but they mostly just sit there. I keep local backups of the RAID and everything gets backed up online as well with Backblaze. \n\nI am getting so sick of having to deal with RAID issues, I'm thinking it might just be easier to use a bunch of loose 16TB drives and manage everything manually. The total archive is currently around 20TB so I could have the older stuff on one 16TB and then have most of the another 16TB for more recent stuff. Obviously with local and online backups of each. \n\nWhat say you? Have I just been unlucky with my RAIDs? Is this normal? Am I doing something wrong?", "author_fullname": "t2_43krw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it normal for a 4 disk DAS in RAID5 to have some sort of issue every few months?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165lugs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693418383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My first DAS was a Promise Pegasus R4, back when 4x4TB drives seemed like a lot of storage. Several times a year a drive would fail and I would replace it. This got so tiresome that I contacted Promise and they sent me a new R4, which didn&amp;#39;t change much. &lt;/p&gt;\n\n&lt;p&gt;Two years ago I replaced the R4 with an OWC Thunderbay 4, and I put 4 brand new 16TB drives inside it. Again, several times a year a drive would fail or there would be some other issue. Often a drive would be marked as faulty but then after a few restarts it would show as ok again. Currently the whole thing is somehow marked &amp;#39;read only&amp;#39; because things are failing again. &lt;/p&gt;\n\n&lt;p&gt;I am by no means a power user. I&amp;#39;m a photographer and the RAID is where I store my archive. Current work lives on my MBP&amp;#39;s internal SSD and gets backed up to an external SSD. Only finished projects gets stored to the RAID archive. This is a few projects a month, ranging from 20GB for small photo projects to up to 400GB for larger video projects. Every now and then I need to access one of these projects but they mostly just sit there. I keep local backups of the RAID and everything gets backed up online as well with Backblaze. &lt;/p&gt;\n\n&lt;p&gt;I am getting so sick of having to deal with RAID issues, I&amp;#39;m thinking it might just be easier to use a bunch of loose 16TB drives and manage everything manually. The total archive is currently around 20TB so I could have the older stuff on one 16TB and then have most of the another 16TB for more recent stuff. Obviously with local and online backups of each. &lt;/p&gt;\n\n&lt;p&gt;What say you? Have I just been unlucky with my RAIDs? Is this normal? Am I doing something wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165lugs", "is_robot_indexable": true, "report_reasons": null, "author": "lilgreenrosetta", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165lugs/is_it_normal_for_a_4_disk_das_in_raid5_to_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165lugs/is_it_normal_for_a_4_disk_das_in_raid5_to_have/", "subreddit_subscribers": 700866, "created_utc": 1693418383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Trying to download [https://web.archive.org/web/20221227075452/https://github.com/nextdns/metadata](https://web.archive.org/web/20221227075452/https://github.com/nextdns/metadata) but only has ReadMe.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nAbout the  repo [https://www.reddit.com/r/nextdns/comments/163tl4l/nextdns\\_hid\\_their\\_blocklists\\_where\\_to\\_get\\_them\\_now/](https://www.reddit.com/r/nextdns/comments/163tl4l/nextdns_hid_their_blocklists_where_to_get_them_now/)", "author_fullname": "t2_4jurunac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download GitHub repo from archive.org ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1659ffo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693386195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to download &lt;a href=\"https://web.archive.org/web/20221227075452/https://github.com/nextdns/metadata\"&gt;https://web.archive.org/web/20221227075452/https://github.com/nextdns/metadata&lt;/a&gt; but only has ReadMe.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;About the  repo &lt;a href=\"https://www.reddit.com/r/nextdns/comments/163tl4l/nextdns_hid_their_blocklists_where_to_get_them_now/\"&gt;https://www.reddit.com/r/nextdns/comments/163tl4l/nextdns_hid_their_blocklists_where_to_get_them_now/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?auto=webp&amp;s=e051bbf633f265539207716db902ea2015f4dfaf", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=87f7ddca45ea443a68693203e54efa62b7aceb22", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9be88dd4b5cdde01df6fb5c7783a2e6d9b2ba075", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=445e7208c5fb379c68b907b9bab5f08243e29647", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=079c07200cafb4f222be6056a1ba8ebff223c122", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=40060d92fa7c860a48cb70337c91386c62d218e9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=00f8dcddd741e469a9e60da33da2c51432abb124", "width": 1080, "height": 540}], "variants": {}, "id": "nYamHCyV1AG3uPhhStxxBypuzgl11wxNWxQrh7DB-e0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1659ffo", "is_robot_indexable": true, "report_reasons": null, "author": "RedditNoobie777", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1659ffo/how_to_download_github_repo_from_archiveorg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1659ffo/how_to_download_github_repo_from_archiveorg/", "subreddit_subscribers": 700866, "created_utc": 1693386195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently working on regular backups for g-mail accounts at the request of a company, they have 11 g-mail accounts that need to be saved once a week, I looked for many solutions but couldn't find anything that would be decent in this case. Do you guys know of any paid or free options for this?", "author_fullname": "t2_7yq32uns", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need to backup e-mails from g-mail regularly", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165n5vi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693421385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently working on regular backups for g-mail accounts at the request of a company, they have 11 g-mail accounts that need to be saved once a week, I looked for many solutions but couldn&amp;#39;t find anything that would be decent in this case. Do you guys know of any paid or free options for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165n5vi", "is_robot_indexable": true, "report_reasons": null, "author": "Vigil-On-Speed", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165n5vi/i_need_to_backup_emails_from_gmail_regularly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165n5vi/i_need_to_backup_emails_from_gmail_regularly/", "subreddit_subscribers": 700866, "created_utc": 1693421385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I've been using Veeam agent, their free solution, to make weekly image backups of entire drives on my PC. This is my main backup in the event of a drive failure.\n\nI want to also make a nightly backup job for my user folder, specifically to backup my photography folders and Lightroom catalog, which is basically all that's in my user folder anyway. I make enough changes on a daily basis to images that my weekly backup might lose some work and I don't want to have to run that long (full volume/drive) backup job nightly.\n\nUnfortunately Veeam Agent doesn't allow more than one backup job for the free version, otherwise it could do what I want. See I'm trying to move away from Onedrive/Cloud backup solutions and migrate to keeping all my stuff backed up myself.\n\nIf I have to I guess I could just use a different program for the individual user folder backup, but I'd prefer to keep it all consolidated to one solution.", "author_fullname": "t2_gg9x4qvy9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a decent, free backup software/solution that allows periodic image backups of full volumes, but also regular backups of individual files/folders?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16623xc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693460120.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693459822.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been using Veeam agent, their free solution, to make weekly image backups of entire drives on my PC. This is my main backup in the event of a drive failure.&lt;/p&gt;\n\n&lt;p&gt;I want to also make a nightly backup job for my user folder, specifically to backup my photography folders and Lightroom catalog, which is basically all that&amp;#39;s in my user folder anyway. I make enough changes on a daily basis to images that my weekly backup might lose some work and I don&amp;#39;t want to have to run that long (full volume/drive) backup job nightly.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately Veeam Agent doesn&amp;#39;t allow more than one backup job for the free version, otherwise it could do what I want. See I&amp;#39;m trying to move away from Onedrive/Cloud backup solutions and migrate to keeping all my stuff backed up myself.&lt;/p&gt;\n\n&lt;p&gt;If I have to I guess I could just use a different program for the individual user folder backup, but I&amp;#39;d prefer to keep it all consolidated to one solution.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16623xc", "is_robot_indexable": true, "report_reasons": null, "author": "YuDunMessedUpAyAyron", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16623xc/looking_for_a_decent_free_backup_softwaresolution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16623xc/looking_for_a_decent_free_backup_softwaresolution/", "subreddit_subscribers": 700866, "created_utc": 1693459822.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, I\u2019ve been thinking about making my first NAS and was wondering if anyone here has some advice for what case I should get? Im looking for something around 200$ or less that has around 6 - 8 hard drive bays.\n\nI\u2019d also love any random advice people have and some tips about what OS I should use(very comfortable with Linux fyi).\n\nSorry if this the wrong sub, didn\u2019t seem like there are any NAS specific subreddits.\n\nThanks", "author_fullname": "t2_8b6h5a5g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thinking about making my first NAS.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165qlnz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693429254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I\u2019ve been thinking about making my first NAS and was wondering if anyone here has some advice for what case I should get? Im looking for something around 200$ or less that has around 6 - 8 hard drive bays.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d also love any random advice people have and some tips about what OS I should use(very comfortable with Linux fyi).&lt;/p&gt;\n\n&lt;p&gt;Sorry if this the wrong sub, didn\u2019t seem like there are any NAS specific subreddits.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165qlnz", "is_robot_indexable": true, "report_reasons": null, "author": "Wafflasy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165qlnz/thinking_about_making_my_first_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165qlnz/thinking_about_making_my_first_nas/", "subreddit_subscribers": 700866, "created_utc": 1693429254.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am planning on upgrading my current setup. I currently have 3 of the WD Red NAS drives configured in a RaidZ1 configuration. I would prefer a z2 configuration but when I built my setup I could only afford the 3 drives. Currently, write speeds are PAINFULLY SLOW. With the current setup I am only getting the write speed of a single HDD which puts me at about 20 MB/s. I am looking for advice on how to configure an upgrade to both provide at least 2 disks of parity and balance speed. I am looking at having 8 - 10 drives in total. Should I setup 2 z2 pools and stripe data between them? I have seen posts where people talk about getting much higher write speeds with HDDs, so if you possess some of this sacred and ancient knowledge please share :)", "author_fullname": "t2_sotym", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any recommendations for a zpool config to balance speed and redundancy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165mug1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693420672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning on upgrading my current setup. I currently have 3 of the WD Red NAS drives configured in a RaidZ1 configuration. I would prefer a z2 configuration but when I built my setup I could only afford the 3 drives. Currently, write speeds are PAINFULLY SLOW. With the current setup I am only getting the write speed of a single HDD which puts me at about 20 MB/s. I am looking for advice on how to configure an upgrade to both provide at least 2 disks of parity and balance speed. I am looking at having 8 - 10 drives in total. Should I setup 2 z2 pools and stripe data between them? I have seen posts where people talk about getting much higher write speeds with HDDs, so if you possess some of this sacred and ancient knowledge please share :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165mug1", "is_robot_indexable": true, "report_reasons": null, "author": "Squiggly-Wiggly", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165mug1/any_recommendations_for_a_zpool_config_to_balance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165mug1/any_recommendations_for_a_zpool_config_to_balance/", "subreddit_subscribers": 700866, "created_utc": 1693420672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nI have QNAP TS-133-US with 4TB WD RED. I transferred the HDD to my PC, but my PC is not detecting the data in the HDD and requires me to format it first. Is there a way to restore the contents of the HDD? \n\nMany thanks.", "author_fullname": "t2_16edim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD with Qnap OS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16597u9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693385452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I have QNAP TS-133-US with 4TB WD RED. I transferred the HDD to my PC, but my PC is not detecting the data in the HDD and requires me to format it first. Is there a way to restore the contents of the HDD? &lt;/p&gt;\n\n&lt;p&gt;Many thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16597u9", "is_robot_indexable": true, "report_reasons": null, "author": "GamesBond5", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16597u9/hdd_with_qnap_os/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16597u9/hdd_with_qnap_os/", "subreddit_subscribers": 700866, "created_utc": 1693385452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "11 enterprise ssd''s 3.8tb 12Gb/s", "author_fullname": "t2_b0te7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "got these for free from work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_16612nu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jKpG5owXegMzmXIYd2mJC-F6q22IzyHC4YlFbbie3ao.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693456455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;11 enterprise ssd&amp;#39;&amp;#39;s 3.8tb 12Gb/s&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/hqjtn9ghjdlb1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/hqjtn9ghjdlb1.png?auto=webp&amp;s=008453c4970de28246d02d87909dcbfbb4fba7d9", "width": 720, "height": 960}, "resolutions": [{"url": "https://preview.redd.it/hqjtn9ghjdlb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c13ab6dfbea4bc0d42f68b455d27de8e2583c599", "width": 108, "height": 144}, {"url": "https://preview.redd.it/hqjtn9ghjdlb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7bfccd8e227ca64906ca2fc8aaea9f239133e5d2", "width": 216, "height": 288}, {"url": "https://preview.redd.it/hqjtn9ghjdlb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b5b46db09e2726e055cd48b4feaa51b62e93368", "width": 320, "height": 426}, {"url": "https://preview.redd.it/hqjtn9ghjdlb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9c4953ae5324a4ea7ed2a45393b34d3feded7b84", "width": 640, "height": 853}], "variants": {}, "id": "PcKLFH5KtZxRdsbNtse7BWnX2MLodPA7QkownCQvBa4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16612nu", "is_robot_indexable": true, "report_reasons": null, "author": "hunterguy4", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16612nu/got_these_for_free_from_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/hqjtn9ghjdlb1.png", "subreddit_subscribers": 700866, "created_utc": 1693456455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, a while ago I bought two drives, wanting to use them as one big drive I created a linear array. Months later, I'm here realizing that this might have been stupid.\n\nPlan is to get two more of those same size drives, and also expand more in the future whenever the wallet allows, so I'd like to go with raid6 or raid10 (Please give some opinions). I tried to find something on the web about it but I either suck at the google game, or there is nothing soo... \n\nHow do I get rid of my linear soft raid (mdadm) without data loss? The raid is fine right now, all drives are healthy and I plan to use them once I reconfigure it with more drives as well, the current data does not yet exceed the first disk, and I'm just planning ahead.\n\nThanks in advance &lt;3", "author_fullname": "t2_67eamyy4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Escape linear-raid mistake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165rdrz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693445069.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693431046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, a while ago I bought two drives, wanting to use them as one big drive I created a linear array. Months later, I&amp;#39;m here realizing that this might have been stupid.&lt;/p&gt;\n\n&lt;p&gt;Plan is to get two more of those same size drives, and also expand more in the future whenever the wallet allows, so I&amp;#39;d like to go with raid6 or raid10 (Please give some opinions). I tried to find something on the web about it but I either suck at the google game, or there is nothing soo... &lt;/p&gt;\n\n&lt;p&gt;How do I get rid of my linear soft raid (mdadm) without data loss? The raid is fine right now, all drives are healthy and I plan to use them once I reconfigure it with more drives as well, the current data does not yet exceed the first disk, and I&amp;#39;m just planning ahead.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance &amp;lt;3&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "32TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165rdrz", "is_robot_indexable": true, "report_reasons": null, "author": "New_Yogurt_521", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/165rdrz/escape_linearraid_mistake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165rdrz/escape_linearraid_mistake/", "subreddit_subscribers": 700866, "created_utc": 1693431046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been getting errors like this. It has me worried that either a drive is having issues or snapraid is.\n\n`Data error in file 'C:/Disks/03/PoolPart.65c87c3b-b51c-49c9-b336-d931e3fa592b/TV/file.mkv' at position '24388', diff bits 64/128`\n\nSometimes after a sync when this happens it mentions a data error and tells me the run the -status or -fix command. It usually fixes the error but there has been one unrecoverable a few times.\n\nThe drives check out with stable bit drive scanner. And the file is easily replaceable, but this has be concerned of what will happen in the event of a failure. Are there more problems happening under the surface and should I trust snapraid.", "author_fullname": "t2_f8az5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snapraid error help please", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165kj2z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693415422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been getting errors like this. It has me worried that either a drive is having issues or snapraid is.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Data error in file &amp;#39;C:/Disks/03/PoolPart.65c87c3b-b51c-49c9-b336-d931e3fa592b/TV/file.mkv&amp;#39; at position &amp;#39;24388&amp;#39;, diff bits 64/128&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Sometimes after a sync when this happens it mentions a data error and tells me the run the -status or -fix command. It usually fixes the error but there has been one unrecoverable a few times.&lt;/p&gt;\n\n&lt;p&gt;The drives check out with stable bit drive scanner. And the file is easily replaceable, but this has be concerned of what will happen in the event of a failure. Are there more problems happening under the surface and should I trust snapraid.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165kj2z", "is_robot_indexable": true, "report_reasons": null, "author": "light5out", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165kj2z/snapraid_error_help_please/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165kj2z/snapraid_error_help_please/", "subreddit_subscribers": 700866, "created_utc": 1693415422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, just investigating which burner should I buy in order to backup my stuff to M-DISK. \n\nIn [tech spec](https://www.asus.com/us/motherboards-components/optical-drives/external-dvd-drive/zendrive-u9m-sdrw-08u9m-u/techspec/) is written that there is support for M-DISK (write x 4 and read x 8). \n\nAny information about it? Anyone tried this ASUS writer with M-DISKs and different sizes (25, 50 or even 100 GB)?\n\nIt looks too cheap for standard Blu-ray/M-DISK writers (mostly above 100 $).\n\n&amp;#x200B;", "author_fullname": "t2_cuk0x87h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Asus ZenDrive U9M (SDRW-08U9M-U) and M-DISKs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165cwe5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693397301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, just investigating which burner should I buy in order to backup my stuff to M-DISK. &lt;/p&gt;\n\n&lt;p&gt;In &lt;a href=\"https://www.asus.com/us/motherboards-components/optical-drives/external-dvd-drive/zendrive-u9m-sdrw-08u9m-u/techspec/\"&gt;tech spec&lt;/a&gt; is written that there is support for M-DISK (write x 4 and read x 8). &lt;/p&gt;\n\n&lt;p&gt;Any information about it? Anyone tried this ASUS writer with M-DISKs and different sizes (25, 50 or even 100 GB)?&lt;/p&gt;\n\n&lt;p&gt;It looks too cheap for standard Blu-ray/M-DISK writers (mostly above 100 $).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165cwe5", "is_robot_indexable": true, "report_reasons": null, "author": "NTBBT", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165cwe5/asus_zendrive_u9m_sdrw08u9mu_and_mdisks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165cwe5/asus_zendrive_u9m_sdrw08u9mu_and_mdisks/", "subreddit_subscribers": 700866, "created_utc": 1693397301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So iv got a home  server rack and some always on Internet connections iv got split over the 2 servers in the rack 24TB of SAS drives and I'm at a loss on what to store on them i was wondering do you guys and girls have any suggestions (sensible) as to what i could put on them for preservation.\n\nI was originally thinking about using them with StorJ but i don't want to be running these servers 24/7 to maybe get a little something out of it if i'm lucky... I would much sooner archive some data of value...\n\nIf any of you know any good archival causes that could do with help storing data please let me know...\n\nThanks in Advance!", "author_fullname": "t2_fpuua6fxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Worthy Causes....", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165t0sh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693434936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So iv got a home  server rack and some always on Internet connections iv got split over the 2 servers in the rack 24TB of SAS drives and I&amp;#39;m at a loss on what to store on them i was wondering do you guys and girls have any suggestions (sensible) as to what i could put on them for preservation.&lt;/p&gt;\n\n&lt;p&gt;I was originally thinking about using them with StorJ but i don&amp;#39;t want to be running these servers 24/7 to maybe get a little something out of it if i&amp;#39;m lucky... I would much sooner archive some data of value...&lt;/p&gt;\n\n&lt;p&gt;If any of you know any good archival causes that could do with help storing data please let me know...&lt;/p&gt;\n\n&lt;p&gt;Thanks in Advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165t0sh", "is_robot_indexable": true, "report_reasons": null, "author": "sashamar484", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165t0sh/worthy_causes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165t0sh/worthy_causes/", "subreddit_subscribers": 700866, "created_utc": 1693434936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm backing up a bunch of drives to my NAS and I want to make sure all is good before I backup to cloud and delete from the drives. I'm hoping for a program that will go through every file in every folder, hash it and verify they're the same and in the end give me a list of files/folders that are either not present in the first location or have hashes that do not match.\n\nI'm sure there is something that does this I just don't know the name for it", "author_fullname": "t2_n8citdgq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a program to verify files after they have been backed up to NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165gjn3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.42, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693406339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m backing up a bunch of drives to my NAS and I want to make sure all is good before I backup to cloud and delete from the drives. I&amp;#39;m hoping for a program that will go through every file in every folder, hash it and verify they&amp;#39;re the same and in the end give me a list of files/folders that are either not present in the first location or have hashes that do not match.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure there is something that does this I just don&amp;#39;t know the name for it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165gjn3", "is_robot_indexable": true, "report_reasons": null, "author": "CantPassReCAPTCHA", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165gjn3/is_there_a_program_to_verify_files_after_they/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165gjn3/is_there_a_program_to_verify_files_after_they/", "subreddit_subscribers": 700866, "created_utc": 1693406339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What's good r/DataHoarder(s),\n\nI'm deep in this media preservation project, trying to figure out how to conditionally re-encode videos based on their OG stats to save space, the end game here is to hit a VMAF score of at least 98.8, making sure I don't skimp on quality for space.\n\nWhile VMAF is a reliable after-the-fact metric, it doesn't lend much guidance for the initial re-encoding settings. Sure, I can use ffprobe to get a snapshot of the original metrics, but when it's go-time for picking those first-round encode settings, that's where I hit a wall.\n\nMy Current Approach is:\n\n1. Get the initial video stream info `ffprobe -v error -select_streams v:0 -show_entries stream=codec_name,height,width,bit_rate -of default=noprint_wrappers=1:nokey=1 video123.mp4`\n2. Then to re-encode based on trial-and-error `ffmpeg -hwaccel cuda -c:v h264_cuvid -i video123.mp4 -c:v hevc_nvenc -rc constqp -preset:v slow -cq 32 -c:a copy video123_HEVC_GPU.mp4`\n3. Then measure the VMAF on each run `ffmpeg -i video123.mp4 -i video123_HEVC_GPU_NEW.mp4 -filter_complex \"[0:v]select=not(mod(n\\,80)),scale=1280:720[main]; [1:v]select=not(mod(n\\,10)),scale=1280:720[ref]; [main][ref]libvmaf\" -an -f null -`\n\n* I've considered manually tweaking encoding settings until I hit the sweet spot, but that's a total time vampire and horribly inefficient. Even if I trim the encoding and down-sample my evals, I'm still stuck playing mad scientist trying to find the right encoding parameters.\n\nSo my questions would be:\n\n1. **Initial Encoding Presets**: Any rules of thumb or formulas for deciding initial re-encoding settings based on the original metrics?\n2. **Efficiency**: Are there any existing tools that could streamline this process and make it less manual?\n\nIf any of y'all got the info on this I'd appreciate it, I'd write out a script to recursively dig though each video in a directory and drop it on GitHub if I could nail this project", "author_fullname": "t2_eai7yd0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Media Preservation Project: How to Conditionally Re-encode Videos for Space Efficiency While Maintaining Quality?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165dzy1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.42, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693400641.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693400209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s good &lt;a href=\"/r/DataHoarder\"&gt;r/DataHoarder&lt;/a&gt;(s),&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m deep in this media preservation project, trying to figure out how to conditionally re-encode videos based on their OG stats to save space, the end game here is to hit a VMAF score of at least 98.8, making sure I don&amp;#39;t skimp on quality for space.&lt;/p&gt;\n\n&lt;p&gt;While VMAF is a reliable after-the-fact metric, it doesn&amp;#39;t lend much guidance for the initial re-encoding settings. Sure, I can use ffprobe to get a snapshot of the original metrics, but when it&amp;#39;s go-time for picking those first-round encode settings, that&amp;#39;s where I hit a wall.&lt;/p&gt;\n\n&lt;p&gt;My Current Approach is:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Get the initial video stream info &lt;code&gt;ffprobe -v error -select_streams v:0 -show_entries stream=codec_name,height,width,bit_rate -of default=noprint_wrappers=1:nokey=1 video123.mp4&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Then to re-encode based on trial-and-error &lt;code&gt;ffmpeg -hwaccel cuda -c:v h264_cuvid -i video123.mp4 -c:v hevc_nvenc -rc constqp -preset:v slow -cq 32 -c:a copy video123_HEVC_GPU.mp4&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Then measure the VMAF on each run &lt;code&gt;ffmpeg -i video123.mp4 -i video123_HEVC_GPU_NEW.mp4 -filter_complex &amp;quot;[0:v]select=not(mod(n\\,80)),scale=1280:720[main]; [1:v]select=not(mod(n\\,10)),scale=1280:720[ref]; [main][ref]libvmaf&amp;quot; -an -f null -&lt;/code&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I&amp;#39;ve considered manually tweaking encoding settings until I hit the sweet spot, but that&amp;#39;s a total time vampire and horribly inefficient. Even if I trim the encoding and down-sample my evals, I&amp;#39;m still stuck playing mad scientist trying to find the right encoding parameters.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So my questions would be:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Initial Encoding Presets&lt;/strong&gt;: Any rules of thumb or formulas for deciding initial re-encoding settings based on the original metrics?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Efficiency&lt;/strong&gt;: Are there any existing tools that could streamline this process and make it less manual?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;If any of y&amp;#39;all got the info on this I&amp;#39;d appreciate it, I&amp;#39;d write out a script to recursively dig though each video in a directory and drop it on GitHub if I could nail this project&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165dzy1", "is_robot_indexable": true, "report_reasons": null, "author": "JuIi0", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165dzy1/media_preservation_project_how_to_conditionally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165dzy1/media_preservation_project_how_to_conditionally/", "subreddit_subscribers": 700866, "created_utc": 1693400209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, \nI am building a new low powered NAS / Server around an N5105 Motherboard to replace my 11 year old Dell T110ii that was running Windows 10 with 3 storage  drives (1x16tb, 1x12tb and 1x5tb) that are pooled together with Stablebit Drive Pool. This has been great for many years as storage as well as Plex Server. \nI was going to go with a NAS specific OS like TrueNAS but it seems I need to buy some more High Capacity drives to actually use the ZFS to have redundancy, where as at the moment with DrivePool I have specific folders (photos, videos and other irriplacebale stuff) duplicated across multiple drives as well as remotely backed up. This means out of the  33tb of total storage I have about 30tb of useable storage with my most important documents and files duplicated across all 3 drives. \n\nI am wanting to reuse my drives, and funds are really not there for another 2 x 16tb drives. With this in mind is sticking with Windows for the new build an ok descion compared to moving over to TrueNAS and with purchasing new drives or losing a ton of storage. \n\nThanks.", "author_fullname": "t2_77qyrr6z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing an OS for new Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1659mpe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693386898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, \nI am building a new low powered NAS / Server around an N5105 Motherboard to replace my 11 year old Dell T110ii that was running Windows 10 with 3 storage  drives (1x16tb, 1x12tb and 1x5tb) that are pooled together with Stablebit Drive Pool. This has been great for many years as storage as well as Plex Server. \nI was going to go with a NAS specific OS like TrueNAS but it seems I need to buy some more High Capacity drives to actually use the ZFS to have redundancy, where as at the moment with DrivePool I have specific folders (photos, videos and other irriplacebale stuff) duplicated across multiple drives as well as remotely backed up. This means out of the  33tb of total storage I have about 30tb of useable storage with my most important documents and files duplicated across all 3 drives. &lt;/p&gt;\n\n&lt;p&gt;I am wanting to reuse my drives, and funds are really not there for another 2 x 16tb drives. With this in mind is sticking with Windows for the new build an ok descion compared to moving over to TrueNAS and with purchasing new drives or losing a ton of storage. &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1659mpe", "is_robot_indexable": true, "report_reasons": null, "author": "EquivalentTip4103", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1659mpe/choosing_an_os_for_new_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1659mpe/choosing_an_os_for_new_server/", "subreddit_subscribers": 700866, "created_utc": 1693386898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just got 2 new drives: a  Seagate HDD 3.5\" EXOS X16 16TB and a Seagate HDD 3.5\" EXOS X18 18TB.   \nI tried plugging them in like any other HDD. (my other drives are a Barracuda 2TB and 3x 4TB Ironwolf NAS Drives)  \n\n\nBut this does not seem to work. My thought now are as follows:  \n\n\nOr they need an other type of powercable? I see my Barracuda has +5 VDC +0.55 A and the new drives have +5 VDC and 1.00 A.  \n\n\nOr they BOTH got damaged while shipping.\n\nI hope it is not the latter.   \n\n\nAnybody has any idea how I am able to trouble shoot or fix the issue? Thanks in advance! (also hope I am at the right sub)  \n", "author_fullname": "t2_lj87k6a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would there be a reason my 2 new disks do not fire up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165rt8f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693432058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just got 2 new drives: a  Seagate HDD 3.5&amp;quot; EXOS X16 16TB and a Seagate HDD 3.5&amp;quot; EXOS X18 18TB.&lt;br/&gt;\nI tried plugging them in like any other HDD. (my other drives are a Barracuda 2TB and 3x 4TB Ironwolf NAS Drives)  &lt;/p&gt;\n\n&lt;p&gt;But this does not seem to work. My thought now are as follows:  &lt;/p&gt;\n\n&lt;p&gt;Or they need an other type of powercable? I see my Barracuda has +5 VDC +0.55 A and the new drives have +5 VDC and 1.00 A.  &lt;/p&gt;\n\n&lt;p&gt;Or they BOTH got damaged while shipping.&lt;/p&gt;\n\n&lt;p&gt;I hope it is not the latter.   &lt;/p&gt;\n\n&lt;p&gt;Anybody has any idea how I am able to trouble shoot or fix the issue? Thanks in advance! (also hope I am at the right sub)  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165rt8f", "is_robot_indexable": true, "report_reasons": null, "author": "gwntim", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165rt8f/would_there_be_a_reason_my_2_new_disks_do_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165rt8f/would_there_be_a_reason_my_2_new_disks_do_not/", "subreddit_subscribers": 700866, "created_utc": 1693432058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My WD drive started behaving weirdly at some point - first took a long time to get recognized in BIOS, restarted when reading/writing every few seconds, then at some point Windows stopped booting with it connected at all (even when hot plugged - it just freezes until drive is disconnected).\nI used HDDSuperClone to clone all of its data to new Seagate Barracuda drive, which was successful (100%). Now I want to completely erase WD drive and return it. How can I do it? Since Windows freaks out when it's connected, I guess I should use a boot USB like HDDSuperClone Xubuntu. What tools can I use?", "author_fullname": "t2_9edwyaot", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I fully erase faulty WD Blue drive in order to return it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165fdc3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693403572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My WD drive started behaving weirdly at some point - first took a long time to get recognized in BIOS, restarted when reading/writing every few seconds, then at some point Windows stopped booting with it connected at all (even when hot plugged - it just freezes until drive is disconnected).\nI used HDDSuperClone to clone all of its data to new Seagate Barracuda drive, which was successful (100%). Now I want to completely erase WD drive and return it. How can I do it? Since Windows freaks out when it&amp;#39;s connected, I guess I should use a boot USB like HDDSuperClone Xubuntu. What tools can I use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165fdc3", "is_robot_indexable": true, "report_reasons": null, "author": "Wapapamow", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165fdc3/how_can_i_fully_erase_faulty_wd_blue_drive_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165fdc3/how_can_i_fully_erase_faulty_wd_blue_drive_in/", "subreddit_subscribers": 700866, "created_utc": 1693403572.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}