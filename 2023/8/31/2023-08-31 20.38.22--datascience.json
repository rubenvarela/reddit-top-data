{"kind": "Listing", "data": {"after": "t3_1666n3b", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We started exploring automated scripts creation for 180\u00ba POV VR porn videos some two years ago as these were in strong demand on the SexLikeReal platform. The idea of interactive sex toys is to perfectly match the movement in the video with up to frame precision. It's an up and down stroker realtime synced with a video player while watching VR (also works with smartphones now).\n\nOnly 1 in 20 videos was scripted and the gap was growing exponentially. It takes up to two weeks to script manually. There are some very few people on Earth knowing the craft and the demand is growing fast with interactive sex toys hitting the market and becoming popular. Now we are looking to render 1,000 scripts in an hour.\n\nWe trained the model on 1,300 craft scripts created over many years and started to fine tune algorithms working hard with script creators and testers. One step after another and it started getting better. What was expected to be somewhat ok turned to be a cool product with quality much better than expected.\n\nThe scripts are generated at first pass. There was a manual QA in place while testing. Now it becomes a problem as we don't have capacity to come over thousands of scripts.\n\nIt's the first successful AI scripts attempt \ud83d\udd25\n\nSome user feedback and BTS how it was going https://forum.sexlikereal.com/d/4757-ai-scripts-latest-updates/96\n\nScripts: NSFW https://www.sexlikereal.com/tags/sex-toy-scripts-vr?type=ai NSFW \n\nLet me know what you think. Will be happy to answer your questions.\n\nThe reaction of the script creating guru we worked with was priceless:\n&gt;these again were all fully automated no manual touch ups? If so, then this is pretty huge improvements from the last\n\n&gt;no more harsh strokes anywhere\n&gt;depths are alot better matched than previous\n&gt;missed strokes in large sections seem to now have all been captured\n&gt;even obstruction parts are significantly improved\n&gt;important variety is still maintained in the script\n&gt;Script 10100 can be released as is, most guys wont notice anything problematic if at all\n&gt;(you could probably release them all and \u2018most\u2019 would be fine with them - especially if they havent tried a manual script for them). Biggest improvement is scene 34865 which is night and day difference. There isnt a whole left to improve to be honest as most guys will probably enjoy theseThese are the best AI versions I\u2019ve seen to date. Toughest parts are when multiple girls are going in different directions, but thats hard even for manual scripters", "author_fullname": "t2_tnsg2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[P] Just released the first batch of 1,000 perfectly synchronised AI sex toy scripts for 180\u00ba POV VR porn videos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165s4dn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 187, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 187, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693432788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We started exploring automated scripts creation for 180\u00ba POV VR porn videos some two years ago as these were in strong demand on the SexLikeReal platform. The idea of interactive sex toys is to perfectly match the movement in the video with up to frame precision. It&amp;#39;s an up and down stroker realtime synced with a video player while watching VR (also works with smartphones now).&lt;/p&gt;\n\n&lt;p&gt;Only 1 in 20 videos was scripted and the gap was growing exponentially. It takes up to two weeks to script manually. There are some very few people on Earth knowing the craft and the demand is growing fast with interactive sex toys hitting the market and becoming popular. Now we are looking to render 1,000 scripts in an hour.&lt;/p&gt;\n\n&lt;p&gt;We trained the model on 1,300 craft scripts created over many years and started to fine tune algorithms working hard with script creators and testers. One step after another and it started getting better. What was expected to be somewhat ok turned to be a cool product with quality much better than expected.&lt;/p&gt;\n\n&lt;p&gt;The scripts are generated at first pass. There was a manual QA in place while testing. Now it becomes a problem as we don&amp;#39;t have capacity to come over thousands of scripts.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s the first successful AI scripts attempt \ud83d\udd25&lt;/p&gt;\n\n&lt;p&gt;Some user feedback and BTS how it was going &lt;a href=\"https://forum.sexlikereal.com/d/4757-ai-scripts-latest-updates/96\"&gt;https://forum.sexlikereal.com/d/4757-ai-scripts-latest-updates/96&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Scripts: NSFW &lt;a href=\"https://www.sexlikereal.com/tags/sex-toy-scripts-vr?type=ai\"&gt;https://www.sexlikereal.com/tags/sex-toy-scripts-vr?type=ai&lt;/a&gt; NSFW &lt;/p&gt;\n\n&lt;p&gt;Let me know what you think. Will be happy to answer your questions.&lt;/p&gt;\n\n&lt;p&gt;The reaction of the script creating guru we worked with was priceless:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;these again were all fully automated no manual touch ups? If so, then this is pretty huge improvements from the last&lt;/p&gt;\n\n&lt;p&gt;no more harsh strokes anywhere\ndepths are alot better matched than previous\nmissed strokes in large sections seem to now have all been captured\neven obstruction parts are significantly improved\nimportant variety is still maintained in the script\nScript 10100 can be released as is, most guys wont notice anything problematic if at all\n(you could probably release them all and \u2018most\u2019 would be fine with them - especially if they havent tried a manual script for them). Biggest improvement is scene 34865 which is night and day difference. There isnt a whole left to improve to be honest as most guys will probably enjoy theseThese are the best AI versions I\u2019ve seen to date. Toughest parts are when multiple girls are going in different directions, but thats hard even for manual scripters&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?auto=webp&amp;s=deadb1d32927e9d9e27d2c3c3cd412216c5d4d87", "width": 1366, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=97e8a90268f65e19efa163037e04a8d85692bd85", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d480bf299d3cc4c9fd24683ad70163e0eec9caaf", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=578aaa755dbe17bcbb6e5ee544bfdb95984b3858", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b783012248ffe14cc0a7119d82224530e82d0708", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=edb253e3e0b90888f6eced52803928a89bf4e28d", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ecd4a04c4d47efb30e5164a121024c305d0c991f", "width": 1080, "height": 607}], "variants": {"obfuscated": {"source": {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=4687b57fb24a55accb91bd40720e43ec71222c2e", "width": 1366, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=6990fad11f0e9f0b1e278ffc9f5db33bfc714d19", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=90f7c5a20d3e10e30a81051aa51695e2ac4a078d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=fc6b420f6c4ef822bae70d7c52ee8af67a893096", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=947360e01bf4cc61b126b494ca0ad7ca52e13af2", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=3fa1556ff96e386d3ba8c68313790c519bdd6bc5", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=0c781480d65e57e2420349f30bc560e858097745", "width": 1080, "height": 607}]}, "nsfw": {"source": {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=4687b57fb24a55accb91bd40720e43ec71222c2e", "width": 1366, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=6990fad11f0e9f0b1e278ffc9f5db33bfc714d19", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=90f7c5a20d3e10e30a81051aa51695e2ac4a078d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=fc6b420f6c4ef822bae70d7c52ee8af67a893096", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=947360e01bf4cc61b126b494ca0ad7ca52e13af2", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=3fa1556ff96e386d3ba8c68313790c519bdd6bc5", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/DCnSLIiDS--wlLYV7F-rLRzM3uecSOdSxk_MSC-wNms.jpg?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=0c781480d65e57e2420349f30bc560e858097745", "width": 1080, "height": 607}]}}, "id": "-RemYreMRu12lrMRUYg5TVJ8TpALewRzsRsx7M4Eqss"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "165s4dn", "is_robot_indexable": true, "report_reasons": null, "author": "doublevr", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/165s4dn/p_just_released_the_first_batch_of_1000_perfectly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/165s4dn/p_just_released_the_first_batch_of_1000_perfectly/", "subreddit_subscribers": 1023977, "created_utc": 1693432788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It is easy to be swayed by the llm-gen-ai hype, while analyst jobs actually constitute the majority of the job market.\n\nThese are new job openings that my bots at [jobs-in-data.com](https://jobs-in-data.com) indexed in August:\n\nTotal Jobs: 75,947\n\n**Split by Position:**\n\n* Analyst: 52,738 jobs (69.44%)\n* Other: 6,933 jobs (9.13%)\n* Other Engineers: 4,639 jobs (6.11%)\n* Data Engineer: 4,575 jobs (6.02%)\n* Data Scientist: 3,419 jobs (4.50%)\n* Data Manager: 1,473 jobs (1.94%)\n* Machine Learning Engineer: 951 jobs (1.25%)\n* Data Entry Clerk: 627 jobs (0.83%)\n* Actuary: 592 jobs (0.78%)\n\nI am also adding the most sought-after platform-related skills (right - MS Excel is not a platform - but is put there just for comparison).\n\n**Split by Platform:**\n\n* MS Excel: 38,408 jobs (50.57%)\n* Tableau: 6,452 jobs (8.50%)\n* Power BI: 6,187 jobs (8.15%)\n* SalesForce: 2,537 jobs (3.34%)\n* Apache Hadoop: 2,256 jobs (2.97%)\n* Snowflake: 2,043 jobs (2.69%)\n* Apache Kafka: 1,787 jobs (2.35%)\n* Databricks: 1,510 jobs (1.99%)\n* Amazon Redshift: 1,013 jobs (1.33%)\n* Google BigQuery: 840 jobs (1.11%)\n* Alteryx: 712 jobs (0.94%)\n* Teradata: 516 jobs (0.68%)\n* Cloudera: 215 jobs (0.28%)\n* Microsoft Azure Synapse Analytics: 203 jobs (0.27%)\n* Hortonworks: 102 jobs (0.13%)\n* Delta Lake: 100 jobs (0.13%)\n* Qubole: 3 jobs (0.00%)\n\n&amp;#x200B;\n\n\\[EDIT\\]:\n\nAlso, as per requests below, I show required programming languages\n\n&amp;#x200B;\n\nhttps://preview.redd.it/vy652vwk3hlb1.png?width=2560&amp;format=png&amp;auto=webp&amp;s=103722ce813491cb1bca64fd1f33c0e88b7cd2cc", "author_fullname": "t2_h7ibth00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analysts &gt; others (in terms of open job positions)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vy652vwk3hlb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=062de38e097bb7a13ca3640500387786197c5714"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=951e9dd75586bbc29d914dbc2e3ed8cef9560f85"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e45ce2cf98b32e9674bf8413b6add686b2ad5366"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6a925ae463fc6a0a7dfe2c717d30f14b06b5c036"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f27cbb13dfc5e12b0052a18265681de0843502d4"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aa6a9666d6b5bd7a028acdc3413601b0787df141"}], "s": {"y": 1440, "x": 2560, "u": "https://preview.redd.it/vy652vwk3hlb1.png?width=2560&amp;format=png&amp;auto=webp&amp;s=103722ce813491cb1bca64fd1f33c0e88b7cd2cc"}, "id": "vy652vwk3hlb1"}}, "name": "t3_166bj2q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 82, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 82, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qLtqezLdWFqW3ZQ7eLTybyYOHNW9bqWbEcrmbcn3e7U.jpg", "edited": 1693499535.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693489327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It is easy to be swayed by the llm-gen-ai hype, while analyst jobs actually constitute the majority of the job market.&lt;/p&gt;\n\n&lt;p&gt;These are new job openings that my bots at &lt;a href=\"https://jobs-in-data.com\"&gt;jobs-in-data.com&lt;/a&gt; indexed in August:&lt;/p&gt;\n\n&lt;p&gt;Total Jobs: 75,947&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Split by Position:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Analyst: 52,738 jobs (69.44%)&lt;/li&gt;\n&lt;li&gt;Other: 6,933 jobs (9.13%)&lt;/li&gt;\n&lt;li&gt;Other Engineers: 4,639 jobs (6.11%)&lt;/li&gt;\n&lt;li&gt;Data Engineer: 4,575 jobs (6.02%)&lt;/li&gt;\n&lt;li&gt;Data Scientist: 3,419 jobs (4.50%)&lt;/li&gt;\n&lt;li&gt;Data Manager: 1,473 jobs (1.94%)&lt;/li&gt;\n&lt;li&gt;Machine Learning Engineer: 951 jobs (1.25%)&lt;/li&gt;\n&lt;li&gt;Data Entry Clerk: 627 jobs (0.83%)&lt;/li&gt;\n&lt;li&gt;Actuary: 592 jobs (0.78%)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am also adding the most sought-after platform-related skills (right - MS Excel is not a platform - but is put there just for comparison).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Split by Platform:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;MS Excel: 38,408 jobs (50.57%)&lt;/li&gt;\n&lt;li&gt;Tableau: 6,452 jobs (8.50%)&lt;/li&gt;\n&lt;li&gt;Power BI: 6,187 jobs (8.15%)&lt;/li&gt;\n&lt;li&gt;SalesForce: 2,537 jobs (3.34%)&lt;/li&gt;\n&lt;li&gt;Apache Hadoop: 2,256 jobs (2.97%)&lt;/li&gt;\n&lt;li&gt;Snowflake: 2,043 jobs (2.69%)&lt;/li&gt;\n&lt;li&gt;Apache Kafka: 1,787 jobs (2.35%)&lt;/li&gt;\n&lt;li&gt;Databricks: 1,510 jobs (1.99%)&lt;/li&gt;\n&lt;li&gt;Amazon Redshift: 1,013 jobs (1.33%)&lt;/li&gt;\n&lt;li&gt;Google BigQuery: 840 jobs (1.11%)&lt;/li&gt;\n&lt;li&gt;Alteryx: 712 jobs (0.94%)&lt;/li&gt;\n&lt;li&gt;Teradata: 516 jobs (0.68%)&lt;/li&gt;\n&lt;li&gt;Cloudera: 215 jobs (0.28%)&lt;/li&gt;\n&lt;li&gt;Microsoft Azure Synapse Analytics: 203 jobs (0.27%)&lt;/li&gt;\n&lt;li&gt;Hortonworks: 102 jobs (0.13%)&lt;/li&gt;\n&lt;li&gt;Delta Lake: 100 jobs (0.13%)&lt;/li&gt;\n&lt;li&gt;Qubole: 3 jobs (0.00%)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;[EDIT]:&lt;/p&gt;\n\n&lt;p&gt;Also, as per requests below, I show required programming languages&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vy652vwk3hlb1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=103722ce813491cb1bca64fd1f33c0e88b7cd2cc\"&gt;https://preview.redd.it/vy652vwk3hlb1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=103722ce813491cb1bca64fd1f33c0e88b7cd2cc&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166bj2q", "is_robot_indexable": true, "report_reasons": null, "author": "pg860", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166bj2q/analysts_others_in_terms_of_open_job_positions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166bj2q/analysts_others_in_terms_of_open_job_positions/", "subreddit_subscribers": 1023977, "created_utc": 1693489327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When will the industry realise if they make a large budget for juniors in just 3 years it will be trivial to find seniors", "author_fullname": "t2_b9zxq8w1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Over 2 million and not a single junior position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_166fyd5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 90, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 90, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pLwg1vRXb9fYAjtqes68LpkYbzEX3mKQN62GgtM74So.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693499671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When will the industry realise if they make a large budget for juniors in just 3 years it will be trivial to find seniors&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q5cizucz3hlb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q5cizucz3hlb1.jpg?auto=webp&amp;s=70ee458daff6a7eba8f1b45b025dbe22759b9db9", "width": 828, "height": 1008}, "resolutions": [{"url": "https://preview.redd.it/q5cizucz3hlb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=540e0b20513e438dc34debd43e42046226ed2927", "width": 108, "height": 131}, {"url": "https://preview.redd.it/q5cizucz3hlb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5f345782d28ae27473cfb823702872a42a6eeb93", "width": 216, "height": 262}, {"url": "https://preview.redd.it/q5cizucz3hlb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e9d34a32b8c6c431b3fa2b45e556e5b4aaa8d17", "width": 320, "height": 389}, {"url": "https://preview.redd.it/q5cizucz3hlb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bc0d8937b20517b17d0308eae90b27edd4e48faf", "width": 640, "height": 779}], "variants": {}, "id": "PCYRgPjep3dXh5zr873WHR6FDNMkaZxlgXhFA7m33qs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "166fyd5", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Reality2341", "discussion_type": null, "num_comments": 81, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166fyd5/over_2_million_and_not_a_single_junior_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q5cizucz3hlb1.jpg", "subreddit_subscribers": 1023977, "created_utc": 1693499671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been giving interviews every now and then but with little success.\n\nOne question is \"why looking for new job?\"\n\nto which I state \"looking to explore a new domain\".\n\nI'm currently in banking domain and truly want to switch.\n\nI'm applying for Sr. Analyst roles, not anything managerial or SME level.", "author_fullname": "t2_736ioria", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is \"change of domain\" not a good reason for job switch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1662ppu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693461813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been giving interviews every now and then but with little success.&lt;/p&gt;\n\n&lt;p&gt;One question is &amp;quot;why looking for new job?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;to which I state &amp;quot;looking to explore a new domain&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently in banking domain and truly want to switch.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m applying for Sr. Analyst roles, not anything managerial or SME level.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1662ppu", "is_robot_indexable": true, "report_reasons": null, "author": "jaegarbong", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1662ppu/is_change_of_domain_not_a_good_reason_for_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1662ppu/is_change_of_domain_not_a_good_reason_for_job/", "subreddit_subscribers": 1023977, "created_utc": 1693461813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_icnu6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New data strategy: German government recognises untapped data potential", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1667qft", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ikIKDm-eh5IkmjhYrx8r7pqyFFwO5Xu-LKrDuYJy9hk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693478875.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "euractiv.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.euractiv.com/section/data-privacy/news/new-data-strategy-german-government-recognises-untapped-data-potential/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fL8I_TRahYpQDbYpmWfiRqRcQdPGZPdmyyD_1dLPNF0.jpg?auto=webp&amp;s=50a41b77a34e1ac2bf48ffdc9d71a1941db6df80", "width": 800, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/fL8I_TRahYpQDbYpmWfiRqRcQdPGZPdmyyD_1dLPNF0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7cd046fb739bf05f183a890cd0999d352942f40d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/fL8I_TRahYpQDbYpmWfiRqRcQdPGZPdmyyD_1dLPNF0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0e0f5fdeaa2d8e3d0245dcc8183f085e0c2db6b5", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/fL8I_TRahYpQDbYpmWfiRqRcQdPGZPdmyyD_1dLPNF0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=27688813a47c18fdedc11c7bf0b99d76ab3c5c76", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/fL8I_TRahYpQDbYpmWfiRqRcQdPGZPdmyyD_1dLPNF0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b46f95afb4ef0daf64ee0d58711530a1e805b9f7", "width": 640, "height": 360}], "variants": {}, "id": "_FUrr4nkJJyC_TtHBSCwmBdqbKnATVApPRqYKZ1Dquc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1667qft", "is_robot_indexable": true, "report_reasons": null, "author": "allants2", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1667qft/new_data_strategy_german_government_recognises/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.euractiv.com/section/data-privacy/news/new-data-strategy-german-government-recognises-untapped-data-potential/", "subreddit_subscribers": 1023977, "created_utc": 1693478875.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'd like to get into the data science industry after spending 8 years in the academia side of data science. I can confidently say that I have a solid foundation on the theoretical side of data science and I have done some computer programming for my thesis and other projects, but I fear that I lack the industry-grade experience to pursue a career in the corporate world.\n\nIn our country, you have to experience other roles first before officially becoming a data scientist. Most people with science degrees that are not heavy on math start as data analysts. IT/CS/Stat/Math graduates usually start as data engineers.\n\nThe problem with my background is that I find the job requirements for data engineering **extremely intimidating**. I only know Python, R, SQL, MATLAB, and C, but somehow the job apparently requires me to also know Java, C# (.NET), Perl, Groovy, and JavaScript. On top of that, this is apparently an entry-level position. \n\nI feel like the only way for me to apply what I studied in school is to become a data engineer first. Unfortunately for me, the multitude of programming languages and the data engineering pipeline intimidates me.\n\nDoes anyone here have any stories to share about shifting from academia (heavy on theory, so-so applications) to the industry? Did any of you also find the IT-heavy background intimidating? I am eager to learn these languages and tech, but I also don't want to overwhelm myself and pretend as if I am fit for data engineering.", "author_fullname": "t2_bmbqthh3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For math/stat majors, do you think data engineering is intimidating?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1664dnx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693467484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to get into the data science industry after spending 8 years in the academia side of data science. I can confidently say that I have a solid foundation on the theoretical side of data science and I have done some computer programming for my thesis and other projects, but I fear that I lack the industry-grade experience to pursue a career in the corporate world.&lt;/p&gt;\n\n&lt;p&gt;In our country, you have to experience other roles first before officially becoming a data scientist. Most people with science degrees that are not heavy on math start as data analysts. IT/CS/Stat/Math graduates usually start as data engineers.&lt;/p&gt;\n\n&lt;p&gt;The problem with my background is that I find the job requirements for data engineering &lt;strong&gt;extremely intimidating&lt;/strong&gt;. I only know Python, R, SQL, MATLAB, and C, but somehow the job apparently requires me to also know Java, C# (.NET), Perl, Groovy, and JavaScript. On top of that, this is apparently an entry-level position. &lt;/p&gt;\n\n&lt;p&gt;I feel like the only way for me to apply what I studied in school is to become a data engineer first. Unfortunately for me, the multitude of programming languages and the data engineering pipeline intimidates me.&lt;/p&gt;\n\n&lt;p&gt;Does anyone here have any stories to share about shifting from academia (heavy on theory, so-so applications) to the industry? Did any of you also find the IT-heavy background intimidating? I am eager to learn these languages and tech, but I also don&amp;#39;t want to overwhelm myself and pretend as if I am fit for data engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1664dnx", "is_robot_indexable": true, "report_reasons": null, "author": "krabbypatty-o-fish", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1664dnx/for_mathstat_majors_do_you_think_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1664dnx/for_mathstat_majors_do_you_think_data_engineering/", "subreddit_subscribers": 1023977, "created_utc": 1693467484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am not talking about trying it out hoping to boost the performance. I'm asking what situations make you think that stacking would be the best approach here?\n\nI know it works because different models works best with certain type of problems and stacking helps you to combine such particular strengths of multiple models.\n\nBut I'm asking for an example that you encountered that would demonstrate this idea where the data told you to use stacking.", "author_fullname": "t2_4s456zpp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "People who are experienced with stacking ensembling, when do you use it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16673tm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693476839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not talking about trying it out hoping to boost the performance. I&amp;#39;m asking what situations make you think that stacking would be the best approach here?&lt;/p&gt;\n\n&lt;p&gt;I know it works because different models works best with certain type of problems and stacking helps you to combine such particular strengths of multiple models.&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m asking for an example that you encountered that would demonstrate this idea where the data told you to use stacking.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16673tm", "is_robot_indexable": true, "report_reasons": null, "author": "dopplegangery", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16673tm/people_who_are_experienced_with_stacking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16673tm/people_who_are_experienced_with_stacking/", "subreddit_subscribers": 1023977, "created_utc": 1693476839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nJust wondering what job title you would give to someone who exclusively uses Power BI to make dashboards and provide information from data queries.\n\nno SQL, Python or any other tools.\n\nrecently finished a masters in Data Science and was very excited to work in Data.\nApplied to a data analyst role to get work experience but as above this is all I have done. With no scope to change in the future.\n\nwould this be called a Data Analyst role or is there another name for it ??", "author_fullname": "t2_8lcykify", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exclusive Power BI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165r0b3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693430169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wondering what job title you would give to someone who exclusively uses Power BI to make dashboards and provide information from data queries.&lt;/p&gt;\n\n&lt;p&gt;no SQL, Python or any other tools.&lt;/p&gt;\n\n&lt;p&gt;recently finished a masters in Data Science and was very excited to work in Data.\nApplied to a data analyst role to get work experience but as above this is all I have done. With no scope to change in the future.&lt;/p&gt;\n\n&lt;p&gt;would this be called a Data Analyst role or is there another name for it ??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "165r0b3", "is_robot_indexable": true, "report_reasons": null, "author": "Largeish_cheese", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/165r0b3/exclusive_power_bi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/165r0b3/exclusive_power_bi/", "subreddit_subscribers": 1023977, "created_utc": 1693430169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In a bid to rival the United States\u2019 stronghold in the AI industry, Chinese search engine and AI firm Baidu, has made its ChatGPT-equivalent language model, Ernie Bot, fully available to the public. This marks a significant move on the AI chessboard.\n\nIf you want to stay on top of everything AI,\u00a0[look here first.](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=baidu-ai&amp;utm_campaign=campaign)\n\nhttps://preview.redd.it/3e08q8utihlb1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;s=e7779eea500a502465bef116fa53a2bbc23c4019\n\n**Why does this matter?**\n\n* **Baidu's public release of Ernie Bot signals the company's aggressive push in the generative AI market.** By opening up its model to the public, Baidu can leverage expansive real-world human feedback to improve Ernie Bot.\n* **China's determination to lead the AI industry is unabated,** with many tech firms launching their own generative models in response to OpenAI's popular ChatGPT. Baidu's move further fuels this rivalry.\n* **Regulation in China seems to support such AI advancements.** CEO Robin Li voiced his optimism about the AI regulations\u2014calling them \"more pro-innovation than regulation\".\n\n**What's the broader response?**\n\n* **Baidu's latest stride has boosted its stock price by over 3%,** underlining the market's high anticipation of Baidu's AI efforts.\n* **Ernie Bot has rocketed to the top of Apple's iOS free app chart in China.** This demonstrates a positive initial response from the public.\n\n**Regulation is key in China's AI game:**\n\n* **China has stringent regulations for the generative AI industry,** requiring a security review and government approvals before any product launch. Moreover, companies need to comply with governmental tech and data requests.\n* **The US, on the other hand, doesn't currently have such regulations in place.** A markedly different approach that could significantly influence the development and application of AI technologies.\n\nIf you like this kind of analysis,\u00a0you might want to [check this out](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=baidu-ai&amp;utm_campaign=campaign).\n\n[(source)](https://apnews.com/article/baidu-ai-chatbot-ernie-chatgpt-627bd09608816847907d41f44da235d9)", "author_fullname": "t2_h4jb4maul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Baidu publicly releases their AI chatbot Ernie Bot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3e08q8utihlb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d1b1b1f72729af1e0be763a013d42e2c15fa9ef2"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f75f9ef2b22fd8d70dd3387ad581296f74a20d76"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cd723570150ec115c9a63c2ccf5956e32c1ebef0"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f4da750348d5b7963360368f537ce39b7e8bf135"}, {"y": 639, "x": 960, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=358d17d55d50b4d79881057e6867a96eec11bf4f"}], "s": {"y": 682, "x": 1024, "u": "https://preview.redd.it/3e08q8utihlb1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;s=e7779eea500a502465bef116fa53a2bbc23c4019"}, "id": "3e08q8utihlb1"}}, "name": "t3_166i2tp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/rPQz06Dwfph2KnPWxOJOGKgRmPdZbNB9p1w88oxG6fA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1693504666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In a bid to rival the United States\u2019 stronghold in the AI industry, Chinese search engine and AI firm Baidu, has made its ChatGPT-equivalent language model, Ernie Bot, fully available to the public. This marks a significant move on the AI chessboard.&lt;/p&gt;\n\n&lt;p&gt;If you want to stay on top of everything AI,\u00a0&lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=baidu-ai&amp;amp;utm_campaign=campaign\"&gt;look here first.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3e08q8utihlb1.jpg?width=1024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e7779eea500a502465bef116fa53a2bbc23c4019\"&gt;https://preview.redd.it/3e08q8utihlb1.jpg?width=1024&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e7779eea500a502465bef116fa53a2bbc23c4019&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why does this matter?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Baidu&amp;#39;s public release of Ernie Bot signals the company&amp;#39;s aggressive push in the generative AI market.&lt;/strong&gt; By opening up its model to the public, Baidu can leverage expansive real-world human feedback to improve Ernie Bot.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;China&amp;#39;s determination to lead the AI industry is unabated,&lt;/strong&gt; with many tech firms launching their own generative models in response to OpenAI&amp;#39;s popular ChatGPT. Baidu&amp;#39;s move further fuels this rivalry.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Regulation in China seems to support such AI advancements.&lt;/strong&gt; CEO Robin Li voiced his optimism about the AI regulations\u2014calling them &amp;quot;more pro-innovation than regulation&amp;quot;.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;What&amp;#39;s the broader response?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Baidu&amp;#39;s latest stride has boosted its stock price by over 3%,&lt;/strong&gt; underlining the market&amp;#39;s high anticipation of Baidu&amp;#39;s AI efforts.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Ernie Bot has rocketed to the top of Apple&amp;#39;s iOS free app chart in China.&lt;/strong&gt; This demonstrates a positive initial response from the public.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Regulation is key in China&amp;#39;s AI game:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;China has stringent regulations for the generative AI industry,&lt;/strong&gt; requiring a security review and government approvals before any product launch. Moreover, companies need to comply with governmental tech and data requests.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;The US, on the other hand, doesn&amp;#39;t currently have such regulations in place.&lt;/strong&gt; A markedly different approach that could significantly influence the development and application of AI technologies.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you like this kind of analysis,\u00a0you might want to &lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=baidu-ai&amp;amp;utm_campaign=campaign\"&gt;check this out&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://apnews.com/article/baidu-ai-chatbot-ernie-chatgpt-627bd09608816847907d41f44da235d9\"&gt;(source)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?auto=webp&amp;s=8972442682f23755fe3d4d7aea312e1cff5c8512", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce15b9c726f05a168b1db503df7ab26f60f62501", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=177bdfd4af3db3eb7dfe0b92698bbd1d97974ee8", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3630ec555e6a1910b62043cf2097eb88a6f14ef5", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=312e7a99fa2a2080e445758016e4648398339990", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=87aa77b180bceb48e3af8ae0450b505860d95694", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=78860fb6488536b343b979bab9c14c0815d49eb5", "width": 1080, "height": 567}], "variants": {}, "id": "NPZM0p8FtC5HwSLNn0lZ-Kh6AiQlvJ78GtZ_8REUGxc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "166i2tp", "is_robot_indexable": true, "report_reasons": null, "author": "AIsupercharged", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166i2tp/baidu_publicly_releases_their_ai_chatbot_ernie_bot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166i2tp/baidu_publicly_releases_their_ai_chatbot_ernie_bot/", "subreddit_subscribers": 1023977, "created_utc": 1693504666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys,\n\nI've been working in the CV domain in the past 2 years and noticed that some peers, which are way more experienced than me (7+ yoe), will implement thier own versions of tools for commonly used tasks. Such examples include annotation tools or data pipelines that a pytorch dataloader is very much suited to perform (load files, split to sets, transform, argument. The basics really..)\n\nPersonally, I'm a lazy fak, so whenever I can I'll prefer an open source, widely used solution for such things. I get that sometimes building your own is a better option like when you have a special use case or want to optimize an important part, but for those type of common tasks I don't see the point.\n\nI consider my colleagues to be good at what they do, but couldn't get a real answer so I'm asking here, hoping for the more experienced of us to share their views.\n\nWhat are your thoughts on this? Where do you draw the line?", "author_fullname": "t2_18148gk5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When should I implement vs of the shelf open source?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16698zq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693483341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working in the CV domain in the past 2 years and noticed that some peers, which are way more experienced than me (7+ yoe), will implement thier own versions of tools for commonly used tasks. Such examples include annotation tools or data pipelines that a pytorch dataloader is very much suited to perform (load files, split to sets, transform, argument. The basics really..)&lt;/p&gt;\n\n&lt;p&gt;Personally, I&amp;#39;m a lazy fak, so whenever I can I&amp;#39;ll prefer an open source, widely used solution for such things. I get that sometimes building your own is a better option like when you have a special use case or want to optimize an important part, but for those type of common tasks I don&amp;#39;t see the point.&lt;/p&gt;\n\n&lt;p&gt;I consider my colleagues to be good at what they do, but couldn&amp;#39;t get a real answer so I&amp;#39;m asking here, hoping for the more experienced of us to share their views.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on this? Where do you draw the line?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16698zq", "is_robot_indexable": true, "report_reasons": null, "author": "Darmerr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16698zq/when_should_i_implement_vs_of_the_shelf_open/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16698zq/when_should_i_implement_vs_of_the_shelf_open/", "subreddit_subscribers": 1023977, "created_utc": 1693483341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Have you all noticed any changes in your own or your coworkers since ChatGpt came out (assuming you're able to use it at work)?\n\nMy main use cases for it are generating docstrings, writing unit tests, or making things more readable in general.\n\nIf the code you're writing is going to prod, I don't see why you wouldn't do some of these things at least, now that it's so much easier. \n\nAs far as I can tell, most are not writing better code now than they were before. Not really sure why.", "author_fullname": "t2_ha2yf9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Code quality changes since ChatGpt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165uxj7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693439713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you all noticed any changes in your own or your coworkers since ChatGpt came out (assuming you&amp;#39;re able to use it at work)?&lt;/p&gt;\n\n&lt;p&gt;My main use cases for it are generating docstrings, writing unit tests, or making things more readable in general.&lt;/p&gt;\n\n&lt;p&gt;If the code you&amp;#39;re writing is going to prod, I don&amp;#39;t see why you wouldn&amp;#39;t do some of these things at least, now that it&amp;#39;s so much easier. &lt;/p&gt;\n\n&lt;p&gt;As far as I can tell, most are not writing better code now than they were before. Not really sure why.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "165uxj7", "is_robot_indexable": true, "report_reasons": null, "author": "HungryQuant", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/165uxj7/code_quality_changes_since_chatgpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/165uxj7/code_quality_changes_since_chatgpt/", "subreddit_subscribers": 1023977, "created_utc": 1693439713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The US government has imposed expanded export restrictions affecting Nvidia\u2019s leading artificial intelligence chips, curbing their exportation beyond China to certain Middle Eastern countries.\n\nIf you want to stay on top of AI advances,\u00a0[look here first.](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=ai-nvidia&amp;utm_campaign=campaign)\n\nhttps://preview.redd.it/k0z0us7h0ilb1.png?width=1240&amp;format=png&amp;auto=webp&amp;s=ab701fb7ca76b158336e7f6f73adb02e0d9c6664\n\n**Why this matters:**\n\n* **Nvidia\u2019s A100 and H100 chips are affected:** These AI chips are important and used to accelerate machine-learning tasks on major AI applications like ChatGPT. Despite the restrictions, Nvidia maintains they won\u2019t have an \u201cimmediate material impact\u201d on its results.\n* **Other companies, like AMD, are also affected:** They\u2019ve reportedly received similar restrictions notice, hinting at a broader move by the US government to control the distribution of AI chip technology.\n* **The move is part of a larger geopolitical play:** These restrictions form part of the Biden administration\u2019s efforts to curtail Beijing\u2019s ability to capitalize on the AI revolution.\n\n**How Nvidia and the industry might respond:**\n\n* **Nvidia CEO Jensen Huang has cautioned the US:** In a Financial Times interview, Huang warned that imposing such restrictions could lead to \u201cenormous damage\u201d to the US tech industry, predicting China may become self-sufficient in AI chip development.\n* **Yet, Nvidia still managed impressive earnings recently:** Despite these challenges, Nvidia recently reported quarterly revenue of $13.5bn, exceeding predictions by $2bn.\n\nFurther restrictions could significantly alter the landscape for AI development, potentially fostering greater innovation in countries affected or even a race to develop independent solutions.\n\nP.S. If you like this kind of analysis,\u00a0you might want to [check this out](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=ai-nvidia&amp;utm_campaign=campaign).\n\n[(source)](https://www.theguardian.com/technology/2023/aug/31/us-restricts-exports-of-nvidia-ai-chips-to-middle-east)", "author_fullname": "t2_h4jb4maul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Breaking: US expands export restrictions on Nvidia AI chips to Middle East", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": true, "media_metadata": {"k0z0us7h0ilb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 64, "x": 108, "u": "https://preview.redd.it/k0z0us7h0ilb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=793795c738717cd4d75bf396c77dc3f3e630910d"}, {"y": 129, "x": 216, "u": "https://preview.redd.it/k0z0us7h0ilb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b56c9534ed5831776d4976de40b4f7be61f72729"}, {"y": 192, "x": 320, "u": "https://preview.redd.it/k0z0us7h0ilb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0632c585cf14383cdf8fbfaee3ca9f016f61defb"}, {"y": 384, "x": 640, "u": "https://preview.redd.it/k0z0us7h0ilb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=314dcc1dff4a942c91f3c92086bc46ffcfad7ae6"}, {"y": 576, "x": 960, "u": "https://preview.redd.it/k0z0us7h0ilb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d92ef4f470a78fa7b7928ed10d23dd3f040be364"}, {"y": 648, "x": 1080, "u": "https://preview.redd.it/k0z0us7h0ilb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8f961d93301040d9106d61e639fa646df9d5d38f"}], "s": {"y": 744, "x": 1240, "u": "https://preview.redd.it/k0z0us7h0ilb1.png?width=1240&amp;format=png&amp;auto=webp&amp;s=ab701fb7ca76b158336e7f6f73adb02e0d9c6664"}, "id": "k0z0us7h0ilb1"}}, "name": "t3_166krvo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/PSvIdM4wkBHLPYwf-NzvVNrbNcNa2FEDsvRt2MtEU_8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1693510798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The US government has imposed expanded export restrictions affecting Nvidia\u2019s leading artificial intelligence chips, curbing their exportation beyond China to certain Middle Eastern countries.&lt;/p&gt;\n\n&lt;p&gt;If you want to stay on top of AI advances,\u00a0&lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=ai-nvidia&amp;amp;utm_campaign=campaign\"&gt;look here first.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/k0z0us7h0ilb1.png?width=1240&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ab701fb7ca76b158336e7f6f73adb02e0d9c6664\"&gt;https://preview.redd.it/k0z0us7h0ilb1.png?width=1240&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ab701fb7ca76b158336e7f6f73adb02e0d9c6664&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why this matters:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Nvidia\u2019s A100 and H100 chips are affected:&lt;/strong&gt; These AI chips are important and used to accelerate machine-learning tasks on major AI applications like ChatGPT. Despite the restrictions, Nvidia maintains they won\u2019t have an \u201cimmediate material impact\u201d on its results.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Other companies, like AMD, are also affected:&lt;/strong&gt; They\u2019ve reportedly received similar restrictions notice, hinting at a broader move by the US government to control the distribution of AI chip technology.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;The move is part of a larger geopolitical play:&lt;/strong&gt; These restrictions form part of the Biden administration\u2019s efforts to curtail Beijing\u2019s ability to capitalize on the AI revolution.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;How Nvidia and the industry might respond:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Nvidia CEO Jensen Huang has cautioned the US:&lt;/strong&gt; In a Financial Times interview, Huang warned that imposing such restrictions could lead to \u201cenormous damage\u201d to the US tech industry, predicting China may become self-sufficient in AI chip development.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Yet, Nvidia still managed impressive earnings recently:&lt;/strong&gt; Despite these challenges, Nvidia recently reported quarterly revenue of $13.5bn, exceeding predictions by $2bn.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Further restrictions could significantly alter the landscape for AI development, potentially fostering greater innovation in countries affected or even a race to develop independent solutions.&lt;/p&gt;\n\n&lt;p&gt;P.S. If you like this kind of analysis,\u00a0you might want to &lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=ai-nvidia&amp;amp;utm_campaign=campaign\"&gt;check this out&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.theguardian.com/technology/2023/aug/31/us-restricts-exports-of-nvidia-ai-chips-to-middle-east\"&gt;(source)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?auto=webp&amp;s=8972442682f23755fe3d4d7aea312e1cff5c8512", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce15b9c726f05a168b1db503df7ab26f60f62501", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=177bdfd4af3db3eb7dfe0b92698bbd1d97974ee8", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3630ec555e6a1910b62043cf2097eb88a6f14ef5", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=312e7a99fa2a2080e445758016e4648398339990", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=87aa77b180bceb48e3af8ae0450b505860d95694", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/m25T0KLl0EPq2gxIYaASkncODJHc8QB_82behpL6X_o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=78860fb6488536b343b979bab9c14c0815d49eb5", "width": 1080, "height": 567}], "variants": {}, "id": "NPZM0p8FtC5HwSLNn0lZ-Kh6AiQlvJ78GtZ_8REUGxc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "166krvo", "is_robot_indexable": true, "report_reasons": null, "author": "AIsupercharged", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166krvo/breaking_us_expands_export_restrictions_on_nvidia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166krvo/breaking_us_expands_export_restrictions_on_nvidia/", "subreddit_subscribers": 1023977, "created_utc": 1693510798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_14izoucv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you ever deployed LLama on AWS Kubernetes? I'm stuck and getting many errors such as \"waiting for Auto Scaling Group\" anyone solved it before?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 21, "top_awarded_type": null, "hide_score": false, "name": "t3_166i0q0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/E0bOwqgp4ZqLwGCDW7yT7sZ1patojOxqY0lE1_9u6m4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693504526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/i1db7089ihlb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?auto=webp&amp;s=06859b5e9cc0d76ebdcd7c577e307f4b3e7160a1", "width": 1600, "height": 242}, "resolutions": [{"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=35f58a41721ace877fdd90c91dd23120125e8729", "width": 108, "height": 16}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2418dfc949e94a52a33fae911463365396c7a234", "width": 216, "height": 32}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4007ad0c712d5643c886ae7871338a2b536d0b8c", "width": 320, "height": 48}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff16e8eb8a8d281d35d26740e4e0a654b2021d0b", "width": 640, "height": 96}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aec65af0973b5f3f14bd9bf3d74c138e25a475bc", "width": 960, "height": 145}, {"url": "https://preview.redd.it/i1db7089ihlb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7c72478925a6d0745b66cf5c936c4c73ebd67ea5", "width": 1080, "height": 163}], "variants": {}, "id": "pIR74sF8xKS0ayVDm8otnRW2VYpeQto8G2JnwyIk_jM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "166i0q0", "is_robot_indexable": true, "report_reasons": null, "author": "AILaunchpad", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166i0q0/have_you_ever_deployed_llama_on_aws_kubernetes_im/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/i1db7089ihlb1.jpg", "subreddit_subscribers": 1023977, "created_utc": 1693504526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently doing my master thesis on a topic regarding interpret ability of data science models and their applications. Interpretability currently holds no strict definition in the field (Doshi &amp; Kim, 2017) and it may be synonymous with explainability (to a human/end-user).\n\n I am curious as to how would you guys define or how do you think of interpretability as. Is there a way you use to measure it ? \n\nPersonally I really like the parallel used by Efron, where it can be thought of as a communication; an exchange of information that depends on the parties involved. For example a doctor may find the name of a predicted disease by a model a sufficient amount of information, but a patient may require a lengthier explanation. \n\nThank you !", "author_fullname": "t2_21mlx7b9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you define interpretability of a model ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166gubu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693501776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently doing my master thesis on a topic regarding interpret ability of data science models and their applications. Interpretability currently holds no strict definition in the field (Doshi &amp;amp; Kim, 2017) and it may be synonymous with explainability (to a human/end-user).&lt;/p&gt;\n\n&lt;p&gt;I am curious as to how would you guys define or how do you think of interpretability as. Is there a way you use to measure it ? &lt;/p&gt;\n\n&lt;p&gt;Personally I really like the parallel used by Efron, where it can be thought of as a communication; an exchange of information that depends on the parties involved. For example a doctor may find the name of a predicted disease by a model a sufficient amount of information, but a patient may require a lengthier explanation. &lt;/p&gt;\n\n&lt;p&gt;Thank you !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166gubu", "is_robot_indexable": true, "report_reasons": null, "author": "johntsaou", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166gubu/how_would_you_define_interpretability_of_a_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166gubu/how_would_you_define_interpretability_of_a_model/", "subreddit_subscribers": 1023977, "created_utc": 1693501776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I need to make a tree-graph. The distance between 2 nodes should be proportional to the weight of their adjacent edge. \n\nThe library should display certain information on hover and do something on click too. \n\nPlease help.", "author_fullname": "t2_9peiwedk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advanced graph visualization libraries in python that are supported by streamlit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166as6f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693487468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to make a tree-graph. The distance between 2 nodes should be proportional to the weight of their adjacent edge. &lt;/p&gt;\n\n&lt;p&gt;The library should display certain information on hover and do something on click too. &lt;/p&gt;\n\n&lt;p&gt;Please help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166as6f", "is_robot_indexable": true, "report_reasons": null, "author": "LucaMarko", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166as6f/advanced_graph_visualization_libraries_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166as6f/advanced_graph_visualization_libraries_in_python/", "subreddit_subscribers": 1023977, "created_utc": 1693487468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Want to learn how to create a React Native to take images and read the text from them using OCR? Check out [this article on using OCR with React Native and Flask](https://medium.com/python-in-plain-english/how-to-use-innovative-ocr-to-effortlessly-empower-your-react-native-app-ea3364ae9ab5). \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_9ssuhjvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn how to integrate OCR into your React Native app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1665kom", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693471623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Want to learn how to create a React Native to take images and read the text from them using OCR? Check out &lt;a href=\"https://medium.com/python-in-plain-english/how-to-use-innovative-ocr-to-effortlessly-empower-your-react-native-app-ea3364ae9ab5\"&gt;this article on using OCR with React Native and Flask&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0Kq4rXHb04m2SQnDc5LpEcpYfRsi9tsh_BwJ8a_y6hg.jpg?auto=webp&amp;s=5cf1e85f007076324f13a1a290f71a97ada23e5c", "width": 1022, "height": 794}, "resolutions": [{"url": "https://external-preview.redd.it/0Kq4rXHb04m2SQnDc5LpEcpYfRsi9tsh_BwJ8a_y6hg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1844e5b8d665444e1b159144853a04bf26adb823", "width": 108, "height": 83}, {"url": "https://external-preview.redd.it/0Kq4rXHb04m2SQnDc5LpEcpYfRsi9tsh_BwJ8a_y6hg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9936e3049cb6b33a5f570c463755b8e64b4a5298", "width": 216, "height": 167}, {"url": "https://external-preview.redd.it/0Kq4rXHb04m2SQnDc5LpEcpYfRsi9tsh_BwJ8a_y6hg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e98e21dff282fe3e9244a66a6de13457df60095e", "width": 320, "height": 248}, {"url": "https://external-preview.redd.it/0Kq4rXHb04m2SQnDc5LpEcpYfRsi9tsh_BwJ8a_y6hg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=46dc1c05a100b2108367758b1cdfb3c017afb9cd", "width": 640, "height": 497}, {"url": "https://external-preview.redd.it/0Kq4rXHb04m2SQnDc5LpEcpYfRsi9tsh_BwJ8a_y6hg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=10a09d082e9e3ad284b7cc929a51de6472ed9cb8", "width": 960, "height": 745}], "variants": {}, "id": "N6pjWI3s3BucVc77NoV7vxeumKJowbwGj2OIlZ76USc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1665kom", "is_robot_indexable": true, "report_reasons": null, "author": "Artistic_Highlight_1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1665kom/learn_how_to_integrate_ocr_into_your_react_native/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1665kom/learn_how_to_integrate_ocr_into_your_react_native/", "subreddit_subscribers": 1023977, "created_utc": 1693471623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Job application process is dehumanizing! I just completed a 6 interview process aced the tech interview and then even had to meet with hiring manager multiple times and they still rejected me for not having the \u201ccommunication skills\u201d required for position even though I have worked in so many different teams, served as a teacher, and communicated with so many different people. \n\nWhy do the companies have such long processes and string candidates along like that!", "author_fullname": "t2_55qnkwk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Application process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16614cs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693456605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Job application process is dehumanizing! I just completed a 6 interview process aced the tech interview and then even had to meet with hiring manager multiple times and they still rejected me for not having the \u201ccommunication skills\u201d required for position even though I have worked in so many different teams, served as a teacher, and communicated with so many different people. &lt;/p&gt;\n\n&lt;p&gt;Why do the companies have such long processes and string candidates along like that!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16614cs", "is_robot_indexable": true, "report_reasons": null, "author": "kbabqiqja", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16614cs/job_application_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16614cs/job_application_process/", "subreddit_subscribers": 1023977, "created_utc": 1693456605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**TLDR;** Test WizardLM + Phind-CodeLlama yourself - [https://litellm.ai/battleground](https://litellm.ai/battleground). Results to be published Friday!\n\nHi [r/d](https://www.reddit.com/r/LocalLLaMA/)atascience,\n\nI\u2019m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, TogetherAI, Cohere, Anthropic, Baseten, Hugging face API Endpoints: [https://github.com/BerriAI/litellm/](https://github.com/BerriAI/litellm/).\n\nWe saw WizardLM's tweet thread - [https://twitter.com/WizardLM\\_AI/status/1696527036804989171](https://twitter.com/WizardLM_AI/status/1696527036804989171), and wanted a chance to test both models side-by-side. So we deployed both models and built a playground to compare them!\n\nWe're planning on hosting it for the next 24 hours (unless our server bills get too crazy) - happy hacking!\n\nLink - [https://litellm.ai/battleground](https://litellm.ai/battleground)", "author_fullname": "t2_b5qc2w9r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WizardLM vs. Phind-CodeLlama - Test yourself Battleground", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165zqmg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693452458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TLDR;&lt;/strong&gt; Test WizardLM + Phind-CodeLlama yourself - &lt;a href=\"https://litellm.ai/battleground\"&gt;https://litellm.ai/battleground&lt;/a&gt;. Results to be published Friday!&lt;/p&gt;\n\n&lt;p&gt;Hi &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/\"&gt;r/d&lt;/a&gt;atascience,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, TogetherAI, Cohere, Anthropic, Baseten, Hugging face API Endpoints: &lt;a href=\"https://github.com/BerriAI/litellm/\"&gt;https://github.com/BerriAI/litellm/&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;We saw WizardLM&amp;#39;s tweet thread - &lt;a href=\"https://twitter.com/WizardLM_AI/status/1696527036804989171\"&gt;https://twitter.com/WizardLM_AI/status/1696527036804989171&lt;/a&gt;, and wanted a chance to test both models side-by-side. So we deployed both models and built a playground to compare them!&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re planning on hosting it for the next 24 hours (unless our server bills get too crazy) - happy hacking!&lt;/p&gt;\n\n&lt;p&gt;Link - &lt;a href=\"https://litellm.ai/battleground\"&gt;https://litellm.ai/battleground&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "165zqmg", "is_robot_indexable": true, "report_reasons": null, "author": "VideoTo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/165zqmg/wizardlm_vs_phindcodellama_test_yourself/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/165zqmg/wizardlm_vs_phindcodellama_test_yourself/", "subreddit_subscribers": 1023977, "created_utc": 1693452458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I already devoted a lot of time in learning bayesian methods and adapting it to frequentist testing methodology, but am having a bit of a crisis right now where the same test can come as significant in bayesian but not in frequentist. I know bayesian can answer a lot more questions like the probability of the null hypothesis being true or how much more likely the alternative is than the null but I feel like it's alarming that bayesian will say we can reject the null when frequentist won't.\n\nLooking for advice here or if anyone knows of any good resources\n\nThanks", "author_fullname": "t2_3kdgnq0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I learn AB Bayesian Testing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165tjhq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693436188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I already devoted a lot of time in learning bayesian methods and adapting it to frequentist testing methodology, but am having a bit of a crisis right now where the same test can come as significant in bayesian but not in frequentist. I know bayesian can answer a lot more questions like the probability of the null hypothesis being true or how much more likely the alternative is than the null but I feel like it&amp;#39;s alarming that bayesian will say we can reject the null when frequentist won&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;Looking for advice here or if anyone knows of any good resources&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "165tjhq", "is_robot_indexable": true, "report_reasons": null, "author": "Jbor941197", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/165tjhq/should_i_learn_ab_bayesian_testing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/165tjhq/should_i_learn_ab_bayesian_testing/", "subreddit_subscribers": 1023977, "created_utc": 1693436188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all, I'd like to get more experience with anything data science/data analytics related. If there's any work you have or organizations you know of please send them my way!", "author_fullname": "t2_aob9aafj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Volunteer looking for experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_166l6hu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693511727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I&amp;#39;d like to get more experience with anything data science/data analytics related. If there&amp;#39;s any work you have or organizations you know of please send them my way!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166l6hu", "is_robot_indexable": true, "report_reasons": null, "author": "chicanatifa", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166l6hu/volunteer_looking_for_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166l6hu/volunteer_looking_for_experience/", "subreddit_subscribers": 1023977, "created_utc": 1693511727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there,\n\nI'm a young financial engineer currently working for a family office that wants to propose \"loan against portfolio\". I'm in charge of designing the pricing engine to determine what would be the risk for a given loan, and of course the best LTV (loan to value) etc.. to maximize the return on the loan.\n\nI already did a Python code that generates portfolio value composed of N assets with X volatility and Y correlation ( I considered only stocks PF for now). From those initial values of X portfolio, I apply a Monte Carlo simulation and do the mean of all the potential ending values of the PF. I chose to base our profit (the expected returns on the loan) on the \"Upside capture\" (the percentage that we catch between the entry value of the PF and the ending value) + the \"Outstanding\" (what we catch due to the interest rate). This will return a .csv with portfolio value, the loan base on the LTV, the duration of the loan etc.. + the ROI ((Upside + Outstanding)/loan amount). I will then print the best \"LTV\", \"duration of the loan\" and \"annual rate\" combo that gives the best ROI.\n\nThe thing is now I don't see how I can continue without actual data.\n\nMy questions are,\n\n\\- I'm debating to orientate the logic on a deep learning model, which would be way more efficient, no?\n\n\\- For this purpose, does anyone know where I could find some portfolio data (anonymized of course)? I'd like to catch real fluctuation on real assets for a given portfolio so I can say \"Ok for this kind of PF we have this kind of return so we can assess this risk...\"\n\n\\- With the current code and csv that I generate it's difficult to catch any relevant pattern and I don't really know how to continue. If anyone has recommendations or tips, it would be greatly appreciated!\n\nThanks guys :)", "author_fullname": "t2_76pyyo72", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Loan Against Portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166gepx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693500760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a young financial engineer currently working for a family office that wants to propose &amp;quot;loan against portfolio&amp;quot;. I&amp;#39;m in charge of designing the pricing engine to determine what would be the risk for a given loan, and of course the best LTV (loan to value) etc.. to maximize the return on the loan.&lt;/p&gt;\n\n&lt;p&gt;I already did a Python code that generates portfolio value composed of N assets with X volatility and Y correlation ( I considered only stocks PF for now). From those initial values of X portfolio, I apply a Monte Carlo simulation and do the mean of all the potential ending values of the PF. I chose to base our profit (the expected returns on the loan) on the &amp;quot;Upside capture&amp;quot; (the percentage that we catch between the entry value of the PF and the ending value) + the &amp;quot;Outstanding&amp;quot; (what we catch due to the interest rate). This will return a .csv with portfolio value, the loan base on the LTV, the duration of the loan etc.. + the ROI ((Upside + Outstanding)/loan amount). I will then print the best &amp;quot;LTV&amp;quot;, &amp;quot;duration of the loan&amp;quot; and &amp;quot;annual rate&amp;quot; combo that gives the best ROI.&lt;/p&gt;\n\n&lt;p&gt;The thing is now I don&amp;#39;t see how I can continue without actual data.&lt;/p&gt;\n\n&lt;p&gt;My questions are,&lt;/p&gt;\n\n&lt;p&gt;- I&amp;#39;m debating to orientate the logic on a deep learning model, which would be way more efficient, no?&lt;/p&gt;\n\n&lt;p&gt;- For this purpose, does anyone know where I could find some portfolio data (anonymized of course)? I&amp;#39;d like to catch real fluctuation on real assets for a given portfolio so I can say &amp;quot;Ok for this kind of PF we have this kind of return so we can assess this risk...&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;- With the current code and csv that I generate it&amp;#39;s difficult to catch any relevant pattern and I don&amp;#39;t really know how to continue. If anyone has recommendations or tips, it would be greatly appreciated!&lt;/p&gt;\n\n&lt;p&gt;Thanks guys :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166gepx", "is_robot_indexable": true, "report_reasons": null, "author": "crystalpaigeee", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166gepx/loan_against_portfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166gepx/loan_against_portfolio/", "subreddit_subscribers": 1023977, "created_utc": 1693500760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello fellows  \nI have a seemingly simple issue but I was wanted to consult with you on how you would solve that.\n\nI have an incremental learning model that I try to predict user actions with. Lets say I have 5 possible actions encoded from 0 to 4 as classes. The model is in batches of 5, meaning I get a batch of 5 records each time. \n\nThe first batch I get has unique classes of 0,1,2 - but since it is the first batch I have nothing to predict so it is moved to train data immediately. The 2nd batch I have is of classes 0,1,3 , I try to predict it with the trained data (the batch from before). My problem is while hyperparameters tuning I use ROC AUC (decision by my coworker) which causes me issues as the labels are not in order (2 is missing in my example)\n\n( [https://stackoverflow.com/questions/63140095/roc-auc-score-mismatch-between-y-test-and-y-score](https://stackoverflow.com/questions/63140095/roc-auc-score-mismatch-between-y-test-and-y-score) )  \n\n\nNow in real life I obviously can't guarentee that I will get batches of records with actions that match the classes order. I can't balance the classes since I have no place to sample the new daAnd I can't change encodings to match the new order since it can cause data leakage (and in general a wrong practice). The only solution I came up with is to replace ROC AUC with a different metric (Balanced Accuracy - since my data is unbalanced) but my coworker does not want to change the metric to a threshold dependent metric.\n\nMy question is both specific and general - how do you handle errors and issues caused by misrepresentation of classes in train/test data? Assuming you are not batch training and/or can not manipulate the train and test data to prevent it?\n\nHighly appreciate your help\n\n \n\n&amp;#x200B;", "author_fullname": "t2_3hqmko1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle issues caused by missing classes representation in dataset when running a model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166e7kl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693495632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellows&lt;br/&gt;\nI have a seemingly simple issue but I was wanted to consult with you on how you would solve that.&lt;/p&gt;\n\n&lt;p&gt;I have an incremental learning model that I try to predict user actions with. Lets say I have 5 possible actions encoded from 0 to 4 as classes. The model is in batches of 5, meaning I get a batch of 5 records each time. &lt;/p&gt;\n\n&lt;p&gt;The first batch I get has unique classes of 0,1,2 - but since it is the first batch I have nothing to predict so it is moved to train data immediately. The 2nd batch I have is of classes 0,1,3 , I try to predict it with the trained data (the batch from before). My problem is while hyperparameters tuning I use ROC AUC (decision by my coworker) which causes me issues as the labels are not in order (2 is missing in my example)&lt;/p&gt;\n\n&lt;p&gt;( &lt;a href=\"https://stackoverflow.com/questions/63140095/roc-auc-score-mismatch-between-y-test-and-y-score\"&gt;https://stackoverflow.com/questions/63140095/roc-auc-score-mismatch-between-y-test-and-y-score&lt;/a&gt; )  &lt;/p&gt;\n\n&lt;p&gt;Now in real life I obviously can&amp;#39;t guarentee that I will get batches of records with actions that match the classes order. I can&amp;#39;t balance the classes since I have no place to sample the new daAnd I can&amp;#39;t change encodings to match the new order since it can cause data leakage (and in general a wrong practice). The only solution I came up with is to replace ROC AUC with a different metric (Balanced Accuracy - since my data is unbalanced) but my coworker does not want to change the metric to a threshold dependent metric.&lt;/p&gt;\n\n&lt;p&gt;My question is both specific and general - how do you handle errors and issues caused by misrepresentation of classes in train/test data? Assuming you are not batch training and/or can not manipulate the train and test data to prevent it?&lt;/p&gt;\n\n&lt;p&gt;Highly appreciate your help&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166e7kl", "is_robot_indexable": true, "report_reasons": null, "author": "nuriel8833", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166e7kl/how_to_handle_issues_caused_by_missing_classes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166e7kl/how_to_handle_issues_caused_by_missing_classes/", "subreddit_subscribers": 1023977, "created_utc": 1693495632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Thinking through a simple A/B test with 2 variants:\n\n* Control\n   * Step 1 -&gt; Step 2 -&gt; Step 3 -&gt; Conversion\n* Test\n   * Step 1 -&gt; Step 2 -&gt; Step 3 -&gt; Step 4 -&gt; Conversion\n\nAssume users are randomly assigned at Step 3 with a coin flip and 50/50 split.\n\nAlso assume that conversion can happen at any time and that, while users can continue browsing through N additional steps, only Step 1-3 are mandatory.\n\nMy hypothesis is that adding Step 4 will reduce conversions. \n\nWhat would be the right metric to measure here? I would say it should be % converting from Step 3, but wondering if I should also consider % converting from Step 4, since those users would be the ones actually impacted by the change.", "author_fullname": "t2_7zmoi25a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Picking the right metric for an A/B test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166dkkf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693494154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thinking through a simple A/B test with 2 variants:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Control\n\n&lt;ul&gt;\n&lt;li&gt;Step 1 -&amp;gt; Step 2 -&amp;gt; Step 3 -&amp;gt; Conversion&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Test\n\n&lt;ul&gt;\n&lt;li&gt;Step 1 -&amp;gt; Step 2 -&amp;gt; Step 3 -&amp;gt; Step 4 -&amp;gt; Conversion&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Assume users are randomly assigned at Step 3 with a coin flip and 50/50 split.&lt;/p&gt;\n\n&lt;p&gt;Also assume that conversion can happen at any time and that, while users can continue browsing through N additional steps, only Step 1-3 are mandatory.&lt;/p&gt;\n\n&lt;p&gt;My hypothesis is that adding Step 4 will reduce conversions. &lt;/p&gt;\n\n&lt;p&gt;What would be the right metric to measure here? I would say it should be % converting from Step 3, but wondering if I should also consider % converting from Step 4, since those users would be the ones actually impacted by the change.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166dkkf", "is_robot_indexable": true, "report_reasons": null, "author": "ergodym", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166dkkf/picking_the_right_metric_for_an_ab_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166dkkf/picking_the_right_metric_for_an_ab_test/", "subreddit_subscribers": 1023977, "created_utc": 1693494154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI have the opportunity to take one of [these](https://ivmf.syracuse.edu/programs/career-training/learning-pathways/) industry-recognized certification exams for free, along with the course that goes with it. I know certifications don't mean much but figured it's free learning and that never hurts. Which would you choose? I'm torn between..\n\n\\- CompTIA A+\n\n\\- CompTIA Security+\n\n\\- PCAP: Programming Essentials in Python\n\nI'm leaning more towards the PCAP, since Python is used in this field and I only really have experience with R. Cyber security interests me but I feel the Python one would be more valuable in this field. What do you all think? Has anyone taken any of these? Thanks!", "author_fullname": "t2_2r732rgx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have the opportunity to take one of these certification exams for free. Which would you choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_166c2e1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693490651.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I have the opportunity to take one of &lt;a href=\"https://ivmf.syracuse.edu/programs/career-training/learning-pathways/\"&gt;these&lt;/a&gt; industry-recognized certification exams for free, along with the course that goes with it. I know certifications don&amp;#39;t mean much but figured it&amp;#39;s free learning and that never hurts. Which would you choose? I&amp;#39;m torn between..&lt;/p&gt;\n\n&lt;p&gt;- CompTIA A+&lt;/p&gt;\n\n&lt;p&gt;- CompTIA Security+&lt;/p&gt;\n\n&lt;p&gt;- PCAP: Programming Essentials in Python&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m leaning more towards the PCAP, since Python is used in this field and I only really have experience with R. Cyber security interests me but I feel the Python one would be more valuable in this field. What do you all think? Has anyone taken any of these? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YohhkSUEzamkODJL4T8qR188FZ12W3TCO3MNVpSpsg4.jpg?auto=webp&amp;s=065b5f1a21125c981c4752d4730ce2c5f994c5d9", "width": 1000, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/YohhkSUEzamkODJL4T8qR188FZ12W3TCO3MNVpSpsg4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7edd285dd2e253638ea7ee89b82e4e7bb8ba4951", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YohhkSUEzamkODJL4T8qR188FZ12W3TCO3MNVpSpsg4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69e396c3ddf0c29ae788ed905ea046c5b2324b0b", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YohhkSUEzamkODJL4T8qR188FZ12W3TCO3MNVpSpsg4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb587ae6e45adb10f2266fc495d2a2d2fb6fa093", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/YohhkSUEzamkODJL4T8qR188FZ12W3TCO3MNVpSpsg4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd0859be93b8e47e2bab6793d04f11a2dcd7a07a", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/YohhkSUEzamkODJL4T8qR188FZ12W3TCO3MNVpSpsg4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=582531477503ebe06deb1768fd9d5fbb12e4da30", "width": 960, "height": 960}], "variants": {}, "id": "jm5fJs9Ll5rM5S1CS8qzs0tySn6P7yhaVWuQFkRoZ9Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "166c2e1", "is_robot_indexable": true, "report_reasons": null, "author": "4077hawkeye-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/166c2e1/i_have_the_opportunity_to_take_one_of_these/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/166c2e1/i_have_the_opportunity_to_take_one_of_these/", "subreddit_subscribers": 1023977, "created_utc": 1693490651.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello!\n\nI am a recent graduate with a master's degree in biomedical engineer with a few university subjects related to AI, databases and a master's thesis related to data science.\n\n\nI want to find a junior data scientist position and I have recently done some interviews. I feel I fail in these interviews not because of the data science techniques but because of questions related to programming and my knowledge of some tools. For example 1) what is the difference between a Jupyter notebook and a Python script, 2) what do you do to optimise your code, and 3) do you know what Docker is?\n\u00a0\n\nThis is probably trivial for a lot of you, but from my past experiences (internships, university subjects), I've never needed to think about these questions.\n\u00a0\n\nSo, I wanted to know, for someone without a background in CS, how can I learn about these things more related to programming besides applying libraries and exploring data? And what do you think I should learn to fill this gap?\n\u00a0\n\nThank you all!", "author_fullname": "t2_jsgqs13t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(Advice) Data Science Interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1666n3b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693475346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I am a recent graduate with a master&amp;#39;s degree in biomedical engineer with a few university subjects related to AI, databases and a master&amp;#39;s thesis related to data science.&lt;/p&gt;\n\n&lt;p&gt;I want to find a junior data scientist position and I have recently done some interviews. I feel I fail in these interviews not because of the data science techniques but because of questions related to programming and my knowledge of some tools. For example 1) what is the difference between a Jupyter notebook and a Python script, 2) what do you do to optimise your code, and 3) do you know what Docker is?\n\u00a0&lt;/p&gt;\n\n&lt;p&gt;This is probably trivial for a lot of you, but from my past experiences (internships, university subjects), I&amp;#39;ve never needed to think about these questions.\n\u00a0&lt;/p&gt;\n\n&lt;p&gt;So, I wanted to know, for someone without a background in CS, how can I learn about these things more related to programming besides applying libraries and exploring data? And what do you think I should learn to fill this gap?\n\u00a0&lt;/p&gt;\n\n&lt;p&gt;Thank you all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1666n3b", "is_robot_indexable": true, "report_reasons": null, "author": "Throwawaylafora", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1666n3b/advice_data_science_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1666n3b/advice_data_science_interviews/", "subreddit_subscribers": 1023977, "created_utc": 1693475346.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}