{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a few services (ETL, metrics, getting data to external services like CRMs, internal tools built with retool, etc) and everything runs on cronjobs. We've gotten somewhat stable over the last few months, wrapped http APIs around everything, and now want an orchestration service. \n\nI've worked with airflow before, and would commit acts of violence if required to do it again. From what I researched, [dagster](https://dagster.io/) is my favorite option for now. We have a good amount of engineering manpower and can go for unconventional alternatives too, if the team sees value in it - say, a very elegant API.", "author_fullname": "t2_44mw8sqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's hot in the orchestration landscape right now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15savgk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692147584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a few services (ETL, metrics, getting data to external services like CRMs, internal tools built with retool, etc) and everything runs on cronjobs. We&amp;#39;ve gotten somewhat stable over the last few months, wrapped http APIs around everything, and now want an orchestration service. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve worked with airflow before, and would commit acts of violence if required to do it again. From what I researched, &lt;a href=\"https://dagster.io/\"&gt;dagster&lt;/a&gt; is my favorite option for now. We have a good amount of engineering manpower and can go for unconventional alternatives too, if the team sees value in it - say, a very elegant API.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-WhHz4puFofeKOrHSueg6zvsVFr30k_zitB8j39U5jU.jpg?auto=webp&amp;s=918dd1e42e3ab1b2e8abc52d0d1928c592fabf73", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/-WhHz4puFofeKOrHSueg6zvsVFr30k_zitB8j39U5jU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=194ea0552832d0ebd11d5eac0308c54bc95ea3f1", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/-WhHz4puFofeKOrHSueg6zvsVFr30k_zitB8j39U5jU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c63d20d62fd492fb46d5190954c36ab073361508", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/-WhHz4puFofeKOrHSueg6zvsVFr30k_zitB8j39U5jU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1a53faddb2de2d75b08dadf8062694a22f8da395", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/-WhHz4puFofeKOrHSueg6zvsVFr30k_zitB8j39U5jU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7c9527e9deaa0a423093120bf55c880a4142354f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/-WhHz4puFofeKOrHSueg6zvsVFr30k_zitB8j39U5jU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=12d78ea94107c3059499d60f509b28d7584a4f57", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/-WhHz4puFofeKOrHSueg6zvsVFr30k_zitB8j39U5jU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9d3884077322827497c08cf405b4b872ab0e7a95", "width": 1080, "height": 567}], "variants": {}, "id": "LWrtH_7Z3lUYq6_L9owMa7zfAN0l2BOJ9wrrYYfif-s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15savgk", "is_robot_indexable": true, "report_reasons": null, "author": "verysmolpupperino", "discussion_type": null, "num_comments": 70, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15savgk/whats_hot_in_the_orchestration_landscape_right_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15savgk/whats_hot_in_the_orchestration_landscape_right_now/", "subreddit_subscribers": 123070, "created_utc": 1692147584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With the new version of this open-source analytic data warehouse, we bring to you:\n\n1. Auto-synchronization from MySQL / Oracle to Doris\n2. Elastic scaling of computation resources\n3. Native support for semi-structured data\n4. Tiered storage for hot and cold data\n5. Storage-compute separation\n6. Support for Kubernetes deployment\n7. Support for cross-cluster replication (CCR)\n8. Optimizations in concurrency to achieve 30,000 QPS per node \n9. Inverted index to speed up log analysis, fuzzy keyword search, and equivalence/range queries\n10. A smarter query optimizer that is 10 times more effective and frees you from tedious fine-tuning\n11. Enhanced data lakehousing capabilities (e.g. 3\\~5 times faster than Presto/Trino in queries on Hive tables)\n12. A self-adaptive parallel execution model for higher efficiency and stability in hybrid workload scenarios\n13. Efficient data update mechanisms (faster data writing, partial column update, conditional update and deletion)\n14. A flexible multi-tenant resource isolation solution (avoid preemption but make full use of CPU &amp; memory resources)", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Doris 2.0.0 is Production-Ready", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15so5vl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692187879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the new version of this open-source analytic data warehouse, we bring to you:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Auto-synchronization from MySQL / Oracle to Doris&lt;/li&gt;\n&lt;li&gt;Elastic scaling of computation resources&lt;/li&gt;\n&lt;li&gt;Native support for semi-structured data&lt;/li&gt;\n&lt;li&gt;Tiered storage for hot and cold data&lt;/li&gt;\n&lt;li&gt;Storage-compute separation&lt;/li&gt;\n&lt;li&gt;Support for Kubernetes deployment&lt;/li&gt;\n&lt;li&gt;Support for cross-cluster replication (CCR)&lt;/li&gt;\n&lt;li&gt;Optimizations in concurrency to achieve 30,000 QPS per node &lt;/li&gt;\n&lt;li&gt;Inverted index to speed up log analysis, fuzzy keyword search, and equivalence/range queries&lt;/li&gt;\n&lt;li&gt;A smarter query optimizer that is 10 times more effective and frees you from tedious fine-tuning&lt;/li&gt;\n&lt;li&gt;Enhanced data lakehousing capabilities (e.g. 3~5 times faster than Presto/Trino in queries on Hive tables)&lt;/li&gt;\n&lt;li&gt;A self-adaptive parallel execution model for higher efficiency and stability in hybrid workload scenarios&lt;/li&gt;\n&lt;li&gt;Efficient data update mechanisms (faster data writing, partial column update, conditional update and deletion)&lt;/li&gt;\n&lt;li&gt;A flexible multi-tenant resource isolation solution (avoid preemption but make full use of CPU &amp;amp; memory resources)&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15so5vl", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15so5vl/apache_doris_200_is_productionready/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15so5vl/apache_doris_200_is_productionready/", "subreddit_subscribers": 123070, "created_utc": 1692187879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am curious why data science students choose a data engineering position rather than a data scientist position.", "author_fullname": "t2_94z2yiq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sktrv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692177727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am curious why data science students choose a data engineering position rather than a data scientist position.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15sktrv", "is_robot_indexable": true, "report_reasons": null, "author": "LengthOld9943", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sktrv/why_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sktrv/why_data_engineering/", "subreddit_subscribers": 123070, "created_utc": 1692177727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With framework here I mean \"set of rules / best practices\".\n\nSome we all know, like \"make the pipeline idempotent\" etc..., But I was wondering if there is some kind of generally accepted gold standard both for high and low lvl concepts.\n\nTo contextualize with an example I encountered recently: let's say you're extracting data from an OLTP database. Do you keep a (json) document with all the schemas for each table? What if there are hundreds of them? And what about schema drifts?\n\nIn other words, I'd like to know if you follow some ruleset when writing a new pipeline, or each time it's on a case by case scenario.\n\nLet me know what your experiences are!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When writing EL pipelines, do you follow any specific design pattern / framework?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sr2cr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692195170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With framework here I mean &amp;quot;set of rules / best practices&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Some we all know, like &amp;quot;make the pipeline idempotent&amp;quot; etc..., But I was wondering if there is some kind of generally accepted gold standard both for high and low lvl concepts.&lt;/p&gt;\n\n&lt;p&gt;To contextualize with an example I encountered recently: let&amp;#39;s say you&amp;#39;re extracting data from an OLTP database. Do you keep a (json) document with all the schemas for each table? What if there are hundreds of them? And what about schema drifts?&lt;/p&gt;\n\n&lt;p&gt;In other words, I&amp;#39;d like to know if you follow some ruleset when writing a new pipeline, or each time it&amp;#39;s on a case by case scenario.&lt;/p&gt;\n\n&lt;p&gt;Let me know what your experiences are!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15sr2cr", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sr2cr/when_writing_el_pipelines_do_you_follow_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sr2cr/when_writing_el_pipelines_do_you_follow_any/", "subreddit_subscribers": 123070, "created_utc": 1692195170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w07bcus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stream Processing Engines and Streaming Databases: Design, Use Cases, and the Future", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15spfny", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zG-1n7L2nYhLKd_4n9VrDvZxkSisbvmH5xQyYZ-Qygs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692191208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "risingwave.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.risingwave.com/blog/stream-processing-engines-and-streaming-databases-design-use-cases-and-the-future/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/U8kWUgPJXBqYyIzz7lB0jQ6P8MHTLKHVgUa5B430rlM.jpg?auto=webp&amp;s=6cd40a2b94cd86b5e76bc6bac7f51b9234427325", "width": 692, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/U8kWUgPJXBqYyIzz7lB0jQ6P8MHTLKHVgUa5B430rlM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cf9bbe0b42d0b9c525116a265e72d37d52f8883d", "width": 108, "height": 124}, {"url": "https://external-preview.redd.it/U8kWUgPJXBqYyIzz7lB0jQ6P8MHTLKHVgUa5B430rlM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6e275a615475bd566cc243d655b5ca9999a24098", "width": 216, "height": 249}, {"url": "https://external-preview.redd.it/U8kWUgPJXBqYyIzz7lB0jQ6P8MHTLKHVgUa5B430rlM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d2c98db2663e63888993b82eeaf683f82324d8d7", "width": 320, "height": 369}, {"url": "https://external-preview.redd.it/U8kWUgPJXBqYyIzz7lB0jQ6P8MHTLKHVgUa5B430rlM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3272c19fe13f4ff6cf4cc94749cc64d7564d1c57", "width": 640, "height": 739}], "variants": {}, "id": "Yl3N5GUR2yabuFWD9SnTBMOZF6LJ3C0CgZm4N1-mpzk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15spfny", "is_robot_indexable": true, "report_reasons": null, "author": "yingjunwu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15spfny/stream_processing_engines_and_streaming_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.risingwave.com/blog/stream-processing-engines-and-streaming-databases-design-use-cases-and-the-future/", "subreddit_subscribers": 123070, "created_utc": 1692191208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Please help how can i  continue the consistency?", "author_fullname": "t2_2dmmbh2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm feeling overwhelmed with Data Engineering (DE)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15shn2j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692167226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please help how can i  continue the consistency?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15shn2j", "is_robot_indexable": true, "report_reasons": null, "author": "prakash_8", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15shn2j/im_feeling_overwhelmed_with_data_engineering_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15shn2j/im_feeling_overwhelmed_with_data_engineering_de/", "subreddit_subscribers": 123070, "created_utc": 1692167226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It's widely known that developers prefer code-based orchestration tools (e.g., Airflow, Prefect, Dagster) vs. GUI-based ones (e.g., Meltano, Fivetran, Airbyte). More discussion available [here](https://www.reddit.com/r/dataengineering/comments/vscvhp/lownocode_etl_tools/).\n\nRecently, I've been seeing posts pitching using them together e.g., [Airbyte-Airflow](https://docs.airbyte.com/operator-guides/using-the-airflow-airbyte-operator/) and [Airbyte-Dagster](https://docs.dagster.io/integrations/airbyte). I get the GUI-based ones mostly provide easy way to \"EL\" but if I am using code-based anyway, then might as well write plain python to DIY. Why would I bother using both?\n\nWhat am I missing here? What situations truly call for using both together?", "author_fullname": "t2_42hc4int", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GUI-based vs code-based orchestrators", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sfmtx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692160833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s widely known that developers prefer code-based orchestration tools (e.g., Airflow, Prefect, Dagster) vs. GUI-based ones (e.g., Meltano, Fivetran, Airbyte). More discussion available &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/vscvhp/lownocode_etl_tools/\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Recently, I&amp;#39;ve been seeing posts pitching using them together e.g., &lt;a href=\"https://docs.airbyte.com/operator-guides/using-the-airflow-airbyte-operator/\"&gt;Airbyte-Airflow&lt;/a&gt; and &lt;a href=\"https://docs.dagster.io/integrations/airbyte\"&gt;Airbyte-Dagster&lt;/a&gt;. I get the GUI-based ones mostly provide easy way to &amp;quot;EL&amp;quot; but if I am using code-based anyway, then might as well write plain python to DIY. Why would I bother using both?&lt;/p&gt;\n\n&lt;p&gt;What am I missing here? What situations truly call for using both together?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15sfmtx", "is_robot_indexable": true, "report_reasons": null, "author": "vanillacap", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sfmtx/guibased_vs_codebased_orchestrators/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sfmtx/guibased_vs_codebased_orchestrators/", "subreddit_subscribers": 123070, "created_utc": 1692160833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI have recently started a new role as a DE in a company and it is really not aligned with what I was expecting, in every possible aspect (stack, stakeholders, managers, etc).\n\nI am thinking of moving on (I still have the role), but what worries me is how to handle this extremely short tenure (1 month, still in probation period) in my CV and discussions with recruiters/HR/etc, especially the notice period.\n\nShould I omit it completely, or try to explain the situation? Have any of you had a similar situation?\n\n&amp;#x200B;\n\nupdate 1: try to clarify the notice period a bit ", "author_fullname": "t2_fr98ul4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle really short job tenures.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15smg30", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692185135.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692182943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I have recently started a new role as a DE in a company and it is really not aligned with what I was expecting, in every possible aspect (stack, stakeholders, managers, etc).&lt;/p&gt;\n\n&lt;p&gt;I am thinking of moving on (I still have the role), but what worries me is how to handle this extremely short tenure (1 month, still in probation period) in my CV and discussions with recruiters/HR/etc, especially the notice period.&lt;/p&gt;\n\n&lt;p&gt;Should I omit it completely, or try to explain the situation? Have any of you had a similar situation?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;update 1: try to clarify the notice period a bit &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15smg30", "is_robot_indexable": true, "report_reasons": null, "author": "notamiko", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15smg30/how_to_handle_really_short_job_tenures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15smg30/how_to_handle_really_short_job_tenures/", "subreddit_subscribers": 123070, "created_utc": 1692182943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm thinking of not going for the Developer Associate or Solutions Architect ones. My understanding is that these are more beginner focused. I have 4 YOE of which 2 are in AWS. My work right now is coding applications that run on EMR.", "author_fullname": "t2_163ma7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it a bad idea to go straight to AWS Data Analytics certification.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15srdfm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692195933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m thinking of not going for the Developer Associate or Solutions Architect ones. My understanding is that these are more beginner focused. I have 4 YOE of which 2 are in AWS. My work right now is coding applications that run on EMR.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15srdfm", "is_robot_indexable": true, "report_reasons": null, "author": "muhmeinchut69", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15srdfm/is_it_a_bad_idea_to_go_straight_to_aws_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15srdfm/is_it_a_bad_idea_to_go_straight_to_aws_data/", "subreddit_subscribers": 123070, "created_utc": 1692195933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Data Industry's Convergence: Fragmented to Unified Experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15sk3x3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oogSHo6UrdROuwZGlbrFuC4aa3F-o-hFq-ZbRY_Ik0U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692175325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/the-data-industrys-convergence-fragmented", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?auto=webp&amp;s=201220b79af8841a0bedb83570e05567d7824573", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4d8ebdcb130995dd420bc262af108bb5ce838eb9", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b90c634dfd836daf41fa06090c420293ac9c411f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cfdc02f96bc51fac9346d1a3ca88dd95f4bcc323", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d59487c9a47240310614e4657d8b71eb3902f9a3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2010454e150006d271f2dfbdf437adba89b726a2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fcf2118478a8b4e4e467f3fc9be6a20308fee3c5", "width": 1080, "height": 540}], "variants": {}, "id": "EJaJOPu1otUjBLOA5ZH4Ay7dRyGnQ_s6FLO6HTswCk8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15sk3x3", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sk3x3/the_data_industrys_convergence_fragmented_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/the-data-industrys-convergence-fragmented", "subreddit_subscribers": 123070, "created_utc": 1692175325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_975og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to write fewer and better data tests with dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15sp1o8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Eq-I8rFi4qk-Jw8iPFESsUGhNWOba5RKlKQANZg7bnA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692190249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "elementary-data.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.elementary-data.com/post/dbt-tests", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?auto=webp&amp;s=f5d91a5633b7ba1907f0f4d46e132b8325eb7246", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4d2d1e15a9666506a101a8572ece2c0f90bc883f", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=029ab7fca886d9bc4c701d70ffc4b15620d645e4", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=48566d5b20f17cf3a8555252de224da9493bae0f", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1214f09c2cf62824cd74e549b86afcbe687778a3", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e8887ac77c741f242ef239818e7625eef63649fc", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e1d6820709ad5dc8bb84ea4414c85be204f7f20f", "width": 1080, "height": 567}], "variants": {}, "id": "dCRPDF1eYYwa8wbz61_ejFTUlUbR7J0dDuxedEes8pA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15sp1o8", "is_robot_indexable": true, "report_reasons": null, "author": "arimbr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sp1o8/how_to_write_fewer_and_better_data_tests_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.elementary-data.com/post/dbt-tests", "subreddit_subscribers": 123070, "created_utc": 1692190249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I work on a project that the client requires multiple database connections, then doing some simple transformations and updating multiple destinations. I love the interface for Mage but I don't get the connection process. \n\nThe AI docs tell me to connect to the MSSQL variable. But I'm lost. \n\nHow do I connect to multiple MSSQL databases? I tried connecting via the default profile using domain credentials but that didn't work. \n\nI tried creating multiple profiles... But that didn't work. \n\nSo I'm lost. Is Mage only for pgsql, MySQL and sqlite?\n\nAre there any GitHub projects or tutorials I can look at?\n\nPerfect seems simpler, but the client wants to develop through the UI blocks, to enable more visibility long term. \n\nUm...help?!?!", "author_fullname": "t2_11t26p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mage for SQL Server ... Ummm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15syerq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692211769.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I work on a project that the client requires multiple database connections, then doing some simple transformations and updating multiple destinations. I love the interface for Mage but I don&amp;#39;t get the connection process. &lt;/p&gt;\n\n&lt;p&gt;The AI docs tell me to connect to the MSSQL variable. But I&amp;#39;m lost. &lt;/p&gt;\n\n&lt;p&gt;How do I connect to multiple MSSQL databases? I tried connecting via the default profile using domain credentials but that didn&amp;#39;t work. &lt;/p&gt;\n\n&lt;p&gt;I tried creating multiple profiles... But that didn&amp;#39;t work. &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m lost. Is Mage only for pgsql, MySQL and sqlite?&lt;/p&gt;\n\n&lt;p&gt;Are there any GitHub projects or tutorials I can look at?&lt;/p&gt;\n\n&lt;p&gt;Perfect seems simpler, but the client wants to develop through the UI blocks, to enable more visibility long term. &lt;/p&gt;\n\n&lt;p&gt;Um...help?!?!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15syerq", "is_robot_indexable": true, "report_reasons": null, "author": "byeproduct", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15syerq/mage_for_sql_server_ummm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15syerq/mage_for_sql_server_ummm/", "subreddit_subscribers": 123070, "created_utc": 1692211769.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team is working through a migration from redshift to snowflake. Overall we have seen performance increases except for external tables. We have a few external tables defined in redshift that are pointed at partitioned parquet files in s3 and we recreated these external tables in snowflake. Redshift performance is 10x better than snowflake. Is there anything I could be missing why this is the case?", "author_fullname": "t2_45pdhd22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake External tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ssz8h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692199664.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team is working through a migration from redshift to snowflake. Overall we have seen performance increases except for external tables. We have a few external tables defined in redshift that are pointed at partitioned parquet files in s3 and we recreated these external tables in snowflake. Redshift performance is 10x better than snowflake. Is there anything I could be missing why this is the case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ssz8h", "is_robot_indexable": true, "report_reasons": null, "author": "theCHEFlin", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ssz8h/snowflake_external_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ssz8h/snowflake_external_tables/", "subreddit_subscribers": 123070, "created_utc": 1692199664.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys!\n\nI'm a back-end dev currently tasked with designing and implementing indexing and storage systems for my company's upcoming product.\n\nNote that I'm very new to data engineering - having only read 70% of \"Designing Data Intensive Applications\" at the time of writing (the project hit before I was able to finish the book). Our team is small, and no one has hands-on experience in data engineering.\n\n**We have a tool to dump raw data to Parquets, and then it's my job to design a pipeline that consumes/transforms this raw data into something higher-level, and stored in Parquets (or something else depending on the data use case)**. There are actually more details to this, but we'd like to ship a PoC the design first. (i.e. details such as querying those higher-level Parquets).\n\nI chose Apache Beam SDK for defining pipelines - in part because of Google Cloud Dataflow, which we will use in production.\n\nBeam Go SDK does not have Parquet IO connector AFAIK, but Python SDK does. **So my initial plan is to have Python \"connector pipeline\" to read Parquet files, send it to Go pipelines to do transformations, before sending the output to Python Parquet connector to write the output**.\n\nI wrote the pipelines, but still, I spent the last 2 hours trying to find ways (or runners) to run Python and Go pipelines locally, but was very confused by the choices and nuances of data engineering. My work laptop is a Mac although I do have access to some Ubuntu and Arch Linux servers (I'd prefer to run it on my laptop).\n\nIs there a way to do this locally? Besides, is my design of having Python connectors and Go processors sound dumb? I will certainly come back for recommendation for querying Parquet files later, but now I just want to run the pipelines written in different language locally.", "author_fullname": "t2_7f6tvoo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to locally run Apache Beam pipelines written in Go and Python on macOS (or Linux)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15spz2h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692192578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a back-end dev currently tasked with designing and implementing indexing and storage systems for my company&amp;#39;s upcoming product.&lt;/p&gt;\n\n&lt;p&gt;Note that I&amp;#39;m very new to data engineering - having only read 70% of &amp;quot;Designing Data Intensive Applications&amp;quot; at the time of writing (the project hit before I was able to finish the book). Our team is small, and no one has hands-on experience in data engineering.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;We have a tool to dump raw data to Parquets, and then it&amp;#39;s my job to design a pipeline that consumes/transforms this raw data into something higher-level, and stored in Parquets (or something else depending on the data use case)&lt;/strong&gt;. There are actually more details to this, but we&amp;#39;d like to ship a PoC the design first. (i.e. details such as querying those higher-level Parquets).&lt;/p&gt;\n\n&lt;p&gt;I chose Apache Beam SDK for defining pipelines - in part because of Google Cloud Dataflow, which we will use in production.&lt;/p&gt;\n\n&lt;p&gt;Beam Go SDK does not have Parquet IO connector AFAIK, but Python SDK does. &lt;strong&gt;So my initial plan is to have Python &amp;quot;connector pipeline&amp;quot; to read Parquet files, send it to Go pipelines to do transformations, before sending the output to Python Parquet connector to write the output&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;I wrote the pipelines, but still, I spent the last 2 hours trying to find ways (or runners) to run Python and Go pipelines locally, but was very confused by the choices and nuances of data engineering. My work laptop is a Mac although I do have access to some Ubuntu and Arch Linux servers (I&amp;#39;d prefer to run it on my laptop).&lt;/p&gt;\n\n&lt;p&gt;Is there a way to do this locally? Besides, is my design of having Python connectors and Go processors sound dumb? I will certainly come back for recommendation for querying Parquet files later, but now I just want to run the pipelines written in different language locally.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15spz2h", "is_robot_indexable": true, "report_reasons": null, "author": "artnoi43", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15spz2h/best_way_to_locally_run_apache_beam_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15spz2h/best_way_to_locally_run_apache_beam_pipelines/", "subreddit_subscribers": 123070, "created_utc": 1692192578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm new to DE and PySpark. I'm trying to create an ETL code using PySpark where I need to fetch data from 3 files and do some data transformations and load it into single transformation. I'm confused when to join the data from the different sources? One approach is to create separate dataframes for each source and joining them into a single dataframe and then perform the transformations. The other approach is start working on one df and join only when a column from other df is needed for any data transformations. In this approach, I will do the join when I'm doing the transformation. I'm not sure if the second approach is completely feasible. I need the code to be efficient. Any thoughts on this? Any alternative approach?", "author_fullname": "t2_cnbdxnrd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When to Join the sources into single dataframe? before or while doing transformations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sp1xl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692190270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to DE and PySpark. I&amp;#39;m trying to create an ETL code using PySpark where I need to fetch data from 3 files and do some data transformations and load it into single transformation. I&amp;#39;m confused when to join the data from the different sources? One approach is to create separate dataframes for each source and joining them into a single dataframe and then perform the transformations. The other approach is start working on one df and join only when a column from other df is needed for any data transformations. In this approach, I will do the join when I&amp;#39;m doing the transformation. I&amp;#39;m not sure if the second approach is completely feasible. I need the code to be efficient. Any thoughts on this? Any alternative approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15sp1xl", "is_robot_indexable": true, "report_reasons": null, "author": "ibrx8", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sp1xl/when_to_join_the_sources_into_single_dataframe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sp1xl/when_to_join_the_sources_into_single_dataframe/", "subreddit_subscribers": 123070, "created_utc": 1692190270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do we have extensions to support it?", "author_fullname": "t2_4ck30tok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can VSCode be used for dbt cloud project development?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sdo0h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692154982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do we have extensions to support it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15sdo0h", "is_robot_indexable": true, "report_reasons": null, "author": "Nomad4455", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sdo0h/can_vscode_be_used_for_dbt_cloud_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sdo0h/can_vscode_be_used_for_dbt_cloud_project/", "subreddit_subscribers": 123070, "created_utc": 1692154982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are doing a migration of a bunch of Oracle data to Snowflake and installing a new data model.  Would like to just auto translate the DDL from Oracle to Snowflake if possible rather than hand editing them.  Found an online site that didn't work and a python script on the Snowflake site that I think will take some work to get working.  Anybody know of any other free resources to do this?  Any help is appreciated!\n\nEdit: solved.  Used sqlglot library.", "author_fullname": "t2_117fpt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oracle to Snowflake DDL translation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15s7v8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692196483.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692140068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are doing a migration of a bunch of Oracle data to Snowflake and installing a new data model.  Would like to just auto translate the DDL from Oracle to Snowflake if possible rather than hand editing them.  Found an online site that didn&amp;#39;t work and a python script on the Snowflake site that I think will take some work to get working.  Anybody know of any other free resources to do this?  Any help is appreciated!&lt;/p&gt;\n\n&lt;p&gt;Edit: solved.  Used sqlglot library.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15s7v8p", "is_robot_indexable": true, "report_reasons": null, "author": "Gators1992", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15s7v8p/oracle_to_snowflake_ddl_translation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15s7v8p/oracle_to_snowflake_ddl_translation/", "subreddit_subscribers": 123070, "created_utc": 1692140068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for a suitable version and migration tool with CLI to use within GitHub action that is compatible with ClickHouse but haven't been successful so far in finding an easy to implement one. \n\nThere is [this](https://clickhouse.com/docs/knowledgebase/schema_migration_tools) list provided by ClickHouse but the options are not that much. What might be the best tool based on my requirements?", "author_fullname": "t2_e9jrhv5r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best database versioning/migration tool for clickhouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sxrmr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692210307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a suitable version and migration tool with CLI to use within GitHub action that is compatible with ClickHouse but haven&amp;#39;t been successful so far in finding an easy to implement one. &lt;/p&gt;\n\n&lt;p&gt;There is &lt;a href=\"https://clickhouse.com/docs/knowledgebase/schema_migration_tools\"&gt;this&lt;/a&gt; list provided by ClickHouse but the options are not that much. What might be the best tool based on my requirements?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?auto=webp&amp;s=b940f46a49700ae6e7892c951cb95b789b4ba807", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=952c9f478be63886c09db18a9321b7fad4cc815b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2468cd9d65f58f2bdeb5acf2806c8fcebf508d30", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3f11b7c42d4af2519525a18ac33e345598d55c2e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=40cd5353357726396d15e6b8fbe58c3deb300183", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0cce7914b15ddbc737c673aca7ab1750e1e3b737", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=86258b4f0cd45add3d8c44bd5256ecd1aadf419c", "width": 1080, "height": 540}], "variants": {}, "id": "7G0kkOcaGegJDbjqragKTYRV0shABWC_AhNkGPHD0Uw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15sxrmr", "is_robot_indexable": true, "report_reasons": null, "author": "AH1376", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sxrmr/best_database_versioningmigration_tool_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sxrmr/best_database_versioningmigration_tool_for/", "subreddit_subscribers": 123070, "created_utc": 1692210307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm trying to find a tool where our data-engineers can create visualizations in a tool such as superset/metabase and then visualize it in a frontend app.\n\nSeems like superset and similar tools mostly offers embedding through iframe which is not optimal. Is there some other tool which offer similar solutions which is easier to embed into a react app?\n\nAlso would be interested in a tool which creates an REST-api on top of a SQL query", "author_fullname": "t2_5gpux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Embed charts from data-visualization tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15staep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692200325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to find a tool where our data-engineers can create visualizations in a tool such as superset/metabase and then visualize it in a frontend app.&lt;/p&gt;\n\n&lt;p&gt;Seems like superset and similar tools mostly offers embedding through iframe which is not optimal. Is there some other tool which offer similar solutions which is easier to embed into a react app?&lt;/p&gt;\n\n&lt;p&gt;Also would be interested in a tool which creates an REST-api on top of a SQL query&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15staep", "is_robot_indexable": true, "report_reasons": null, "author": "muffa", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15staep/embed_charts_from_datavisualization_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15staep/embed_charts_from_datavisualization_tool/", "subreddit_subscribers": 123070, "created_utc": 1692200325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qvzmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running Apache Flink Applications on AWS KDA: Lessons Learnt at Deliveroo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15slh7h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lhs2FF7qUs0W8LUM1OUJRXGKRmyC32D1ErMTtgRN-VA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692179891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoq.com/news/2023/08/deliveroo-apache-flink-aws-kda/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?auto=webp&amp;s=d2787db035351c6aaf4d3593e280cda084bf7e20", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=24f64e8f70f9f8182dcc3b8042bc088424dfd4b5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4396e2557f26214eda6d1e97ea6b2fa8441e483a", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9935d2c372bdaa13584c646990280074a3cee475", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8535bfde9f06a80c0d9855d09834571316c11942", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0d86e00c83ab012d51bc7bc223ad35a68ed17b4c", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a58aa5e6f4844ed9782081ab4412baa2f504002d", "width": 1080, "height": 567}], "variants": {}, "id": "4pqSuGmF3d7Vr6ujI_YrmtYXFnSgjWbWnSjdeot4qgI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15slh7h", "is_robot_indexable": true, "report_reasons": null, "author": "rgancarz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15slh7h/running_apache_flink_applications_on_aws_kda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoq.com/news/2023/08/deliveroo-apache-flink-aws-kda/", "subreddit_subscribers": 123070, "created_utc": 1692179891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_16q5j0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing continuous data pipelines for low latency using Snowpipe Streaming API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 59, "top_awarded_type": null, "hide_score": false, "name": "t3_15sbbzc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iA1DghiHC6GTUf2IwxcknP5ggnZMgIOGV99nolFw-Rw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692148765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/snowflake/optimizing-continuous-data-pipelines-for-low-latency-using-snowpipe-streaming-api-in-striim-507a7798b0fc", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?auto=webp&amp;s=6a0fe9cf445f64cf4be45042681a85fdb00affd6", "width": 1200, "height": 507}, "resolutions": [{"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=96b21b1687cc27b97f0f55d653679369aa33d94a", "width": 108, "height": 45}, {"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bad42a4659dd0a2c3c18d3182ad3f37a626884e6", "width": 216, "height": 91}, {"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=63b3b562678b405f3786dd6883052f7059c6e757", "width": 320, "height": 135}, {"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca29cefb11659e539bd65fab148dbc079b5c2785", "width": 640, "height": 270}, {"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=07b1a32f98d85b7c553719424cef17d547d54ba5", "width": 960, "height": 405}, {"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9188da05ac2b5100d9991369c131472418d97c78", "width": 1080, "height": 456}], "variants": {}, "id": "zwFg9gsMOgjOEr51sL9OJAOAXFvRCfJ4Fs61rmqVF1I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15sbbzc", "is_robot_indexable": true, "report_reasons": null, "author": "audiologician", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sbbzc/optimizing_continuous_data_pipelines_for_low/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/snowflake/optimizing-continuous-data-pipelines-for-low-latency-using-snowpipe-streaming-api-in-striim-507a7798b0fc", "subreddit_subscribers": 123070, "created_utc": 1692148765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nIm new here! I hope you don't mind me asking for advice. I'm a new dev and new to the data scene.\n\nBut I would like to ask if you were to construct an airbnb app, how would you structure the images in the sql and folders?\n\nI would imagine it would state-&gt; province -&gt; city\n\n I think using a tree structure would be best for the folders, but would you have to implement the structure in the SQL? Would you need to store all the file names in a sql table called images, or like would you just save everything in the folder and just retrieve everything inside a folder?\n\nAny advice is truly appreciated!", "author_fullname": "t2_s9o0vtx7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would airbnb manage their folders and images?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sfg1l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692162029.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692160265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Im new here! I hope you don&amp;#39;t mind me asking for advice. I&amp;#39;m a new dev and new to the data scene.&lt;/p&gt;\n\n&lt;p&gt;But I would like to ask if you were to construct an airbnb app, how would you structure the images in the sql and folders?&lt;/p&gt;\n\n&lt;p&gt;I would imagine it would state-&amp;gt; province -&amp;gt; city&lt;/p&gt;\n\n&lt;p&gt;I think using a tree structure would be best for the folders, but would you have to implement the structure in the SQL? Would you need to store all the file names in a sql table called images, or like would you just save everything in the folder and just retrieve everything inside a folder?&lt;/p&gt;\n\n&lt;p&gt;Any advice is truly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15sfg1l", "is_robot_indexable": true, "report_reasons": null, "author": "IwannabeCrow", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sfg1l/how_would_airbnb_manage_their_folders_and_images/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sfg1l/how_would_airbnb_manage_their_folders_and_images/", "subreddit_subscribers": 123070, "created_utc": 1692160265.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need help", "author_fullname": "t2_unoeaew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help: I'm a Brazilian lawyer 29yo, will i be able to change my profession to DE at this point of my life?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15s6y08", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.27, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692137828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15s6y08", "is_robot_indexable": true, "report_reasons": null, "author": "Hobbit_Hunter", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15s6y08/need_help_im_a_brazilian_lawyer_29yo_will_i_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15s6y08/need_help_im_a_brazilian_lawyer_29yo_will_i_be/", "subreddit_subscribers": 123070, "created_utc": 1692137828.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}