{"kind": "Listing", "data": {"after": "t3_15nfsw1", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I wanted to say a big thanks to this sub-Reddit, as I just got my first job as a Data Engineer. \n\nAfter losing my job I decided to make a career change into Data Engineering from Data Science. From reading posts here for the past year or so my interest has grown in the area, leading up to this, so thanks everyone for all of the interesting and useful posts!\n\nAny advice for topic area to read up on before I start? Or maybe courses/YouTube series to help me be ready? \n\nThanks!", "author_fullname": "t2_7kdevi10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got my first Data Engineer job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ni579", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 107, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 107, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691687242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I wanted to say a big thanks to this sub-Reddit, as I just got my first job as a Data Engineer. &lt;/p&gt;\n\n&lt;p&gt;After losing my job I decided to make a career change into Data Engineering from Data Science. From reading posts here for the past year or so my interest has grown in the area, leading up to this, so thanks everyone for all of the interesting and useful posts!&lt;/p&gt;\n\n&lt;p&gt;Any advice for topic area to read up on before I start? Or maybe courses/YouTube series to help me be ready? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 300, "id": "award_cc299d65-77de-4828-89de-708b088349a0", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=16&amp;height=16&amp;auto=webp&amp;s=65edcad28bb61e02c98f6e5abae94570f15577af", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=32&amp;height=32&amp;auto=webp&amp;s=ade31fce9fae3cd026513278fd6d8f43a2470473", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=48&amp;height=48&amp;auto=webp&amp;s=4a6669f710a159e308d70a09ad5d91bf26576801", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=64&amp;height=64&amp;auto=webp&amp;s=6411ff24501a3c9ab1ba1fcc56e111e2897ed4f6", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=128&amp;height=128&amp;auto=webp&amp;s=161171b7b4aadddcf4bd0b258229c95cbf461625", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Historical anomaly - greatest in eternity.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "GOAT", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=16&amp;height=16&amp;auto=webp&amp;s=65edcad28bb61e02c98f6e5abae94570f15577af", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=32&amp;height=32&amp;auto=webp&amp;s=ade31fce9fae3cd026513278fd6d8f43a2470473", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=48&amp;height=48&amp;auto=webp&amp;s=4a6669f710a159e308d70a09ad5d91bf26576801", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=64&amp;height=64&amp;auto=webp&amp;s=6411ff24501a3c9ab1ba1fcc56e111e2897ed4f6", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=128&amp;height=128&amp;auto=webp&amp;s=161171b7b4aadddcf4bd0b258229c95cbf461625", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ni579", "is_robot_indexable": true, "report_reasons": null, "author": "Impressive_Fact_6561", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ni579/got_my_first_data_engineer_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ni579/got_my_first_data_engineer_job/", "subreddit_subscribers": 122114, "created_utc": 1691687242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am wondering what the devops and production architectures look like for teams that have effectively in-housed dbt-core without paying for dbt-cloud.\n\nDo you run dbt on a server that accepts http requests from a scheduler? If so, how do you define 'jobs' and 'environments' the way dbt-cloud does? \n\nOpen to any ideas on the subject", "author_fullname": "t2_ofoc42j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your team use dbt-core without dbt-cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nhu70", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691686564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wondering what the devops and production architectures look like for teams that have effectively in-housed dbt-core without paying for dbt-cloud.&lt;/p&gt;\n\n&lt;p&gt;Do you run dbt on a server that accepts http requests from a scheduler? If so, how do you define &amp;#39;jobs&amp;#39; and &amp;#39;environments&amp;#39; the way dbt-cloud does? &lt;/p&gt;\n\n&lt;p&gt;Open to any ideas on the subject&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15nhu70", "is_robot_indexable": true, "report_reasons": null, "author": "PangeanPrawn", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nhu70/how_does_your_team_use_dbtcore_without_dbtcloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nhu70/how_does_your_team_use_dbtcore_without_dbtcloud/", "subreddit_subscribers": 122114, "created_utc": 1691686564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Given this is by far the subreddit that has the most discussions about Databricks (good, bad,  and ugly) ...)\n\nMyself and a few other Databricks employees have reclaimed /r/Databricks which was previously private and made it public.\n\nFeel free to come join us there to ask questions and discuss all things Databricks and the lakehouse!\n\nOr stay here and compare us to Snowflake some more, we love that.", "author_fullname": "t2_2gj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "/r/Databricks has been relaunched as a public subreddit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nxf1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691724418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Given this is by far the subreddit that has the most discussions about Databricks (good, bad,  and ugly) ...)&lt;/p&gt;\n\n&lt;p&gt;Myself and a few other Databricks employees have reclaimed &lt;a href=\"/r/Databricks\"&gt;/r/Databricks&lt;/a&gt; which was previously private and made it public.&lt;/p&gt;\n\n&lt;p&gt;Feel free to come join us there to ask questions and discuss all things Databricks and the lakehouse!&lt;/p&gt;\n\n&lt;p&gt;Or stay here and compare us to Snowflake some more, we love that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15nxf1q", "is_robot_indexable": true, "report_reasons": null, "author": "kthejoker", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nxf1q/rdatabricks_has_been_relaunched_as_a_public/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nxf1q/rdatabricks_has_been_relaunched_as_a_public/", "subreddit_subscribers": 122114, "created_utc": 1691724418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, does anyone knows the process? How much algo/fundamentals knowledge do I need? Let's say algo in terms of codeforces rating or how much time on leetcode easy/medium/hard and fundamentals in terms of questions that might be asked and areas. Thanks for all the answers. Intersted because they pay good and it's EU + NL has 30% tax ruling.", "author_fullname": "t2_g6ziwt5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get hired to Databricks in NL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nk88r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691691968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, does anyone knows the process? How much algo/fundamentals knowledge do I need? Let&amp;#39;s say algo in terms of codeforces rating or how much time on leetcode easy/medium/hard and fundamentals in terms of questions that might be asked and areas. Thanks for all the answers. Intersted because they pay good and it&amp;#39;s EU + NL has 30% tax ruling.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15nk88r", "is_robot_indexable": true, "report_reasons": null, "author": "fire_air", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nk88r/how_to_get_hired_to_databricks_in_nl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nk88r/how_to_get_hired_to_databricks_in_nl/", "subreddit_subscribers": 122114, "created_utc": 1691691968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# Overview\n\nWith the Premier League season starting tomorrow, I wanted to showcase some updates I've made to this project I've been working and have posted about in the past:\n\n* 1st [post](https://www.reddit.com/r/dataengineering/comments/10jjsfp/another_data_project_this_time_with_python_go/).\n* 2nd [post](https://www.reddit.com/r/dataengineering/comments/13eqbfy/introducing_firestore_into_my_premier_league/).\n\nInstead of using Streamlit Cloud, I am now hosting the app with Cloud Run as a Service. (a Docker container): [https://streamlit.digitalghost.dev](https://streamlit.digitalghost.dev) \\- proxied through CloudFlare \ud83d\ude09. This was done so that I can further play and practice with GitHub Actions and Streamlit and because Streamlit is [removing IP whitelisting for external database connections](https://discuss.streamlit.io/t/link-to-ip-allowlist-documentation-is-broken/40648/7) so this was a necessary change to get ahead of the curb.\n\nI've also moved the project's documentation to GitBook: [https://docs.digitalghost.dev](https://docs.digitalghost.dev) \\- a bit nicer than Notion.\n\n# Links\n\n* Dashboard: [https://streamlit.digitalghost.dev](https://streamlit.digitalghost.dev)\n* Docs: [https://docs.digitalghost.dev](https://docs.digitalghost.dev) (Work in Progress)\n* GitHub: [https://github.com/digitalghost-dev/premier-league](https://github.com/digitalghost-dev/premier-league)\n* DockerHub: [https://hub.docker.com/r/digitalghostdev/premier-league/tags](https://hub.docker.com/r/digitalghostdev/premier-league/tags)\n\n# Flowchart\n\nI've changed quite a lot now to make a bit less complex and introduce some new technologies that I've been wanting to play with, mainly Prefect, Terraform, PostgreSQL.\n\nHere is an updated flowchart:\n\n[Pipeline Flowchart created with eraser.io](https://preview.redd.it/5mp1zk433bhb1.png?width=2574&amp;format=png&amp;auto=webp&amp;s=a3cd6e49b18390804c02f43386c99c9c176dabd9)\n\nOf course none of these changes were necessary but like stated before, I wanted to use new technologies. I subbed out BigQuery with PostgreSQL running on [Cloud SQL](https://cloud.google.com/sql). I could hold JSON data in PostgreSQL but wanted to keep Firestore. I now have Prefect running on a Virtual Machine (VM) that is the orchestration tool to schedule and execute the ETL scripts. The VM is created with Terraform and installs everything for me with a `.sh` file.\n\n# CI/CD Pipeline\n\n The CI/CD pipeline has changed to focus 100% on the Streamlit app:\n\n[Example from Testing the Pipeline](https://preview.redd.it/qtbk8r7g9bhb1.png?width=2570&amp;format=png&amp;auto=webp&amp;s=f7e1e0bdade907da18b3a47b7b286d20d762b05d)\n\nAfter the Docker image is built, it's pushed to Artifact Registry and deployed to Cloud Run.\n\nThere is another step that builds the image for different architectures: `linux/amd64` and `linux/arm64` and pushes them to my [DockerHub](https://hub.docker.com/r/digitalghostdev/premier-league/tags).\n\n**Security**\n\nI have included [Snyk](https://snyk.io) to scan the dependencies in the repositories and under the security tab in the Github Repo, I can see all vulnerabilities.\n\nAfter the image is built, an SBOM is created using [Syft](https://github.com/anchore/syft) then that SBOM is scanned with [Grype](https://github.com/anchore/grype) and just like Snyk, the security tab is filled with the vulnerabilities as a `SARIF` report.\n\n[Vulnerabilities in Repo](https://preview.redd.it/sfi70wunabhb1.png?width=2554&amp;format=png&amp;auto=webp&amp;s=5974f8402f678c4571d968ae75f16fceade8dae0)\n\n# Closing Notes\n\nThe cool thing I have come to realized about building this is that I was able to implement Prefect at work with a decent amount of confidence to fix our automation needs.\n\nLooking ahead, I think I am at a good place where I won't be changing the ETL architecture anymore and just focus on adding more content to the Streamlit app itself.", "author_fullname": "t2_bix7v2w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Premier League Data Pipeline Project Update [Prefect, Terraform, PostgreSQL]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 132, "top_awarded_type": null, "hide_score": false, "media_metadata": {"5mp1zk433bhb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 102, "x": 108, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c1c686a1b587fcaa609b6048c4c9b005704b867"}, {"y": 204, "x": 216, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=232089d62675c4e7da4fc06042b137f0d5d339a3"}, {"y": 302, "x": 320, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=38c9381a6310b8aa9a281eddf7a01d1ea4a54c14"}, {"y": 605, "x": 640, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f0f7bb12c9d00dab37ed292a2c219732e8d743e5"}, {"y": 908, "x": 960, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e9e77708da785f5481b9bea2cfbe216821ea7098"}, {"y": 1022, "x": 1080, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2c5309a2924636864b7ffa423d80d66d3aebd142"}], "s": {"y": 2436, "x": 2574, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=2574&amp;format=png&amp;auto=webp&amp;s=a3cd6e49b18390804c02f43386c99c9c176dabd9"}, "id": "5mp1zk433bhb1"}, "sfi70wunabhb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=80de52624397738554c51fa8c63a294921a5e377"}, {"y": 72, "x": 216, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a8421059c3bfb628739fdfa732143261098bad9d"}, {"y": 107, "x": 320, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a13fd80c046101a5d48b23af739486ccf0fe0c2f"}, {"y": 215, "x": 640, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e9981d772dcfaf6922c64cb3096210ca663d367c"}, {"y": 322, "x": 960, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=27bc1f57081548e1ec99428c24346f919951e7ab"}, {"y": 362, "x": 1080, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=35b1337a0c51e2841977782442e27d74070a3cdc"}], "s": {"y": 858, "x": 2554, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=2554&amp;format=png&amp;auto=webp&amp;s=5974f8402f678c4571d968ae75f16fceade8dae0"}, "id": "sfi70wunabhb1"}, "qtbk8r7g9bhb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 31, "x": 108, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7784a281045ba4e78d6ffed8083b3d81cc178a1c"}, {"y": 63, "x": 216, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=32be5e8761420dc8db2384adcae2c4b2000ff893"}, {"y": 93, "x": 320, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7433d279352d3c7ea70792b4568a7d31456d7f7e"}, {"y": 186, "x": 640, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=98a5923059ae8dcf1f4342b78f556fc65327385e"}, {"y": 280, "x": 960, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c4c1b2a990466adf49cdfd82cfbe1111fe447f44"}, {"y": 315, "x": 1080, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d84d392e1c0076bb2794b89ea54856ac29753c2e"}], "s": {"y": 750, "x": 2570, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=2570&amp;format=png&amp;auto=webp&amp;s=f7e1e0bdade907da18b3a47b7b286d20d762b05d"}, "id": "qtbk8r7g9bhb1"}}, "name": "t3_15nhq56", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LCnLCMzf6omKKoHE5RRnPL1Oear0z01ReaQUHIQpZoU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691686295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Overview&lt;/h1&gt;\n\n&lt;p&gt;With the Premier League season starting tomorrow, I wanted to showcase some updates I&amp;#39;ve made to this project I&amp;#39;ve been working and have posted about in the past:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;1st &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/10jjsfp/another_data_project_this_time_with_python_go/\"&gt;post&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;2nd &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/13eqbfy/introducing_firestore_into_my_premier_league/\"&gt;post&lt;/a&gt;.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Instead of using Streamlit Cloud, I am now hosting the app with Cloud Run as a Service. (a Docker container): &lt;a href=\"https://streamlit.digitalghost.dev\"&gt;https://streamlit.digitalghost.dev&lt;/a&gt; - proxied through CloudFlare \ud83d\ude09. This was done so that I can further play and practice with GitHub Actions and Streamlit and because Streamlit is &lt;a href=\"https://discuss.streamlit.io/t/link-to-ip-allowlist-documentation-is-broken/40648/7\"&gt;removing IP whitelisting for external database connections&lt;/a&gt; so this was a necessary change to get ahead of the curb.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also moved the project&amp;#39;s documentation to GitBook: &lt;a href=\"https://docs.digitalghost.dev\"&gt;https://docs.digitalghost.dev&lt;/a&gt; - a bit nicer than Notion.&lt;/p&gt;\n\n&lt;h1&gt;Links&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Dashboard: &lt;a href=\"https://streamlit.digitalghost.dev\"&gt;https://streamlit.digitalghost.dev&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Docs: &lt;a href=\"https://docs.digitalghost.dev\"&gt;https://docs.digitalghost.dev&lt;/a&gt; (Work in Progress)&lt;/li&gt;\n&lt;li&gt;GitHub: &lt;a href=\"https://github.com/digitalghost-dev/premier-league\"&gt;https://github.com/digitalghost-dev/premier-league&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;DockerHub: &lt;a href=\"https://hub.docker.com/r/digitalghostdev/premier-league/tags\"&gt;https://hub.docker.com/r/digitalghostdev/premier-league/tags&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Flowchart&lt;/h1&gt;\n\n&lt;p&gt;I&amp;#39;ve changed quite a lot now to make a bit less complex and introduce some new technologies that I&amp;#39;ve been wanting to play with, mainly Prefect, Terraform, PostgreSQL.&lt;/p&gt;\n\n&lt;p&gt;Here is an updated flowchart:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/5mp1zk433bhb1.png?width=2574&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a3cd6e49b18390804c02f43386c99c9c176dabd9\"&gt;Pipeline Flowchart created with eraser.io&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Of course none of these changes were necessary but like stated before, I wanted to use new technologies. I subbed out BigQuery with PostgreSQL running on &lt;a href=\"https://cloud.google.com/sql\"&gt;Cloud SQL&lt;/a&gt;. I could hold JSON data in PostgreSQL but wanted to keep Firestore. I now have Prefect running on a Virtual Machine (VM) that is the orchestration tool to schedule and execute the ETL scripts. The VM is created with Terraform and installs everything for me with a &lt;code&gt;.sh&lt;/code&gt; file.&lt;/p&gt;\n\n&lt;h1&gt;CI/CD Pipeline&lt;/h1&gt;\n\n&lt;p&gt;The CI/CD pipeline has changed to focus 100% on the Streamlit app:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qtbk8r7g9bhb1.png?width=2570&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f7e1e0bdade907da18b3a47b7b286d20d762b05d\"&gt;Example from Testing the Pipeline&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;After the Docker image is built, it&amp;#39;s pushed to Artifact Registry and deployed to Cloud Run.&lt;/p&gt;\n\n&lt;p&gt;There is another step that builds the image for different architectures: &lt;code&gt;linux/amd64&lt;/code&gt; and &lt;code&gt;linux/arm64&lt;/code&gt; and pushes them to my &lt;a href=\"https://hub.docker.com/r/digitalghostdev/premier-league/tags\"&gt;DockerHub&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Security&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have included &lt;a href=\"https://snyk.io\"&gt;Snyk&lt;/a&gt; to scan the dependencies in the repositories and under the security tab in the Github Repo, I can see all vulnerabilities.&lt;/p&gt;\n\n&lt;p&gt;After the image is built, an SBOM is created using &lt;a href=\"https://github.com/anchore/syft\"&gt;Syft&lt;/a&gt; then that SBOM is scanned with &lt;a href=\"https://github.com/anchore/grype\"&gt;Grype&lt;/a&gt; and just like Snyk, the security tab is filled with the vulnerabilities as a &lt;code&gt;SARIF&lt;/code&gt; report.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/sfi70wunabhb1.png?width=2554&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5974f8402f678c4571d968ae75f16fceade8dae0\"&gt;Vulnerabilities in Repo&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Closing Notes&lt;/h1&gt;\n\n&lt;p&gt;The cool thing I have come to realized about building this is that I was able to implement Prefect at work with a decent amount of confidence to fix our automation needs.&lt;/p&gt;\n\n&lt;p&gt;Looking ahead, I think I am at a good place where I won&amp;#39;t be changing the ETL architecture anymore and just focus on adding more content to the Streamlit app itself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "15nhq56", "is_robot_indexable": true, "report_reasons": null, "author": "digitalghost-dev", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nhq56/premier_league_data_pipeline_project_update/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nhq56/premier_league_data_pipeline_project_update/", "subreddit_subscribers": 122114, "created_utc": 1691686295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nI recently joined an e-commerce company as a Senior Data Analyst. My work involves heavy usage of SQL and digital analytics (GA4, GTM, A/B testing). \n\nI\u2019ve been in the analytics space for the last 4 years and have been closely involved with growth marketing. At my previous company, a Fintech startup (pre series A), I ended up as the team lead (small team of 4) where we built a simple modern data stack (Fivetran, BigQuery, dbt &amp; Looker) from scratch. We delivered quite a few data products for descriptive &amp; diagnostic analytics but couldn\u2019t get to the stage of predictive analytics/ML. I wasn\u2019t very hands-on on the ELT procedure but the experience did give me a good understanding of the analytics lifecycle.\n\nNow, I feel I\u2019m at a crossroads in my career. I\u2019m doing well at my current company but I want to upskill to stay relevant and further grow my career. I\u2019m evaluating these 3 paths: \n\n1. Analytics Engineering\nStrength: My experience in DA. I understand business quite well. Have played the role of a bridge between business and technical teams. \n\nWeakness: Not sure if AE is just a fad or does it have high potential. Also, I\u2019m not good at software engineering practices. (Though I\u2019m willing to learn) \n\n2. Data Engineering \nStrength: I think DE will become more important with time since Gen AI can replace analysts to a certain extent but can\u2019t build the infrastructure (atleast not as of now). I understand quite a few theoretical concepts around DE.\n\nWeakness: No hands on experience of DE. I assume a steep learning curve. Not good at software engineering. \n\n3. Data Scientist (focused on LLMs) \nStrength: I clearly see the potential of getting skilled at dealing with LLMs. Have some understanding of ML algorithms. Have business exposure.\n\nWeakness: No hands on experience with LLMs. Have worked with ML but haven\u2019t ever deployed a model in a business setting. \n\n\nPersonally, I think AE might be a natural progression for me but I\u2019m open to hear thoughts from this community. I\u2019d appreciate even if you\u2019ve any other suggestions apart from the choices mentioned. \n\nP.s. this is my first post here and didn\u2019t expect it to be so long! \n\nThanks a ton!", "author_fullname": "t2_6oqhtw12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career path options for DA?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nlj1x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691694965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I recently joined an e-commerce company as a Senior Data Analyst. My work involves heavy usage of SQL and digital analytics (GA4, GTM, A/B testing). &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been in the analytics space for the last 4 years and have been closely involved with growth marketing. At my previous company, a Fintech startup (pre series A), I ended up as the team lead (small team of 4) where we built a simple modern data stack (Fivetran, BigQuery, dbt &amp;amp; Looker) from scratch. We delivered quite a few data products for descriptive &amp;amp; diagnostic analytics but couldn\u2019t get to the stage of predictive analytics/ML. I wasn\u2019t very hands-on on the ELT procedure but the experience did give me a good understanding of the analytics lifecycle.&lt;/p&gt;\n\n&lt;p&gt;Now, I feel I\u2019m at a crossroads in my career. I\u2019m doing well at my current company but I want to upskill to stay relevant and further grow my career. I\u2019m evaluating these 3 paths: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Analytics Engineering\nStrength: My experience in DA. I understand business quite well. Have played the role of a bridge between business and technical teams. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Weakness: Not sure if AE is just a fad or does it have high potential. Also, I\u2019m not good at software engineering practices. (Though I\u2019m willing to learn) &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Engineering \nStrength: I think DE will become more important with time since Gen AI can replace analysts to a certain extent but can\u2019t build the infrastructure (atleast not as of now). I understand quite a few theoretical concepts around DE.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Weakness: No hands on experience of DE. I assume a steep learning curve. Not good at software engineering. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Scientist (focused on LLMs) \nStrength: I clearly see the potential of getting skilled at dealing with LLMs. Have some understanding of ML algorithms. Have business exposure.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Weakness: No hands on experience with LLMs. Have worked with ML but haven\u2019t ever deployed a model in a business setting. &lt;/p&gt;\n\n&lt;p&gt;Personally, I think AE might be a natural progression for me but I\u2019m open to hear thoughts from this community. I\u2019d appreciate even if you\u2019ve any other suggestions apart from the choices mentioned. &lt;/p&gt;\n\n&lt;p&gt;P.s. this is my first post here and didn\u2019t expect it to be so long! &lt;/p&gt;\n\n&lt;p&gt;Thanks a ton!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15nlj1x", "is_robot_indexable": true, "report_reasons": null, "author": "CowCultural9007", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nlj1x/career_path_options_for_da/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nlj1x/career_path_options_for_da/", "subreddit_subscribers": 122114, "created_utc": 1691694965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Community,\n\nHope you are doing well.\n\nI want to improve the existing Git flow for my projects -\n\nCurrently the Git flow that we have in place, works as below -\n\n1. Create a new feature branch from **Develop** using the naming convention: **feature/issue#\\_&lt;name&gt;**.\n2. When development is complete, open a PR targeting **Develop**. Upon approval, merge using the \"Squash and Merge\" option. Delete the feature branch afterward if it's no longer needed.\n3. To introduce changes into pre-production, initiate a PR from **Develop** to **Master**. Utilize the \"Create Merge Commit\" strategy for merging (without deleting the **Develop** branch, of course).\n4. For deployment to production, create a release branch from **Master**. Tag the commit with the desired deployment version.\n5. After verifying that the deployment is successful, merge the release branch into **Master** using the regular merge strategy.\n6. Subsequently, make an additional commit on the release branch to update the version (increment the minor version and append \"dev\"). Finally, open a PR targeting **Develop**.\n\n**For HotFix -**\n\n1. Create a branch based on the most recent deployed commit, which is the merge from the last release branch.\n2. Adjust the patch version and apply your changes.\n3. Submit a PR to the **master** branch. After getting approval, tag your commit and initiate deployment.\n4. Complete the merge into **master.**\n5. Sync the version with that of the **develop** branch and raise a PR for **develop**.\n\n\\---\n\nI want to improve the below points -\n\n* 3rd point - how will you know if the new feature is ready to push to pre-production. Currently, we manually running the ETL pipeline, once all the tests are successful, we mention everything on PR ( including test cases )\n* how to align the master and develop after the release in the production / HotFix.\n\nAre there any other git flow are you following, please share your experience.", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Git flow for Data Engineering projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o4h68", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691747549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Community,&lt;/p&gt;\n\n&lt;p&gt;Hope you are doing well.&lt;/p&gt;\n\n&lt;p&gt;I want to improve the existing Git flow for my projects -&lt;/p&gt;\n\n&lt;p&gt;Currently the Git flow that we have in place, works as below -&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create a new feature branch from &lt;strong&gt;Develop&lt;/strong&gt; using the naming convention: &lt;strong&gt;feature/issue#_&amp;lt;name&amp;gt;&lt;/strong&gt;.&lt;/li&gt;\n&lt;li&gt;When development is complete, open a PR targeting &lt;strong&gt;Develop&lt;/strong&gt;. Upon approval, merge using the &amp;quot;Squash and Merge&amp;quot; option. Delete the feature branch afterward if it&amp;#39;s no longer needed.&lt;/li&gt;\n&lt;li&gt;To introduce changes into pre-production, initiate a PR from &lt;strong&gt;Develop&lt;/strong&gt; to &lt;strong&gt;Master&lt;/strong&gt;. Utilize the &amp;quot;Create Merge Commit&amp;quot; strategy for merging (without deleting the &lt;strong&gt;Develop&lt;/strong&gt; branch, of course).&lt;/li&gt;\n&lt;li&gt;For deployment to production, create a release branch from &lt;strong&gt;Master&lt;/strong&gt;. Tag the commit with the desired deployment version.&lt;/li&gt;\n&lt;li&gt;After verifying that the deployment is successful, merge the release branch into &lt;strong&gt;Master&lt;/strong&gt; using the regular merge strategy.&lt;/li&gt;\n&lt;li&gt;Subsequently, make an additional commit on the release branch to update the version (increment the minor version and append &amp;quot;dev&amp;quot;). Finally, open a PR targeting &lt;strong&gt;Develop&lt;/strong&gt;.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;For HotFix -&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create a branch based on the most recent deployed commit, which is the merge from the last release branch.&lt;/li&gt;\n&lt;li&gt;Adjust the patch version and apply your changes.&lt;/li&gt;\n&lt;li&gt;Submit a PR to the &lt;strong&gt;master&lt;/strong&gt; branch. After getting approval, tag your commit and initiate deployment.&lt;/li&gt;\n&lt;li&gt;Complete the merge into &lt;strong&gt;master.&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Sync the version with that of the &lt;strong&gt;develop&lt;/strong&gt; branch and raise a PR for &lt;strong&gt;develop&lt;/strong&gt;.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;I want to improve the below points -&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;3rd point - how will you know if the new feature is ready to push to pre-production. Currently, we manually running the ETL pipeline, once all the tests are successful, we mention everything on PR ( including test cases )&lt;/li&gt;\n&lt;li&gt;how to align the master and develop after the release in the production / HotFix.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Are there any other git flow are you following, please share your experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15o4h68", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15o4h68/git_flow_for_data_engineering_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o4h68/git_flow_for_data_engineering_projects/", "subreddit_subscribers": 122114, "created_utc": 1691747549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello friends, for my thesis I need to do research on what the most common factors are the cause a datawarehouse project to fail. Is there anybody who knows of good sources I could use for my research. Thank you", "author_fullname": "t2_8mte9pyz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datawarehouse thesis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nms1s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691697813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello friends, for my thesis I need to do research on what the most common factors are the cause a datawarehouse project to fail. Is there anybody who knows of good sources I could use for my research. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15nms1s", "is_robot_indexable": true, "report_reasons": null, "author": "SnowEcstatic", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nms1s/datawarehouse_thesis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nms1s/datawarehouse_thesis/", "subreddit_subscribers": 122114, "created_utc": 1691697813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7lbbuuh58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I couldn't find any detailed comparison between dataframe tools so I wrote one: this post compares Polars, DuckDB, Pandas, Modin, Ponder, Fugue, Daft, and more", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o5q7l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1691751543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kestra.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://kestra.io/blogs/2023-08-11-dataframes", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15o5q7l", "is_robot_indexable": true, "report_reasons": null, "author": "Round-Following1532", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o5q7l/i_couldnt_find_any_detailed_comparison_between/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://kestra.io/blogs/2023-08-11-dataframes", "subreddit_subscribers": 122114, "created_utc": 1691751543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been trying to research what the best way to do this is, but I have a bunch of CSVs I need to convert to parquet in S3.  \n\n\nIs the best way to create multiple dataframes of equal number of CSV files and then parallel write those dataframes to S3\n\nor\n\nRead one dataframe containing all files and then repartition the df by the partition column and number of executors to shuffle them into an ordered fashion and then have the shuffle write minimize data movement?", "author_fullname": "t2_7jt0qboi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark: How to Handle Parallel Writes to Parquet?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nw73k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691721030.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been trying to research what the best way to do this is, but I have a bunch of CSVs I need to convert to parquet in S3.  &lt;/p&gt;\n\n&lt;p&gt;Is the best way to create multiple dataframes of equal number of CSV files and then parallel write those dataframes to S3&lt;/p&gt;\n\n&lt;p&gt;or&lt;/p&gt;\n\n&lt;p&gt;Read one dataframe containing all files and then repartition the df by the partition column and number of executors to shuffle them into an ordered fashion and then have the shuffle write minimize data movement?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15nw73k", "is_robot_indexable": true, "report_reasons": null, "author": "omscsdatathrow", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nw73k/spark_how_to_handle_parallel_writes_to_parquet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nw73k/spark_how_to_handle_parallel_writes_to_parquet/", "subreddit_subscribers": 122114, "created_utc": 1691721030.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Struggling to get any interviews for junior or entry DE jobs. \n\nI\u2019m thinking I should instead focus on another path in either SWE or DA.\n\nHowever, I\u2019m burning myself out trying to learn everything rather than focusing in on one specific discipline - and a feeling a bit lost on my journey.\n\nI\u2019m also unsure what my LinkedIn should say/look like if I\u2019m applying for all 3 of these roles.\n\nAny advice on what I should be focused on, or what skills I should be learning?\n\nIm proficient in Python &amp; SQL, with some experience through personal projects with Airflow, IaC, AWS, Data Warehousing, among other things.", "author_fullname": "t2_7xk4etxe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I be looking at SWE or Data Analyst roles instead - and what skills to focus on for these?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o0pt9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691734648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Struggling to get any interviews for junior or entry DE jobs. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m thinking I should instead focus on another path in either SWE or DA.&lt;/p&gt;\n\n&lt;p&gt;However, I\u2019m burning myself out trying to learn everything rather than focusing in on one specific discipline - and a feeling a bit lost on my journey.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m also unsure what my LinkedIn should say/look like if I\u2019m applying for all 3 of these roles.&lt;/p&gt;\n\n&lt;p&gt;Any advice on what I should be focused on, or what skills I should be learning?&lt;/p&gt;\n\n&lt;p&gt;Im proficient in Python &amp;amp; SQL, with some experience through personal projects with Airflow, IaC, AWS, Data Warehousing, among other things.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15o0pt9", "is_robot_indexable": true, "report_reasons": null, "author": "Weekly_Dimension_332", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o0pt9/should_i_be_looking_at_swe_or_data_analyst_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o0pt9/should_i_be_looking_at_swe_or_data_analyst_roles/", "subreddit_subscribers": 122114, "created_utc": 1691734648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "DATA TEAM OFFICE - FRIDAY AFTRENOON\n\nThe DATA ENGINEER is sitting at a computer, face buried in his hands. The POSTGRESQL QUERY PLANNER, portrayed as a disheveled character wearing a tie on his head and holding a bottle labeled \"Inefficient Index IPA\" stumbles around the office.\n\nDATA ENGINEER: (frustrated) Come on, Postgres, get it together! We've got to make this query to run fast enough before the deadline.\n\nPOSTGRESQL: (slurring) Optimize? Sure, I know how to do that!\n\n\\*POSTGRESQL grabs a new bottle from desk draw and starts going though file cabinet\\*\n\nDATA ENGINEER: Oh, no no no, that's a full table scan! Why!?!? The index is right there! Look!\n\n\\*DATA ENGINEER points to the screen with fear and desperation in his eyes.\\*\n\nPOSTGRESQL: Index? Ha? Where? This \"Full Table Tequila\" is so good, want some?\n\nDATA ENGINEER: (pleadingly) Please, Query Planner, we need you sober for this. The team is counting on us.\n\nPOSTGRESQL: (giggling) Sober? Where's the fun in that? How 'bout we make our selves a Nested Loop Negroni! Those are amazing!\n\nDATA ENGINEER: Please don't do nested loop, please. Just use hash join. Remember the good times we had with hash joins?\n\nPOSTGRESQL: (stumbling) Hash? Nah, I'm not smoking while I'm drinking.\n\nDATA ENGINEER: (gritting teeth) You're slow and inefficient! I'm going to replace you with DuckDB!\n\nPOSTGRESQL: (tearfully) Why you gotta be so mean? I'm just trying to find the best query execution path, in my own way.\n\nDATA ENGINEER: And I'm trying to help you, but you're making it impossible! Why can't you see that the indices are right there?\n\nPOSTGRESQL: (dramatically) Because I'm blind to the conventional ways, my friend. I walk the path less traveled. I like the scenic route!\n\nDATA ENGINEER: (shaking head) I'll be here all night.\n\nDATA ENGINEER slumps back in his chair, as POSTGRESQL stumbles towards the window, singing an off-key version of \"Row, Row, Row Your Boat.\" holding \"Cursed Cartesian Vodka\" bottle in their hand.\n\nFADE TO BLACK", "author_fullname": "t2_cmjwin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing Postgres - Scene from fictional sitcom \"Data Dilemmas\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o06a0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691732873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DATA TEAM OFFICE - FRIDAY AFTRENOON&lt;/p&gt;\n\n&lt;p&gt;The DATA ENGINEER is sitting at a computer, face buried in his hands. The POSTGRESQL QUERY PLANNER, portrayed as a disheveled character wearing a tie on his head and holding a bottle labeled &amp;quot;Inefficient Index IPA&amp;quot; stumbles around the office.&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: (frustrated) Come on, Postgres, get it together! We&amp;#39;ve got to make this query to run fast enough before the deadline.&lt;/p&gt;\n\n&lt;p&gt;POSTGRESQL: (slurring) Optimize? Sure, I know how to do that!&lt;/p&gt;\n\n&lt;p&gt;*POSTGRESQL grabs a new bottle from desk draw and starts going though file cabinet*&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: Oh, no no no, that&amp;#39;s a full table scan! Why!?!? The index is right there! Look!&lt;/p&gt;\n\n&lt;p&gt;*DATA ENGINEER points to the screen with fear and desperation in his eyes.*&lt;/p&gt;\n\n&lt;p&gt;POSTGRESQL: Index? Ha? Where? This &amp;quot;Full Table Tequila&amp;quot; is so good, want some?&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: (pleadingly) Please, Query Planner, we need you sober for this. The team is counting on us.&lt;/p&gt;\n\n&lt;p&gt;POSTGRESQL: (giggling) Sober? Where&amp;#39;s the fun in that? How &amp;#39;bout we make our selves a Nested Loop Negroni! Those are amazing!&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: Please don&amp;#39;t do nested loop, please. Just use hash join. Remember the good times we had with hash joins?&lt;/p&gt;\n\n&lt;p&gt;POSTGRESQL: (stumbling) Hash? Nah, I&amp;#39;m not smoking while I&amp;#39;m drinking.&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: (gritting teeth) You&amp;#39;re slow and inefficient! I&amp;#39;m going to replace you with DuckDB!&lt;/p&gt;\n\n&lt;p&gt;POSTGRESQL: (tearfully) Why you gotta be so mean? I&amp;#39;m just trying to find the best query execution path, in my own way.&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: And I&amp;#39;m trying to help you, but you&amp;#39;re making it impossible! Why can&amp;#39;t you see that the indices are right there?&lt;/p&gt;\n\n&lt;p&gt;POSTGRESQL: (dramatically) Because I&amp;#39;m blind to the conventional ways, my friend. I walk the path less traveled. I like the scenic route!&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: (shaking head) I&amp;#39;ll be here all night.&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER slumps back in his chair, as POSTGRESQL stumbles towards the window, singing an off-key version of &amp;quot;Row, Row, Row Your Boat.&amp;quot; holding &amp;quot;Cursed Cartesian Vodka&amp;quot; bottle in their hand.&lt;/p&gt;\n\n&lt;p&gt;FADE TO BLACK&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "15o06a0", "is_robot_indexable": true, "report_reasons": null, "author": "tiltaltti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o06a0/optimizing_postgres_scene_from_fictional_sitcom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o06a0/optimizing_postgres_scene_from_fictional_sitcom/", "subreddit_subscribers": 122114, "created_utc": 1691732873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nI am a data engineer with 6-7 YoE from Italy. During my career I have both developed custom data platforms (there were almost no data  platform   SaaS back then), and worked on the data modelling/analytics  part   (developed ETL pipelines, generated analytics reports, supported  data   scientists to implement ML models etc.)\n\nThis year has been quite bad for everyone who was considering to find a new job, and I am no exception.\n\nCompanies seem to only look for senior profiles, which I think I am, but they only consider - or actively search -  people  from renowned companies instead of evaluating skills/experience, and I have only worked - and currently  work -   in less known ones.\n\nSince   the  Italian market is quite a barren land, I have also tried to  find open positions in other European countries, such as Spain or  Germany, but  till date nobody has contacted me back, probably because  they   prefer a candidate that doesn't have to relocate.\n\nIn  case you have recently found a new job as a DE, could you please share  how did you do it, or any useful tips to make my profile more appealing?\n\nThank you!", "author_fullname": "t2_do2bj7xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for career advices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nzg7z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691734540.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691730541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I am a data engineer with 6-7 YoE from Italy. During my career I have both developed custom data platforms (there were almost no data  platform   SaaS back then), and worked on the data modelling/analytics  part   (developed ETL pipelines, generated analytics reports, supported  data   scientists to implement ML models etc.)&lt;/p&gt;\n\n&lt;p&gt;This year has been quite bad for everyone who was considering to find a new job, and I am no exception.&lt;/p&gt;\n\n&lt;p&gt;Companies seem to only look for senior profiles, which I think I am, but they only consider - or actively search -  people  from renowned companies instead of evaluating skills/experience, and I have only worked - and currently  work -   in less known ones.&lt;/p&gt;\n\n&lt;p&gt;Since   the  Italian market is quite a barren land, I have also tried to  find open positions in other European countries, such as Spain or  Germany, but  till date nobody has contacted me back, probably because  they   prefer a candidate that doesn&amp;#39;t have to relocate.&lt;/p&gt;\n\n&lt;p&gt;In  case you have recently found a new job as a DE, could you please share  how did you do it, or any useful tips to make my profile more appealing?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15nzg7z", "is_robot_indexable": true, "report_reasons": null, "author": "somerandomdataeng", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15nzg7z/looking_for_career_advices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nzg7z/looking_for_career_advices/", "subreddit_subscribers": 122114, "created_utc": 1691730541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi data friends \ud83d\udc4b  \n\n\nI'm Ian and I'm building AI-powered data tools at Turntable.\n\nWe just opened up public access to our new free VS Code extension for writing dbt documentation side-by-side with your dbt models. You can also use AI to auto generate model and column descriptions.  \n\n\nLearn more from our announcement here: [https://twitter.com/turntabledata/status/1689744394897756160](https://twitter.com/turntabledata/status/1689744394897756160)  \n\n\nYou can you download it here [https://www.turntable.so/](https://www.turntable.so/)", "author_fullname": "t2_esppz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free VS Code Extension for writing dbt documentation using AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nohkj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691701717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi data friends \ud83d\udc4b  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m Ian and I&amp;#39;m building AI-powered data tools at Turntable.&lt;/p&gt;\n\n&lt;p&gt;We just opened up public access to our new free VS Code extension for writing dbt documentation side-by-side with your dbt models. You can also use AI to auto generate model and column descriptions.  &lt;/p&gt;\n\n&lt;p&gt;Learn more from our announcement here: &lt;a href=\"https://twitter.com/turntabledata/status/1689744394897756160\"&gt;https://twitter.com/turntabledata/status/1689744394897756160&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;You can you download it here &lt;a href=\"https://www.turntable.so/\"&gt;https://www.turntable.so/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-71GoTv5rIrTKhv_-eCLkPRq5D460ZS2CboAHd6AeJs.jpg?auto=webp&amp;s=f8051e95ad5fc8d18792fe9a7e995a615b50264c", "width": 140, "height": 113}, "resolutions": [{"url": "https://external-preview.redd.it/-71GoTv5rIrTKhv_-eCLkPRq5D460ZS2CboAHd6AeJs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4f1d4bd261c9034d5c94eab5d4efdbf984d1cb08", "width": 108, "height": 87}], "variants": {}, "id": "nAtL11tqbwGo2Q21fH-ZRssRpHe9KrnDTFZeXwynSSw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15nohkj", "is_robot_indexable": true, "report_reasons": null, "author": "StartCompaniesNotWar", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nohkj/free_vs_code_extension_for_writing_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nohkj/free_vs_code_extension_for_writing_dbt/", "subreddit_subscribers": 122114, "created_utc": 1691701717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://dataengineeracademy.com/blog/dbt-data-build-tool-tutorial/](https://dataengineeracademy.com/blog/dbt-data-build-tool-tutorial/)", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT (Data Build Tool) Tutorial", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nmat8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691696727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://dataengineeracademy.com/blog/dbt-data-build-tool-tutorial/\"&gt;https://dataengineeracademy.com/blog/dbt-data-build-tool-tutorial/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?auto=webp&amp;s=7572d931b25c11ffd99056a38463595b524705d1", "width": 1080, "height": 558}, "resolutions": [{"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2d964d3529b465d201aa2f951bfb522ff306cc31", "width": 108, "height": 55}, {"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1ae456b40f75b50ac3a4c6e42f07648100083c8e", "width": 216, "height": 111}, {"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d891ea0c4e5fb22984c418f5eda694e7d76f7546", "width": 320, "height": 165}, {"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4d46b1c275f86156eff316f7d1ff90f4235862e", "width": 640, "height": 330}, {"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a89e7fcb176ea9b5831f92b039d6af38ace56a7b", "width": 960, "height": 496}, {"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ac16666bd26109d0b0388c48ca1b05091bf6bf5f", "width": 1080, "height": 558}], "variants": {}, "id": "mcK8PbLckSlzatuuN1mtQwTxO2kzsHIVaX_NVVZ8JO8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "CEO of DE Academy/Amazon/Lyft/Author", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15nmat8", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15nmat8/dbt_data_build_tool_tutorial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nmat8/dbt_data_build_tool_tutorial/", "subreddit_subscribers": 122114, "created_utc": 1691696727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a question that pops up more and more in my head as I'm getting more of an understanding about what data engineering entails. I know what the core of my job is supposed to be. Be it ETL pipelines, warehouses... I get all that. Hell, you can find that kind of info pretty easily online, as well as all the knowledge you ever need about the tools we use.\n\nMy question is more about the process that comes before building any pipeline. For example: what is the deliverable you require to actually set up a pipeline? Is it an example query? Is it an excel that describes each column in a source-to-target mapping kind of way?\n\nFurthermore, who's task is it to actually make this mapping? What do you do when the mapping they provide isn't sufficient? (For example the cities table doesn't contain all cities in the country but only the state/province). What about when you're doing Kimball and people have not modeled correctly?\n\nI'm curious as to the methods people in this community use. I understand this depends a lot on the project itself as well as the team, but I would like to know what would normally be considered the boundaries of our work.", "author_fullname": "t2_2pbhwnrm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does my job begin and end?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ni690", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691687310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a question that pops up more and more in my head as I&amp;#39;m getting more of an understanding about what data engineering entails. I know what the core of my job is supposed to be. Be it ETL pipelines, warehouses... I get all that. Hell, you can find that kind of info pretty easily online, as well as all the knowledge you ever need about the tools we use.&lt;/p&gt;\n\n&lt;p&gt;My question is more about the process that comes before building any pipeline. For example: what is the deliverable you require to actually set up a pipeline? Is it an example query? Is it an excel that describes each column in a source-to-target mapping kind of way?&lt;/p&gt;\n\n&lt;p&gt;Furthermore, who&amp;#39;s task is it to actually make this mapping? What do you do when the mapping they provide isn&amp;#39;t sufficient? (For example the cities table doesn&amp;#39;t contain all cities in the country but only the state/province). What about when you&amp;#39;re doing Kimball and people have not modeled correctly?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious as to the methods people in this community use. I understand this depends a lot on the project itself as well as the team, but I would like to know what would normally be considered the boundaries of our work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ni690", "is_robot_indexable": true, "report_reasons": null, "author": "AirisuB", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15ni690/where_does_my_job_begin_and_end/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ni690/where_does_my_job_begin_and_end/", "subreddit_subscribers": 122114, "created_utc": 1691687310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A project has fallen into my lap to provide some consulting work for a small company that has five daily external data sources that are either full drop and replace (full refresh) each day, or append daily. The company is currently leveraging a managed service to provide all of the ETL work in their database, but the SOW for database license/managed service is both prohibitively expensive and coming to an end at end of this year (it was tied to other projects but business has changed dramatically and has slimmed since then). The company owns all of the data, they just outsource all of the data management.\n\nThe company has asked if I can be their consultant and set up a new database and can intake and store these five daily data sources automatically (currently sent via SFTP), perform ETL, and then replicate their analytic views so that their Tableau dashboards can continue to run, but just be pointed to a new database.\n\nDoes this thread have any recommended tools for low cost database and ETL tools that are simple to implement and build? Also any suggestions for SFTP site that are easy to setup?\n\nFor context, a friend is a VP in this small company and has asked me if I could do this but I am usually the person that builds analytic views and analyzes data vs. building data engineering processes upstream.\n\nThanks in advance!", "author_fullname": "t2_7nj41", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project Advice - Low Cost and Simple Database, ETL, SFTP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ncho1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691673930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A project has fallen into my lap to provide some consulting work for a small company that has five daily external data sources that are either full drop and replace (full refresh) each day, or append daily. The company is currently leveraging a managed service to provide all of the ETL work in their database, but the SOW for database license/managed service is both prohibitively expensive and coming to an end at end of this year (it was tied to other projects but business has changed dramatically and has slimmed since then). The company owns all of the data, they just outsource all of the data management.&lt;/p&gt;\n\n&lt;p&gt;The company has asked if I can be their consultant and set up a new database and can intake and store these five daily data sources automatically (currently sent via SFTP), perform ETL, and then replicate their analytic views so that their Tableau dashboards can continue to run, but just be pointed to a new database.&lt;/p&gt;\n\n&lt;p&gt;Does this thread have any recommended tools for low cost database and ETL tools that are simple to implement and build? Also any suggestions for SFTP site that are easy to setup?&lt;/p&gt;\n\n&lt;p&gt;For context, a friend is a VP in this small company and has asked me if I could do this but I am usually the person that builds analytic views and analyzes data vs. building data engineering processes upstream.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ncho1", "is_robot_indexable": true, "report_reasons": null, "author": "jroddaman", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ncho1/project_advice_low_cost_and_simple_database_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ncho1/project_advice_low_cost_and_simple_database_etl/", "subreddit_subscribers": 122114, "created_utc": 1691673930.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "KPIs provide valuable insights and data-driven measurements that enable data analytics teams to monitor the achievement of organizational goals, track progress, identify opportunities and challenges, and make informed decisions for optimal performance. \n\nKnow more: [https://www.dasca.org/data-science-certifications/top-kpls-for-data-science-teams](https://www.dasca.org/data-science-certifications/top-kpls-for-data-science-teams)", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Top KPIs for Data Teams: A Blueprint for Data-Driven Success", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15o8aff", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691758806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;KPIs provide valuable insights and data-driven measurements that enable data analytics teams to monitor the achievement of organizational goals, track progress, identify opportunities and challenges, and make informed decisions for optimal performance. &lt;/p&gt;\n\n&lt;p&gt;Know more: &lt;a href=\"https://www.dasca.org/data-science-certifications/top-kpls-for-data-science-teams\"&gt;https://www.dasca.org/data-science-certifications/top-kpls-for-data-science-teams&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lX_5NyPJO25I6iECYm_3RqJC9Vot1DwT-Otu0FWo9jY.jpg?auto=webp&amp;s=9e2dfcf28272cde341729206655ed0c436eb8e75", "width": 4801, "height": 2701}, "resolutions": [{"url": "https://external-preview.redd.it/lX_5NyPJO25I6iECYm_3RqJC9Vot1DwT-Otu0FWo9jY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a1d57a37e9770344b10abe0a7f54f0edb35f17e0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/lX_5NyPJO25I6iECYm_3RqJC9Vot1DwT-Otu0FWo9jY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=be21d60911c935aa7413d151c4065a4da36a7406", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/lX_5NyPJO25I6iECYm_3RqJC9Vot1DwT-Otu0FWo9jY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=216a5498b67cee3973b37be6d40611ce6e08f05b", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/lX_5NyPJO25I6iECYm_3RqJC9Vot1DwT-Otu0FWo9jY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a82c43de334e47b7ab51ca73cb221ecef0408045", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/lX_5NyPJO25I6iECYm_3RqJC9Vot1DwT-Otu0FWo9jY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=160ea45dee3f2313f2f213832044d85639df4472", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/lX_5NyPJO25I6iECYm_3RqJC9Vot1DwT-Otu0FWo9jY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=afa4146d5c374d2b5a52a2481f4065223cbb57d3", "width": 1080, "height": 607}], "variants": {}, "id": "l3r3cXMKVyFtwzsyckBNaiLftzgTUT3FjCPloSsjYCQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15o8aff", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o8aff/top_kpis_for_data_teams_a_blueprint_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o8aff/top_kpis_for_data_teams_a_blueprint_for/", "subreddit_subscribers": 122114, "created_utc": 1691758806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2dx4q7wn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "List of over 1.6K open data engineering jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_15o3rv0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/M0lq92HhmkXmbhDrUHr3vSRTiJFUsnTbo1F7goM8u1w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691745082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ai-jobs.net", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://ai-jobs.net/engineering-jobs/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fMWKl6P17hrCfVTR6ZIgR3zkqdcvVcFoa9Cr4kcgxgo.jpg?auto=webp&amp;s=6f63a7a5194953a0c06a0e04115b73be6d497f16", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/fMWKl6P17hrCfVTR6ZIgR3zkqdcvVcFoa9Cr4kcgxgo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=806f5dcd009e30a18ade33f27e13f2345d16f3fb", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/fMWKl6P17hrCfVTR6ZIgR3zkqdcvVcFoa9Cr4kcgxgo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c17290181c0fbc2133b688b456bf4ef3dd9ff7b7", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/fMWKl6P17hrCfVTR6ZIgR3zkqdcvVcFoa9Cr4kcgxgo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=153fb5e6361843f9c459207c96ff3d74661db926", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/fMWKl6P17hrCfVTR6ZIgR3zkqdcvVcFoa9Cr4kcgxgo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f6ea7ffec42c135ef3b7805136fbefa5736b1e2b", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/fMWKl6P17hrCfVTR6ZIgR3zkqdcvVcFoa9Cr4kcgxgo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6c63b0b1f6388c3f174211ca48920d2dd03190bb", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/fMWKl6P17hrCfVTR6ZIgR3zkqdcvVcFoa9Cr4kcgxgo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0ca9de2820366d3b7073e6e0bc859aabf9259d1d", "width": 1080, "height": 607}], "variants": {}, "id": "ZCfhKtu1C5Q6J7mt0GRPDbKMcVh0gak5KNA72cM0cTw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15o3rv0", "is_robot_indexable": true, "report_reasons": null, "author": "ai_jobs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o3rv0/list_of_over_16k_open_data_engineering_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ai-jobs.net/engineering-jobs/", "subreddit_subscribers": 122114, "created_utc": 1691745082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a use case where we need to run multiple data flows and automate the process based on some triggers. We will have python &amp; R code, data movement between S3 buckets and Redshift as some of our targets. \nThe client has a licence for Domino already in place but we are exploring our options to run our code via AWS Batch.\n\nEg, one of our flow involves moving data from an external source to S3, processing the data via python/R and then storing it on Redshift\n\nWhat would a good option to run our code and create pipelines?\n\nWhat would be cost effective and efficient?\n\nVery new to Domino and need understand whether there are any benefits of using it rather than going for Batch\n\nThanks", "author_fullname": "t2_end1j06n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running code via Domino Labs vs AWS Batch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o2liw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691741017.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a use case where we need to run multiple data flows and automate the process based on some triggers. We will have python &amp;amp; R code, data movement between S3 buckets and Redshift as some of our targets. \nThe client has a licence for Domino already in place but we are exploring our options to run our code via AWS Batch.&lt;/p&gt;\n\n&lt;p&gt;Eg, one of our flow involves moving data from an external source to S3, processing the data via python/R and then storing it on Redshift&lt;/p&gt;\n\n&lt;p&gt;What would a good option to run our code and create pipelines?&lt;/p&gt;\n\n&lt;p&gt;What would be cost effective and efficient?&lt;/p&gt;\n\n&lt;p&gt;Very new to Domino and need understand whether there are any benefits of using it rather than going for Batch&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15o2liw", "is_robot_indexable": true, "report_reasons": null, "author": "reddit-snorter", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o2liw/running_code_via_domino_labs_vs_aws_batch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o2liw/running_code_via_domino_labs_vs_aws_batch/", "subreddit_subscribers": 122114, "created_utc": 1691741017.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello partners\n\nI am 27 years old and I am a biomedical engineer, I have worked maintaining medical equipment since I graduated and studied a master's degree in medical technology and health business with the intention of giving a change to my working life, in my last job I worked as an applications specialist clinics but I recently had surgery and in the time I was in recovery I realized that I really hate my job. I have always been a very curious person and during my masters I learned about data analysis focused on the business of medical devices and disease prediction.\n\nThey were my favorite classes and I learned a lot about python and SQL, while I recover I am taking a google analytics course because I plan to quit and look for my first job in the data field.\n\nI would like you to give me tips to prepare myself for the difficulties I am going to face.\n\n&amp;#x200B;\n\nGreetings", "author_fullname": "t2_2lvwse0r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transition of biomedical engineering to data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o1zvx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691738987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello partners&lt;/p&gt;\n\n&lt;p&gt;I am 27 years old and I am a biomedical engineer, I have worked maintaining medical equipment since I graduated and studied a master&amp;#39;s degree in medical technology and health business with the intention of giving a change to my working life, in my last job I worked as an applications specialist clinics but I recently had surgery and in the time I was in recovery I realized that I really hate my job. I have always been a very curious person and during my masters I learned about data analysis focused on the business of medical devices and disease prediction.&lt;/p&gt;\n\n&lt;p&gt;They were my favorite classes and I learned a lot about python and SQL, while I recover I am taking a google analytics course because I plan to quit and look for my first job in the data field.&lt;/p&gt;\n\n&lt;p&gt;I would like you to give me tips to prepare myself for the difficulties I am going to face.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Greetings&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15o1zvx", "is_robot_indexable": true, "report_reasons": null, "author": "maturelovergto", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o1zvx/transition_of_biomedical_engineering_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o1zvx/transition_of_biomedical_engineering_to_data/", "subreddit_subscribers": 122114, "created_utc": 1691738987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow Redditors! We're currently dealing with user activity data storage for our internal site using Cosmos DB. Our data schema includes information on clicks, focus, and user-related data like session IDs. As you can imagine, data flow is substantial and frequent. We're at a crossroads between continuing with Cosmos DB or making the shift to a Kusto cluster. Additionally, data that's older than 24 hours isn't particularly useful to us. We'd greatly appreciate your insights and suggestions on which data storage technology would best suit our use case. Thanks in advance!", "author_fullname": "t2_4rwmtqki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cosmos db vs kusto cluster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nzyl0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691732177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors! We&amp;#39;re currently dealing with user activity data storage for our internal site using Cosmos DB. Our data schema includes information on clicks, focus, and user-related data like session IDs. As you can imagine, data flow is substantial and frequent. We&amp;#39;re at a crossroads between continuing with Cosmos DB or making the shift to a Kusto cluster. Additionally, data that&amp;#39;s older than 24 hours isn&amp;#39;t particularly useful to us. We&amp;#39;d greatly appreciate your insights and suggestions on which data storage technology would best suit our use case. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15nzyl0", "is_robot_indexable": true, "report_reasons": null, "author": "Independent_Art_952", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nzyl0/cosmos_db_vs_kusto_cluster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nzyl0/cosmos_db_vs_kusto_cluster/", "subreddit_subscribers": 122114, "created_utc": 1691732177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Disclaimer that I\u2019m currently new to the field of DE in general and I\u2019m learning airflow for the first time\n\nI have a pipeline written in python that\u2019s a single class where each method is a task, and they communicate with each other mainly via class variables. From what I understand, xcoms are airflows way of passing variables between tasks\n\nThe problem I can see myself running into is that I use a copious amount of \u201cmetadata\u201d in the form of these variables (I even pass dataframes this way instead of returning a dataframe from the methods)\n\nI haven\u2019t experimented much, but would I be able to convert any python object to an xcom, or would it be better to sort of rewrite the logic so that these tasks actually return values?\n\nI\u2019m very new to airflow, so any help is appreciated", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting an object-oriented pipeline to Airflow, how to handle a copious amount of instance variables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nvivv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691719237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Disclaimer that I\u2019m currently new to the field of DE in general and I\u2019m learning airflow for the first time&lt;/p&gt;\n\n&lt;p&gt;I have a pipeline written in python that\u2019s a single class where each method is a task, and they communicate with each other mainly via class variables. From what I understand, xcoms are airflows way of passing variables between tasks&lt;/p&gt;\n\n&lt;p&gt;The problem I can see myself running into is that I use a copious amount of \u201cmetadata\u201d in the form of these variables (I even pass dataframes this way instead of returning a dataframe from the methods)&lt;/p&gt;\n\n&lt;p&gt;I haven\u2019t experimented much, but would I be able to convert any python object to an xcom, or would it be better to sort of rewrite the logic so that these tasks actually return values?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m very new to airflow, so any help is appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15nvivv", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nvivv/converting_an_objectoriented_pipeline_to_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nvivv/converting_an_objectoriented_pipeline_to_airflow/", "subreddit_subscribers": 122114, "created_utc": 1691719237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI am looking to understand fortune companies' database design and architecture, specifically I am wanting to know how Spotify collects our data, uses it in AI through real stream technology. Where can I find this information? which websites will be helpful to learn them? I am preparing for system design interviews and would highly appreciate your help!", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I find Fortune 500 companies' database design patters?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nu3gd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691715407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I am looking to understand fortune companies&amp;#39; database design and architecture, specifically I am wanting to know how Spotify collects our data, uses it in AI through real stream technology. Where can I find this information? which websites will be helpful to learn them? I am preparing for system design interviews and would highly appreciate your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15nu3gd", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nu3gd/where_can_i_find_fortune_500_companies_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nu3gd/where_can_i_find_fortune_500_companies_database/", "subreddit_subscribers": 122114, "created_utc": 1691715407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone had experience using this data generator?\n\nI need to set up a solution that ingests streaming data, but I don\u2019t have any legitimate streaming sources. I could fake one myself with an azure function that creates files in the storage account, but then I found the event hubs data generator.\n\nAny other cheap / free tools I should consider?", "author_fullname": "t2_g65isv8ej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Event Hubs Data Generator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nfsw1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691681851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone had experience using this data generator?&lt;/p&gt;\n\n&lt;p&gt;I need to set up a solution that ingests streaming data, but I don\u2019t have any legitimate streaming sources. I could fake one myself with an azure function that creates files in the storage account, but then I found the event hubs data generator.&lt;/p&gt;\n\n&lt;p&gt;Any other cheap / free tools I should consider?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15nfsw1", "is_robot_indexable": true, "report_reasons": null, "author": "Federal_Equivalent80", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nfsw1/azure_event_hubs_data_generator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nfsw1/azure_event_hubs_data_generator/", "subreddit_subscribers": 122114, "created_utc": 1691681851.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}