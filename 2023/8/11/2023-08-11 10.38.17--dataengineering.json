{"kind": "Listing", "data": {"after": "t3_15o4ajp", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I wanted to say a big thanks to this sub-Reddit, as I just got my first job as a Data Engineer. \n\nAfter losing my job I decided to make a career change into Data Engineering from Data Science. From reading posts here for the past year or so my interest has grown in the area, leading up to this, so thanks everyone for all of the interesting and useful posts!\n\nAny advice for topic area to read up on before I start? Or maybe courses/YouTube series to help me be ready? \n\nThanks!", "author_fullname": "t2_7kdevi10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got my first Data Engineer job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ni579", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 88, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 88, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691687242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I wanted to say a big thanks to this sub-Reddit, as I just got my first job as a Data Engineer. &lt;/p&gt;\n\n&lt;p&gt;After losing my job I decided to make a career change into Data Engineering from Data Science. From reading posts here for the past year or so my interest has grown in the area, leading up to this, so thanks everyone for all of the interesting and useful posts!&lt;/p&gt;\n\n&lt;p&gt;Any advice for topic area to read up on before I start? Or maybe courses/YouTube series to help me be ready? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 300, "id": "award_cc299d65-77de-4828-89de-708b088349a0", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=16&amp;height=16&amp;auto=webp&amp;s=65edcad28bb61e02c98f6e5abae94570f15577af", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=32&amp;height=32&amp;auto=webp&amp;s=ade31fce9fae3cd026513278fd6d8f43a2470473", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=48&amp;height=48&amp;auto=webp&amp;s=4a6669f710a159e308d70a09ad5d91bf26576801", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=64&amp;height=64&amp;auto=webp&amp;s=6411ff24501a3c9ab1ba1fcc56e111e2897ed4f6", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=128&amp;height=128&amp;auto=webp&amp;s=161171b7b4aadddcf4bd0b258229c95cbf461625", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Historical anomaly - greatest in eternity.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "GOAT", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=16&amp;height=16&amp;auto=webp&amp;s=65edcad28bb61e02c98f6e5abae94570f15577af", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=32&amp;height=32&amp;auto=webp&amp;s=ade31fce9fae3cd026513278fd6d8f43a2470473", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=48&amp;height=48&amp;auto=webp&amp;s=4a6669f710a159e308d70a09ad5d91bf26576801", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=64&amp;height=64&amp;auto=webp&amp;s=6411ff24501a3c9ab1ba1fcc56e111e2897ed4f6", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png?width=128&amp;height=128&amp;auto=webp&amp;s=161171b7b4aadddcf4bd0b258229c95cbf461625", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/x52x5be57fd41_GOAT.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ni579", "is_robot_indexable": true, "report_reasons": null, "author": "Impressive_Fact_6561", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ni579/got_my_first_data_engineer_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ni579/got_my_first_data_engineer_job/", "subreddit_subscribers": 122093, "created_utc": 1691687242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hjo8koz9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Labs to add usage-based pricing on top of their seat costs for dbt Cloud. $0.01 per model after free tier.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_15nbhzf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "ups": 72, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 72, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VOZK9PPnf5QCFLMFLu-vvLSpDJzxccPPEL-pAx9iQwc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691671419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getdbt.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getdbt.com/blog/consumption-based-pricing-and-the-future-of-dbt-cloud/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?auto=webp&amp;s=edabdd18634aef29128ecc0d5693053ba1a95f6e", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5df6a50eec64ce3d126f3a47e1746feaf267cebb", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d02b260d5dddd4e2e7c80420970b653c3cdddab", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa646e05e744be5f524016d4c775b326ef90c2d1", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e29469bfc58fee1f76e41ce74322e006445b9bb6", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f7b72e416c6ef27bd12b9f3a5a19ef15ad9e8249", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=285b785bfdba2ba6f0da014cf261fbe2d5f57f3d", "width": 1080, "height": 607}], "variants": {}, "id": "1atsLEhqeX9kFaissrSt8acZk9ienTNBpjUXMcidAMU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15nbhzf", "is_robot_indexable": true, "report_reasons": null, "author": "PandaUnicornAlbatros", "discussion_type": null, "num_comments": 62, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nbhzf/dbt_labs_to_add_usagebased_pricing_on_top_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getdbt.com/blog/consumption-based-pricing-and-the-future-of-dbt-cloud/", "subreddit_subscribers": 122093, "created_utc": 1691671419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am wondering what the devops and production architectures look like for teams that have effectively in-housed dbt-core without paying for dbt-cloud.\n\nDo you run dbt on a server that accepts http requests from a scheduler? If so, how do you define 'jobs' and 'environments' the way dbt-cloud does? \n\nOpen to any ideas on the subject", "author_fullname": "t2_ofoc42j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your team use dbt-core without dbt-cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nhu70", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691686564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wondering what the devops and production architectures look like for teams that have effectively in-housed dbt-core without paying for dbt-cloud.&lt;/p&gt;\n\n&lt;p&gt;Do you run dbt on a server that accepts http requests from a scheduler? If so, how do you define &amp;#39;jobs&amp;#39; and &amp;#39;environments&amp;#39; the way dbt-cloud does? &lt;/p&gt;\n\n&lt;p&gt;Open to any ideas on the subject&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15nhu70", "is_robot_indexable": true, "report_reasons": null, "author": "PangeanPrawn", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nhu70/how_does_your_team_use_dbtcore_without_dbtcloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nhu70/how_does_your_team_use_dbtcore_without_dbtcloud/", "subreddit_subscribers": 122093, "created_utc": 1691686564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Given this is by far the subreddit that has the most discussions about Databricks (good, bad,  and ugly) ...)\n\nMyself and a few other Databricks employees have reclaimed /r/Databricks which was previously private and made it public.\n\nFeel free to come join us there to ask questions and discuss all things Databricks and the lakehouse!\n\nOr stay here and compare us to Snowflake some more, we love that.", "author_fullname": "t2_2gj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "/r/Databricks has been relaunched as a public subreddit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nxf1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691724418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Given this is by far the subreddit that has the most discussions about Databricks (good, bad,  and ugly) ...)&lt;/p&gt;\n\n&lt;p&gt;Myself and a few other Databricks employees have reclaimed &lt;a href=\"/r/Databricks\"&gt;/r/Databricks&lt;/a&gt; which was previously private and made it public.&lt;/p&gt;\n\n&lt;p&gt;Feel free to come join us there to ask questions and discuss all things Databricks and the lakehouse!&lt;/p&gt;\n\n&lt;p&gt;Or stay here and compare us to Snowflake some more, we love that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15nxf1q", "is_robot_indexable": true, "report_reasons": null, "author": "kthejoker", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nxf1q/rdatabricks_has_been_relaunched_as_a_public/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nxf1q/rdatabricks_has_been_relaunched_as_a_public/", "subreddit_subscribers": 122093, "created_utc": 1691724418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, does anyone knows the process? How much algo/fundamentals knowledge do I need? Let's say algo in terms of codeforces rating or how much time on leetcode easy/medium/hard and fundamentals in terms of questions that might be asked and areas. Thanks for all the answers. Intersted because they pay good and it's EU + NL has 30% tax ruling.", "author_fullname": "t2_g6ziwt5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get hired to Databricks in NL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nk88r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691691968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, does anyone knows the process? How much algo/fundamentals knowledge do I need? Let&amp;#39;s say algo in terms of codeforces rating or how much time on leetcode easy/medium/hard and fundamentals in terms of questions that might be asked and areas. Thanks for all the answers. Intersted because they pay good and it&amp;#39;s EU + NL has 30% tax ruling.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15nk88r", "is_robot_indexable": true, "report_reasons": null, "author": "fire_air", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nk88r/how_to_get_hired_to_databricks_in_nl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nk88r/how_to_get_hired_to_databricks_in_nl/", "subreddit_subscribers": 122093, "created_utc": 1691691968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# Overview\n\nWith the Premier League season starting tomorrow, I wanted to showcase some updates I've made to this project I've been working and have posted about in the past:\n\n* 1st [post](https://www.reddit.com/r/dataengineering/comments/10jjsfp/another_data_project_this_time_with_python_go/).\n* 2nd [post](https://www.reddit.com/r/dataengineering/comments/13eqbfy/introducing_firestore_into_my_premier_league/).\n\nInstead of using Streamlit Cloud, I am now hosting the app with Cloud Run as a Service. (a Docker container): [https://streamlit.digitalghost.dev](https://streamlit.digitalghost.dev) \\- proxied through CloudFlare \ud83d\ude09. This was done so that I can further play and practice with GitHub Actions and Streamlit and because Streamlit is [removing IP whitelisting for external database connections](https://discuss.streamlit.io/t/link-to-ip-allowlist-documentation-is-broken/40648/7) so this was a necessary change to get ahead of the curb.\n\nI've also moved the project's documentation to GitBook: [https://docs.digitalghost.dev](https://docs.digitalghost.dev) \\- a bit nicer than Notion.\n\n# Links\n\n* Dashboard: [https://streamlit.digitalghost.dev](https://streamlit.digitalghost.dev)\n* Docs: [https://docs.digitalghost.dev](https://docs.digitalghost.dev) (Work in Progress)\n* GitHub: [https://github.com/digitalghost-dev/premier-league](https://github.com/digitalghost-dev/premier-league)\n* DockerHub: [https://hub.docker.com/r/digitalghostdev/premier-league/tags](https://hub.docker.com/r/digitalghostdev/premier-league/tags)\n\n# Flowchart\n\nI've changed quite a lot now to make a bit less complex and introduce some new technologies that I've been wanting to play with, mainly Prefect, Terraform, PostgreSQL.\n\nHere is an updated flowchart:\n\n[Pipeline Flowchart created with eraser.io](https://preview.redd.it/5mp1zk433bhb1.png?width=2574&amp;format=png&amp;auto=webp&amp;s=a3cd6e49b18390804c02f43386c99c9c176dabd9)\n\nOf course none of these changes were necessary but like stated before, I wanted to use new technologies. I subbed out BigQuery with PostgreSQL running on [Cloud SQL](https://cloud.google.com/sql). I could hold JSON data in PostgreSQL but wanted to keep Firestore. I now have Prefect running on a Virtual Machine (VM) that is the orchestration tool to schedule and execute the ETL scripts. The VM is created with Terraform and installs everything for me with a `.sh` file.\n\n# CI/CD Pipeline\n\n The CI/CD pipeline has changed to focus 100% on the Streamlit app:\n\n[Example from Testing the Pipeline](https://preview.redd.it/qtbk8r7g9bhb1.png?width=2570&amp;format=png&amp;auto=webp&amp;s=f7e1e0bdade907da18b3a47b7b286d20d762b05d)\n\nAfter the Docker image is built, it's pushed to Artifact Registry and deployed to Cloud Run.\n\nThere is another step that builds the image for different architectures: `linux/amd64` and `linux/arm64` and pushes them to my [DockerHub](https://hub.docker.com/r/digitalghostdev/premier-league/tags).\n\n**Security**\n\nI have included [Snyk](https://snyk.io) to scan the dependencies in the repositories and under the security tab in the Github Repo, I can see all vulnerabilities.\n\nAfter the image is built, an SBOM is created using [Syft](https://github.com/anchore/syft) then that SBOM is scanned with [Grype](https://github.com/anchore/grype) and just like Snyk, the security tab is filled with the vulnerabilities as a `SARIF` report.\n\n[Vulnerabilities in Repo](https://preview.redd.it/sfi70wunabhb1.png?width=2554&amp;format=png&amp;auto=webp&amp;s=5974f8402f678c4571d968ae75f16fceade8dae0)\n\n# Closing Notes\n\nThe cool thing I have come to realized about building this is that I was able to implement Prefect at work with a decent amount of confidence to fix our automation needs.\n\nLooking ahead, I think I am at a good place where I won't be changing the ETL architecture anymore and just focus on adding more content to the Streamlit app itself.", "author_fullname": "t2_bix7v2w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Premier League Data Pipeline Project Update [Prefect, Terraform, PostgreSQL]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 132, "top_awarded_type": null, "hide_score": false, "media_metadata": {"5mp1zk433bhb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 102, "x": 108, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c1c686a1b587fcaa609b6048c4c9b005704b867"}, {"y": 204, "x": 216, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=232089d62675c4e7da4fc06042b137f0d5d339a3"}, {"y": 302, "x": 320, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=38c9381a6310b8aa9a281eddf7a01d1ea4a54c14"}, {"y": 605, "x": 640, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f0f7bb12c9d00dab37ed292a2c219732e8d743e5"}, {"y": 908, "x": 960, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e9e77708da785f5481b9bea2cfbe216821ea7098"}, {"y": 1022, "x": 1080, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2c5309a2924636864b7ffa423d80d66d3aebd142"}], "s": {"y": 2436, "x": 2574, "u": "https://preview.redd.it/5mp1zk433bhb1.png?width=2574&amp;format=png&amp;auto=webp&amp;s=a3cd6e49b18390804c02f43386c99c9c176dabd9"}, "id": "5mp1zk433bhb1"}, "sfi70wunabhb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=80de52624397738554c51fa8c63a294921a5e377"}, {"y": 72, "x": 216, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a8421059c3bfb628739fdfa732143261098bad9d"}, {"y": 107, "x": 320, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a13fd80c046101a5d48b23af739486ccf0fe0c2f"}, {"y": 215, "x": 640, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e9981d772dcfaf6922c64cb3096210ca663d367c"}, {"y": 322, "x": 960, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=27bc1f57081548e1ec99428c24346f919951e7ab"}, {"y": 362, "x": 1080, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=35b1337a0c51e2841977782442e27d74070a3cdc"}], "s": {"y": 858, "x": 2554, "u": "https://preview.redd.it/sfi70wunabhb1.png?width=2554&amp;format=png&amp;auto=webp&amp;s=5974f8402f678c4571d968ae75f16fceade8dae0"}, "id": "sfi70wunabhb1"}, "qtbk8r7g9bhb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 31, "x": 108, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7784a281045ba4e78d6ffed8083b3d81cc178a1c"}, {"y": 63, "x": 216, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=32be5e8761420dc8db2384adcae2c4b2000ff893"}, {"y": 93, "x": 320, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7433d279352d3c7ea70792b4568a7d31456d7f7e"}, {"y": 186, "x": 640, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=98a5923059ae8dcf1f4342b78f556fc65327385e"}, {"y": 280, "x": 960, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c4c1b2a990466adf49cdfd82cfbe1111fe447f44"}, {"y": 315, "x": 1080, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d84d392e1c0076bb2794b89ea54856ac29753c2e"}], "s": {"y": 750, "x": 2570, "u": "https://preview.redd.it/qtbk8r7g9bhb1.png?width=2570&amp;format=png&amp;auto=webp&amp;s=f7e1e0bdade907da18b3a47b7b286d20d762b05d"}, "id": "qtbk8r7g9bhb1"}}, "name": "t3_15nhq56", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LCnLCMzf6omKKoHE5RRnPL1Oear0z01ReaQUHIQpZoU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691686295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Overview&lt;/h1&gt;\n\n&lt;p&gt;With the Premier League season starting tomorrow, I wanted to showcase some updates I&amp;#39;ve made to this project I&amp;#39;ve been working and have posted about in the past:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;1st &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/10jjsfp/another_data_project_this_time_with_python_go/\"&gt;post&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;2nd &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/13eqbfy/introducing_firestore_into_my_premier_league/\"&gt;post&lt;/a&gt;.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Instead of using Streamlit Cloud, I am now hosting the app with Cloud Run as a Service. (a Docker container): &lt;a href=\"https://streamlit.digitalghost.dev\"&gt;https://streamlit.digitalghost.dev&lt;/a&gt; - proxied through CloudFlare \ud83d\ude09. This was done so that I can further play and practice with GitHub Actions and Streamlit and because Streamlit is &lt;a href=\"https://discuss.streamlit.io/t/link-to-ip-allowlist-documentation-is-broken/40648/7\"&gt;removing IP whitelisting for external database connections&lt;/a&gt; so this was a necessary change to get ahead of the curb.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also moved the project&amp;#39;s documentation to GitBook: &lt;a href=\"https://docs.digitalghost.dev\"&gt;https://docs.digitalghost.dev&lt;/a&gt; - a bit nicer than Notion.&lt;/p&gt;\n\n&lt;h1&gt;Links&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Dashboard: &lt;a href=\"https://streamlit.digitalghost.dev\"&gt;https://streamlit.digitalghost.dev&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Docs: &lt;a href=\"https://docs.digitalghost.dev\"&gt;https://docs.digitalghost.dev&lt;/a&gt; (Work in Progress)&lt;/li&gt;\n&lt;li&gt;GitHub: &lt;a href=\"https://github.com/digitalghost-dev/premier-league\"&gt;https://github.com/digitalghost-dev/premier-league&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;DockerHub: &lt;a href=\"https://hub.docker.com/r/digitalghostdev/premier-league/tags\"&gt;https://hub.docker.com/r/digitalghostdev/premier-league/tags&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Flowchart&lt;/h1&gt;\n\n&lt;p&gt;I&amp;#39;ve changed quite a lot now to make a bit less complex and introduce some new technologies that I&amp;#39;ve been wanting to play with, mainly Prefect, Terraform, PostgreSQL.&lt;/p&gt;\n\n&lt;p&gt;Here is an updated flowchart:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/5mp1zk433bhb1.png?width=2574&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a3cd6e49b18390804c02f43386c99c9c176dabd9\"&gt;Pipeline Flowchart created with eraser.io&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Of course none of these changes were necessary but like stated before, I wanted to use new technologies. I subbed out BigQuery with PostgreSQL running on &lt;a href=\"https://cloud.google.com/sql\"&gt;Cloud SQL&lt;/a&gt;. I could hold JSON data in PostgreSQL but wanted to keep Firestore. I now have Prefect running on a Virtual Machine (VM) that is the orchestration tool to schedule and execute the ETL scripts. The VM is created with Terraform and installs everything for me with a &lt;code&gt;.sh&lt;/code&gt; file.&lt;/p&gt;\n\n&lt;h1&gt;CI/CD Pipeline&lt;/h1&gt;\n\n&lt;p&gt;The CI/CD pipeline has changed to focus 100% on the Streamlit app:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qtbk8r7g9bhb1.png?width=2570&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f7e1e0bdade907da18b3a47b7b286d20d762b05d\"&gt;Example from Testing the Pipeline&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;After the Docker image is built, it&amp;#39;s pushed to Artifact Registry and deployed to Cloud Run.&lt;/p&gt;\n\n&lt;p&gt;There is another step that builds the image for different architectures: &lt;code&gt;linux/amd64&lt;/code&gt; and &lt;code&gt;linux/arm64&lt;/code&gt; and pushes them to my &lt;a href=\"https://hub.docker.com/r/digitalghostdev/premier-league/tags\"&gt;DockerHub&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Security&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have included &lt;a href=\"https://snyk.io\"&gt;Snyk&lt;/a&gt; to scan the dependencies in the repositories and under the security tab in the Github Repo, I can see all vulnerabilities.&lt;/p&gt;\n\n&lt;p&gt;After the image is built, an SBOM is created using &lt;a href=\"https://github.com/anchore/syft\"&gt;Syft&lt;/a&gt; then that SBOM is scanned with &lt;a href=\"https://github.com/anchore/grype\"&gt;Grype&lt;/a&gt; and just like Snyk, the security tab is filled with the vulnerabilities as a &lt;code&gt;SARIF&lt;/code&gt; report.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/sfi70wunabhb1.png?width=2554&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5974f8402f678c4571d968ae75f16fceade8dae0\"&gt;Vulnerabilities in Repo&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Closing Notes&lt;/h1&gt;\n\n&lt;p&gt;The cool thing I have come to realized about building this is that I was able to implement Prefect at work with a decent amount of confidence to fix our automation needs.&lt;/p&gt;\n\n&lt;p&gt;Looking ahead, I think I am at a good place where I won&amp;#39;t be changing the ETL architecture anymore and just focus on adding more content to the Streamlit app itself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "15nhq56", "is_robot_indexable": true, "report_reasons": null, "author": "digitalghost-dev", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nhq56/premier_league_data_pipeline_project_update/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nhq56/premier_league_data_pipeline_project_update/", "subreddit_subscribers": 122093, "created_utc": 1691686295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nI recently joined an e-commerce company as a Senior Data Analyst. My work involves heavy usage of SQL and digital analytics (GA4, GTM, A/B testing). \n\nI\u2019ve been in the analytics space for the last 4 years and have been closely involved with growth marketing. At my previous company, a Fintech startup (pre series A), I ended up as the team lead (small team of 4) where we built a simple modern data stack (Fivetran, BigQuery, dbt &amp; Looker) from scratch. We delivered quite a few data products for descriptive &amp; diagnostic analytics but couldn\u2019t get to the stage of predictive analytics/ML. I wasn\u2019t very hands-on on the ELT procedure but the experience did give me a good understanding of the analytics lifecycle.\n\nNow, I feel I\u2019m at a crossroads in my career. I\u2019m doing well at my current company but I want to upskill to stay relevant and further grow my career. I\u2019m evaluating these 3 paths: \n\n1. Analytics Engineering\nStrength: My experience in DA. I understand business quite well. Have played the role of a bridge between business and technical teams. \n\nWeakness: Not sure if AE is just a fad or does it have high potential. Also, I\u2019m not good at software engineering practices. (Though I\u2019m willing to learn) \n\n2. Data Engineering \nStrength: I think DE will become more important with time since Gen AI can replace analysts to a certain extent but can\u2019t build the infrastructure (atleast not as of now). I understand quite a few theoretical concepts around DE.\n\nWeakness: No hands on experience of DE. I assume a steep learning curve. Not good at software engineering. \n\n3. Data Scientist (focused on LLMs) \nStrength: I clearly see the potential of getting skilled at dealing with LLMs. Have some understanding of ML algorithms. Have business exposure.\n\nWeakness: No hands on experience with LLMs. Have worked with ML but haven\u2019t ever deployed a model in a business setting. \n\n\nPersonally, I think AE might be a natural progression for me but I\u2019m open to hear thoughts from this community. I\u2019d appreciate even if you\u2019ve any other suggestions apart from the choices mentioned. \n\nP.s. this is my first post here and didn\u2019t expect it to be so long! \n\nThanks a ton!", "author_fullname": "t2_6oqhtw12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career path options for DA?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nlj1x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691694965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I recently joined an e-commerce company as a Senior Data Analyst. My work involves heavy usage of SQL and digital analytics (GA4, GTM, A/B testing). &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been in the analytics space for the last 4 years and have been closely involved with growth marketing. At my previous company, a Fintech startup (pre series A), I ended up as the team lead (small team of 4) where we built a simple modern data stack (Fivetran, BigQuery, dbt &amp;amp; Looker) from scratch. We delivered quite a few data products for descriptive &amp;amp; diagnostic analytics but couldn\u2019t get to the stage of predictive analytics/ML. I wasn\u2019t very hands-on on the ELT procedure but the experience did give me a good understanding of the analytics lifecycle.&lt;/p&gt;\n\n&lt;p&gt;Now, I feel I\u2019m at a crossroads in my career. I\u2019m doing well at my current company but I want to upskill to stay relevant and further grow my career. I\u2019m evaluating these 3 paths: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Analytics Engineering\nStrength: My experience in DA. I understand business quite well. Have played the role of a bridge between business and technical teams. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Weakness: Not sure if AE is just a fad or does it have high potential. Also, I\u2019m not good at software engineering practices. (Though I\u2019m willing to learn) &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Engineering \nStrength: I think DE will become more important with time since Gen AI can replace analysts to a certain extent but can\u2019t build the infrastructure (atleast not as of now). I understand quite a few theoretical concepts around DE.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Weakness: No hands on experience of DE. I assume a steep learning curve. Not good at software engineering. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Scientist (focused on LLMs) \nStrength: I clearly see the potential of getting skilled at dealing with LLMs. Have some understanding of ML algorithms. Have business exposure.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Weakness: No hands on experience with LLMs. Have worked with ML but haven\u2019t ever deployed a model in a business setting. &lt;/p&gt;\n\n&lt;p&gt;Personally, I think AE might be a natural progression for me but I\u2019m open to hear thoughts from this community. I\u2019d appreciate even if you\u2019ve any other suggestions apart from the choices mentioned. &lt;/p&gt;\n\n&lt;p&gt;P.s. this is my first post here and didn\u2019t expect it to be so long! &lt;/p&gt;\n\n&lt;p&gt;Thanks a ton!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15nlj1x", "is_robot_indexable": true, "report_reasons": null, "author": "CowCultural9007", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nlj1x/career_path_options_for_da/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nlj1x/career_path_options_for_da/", "subreddit_subscribers": 122093, "created_utc": 1691694965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was disappointed (but not shocked) by dbt's new release coupling their new semantic layer to their cloud product. Every \"semantic layer\" or \"metrics layer\" that I'm aware of couples metrics definition to a specific product or service that requires its own server. This is unsurprising from a vendor perspective, but I think it leaves a basic gap in open-source functionality: a metrics layer could exist entirely as config files that generate SQL views (materialized or not) with different grouping sets. I think this could handle joins as well, but as a basic MVP I think just different grouping sets would cover a variety of simple use cases.\n\nIs there a dbt package that already exists that does this kind of thing? (One config file -&gt; multiple SQL views with different groupings) ", "author_fullname": "t2_3rnvqshi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simple, decoupled config -&gt; SQL metrics layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15na07t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691667429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was disappointed (but not shocked) by dbt&amp;#39;s new release coupling their new semantic layer to their cloud product. Every &amp;quot;semantic layer&amp;quot; or &amp;quot;metrics layer&amp;quot; that I&amp;#39;m aware of couples metrics definition to a specific product or service that requires its own server. This is unsurprising from a vendor perspective, but I think it leaves a basic gap in open-source functionality: a metrics layer could exist entirely as config files that generate SQL views (materialized or not) with different grouping sets. I think this could handle joins as well, but as a basic MVP I think just different grouping sets would cover a variety of simple use cases.&lt;/p&gt;\n\n&lt;p&gt;Is there a dbt package that already exists that does this kind of thing? (One config file -&amp;gt; multiple SQL views with different groupings) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15na07t", "is_robot_indexable": true, "report_reasons": null, "author": "PaginatedSalmon", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15na07t/simple_decoupled_config_sql_metrics_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15na07t/simple_decoupled_config_sql_metrics_layer/", "subreddit_subscribers": 122093, "created_utc": 1691667429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello friends, for my thesis I need to do research on what the most common factors are the cause a datawarehouse project to fail. Is there anybody who knows of good sources I could use for my research. Thank you", "author_fullname": "t2_8mte9pyz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datawarehouse thesis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nms1s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691697813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello friends, for my thesis I need to do research on what the most common factors are the cause a datawarehouse project to fail. Is there anybody who knows of good sources I could use for my research. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15nms1s", "is_robot_indexable": true, "report_reasons": null, "author": "SnowEcstatic", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nms1s/datawarehouse_thesis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nms1s/datawarehouse_thesis/", "subreddit_subscribers": 122093, "created_utc": 1691697813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TL;DR - Are certifications the best move for me right now? What's my next job title on the path to Data Engineer?\n\n\\---\n\n2019 - Graduated with humanities degree from top university. Interned at Medical Nonprofit as a translator, general admin guy, and writer.\n\n2020 - Hired as a Research Coordinator and Data Analyst for its research team under a different job title. Worked with R for data viz and basic analysis, basic SQL to retrieve data.\n\n2021 - Became a full time student online to take math courses, as I thought I wanted to pursue a PhD in Biostatistics. Went up through Real Analysis, A's. I continued doing the data analysis work for the research projects but for free. Second author on one publication with another pending.\n\n2022-early 2023 - Eventually decided I was more interested in engineering over analysis and statistics. Looked into Data Engineering and did a 6 month bootcamp in the Fall (Bash, Python, SQL, basic GCP, DBT, Airflow). Built ETL projects and a portfolio website. Through the connections of the Bootcamp founder, I interned for about month at a small cloud consulting outfit using AWS, then got a contract using scraping and ChatGPT for an individual client.\n\nCurrent - Landed a one year \"Data Engineering Fellowship\" at a non-profit tech consultancy, consulting for other non-profits and government agencies. Pay is pretty good for LCOL area ($70k). But in my first 2 months here I've been doing a lot of non-technical tasks which have eaten into my technical skill-building time. My most technical projects currently are to deploy an API-driven workflow in the cloud and to design and implement a new data model for a client in Snowflake.  Both of these are in very early stages.\n\nMay 2024 - Fellowship ends with possibility of extension or being hired.\n\n\\---\n\n1.) What should I be doing to maximize my chances of getting a job when this program ends?\n\n* I feel like I need more foundational CS knowledge and to obtain a formal degree. So I am taking an EDx course in Java OOP from GT to prepare for their OMSCS. OTOH,  I could obtain some kind of certification(s) (e.g. AWS/Azure, Snowflake/Databricks) and build projects leveraging those technologies. This could pay off more quickly for me career-wise, and so I'm wondering if I should delay the MS preparation. I believe have till 2025 before my math credits start to become outdated for the application.\n\n2.) What sorts of job titles should I be targeting? At what kinds of companies? I realize now that Data Engineer is not an entry-level position, so while I would love to become one, I don't know if that's realistic for my first job come June of next year.", "author_fullname": "t2_qn652con", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unusual early-career trajectory with some experience - seeking advice on how to land first \"real\" job on path to DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nbs07", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691672154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR - Are certifications the best move for me right now? What&amp;#39;s my next job title on the path to Data Engineer?&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;2019 - Graduated with humanities degree from top university. Interned at Medical Nonprofit as a translator, general admin guy, and writer.&lt;/p&gt;\n\n&lt;p&gt;2020 - Hired as a Research Coordinator and Data Analyst for its research team under a different job title. Worked with R for data viz and basic analysis, basic SQL to retrieve data.&lt;/p&gt;\n\n&lt;p&gt;2021 - Became a full time student online to take math courses, as I thought I wanted to pursue a PhD in Biostatistics. Went up through Real Analysis, A&amp;#39;s. I continued doing the data analysis work for the research projects but for free. Second author on one publication with another pending.&lt;/p&gt;\n\n&lt;p&gt;2022-early 2023 - Eventually decided I was more interested in engineering over analysis and statistics. Looked into Data Engineering and did a 6 month bootcamp in the Fall (Bash, Python, SQL, basic GCP, DBT, Airflow). Built ETL projects and a portfolio website. Through the connections of the Bootcamp founder, I interned for about month at a small cloud consulting outfit using AWS, then got a contract using scraping and ChatGPT for an individual client.&lt;/p&gt;\n\n&lt;p&gt;Current - Landed a one year &amp;quot;Data Engineering Fellowship&amp;quot; at a non-profit tech consultancy, consulting for other non-profits and government agencies. Pay is pretty good for LCOL area ($70k). But in my first 2 months here I&amp;#39;ve been doing a lot of non-technical tasks which have eaten into my technical skill-building time. My most technical projects currently are to deploy an API-driven workflow in the cloud and to design and implement a new data model for a client in Snowflake.  Both of these are in very early stages.&lt;/p&gt;\n\n&lt;p&gt;May 2024 - Fellowship ends with possibility of extension or being hired.&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;1.) What should I be doing to maximize my chances of getting a job when this program ends?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I feel like I need more foundational CS knowledge and to obtain a formal degree. So I am taking an EDx course in Java OOP from GT to prepare for their OMSCS. OTOH,  I could obtain some kind of certification(s) (e.g. AWS/Azure, Snowflake/Databricks) and build projects leveraging those technologies. This could pay off more quickly for me career-wise, and so I&amp;#39;m wondering if I should delay the MS preparation. I believe have till 2025 before my math credits start to become outdated for the application.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;2.) What sorts of job titles should I be targeting? At what kinds of companies? I realize now that Data Engineer is not an entry-level position, so while I would love to become one, I don&amp;#39;t know if that&amp;#39;s realistic for my first job come June of next year.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15nbs07", "is_robot_indexable": true, "report_reasons": null, "author": "aksandros", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nbs07/unusual_earlycareer_trajectory_with_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nbs07/unusual_earlycareer_trajectory_with_some/", "subreddit_subscribers": 122093, "created_utc": 1691672154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have experience working in environments where most, if not all, of the operational reports are generated directly from the data warehouse. \n\nDo you opt for designing a star schema and/or a Big Table that caters to both functions? Alternatively, do you lean towards having users generate operational reports from the staging layer (essentially a copy of the operational databases) and then transforming the data to best fit analytical needs?\n\nI'm curious to learn about your approach or your team's approach to this!", "author_fullname": "t2_tov4xq2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Operational Reporting and Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nbd3g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691671060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have experience working in environments where most, if not all, of the operational reports are generated directly from the data warehouse. &lt;/p&gt;\n\n&lt;p&gt;Do you opt for designing a star schema and/or a Big Table that caters to both functions? Alternatively, do you lean towards having users generate operational reports from the staging layer (essentially a copy of the operational databases) and then transforming the data to best fit analytical needs?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to learn about your approach or your team&amp;#39;s approach to this!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15nbd3g", "is_robot_indexable": true, "report_reasons": null, "author": "nanksk", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nbd3g/operational_reporting_and_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nbd3g/operational_reporting_and_analytics/", "subreddit_subscribers": 122093, "created_utc": 1691671060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been trying to research what the best way to do this is, but I have a bunch of CSVs I need to convert to parquet in S3.  \n\n\nIs the best way to create multiple dataframes of equal number of CSV files and then parallel write those dataframes to S3\n\nor\n\nRead one dataframe containing all files and then repartition the df by the partition column and number of executors to shuffle them into an ordered fashion and then have the shuffle write minimize data movement?", "author_fullname": "t2_7jt0qboi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark: How to Handle Parallel Writes to Parquet?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nw73k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691721030.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been trying to research what the best way to do this is, but I have a bunch of CSVs I need to convert to parquet in S3.  &lt;/p&gt;\n\n&lt;p&gt;Is the best way to create multiple dataframes of equal number of CSV files and then parallel write those dataframes to S3&lt;/p&gt;\n\n&lt;p&gt;or&lt;/p&gt;\n\n&lt;p&gt;Read one dataframe containing all files and then repartition the df by the partition column and number of executors to shuffle them into an ordered fashion and then have the shuffle write minimize data movement?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15nw73k", "is_robot_indexable": true, "report_reasons": null, "author": "omscsdatathrow", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nw73k/spark_how_to_handle_parallel_writes_to_parquet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nw73k/spark_how_to_handle_parallel_writes_to_parquet/", "subreddit_subscribers": 122093, "created_utc": 1691721030.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm a junior data engineer and at my work I have to create an on premise Kubernetes cluster to support spark applications on a small project that we have. This project is already running with Hadoop stack, but we have to upgrade it and my boss didn't want to use Hadoop anymore, so it was up to me to bring alternatives and after some research I saw k8s as a good alternative. The problem is neither me nor my boss have experience with k8s, and he does not have that much time to help me  technically, searching thing and so on, so I'm alone on this.  \n\n\nI've created a local Minikube cluster on my laptop, and installed Ceph via Rook to manage a shared file system, used Mysql as an external metastore to both my spark application and spark thrift server (to expose data to other people), and Lens to view and manage the cluster. It worked locally, but now I'm afraid to \"scale\" it up to a production environment, because there are a lot more things to considered, like fault tolerance, security, and so on, so I'm kinda lost on how to tackle this and would appreciate some tips or tricks or any kind of help honestly.  \n\n\n* My production environment have 4 machines, that I would use as nodes;\n* It has to be on premise, it's a business obligation on this project;", "author_fullname": "t2_6iu8m5m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On Prem Kubernetes Cluster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15na4gd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691667757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m a junior data engineer and at my work I have to create an on premise Kubernetes cluster to support spark applications on a small project that we have. This project is already running with Hadoop stack, but we have to upgrade it and my boss didn&amp;#39;t want to use Hadoop anymore, so it was up to me to bring alternatives and after some research I saw k8s as a good alternative. The problem is neither me nor my boss have experience with k8s, and he does not have that much time to help me  technically, searching thing and so on, so I&amp;#39;m alone on this.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve created a local Minikube cluster on my laptop, and installed Ceph via Rook to manage a shared file system, used Mysql as an external metastore to both my spark application and spark thrift server (to expose data to other people), and Lens to view and manage the cluster. It worked locally, but now I&amp;#39;m afraid to &amp;quot;scale&amp;quot; it up to a production environment, because there are a lot more things to considered, like fault tolerance, security, and so on, so I&amp;#39;m kinda lost on how to tackle this and would appreciate some tips or tricks or any kind of help honestly.  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;My production environment have 4 machines, that I would use as nodes;&lt;/li&gt;\n&lt;li&gt;It has to be on premise, it&amp;#39;s a business obligation on this project;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15na4gd", "is_robot_indexable": true, "report_reasons": null, "author": "gss-", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15na4gd/on_prem_kubernetes_cluster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15na4gd/on_prem_kubernetes_cluster/", "subreddit_subscribers": 122093, "created_utc": 1691667757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Struggling to get any interviews for junior or entry DE jobs. \n\nI\u2019m thinking I should instead focus on another path in either SWE or DA.\n\nHowever, I\u2019m burning myself out trying to learn everything rather than focusing in on one specific discipline - and a feeling a bit lost on my journey.\n\nI\u2019m also unsure what my LinkedIn should say/look like if I\u2019m applying for all 3 of these roles.\n\nAny advice on what I should be focused on, or what skills I should be learning?\n\nIm proficient in Python &amp; SQL, with some experience through personal projects with Airflow, IaC, AWS, Data Warehousing, among other things.", "author_fullname": "t2_7xk4etxe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I be looking at SWE or Data Analyst roles instead - and what skills to focus on for these?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o0pt9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691734648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Struggling to get any interviews for junior or entry DE jobs. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m thinking I should instead focus on another path in either SWE or DA.&lt;/p&gt;\n\n&lt;p&gt;However, I\u2019m burning myself out trying to learn everything rather than focusing in on one specific discipline - and a feeling a bit lost on my journey.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m also unsure what my LinkedIn should say/look like if I\u2019m applying for all 3 of these roles.&lt;/p&gt;\n\n&lt;p&gt;Any advice on what I should be focused on, or what skills I should be learning?&lt;/p&gt;\n\n&lt;p&gt;Im proficient in Python &amp;amp; SQL, with some experience through personal projects with Airflow, IaC, AWS, Data Warehousing, among other things.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15o0pt9", "is_robot_indexable": true, "report_reasons": null, "author": "Weekly_Dimension_332", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o0pt9/should_i_be_looking_at_swe_or_data_analyst_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o0pt9/should_i_be_looking_at_swe_or_data_analyst_roles/", "subreddit_subscribers": 122093, "created_utc": 1691734648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "DATA TEAM OFFICE - FRIDAY AFTRENOON\n\nThe DATA ENGINEER is sitting at a computer, face buried in his hands. The POSTGRESQL QUERY PLANNER, portrayed as a disheveled character wearing a tie on his head and holding a bottle labeled \"Inefficient Index IPA\" stumbles around the office.\n\nDATA ENGINEER: (frustrated) Come on, Postgres, get it together! We've got to make this query to run fast enough before the deadline.\n\nPOSTGRESQL: (slurring) Optimize? Sure, I know how to do that!\n\n\\*POSTGRESQL grabs a new bottle from desk draw and starts going though file cabinet\\*\n\nDATA ENGINEER: Oh, no no no, that's a full table scan! Why!?!? The index is right there! Look!\n\n\\*DATA ENGINEER points to the screen with fear and desperation in his eyes.\\*\n\nPOSTGRESQL: Index? Ha? Where? This \"Full Table Tequila\" is so good, want some?\n\nDATA ENGINEER: (pleadingly) Please, Query Planner, we need you sober for this. The team is counting on us.\n\nPOSTGRESQL: (giggling) Sober? Where's the fun in that? How 'bout we make our selves a Nested Loop Negroni! Those are amazing!\n\nDATA ENGINEER: Please don't do nested loop, please. Just use hash join. Remember the good times we had with hash joins?\n\nPOSTGRESQL: (stumbling) Hash? Nah, I'm not smoking while I'm drinking.\n\nDATA ENGINEER: (gritting teeth) You're slow and inefficient! I'm going to replace you with DuckDB!\n\nPOSTGRESQL: (tearfully) Why you gotta be so mean? I'm just trying to find the best query execution path, in my own way.\n\nDATA ENGINEER: And I'm trying to help you, but you're making it impossible! Why can't you see that the indices are right there?\n\nPOSTGRESQL: (dramatically) Because I'm blind to the conventional ways, my friend. I walk the path less traveled. I like the scenic route!\n\nDATA ENGINEER: (shaking head) I'll be here all night.\n\nDATA ENGINEER slumps back in his chair, as POSTGRESQL stumbles towards the window, singing an off-key version of \"Row, Row, Row Your Boat.\" holding \"Cursed Cartesian Vodka\" bottle in their hand.\n\nFADE TO BLACK", "author_fullname": "t2_cmjwin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing Postgres - Scene from fictional sitcom \"Data Dilemmas\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o06a0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691732873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DATA TEAM OFFICE - FRIDAY AFTRENOON&lt;/p&gt;\n\n&lt;p&gt;The DATA ENGINEER is sitting at a computer, face buried in his hands. The POSTGRESQL QUERY PLANNER, portrayed as a disheveled character wearing a tie on his head and holding a bottle labeled &amp;quot;Inefficient Index IPA&amp;quot; stumbles around the office.&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: (frustrated) Come on, Postgres, get it together! We&amp;#39;ve got to make this query to run fast enough before the deadline.&lt;/p&gt;\n\n&lt;p&gt;POSTGRESQL: (slurring) Optimize? Sure, I know how to do that!&lt;/p&gt;\n\n&lt;p&gt;*POSTGRESQL grabs a new bottle from desk draw and starts going though file cabinet*&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: Oh, no no no, that&amp;#39;s a full table scan! Why!?!? The index is right there! Look!&lt;/p&gt;\n\n&lt;p&gt;*DATA ENGINEER points to the screen with fear and desperation in his eyes.*&lt;/p&gt;\n\n&lt;p&gt;POSTGRESQL: Index? Ha? Where? This &amp;quot;Full Table Tequila&amp;quot; is so good, want some?&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: (pleadingly) Please, Query Planner, we need you sober for this. The team is counting on us.&lt;/p&gt;\n\n&lt;p&gt;POSTGRESQL: (giggling) Sober? Where&amp;#39;s the fun in that? How &amp;#39;bout we make our selves a Nested Loop Negroni! Those are amazing!&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: Please don&amp;#39;t do nested loop, please. Just use hash join. Remember the good times we had with hash joins?&lt;/p&gt;\n\n&lt;p&gt;POSTGRESQL: (stumbling) Hash? Nah, I&amp;#39;m not smoking while I&amp;#39;m drinking.&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: (gritting teeth) You&amp;#39;re slow and inefficient! I&amp;#39;m going to replace you with DuckDB!&lt;/p&gt;\n\n&lt;p&gt;POSTGRESQL: (tearfully) Why you gotta be so mean? I&amp;#39;m just trying to find the best query execution path, in my own way.&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: And I&amp;#39;m trying to help you, but you&amp;#39;re making it impossible! Why can&amp;#39;t you see that the indices are right there?&lt;/p&gt;\n\n&lt;p&gt;POSTGRESQL: (dramatically) Because I&amp;#39;m blind to the conventional ways, my friend. I walk the path less traveled. I like the scenic route!&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER: (shaking head) I&amp;#39;ll be here all night.&lt;/p&gt;\n\n&lt;p&gt;DATA ENGINEER slumps back in his chair, as POSTGRESQL stumbles towards the window, singing an off-key version of &amp;quot;Row, Row, Row Your Boat.&amp;quot; holding &amp;quot;Cursed Cartesian Vodka&amp;quot; bottle in their hand.&lt;/p&gt;\n\n&lt;p&gt;FADE TO BLACK&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "15o06a0", "is_robot_indexable": true, "report_reasons": null, "author": "tiltaltti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o06a0/optimizing_postgres_scene_from_fictional_sitcom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o06a0/optimizing_postgres_scene_from_fictional_sitcom/", "subreddit_subscribers": 122093, "created_utc": 1691732873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nI am a data engineer with 6-7 YoE from Italy. During my career I have both developed custom data platforms (there were almost no data  platform   SaaS back then), and worked on the data modelling/analytics  part   (developed ETL pipelines, generated analytics reports, supported  data   scientists to implement ML models etc.)\n\nThis year has been quite bad for everyone who was considering to find a new job, and I am no exception.\n\nCompanies seem to only look for senior profiles, which I think I am, but they only consider - or actively search -  people  from renowned companies instead of evaluating skills/experience, and I have only worked - and currently  work -   in less known ones.\n\nSince   the  Italian market is quite a barren land, I have also tried to  find open positions in other European countries, such as Spain or  Germany, but  till date nobody has contacted me back, probably because  they   prefer a candidate that doesn't have to relocate.\n\nIn  case you have recently found a new job as a DE, could you please share  how did you do it, or any useful tips to make my profile more appealing?\n\nThank you!", "author_fullname": "t2_do2bj7xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for career advices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nzg7z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691734540.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691730541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I am a data engineer with 6-7 YoE from Italy. During my career I have both developed custom data platforms (there were almost no data  platform   SaaS back then), and worked on the data modelling/analytics  part   (developed ETL pipelines, generated analytics reports, supported  data   scientists to implement ML models etc.)&lt;/p&gt;\n\n&lt;p&gt;This year has been quite bad for everyone who was considering to find a new job, and I am no exception.&lt;/p&gt;\n\n&lt;p&gt;Companies seem to only look for senior profiles, which I think I am, but they only consider - or actively search -  people  from renowned companies instead of evaluating skills/experience, and I have only worked - and currently  work -   in less known ones.&lt;/p&gt;\n\n&lt;p&gt;Since   the  Italian market is quite a barren land, I have also tried to  find open positions in other European countries, such as Spain or  Germany, but  till date nobody has contacted me back, probably because  they   prefer a candidate that doesn&amp;#39;t have to relocate.&lt;/p&gt;\n\n&lt;p&gt;In  case you have recently found a new job as a DE, could you please share  how did you do it, or any useful tips to make my profile more appealing?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15nzg7z", "is_robot_indexable": true, "report_reasons": null, "author": "somerandomdataeng", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15nzg7z/looking_for_career_advices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nzg7z/looking_for_career_advices/", "subreddit_subscribers": 122093, "created_utc": 1691730541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi data friends \ud83d\udc4b  \n\n\nI'm Ian and I'm building AI-powered data tools at Turntable.\n\nWe just opened up public access to our new free VS Code extension for writing dbt documentation side-by-side with your dbt models. You can also use AI to auto generate model and column descriptions.  \n\n\nLearn more from our announcement here: [https://twitter.com/turntabledata/status/1689744394897756160](https://twitter.com/turntabledata/status/1689744394897756160)  \n\n\nYou can you download it here [https://www.turntable.so/](https://www.turntable.so/)", "author_fullname": "t2_esppz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free VS Code Extension for writing dbt documentation using AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nohkj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691701717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi data friends \ud83d\udc4b  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m Ian and I&amp;#39;m building AI-powered data tools at Turntable.&lt;/p&gt;\n\n&lt;p&gt;We just opened up public access to our new free VS Code extension for writing dbt documentation side-by-side with your dbt models. You can also use AI to auto generate model and column descriptions.  &lt;/p&gt;\n\n&lt;p&gt;Learn more from our announcement here: &lt;a href=\"https://twitter.com/turntabledata/status/1689744394897756160\"&gt;https://twitter.com/turntabledata/status/1689744394897756160&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;You can you download it here &lt;a href=\"https://www.turntable.so/\"&gt;https://www.turntable.so/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-71GoTv5rIrTKhv_-eCLkPRq5D460ZS2CboAHd6AeJs.jpg?auto=webp&amp;s=f8051e95ad5fc8d18792fe9a7e995a615b50264c", "width": 140, "height": 113}, "resolutions": [{"url": "https://external-preview.redd.it/-71GoTv5rIrTKhv_-eCLkPRq5D460ZS2CboAHd6AeJs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4f1d4bd261c9034d5c94eab5d4efdbf984d1cb08", "width": 108, "height": 87}], "variants": {}, "id": "nAtL11tqbwGo2Q21fH-ZRssRpHe9KrnDTFZeXwynSSw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15nohkj", "is_robot_indexable": true, "report_reasons": null, "author": "StartCompaniesNotWar", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nohkj/free_vs_code_extension_for_writing_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nohkj/free_vs_code_extension_for_writing_dbt/", "subreddit_subscribers": 122093, "created_utc": 1691701717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://dataengineeracademy.com/blog/dbt-data-build-tool-tutorial/](https://dataengineeracademy.com/blog/dbt-data-build-tool-tutorial/)", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT (Data Build Tool) Tutorial", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nmat8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691696727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://dataengineeracademy.com/blog/dbt-data-build-tool-tutorial/\"&gt;https://dataengineeracademy.com/blog/dbt-data-build-tool-tutorial/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?auto=webp&amp;s=7572d931b25c11ffd99056a38463595b524705d1", "width": 1080, "height": 558}, "resolutions": [{"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2d964d3529b465d201aa2f951bfb522ff306cc31", "width": 108, "height": 55}, {"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1ae456b40f75b50ac3a4c6e42f07648100083c8e", "width": 216, "height": 111}, {"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d891ea0c4e5fb22984c418f5eda694e7d76f7546", "width": 320, "height": 165}, {"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4d46b1c275f86156eff316f7d1ff90f4235862e", "width": 640, "height": 330}, {"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a89e7fcb176ea9b5831f92b039d6af38ace56a7b", "width": 960, "height": 496}, {"url": "https://external-preview.redd.it/i2dCwdin2j3zmn736S5wm7qK7EqUeQDF29sDHFronVw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ac16666bd26109d0b0388c48ca1b05091bf6bf5f", "width": 1080, "height": 558}], "variants": {}, "id": "mcK8PbLckSlzatuuN1mtQwTxO2kzsHIVaX_NVVZ8JO8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "CEO of DE Academy/Amazon/Lyft/Author", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15nmat8", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15nmat8/dbt_data_build_tool_tutorial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nmat8/dbt_data_build_tool_tutorial/", "subreddit_subscribers": 122093, "created_utc": 1691696727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a question that pops up more and more in my head as I'm getting more of an understanding about what data engineering entails. I know what the core of my job is supposed to be. Be it ETL pipelines, warehouses... I get all that. Hell, you can find that kind of info pretty easily online, as well as all the knowledge you ever need about the tools we use.\n\nMy question is more about the process that comes before building any pipeline. For example: what is the deliverable you require to actually set up a pipeline? Is it an example query? Is it an excel that describes each column in a source-to-target mapping kind of way?\n\nFurthermore, who's task is it to actually make this mapping? What do you do when the mapping they provide isn't sufficient? (For example the cities table doesn't contain all cities in the country but only the state/province). What about when you're doing Kimball and people have not modeled correctly?\n\nI'm curious as to the methods people in this community use. I understand this depends a lot on the project itself as well as the team, but I would like to know what would normally be considered the boundaries of our work.", "author_fullname": "t2_2pbhwnrm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does my job begin and end?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ni690", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691687310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a question that pops up more and more in my head as I&amp;#39;m getting more of an understanding about what data engineering entails. I know what the core of my job is supposed to be. Be it ETL pipelines, warehouses... I get all that. Hell, you can find that kind of info pretty easily online, as well as all the knowledge you ever need about the tools we use.&lt;/p&gt;\n\n&lt;p&gt;My question is more about the process that comes before building any pipeline. For example: what is the deliverable you require to actually set up a pipeline? Is it an example query? Is it an excel that describes each column in a source-to-target mapping kind of way?&lt;/p&gt;\n\n&lt;p&gt;Furthermore, who&amp;#39;s task is it to actually make this mapping? What do you do when the mapping they provide isn&amp;#39;t sufficient? (For example the cities table doesn&amp;#39;t contain all cities in the country but only the state/province). What about when you&amp;#39;re doing Kimball and people have not modeled correctly?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious as to the methods people in this community use. I understand this depends a lot on the project itself as well as the team, but I would like to know what would normally be considered the boundaries of our work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ni690", "is_robot_indexable": true, "report_reasons": null, "author": "AirisuB", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15ni690/where_does_my_job_begin_and_end/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ni690/where_does_my_job_begin_and_end/", "subreddit_subscribers": 122093, "created_utc": 1691687310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A project has fallen into my lap to provide some consulting work for a small company that has five daily external data sources that are either full drop and replace (full refresh) each day, or append daily. The company is currently leveraging a managed service to provide all of the ETL work in their database, but the SOW for database license/managed service is both prohibitively expensive and coming to an end at end of this year (it was tied to other projects but business has changed dramatically and has slimmed since then). The company owns all of the data, they just outsource all of the data management.\n\nThe company has asked if I can be their consultant and set up a new database and can intake and store these five daily data sources automatically (currently sent via SFTP), perform ETL, and then replicate their analytic views so that their Tableau dashboards can continue to run, but just be pointed to a new database.\n\nDoes this thread have any recommended tools for low cost database and ETL tools that are simple to implement and build? Also any suggestions for SFTP site that are easy to setup?\n\nFor context, a friend is a VP in this small company and has asked me if I could do this but I am usually the person that builds analytic views and analyzes data vs. building data engineering processes upstream.\n\nThanks in advance!", "author_fullname": "t2_7nj41", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project Advice - Low Cost and Simple Database, ETL, SFTP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ncho1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691673930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A project has fallen into my lap to provide some consulting work for a small company that has five daily external data sources that are either full drop and replace (full refresh) each day, or append daily. The company is currently leveraging a managed service to provide all of the ETL work in their database, but the SOW for database license/managed service is both prohibitively expensive and coming to an end at end of this year (it was tied to other projects but business has changed dramatically and has slimmed since then). The company owns all of the data, they just outsource all of the data management.&lt;/p&gt;\n\n&lt;p&gt;The company has asked if I can be their consultant and set up a new database and can intake and store these five daily data sources automatically (currently sent via SFTP), perform ETL, and then replicate their analytic views so that their Tableau dashboards can continue to run, but just be pointed to a new database.&lt;/p&gt;\n\n&lt;p&gt;Does this thread have any recommended tools for low cost database and ETL tools that are simple to implement and build? Also any suggestions for SFTP site that are easy to setup?&lt;/p&gt;\n\n&lt;p&gt;For context, a friend is a VP in this small company and has asked me if I could do this but I am usually the person that builds analytic views and analyzes data vs. building data engineering processes upstream.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ncho1", "is_robot_indexable": true, "report_reasons": null, "author": "jroddaman", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ncho1/project_advice_low_cost_and_simple_database_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ncho1/project_advice_low_cost_and_simple_database_etl/", "subreddit_subscribers": 122093, "created_utc": 1691673930.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My org has hundreds of large batch processing data scripts that run mostly independently on bare metal to pull data from various sources and I\u2019m wondering if there\u2019s any self hosted workflow orchestration where we could easily have those scripts moved over to. \n\nThe current system uses modded Jenkins *gasp* to orchestrate these jobs, which is actually quite nice for what we need (especially the orchestrating of builds across nodes). Aside from a few jobs, dependency management is actually not super important for these specific jobs, mainly looking for something that can run arbitrary code/programs on a schedule, simple alerting/logging and be able to run them across different machines based on load.\n\nPerhaps it might be that a new system isn\u2019t needed, but it\u2019s been a number of years since this was set up and just curious about what alternatives today could offer. Having job configs source controlled would be a nice to have.\n\nI use prefect for my personal data warehouse, but, based on my experience, have concerns it would be too slow for our needs as it definitely adds compute overhead and many of these jobs are highly optimized for memory/performance/cost.", "author_fullname": "t2_4v53a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-hosted workflow orchestration suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15napvt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691669349.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My org has hundreds of large batch processing data scripts that run mostly independently on bare metal to pull data from various sources and I\u2019m wondering if there\u2019s any self hosted workflow orchestration where we could easily have those scripts moved over to. &lt;/p&gt;\n\n&lt;p&gt;The current system uses modded Jenkins &lt;em&gt;gasp&lt;/em&gt; to orchestrate these jobs, which is actually quite nice for what we need (especially the orchestrating of builds across nodes). Aside from a few jobs, dependency management is actually not super important for these specific jobs, mainly looking for something that can run arbitrary code/programs on a schedule, simple alerting/logging and be able to run them across different machines based on load.&lt;/p&gt;\n\n&lt;p&gt;Perhaps it might be that a new system isn\u2019t needed, but it\u2019s been a number of years since this was set up and just curious about what alternatives today could offer. Having job configs source controlled would be a nice to have.&lt;/p&gt;\n\n&lt;p&gt;I use prefect for my personal data warehouse, but, based on my experience, have concerns it would be too slow for our needs as it definitely adds compute overhead and many of these jobs are highly optimized for memory/performance/cost.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15napvt", "is_robot_indexable": true, "report_reasons": null, "author": "HobbeScotch", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15napvt/selfhosted_workflow_orchestration_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15napvt/selfhosted_workflow_orchestration_suggestions/", "subreddit_subscribers": 122093, "created_utc": 1691669349.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello All,\n\nI want the perspectives of experienced data engineers on this matter.  I've started my first data engineer role at the end of May and its been wonderful.  Two days ago we were notified that the company has been acquired and how this is an exciting time for us.  They eventually mentioned that within 45 days there will be layoffs.    They mentioned exit packages will be available due to tenure and I'm barely at the 3 months mark.  I've started looking for other roles but I wanted to know if it was likely that I'll be cut and what does a typical exit package look like for such a short time with the company.  I'm one of two data engineers on a small team working on a specific project. We are the only data engineers  that use Microsoft Azure.  Most of our data engineers work with AWS. \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_6ard8gzq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Data Engineer Now Job Acquisition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15na7fw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691667986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,&lt;/p&gt;\n\n&lt;p&gt;I want the perspectives of experienced data engineers on this matter.  I&amp;#39;ve started my first data engineer role at the end of May and its been wonderful.  Two days ago we were notified that the company has been acquired and how this is an exciting time for us.  They eventually mentioned that within 45 days there will be layoffs.    They mentioned exit packages will be available due to tenure and I&amp;#39;m barely at the 3 months mark.  I&amp;#39;ve started looking for other roles but I wanted to know if it was likely that I&amp;#39;ll be cut and what does a typical exit package look like for such a short time with the company.  I&amp;#39;m one of two data engineers on a small team working on a specific project. We are the only data engineers  that use Microsoft Azure.  Most of our data engineers work with AWS. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15na7fw", "is_robot_indexable": true, "report_reasons": null, "author": "py_vel26", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15na7fw/new_data_engineer_now_job_acquisition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15na7fw/new_data_engineer_now_job_acquisition/", "subreddit_subscribers": 122093, "created_utc": 1691667986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello,\n\nI currently hold a position as a data scientist, and a few weeks ago, I expressed my interest to my manager in transitioning to a role as a data engineer. Last week, they informed me about an available data engineer position. After attending the interview, I'm having some doubts about whether it truly aligns with the responsibilities of a data engineer.\n\nThis data engineer (DE) role seems to deviate from the usual tools and technologies I'm familiar with, such as Python, SQL, Airflow, Azure, and AWS. Instead, the team relies on SnapLogic and Splunk. During my interactions with colleagues in this department, I learned that some of them have the title of \"citizen integrator.\" This has raised concerns that the role I'm being offered might be more aligned with that of a citizen integrator rather than a traditional data engineer.\n\nFurthermore, one of my coworkers shared their Teams calendar with me, revealing that they spend around 5 to 6 hours in meetings, leaving only limited time for actual development work, which seems to be infrequent.\n\nConsidering my relatively limited one year of experience, I'm now unsure whether I should accept this position or continue searching for opportunities that offer more hands-on experience with SQL and Python, skills that I believe are essential for my professional growth.\n\nThank you for your input and advice. :)\n\n ", "author_fullname": "t2_hajfn89cb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15n886q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691662086.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I currently hold a position as a data scientist, and a few weeks ago, I expressed my interest to my manager in transitioning to a role as a data engineer. Last week, they informed me about an available data engineer position. After attending the interview, I&amp;#39;m having some doubts about whether it truly aligns with the responsibilities of a data engineer.&lt;/p&gt;\n\n&lt;p&gt;This data engineer (DE) role seems to deviate from the usual tools and technologies I&amp;#39;m familiar with, such as Python, SQL, Airflow, Azure, and AWS. Instead, the team relies on SnapLogic and Splunk. During my interactions with colleagues in this department, I learned that some of them have the title of &amp;quot;citizen integrator.&amp;quot; This has raised concerns that the role I&amp;#39;m being offered might be more aligned with that of a citizen integrator rather than a traditional data engineer.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, one of my coworkers shared their Teams calendar with me, revealing that they spend around 5 to 6 hours in meetings, leaving only limited time for actual development work, which seems to be infrequent.&lt;/p&gt;\n\n&lt;p&gt;Considering my relatively limited one year of experience, I&amp;#39;m now unsure whether I should accept this position or continue searching for opportunities that offer more hands-on experience with SQL and Python, skills that I believe are essential for my professional growth.&lt;/p&gt;\n\n&lt;p&gt;Thank you for your input and advice. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15n886q", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway_2023_08", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15n886q/is_this_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15n886q/is_this_data_engineer/", "subreddit_subscribers": 122093, "created_utc": 1691662086.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Community,\n\nHope you are doing well.\n\nI want to improve the existing Git flow for my projects -\n\nCurrently the Git flow that we have in place, works as below -\n\n1. Create a new feature branch from **Develop** using the naming convention: **feature/issue#\\_&lt;name&gt;**.\n2. When development is complete, open a PR targeting **Develop**. Upon approval, merge using the \"Squash and Merge\" option. Delete the feature branch afterward if it's no longer needed.\n3. To introduce changes into pre-production, initiate a PR from **Develop** to **Master**. Utilize the \"Create Merge Commit\" strategy for merging (without deleting the **Develop** branch, of course).\n4. For deployment to production, create a release branch from **Master**. Tag the commit with the desired deployment version.\n5. After verifying that the deployment is successful, merge the release branch into **Master** using the regular merge strategy.\n6. Subsequently, make an additional commit on the release branch to update the version (increment the minor version and append \"dev\"). Finally, open a PR targeting **Develop**.\n\n**For HotFix -**\n\n1. Create a branch based on the most recent deployed commit, which is the merge from the last release branch.\n2. Adjust the patch version and apply your changes.\n3. Submit a PR to the **master** branch. After getting approval, tag your commit and initiate deployment.\n4. Complete the merge into **master.**\n5. Sync the version with that of the **develop** branch and raise a PR for **develop**.\n\n\\---\n\nI want to improve the below points -\n\n* 3rd point - how will you know if the new feature is ready to push to pre-production. Currently, we manually running the ETL pipeline, once all the tests are successful, we mention everything on PR ( including test cases )\n* how to align the master and develop after the release in the production / HotFix.\n\nAre there any other git flow are you following, please share your experience.", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Git flow for Data Engineering projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15o4h68", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691747549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Community,&lt;/p&gt;\n\n&lt;p&gt;Hope you are doing well.&lt;/p&gt;\n\n&lt;p&gt;I want to improve the existing Git flow for my projects -&lt;/p&gt;\n\n&lt;p&gt;Currently the Git flow that we have in place, works as below -&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create a new feature branch from &lt;strong&gt;Develop&lt;/strong&gt; using the naming convention: &lt;strong&gt;feature/issue#_&amp;lt;name&amp;gt;&lt;/strong&gt;.&lt;/li&gt;\n&lt;li&gt;When development is complete, open a PR targeting &lt;strong&gt;Develop&lt;/strong&gt;. Upon approval, merge using the &amp;quot;Squash and Merge&amp;quot; option. Delete the feature branch afterward if it&amp;#39;s no longer needed.&lt;/li&gt;\n&lt;li&gt;To introduce changes into pre-production, initiate a PR from &lt;strong&gt;Develop&lt;/strong&gt; to &lt;strong&gt;Master&lt;/strong&gt;. Utilize the &amp;quot;Create Merge Commit&amp;quot; strategy for merging (without deleting the &lt;strong&gt;Develop&lt;/strong&gt; branch, of course).&lt;/li&gt;\n&lt;li&gt;For deployment to production, create a release branch from &lt;strong&gt;Master&lt;/strong&gt;. Tag the commit with the desired deployment version.&lt;/li&gt;\n&lt;li&gt;After verifying that the deployment is successful, merge the release branch into &lt;strong&gt;Master&lt;/strong&gt; using the regular merge strategy.&lt;/li&gt;\n&lt;li&gt;Subsequently, make an additional commit on the release branch to update the version (increment the minor version and append &amp;quot;dev&amp;quot;). Finally, open a PR targeting &lt;strong&gt;Develop&lt;/strong&gt;.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;For HotFix -&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create a branch based on the most recent deployed commit, which is the merge from the last release branch.&lt;/li&gt;\n&lt;li&gt;Adjust the patch version and apply your changes.&lt;/li&gt;\n&lt;li&gt;Submit a PR to the &lt;strong&gt;master&lt;/strong&gt; branch. After getting approval, tag your commit and initiate deployment.&lt;/li&gt;\n&lt;li&gt;Complete the merge into &lt;strong&gt;master.&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Sync the version with that of the &lt;strong&gt;develop&lt;/strong&gt; branch and raise a PR for &lt;strong&gt;develop&lt;/strong&gt;.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;I want to improve the below points -&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;3rd point - how will you know if the new feature is ready to push to pre-production. Currently, we manually running the ETL pipeline, once all the tests are successful, we mention everything on PR ( including test cases )&lt;/li&gt;\n&lt;li&gt;how to align the master and develop after the release in the production / HotFix.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Are there any other git flow are you following, please share your experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15o4h68", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15o4h68/git_flow_for_data_engineering_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o4h68/git_flow_for_data_engineering_projects/", "subreddit_subscribers": 122093, "created_utc": 1691747549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why You Should Create Your Next Analytical Project in Code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_15o4ajp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/j5tNHIC-69uMOwPose3rTrb1G_owvR8SeAIcE1t1W0o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691746885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/gooddata-developers/why-you-should-create-your-next-analytical-project-in-code-64318ec91c90", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gEQgbdw0z3gNDu-pHSM7gOYvAkGWKaOwQTITRsl0Lzk.jpg?auto=webp&amp;s=b98b919ec83dc717a96de1e6cb8c5553e66c978f", "width": 1200, "height": 629}, "resolutions": [{"url": "https://external-preview.redd.it/gEQgbdw0z3gNDu-pHSM7gOYvAkGWKaOwQTITRsl0Lzk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ea8e4b1d1655b1abde8cf2aa9b965d4603c42c7b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/gEQgbdw0z3gNDu-pHSM7gOYvAkGWKaOwQTITRsl0Lzk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c5209cee3183c2a592c0f7701be9cabec34941b6", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/gEQgbdw0z3gNDu-pHSM7gOYvAkGWKaOwQTITRsl0Lzk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ddf1e1ccbb1c7038829eb473ff1afa6a99fbc9ae", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/gEQgbdw0z3gNDu-pHSM7gOYvAkGWKaOwQTITRsl0Lzk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5e1ce91ee8705d770a9b918eb58aa89412bfd38", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/gEQgbdw0z3gNDu-pHSM7gOYvAkGWKaOwQTITRsl0Lzk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7b933d0c01c30b98ce78232ba6e27240e716cac9", "width": 960, "height": 503}, {"url": "https://external-preview.redd.it/gEQgbdw0z3gNDu-pHSM7gOYvAkGWKaOwQTITRsl0Lzk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6f0e9e560262f80f592e3829453ee83298ac54ee", "width": 1080, "height": 566}], "variants": {}, "id": "e580lG8sQXqhpFuM0l8UbZdfxR6g0ukH1r2rZn9wsqQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15o4ajp", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o4ajp/why_you_should_create_your_next_analytical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/gooddata-developers/why-you-should-create-your-next-analytical-project-in-code-64318ec91c90", "subreddit_subscribers": 122093, "created_utc": 1691746885.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}