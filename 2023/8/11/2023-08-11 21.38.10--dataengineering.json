{"kind": "Listing", "data": {"after": "t3_15nzyl0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Given this is by far the subreddit that has the most discussions about Databricks (good, bad,  and ugly) ...)\n\nMyself and a few other Databricks employees have reclaimed /r/Databricks which was previously private and made it public.\n\nFeel free to come join us there to ask questions and discuss all things Databricks and the lakehouse!\n\nOr stay here and compare us to Snowflake some more, we love that.", "author_fullname": "t2_2gj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "/r/Databricks has been relaunched as a public subreddit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nxf1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691724418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Given this is by far the subreddit that has the most discussions about Databricks (good, bad,  and ugly) ...)&lt;/p&gt;\n\n&lt;p&gt;Myself and a few other Databricks employees have reclaimed &lt;a href=\"/r/Databricks\"&gt;/r/Databricks&lt;/a&gt; which was previously private and made it public.&lt;/p&gt;\n\n&lt;p&gt;Feel free to come join us there to ask questions and discuss all things Databricks and the lakehouse!&lt;/p&gt;\n\n&lt;p&gt;Or stay here and compare us to Snowflake some more, we love that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15nxf1q", "is_robot_indexable": true, "report_reasons": null, "author": "kthejoker", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nxf1q/rdatabricks_has_been_relaunched_as_a_public/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nxf1q/rdatabricks_has_been_relaunched_as_a_public/", "subreddit_subscribers": 122185, "created_utc": 1691724418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I did not work extensively with dbt, but it always seemed less appealing than having a databricks based pyspark/spark sql workflow + some orchestrator and some internal python libs to make things smooth. Sure data models and lineage are alright with dbt, but they can get out of hand with analysts chiming in. Maybe my DWH/etl usecases were not big enough for them not to be managed via an a priori sketched out data model, decent PKs and FKs, good naming conventions and job structure.\n\nMaking things performant and cost effective just seem more straight forward in databricks.\n\nMaybe I just did not get the vibe. dbt cloud also kinda feels like the myriad of other scammy \"modern data tools\".\n\nCurious about other perspectives!", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is dbt popular for the transformation step?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oc8z5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691768369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I did not work extensively with dbt, but it always seemed less appealing than having a databricks based pyspark/spark sql workflow + some orchestrator and some internal python libs to make things smooth. Sure data models and lineage are alright with dbt, but they can get out of hand with analysts chiming in. Maybe my DWH/etl usecases were not big enough for them not to be managed via an a priori sketched out data model, decent PKs and FKs, good naming conventions and job structure.&lt;/p&gt;\n\n&lt;p&gt;Making things performant and cost effective just seem more straight forward in databricks.&lt;/p&gt;\n\n&lt;p&gt;Maybe I just did not get the vibe. dbt cloud also kinda feels like the myriad of other scammy &amp;quot;modern data tools&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Curious about other perspectives!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15oc8z5", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oc8z5/why_is_dbt_popular_for_the_transformation_step/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oc8z5/why_is_dbt_popular_for_the_transformation_step/", "subreddit_subscribers": 122185, "created_utc": 1691768369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7lbbuuh58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I couldn't find any detailed comparison between dataframe tools so I wrote one: this post compares Polars, DuckDB, Pandas, Modin, Ponder, Fugue, Daft, and more", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o5q7l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1691751543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kestra.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://kestra.io/blogs/2023-08-11-dataframes", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15o5q7l", "is_robot_indexable": true, "report_reasons": null, "author": "Round-Following1532", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o5q7l/i_couldnt_find_any_detailed_comparison_between/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://kestra.io/blogs/2023-08-11-dataframes", "subreddit_subscribers": 122185, "created_utc": 1691751543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Community,\n\nHope you are doing well.\n\nI want to improve the existing Git flow for my projects -\n\nCurrently the Git flow that we have in place, works as below -\n\n1. Create a new feature branch from **Develop** using the naming convention: **feature/issue#\\_&lt;name&gt;**.\n2. When development is complete, open a PR targeting **Develop**. Upon approval, merge using the \"Squash and Merge\" option. Delete the feature branch afterward if it's no longer needed.\n3. To introduce changes into pre-production, initiate a PR from **Develop** to **Master**. Utilize the \"Create Merge Commit\" strategy for merging (without deleting the **Develop** branch, of course).\n4. For deployment to production, create a release branch from **Master**. Tag the commit with the desired deployment version.\n5. After verifying that the deployment is successful, merge the release branch into **Master** using the regular merge strategy.\n6. Subsequently, make an additional commit on the release branch to update the version (increment the minor version and append \"dev\"). Finally, open a PR targeting **Develop**.\n\n**For HotFix -**\n\n1. Create a branch based on the most recent deployed commit, which is the merge from the last release branch.\n2. Adjust the patch version and apply your changes.\n3. Submit a PR to the **master** branch. After getting approval, tag your commit and initiate deployment.\n4. Complete the merge into **master.**\n5. Sync the version with that of the **develop** branch and raise a PR for **develop**.\n\n\\---\n\nI want to improve the below points -\n\n* 3rd point - how will you know if the new feature is ready to push to pre-production. Currently, we manually running the ETL pipeline, once all the tests are successful, we mention everything on PR ( including test cases )\n* how to align the master and develop after the release in the production / HotFix.\n\nAre there any other git flow are you following, please share your experience.", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Git flow for Data Engineering projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o4h68", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691747549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Community,&lt;/p&gt;\n\n&lt;p&gt;Hope you are doing well.&lt;/p&gt;\n\n&lt;p&gt;I want to improve the existing Git flow for my projects -&lt;/p&gt;\n\n&lt;p&gt;Currently the Git flow that we have in place, works as below -&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create a new feature branch from &lt;strong&gt;Develop&lt;/strong&gt; using the naming convention: &lt;strong&gt;feature/issue#_&amp;lt;name&amp;gt;&lt;/strong&gt;.&lt;/li&gt;\n&lt;li&gt;When development is complete, open a PR targeting &lt;strong&gt;Develop&lt;/strong&gt;. Upon approval, merge using the &amp;quot;Squash and Merge&amp;quot; option. Delete the feature branch afterward if it&amp;#39;s no longer needed.&lt;/li&gt;\n&lt;li&gt;To introduce changes into pre-production, initiate a PR from &lt;strong&gt;Develop&lt;/strong&gt; to &lt;strong&gt;Master&lt;/strong&gt;. Utilize the &amp;quot;Create Merge Commit&amp;quot; strategy for merging (without deleting the &lt;strong&gt;Develop&lt;/strong&gt; branch, of course).&lt;/li&gt;\n&lt;li&gt;For deployment to production, create a release branch from &lt;strong&gt;Master&lt;/strong&gt;. Tag the commit with the desired deployment version.&lt;/li&gt;\n&lt;li&gt;After verifying that the deployment is successful, merge the release branch into &lt;strong&gt;Master&lt;/strong&gt; using the regular merge strategy.&lt;/li&gt;\n&lt;li&gt;Subsequently, make an additional commit on the release branch to update the version (increment the minor version and append &amp;quot;dev&amp;quot;). Finally, open a PR targeting &lt;strong&gt;Develop&lt;/strong&gt;.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;For HotFix -&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create a branch based on the most recent deployed commit, which is the merge from the last release branch.&lt;/li&gt;\n&lt;li&gt;Adjust the patch version and apply your changes.&lt;/li&gt;\n&lt;li&gt;Submit a PR to the &lt;strong&gt;master&lt;/strong&gt; branch. After getting approval, tag your commit and initiate deployment.&lt;/li&gt;\n&lt;li&gt;Complete the merge into &lt;strong&gt;master.&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Sync the version with that of the &lt;strong&gt;develop&lt;/strong&gt; branch and raise a PR for &lt;strong&gt;develop&lt;/strong&gt;.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;I want to improve the below points -&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;3rd point - how will you know if the new feature is ready to push to pre-production. Currently, we manually running the ETL pipeline, once all the tests are successful, we mention everything on PR ( including test cases )&lt;/li&gt;\n&lt;li&gt;how to align the master and develop after the release in the production / HotFix.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Are there any other git flow are you following, please share your experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15o4h68", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15o4h68/git_flow_for_data_engineering_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o4h68/git_flow_for_data_engineering_projects/", "subreddit_subscribers": 122185, "created_utc": 1691747549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been trying to research what the best way to do this is, but I have a bunch of CSVs I need to convert to parquet in S3.  \n\n\nIs the best way to create multiple dataframes of equal number of CSV files and then parallel write those dataframes to S3\n\nor\n\nRead one dataframe containing all files and then repartition the df by the partition column and number of executors to shuffle them into an ordered fashion and then have the shuffle write minimize data movement?", "author_fullname": "t2_7jt0qboi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark: How to Handle Parallel Writes to Parquet?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nw73k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691721030.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been trying to research what the best way to do this is, but I have a bunch of CSVs I need to convert to parquet in S3.  &lt;/p&gt;\n\n&lt;p&gt;Is the best way to create multiple dataframes of equal number of CSV files and then parallel write those dataframes to S3&lt;/p&gt;\n\n&lt;p&gt;or&lt;/p&gt;\n\n&lt;p&gt;Read one dataframe containing all files and then repartition the df by the partition column and number of executors to shuffle them into an ordered fashion and then have the shuffle write minimize data movement?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15nw73k", "is_robot_indexable": true, "report_reasons": null, "author": "omscsdatathrow", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nw73k/spark_how_to_handle_parallel_writes_to_parquet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nw73k/spark_how_to_handle_parallel_writes_to_parquet/", "subreddit_subscribers": 122185, "created_utc": 1691721030.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Maybe a better question would be \"what does your workplace do and how BIG is your data\"?\n\nBut mostly just curious.\n\nI wanna know how Big your \"Big Data\" is?", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How big is your Data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oe2wu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691772720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe a better question would be &amp;quot;what does your workplace do and how BIG is your data&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;But mostly just curious.&lt;/p&gt;\n\n&lt;p&gt;I wanna know how Big your &amp;quot;Big Data&amp;quot; is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "15oe2wu", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oe2wu/how_big_is_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oe2wu/how_big_is_your_data/", "subreddit_subscribers": 122185, "created_utc": 1691772720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Struggling to get any interviews for junior or entry DE jobs. \n\nI\u2019m thinking I should instead focus on another path in either SWE or DA.\n\nHowever, I\u2019m burning myself out trying to learn everything rather than focusing in on one specific discipline - and a feeling a bit lost on my journey.\n\nI\u2019m also unsure what my LinkedIn should say/look like if I\u2019m applying for all 3 of these roles.\n\nAny advice on what I should be focused on, or what skills I should be learning?\n\nIm proficient in Python &amp; SQL, with some experience through personal projects with Airflow, IaC, AWS, Data Warehousing, among other things.", "author_fullname": "t2_7xk4etxe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I be looking at SWE or Data Analyst roles instead - and what skills to focus on for these?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o0pt9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691734648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Struggling to get any interviews for junior or entry DE jobs. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m thinking I should instead focus on another path in either SWE or DA.&lt;/p&gt;\n\n&lt;p&gt;However, I\u2019m burning myself out trying to learn everything rather than focusing in on one specific discipline - and a feeling a bit lost on my journey.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m also unsure what my LinkedIn should say/look like if I\u2019m applying for all 3 of these roles.&lt;/p&gt;\n\n&lt;p&gt;Any advice on what I should be focused on, or what skills I should be learning?&lt;/p&gt;\n\n&lt;p&gt;Im proficient in Python &amp;amp; SQL, with some experience through personal projects with Airflow, IaC, AWS, Data Warehousing, among other things.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15o0pt9", "is_robot_indexable": true, "report_reasons": null, "author": "Weekly_Dimension_332", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o0pt9/should_i_be_looking_at_swe_or_data_analyst_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o0pt9/should_i_be_looking_at_swe_or_data_analyst_roles/", "subreddit_subscribers": 122185, "created_utc": 1691734648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not actively thinking about leaving my job because it is my first, and I have been there for just under a year. Is there any harm in talking to the recruiters in your inbox on LinkedIn?", "author_fullname": "t2_23fntgb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Harm from hearing out recruiters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oheb8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691780339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not actively thinking about leaving my job because it is my first, and I have been there for just under a year. Is there any harm in talking to the recruiters in your inbox on LinkedIn?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15oheb8", "is_robot_indexable": true, "report_reasons": null, "author": "LoudSphinx517", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oheb8/harm_from_hearing_out_recruiters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oheb8/harm_from_hearing_out_recruiters/", "subreddit_subscribers": 122185, "created_utc": 1691780339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data analyst with two years of relevant experience. I am trying to get a data engineer position internally but failed to see any openings on workday. I recently came across an opening for a big data developer. Should I try this opportunity? In the job description they mentioned about familiarity with different file formats, compression types, Hadoop and SQL. I am not sure if I should wait for a good opportunity and till then continue with my data analyst job or I should try for this position.\nPS. I have started to learn data engineering. I have good command over python and SQL. I have also taught myself spark, hive and little bit of data factory and data bricks. But, I am not confident as I don't have much hands on experience and I fear that I might just superficial knowledge about it. So I seek your help. \n\nThanks", "author_fullname": "t2_t09x3o4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I take an internal position as a big data developer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oeaqp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691773237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data analyst with two years of relevant experience. I am trying to get a data engineer position internally but failed to see any openings on workday. I recently came across an opening for a big data developer. Should I try this opportunity? In the job description they mentioned about familiarity with different file formats, compression types, Hadoop and SQL. I am not sure if I should wait for a good opportunity and till then continue with my data analyst job or I should try for this position.\nPS. I have started to learn data engineering. I have good command over python and SQL. I have also taught myself spark, hive and little bit of data factory and data bricks. But, I am not confident as I don&amp;#39;t have much hands on experience and I fear that I might just superficial knowledge about it. So I seek your help. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15oeaqp", "is_robot_indexable": true, "report_reasons": null, "author": "frustratedhu", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oeaqp/should_i_take_an_internal_position_as_a_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oeaqp/should_i_take_an_internal_position_as_a_big_data/", "subreddit_subscribers": 122185, "created_utc": 1691773237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi data friends \ud83d\udc4b  \n\n\nI'm Ian and I'm building AI-powered data tools at Turntable.\n\nWe just opened up public access to our new free VS Code extension for writing dbt documentation side-by-side with your dbt models. You can also use AI to auto generate model and column descriptions.  \n\n\nLearn more from our announcement here: [https://twitter.com/turntabledata/status/1689744394897756160](https://twitter.com/turntabledata/status/1689744394897756160)  \n\n\nYou can you download it here [https://www.turntable.so/](https://www.turntable.so/)", "author_fullname": "t2_esppz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free VS Code Extension for writing dbt documentation using AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nohkj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691701717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi data friends \ud83d\udc4b  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m Ian and I&amp;#39;m building AI-powered data tools at Turntable.&lt;/p&gt;\n\n&lt;p&gt;We just opened up public access to our new free VS Code extension for writing dbt documentation side-by-side with your dbt models. You can also use AI to auto generate model and column descriptions.  &lt;/p&gt;\n\n&lt;p&gt;Learn more from our announcement here: &lt;a href=\"https://twitter.com/turntabledata/status/1689744394897756160\"&gt;https://twitter.com/turntabledata/status/1689744394897756160&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;You can you download it here &lt;a href=\"https://www.turntable.so/\"&gt;https://www.turntable.so/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-71GoTv5rIrTKhv_-eCLkPRq5D460ZS2CboAHd6AeJs.jpg?auto=webp&amp;s=f8051e95ad5fc8d18792fe9a7e995a615b50264c", "width": 140, "height": 113}, "resolutions": [{"url": "https://external-preview.redd.it/-71GoTv5rIrTKhv_-eCLkPRq5D460ZS2CboAHd6AeJs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4f1d4bd261c9034d5c94eab5d4efdbf984d1cb08", "width": 108, "height": 87}], "variants": {}, "id": "nAtL11tqbwGo2Q21fH-ZRssRpHe9KrnDTFZeXwynSSw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15nohkj", "is_robot_indexable": true, "report_reasons": null, "author": "StartCompaniesNotWar", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nohkj/free_vs_code_extension_for_writing_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nohkj/free_vs_code_extension_for_writing_dbt/", "subreddit_subscribers": 122185, "created_utc": 1691701717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone :)\n\nI have a lambda function that extracts from a postgres ddbb using awswrangler, but the dataset appears to be too large to keep in memory even when reading in chunks so the lambda timed out.\n\nI searched and found the glue ray scripts and their integration with awswrangler, so I tried setting up a simple script like below. It was convinient since the transformations where all done in pandas already so I didn't need to refactor the code.\n\n    import awswrangler as wr\n    print(f\"Execution Engine: {wr.engine.get()}\")\n    print(f\"Memory Format: {wr.memory_format.get()}\")\n    \n    df = wr.s3.read_parquet(\n        path=path,\n        dataset=True,\n        path_suffix='.parquet'\n    )\n    \n    #perform some transformations\n    \n    dtypes = {...}\n    \n    wr.athena.to_iceberg(\n        df=df,\n        database='&lt;database&gt;',\n        table='&lt;table_name&gt;',\n        temp_path='&lt;temp_path&gt;',\n        index=False,\n        table_location='&lt;table_location&gt;',\n        partition_cols=&lt;partition_cols&gt;,\n        keep_files=False,\n        dtype=dtypes\n    )\n\nThe job parameteres are the following:\n\nhttps://preview.redd.it/c5doul9pjihb1.png?width=785&amp;format=png&amp;auto=webp&amp;s=4adfafe143afbaa264c262f4678ed7ed333ae34a\n\nThe csv files i'm reading are \\~4gb on memory,  the job executed for almost 12 min and \\~10 of them where for initializing the ray instance.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/a611ijm1kihb1.png?width=1467&amp;format=png&amp;auto=webp&amp;s=e3d40e396665d9ef3cfd8d61d2f4efe5b13d0074\n\nIs this duration normal? Is it correct that it initializes an instance for every execution? [https://aws-sdk-pandas.readthedocs.io/en/stable/scale.html#getting-started](https://aws-sdk-pandas.readthedocs.io/en/stable/scale.html#getting-started)\n\nAlso is it possible to run the existing code (using awswrangler and pd but with slight necessary adjustments) on a spark glue job?", "author_fullname": "t2_dpj60sgl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue Ray script long startup time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"a611ijm1kihb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 40, "x": 108, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=743b05c4d3e02335610d161e436bee870d59bae4"}, {"y": 81, "x": 216, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c8379cfadf84a489848dbd1b65c5d85423e87697"}, {"y": 120, "x": 320, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d68811b42627f004b0e7085ef1f68d8a441f211e"}, {"y": 240, "x": 640, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=593e2539f4720cf140ab5a61f968036878497ef2"}, {"y": 361, "x": 960, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=63d18aaea588606324437f6019b2d058545d6c86"}, {"y": 406, "x": 1080, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3711933400a6ac96ea76b90eb0a896e374aec025"}], "s": {"y": 552, "x": 1467, "u": "https://preview.redd.it/a611ijm1kihb1.png?width=1467&amp;format=png&amp;auto=webp&amp;s=e3d40e396665d9ef3cfd8d61d2f4efe5b13d0074"}, "id": "a611ijm1kihb1"}, "c5doul9pjihb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 125, "x": 108, "u": "https://preview.redd.it/c5doul9pjihb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b4b3df445f1f65efe37f45dac575b73600b6af8"}, {"y": 250, "x": 216, "u": "https://preview.redd.it/c5doul9pjihb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a667cbf218fca0a9ccf68d9e1dae0ef5af2b8d9"}, {"y": 371, "x": 320, "u": "https://preview.redd.it/c5doul9pjihb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9e5982a883a6e012b0002d9120f4e04b66a79c9d"}, {"y": 743, "x": 640, "u": "https://preview.redd.it/c5doul9pjihb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=718b3ccf21436b056e647128266d1e19fc11960b"}], "s": {"y": 912, "x": 785, "u": "https://preview.redd.it/c5doul9pjihb1.png?width=785&amp;format=png&amp;auto=webp&amp;s=4adfafe143afbaa264c262f4678ed7ed333ae34a"}, "id": "c5doul9pjihb1"}}, "name": "t3_15oepxu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/DDQUlN5PPe9fegmj6Ut4i6hhnp8pWhNrALsnk_QlMa8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691774194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone :)&lt;/p&gt;\n\n&lt;p&gt;I have a lambda function that extracts from a postgres ddbb using awswrangler, but the dataset appears to be too large to keep in memory even when reading in chunks so the lambda timed out.&lt;/p&gt;\n\n&lt;p&gt;I searched and found the glue ray scripts and their integration with awswrangler, so I tried setting up a simple script like below. It was convinient since the transformations where all done in pandas already so I didn&amp;#39;t need to refactor the code.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import awswrangler as wr\nprint(f&amp;quot;Execution Engine: {wr.engine.get()}&amp;quot;)\nprint(f&amp;quot;Memory Format: {wr.memory_format.get()}&amp;quot;)\n\ndf = wr.s3.read_parquet(\n    path=path,\n    dataset=True,\n    path_suffix=&amp;#39;.parquet&amp;#39;\n)\n\n#perform some transformations\n\ndtypes = {...}\n\nwr.athena.to_iceberg(\n    df=df,\n    database=&amp;#39;&amp;lt;database&amp;gt;&amp;#39;,\n    table=&amp;#39;&amp;lt;table_name&amp;gt;&amp;#39;,\n    temp_path=&amp;#39;&amp;lt;temp_path&amp;gt;&amp;#39;,\n    index=False,\n    table_location=&amp;#39;&amp;lt;table_location&amp;gt;&amp;#39;,\n    partition_cols=&amp;lt;partition_cols&amp;gt;,\n    keep_files=False,\n    dtype=dtypes\n)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The job parameteres are the following:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/c5doul9pjihb1.png?width=785&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4adfafe143afbaa264c262f4678ed7ed333ae34a\"&gt;https://preview.redd.it/c5doul9pjihb1.png?width=785&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4adfafe143afbaa264c262f4678ed7ed333ae34a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The csv files i&amp;#39;m reading are ~4gb on memory,  the job executed for almost 12 min and ~10 of them where for initializing the ray instance.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/a611ijm1kihb1.png?width=1467&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e3d40e396665d9ef3cfd8d61d2f4efe5b13d0074\"&gt;https://preview.redd.it/a611ijm1kihb1.png?width=1467&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e3d40e396665d9ef3cfd8d61d2f4efe5b13d0074&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is this duration normal? Is it correct that it initializes an instance for every execution? &lt;a href=\"https://aws-sdk-pandas.readthedocs.io/en/stable/scale.html#getting-started\"&gt;https://aws-sdk-pandas.readthedocs.io/en/stable/scale.html#getting-started&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Also is it possible to run the existing code (using awswrangler and pd but with slight necessary adjustments) on a spark glue job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15oepxu", "is_robot_indexable": true, "report_reasons": null, "author": "_unwin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oepxu/aws_glue_ray_script_long_startup_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oepxu/aws_glue_ray_script_long_startup_time/", "subreddit_subscribers": 122185, "created_utc": 1691774194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, folks I'm 27 years old and working as an IAM engineer I wouldn't say I like this role much as it's dull and there is nothing new to learn I don't see growth, I also have a love towards data so have planned to switch to data domain but my biggest question is should I first get into data analyst and then transition into data engineer?\n\nOr the right way to jump into data engineering need your help folks I so confused ", "author_fullname": "t2_494n4hlc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need suggestions on career transformation from IAM Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oeciu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691773339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, folks I&amp;#39;m 27 years old and working as an IAM engineer I wouldn&amp;#39;t say I like this role much as it&amp;#39;s dull and there is nothing new to learn I don&amp;#39;t see growth, I also have a love towards data so have planned to switch to data domain but my biggest question is should I first get into data analyst and then transition into data engineer?&lt;/p&gt;\n\n&lt;p&gt;Or the right way to jump into data engineering need your help folks I so confused &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15oeciu", "is_robot_indexable": true, "report_reasons": null, "author": "callmesasi", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oeciu/need_suggestions_on_career_transformation_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oeciu/need_suggestions_on_career_transformation_from/", "subreddit_subscribers": 122185, "created_utc": 1691773339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm looking at automating a process for uploading data to a SQL server DB using a python script which loops through CSVs in a SharePoint location, does some validation on the columns and values and then inserts the data to the existing dB. \n\nMy plan is to open the file, create a staging table from the corresponding df and then insert that into the main table.\n\nBut I'm not sure on the exact syntax for inserting the data into the table especially cause I need it to parameterised in case there are more files.\n\nDoes anybody have any advice on either the Syntax or if there's a better way of doing this?\n\nThis is entirely new to me and I'm sure I'm missing something fairly simple. \n\nThanks in advance", "author_fullname": "t2_44gx5087", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Importing from CSV to SQL server DB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ob1vi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691765585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking at automating a process for uploading data to a SQL server DB using a python script which loops through CSVs in a SharePoint location, does some validation on the columns and values and then inserts the data to the existing dB. &lt;/p&gt;\n\n&lt;p&gt;My plan is to open the file, create a staging table from the corresponding df and then insert that into the main table.&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m not sure on the exact syntax for inserting the data into the table especially cause I need it to parameterised in case there are more files.&lt;/p&gt;\n\n&lt;p&gt;Does anybody have any advice on either the Syntax or if there&amp;#39;s a better way of doing this?&lt;/p&gt;\n\n&lt;p&gt;This is entirely new to me and I&amp;#39;m sure I&amp;#39;m missing something fairly simple. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ob1vi", "is_robot_indexable": true, "report_reasons": null, "author": "rogerbarario", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ob1vi/importing_from_csv_to_sql_server_db/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ob1vi/importing_from_csv_to_sql_server_db/", "subreddit_subscribers": 122185, "created_utc": 1691765585.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Assuming no airflow and just serverless.( or AWS native services ). maybe lambda and something else\n\nWhat would be the easiest way for a newbie DE as I need to POC based on the suggestion provided.\n\nRequirement\n\n\\- api need to be looped based on date\n\n\\- definitely lambda limit of 15mins would not be able to do it\n\n\\- need to backfill the past 365 days\n\nIf you an idea, maybe a youtube or URL that I can follow through.\n\nThanks", "author_fullname": "t2_ecope", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to backfill data using AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o92y7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691760812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Assuming no airflow and just serverless.( or AWS native services ). maybe lambda and something else&lt;/p&gt;\n\n&lt;p&gt;What would be the easiest way for a newbie DE as I need to POC based on the suggestion provided.&lt;/p&gt;\n\n&lt;p&gt;Requirement&lt;/p&gt;\n\n&lt;p&gt;- api need to be looped based on date&lt;/p&gt;\n\n&lt;p&gt;- definitely lambda limit of 15mins would not be able to do it&lt;/p&gt;\n\n&lt;p&gt;- need to backfill the past 365 days&lt;/p&gt;\n\n&lt;p&gt;If you an idea, maybe a youtube or URL that I can follow through.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15o92y7", "is_robot_indexable": true, "report_reasons": null, "author": "snip3r77", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o92y7/how_to_backfill_data_using_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o92y7/how_to_backfill_data_using_aws/", "subreddit_subscribers": 122185, "created_utc": 1691760812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nI am a data engineer with 6-7 YoE from Italy. During my career I have both developed custom data platforms (there were almost no data  platform   SaaS back then), and worked on the data modelling/analytics  part   (developed ETL pipelines, generated analytics reports, supported  data   scientists to implement ML models etc.)\n\nThis year has been quite bad for everyone who was considering to find a new job, and I am no exception.\n\nCompanies seem to only look for senior profiles, which I think I am, but they only consider - or actively search -  people  from renowned companies instead of evaluating skills/experience, and I have only worked - and currently  work -   in less known ones.\n\nSince   the  Italian market is quite a barren land, I have also tried to  find open positions in other European countries, such as Spain or  Germany, but  till date nobody has contacted me back, probably because  they   prefer a candidate that doesn't have to relocate.\n\nIn  case you have recently found a new job as a DE, could you please share  how did you do it, or any useful tips to make my profile more appealing?\n\nThank you!", "author_fullname": "t2_do2bj7xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for career advices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nzg7z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691734540.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691730541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I am a data engineer with 6-7 YoE from Italy. During my career I have both developed custom data platforms (there were almost no data  platform   SaaS back then), and worked on the data modelling/analytics  part   (developed ETL pipelines, generated analytics reports, supported  data   scientists to implement ML models etc.)&lt;/p&gt;\n\n&lt;p&gt;This year has been quite bad for everyone who was considering to find a new job, and I am no exception.&lt;/p&gt;\n\n&lt;p&gt;Companies seem to only look for senior profiles, which I think I am, but they only consider - or actively search -  people  from renowned companies instead of evaluating skills/experience, and I have only worked - and currently  work -   in less known ones.&lt;/p&gt;\n\n&lt;p&gt;Since   the  Italian market is quite a barren land, I have also tried to  find open positions in other European countries, such as Spain or  Germany, but  till date nobody has contacted me back, probably because  they   prefer a candidate that doesn&amp;#39;t have to relocate.&lt;/p&gt;\n\n&lt;p&gt;In  case you have recently found a new job as a DE, could you please share  how did you do it, or any useful tips to make my profile more appealing?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15nzg7z", "is_robot_indexable": true, "report_reasons": null, "author": "somerandomdataeng", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15nzg7z/looking_for_career_advices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nzg7z/looking_for_career_advices/", "subreddit_subscribers": 122185, "created_utc": 1691730541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My boss is super hyped about how they promise to automagically rewrite the ETL from an Informatica/Oracle platform we have and have it work on a cloud data platform.  We had a small demo of the product and the little bit of code I saw looked messy, but no idea what that was from.  Besides the fact that we are also migrating our tech debt, any other impressions from this process?  Did you just get code spit out with no reference to where it came from in the source application?  Did finding the last 10% of stuff that didn't work take you more time than rewriting from scratch?  I am pretty skeptical on these kinds of things so any feedback is appreciated.", "author_fullname": "t2_117fpt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody done a migration with Leaplogic?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15ok195", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691786421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My boss is super hyped about how they promise to automagically rewrite the ETL from an Informatica/Oracle platform we have and have it work on a cloud data platform.  We had a small demo of the product and the little bit of code I saw looked messy, but no idea what that was from.  Besides the fact that we are also migrating our tech debt, any other impressions from this process?  Did you just get code spit out with no reference to where it came from in the source application?  Did finding the last 10% of stuff that didn&amp;#39;t work take you more time than rewriting from scratch?  I am pretty skeptical on these kinds of things so any feedback is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ok195", "is_robot_indexable": true, "report_reasons": null, "author": "Gators1992", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ok195/anybody_done_a_migration_with_leaplogic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ok195/anybody_done_a_migration_with_leaplogic/", "subreddit_subscribers": 122185, "created_utc": 1691786421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pretty much the title, I recently started looking into vector databases and it's flowing over my head what even is a multidimensional space and how do you represent it in a computer let alone calculate it's vector\n\nWould be great if someone can provide a link to a simpler explanation because the ones on YouTube just say it's data stored in multidimensional space I want to know what is that multidimensional space how do you represent it etc", "author_fullname": "t2_clgl2jqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I can't wrap my head around multidimensional space and vector databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oi6cf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691782115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much the title, I recently started looking into vector databases and it&amp;#39;s flowing over my head what even is a multidimensional space and how do you represent it in a computer let alone calculate it&amp;#39;s vector&lt;/p&gt;\n\n&lt;p&gt;Would be great if someone can provide a link to a simpler explanation because the ones on YouTube just say it&amp;#39;s data stored in multidimensional space I want to know what is that multidimensional space how do you represent it etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15oi6cf", "is_robot_indexable": true, "report_reasons": null, "author": "BadKarma-18", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oi6cf/i_cant_wrap_my_head_around_multidimensional_space/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oi6cf/i_cant_wrap_my_head_around_multidimensional_space/", "subreddit_subscribers": 122185, "created_utc": 1691782115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have some AWS data related books and resources that involve the Amazon reviews dataset at s3://amazon-reviews-pds, and I'm certain that I've been able to access it in the past. \n\nHowever, now when I try to access it I am getting access errors:\n\n    aws s3 ls s3://amazon-reviews-pds/tsv/\n    \n    An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied\n\nIs this the Mandela effect and I'm misremembering this dataset being there and available?", "author_fullname": "t2_wxoh8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trouble accessing the Amazon reviews dataset in S3. s3://amazon-reviews-pds", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ohj6q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691780631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some AWS data related books and resources that involve the Amazon reviews dataset at s3://amazon-reviews-pds, and I&amp;#39;m certain that I&amp;#39;ve been able to access it in the past. &lt;/p&gt;\n\n&lt;p&gt;However, now when I try to access it I am getting access errors:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;aws s3 ls s3://amazon-reviews-pds/tsv/\n\nAn error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Is this the Mandela effect and I&amp;#39;m misremembering this dataset being there and available?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ohj6q", "is_robot_indexable": true, "report_reasons": null, "author": "tylerjaywood", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ohj6q/trouble_accessing_the_amazon_reviews_dataset_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ohj6q/trouble_accessing_the_amazon_reviews_dataset_in/", "subreddit_subscribers": 122185, "created_utc": 1691780631.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If anyone has experience with data warehouse projects failures and would like to fill in my survey for my thesis. Its only 3 questions and takes only 1 min. Appreciate it! [https://www.survio.com/survey/d/P3N6I3S8J9X2Y4D9U](https://www.survio.com/survey/d/P3N6I3S8J9X2Y4D9U)", "author_fullname": "t2_8mte9pyz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Survey datawarehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oh9na", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691780029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If anyone has experience with data warehouse projects failures and would like to fill in my survey for my thesis. Its only 3 questions and takes only 1 min. Appreciate it! &lt;a href=\"https://www.survio.com/survey/d/P3N6I3S8J9X2Y4D9U\"&gt;https://www.survio.com/survey/d/P3N6I3S8J9X2Y4D9U&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?auto=webp&amp;s=d32302597e6a051095d42ddc6d6bd40738960c3f", "width": 1080, "height": 568}, "resolutions": [{"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d840b37f36aedc3f632442ab76e16f6f4dda566", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3d7e30c2155ef32e3f4381bea1b3e92b6aaf6000", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2e71ad07247492bfafee64085292868956c28352", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4a580e96ba6c79fae1c84757913f869f9164f886", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=667c725db06552318bc67b5f192602dd5280045a", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/8EtKqqxZshRKO2CGsHD9-uPQwDE6bH0XxgqPMgWpdeo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7d3f863501d04e71f77244864f8ff7faba0b291e", "width": 1080, "height": 568}], "variants": {}, "id": "2xHCw5zDPJw0O7yNG6syCApB7a03gAosm458RLMNPwk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15oh9na", "is_robot_indexable": true, "report_reasons": null, "author": "SnowEcstatic", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oh9na/survey_datawarehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oh9na/survey_datawarehouse/", "subreddit_subscribers": 122185, "created_utc": 1691780029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "On-Prem\n\n\nHello folks \n\nI'm currently working with a data pipeline that involves:\n\nA CentOS system with Docker container running Airflow. Every day, several DAGs execute at dawn, connecting to a PostgreSQL database via API to extract data.\n\nThis data is subsequently transformed using Python scripts which perform various business-related computations, ultimately producing multiple xlsx and csv files stored in directories on CentOS.\n\nIn the morning, several PowerBI dashboards access these files via a Windows VM gateway for publication.\n\nGiven the above, I'm contemplating the need to transition from file-based storage to a more professional setup like a data lake or data warehouse. Due to budget constraints, cloud solutions are off the table. The entire setup is on-premises.\n\nAre there on-premises data lake or data warehouse solutions that would integrate well with the described scenario?\n\nI was thinking about put this files in another postgree containers or minIO maybe, \n\nAnd perhaps I'm over engineering, since it works right now as it is.. \n\n\nThank you for your insights.", "author_fullname": "t2_5rgphe3z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL doubt for improvement On-Prem Data Storage Options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oeqe2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691774224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On-Prem&lt;/p&gt;\n\n&lt;p&gt;Hello folks &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working with a data pipeline that involves:&lt;/p&gt;\n\n&lt;p&gt;A CentOS system with Docker container running Airflow. Every day, several DAGs execute at dawn, connecting to a PostgreSQL database via API to extract data.&lt;/p&gt;\n\n&lt;p&gt;This data is subsequently transformed using Python scripts which perform various business-related computations, ultimately producing multiple xlsx and csv files stored in directories on CentOS.&lt;/p&gt;\n\n&lt;p&gt;In the morning, several PowerBI dashboards access these files via a Windows VM gateway for publication.&lt;/p&gt;\n\n&lt;p&gt;Given the above, I&amp;#39;m contemplating the need to transition from file-based storage to a more professional setup like a data lake or data warehouse. Due to budget constraints, cloud solutions are off the table. The entire setup is on-premises.&lt;/p&gt;\n\n&lt;p&gt;Are there on-premises data lake or data warehouse solutions that would integrate well with the described scenario?&lt;/p&gt;\n\n&lt;p&gt;I was thinking about put this files in another postgree containers or minIO maybe, &lt;/p&gt;\n\n&lt;p&gt;And perhaps I&amp;#39;m over engineering, since it works right now as it is.. &lt;/p&gt;\n\n&lt;p&gt;Thank you for your insights.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15oeqe2", "is_robot_indexable": true, "report_reasons": null, "author": "rafaellelero", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15oeqe2/etl_doubt_for_improvement_onprem_data_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oeqe2/etl_doubt_for_improvement_onprem_data_storage/", "subreddit_subscribers": 122185, "created_utc": 1691774224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 2.5+ years of exp in a service based company mainly migrating data from legacy SAS system to big data environment for a financial client using Dataiku. Now the client is offering me an opportunity to switch to client company for a permanent role and continue the project. We are using SparkSQL for data transformations and little amount of Python for data flow automation(date manipulation and flow run). I think I will get low technical guidance as most of the senior developers have less experience with big data technologies.\nFinancially it's a good opportunity but I will not get chance to work on other DE/cloud technologies and I think i will not get good feedbacks on mistakes I am doing from a technical perspective.\nThis is the first time I will switch my job so getting nervous about making a wrong decision.\nI am pursuing IBM data engineering professional course from Coursera and planning to do GCP certifications after this course.\nCould you please advice me if I should go for this offer or wait for better opportunity", "author_fullname": "t2_bnjs6erc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on job offer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15oannq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691764638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 2.5+ years of exp in a service based company mainly migrating data from legacy SAS system to big data environment for a financial client using Dataiku. Now the client is offering me an opportunity to switch to client company for a permanent role and continue the project. We are using SparkSQL for data transformations and little amount of Python for data flow automation(date manipulation and flow run). I think I will get low technical guidance as most of the senior developers have less experience with big data technologies.\nFinancially it&amp;#39;s a good opportunity but I will not get chance to work on other DE/cloud technologies and I think i will not get good feedbacks on mistakes I am doing from a technical perspective.\nThis is the first time I will switch my job so getting nervous about making a wrong decision.\nI am pursuing IBM data engineering professional course from Coursera and planning to do GCP certifications after this course.\nCould you please advice me if I should go for this offer or wait for better opportunity&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15oannq", "is_robot_indexable": true, "report_reasons": null, "author": "HearingMajor", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15oannq/need_advice_on_job_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15oannq/need_advice_on_job_offer/", "subreddit_subscribers": 122185, "created_utc": 1691764638.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_73d9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TerminusDB vs Neo4j - Graph Database Performance Benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15o8ltv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dIozhhfha_5n1E8nMD6lYz9O8jkAtKYjzovznIySB9o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691759588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "terminusdb.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://terminusdb.com/blog/graph-database-performance-benchmark/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?auto=webp&amp;s=bff1f3fcca8a981f1127eae785c69a5e2c590a4b", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b6aa938e31850a8f289e3e852367ebe23c474809", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7f7b42256ca55c46c8acab2f0002e5aafbb2ae52", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=26f3fc7bd297d3c4d7afaae42e6584eaa51ef1b4", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4e3284e9b725de75aa43525886bb637c4fe39db", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9c196340fa508fe4413688b43dffee7a807abff5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/WATI3GkAXIcj5txE5Sdj7bsXcdhfgyEkEVY02vhgHwg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=07dcaaf8b61bef9cbeeeb6cc96abbebe74f0f6c4", "width": 1080, "height": 567}], "variants": {}, "id": "QAkbE8lTgs4X_xITut4Ph_jglvAUljTec3N-pGtmQ1E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15o8ltv", "is_robot_indexable": true, "report_reasons": null, "author": "GavinMendelGleason", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o8ltv/terminusdb_vs_neo4j_graph_database_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://terminusdb.com/blog/graph-database-performance-benchmark/", "subreddit_subscribers": 122185, "created_utc": 1691759588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a use case where we need to run multiple data flows and automate the process based on some triggers. We will have python &amp; R code, data movement between S3 buckets and Redshift as some of our targets. \nThe client has a licence for Domino already in place but we are exploring our options to run our code via AWS Batch.\n\nEg, one of our flow involves moving data from an external source to S3, processing the data via python/R and then storing it on Redshift\n\nWhat would a good option to run our code and create pipelines?\n\nWhat would be cost effective and efficient?\n\nVery new to Domino and need understand whether there are any benefits of using it rather than going for Batch\n\nThanks", "author_fullname": "t2_end1j06n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running code via Domino Labs vs AWS Batch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o2liw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691741017.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a use case where we need to run multiple data flows and automate the process based on some triggers. We will have python &amp;amp; R code, data movement between S3 buckets and Redshift as some of our targets. \nThe client has a licence for Domino already in place but we are exploring our options to run our code via AWS Batch.&lt;/p&gt;\n\n&lt;p&gt;Eg, one of our flow involves moving data from an external source to S3, processing the data via python/R and then storing it on Redshift&lt;/p&gt;\n\n&lt;p&gt;What would a good option to run our code and create pipelines?&lt;/p&gt;\n\n&lt;p&gt;What would be cost effective and efficient?&lt;/p&gt;\n\n&lt;p&gt;Very new to Domino and need understand whether there are any benefits of using it rather than going for Batch&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15o2liw", "is_robot_indexable": true, "report_reasons": null, "author": "reddit-snorter", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o2liw/running_code_via_domino_labs_vs_aws_batch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o2liw/running_code_via_domino_labs_vs_aws_batch/", "subreddit_subscribers": 122185, "created_utc": 1691741017.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey r/DataEngineering!\n\nI'm currently working on a small data project where I need to set up and deploy Airflow, Airbyte, and dbt Core with BigQuery. I'm excited about the potential of these tools to streamline our data pipeline and analytics process.\n\nHowever, I'm a bit unsure about the best deployment strategies for these components. I want to avoid diving into Kubernetes for now, as the project is still relatively small, and I want to keep things as simple as possible.\n\nI'd love to hear from the community about your experiences and recommendations for deploying these tools.  \n(Credits: ChatGpt)", "author_fullname": "t2_g4sk9zm75", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Deployment Strategies for Airflow, Airbyte, and dbt Core (BigQuery) - Seeking Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15o1ct3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691736796.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/DataEngineering\"&gt;r/DataEngineering&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on a small data project where I need to set up and deploy Airflow, Airbyte, and dbt Core with BigQuery. I&amp;#39;m excited about the potential of these tools to streamline our data pipeline and analytics process.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;m a bit unsure about the best deployment strategies for these components. I want to avoid diving into Kubernetes for now, as the project is still relatively small, and I want to keep things as simple as possible.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear from the community about your experiences and recommendations for deploying these tools.&lt;br/&gt;\n(Credits: ChatGpt)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15o1ct3", "is_robot_indexable": true, "report_reasons": null, "author": "the___lone__wanderer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15o1ct3/best_deployment_strategies_for_airflow_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15o1ct3/best_deployment_strategies_for_airflow_airbyte/", "subreddit_subscribers": 122185, "created_utc": 1691736796.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow Redditors! We're currently dealing with user activity data storage for our internal site using Cosmos DB. Our data schema includes information on clicks, focus, and user-related data like session IDs. As you can imagine, data flow is substantial and frequent. We're at a crossroads between continuing with Cosmos DB or making the shift to a Kusto cluster. Additionally, data that's older than 24 hours isn't particularly useful to us. We'd greatly appreciate your insights and suggestions on which data storage technology would best suit our use case. Thanks in advance!", "author_fullname": "t2_4rwmtqki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cosmos db vs kusto cluster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15nzyl0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691732177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors! We&amp;#39;re currently dealing with user activity data storage for our internal site using Cosmos DB. Our data schema includes information on clicks, focus, and user-related data like session IDs. As you can imagine, data flow is substantial and frequent. We&amp;#39;re at a crossroads between continuing with Cosmos DB or making the shift to a Kusto cluster. Additionally, data that&amp;#39;s older than 24 hours isn&amp;#39;t particularly useful to us. We&amp;#39;d greatly appreciate your insights and suggestions on which data storage technology would best suit our use case. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15nzyl0", "is_robot_indexable": true, "report_reasons": null, "author": "Independent_Art_952", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15nzyl0/cosmos_db_vs_kusto_cluster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15nzyl0/cosmos_db_vs_kusto_cluster/", "subreddit_subscribers": 122185, "created_utc": 1691732177.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}