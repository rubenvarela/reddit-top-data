{"kind": "Listing", "data": {"after": "t3_15ix0ey", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seems more and more necessary to learn K8s in this space.\n\nI stumbled into data engineering from a data science background. By virtue of working in a small team I have been exposed to some basic cloud infra stuff like using the cloud provider's cli to create resources and set properties etc.\n\nI don't understand very much at all about networking apart from that it's a pain in my ass. \n\nI do feel relatively comfortable with using docker.\n\nCan someone who has learned kubernetes recently give me any guidance about how best to go about learning?\n\nMy primary use cases would be running workloads adaptively on kubernetes. Specifically it would be nice to learn enough that I can create a nice workflow using Ray (KubeRay) to run ML training workloads.", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How did you go about learning K8s", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15i8nlo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691175732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seems more and more necessary to learn K8s in this space.&lt;/p&gt;\n\n&lt;p&gt;I stumbled into data engineering from a data science background. By virtue of working in a small team I have been exposed to some basic cloud infra stuff like using the cloud provider&amp;#39;s cli to create resources and set properties etc.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t understand very much at all about networking apart from that it&amp;#39;s a pain in my ass. &lt;/p&gt;\n\n&lt;p&gt;I do feel relatively comfortable with using docker.&lt;/p&gt;\n\n&lt;p&gt;Can someone who has learned kubernetes recently give me any guidance about how best to go about learning?&lt;/p&gt;\n\n&lt;p&gt;My primary use cases would be running workloads adaptively on kubernetes. Specifically it would be nice to learn enough that I can create a nice workflow using Ray (KubeRay) to run ML training workloads.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15i8nlo", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15i8nlo/how_did_you_go_about_learning_k8s/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15i8nlo/how_did_you_go_about_learning_k8s/", "subreddit_subscribers": 120938, "created_utc": 1691175732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been blocked on the post, but OP is clearly running a sock puppet network as I detailed in (rapidly downvoted) comments in the post.", "author_fullname": "t2_30190", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Don't fall for the \"Data is Beautiful\" post with the mug. It is an ad. Mods, is there anything we can do about shit like this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15iu5ya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691237658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been blocked on the post, but OP is clearly running a sock puppet network as I detailed in (rapidly downvoted) comments in the post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15iu5ya", "is_robot_indexable": true, "report_reasons": null, "author": "mojitz", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iu5ya/dont_fall_for_the_data_is_beautiful_post_with_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iu5ya/dont_fall_for_the_data_is_beautiful_post_with_the/", "subreddit_subscribers": 120938, "created_utc": 1691237658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I've been working in SAP (within SAP itself) for 8 years now, as a data and analytics consultant (Mainly Hana, BO 4, Dataservices and SAC BI - not planning but BI )  \nAs my pay didn't evolve much and as i'm getting bored and I don't see how i can evolve in SAP. I started to check other opportunities :  \nI got certified as data analyst in Azure and GCP and i've been looking into going out from the SAP world as going freelance seems like a good idea for salary and new challenges, and going freelance in SAP is hard (no that many opportunities, except for SAC Planning that i've never worked on)  \nSo my plan is work with a company for one year on either Azure or GCP as data and analytics engineer then move to freelance.  \nAfter a lot of work, certifications and after i got a positive answer from a good company to work on GCP i'm wondering whether or not i'm making a huge mistake. Leaving SAP behind for GCP, i'm in europe and the market is full of freelance offers in GCP, also unlike Azure or AWS, GCP is still relatively so i bet i can compete in a year or so..  \nBut at the same time leaving SAP after 8 years ain't that easy so... what do you think ? ", "author_fullname": "t2_4kn0fb0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving out to GCP after 8 years in SAP, is it a good decision ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15i500l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691167200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working in SAP (within SAP itself) for 8 years now, as a data and analytics consultant (Mainly Hana, BO 4, Dataservices and SAC BI - not planning but BI )&lt;br/&gt;\nAs my pay didn&amp;#39;t evolve much and as i&amp;#39;m getting bored and I don&amp;#39;t see how i can evolve in SAP. I started to check other opportunities :&lt;br/&gt;\nI got certified as data analyst in Azure and GCP and i&amp;#39;ve been looking into going out from the SAP world as going freelance seems like a good idea for salary and new challenges, and going freelance in SAP is hard (no that many opportunities, except for SAC Planning that i&amp;#39;ve never worked on)&lt;br/&gt;\nSo my plan is work with a company for one year on either Azure or GCP as data and analytics engineer then move to freelance.&lt;br/&gt;\nAfter a lot of work, certifications and after i got a positive answer from a good company to work on GCP i&amp;#39;m wondering whether or not i&amp;#39;m making a huge mistake. Leaving SAP behind for GCP, i&amp;#39;m in europe and the market is full of freelance offers in GCP, also unlike Azure or AWS, GCP is still relatively so i bet i can compete in a year or so..&lt;br/&gt;\nBut at the same time leaving SAP after 8 years ain&amp;#39;t that easy so... what do you think ? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15i500l", "is_robot_indexable": true, "report_reasons": null, "author": "Ezzarrass", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15i500l/moving_out_to_gcp_after_8_years_in_sap_is_it_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15i500l/moving_out_to_gcp_after_8_years_in_sap_is_it_a/", "subreddit_subscribers": 120938, "created_utc": 1691167200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have been working as a senior engineer for a while now.  Quite comfortable with streaming, batch processing, python, SQL, Snowflake, DE concepts etc. I have been doing well at my current place so they have offered me a managerial role. Now I really liked getting my hands dirty but I have decided to take it up.\n\nSo wanted to know from folks who made the transition. What were the pitfalls? And any advice in general would greatly help! ", "author_fullname": "t2_ryny2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving on to a managerial position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15i5dul", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691168092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have been working as a senior engineer for a while now.  Quite comfortable with streaming, batch processing, python, SQL, Snowflake, DE concepts etc. I have been doing well at my current place so they have offered me a managerial role. Now I really liked getting my hands dirty but I have decided to take it up.&lt;/p&gt;\n\n&lt;p&gt;So wanted to know from folks who made the transition. What were the pitfalls? And any advice in general would greatly help! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15i5dul", "is_robot_indexable": true, "report_reasons": null, "author": "king_booker", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15i5dul/moving_on_to_a_managerial_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15i5dul/moving_on_to_a_managerial_position/", "subreddit_subscribers": 120938, "created_utc": 1691168092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, \n\nI read about DuckDB from this subreddit and decided to give it a spin together with dbt. I think it is a blast and I am amazed at the speed of DuckDB. Currently, I am building a local data warehouse that is grabbing data from the open Danish parliament API, landing it in a folder, and then creating views in DuckDB to query. This could easily be shifted to the cloud but I love the simplicity of running it just in time when I would like to look at the data.\n\nI have so far designed one fact that tracks the process of voting, with dimensions on actors, cases, dates, meetings, and votes.\n\nI have yet to decide on an EL tool, and I would like to implement some delta loading and further build out the dimensional model. Furthermore, I am in doubt about a visualization tool as I use Power BI in my daily job, which is the go-to tool in Denmark for data.\n\nIt is still a work in progress, but I think it's great fun to build something on real-world data that is not company based. The project is open source and available here: [https://github.com/bgarcevic/danish-democracy-data](https://github.com/bgarcevic/danish-democracy-data)\n\nIf I ever go back to work as an analyst instead of data engineering I would start using DuckDB in my daily work. If anyone has feedback on how to improve the project, please feel free to chip in.", "author_fullname": "t2_1j8f19jc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Currently building a local data warehouse with dbt/DuckDB using real data from the danish parliament", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15iq5bk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691224320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;I read about DuckDB from this subreddit and decided to give it a spin together with dbt. I think it is a blast and I am amazed at the speed of DuckDB. Currently, I am building a local data warehouse that is grabbing data from the open Danish parliament API, landing it in a folder, and then creating views in DuckDB to query. This could easily be shifted to the cloud but I love the simplicity of running it just in time when I would like to look at the data.&lt;/p&gt;\n\n&lt;p&gt;I have so far designed one fact that tracks the process of voting, with dimensions on actors, cases, dates, meetings, and votes.&lt;/p&gt;\n\n&lt;p&gt;I have yet to decide on an EL tool, and I would like to implement some delta loading and further build out the dimensional model. Furthermore, I am in doubt about a visualization tool as I use Power BI in my daily job, which is the go-to tool in Denmark for data.&lt;/p&gt;\n\n&lt;p&gt;It is still a work in progress, but I think it&amp;#39;s great fun to build something on real-world data that is not company based. The project is open source and available here: &lt;a href=\"https://github.com/bgarcevic/danish-democracy-data\"&gt;https://github.com/bgarcevic/danish-democracy-data&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If I ever go back to work as an analyst instead of data engineering I would start using DuckDB in my daily work. If anyone has feedback on how to improve the project, please feel free to chip in.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?auto=webp&amp;s=d440a9b03ad7be4bd8ccbab3eea98961d188954b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c7f75b61b4185c330bde2a091c8da5756fb83e2f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9989ad88c395bfe0f60169409451bf20647bdf2d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=66b2a7ade568849f387186e14a78e2664c25384d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bad7f84339e26933c09eef145d5fbf77e4811e56", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8b6d67b5f7ceb1276bbd892207792c85f11c9c45", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c0bf07519000fee88d7ebee0b0ee08b465ff7a9e", "width": 1080, "height": 540}], "variants": {}, "id": "lKWf3uuaiZX6lRl11i9elQHtnYAFKgHicR3A0_a2wCs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "15iq5bk", "is_robot_indexable": true, "report_reasons": null, "author": "bgarcevic", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iq5bk/currently_building_a_local_data_warehouse_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iq5bk/currently_building_a_local_data_warehouse_with/", "subreddit_subscribers": 120938, "created_utc": 1691224320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a big distinction between data engineers and senior roles? \n\nIs it easier to look for senior roles rather than get promoted in the current company?\n\n&amp;#x200B;", "author_fullname": "t2_av88gzj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between Data engineer and Senior Data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15iqtrz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691226704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a big distinction between data engineers and senior roles? &lt;/p&gt;\n\n&lt;p&gt;Is it easier to look for senior roles rather than get promoted in the current company?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15iqtrz", "is_robot_indexable": true, "report_reasons": null, "author": "rdmcoloring", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iqtrz/difference_between_data_engineer_and_senior_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iqtrz/difference_between_data_engineer_and_senior_data/", "subreddit_subscribers": 120938, "created_utc": 1691226704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey so I'm not quite sure what is considered to be an ETL pipeline but I've been working on a project and so far I have been able to:\n- Scrape job listings from linkedin using Python (selenium)\n- Clean and organize the listings into data using Python \n- Create tables and store data into a local PostgreSQL database using Python (psycopg2)\n- Query the data in Postico 2 or query the data in jupyter notebooks\n\nIs this technically an ETL pipeline? What would you suggest I spend some time working on or try to develop more \"industry\" knowledge?", "author_fullname": "t2_7totmqdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kinda winging a project. What am I missing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15igzpv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691195586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey so I&amp;#39;m not quite sure what is considered to be an ETL pipeline but I&amp;#39;ve been working on a project and so far I have been able to:\n- Scrape job listings from linkedin using Python (selenium)\n- Clean and organize the listings into data using Python \n- Create tables and store data into a local PostgreSQL database using Python (psycopg2)\n- Query the data in Postico 2 or query the data in jupyter notebooks&lt;/p&gt;\n\n&lt;p&gt;Is this technically an ETL pipeline? What would you suggest I spend some time working on or try to develop more &amp;quot;industry&amp;quot; knowledge?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15igzpv", "is_robot_indexable": true, "report_reasons": null, "author": "Impossible-Evidence9", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15igzpv/kinda_winging_a_project_what_am_i_missing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15igzpv/kinda_winging_a_project_what_am_i_missing/", "subreddit_subscribers": 120938, "created_utc": 1691195586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the best way to run DBT in airflow?\n\nWe're currently using ECS to execute tasks in airflow and for every ECS task its one single DBT model. Is this best practice? ", "author_fullname": "t2_av88gzj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running DBT in Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ijr4r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691203332.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the best way to run DBT in airflow?&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re currently using ECS to execute tasks in airflow and for every ECS task its one single DBT model. Is this best practice? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ijr4r", "is_robot_indexable": true, "report_reasons": null, "author": "rdmcoloring", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ijr4r/running_dbt_in_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ijr4r/running_dbt_in_airflow/", "subreddit_subscribers": 120938, "created_utc": 1691203332.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My shop wants to train (remotely) several employees on SSIS--the goal being to improve their skills from very beginner to intermediate/advanced. I understand that both Plural Sight and LinkedIn Learning offer trainings that could help accomplish this, but I've been tasked exploring additional options which might cost more $ but would ideally include a trainer (either live or at least able to respond quickly to messages). We're considering trainings ranging from several weeks to a month. Interested to hear thoughts on some of the top offerings currently available for this. Thank you!", "author_fullname": "t2_rr8568c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Paid Remote SSIS Training Courses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ii1vw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691198465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My shop wants to train (remotely) several employees on SSIS--the goal being to improve their skills from very beginner to intermediate/advanced. I understand that both Plural Sight and LinkedIn Learning offer trainings that could help accomplish this, but I&amp;#39;ve been tasked exploring additional options which might cost more $ but would ideally include a trainer (either live or at least able to respond quickly to messages). We&amp;#39;re considering trainings ranging from several weeks to a month. Interested to hear thoughts on some of the top offerings currently available for this. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ii1vw", "is_robot_indexable": true, "report_reasons": null, "author": "HlpM3Plz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ii1vw/best_paid_remote_ssis_training_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ii1vw/best_paid_remote_ssis_training_courses/", "subreddit_subscribers": 120938, "created_utc": 1691198465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So regarding business end users being able to accessibly (but obv not too accessibly, ie security and lowest privilege, data integrity etc) write back data to databases for archiving operational data (think uploading forecast scenarios over time), does anyone here have have any idea how to best handle this situation?\n\nFor being extremely common of a situation it seems like the lesser talked about concept, with no very apparent scalable solutions. \n\nAnd in terms of volume of write back, I\u2019m meaning literally like excel files of no more than 20,000 rows uploaded to staging tables in snowflake. \n\nIs the solution just building web apps? Is it building power app forms embedded in Power BI? Or is there a more robust route without relying on random small third parties to abstract this?", "author_fullname": "t2_bnrsqazi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data write-back", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15i83ge", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691174397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So regarding business end users being able to accessibly (but obv not too accessibly, ie security and lowest privilege, data integrity etc) write back data to databases for archiving operational data (think uploading forecast scenarios over time), does anyone here have have any idea how to best handle this situation?&lt;/p&gt;\n\n&lt;p&gt;For being extremely common of a situation it seems like the lesser talked about concept, with no very apparent scalable solutions. &lt;/p&gt;\n\n&lt;p&gt;And in terms of volume of write back, I\u2019m meaning literally like excel files of no more than 20,000 rows uploaded to staging tables in snowflake. &lt;/p&gt;\n\n&lt;p&gt;Is the solution just building web apps? Is it building power app forms embedded in Power BI? Or is there a more robust route without relying on random small third parties to abstract this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15i83ge", "is_robot_indexable": true, "report_reasons": null, "author": "No_Newspaper3209", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15i83ge/data_writeback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15i83ge/data_writeback/", "subreddit_subscribers": 120938, "created_utc": 1691174397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I just wanted to come on here to rant/ask for advice.\nI am a recent grad and got a sick job as a data engineer at a pretty large consulting company and I loved it at first, like I want to do this for the rest of my life. My colleagues are awesome, my bosses/managers are awesome. I am pretty good at what I do too, I\u2019ve had a few managers tell me that I\u2019m doing a great job and that I\u2019m a great dev, and I really feel fulfilled and valuable here. However, our client is terrible to us. They give us extremely unreasonable deadlines and are super impatient when it comes to development that would take some time - resulting in most of the backend engineers working up to 60 hrs per week for a few months. \nThis has resulted in a snowball effect where all of us are so burnt out and so our deliverables can\u2019t keep up with their big asks/deadlines, and I\u2019m not sure why the folks that communicate most with the client doesn\u2019t push back at all. I\u2019ve sat in a few of these client meetings and all they do is yell at us and complain about how long it takes to develop a very drastic change that would take a huge LOE.\nLast Friday I got assigned to basically redo a bunch of code that had taken weeks to develop (not by me) initially, and it was supposed to be released on that Thursday and I had no support and NONE of this was in writing or documented until Wednesday. I worked so hard on it, and worked from 8am-4am on Tuesday trying to get it out so we can test it. I got pulled into a big call w all of the managers on Thursday (after it was released) and basically got screamed at by a senior manager that talks to the client a bunch bc I was told to do something different, even though he was the one that confirmed with me that I understood the assignment on Tuesday. So he basically lied to everyone to make me seem incompetent. I started defending myself and he started yelling over me \u201cWHY IS SHE TALKING AND NOT A MANAGER?\u201d Luckily, one of the other senior managers stood up for me, saying that I was the one that developed the code and I should be speaking on this. And so I started crying bc I was so frustrated, sleep deprived, and couldn\u2019t hold back my tears anymore. My leads/managers reached out to me during and after the meeting assuring me it wasn\u2019t my fault and they know I did what I was asked to do. Luckily, we were able to redo it the next day, as I had a lot of support and clearly understood the assignment.\nI want to leave this project so bad, I\u2019m miserable, constantly anxious at work, and I don\u2019t have a life anymore. I also start grad school again in about a month and I have no idea how I am going to balance this with school, and job searching is really difficult when I don\u2019t have the time or the energy to do it, especially with only having under a year of experience. Also I would have to brush up on my Leetcode/data structures if I wanna start job searching again lol, which is possible but man I am just SO burnt out and I need to pay the bills, so I can\u2019t just take a break to job search (I am very much underpaid for a DE so I don\u2019t have a lot of savings). Or maybe I\u2019m just making up excuses and just need a push haha. What should I do?\n\nTLDR; I am underpaid, got yelled at for things that are not my fault, work up to 60 hours a week, and I have to go back to night school in less than a month and can\u2019t balance this like I used to before it got so bad. I just need advice on what I should do or how to find time to look for other jobs.", "author_fullname": "t2_5i0h4l3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Terrible work environment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15iwbtf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691243670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I just wanted to come on here to rant/ask for advice.\nI am a recent grad and got a sick job as a data engineer at a pretty large consulting company and I loved it at first, like I want to do this for the rest of my life. My colleagues are awesome, my bosses/managers are awesome. I am pretty good at what I do too, I\u2019ve had a few managers tell me that I\u2019m doing a great job and that I\u2019m a great dev, and I really feel fulfilled and valuable here. However, our client is terrible to us. They give us extremely unreasonable deadlines and are super impatient when it comes to development that would take some time - resulting in most of the backend engineers working up to 60 hrs per week for a few months. \nThis has resulted in a snowball effect where all of us are so burnt out and so our deliverables can\u2019t keep up with their big asks/deadlines, and I\u2019m not sure why the folks that communicate most with the client doesn\u2019t push back at all. I\u2019ve sat in a few of these client meetings and all they do is yell at us and complain about how long it takes to develop a very drastic change that would take a huge LOE.\nLast Friday I got assigned to basically redo a bunch of code that had taken weeks to develop (not by me) initially, and it was supposed to be released on that Thursday and I had no support and NONE of this was in writing or documented until Wednesday. I worked so hard on it, and worked from 8am-4am on Tuesday trying to get it out so we can test it. I got pulled into a big call w all of the managers on Thursday (after it was released) and basically got screamed at by a senior manager that talks to the client a bunch bc I was told to do something different, even though he was the one that confirmed with me that I understood the assignment on Tuesday. So he basically lied to everyone to make me seem incompetent. I started defending myself and he started yelling over me \u201cWHY IS SHE TALKING AND NOT A MANAGER?\u201d Luckily, one of the other senior managers stood up for me, saying that I was the one that developed the code and I should be speaking on this. And so I started crying bc I was so frustrated, sleep deprived, and couldn\u2019t hold back my tears anymore. My leads/managers reached out to me during and after the meeting assuring me it wasn\u2019t my fault and they know I did what I was asked to do. Luckily, we were able to redo it the next day, as I had a lot of support and clearly understood the assignment.\nI want to leave this project so bad, I\u2019m miserable, constantly anxious at work, and I don\u2019t have a life anymore. I also start grad school again in about a month and I have no idea how I am going to balance this with school, and job searching is really difficult when I don\u2019t have the time or the energy to do it, especially with only having under a year of experience. Also I would have to brush up on my Leetcode/data structures if I wanna start job searching again lol, which is possible but man I am just SO burnt out and I need to pay the bills, so I can\u2019t just take a break to job search (I am very much underpaid for a DE so I don\u2019t have a lot of savings). Or maybe I\u2019m just making up excuses and just need a push haha. What should I do?&lt;/p&gt;\n\n&lt;p&gt;TLDR; I am underpaid, got yelled at for things that are not my fault, work up to 60 hours a week, and I have to go back to night school in less than a month and can\u2019t balance this like I used to before it got so bad. I just need advice on what I should do or how to find time to look for other jobs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15iwbtf", "is_robot_indexable": true, "report_reasons": null, "author": "manwithenormouspeepe", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iwbtf/terrible_work_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iwbtf/terrible_work_environment/", "subreddit_subscribers": 120938, "created_utc": 1691243670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uypc8pwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Lake Introduction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_15ieps5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/FcCdeUsvj4k?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Delta Lake Introduction - Part 2\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Delta Lake Introduction - Part 2", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/FcCdeUsvj4k?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Delta Lake Introduction - Part 2\"&gt;&lt;/iframe&gt;", "author_name": "TheAverageEngineer", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/FcCdeUsvj4k/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@theaverageengineer"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/FcCdeUsvj4k?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Delta Lake Introduction - Part 2\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/15ieps5", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Er_jRVtvtlc4fh7LHuFvpzstwaFfwLMVZX0mWHhJevM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691189771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/FcCdeUsvj4k", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/z_8gQFASVukkDwdz1PbuZWkncZ2wDjGpUmlPfLbMwP0.jpg?auto=webp&amp;s=ec5d1df488b5b070db46181f82ca14593ebb5637", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/z_8gQFASVukkDwdz1PbuZWkncZ2wDjGpUmlPfLbMwP0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=68760b98d92d17ec3956e4f665508ef95aade104", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/z_8gQFASVukkDwdz1PbuZWkncZ2wDjGpUmlPfLbMwP0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=be0a905a69897f5bff9a4a3b14e67e4eb643db91", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/z_8gQFASVukkDwdz1PbuZWkncZ2wDjGpUmlPfLbMwP0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=52a8a7f5349adbeebb87935e4909c340f392d55a", "width": 320, "height": 240}], "variants": {}, "id": "v35AlQQlmWeTbIt2zrKFz8w03gzA6zV4FU8wUnn34is"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ieps5", "is_robot_indexable": true, "report_reasons": null, "author": "DarkClear3881", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ieps5/delta_lake_introduction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/FcCdeUsvj4k", "subreddit_subscribers": 120938, "created_utc": 1691189771.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Delta Lake Introduction - Part 2", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/FcCdeUsvj4k?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Delta Lake Introduction - Part 2\"&gt;&lt;/iframe&gt;", "author_name": "TheAverageEngineer", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/FcCdeUsvj4k/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@theaverageengineer"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a few external delta tables which are loaded incrementally every 3 hours from kafka, whereas some are MVs\n\nSchema for these tables has been created in Synapse using DDLs.\n\nHow can I push these tables incrementally at the same frequency (wherever possible) to Synapse? Is ADF the best approach here?", "author_fullname": "t2_wkq4zhf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Delta Table to Synapse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15i71lk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691173121.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691171967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few external delta tables which are loaded incrementally every 3 hours from kafka, whereas some are MVs&lt;/p&gt;\n\n&lt;p&gt;Schema for these tables has been created in Synapse using DDLs.&lt;/p&gt;\n\n&lt;p&gt;How can I push these tables incrementally at the same frequency (wherever possible) to Synapse? Is ADF the best approach here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15i71lk", "is_robot_indexable": true, "report_reasons": null, "author": "the_aris", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15i71lk/databricks_delta_table_to_synapse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15i71lk/databricks_delta_table_to_synapse/", "subreddit_subscribers": 120938, "created_utc": 1691171967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nAside from Scala (and only for specific aspects), I have the impression that JVM-based languages are not really recommended.\n\nBut as an engineer in the data field for 8 years, I see many potential shortcomings with Python (packaging, multithreading, versioning, scalability). Maybe I am wrong, I have not decided that yet, but I have compared in my work Python vs Java code for Apache Beam and Java code looks surprisingly shorter with many magical features and at the same time cleaner code and faster execution. \n\nYes it is an isolated sample of code, but I've looked into Java 17 and new features are really great for data processing (processors chaining in Stream are one of them). Coupled with a  great scripting language like Kotlin of Clojure, it could be a very very good base for DE in general.\n\nHas someone a successful experience with JVM-based (of course not for all but for a decent part of the coding pool) in their companies ?\n\n&amp;#x200B;\n\nThanks, and sorry for my very very bad english", "author_fullname": "t2_etc5rwyp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is JVM-based languages not recommended for DE ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15iy5fp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691248266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Aside from Scala (and only for specific aspects), I have the impression that JVM-based languages are not really recommended.&lt;/p&gt;\n\n&lt;p&gt;But as an engineer in the data field for 8 years, I see many potential shortcomings with Python (packaging, multithreading, versioning, scalability). Maybe I am wrong, I have not decided that yet, but I have compared in my work Python vs Java code for Apache Beam and Java code looks surprisingly shorter with many magical features and at the same time cleaner code and faster execution. &lt;/p&gt;\n\n&lt;p&gt;Yes it is an isolated sample of code, but I&amp;#39;ve looked into Java 17 and new features are really great for data processing (processors chaining in Stream are one of them). Coupled with a  great scripting language like Kotlin of Clojure, it could be a very very good base for DE in general.&lt;/p&gt;\n\n&lt;p&gt;Has someone a successful experience with JVM-based (of course not for all but for a decent part of the coding pool) in their companies ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks, and sorry for my very very bad english&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15iy5fp", "is_robot_indexable": true, "report_reasons": null, "author": "AnsoudDeMaule", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iy5fp/why_is_jvmbased_languages_not_recommended_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iy5fp/why_is_jvmbased_languages_not_recommended_for_de/", "subreddit_subscribers": 120938, "created_utc": 1691248266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All!  \nSince this a long question, I will organize it into topics as follows:\n\nBreathily explaining our architecture:   \nWe have a landing AWS s3 bucket that receives raw files from Airbyte, then using Trino we run some merge statements to promote and treat this data, converting the raw parquet files into iceberg tables (this is our cleansed layer).   \n\n\nMore context:   \nWe run several refreshes throughout the day, meaning we have thousands of small files and We are not using partitioning at the landing layer, so every merge statement from every table fully scans the landing layer before refreshing the cleansed layer.\n\nOur main problem:   \n**Costs!** We are paying around USD 150 every day **only for the get and put requests** on AWS S3.   \n\n\nMy proposed solution:  \nI'm wondering about partitioning our landing layer by the `_airbyte_emitted_at` date key, so that we will have a partition for each day and the merge operations will only scan these files instead of scanning all the old files.  \n\n\nMy question:  \nConsidering that my landing layer relies on a Hive Catalog and we orchestrate everything using Trino.  After Airbyte syncs the incremental data, I would run the following statement to update the Hive table's metadata:\n\n    call landing_catalog.system.sync_partition_metadata(\n        schema_name =&gt; '&lt;my schema&gt;',\n        table_name =&gt; '&lt;my table name&gt;',\n        mode =&gt; 'full'\n    );\n\n\nIs this `sync_partition_metadata` function as expensive as fully scanning the s3 bucket every time?  Considering that it probably scans all the folders and files for each one of the table....  \n\n\nOther comments about the architecture are also welcome!  \nThank you!", "author_fullname": "t2_ijp90vxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to save money with AWS S3 get and put requests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15iwlpd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691244369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All!&lt;br/&gt;\nSince this a long question, I will organize it into topics as follows:&lt;/p&gt;\n\n&lt;p&gt;Breathily explaining our architecture:&lt;br/&gt;\nWe have a landing AWS s3 bucket that receives raw files from Airbyte, then using Trino we run some merge statements to promote and treat this data, converting the raw parquet files into iceberg tables (this is our cleansed layer).   &lt;/p&gt;\n\n&lt;p&gt;More context:&lt;br/&gt;\nWe run several refreshes throughout the day, meaning we have thousands of small files and We are not using partitioning at the landing layer, so every merge statement from every table fully scans the landing layer before refreshing the cleansed layer.&lt;/p&gt;\n\n&lt;p&gt;Our main problem:&lt;br/&gt;\n&lt;strong&gt;Costs!&lt;/strong&gt; We are paying around USD 150 every day &lt;strong&gt;only for the get and put requests&lt;/strong&gt; on AWS S3.   &lt;/p&gt;\n\n&lt;p&gt;My proposed solution:&lt;br/&gt;\nI&amp;#39;m wondering about partitioning our landing layer by the &lt;code&gt;_airbyte_emitted_at&lt;/code&gt; date key, so that we will have a partition for each day and the merge operations will only scan these files instead of scanning all the old files.  &lt;/p&gt;\n\n&lt;p&gt;My question:&lt;br/&gt;\nConsidering that my landing layer relies on a Hive Catalog and we orchestrate everything using Trino.  After Airbyte syncs the incremental data, I would run the following statement to update the Hive table&amp;#39;s metadata:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;call landing_catalog.system.sync_partition_metadata(\n    schema_name =&amp;gt; &amp;#39;&amp;lt;my schema&amp;gt;&amp;#39;,\n    table_name =&amp;gt; &amp;#39;&amp;lt;my table name&amp;gt;&amp;#39;,\n    mode =&amp;gt; &amp;#39;full&amp;#39;\n);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Is this &lt;code&gt;sync_partition_metadata&lt;/code&gt; function as expensive as fully scanning the s3 bucket every time?  Considering that it probably scans all the folders and files for each one of the table....  &lt;/p&gt;\n\n&lt;p&gt;Other comments about the architecture are also welcome!&lt;br/&gt;\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15iwlpd", "is_robot_indexable": true, "report_reasons": null, "author": "CzarSantos98", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iwlpd/trying_to_save_money_with_aws_s3_get_and_put/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iwlpd/trying_to_save_money_with_aws_s3_get_and_put/", "subreddit_subscribers": 120938, "created_utc": 1691244369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "No Talend or Fivetran, just native gcp tools.", "author_fullname": "t2_ebaw8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best gcp tooling for paginating an Api and sinking the json to bigquery? Batch not stream. Thanks!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ii7hd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691198892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;No Talend or Fivetran, just native gcp tools.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ii7hd", "is_robot_indexable": true, "report_reasons": null, "author": "sois", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ii7hd/what_is_the_best_gcp_tooling_for_paginating_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ii7hd/what_is_the_best_gcp_tooling_for_paginating_an/", "subreddit_subscribers": 120938, "created_utc": 1691198892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my job I query data from Snowflake and Hue Hive. I love snowflake, but I hate Hue and consequently Hive (I am guessing there are easier ways to query but I don't know them and doubt I'd get IT permission). Snowflake is so easy to use I love it; Hue on the other hand is utter dogshit. Takes forever to run basic queries and I am limited to only 100,000 row CSV downloads (WTF!). I am querying pretty much the exact same data; both POS tables, main difference is that the Hive table has a customer identifier column. \n\nMy question is, what is happening under the hood, that I am obviously missing, that would require the organization to use two different tools to query these databases? What are some reasons why they wouldn't store the data in the same service and have both be query-able in Snowflake?  ", "author_fullname": "t2_ep8p7sugb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Question to Engineers from an Analyst] Why would an organization use multiple services to access similar data in lake/warehouse instead of one?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15idr4o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691187415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my job I query data from Snowflake and Hue Hive. I love snowflake, but I hate Hue and consequently Hive (I am guessing there are easier ways to query but I don&amp;#39;t know them and doubt I&amp;#39;d get IT permission). Snowflake is so easy to use I love it; Hue on the other hand is utter dogshit. Takes forever to run basic queries and I am limited to only 100,000 row CSV downloads (WTF!). I am querying pretty much the exact same data; both POS tables, main difference is that the Hive table has a customer identifier column. &lt;/p&gt;\n\n&lt;p&gt;My question is, what is happening under the hood, that I am obviously missing, that would require the organization to use two different tools to query these databases? What are some reasons why they wouldn&amp;#39;t store the data in the same service and have both be query-able in Snowflake?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15idr4o", "is_robot_indexable": true, "report_reasons": null, "author": "bestanalystever", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15idr4o/question_to_engineers_from_an_analyst_why_would/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15idr4o/question_to_engineers_from_an_analyst_why_would/", "subreddit_subscribers": 120938, "created_utc": 1691187415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wanted to ask some experienced people here about what gave them the best return on investment. Will investing in my data engineering/interviewing skills be more fruitful or will  some freelancing/consulting on the side would be better?\n\nAnd if doing some freelancing/consulting for extra cash is better, what platforms do you guys use to find such opportunities?", "author_fullname": "t2_l35gwhuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Invest More in Day Job and Skills VS Investing In a Side Hustle?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15iz9jc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691251022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanted to ask some experienced people here about what gave them the best return on investment. Will investing in my data engineering/interviewing skills be more fruitful or will  some freelancing/consulting on the side would be better?&lt;/p&gt;\n\n&lt;p&gt;And if doing some freelancing/consulting for extra cash is better, what platforms do you guys use to find such opportunities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15iz9jc", "is_robot_indexable": true, "report_reasons": null, "author": "Senior_Anteater4688", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iz9jc/invest_more_in_day_job_and_skills_vs_investing_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iz9jc/invest_more_in_day_job_and_skills_vs_investing_in/", "subreddit_subscribers": 120938, "created_utc": 1691251022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, i'm currently following this [course](https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/), and i'm wondering if Pig is still used in industry because in jobs offer (at least in France) they never mention Pig only Hive\n\nTy", "author_fullname": "t2_w54e628x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Apache Pig used in industry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15iyfjx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691248953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, i&amp;#39;m currently following this &lt;a href=\"https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/\"&gt;course&lt;/a&gt;, and i&amp;#39;m wondering if Pig is still used in industry because in jobs offer (at least in France) they never mention Pig only Hive&lt;/p&gt;\n\n&lt;p&gt;Ty&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15iyfjx", "is_robot_indexable": true, "report_reasons": null, "author": "rxmi_bkd_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iyfjx/is_apache_pig_used_in_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iyfjx/is_apache_pig_used_in_industry/", "subreddit_subscribers": 120938, "created_utc": 1691248953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data engineer with 6+ years of experience. We have built pipelines to bring data into our warehouse. Now my manager says \"now that we have brought in a lot of data, lets analyze it to find if we can provide the company with some insights on the data.\" Shouldn't this be the other way round where we know what we are looking for?\nShould i start transitioning into a data analyst? If yes, what are the ways to get started?", "author_fullname": "t2_eobyj34v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Conundrum", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ioiih", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691218620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data engineer with 6+ years of experience. We have built pipelines to bring data into our warehouse. Now my manager says &amp;quot;now that we have brought in a lot of data, lets analyze it to find if we can provide the company with some insights on the data.&amp;quot; Shouldn&amp;#39;t this be the other way round where we know what we are looking for?\nShould i start transitioning into a data analyst? If yes, what are the ways to get started?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ioiih", "is_robot_indexable": true, "report_reasons": null, "author": "Stoic_Akshay", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ioiih/conundrum/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ioiih/conundrum/", "subreddit_subscribers": 120938, "created_utc": 1691218620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need some advice on my use case. I have a table which has the list of assets in the organization and I am working on a project where we are required to compute a security score for all assets. The algorithm and parameters used for various asset types is different and I decided to create a staging table to compute the score and later join to the primary dim table to store the score. However I received push back during a review as this requires a separate pipeline and storage requirements. I wanted some advice on the approach I should use and pros and cons on these approaches. I feel merging these computations to the existing pipeline can make it complex. Can some who has worked on something similar share some advice on what the pro and con is for these approaches and why i should use one versus other.", "author_fullname": "t2_kb23rcjq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on creating a separate staging table versus computing in the same pipeline.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15io4u9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691217251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need some advice on my use case. I have a table which has the list of assets in the organization and I am working on a project where we are required to compute a security score for all assets. The algorithm and parameters used for various asset types is different and I decided to create a staging table to compute the score and later join to the primary dim table to store the score. However I received push back during a review as this requires a separate pipeline and storage requirements. I wanted some advice on the approach I should use and pros and cons on these approaches. I feel merging these computations to the existing pipeline can make it complex. Can some who has worked on something similar share some advice on what the pro and con is for these approaches and why i should use one versus other.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15io4u9", "is_robot_indexable": true, "report_reasons": null, "author": "SweetAbject2153", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15io4u9/advice_on_creating_a_separate_staging_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15io4u9/advice_on_creating_a_separate_staging_table/", "subreddit_subscribers": 120938, "created_utc": 1691217251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nWe are going to work on building data foundation for an on-demand Fitness app called **DashFit**. In this application, we have the following components:\n\n* Users sign up with the app to access video of the workout content.\n* There are multiple workout categories offered in the app e.g. Yoga, HIIT, Stretch.\n* Each category can have multiple classes offered under them. Each class will have 1 primary category but can belong to more than one category (e.g. Yoga &amp; stretch).\n* There are trainers who record these classes, and one trainer can offer several different classes (yoga &amp; HIIT from the same instructor).\n\nNow, you are responsible for modeling the data foundation to track the success of this product. \n\n&amp;#x200B;\n\nSuccess metric:\n\n Avg 7-day usage = for any active user in the last 7 days, what is the avg number of days they were \u201cactive\u201d in those 7 days? \n\n&amp;#x200B;\n\nMy answer\n\nFirst, schema design:\n\n&amp;#x200B;\n\n**dim\\_user:**\n\n* **user\\_id**\n* **email**\n* **name**\n* **sign\\_up\\_date**\n\n**dim\\_trainers:**\n\n* **trainer\\_id**\n* **trainer\\_name**\n* **sign\\_up\\_date**\n* **cateogry\\_id (FK)**\n\n**dim\\_classes:**\n\n* **class\\_id (PK)**\n* **category\\_id (FK)**\n* **class\\_name**\n\n**dim\\_category:**\n\n* **category\\_id (PK)**\n* **category\\_name**\n\n**fact\\_activity\\_video:**\n\n* **user\\_id**\n* **timestart**\n* **timestop** \n* **video\\_length**\n* **class\\_id**\n* **trainer\\_id**\n\n&amp;#x200B;\n\n=========================\n\n Then SQL. \n\n&amp;#x200B;\n\n**With active\\_users AS (**\n\n**SELECT \\*,**\n\n**CASE**\n\n**WHEN (timeend - timestart) &gt;= video\\_length/2**\n\n**THEN 1**\n\n**ELSE 0**\n\n**as is\\_active**\n\n**FROM fact\\_activity\\_video**\n\n**),**\n\n**With all\\_users AS (**\n\n**SELECT user\\_id, COUNT(DISTINCT CAST(timestart as DATE)) as tot\\_days**\n\n**FROM active\\_users**\n\n**WHERE is\\_active = 1**\n\n**AND CAST(timestart as DATE) &gt;= TODAY() - 7**\n\n**GROUP BY user\\_id**\n\n**)**\n\n**SELECT AVG(tot\\_days) FROM all\\_users**", "author_fullname": "t2_a9ij7ckc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BI engineer interview question - Feedback please", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15imc1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691211255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are going to work on building data foundation for an on-demand Fitness app called &lt;strong&gt;DashFit&lt;/strong&gt;. In this application, we have the following components:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Users sign up with the app to access video of the workout content.&lt;/li&gt;\n&lt;li&gt;There are multiple workout categories offered in the app e.g. Yoga, HIIT, Stretch.&lt;/li&gt;\n&lt;li&gt;Each category can have multiple classes offered under them. Each class will have 1 primary category but can belong to more than one category (e.g. Yoga &amp;amp; stretch).&lt;/li&gt;\n&lt;li&gt;There are trainers who record these classes, and one trainer can offer several different classes (yoga &amp;amp; HIIT from the same instructor).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Now, you are responsible for modeling the data foundation to track the success of this product. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Success metric:&lt;/p&gt;\n\n&lt;p&gt;Avg 7-day usage = for any active user in the last 7 days, what is the avg number of days they were \u201cactive\u201d in those 7 days? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My answer&lt;/p&gt;\n\n&lt;p&gt;First, schema design:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;dim_user:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;user_id&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;email&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;name&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;sign_up_date&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;dim_trainers:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;trainer_id&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;trainer_name&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;sign_up_date&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;cateogry_id (FK)&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;dim_classes:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;class_id (PK)&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;category_id (FK)&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;class_name&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;dim_category:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;category_id (PK)&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;category_name&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;fact_activity_video:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;user_id&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;timestart&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;timestop&lt;/strong&gt; &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;video_length&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;class_id&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;trainer_id&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h1&gt;&lt;/h1&gt;\n\n&lt;p&gt;Then SQL. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;With active_users AS (&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;SELECT *,&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;CASE&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;WHEN (timeend - timestart) &amp;gt;= video_length/2&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;THEN 1&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;ELSE 0&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;as is_active&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;FROM fact_activity_video&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;),&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;With all_users AS (&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;SELECT user_id, COUNT(DISTINCT CAST(timestart as DATE)) as tot_days&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;FROM active_users&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;WHERE is_active = 1&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;AND CAST(timestart as DATE) &amp;gt;= TODAY() - 7&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;GROUP BY user_id&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;SELECT AVG(tot_days) FROM all_users&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15imc1q", "is_robot_indexable": true, "report_reasons": null, "author": "thriftyberry", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15imc1q/bi_engineer_interview_question_feedback_please/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15imc1q/bi_engineer_interview_question_feedback_please/", "subreddit_subscribers": 120938, "created_utc": 1691211255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_i0qyphvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A how-to-guide for building Fivetran data lineage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 95, "top_awarded_type": null, "hide_score": false, "name": "t3_15i5662", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/okSO9OD_vtx8VVNh99oLJm2er50-d_ufGcBU5_rIXeQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691167586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.grai.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.grai.io/extracting-fivetran-data-lineag/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LmM-WK8msIpdPIBwGyV-zJ7ghruaWUny1DryZly_0G8.jpg?auto=webp&amp;s=378470206e2b11090bf8e66e8a4835dfa5a5293a", "width": 2000, "height": 1365}, "resolutions": [{"url": "https://external-preview.redd.it/LmM-WK8msIpdPIBwGyV-zJ7ghruaWUny1DryZly_0G8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=949fe76bc0dab2518d219f437fc3fb0f39917ab9", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/LmM-WK8msIpdPIBwGyV-zJ7ghruaWUny1DryZly_0G8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3feef2a4c21042a51a7fb2f6613fc7fef66d575e", "width": 216, "height": 147}, {"url": "https://external-preview.redd.it/LmM-WK8msIpdPIBwGyV-zJ7ghruaWUny1DryZly_0G8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ee112a3c1e5439c849875b48585727a0f14369d1", "width": 320, "height": 218}, {"url": "https://external-preview.redd.it/LmM-WK8msIpdPIBwGyV-zJ7ghruaWUny1DryZly_0G8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fdd90616bbecf32280b6615061885795b7aa35a6", "width": 640, "height": 436}, {"url": "https://external-preview.redd.it/LmM-WK8msIpdPIBwGyV-zJ7ghruaWUny1DryZly_0G8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=55fb1c6e5c3b0165d886fe346fbe7def7e6a3d80", "width": 960, "height": 655}, {"url": "https://external-preview.redd.it/LmM-WK8msIpdPIBwGyV-zJ7ghruaWUny1DryZly_0G8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cb2fec32e404cd70895457238a162013a7901547", "width": 1080, "height": 737}], "variants": {}, "id": "75HGScCuZTm94ZuOQcZsMhCT7Wv3FpSGPhAabJdB0tA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15i5662", "is_robot_indexable": true, "report_reasons": null, "author": "ProfessionalHorse707", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15i5662/a_howtoguide_for_building_fivetran_data_lineage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.grai.io/extracting-fivetran-data-lineag/", "subreddit_subscribers": 120938, "created_utc": 1691167586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to figure out how to do a rotated personal access token from Databricks into a Power BI Dataset but for the life of me I cannot figure out how to properly syntax the api call into PowerBI to update the key value, if anyone has experience with this I would be grateful.\n\nI know its a long shot but I am out of other ideas then throwing it out into the internet and hoping for the best.", "author_fullname": "t2_8wk1hrsn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using Databricks to Power BI?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15i4sll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691166722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to figure out how to do a rotated personal access token from Databricks into a Power BI Dataset but for the life of me I cannot figure out how to properly syntax the api call into PowerBI to update the key value, if anyone has experience with this I would be grateful.&lt;/p&gt;\n\n&lt;p&gt;I know its a long shot but I am out of other ideas then throwing it out into the internet and hoping for the best.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15i4sll", "is_robot_indexable": true, "report_reasons": null, "author": "epicfaceman97", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15i4sll/anyone_using_databricks_to_power_bi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15i4sll/anyone_using_databricks_to_power_bi/", "subreddit_subscribers": 120938, "created_utc": 1691166722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I posted to this reddit a week ago and it got removed (not sure why as it was a genuine \"where to start\" kind of post. Hopefully this one does not get removed.)\n\n&amp;#x200B;\n\nI have been self teaching myself SQL (via SQLBOLT, brain is currently mush trying to understand LEFT JOIN clause) for the last week with zero coding skills prior (Economics major and have worked in Finance Analyst for last 7 years) and wanted to know how I can use SQL in my current position to get me ready for becoming a Data Analyst in 2 years (end goal is to become a Data Engineer but I understand I would need some experience in data in order to make that big of a jump, hence DA first then DE in my roadmap)\n\nI work in excel a sh\\*t ton so maybe I can start there if possible to use SQL in excel? Just wanted some input from those on the \"inside\" on what I can do in order to become proficient in SQL in my current function before attempting to jump over to a DA role. Studying SQL on the side is obviously going to help, but I want to also try and use what I am studying in my current role to further solidify what I am learning. \n\n&amp;#x200B;\n\nSELECT How To\n\nFROM Help", "author_fullname": "t2_22q9pua0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How To utilize SQL in current job to get ready for next step? (pls dont remove this post)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ix0ey", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691245638.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691245408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I posted to this reddit a week ago and it got removed (not sure why as it was a genuine &amp;quot;where to start&amp;quot; kind of post. Hopefully this one does not get removed.)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have been self teaching myself SQL (via SQLBOLT, brain is currently mush trying to understand LEFT JOIN clause) for the last week with zero coding skills prior (Economics major and have worked in Finance Analyst for last 7 years) and wanted to know how I can use SQL in my current position to get me ready for becoming a Data Analyst in 2 years (end goal is to become a Data Engineer but I understand I would need some experience in data in order to make that big of a jump, hence DA first then DE in my roadmap)&lt;/p&gt;\n\n&lt;p&gt;I work in excel a sh*t ton so maybe I can start there if possible to use SQL in excel? Just wanted some input from those on the &amp;quot;inside&amp;quot; on what I can do in order to become proficient in SQL in my current function before attempting to jump over to a DA role. Studying SQL on the side is obviously going to help, but I want to also try and use what I am studying in my current role to further solidify what I am learning. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;SELECT How To&lt;/p&gt;\n\n&lt;p&gt;FROM Help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ix0ey", "is_robot_indexable": true, "report_reasons": null, "author": "PoloParachutes", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ix0ey/how_to_utilize_sql_in_current_job_to_get_ready/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ix0ey/how_to_utilize_sql_in_current_job_to_get_ready/", "subreddit_subscribers": 120938, "created_utc": 1691245408.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}