{"kind": "Listing", "data": {"after": "t3_15t5pat", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there,\n\nI already have a job and this position is paying 160k in MA area and is looking to conduct 5 interview rounds.\n\n3 on one day starting 11 am until 2 pm. with three different individuals\n\nand \n\n2 on another day from 10 until 12 with 2 other individuals.\n\n&amp;#x200B;\n\nI had asked them to respect my time and have two one hour interviews but they sent this anyways.\n\nI feel like just saying no to this. This is getting out of hand.\n\nUnless they want to pay 300k, I feel like this would just waste of my time.", "author_fullname": "t2_kz99f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One company wants me to attend 5 interview rounds in 2 days. Even worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15trl9q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692287948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I already have a job and this position is paying 160k in MA area and is looking to conduct 5 interview rounds.&lt;/p&gt;\n\n&lt;p&gt;3 on one day starting 11 am until 2 pm. with three different individuals&lt;/p&gt;\n\n&lt;p&gt;and &lt;/p&gt;\n\n&lt;p&gt;2 on another day from 10 until 12 with 2 other individuals.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I had asked them to respect my time and have two one hour interviews but they sent this anyways.&lt;/p&gt;\n\n&lt;p&gt;I feel like just saying no to this. This is getting out of hand.&lt;/p&gt;\n\n&lt;p&gt;Unless they want to pay 300k, I feel like this would just waste of my time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15trl9q", "is_robot_indexable": true, "report_reasons": null, "author": "jerrie86", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15trl9q/one_company_wants_me_to_attend_5_interview_rounds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15trl9q/one_company_wants_me_to_attend_5_interview_rounds/", "subreddit_subscribers": 123265, "created_utc": 1692287948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi friends, I'm hearing this from a friend but didn't get the chance to get the details. Basically in his company the BIs are ONLY using Redshift, and he said it is a bad thing. I have no experience with Redshift but I work in a GCP shop where we mostly use Google Bigquery and I didn't see any issue.\n\nWhat could the issue if Redshift is the only DB BI is using? I assume this is going to be data warehousing as BI is the user.", "author_fullname": "t2_bmsha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the risk of using Redshift as the only database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15t5otn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692228178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends, I&amp;#39;m hearing this from a friend but didn&amp;#39;t get the chance to get the details. Basically in his company the BIs are ONLY using Redshift, and he said it is a bad thing. I have no experience with Redshift but I work in a GCP shop where we mostly use Google Bigquery and I didn&amp;#39;t see any issue.&lt;/p&gt;\n\n&lt;p&gt;What could the issue if Redshift is the only DB BI is using? I assume this is going to be data warehousing as BI is the user.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15t5otn", "is_robot_indexable": true, "report_reasons": null, "author": "levelworm", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15t5otn/what_is_the_risk_of_using_redshift_as_the_only/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15t5otn/what_is_the_risk_of_using_redshift_as_the_only/", "subreddit_subscribers": 123265, "created_utc": 1692228178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Only database we use currently, someone asked about redshift and it made me think of this", "author_fullname": "t2_e0rep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a risk of using just Postgres as the only database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15t89km", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692234551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Only database we use currently, someone asked about redshift and it made me think of this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15t89km", "is_robot_indexable": true, "report_reasons": null, "author": "BiggyDeeKay", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15t89km/is_there_a_risk_of_using_just_postgres_as_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15t89km/is_there_a_risk_of_using_just_postgres_as_the/", "subreddit_subscribers": 123265, "created_utc": 1692234551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Tools experience also works too.\n\nBasically what level of familiarity did you have with the topic in general?", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much \"data\" experience did you have before getting your first data engineering job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tqf1i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692285297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tools experience also works too.&lt;/p&gt;\n\n&lt;p&gt;Basically what level of familiarity did you have with the topic in general?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15tqf1i", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tqf1i/how_much_data_experience_did_you_have_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tqf1i/how_much_data_experience_did_you_have_before/", "subreddit_subscribers": 123265, "created_utc": 1692285297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys. So I've been working in Bangalore in an MNC for about 3 years now as an associate data engineer.\n\nBefore joining this company, I was an energetic, ambitious and hard working guy and was expecting a lot of developement work from my company. I was pretty good in coding and app development compared to my peers in college. \n\nBut after I joined my first company, things seemed alright. They put me mostly into SQL scripting work which was mostly SQL logic and nothing much of a development. I had even taken a home loan because me and my family had never actually owned a house so even after a year of SQL scripting, I thought I'll continue in the same company hoping to get a better project. This now turned from 1 year to 2 years and then 2 years to 3 years now and these guys have gotten me in the same project. My day to day work is almost the same as what I used to do the day I joined. I've asked my manager multiple times to give me some good project but they keep saying, just wait, we'll get you something good. Sometimes they say, you need to be \"proactive\" and create your own PoC project. I did learn stuff via courses but I feel that if we don't get any projects related to what we studied, it's of no use. I don't even have any teamate who is a data engineers to guild me since the last 2 years. My product manager doesn't care about me or my ambition. They keep dumping the same work over and over.\n\nIt sickens me to think that, all those years in college where I put more effort into programming, and my managers haven't utilised me at all. All my friends who wasted time and had fun in college are now earning better than me and are in good projects. \n\nNow, I am trying to search jobs in other companies and I see that the market expects a lot from a 3 year experienced guy. I feel very incompetent, very anxious thinking that no one might employee me because of my lack of exposure. \n\nMy question here is, is there any way where I can start over as a data engineer where I can apply for fresher job or a 1 year experience job in decent product based companies (I've seen third party company employees being treated like dirt, with constant threat of getting released from the project). I wouldn't mind having the same salary or even slightly lesser (10-20% lower) but is such a thing possible where I go to a company which is offering a 1 year experience job. I explain them what actually happened in my company, how I've got to work only on SQL and expect them to train in and put me in a good development project. Are such things possible in IT field? Please let me know your thoughts. \n\nThank you.", "author_fullname": "t2_is9w2714", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "3 years of work and I still feel like a fresher", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15t7wii", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692233668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. So I&amp;#39;ve been working in Bangalore in an MNC for about 3 years now as an associate data engineer.&lt;/p&gt;\n\n&lt;p&gt;Before joining this company, I was an energetic, ambitious and hard working guy and was expecting a lot of developement work from my company. I was pretty good in coding and app development compared to my peers in college. &lt;/p&gt;\n\n&lt;p&gt;But after I joined my first company, things seemed alright. They put me mostly into SQL scripting work which was mostly SQL logic and nothing much of a development. I had even taken a home loan because me and my family had never actually owned a house so even after a year of SQL scripting, I thought I&amp;#39;ll continue in the same company hoping to get a better project. This now turned from 1 year to 2 years and then 2 years to 3 years now and these guys have gotten me in the same project. My day to day work is almost the same as what I used to do the day I joined. I&amp;#39;ve asked my manager multiple times to give me some good project but they keep saying, just wait, we&amp;#39;ll get you something good. Sometimes they say, you need to be &amp;quot;proactive&amp;quot; and create your own PoC project. I did learn stuff via courses but I feel that if we don&amp;#39;t get any projects related to what we studied, it&amp;#39;s of no use. I don&amp;#39;t even have any teamate who is a data engineers to guild me since the last 2 years. My product manager doesn&amp;#39;t care about me or my ambition. They keep dumping the same work over and over.&lt;/p&gt;\n\n&lt;p&gt;It sickens me to think that, all those years in college where I put more effort into programming, and my managers haven&amp;#39;t utilised me at all. All my friends who wasted time and had fun in college are now earning better than me and are in good projects. &lt;/p&gt;\n\n&lt;p&gt;Now, I am trying to search jobs in other companies and I see that the market expects a lot from a 3 year experienced guy. I feel very incompetent, very anxious thinking that no one might employee me because of my lack of exposure. &lt;/p&gt;\n\n&lt;p&gt;My question here is, is there any way where I can start over as a data engineer where I can apply for fresher job or a 1 year experience job in decent product based companies (I&amp;#39;ve seen third party company employees being treated like dirt, with constant threat of getting released from the project). I wouldn&amp;#39;t mind having the same salary or even slightly lesser (10-20% lower) but is such a thing possible where I go to a company which is offering a 1 year experience job. I explain them what actually happened in my company, how I&amp;#39;ve got to work only on SQL and expect them to train in and put me in a good development project. Are such things possible in IT field? Please let me know your thoughts. &lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15t7wii", "is_robot_indexable": true, "report_reasons": null, "author": "walter_bhai", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15t7wii/3_years_of_work_and_i_still_feel_like_a_fresher/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15t7wii/3_years_of_work_and_i_still_feel_like_a_fresher/", "subreddit_subscribers": 123265, "created_utc": 1692233668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it due to the increasing difficulty of finding Data Engineers or just companies trying to collect CV for possible future recruitments?", "author_fullname": "t2_8ijlo4rl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A lot of \"reposted\" jobs on LinkedIn", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tnkef", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692278691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it due to the increasing difficulty of finding Data Engineers or just companies trying to collect CV for possible future recruitments?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15tnkef", "is_robot_indexable": true, "report_reasons": null, "author": "Noway721", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tnkef/a_lot_of_reposted_jobs_on_linkedin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tnkef/a_lot_of_reposted_jobs_on_linkedin/", "subreddit_subscribers": 123265, "created_utc": 1692278691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_s63bu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fast access to training data for ML using DuckDB and ArrowFlight", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15tmgln", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nesD4FNXy7nBOfJgfcp_U98d0fHwHnFhhjvLzkuxOzo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692276215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hopsworks.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.hopsworks.ai/post/python-centric-feature-service-with-arrowflight-and-duckdb", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?auto=webp&amp;s=b4dbff81b3d60c0d5b10398cbb7ad8b8f49d18e4", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=454b24dd1331e9d874860de1e9d40c3a939b0327", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dfbe414118cf248f5eb082d36641f064766c10ce", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7db8e55a7d3e25eb65721d05449ab0e7096c7315", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9679f131a6c5d1d1860cc9a14884f7a66137efc9", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cb5c04b6009148943e51787b7b1ffeaed607c818", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4b2cd653bc25f99e895e380db6a91d99ab75ea0c", "width": 1080, "height": 567}], "variants": {}, "id": "cshXE1zE9RNFAI9a-Ajpp18V8vqIauNFQE-MA9SsDds"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15tmgln", "is_robot_indexable": true, "report_reasons": null, "author": "SirOibaf", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tmgln/fast_access_to_training_data_for_ml_using_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.hopsworks.ai/post/python-centric-feature-service-with-arrowflight-and-duckdb", "subreddit_subscribers": 123265, "created_utc": 1692276215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nWe have our DAGs setup to run Based on events in database(s3). Setup is as below.\n\nS3 -&gt; SQS -&gt; Lambda -&gt; Airflow\n\nWe have audit table to capture the new files and some Metadata. Works seamlessly. \n\nProblem We have is, we are unable to alert if the file doesn't arrive for a day. As the DAGs aren't scheduled we cannot use any of Airflow's features like sla etc.\n\nNeed help on 2 things -\nHow to setup alerting if files don't arrive?\nCan we setup calendars to see If the file arriving is actually the expected one?", "author_fullname": "t2_6kmo2ecy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event Based Airflow DAGs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15t9qc3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692238292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We have our DAGs setup to run Based on events in database(s3). Setup is as below.&lt;/p&gt;\n\n&lt;p&gt;S3 -&amp;gt; SQS -&amp;gt; Lambda -&amp;gt; Airflow&lt;/p&gt;\n\n&lt;p&gt;We have audit table to capture the new files and some Metadata. Works seamlessly. &lt;/p&gt;\n\n&lt;p&gt;Problem We have is, we are unable to alert if the file doesn&amp;#39;t arrive for a day. As the DAGs aren&amp;#39;t scheduled we cannot use any of Airflow&amp;#39;s features like sla etc.&lt;/p&gt;\n\n&lt;p&gt;Need help on 2 things -\nHow to setup alerting if files don&amp;#39;t arrive?\nCan we setup calendars to see If the file arriving is actually the expected one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15t9qc3", "is_robot_indexable": true, "report_reasons": null, "author": "soujoshi", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15t9qc3/event_based_airflow_dags/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15t9qc3/event_based_airflow_dags/", "subreddit_subscribers": 123265, "created_utc": 1692238292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, \nHow do you all do it basically?\nI am a young data scientist (even though most of my job title is DE ) ans sometimes I really struggle to not feel defeated by my current role. \nLike I feel I am getting no support with a lot of my pipelines never being validated as we lack any senior peoples, having to do quick fixes after quick fixes, dealing with rubbish data or having to deal with some confusing other companies (like today was sending an update to one of our contact as the data their API was showing was not up to date, turns out their API is not pulling from their live dB \ud83d\ude2b).\nI enjoy it and everyone on my team is happy with my work but it feels it is impacting my wellbeing and wonder if I should just quit.\nMain problem being my background is not in data so finding another role is a lot harder. \nAny advice?", "author_fullname": "t2_aflyojn9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Handling the pressure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tslrw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692290288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, \nHow do you all do it basically?\nI am a young data scientist (even though most of my job title is DE ) ans sometimes I really struggle to not feel defeated by my current role. \nLike I feel I am getting no support with a lot of my pipelines never being validated as we lack any senior peoples, having to do quick fixes after quick fixes, dealing with rubbish data or having to deal with some confusing other companies (like today was sending an update to one of our contact as the data their API was showing was not up to date, turns out their API is not pulling from their live dB \ud83d\ude2b).\nI enjoy it and everyone on my team is happy with my work but it feels it is impacting my wellbeing and wonder if I should just quit.\nMain problem being my background is not in data so finding another role is a lot harder. \nAny advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15tslrw", "is_robot_indexable": true, "report_reasons": null, "author": "SuperFrenchie19", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tslrw/handling_the_pressure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tslrw/handling_the_pressure/", "subreddit_subscribers": 123265, "created_utc": 1692290288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Souce: Bigquery\nTables: 200+\nSize: approx 100gb per table some of them are 750gb around with approx 900m rows\n\nDestination: Google Cloud sql Postgres (quite beefed up instance with 40gb memory and 50tb ssds) \n\nFivetran Connectors fail for multiple reasons..viz, reschedules, db query timeout (all timeouts are set to unlimited)\n\nWhile Fivetran works for smaller size tables, It looks like Fivetran is not capable of for bigger tables say 200gb plus.. \n\nFivetran or Google support has been of no use, 3 months of efforts are wasted. Why it was choosen at first place; Or what was business thinking has no answers! Make your peace with it! \n\nIs there other way than using postgres copy command from extrated files in gcp bucket. Did anyone experience similar kind of scenario? Any suggestion / discussion / advice is appreciated.", "author_fullname": "t2_1l9tu7ql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran for large loads", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tiq2h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692265689.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Souce: Bigquery\nTables: 200+\nSize: approx 100gb per table some of them are 750gb around with approx 900m rows&lt;/p&gt;\n\n&lt;p&gt;Destination: Google Cloud sql Postgres (quite beefed up instance with 40gb memory and 50tb ssds) &lt;/p&gt;\n\n&lt;p&gt;Fivetran Connectors fail for multiple reasons..viz, reschedules, db query timeout (all timeouts are set to unlimited)&lt;/p&gt;\n\n&lt;p&gt;While Fivetran works for smaller size tables, It looks like Fivetran is not capable of for bigger tables say 200gb plus.. &lt;/p&gt;\n\n&lt;p&gt;Fivetran or Google support has been of no use, 3 months of efforts are wasted. Why it was choosen at first place; Or what was business thinking has no answers! Make your peace with it! &lt;/p&gt;\n\n&lt;p&gt;Is there other way than using postgres copy command from extrated files in gcp bucket. Did anyone experience similar kind of scenario? Any suggestion / discussion / advice is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15tiq2h", "is_robot_indexable": true, "report_reasons": null, "author": "onksssss", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tiq2h/fivetran_for_large_loads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tiq2h/fivetran_for_large_loads/", "subreddit_subscribers": 123265, "created_utc": 1692265689.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nMy question is pretty much the same but I will add more context.\n\nI am 26 yo, senior data engineer with 5 years of industry experience.\n\ni am from a South Asian country (Not India), I did my bachelors in Software Engineering here, worked for around 3 years here and then found a job and moved to Germany.\n\nNow, in Germany, work life balance is good, you get all the state benefits, vacations, sick leaves all of it. If I think in the long term, it's a very safe country, humans are valued, socially you are secure etc, which makes life quite peaceful.\n\nOn the other side, you have to learn the language to get permanent here, I earn like 80k euroes per year and being single around 40% of my salary goes to taxes, which of course is an investment for my and my family's future, and lots of pretty places nearby to travel to and spend time at.\n\nBUT, having your family move here is a huge pain in the ass if you get married back in your home country after moving here, it's almost impossible to have your parents visit you or move with you, and your buying power is less and you have to live in relatively smaller apartments/houses.\n\nRecently, I came across a VISA for permanently moving to US which i could be eligible for, I reached out to some immigration lawyers and most of them said I am likely to get it and I can apply for it,\n\nNow, this whole process is going to cost me almost all of my savings in legal fee and so, but what I am confused about is it worth it? Will I be able to find a job there with my South Asian university degree in US?\n\nOn one hand I see people with even average incomes in the US living in big houses driving nice cars, but on the other hand I see that it's not safe, you can be homeless or on the street, but on the other hand I see so many people living prosperous lives there (I am not talking about outliers or celeberities). Your parents can visit you with multiple entry visas, the market is bigger (but obviously more competetive as well).\n\nI have never been truly jobless in my life, I once got affected by mass layoffs but even then I found another job before my guardian period even expired.\n\nI also feel like if in US I could earn more, I could, may be, save in my young years and invest in some assests for passive income in my later years whihc seems very difficult here in Germany as after taxes, rent, expenses and family support you are barely left with anything.\n\nAnd when I talked to other people here I realised I am payed very good salary for my experience bracket.\n\nSo people who have worked in both countries or people who are working in CS careers in the US, what would you recommend in this situation?\n\nI am 26 yo already, just yesterday I remember completing my bachers at 21, and life doesn't stop. I want to put my mind to peace if i should just accept this place to be my home and spend all my energy here or try to move to a place with better prospects.", "author_fullname": "t2_rol5v4w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I move to the US or should I stay in Germany?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15txz1z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692302439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;My question is pretty much the same but I will add more context.&lt;/p&gt;\n\n&lt;p&gt;I am 26 yo, senior data engineer with 5 years of industry experience.&lt;/p&gt;\n\n&lt;p&gt;i am from a South Asian country (Not India), I did my bachelors in Software Engineering here, worked for around 3 years here and then found a job and moved to Germany.&lt;/p&gt;\n\n&lt;p&gt;Now, in Germany, work life balance is good, you get all the state benefits, vacations, sick leaves all of it. If I think in the long term, it&amp;#39;s a very safe country, humans are valued, socially you are secure etc, which makes life quite peaceful.&lt;/p&gt;\n\n&lt;p&gt;On the other side, you have to learn the language to get permanent here, I earn like 80k euroes per year and being single around 40% of my salary goes to taxes, which of course is an investment for my and my family&amp;#39;s future, and lots of pretty places nearby to travel to and spend time at.&lt;/p&gt;\n\n&lt;p&gt;BUT, having your family move here is a huge pain in the ass if you get married back in your home country after moving here, it&amp;#39;s almost impossible to have your parents visit you or move with you, and your buying power is less and you have to live in relatively smaller apartments/houses.&lt;/p&gt;\n\n&lt;p&gt;Recently, I came across a VISA for permanently moving to US which i could be eligible for, I reached out to some immigration lawyers and most of them said I am likely to get it and I can apply for it,&lt;/p&gt;\n\n&lt;p&gt;Now, this whole process is going to cost me almost all of my savings in legal fee and so, but what I am confused about is it worth it? Will I be able to find a job there with my South Asian university degree in US?&lt;/p&gt;\n\n&lt;p&gt;On one hand I see people with even average incomes in the US living in big houses driving nice cars, but on the other hand I see that it&amp;#39;s not safe, you can be homeless or on the street, but on the other hand I see so many people living prosperous lives there (I am not talking about outliers or celeberities). Your parents can visit you with multiple entry visas, the market is bigger (but obviously more competetive as well).&lt;/p&gt;\n\n&lt;p&gt;I have never been truly jobless in my life, I once got affected by mass layoffs but even then I found another job before my guardian period even expired.&lt;/p&gt;\n\n&lt;p&gt;I also feel like if in US I could earn more, I could, may be, save in my young years and invest in some assests for passive income in my later years whihc seems very difficult here in Germany as after taxes, rent, expenses and family support you are barely left with anything.&lt;/p&gt;\n\n&lt;p&gt;And when I talked to other people here I realised I am payed very good salary for my experience bracket.&lt;/p&gt;\n\n&lt;p&gt;So people who have worked in both countries or people who are working in CS careers in the US, what would you recommend in this situation?&lt;/p&gt;\n\n&lt;p&gt;I am 26 yo already, just yesterday I remember completing my bachers at 21, and life doesn&amp;#39;t stop. I want to put my mind to peace if i should just accept this place to be my home and spend all my energy here or try to move to a place with better prospects.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15txz1z", "is_robot_indexable": true, "report_reasons": null, "author": "Botmon_DaDorkNight", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15txz1z/should_i_move_to_the_us_or_should_i_stay_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15txz1z/should_i_move_to_the_us_or_should_i_stay_in/", "subreddit_subscribers": 123265, "created_utc": 1692302439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is currently in the process of moving ELT process from IBM DataStage to python. We are currently researching using pyspark which seemed to be a pretty promising tool until we tried writing large files to relational databases with concurrent sessions. The file I am trying to write is about 10g large with over 700 columns in it and spark seems to read the file incredibly fast but databases are a big bottleneck. We currently have 2 types of relational databases that within our warehouse which are SQL Server and Teradata. SQL Server gets about half way through the load and crashes due to a overwhelming amount of transaction logs being written and Teradata will block more than 1 session trying to write to a database. \n\nAfter this research I feel like I am doing something wrong. Is spark the best tool for this job? Is there a  certain design that can avoid this issue? ", "author_fullname": "t2_6lh4st48", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Spark to Migrating Data to Relational Databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15trsml", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692288387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is currently in the process of moving ELT process from IBM DataStage to python. We are currently researching using pyspark which seemed to be a pretty promising tool until we tried writing large files to relational databases with concurrent sessions. The file I am trying to write is about 10g large with over 700 columns in it and spark seems to read the file incredibly fast but databases are a big bottleneck. We currently have 2 types of relational databases that within our warehouse which are SQL Server and Teradata. SQL Server gets about half way through the load and crashes due to a overwhelming amount of transaction logs being written and Teradata will block more than 1 session trying to write to a database. &lt;/p&gt;\n\n&lt;p&gt;After this research I feel like I am doing something wrong. Is spark the best tool for this job? Is there a  certain design that can avoid this issue? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15trsml", "is_robot_indexable": true, "report_reasons": null, "author": "Equivalent_Bluebird7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15trsml/using_spark_to_migrating_data_to_relational/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15trsml/using_spark_to_migrating_data_to_relational/", "subreddit_subscribers": 123265, "created_utc": 1692288387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_io93l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Passwordless Schema Migrations on RDS with Atlas | Atlas | Open-source database schema management tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_15tia33", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vecx1oVMUlPAM9MLSxYASiHqXTsyQh2L8HlgszxlSFw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692264237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "atlasgo.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://atlasgo.io/blog/2023/08/16/passwordless-migrations?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=iamauth", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/R94r9K1y5Vm8Y6JkJxzLgK-rtZ3ogz_B6J9VHtwXjwk.jpg?auto=webp&amp;s=dbbf208807a0b26f2fc7a9c8fe42793c1fb764b9", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/R94r9K1y5Vm8Y6JkJxzLgK-rtZ3ogz_B6J9VHtwXjwk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=723883edc0534e3eec1f47de19328715f473b84e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/R94r9K1y5Vm8Y6JkJxzLgK-rtZ3ogz_B6J9VHtwXjwk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3119735fcf87d5acb8bd3163c070b09579a8da33", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/R94r9K1y5Vm8Y6JkJxzLgK-rtZ3ogz_B6J9VHtwXjwk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4a4224baa1b43ecf282830c687e499d5b28cb41", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/R94r9K1y5Vm8Y6JkJxzLgK-rtZ3ogz_B6J9VHtwXjwk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fef337014530d3dfcc77685de7a85d80393bb71e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/R94r9K1y5Vm8Y6JkJxzLgK-rtZ3ogz_B6J9VHtwXjwk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=def9b289435b66635ed7dd202f1fba996eff7282", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/R94r9K1y5Vm8Y6JkJxzLgK-rtZ3ogz_B6J9VHtwXjwk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=580db82a00a697b34c034936e05d39c88e61f60c", "width": 1080, "height": 607}], "variants": {}, "id": "6GrXmrVgv4FvjczM_3MEr-ZFORY1IovI5AUV_nfXhug"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15tia33", "is_robot_indexable": true, "report_reasons": null, "author": "rotemtam", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tia33/passwordless_schema_migrations_on_rds_with_atlas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://atlasgo.io/blog/2023/08/16/passwordless-migrations?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=iamauth", "subreddit_subscribers": 123265, "created_utc": 1692264237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone. I'm a data analyst jr in a place without a data engineer, so my coworker and I are trying to design a Data Warehouse to be the source to our Power BI dashboards. \n\nWe have multiple clients and we are receiving the same type of information from each one. My proposal is to use a star schema: defining our fact tables and relation them with their corresponding dim tables. Then any calculation or aggregation would be performed in Power BI.\n\nMy coworker proposal is to use a Snowflake schema: fact tables, dim tables, and aggregated tables. For example a table for sales, with its corresponding client information (name, state, country) and aggregated table branches like Sales by client, sales by state, sales by country. Then just import those aggregated tables to Power BI.\n\nThe data would be refresh once per day or so. \n\nWith this in mind, any recommendation (besides getting a data engineer)?", "author_fullname": "t2_5i1nco5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouse with aggregated tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15t99m9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692237114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone. I&amp;#39;m a data analyst jr in a place without a data engineer, so my coworker and I are trying to design a Data Warehouse to be the source to our Power BI dashboards. &lt;/p&gt;\n\n&lt;p&gt;We have multiple clients and we are receiving the same type of information from each one. My proposal is to use a star schema: defining our fact tables and relation them with their corresponding dim tables. Then any calculation or aggregation would be performed in Power BI.&lt;/p&gt;\n\n&lt;p&gt;My coworker proposal is to use a Snowflake schema: fact tables, dim tables, and aggregated tables. For example a table for sales, with its corresponding client information (name, state, country) and aggregated table branches like Sales by client, sales by state, sales by country. Then just import those aggregated tables to Power BI.&lt;/p&gt;\n\n&lt;p&gt;The data would be refresh once per day or so. &lt;/p&gt;\n\n&lt;p&gt;With this in mind, any recommendation (besides getting a data engineer)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15t99m9", "is_robot_indexable": true, "report_reasons": null, "author": "gera0220", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15t99m9/data_warehouse_with_aggregated_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15t99m9/data_warehouse_with_aggregated_tables/", "subreddit_subscribers": 123265, "created_utc": 1692237114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear data engineers,   \n\nHere's another approach to building a customizable Modern Data Stack (MDS) in a single package.\n\nThis insightful article introduces a ***GA4*** events source in combination with **dlt**, **dbt**, **DuckDB**, **MotherDuck**, and **Metabase** for creating seamless data pipelines from scratch and deploying them to production.\n\nDive into the technical details and consider how to simplify data ingestion, transformation, and visualization. If you're passionate about data and want to explore a fresh perspective on MDS, this is a must-read!\n\n\ud83d\udcd6 Read the full article here: [Blog post](https://dlthub.com/docs/blog/dlt-motherduck-demo)\n\n\ud83c\udfa5 Watch the loom video: [Loom video](https://www.loom.com/share/2bf3a187edb54c3cae8f32b5430dd0cd?sid=c6193f1c-07cf-45b8-8fe7-2f854d098704)\n\n\ud83d\udc49 Join the conversation and gain insights from fellow enthusiasts in [the dlt Slack community!](https://join.slack.com/t/dlthub-community/shared_invite/zt-1slox199h-HAE7EQoXmstkP_bTqal65g)\n\nHappy reading!", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simplified MDS in a box! with dlt, dbt, DuckDB, MotherDuck, and Metabase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15touk8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692281687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear data engineers,   &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s another approach to building a customizable Modern Data Stack (MDS) in a single package.&lt;/p&gt;\n\n&lt;p&gt;This insightful article introduces a &lt;strong&gt;&lt;em&gt;GA4&lt;/em&gt;&lt;/strong&gt; events source in combination with &lt;strong&gt;dlt&lt;/strong&gt;, &lt;strong&gt;dbt&lt;/strong&gt;, &lt;strong&gt;DuckDB&lt;/strong&gt;, &lt;strong&gt;MotherDuck&lt;/strong&gt;, and &lt;strong&gt;Metabase&lt;/strong&gt; for creating seamless data pipelines from scratch and deploying them to production.&lt;/p&gt;\n\n&lt;p&gt;Dive into the technical details and consider how to simplify data ingestion, transformation, and visualization. If you&amp;#39;re passionate about data and want to explore a fresh perspective on MDS, this is a must-read!&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcd6 Read the full article here: &lt;a href=\"https://dlthub.com/docs/blog/dlt-motherduck-demo\"&gt;Blog post&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udfa5 Watch the loom video: &lt;a href=\"https://www.loom.com/share/2bf3a187edb54c3cae8f32b5430dd0cd?sid=c6193f1c-07cf-45b8-8fe7-2f854d098704\"&gt;Loom video&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udc49 Join the conversation and gain insights from fellow enthusiasts in &lt;a href=\"https://join.slack.com/t/dlthub-community/shared_invite/zt-1slox199h-HAE7EQoXmstkP_bTqal65g\"&gt;the dlt Slack community!&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Happy reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?auto=webp&amp;s=d391739ead216d44e810a905331dc5207e6ae30d", "width": 1226, "height": 419}, "resolutions": [{"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=98dfb0ae5b60a5e292ebfb98dfc788a08283d476", "width": 108, "height": 36}, {"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a77b0e5882d5ca28890e92adaa1fb57ca881f7e7", "width": 216, "height": 73}, {"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bffe572d02d6c77efb93beb172e6846759f1e0dd", "width": 320, "height": 109}, {"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a9085fa551306aec021df6e018b54a6d81f9ec3a", "width": 640, "height": 218}, {"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=329a29d2ec6c911e981655092a2915c63503a8cc", "width": 960, "height": 328}, {"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=862909a1d252bff7b26a3a9789690bd65f66f459", "width": 1080, "height": 369}], "variants": {}, "id": "afjYuREOaT4bQBJgRudtYf7GMXVtSBqS8UuFyHzE3NU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15touk8", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15touk8/simplified_mds_in_a_box_with_dlt_dbt_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15touk8/simplified_mds_in_a_box_with_dlt_dbt_duckdb/", "subreddit_subscribers": 123265, "created_utc": 1692281687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI've kept these doubts in my head for a few months now and thought about sharing them. Sorry if the post is quite long and personal, hopefully I will get some good advice.\n\nI got an M.Sc. in Theoretical Physics about 4 and 1/2 years ago and started working as a BI/Data analyst consultant, since I didn't want to pursue research. I worked in consultancy for about 2 years but didn't really like the job and the culture, looking around I got an offer as a Cloud Data Engineer on Azure at a small fintech startup that was just starting to build its own Data team, which is where I've been working for the last 2 years.\n\nI really enjoyed my last 2 years in this company, both the job and the colleagues were quite stimulating. The job was kind of a hybrid, even if most of the tasks revolved around building a data platform we also did a lot of different things:\n- As mentioned, we built a data platform fully on Azure cloud: data factory, databricks, pyspark, service bus, eventhub, apim etc.\n- Developed internal Python libraries, with unit tests etc.\n- Deployed REST APIs using flask/fastapi on Azure functions + APIM to expose some KPIs\n- Developed some ML models: mostly user segmentation/clustering and time series forecasting. Some of my colleagues had a Data Science background and I was involved since I studied DS in my spare time, I think these can be considered full DS projects involving research + experimentation + performances comparison + tuning + industrialization. One of these projects spanned several months and involved external consultants\n- Deployed some of the aforementioned models in production, mostly using Databricks + MLFlow + APIM for automated training, monitoring and scheduled batch serving of the model predictions\n\nIn these last 2 years, I've grown immensely both professionally and technically. So much so that recently I received an offer as a Data Engineer Tech Lead from a competitor company, which I accepted. They're building their Data Platform on a similar tech stack and I'm going to start this September. The reason I left is also because my current company isn't doing so well, so I took the opportunity. \n\nNow, this should be good news but it sparked a lot of doubts in me:\n- I feel like I kinda fell into it: I like the engineering/architecture part of DE, despise the BI/visualization part and I'm not sure what are the possible career paths from here. What are possible evolutions of my career?\n- I feel like I am not using my physics background. I have been studying Machine Learning in my spare time and was lucky enough to apply some of what I studied in my current job, but I'm not sure if that's something I would like to do the whole day, as I find the whole back and forth to improve performances of a model kind of exhausting. On the other side, I like software development but I feel out of place and that I'm wasting my skills in math/stat. I'd like to work in a more ML oriented field, but I'm not sure about how plausible and beneficial transitioning to DS or some kind of in-between role would be?", "author_fullname": "t2_e8jk0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career in the Data space", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tgg3k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692258082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve kept these doubts in my head for a few months now and thought about sharing them. Sorry if the post is quite long and personal, hopefully I will get some good advice.&lt;/p&gt;\n\n&lt;p&gt;I got an M.Sc. in Theoretical Physics about 4 and 1/2 years ago and started working as a BI/Data analyst consultant, since I didn&amp;#39;t want to pursue research. I worked in consultancy for about 2 years but didn&amp;#39;t really like the job and the culture, looking around I got an offer as a Cloud Data Engineer on Azure at a small fintech startup that was just starting to build its own Data team, which is where I&amp;#39;ve been working for the last 2 years.&lt;/p&gt;\n\n&lt;p&gt;I really enjoyed my last 2 years in this company, both the job and the colleagues were quite stimulating. The job was kind of a hybrid, even if most of the tasks revolved around building a data platform we also did a lot of different things:\n- As mentioned, we built a data platform fully on Azure cloud: data factory, databricks, pyspark, service bus, eventhub, apim etc.\n- Developed internal Python libraries, with unit tests etc.\n- Deployed REST APIs using flask/fastapi on Azure functions + APIM to expose some KPIs\n- Developed some ML models: mostly user segmentation/clustering and time series forecasting. Some of my colleagues had a Data Science background and I was involved since I studied DS in my spare time, I think these can be considered full DS projects involving research + experimentation + performances comparison + tuning + industrialization. One of these projects spanned several months and involved external consultants\n- Deployed some of the aforementioned models in production, mostly using Databricks + MLFlow + APIM for automated training, monitoring and scheduled batch serving of the model predictions&lt;/p&gt;\n\n&lt;p&gt;In these last 2 years, I&amp;#39;ve grown immensely both professionally and technically. So much so that recently I received an offer as a Data Engineer Tech Lead from a competitor company, which I accepted. They&amp;#39;re building their Data Platform on a similar tech stack and I&amp;#39;m going to start this September. The reason I left is also because my current company isn&amp;#39;t doing so well, so I took the opportunity. &lt;/p&gt;\n\n&lt;p&gt;Now, this should be good news but it sparked a lot of doubts in me:\n- I feel like I kinda fell into it: I like the engineering/architecture part of DE, despise the BI/visualization part and I&amp;#39;m not sure what are the possible career paths from here. What are possible evolutions of my career?\n- I feel like I am not using my physics background. I have been studying Machine Learning in my spare time and was lucky enough to apply some of what I studied in my current job, but I&amp;#39;m not sure if that&amp;#39;s something I would like to do the whole day, as I find the whole back and forth to improve performances of a model kind of exhausting. On the other side, I like software development but I feel out of place and that I&amp;#39;m wasting my skills in math/stat. I&amp;#39;d like to work in a more ML oriented field, but I&amp;#39;m not sure about how plausible and beneficial transitioning to DS or some kind of in-between role would be?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15tgg3k", "is_robot_indexable": true, "report_reasons": null, "author": "lbranco93", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tgg3k/career_in_the_data_space/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tgg3k/career_in_the_data_space/", "subreddit_subscribers": 123265, "created_utc": 1692258082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I am new to data engineering, I am trying to create my first end-to-end ETL pipeline, I have done my data modeling on jupyter notebook and uploaded to s3 bucket.\n\nTrying to copy the data to aws redshift using glue jobs python shell, but i keep getting connection timed out error.\n\nThe doc suggested i add my security group to the inbound rule and associate the full Access role, i have done that and still didn't fix it.\n\nMost resources online seem outdated, can anyone help me with a guide  on how to properly setup the cluster to enable connection from glue python shell?\n\nThanks.", "author_fullname": "t2_lp01da97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aws glue to redshift connection issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tg0y9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692256678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I am new to data engineering, I am trying to create my first end-to-end ETL pipeline, I have done my data modeling on jupyter notebook and uploaded to s3 bucket.&lt;/p&gt;\n\n&lt;p&gt;Trying to copy the data to aws redshift using glue jobs python shell, but i keep getting connection timed out error.&lt;/p&gt;\n\n&lt;p&gt;The doc suggested i add my security group to the inbound rule and associate the full Access role, i have done that and still didn&amp;#39;t fix it.&lt;/p&gt;\n\n&lt;p&gt;Most resources online seem outdated, can anyone help me with a guide  on how to properly setup the cluster to enable connection from glue python shell?&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15tg0y9", "is_robot_indexable": true, "report_reasons": null, "author": "Wise_Language_5565", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tg0y9/aws_glue_to_redshift_connection_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tg0y9/aws_glue_to_redshift_connection_issue/", "subreddit_subscribers": 123265, "created_utc": 1692256678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone.   \n\n\nIm a DE in a company and we need a data lake.   \n\n\nI am using azure cloud and more specifically  data factory to do the move if possible, but open to all options.  Python is my bread and butter, so no prob writing couple functions to do this.    \n\n\nI was hoping I could enable Change Data Capture in data factory to capture any changes in the tables so i can only move over the rows that have had CRUD done on them. This way the analytics teams can have a time series events when doing predictive modeling. But the decision to turn on CDC was not approved.   \n\n\nWith change data capture, I need a date column to hook into, to pick up any changes and only those changes. This is where my problems start.   \n\n\nThe date columns in the tables are very unreliable and do not get updated as you would think. So I have no date columns to hook into to pick up CRUD records and move them over.   \n\n\nThe dba has advised me of only one column they update when CRUD happens, which is an alpha numeric value that increments up (i know, yuck).    \n\n\nWhat are some other ways I can only pick up CRUD records if I have no way to tell what is really a record I want, when it changes in the tables?", "author_fullname": "t2_l1znu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Help with Data Lake Design For Capturing Only New Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tdxb5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692250002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone.   &lt;/p&gt;\n\n&lt;p&gt;Im a DE in a company and we need a data lake.   &lt;/p&gt;\n\n&lt;p&gt;I am using azure cloud and more specifically  data factory to do the move if possible, but open to all options.  Python is my bread and butter, so no prob writing couple functions to do this.    &lt;/p&gt;\n\n&lt;p&gt;I was hoping I could enable Change Data Capture in data factory to capture any changes in the tables so i can only move over the rows that have had CRUD done on them. This way the analytics teams can have a time series events when doing predictive modeling. But the decision to turn on CDC was not approved.   &lt;/p&gt;\n\n&lt;p&gt;With change data capture, I need a date column to hook into, to pick up any changes and only those changes. This is where my problems start.   &lt;/p&gt;\n\n&lt;p&gt;The date columns in the tables are very unreliable and do not get updated as you would think. So I have no date columns to hook into to pick up CRUD records and move them over.   &lt;/p&gt;\n\n&lt;p&gt;The dba has advised me of only one column they update when CRUD happens, which is an alpha numeric value that increments up (i know, yuck).    &lt;/p&gt;\n\n&lt;p&gt;What are some other ways I can only pick up CRUD records if I have no way to tell what is really a record I want, when it changes in the tables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15tdxb5", "is_robot_indexable": true, "report_reasons": null, "author": "boston101", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tdxb5/need_help_with_data_lake_design_for_capturing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tdxb5/need_help_with_data_lake_design_for_capturing/", "subreddit_subscribers": 123265, "created_utc": 1692250002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI will start studying Data Engineering in Stockholm this month and I got some minimum requirements direct from my university. As a new student I'm a little bit confused about what laptop should I pick for now (if it last some years, better)  \n\n\nMSI Cyborg 15  i5-12450H /  16 GB DDR5 /  512 GB SSD /  RTX 4050  \u2248  1005 usd\n\nMSI Katana GF66  i5-11400H / 16 GB DDR4 / 512 GB SSD / RTX 3060 \u2248 915 usd\n\nHP Probook 440 i7-1355U / 16 GB DDR4 / 512 GB SSD / Intel UHD \u2248 1280 usd\n\nHP Elitebook 650  i7-1355U / 16 GB DDR4 / 512 GB SSD / Intel Iris Xe \u2248 1608 usd\n\n&amp;#x200B;\n\nI would prefer a MSI laptop from the above because of price and better GPU (I do casual gaming) but I don't know if there is a big difference between those i5 and i7. If some of you have a better option in that budget I will appreciate the tips.\n\n&amp;#x200B;\n\nThanks in advance!", "author_fullname": "t2_5lc174ra", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Laptop recommendation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15t7k1l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692232772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I will start studying Data Engineering in Stockholm this month and I got some minimum requirements direct from my university. As a new student I&amp;#39;m a little bit confused about what laptop should I pick for now (if it last some years, better)  &lt;/p&gt;\n\n&lt;p&gt;MSI Cyborg 15  i5-12450H /  16 GB DDR5 /  512 GB SSD /  RTX 4050  \u2248  1005 usd&lt;/p&gt;\n\n&lt;p&gt;MSI Katana GF66  i5-11400H / 16 GB DDR4 / 512 GB SSD / RTX 3060 \u2248 915 usd&lt;/p&gt;\n\n&lt;p&gt;HP Probook 440 i7-1355U / 16 GB DDR4 / 512 GB SSD / Intel UHD \u2248 1280 usd&lt;/p&gt;\n\n&lt;p&gt;HP Elitebook 650  i7-1355U / 16 GB DDR4 / 512 GB SSD / Intel Iris Xe \u2248 1608 usd&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I would prefer a MSI laptop from the above because of price and better GPU (I do casual gaming) but I don&amp;#39;t know if there is a big difference between those i5 and i7. If some of you have a better option in that budget I will appreciate the tips.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15t7k1l", "is_robot_indexable": true, "report_reasons": null, "author": "EroSenninSSA", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15t7k1l/laptop_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15t7k1l/laptop_recommendation/", "subreddit_subscribers": 123265, "created_utc": 1692232772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI wanted to share a project I have built, maybe some of you find it interesting. The project can be found here: [https://github.com/dominikhei/eartquake-streaming](https://github.com/dominikhei/eartquake-streaming)\n\nWith this project I have built a distributed system to display earthquakes in real time on a map, accessible via your browser. The front end service on Fargate has an upstream loadbalancer to scale out if needed. Data is streamed using Springboot Kafka in a Docker Compose setup. The whole AWS infrastructure is created and configured using Terraform. In addition to that I have implemented logging of the backend using Promtail, Loki and Grafana.\n\nObviously the projects is overengineered, but I had  fun building it.\n\nFeedback is well appreciated :)", "author_fullname": "t2_v219tksh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project showcase: Distributed System on AWS streaming earthquakes using Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15tyvgg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692304416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I wanted to share a project I have built, maybe some of you find it interesting. The project can be found here: &lt;a href=\"https://github.com/dominikhei/eartquake-streaming\"&gt;https://github.com/dominikhei/eartquake-streaming&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;With this project I have built a distributed system to display earthquakes in real time on a map, accessible via your browser. The front end service on Fargate has an upstream loadbalancer to scale out if needed. Data is streamed using Springboot Kafka in a Docker Compose setup. The whole AWS infrastructure is created and configured using Terraform. In addition to that I have implemented logging of the backend using Promtail, Loki and Grafana.&lt;/p&gt;\n\n&lt;p&gt;Obviously the projects is overengineered, but I had  fun building it.&lt;/p&gt;\n\n&lt;p&gt;Feedback is well appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?auto=webp&amp;s=f3b64e28101051429559372b5aeb98884301229b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eb6a8172d47007f72c2f0183f6fa0b669826d0e2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=943c5ceb61b72408f718effc4e442a91e7653462", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3a317d8b53191a6640b22cf2620747430f1d8191", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d0195143e4fe8977aea02bec33010a0e873b345a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=219bc6cc3232e88d49b511f0eb78e63c0f325682", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=11e5c0eccc404f77401851c536fe17895134daca", "width": 1080, "height": 540}], "variants": {}, "id": "kS-I3ya27NJN-dmNgvM5ikzQz5_TUVACPdituRrCqh4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "15tyvgg", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Hand-577", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tyvgg/project_showcase_distributed_system_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tyvgg/project_showcase_distributed_system_on_aws/", "subreddit_subscribers": 123265, "created_utc": 1692304416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi 5 yoe data engineer here,\n\nI have a few interviews for DE positions. They all use either azure or gcp. I unfortuntely have 0 cloud experience. Most of my current experience revolves around production support/debugging/optimization/deploying spark scala pipelines on on-prem systems. Another thing to note is I don't do much data modeling in my job as well.\n\nJust curious to know, how much different is on-prem developement than on cloud? Are there any concepts that I should know before walking in the interview?\nAny advice on any skill that I should highlight? \n\n\nYou advice is very much appreciated", "author_fullname": "t2_69bro8kq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lots on on prem experience/ no cloud experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tsd9r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692289750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi 5 yoe data engineer here,&lt;/p&gt;\n\n&lt;p&gt;I have a few interviews for DE positions. They all use either azure or gcp. I unfortuntely have 0 cloud experience. Most of my current experience revolves around production support/debugging/optimization/deploying spark scala pipelines on on-prem systems. Another thing to note is I don&amp;#39;t do much data modeling in my job as well.&lt;/p&gt;\n\n&lt;p&gt;Just curious to know, how much different is on-prem developement than on cloud? Are there any concepts that I should know before walking in the interview?\nAny advice on any skill that I should highlight? &lt;/p&gt;\n\n&lt;p&gt;You advice is very much appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15tsd9r", "is_robot_indexable": true, "report_reasons": null, "author": "Significant-Skirt-75", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tsd9r/lots_on_on_prem_experience_no_cloud_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tsd9r/lots_on_on_prem_experience_no_cloud_experience/", "subreddit_subscribers": 123265, "created_utc": 1692289750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for simplistic tools for a one off data compaction of partitioned csv/parquet files in cloud storage. Have hive based storage partitions by day; where each day may have none to several hundreds of small csv/parquet files(type/schema stays consistent I just have multiple datasets). Looking to merge them to preset chunks. Started to put together a script to do it but interested if there\u2019s tooling that already is tested.\n\nNot looking to add expansive tools with large setup efforts. Overall dataset size is tiny &lt;100gb. Suggestions?\n\nI'd also be interested in considerations for validations that the compaction didn't modify data; I was primarily leaning towards row count and row count by id. Though that doesn't test any of the actual data.", "author_fullname": "t2_20funj35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easy tool for data compaction?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15trwwk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692288666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for simplistic tools for a one off data compaction of partitioned csv/parquet files in cloud storage. Have hive based storage partitions by day; where each day may have none to several hundreds of small csv/parquet files(type/schema stays consistent I just have multiple datasets). Looking to merge them to preset chunks. Started to put together a script to do it but interested if there\u2019s tooling that already is tested.&lt;/p&gt;\n\n&lt;p&gt;Not looking to add expansive tools with large setup efforts. Overall dataset size is tiny &amp;lt;100gb. Suggestions?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d also be interested in considerations for validations that the compaction didn&amp;#39;t modify data; I was primarily leaning towards row count and row count by id. Though that doesn&amp;#39;t test any of the actual data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15trwwk", "is_robot_indexable": true, "report_reasons": null, "author": "FridayPush", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15trwwk/easy_tool_for_data_compaction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15trwwk/easy_tool_for_data_compaction/", "subreddit_subscribers": 123265, "created_utc": 1692288666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can DLT-Meta be run independently in the databricks notebook or can only be enabled thru databricks workflows", "author_fullname": "t2_kbwr9eii", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks DLT-Meta API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tkao1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692270484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can DLT-Meta be run independently in the databricks notebook or can only be enabled thru databricks workflows&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15tkao1", "is_robot_indexable": true, "report_reasons": null, "author": "Dismal-Ad3028", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tkao1/databricks_dltmeta_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tkao1/databricks_dltmeta_api/", "subreddit_subscribers": 123265, "created_utc": 1692270484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Task scheduling with a message broker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_15thibi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wyeIKmJWPnPAyOQsj_zB3mMyhMHlktSk142chc3mKfE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692261702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "memphis.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://memphis.dev/blog/task-scheduling-with-a-message-broker/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GPK0IFyUKPfAvMuOF4zYWAEIcvIP7vnhaLuC6TIns3I.jpg?auto=webp&amp;s=135ad37b9812dce220cb909790f79a38c7bbf257", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/GPK0IFyUKPfAvMuOF4zYWAEIcvIP7vnhaLuC6TIns3I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4c6368f9cbb3756a15d7111614cebc4283bcadd9", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/GPK0IFyUKPfAvMuOF4zYWAEIcvIP7vnhaLuC6TIns3I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2e36fab24a781b7b69490c6cf98104d92d1dc66b", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/GPK0IFyUKPfAvMuOF4zYWAEIcvIP7vnhaLuC6TIns3I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d33d354a196c63946126ecc4c8415f0c6dca8e40", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/GPK0IFyUKPfAvMuOF4zYWAEIcvIP7vnhaLuC6TIns3I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ffac439e1341776445087dfa9c0547406654d0e9", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/GPK0IFyUKPfAvMuOF4zYWAEIcvIP7vnhaLuC6TIns3I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f859353658989fbc93efff56a53ce85397ac5ac4", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/GPK0IFyUKPfAvMuOF4zYWAEIcvIP7vnhaLuC6TIns3I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ebcd3c3ef000285104567a14e70708249eeee2fd", "width": 1080, "height": 607}], "variants": {}, "id": "2TbsMbw-oOXnE-q4Py-iJZkQ7StTfU9QkDP7k-qzDGc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15thibi", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15thibi/task_scheduling_with_a_message_broker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://memphis.dev/blog/task-scheduling-with-a-message-broker/", "subreddit_subscribers": 123265, "created_utc": 1692261702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, \n\nHas anyone ever had the need to transpose a data frame using PySpark? Is the transpose operation slow or resource intensive even for smaller datasets?\n\nI\u2019m on a project with a pretty denormalized table in a DB that has a bunch of Boolean columns to store information about customers and I\u2019m trying to come up with a way to return the actual column metadata (aka descriptions tied to the Boolean flags) back to my end user. \n\nSo far my end user has communicated to me that they need the tables to research customers who meet/do not meet certain conditions which vary depending on the flag (aka column) in question. However said end user isn\u2019t very tech savvy so I\u2019m thinking about transposing the data frame so that a given customer id is the column name thus enabling me to run \u201c where customer_id = 1\u201d or something like that. Then I\u2019ll have the rows (flags) that were True for a particular customer. \n\nIs this a naive approach? We are talking about 300 Boolean columns here and on average 1.5million total customers. \n\nThanks!", "author_fullname": "t2_s3fda0o9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transposing a table using PySpark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15t5pat", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692228210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;Has anyone ever had the need to transpose a data frame using PySpark? Is the transpose operation slow or resource intensive even for smaller datasets?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m on a project with a pretty denormalized table in a DB that has a bunch of Boolean columns to store information about customers and I\u2019m trying to come up with a way to return the actual column metadata (aka descriptions tied to the Boolean flags) back to my end user. &lt;/p&gt;\n\n&lt;p&gt;So far my end user has communicated to me that they need the tables to research customers who meet/do not meet certain conditions which vary depending on the flag (aka column) in question. However said end user isn\u2019t very tech savvy so I\u2019m thinking about transposing the data frame so that a given customer id is the column name thus enabling me to run \u201c where customer_id = 1\u201d or something like that. Then I\u2019ll have the rows (flags) that were True for a particular customer. &lt;/p&gt;\n\n&lt;p&gt;Is this a naive approach? We are talking about 300 Boolean columns here and on average 1.5million total customers. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15t5pat", "is_robot_indexable": true, "report_reasons": null, "author": "lmao_unemployment", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15t5pat/transposing_a_table_using_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15t5pat/transposing_a_table_using_pyspark/", "subreddit_subscribers": 123265, "created_utc": 1692228210.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}