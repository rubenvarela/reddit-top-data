{"kind": "Listing", "data": {"after": "t3_15sfg1l", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With the new version of this open-source analytic data warehouse, we bring to you:\n\n1. Auto-synchronization from MySQL / Oracle to Doris\n2. Elastic scaling of computation resources\n3. Native support for semi-structured data\n4. Tiered storage for hot and cold data\n5. Storage-compute separation\n6. Support for Kubernetes deployment\n7. Support for cross-cluster replication (CCR)\n8. Optimizations in concurrency to achieve 30,000 QPS per node \n9. Inverted index to speed up log analysis, fuzzy keyword search, and equivalence/range queries\n10. A smarter query optimizer that is 10 times more effective and frees you from tedious fine-tuning\n11. Enhanced data lakehousing capabilities (e.g. 3\\~5 times faster than Presto/Trino in queries on Hive tables)\n12. A self-adaptive parallel execution model for higher efficiency and stability in hybrid workload scenarios\n13. Efficient data update mechanisms (faster data writing, partial column update, conditional update and deletion)\n14. A flexible multi-tenant resource isolation solution (avoid preemption but make full use of CPU &amp; memory resources)", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Doris 2.0.0 is Production-Ready", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15so5vl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692187879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the new version of this open-source analytic data warehouse, we bring to you:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Auto-synchronization from MySQL / Oracle to Doris&lt;/li&gt;\n&lt;li&gt;Elastic scaling of computation resources&lt;/li&gt;\n&lt;li&gt;Native support for semi-structured data&lt;/li&gt;\n&lt;li&gt;Tiered storage for hot and cold data&lt;/li&gt;\n&lt;li&gt;Storage-compute separation&lt;/li&gt;\n&lt;li&gt;Support for Kubernetes deployment&lt;/li&gt;\n&lt;li&gt;Support for cross-cluster replication (CCR)&lt;/li&gt;\n&lt;li&gt;Optimizations in concurrency to achieve 30,000 QPS per node &lt;/li&gt;\n&lt;li&gt;Inverted index to speed up log analysis, fuzzy keyword search, and equivalence/range queries&lt;/li&gt;\n&lt;li&gt;A smarter query optimizer that is 10 times more effective and frees you from tedious fine-tuning&lt;/li&gt;\n&lt;li&gt;Enhanced data lakehousing capabilities (e.g. 3~5 times faster than Presto/Trino in queries on Hive tables)&lt;/li&gt;\n&lt;li&gt;A self-adaptive parallel execution model for higher efficiency and stability in hybrid workload scenarios&lt;/li&gt;\n&lt;li&gt;Efficient data update mechanisms (faster data writing, partial column update, conditional update and deletion)&lt;/li&gt;\n&lt;li&gt;A flexible multi-tenant resource isolation solution (avoid preemption but make full use of CPU &amp;amp; memory resources)&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15so5vl", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15so5vl/apache_doris_200_is_productionready/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15so5vl/apache_doris_200_is_productionready/", "subreddit_subscribers": 123102, "created_utc": 1692187879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am curious why data science students choose a data engineering position rather than a data scientist position.", "author_fullname": "t2_94z2yiq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sktrv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692177727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am curious why data science students choose a data engineering position rather than a data scientist position.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15sktrv", "is_robot_indexable": true, "report_reasons": null, "author": "LengthOld9943", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sktrv/why_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sktrv/why_data_engineering/", "subreddit_subscribers": 123102, "created_utc": 1692177727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With framework here I mean \"set of rules / best practices\".\n\nSome we all know, like \"make the pipeline idempotent\" etc..., But I was wondering if there is some kind of generally accepted gold standard both for high and low lvl concepts.\n\nTo contextualize with an example I encountered recently: let's say you're extracting data from an OLTP database. Do you keep a (json) document with all the schemas for each table? What if there are hundreds of them? And what about schema drifts?\n\nIn other words, I'd like to know if you follow some ruleset when writing a new pipeline, or each time it's on a case by case scenario.\n\nLet me know what your experiences are!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When writing EL pipelines, do you follow any specific design pattern / framework?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sr2cr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692195170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With framework here I mean &amp;quot;set of rules / best practices&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Some we all know, like &amp;quot;make the pipeline idempotent&amp;quot; etc..., But I was wondering if there is some kind of generally accepted gold standard both for high and low lvl concepts.&lt;/p&gt;\n\n&lt;p&gt;To contextualize with an example I encountered recently: let&amp;#39;s say you&amp;#39;re extracting data from an OLTP database. Do you keep a (json) document with all the schemas for each table? What if there are hundreds of them? And what about schema drifts?&lt;/p&gt;\n\n&lt;p&gt;In other words, I&amp;#39;d like to know if you follow some ruleset when writing a new pipeline, or each time it&amp;#39;s on a case by case scenario.&lt;/p&gt;\n\n&lt;p&gt;Let me know what your experiences are!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15sr2cr", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sr2cr/when_writing_el_pipelines_do_you_follow_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sr2cr/when_writing_el_pipelines_do_you_follow_any/", "subreddit_subscribers": 123102, "created_utc": 1692195170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w07bcus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stream Processing Engines and Streaming Databases: Design, Use Cases, and the Future", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15spfny", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zG-1n7L2nYhLKd_4n9VrDvZxkSisbvmH5xQyYZ-Qygs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692191208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "risingwave.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.risingwave.com/blog/stream-processing-engines-and-streaming-databases-design-use-cases-and-the-future/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/U8kWUgPJXBqYyIzz7lB0jQ6P8MHTLKHVgUa5B430rlM.jpg?auto=webp&amp;s=6cd40a2b94cd86b5e76bc6bac7f51b9234427325", "width": 692, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/U8kWUgPJXBqYyIzz7lB0jQ6P8MHTLKHVgUa5B430rlM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cf9bbe0b42d0b9c525116a265e72d37d52f8883d", "width": 108, "height": 124}, {"url": "https://external-preview.redd.it/U8kWUgPJXBqYyIzz7lB0jQ6P8MHTLKHVgUa5B430rlM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6e275a615475bd566cc243d655b5ca9999a24098", "width": 216, "height": 249}, {"url": "https://external-preview.redd.it/U8kWUgPJXBqYyIzz7lB0jQ6P8MHTLKHVgUa5B430rlM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d2c98db2663e63888993b82eeaf683f82324d8d7", "width": 320, "height": 369}, {"url": "https://external-preview.redd.it/U8kWUgPJXBqYyIzz7lB0jQ6P8MHTLKHVgUa5B430rlM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3272c19fe13f4ff6cf4cc94749cc64d7564d1c57", "width": 640, "height": 739}], "variants": {}, "id": "Yl3N5GUR2yabuFWD9SnTBMOZF6LJ3C0CgZm4N1-mpzk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15spfny", "is_robot_indexable": true, "report_reasons": null, "author": "yingjunwu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15spfny/stream_processing_engines_and_streaming_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.risingwave.com/blog/stream-processing-engines-and-streaming-databases-design-use-cases-and-the-future/", "subreddit_subscribers": 123102, "created_utc": 1692191208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It's widely known that developers prefer code-based orchestration tools (e.g., Airflow, Prefect, Dagster) vs. GUI-based ones (e.g., Meltano, Fivetran, Airbyte). More discussion available [here](https://www.reddit.com/r/dataengineering/comments/vscvhp/lownocode_etl_tools/).\n\nRecently, I've been seeing posts pitching using them together e.g., [Airbyte-Airflow](https://docs.airbyte.com/operator-guides/using-the-airflow-airbyte-operator/) and [Airbyte-Dagster](https://docs.dagster.io/integrations/airbyte). I get the GUI-based ones mostly provide easy way to \"EL\" but if I am using code-based anyway, then might as well write plain python to DIY. Why would I bother using both?\n\nWhat am I missing here? What situations truly call for using both together?", "author_fullname": "t2_42hc4int", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GUI-based vs code-based orchestrators", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sfmtx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692160833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s widely known that developers prefer code-based orchestration tools (e.g., Airflow, Prefect, Dagster) vs. GUI-based ones (e.g., Meltano, Fivetran, Airbyte). More discussion available &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/vscvhp/lownocode_etl_tools/\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Recently, I&amp;#39;ve been seeing posts pitching using them together e.g., &lt;a href=\"https://docs.airbyte.com/operator-guides/using-the-airflow-airbyte-operator/\"&gt;Airbyte-Airflow&lt;/a&gt; and &lt;a href=\"https://docs.dagster.io/integrations/airbyte\"&gt;Airbyte-Dagster&lt;/a&gt;. I get the GUI-based ones mostly provide easy way to &amp;quot;EL&amp;quot; but if I am using code-based anyway, then might as well write plain python to DIY. Why would I bother using both?&lt;/p&gt;\n\n&lt;p&gt;What am I missing here? What situations truly call for using both together?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15sfmtx", "is_robot_indexable": true, "report_reasons": null, "author": "vanillacap", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sfmtx/guibased_vs_codebased_orchestrators/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sfmtx/guibased_vs_codebased_orchestrators/", "subreddit_subscribers": 123102, "created_utc": 1692160833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi friends, I'm hearing this from a friend but didn't get the chance to get the details. Basically in his company the BIs are ONLY using Redshift, and he said it is a bad thing. I have no experience with Redshift but I work in a GCP shop where we mostly use Google Bigquery and I didn't see any issue.\n\nWhat could the issue if Redshift is the only DB BI is using? I assume this is going to be data warehousing as BI is the user.", "author_fullname": "t2_bmsha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the risk of using Redshift as the only database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15t5otn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692228178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends, I&amp;#39;m hearing this from a friend but didn&amp;#39;t get the chance to get the details. Basically in his company the BIs are ONLY using Redshift, and he said it is a bad thing. I have no experience with Redshift but I work in a GCP shop where we mostly use Google Bigquery and I didn&amp;#39;t see any issue.&lt;/p&gt;\n\n&lt;p&gt;What could the issue if Redshift is the only DB BI is using? I assume this is going to be data warehousing as BI is the user.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15t5otn", "is_robot_indexable": true, "report_reasons": null, "author": "levelworm", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15t5otn/what_is_the_risk_of_using_redshift_as_the_only/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15t5otn/what_is_the_risk_of_using_redshift_as_the_only/", "subreddit_subscribers": 123102, "created_utc": 1692228178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm thinking of not going for the Developer Associate or Solutions Architect ones. My understanding is that these are more beginner focused. I have 4 YOE of which 2 are in AWS. My work right now is coding applications that run on EMR.", "author_fullname": "t2_163ma7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it a bad idea to go straight to AWS Data Analytics certification.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15srdfm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692195933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m thinking of not going for the Developer Associate or Solutions Architect ones. My understanding is that these are more beginner focused. I have 4 YOE of which 2 are in AWS. My work right now is coding applications that run on EMR.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15srdfm", "is_robot_indexable": true, "report_reasons": null, "author": "muhmeinchut69", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15srdfm/is_it_a_bad_idea_to_go_straight_to_aws_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15srdfm/is_it_a_bad_idea_to_go_straight_to_aws_data/", "subreddit_subscribers": 123102, "created_utc": 1692195933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI have recently started a new role as a DE in a company and it is really not aligned with what I was expecting, in every possible aspect (stack, stakeholders, managers, etc).\n\nI am thinking of moving on (I still have the role), but what worries me is how to handle this extremely short tenure (1 month, still in probation period) in my CV and discussions with recruiters/HR/etc, especially the notice period.\n\nShould I omit it completely, or try to explain the situation? Have any of you had a similar situation?\n\n&amp;#x200B;\n\nupdate 1: try to clarify the notice period a bit ", "author_fullname": "t2_fr98ul4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle really short job tenures.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15smg30", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692185135.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692182943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I have recently started a new role as a DE in a company and it is really not aligned with what I was expecting, in every possible aspect (stack, stakeholders, managers, etc).&lt;/p&gt;\n\n&lt;p&gt;I am thinking of moving on (I still have the role), but what worries me is how to handle this extremely short tenure (1 month, still in probation period) in my CV and discussions with recruiters/HR/etc, especially the notice period.&lt;/p&gt;\n\n&lt;p&gt;Should I omit it completely, or try to explain the situation? Have any of you had a similar situation?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;update 1: try to clarify the notice period a bit &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15smg30", "is_robot_indexable": true, "report_reasons": null, "author": "notamiko", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15smg30/how_to_handle_really_short_job_tenures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15smg30/how_to_handle_really_short_job_tenures/", "subreddit_subscribers": 123102, "created_utc": 1692182943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Please help how can i  continue the consistency?", "author_fullname": "t2_2dmmbh2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm feeling overwhelmed with Data Engineering (DE)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15shn2j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692167226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please help how can i  continue the consistency?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15shn2j", "is_robot_indexable": true, "report_reasons": null, "author": "prakash_8", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15shn2j/im_feeling_overwhelmed_with_data_engineering_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15shn2j/im_feeling_overwhelmed_with_data_engineering_de/", "subreddit_subscribers": 123102, "created_utc": 1692167226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team is working through a migration from redshift to snowflake. Overall we have seen performance increases except for external tables. We have a few external tables defined in redshift that are pointed at partitioned parquet files in s3 and we recreated these external tables in snowflake. Redshift performance is 10x better than snowflake. Is there anything I could be missing why this is the case?", "author_fullname": "t2_45pdhd22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake External tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ssz8h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692199664.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team is working through a migration from redshift to snowflake. Overall we have seen performance increases except for external tables. We have a few external tables defined in redshift that are pointed at partitioned parquet files in s3 and we recreated these external tables in snowflake. Redshift performance is 10x better than snowflake. Is there anything I could be missing why this is the case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ssz8h", "is_robot_indexable": true, "report_reasons": null, "author": "theCHEFlin", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ssz8h/snowflake_external_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ssz8h/snowflake_external_tables/", "subreddit_subscribers": 123102, "created_utc": 1692199664.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Data Industry's Convergence: Fragmented to Unified Experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15sk3x3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oogSHo6UrdROuwZGlbrFuC4aa3F-o-hFq-ZbRY_Ik0U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692175325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/the-data-industrys-convergence-fragmented", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?auto=webp&amp;s=201220b79af8841a0bedb83570e05567d7824573", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4d8ebdcb130995dd420bc262af108bb5ce838eb9", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b90c634dfd836daf41fa06090c420293ac9c411f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cfdc02f96bc51fac9346d1a3ca88dd95f4bcc323", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d59487c9a47240310614e4657d8b71eb3902f9a3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2010454e150006d271f2dfbdf437adba89b726a2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/MHFqFDm1vRTBNWmbuNgLpnzjH3OLz5gvRDeULOn30gE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fcf2118478a8b4e4e467f3fc9be6a20308fee3c5", "width": 1080, "height": 540}], "variants": {}, "id": "EJaJOPu1otUjBLOA5ZH4Ay7dRyGnQ_s6FLO6HTswCk8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15sk3x3", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sk3x3/the_data_industrys_convergence_fragmented_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/the-data-industrys-convergence-fragmented", "subreddit_subscribers": 123102, "created_utc": 1692175325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_975og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to write fewer and better data tests with dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15sp1o8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Eq-I8rFi4qk-Jw8iPFESsUGhNWOba5RKlKQANZg7bnA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692190249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "elementary-data.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.elementary-data.com/post/dbt-tests", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?auto=webp&amp;s=f5d91a5633b7ba1907f0f4d46e132b8325eb7246", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4d2d1e15a9666506a101a8572ece2c0f90bc883f", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=029ab7fca886d9bc4c701d70ffc4b15620d645e4", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=48566d5b20f17cf3a8555252de224da9493bae0f", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1214f09c2cf62824cd74e549b86afcbe687778a3", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e8887ac77c741f242ef239818e7625eef63649fc", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/T_ypTxbiDdhxcF3r9mew_DiS85ATwusl0EgUVMhjCxY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e1d6820709ad5dc8bb84ea4414c85be204f7f20f", "width": 1080, "height": 567}], "variants": {}, "id": "dCRPDF1eYYwa8wbz61_ejFTUlUbR7J0dDuxedEes8pA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15sp1o8", "is_robot_indexable": true, "report_reasons": null, "author": "arimbr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sp1o8/how_to_write_fewer_and_better_data_tests_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.elementary-data.com/post/dbt-tests", "subreddit_subscribers": 123102, "created_utc": 1692190249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI will start studying Data Engineering in Stockholm this month and I got some minimum requirements direct from my university. As a new student I'm a little bit confused about what laptop should I pick for now (if it last some years, better)  \n\n\nMSI Cyborg 15  i5-12450H /  16 GB DDR5 /  512 GB SSD /  RTX 4050  \u2248  1005 usd\n\nMSI Katana GF66  i5-11400H / 16 GB DDR4 / 512 GB SSD / RTX 3060 \u2248 915 usd\n\nHP Probook 440 i7-1355U / 16 GB DDR4 / 512 GB SSD / Intel UHD \u2248 1280 usd\n\nHP Elitebook 650  i7-1355U / 16 GB DDR4 / 512 GB SSD / Intel Iris Xe \u2248 1608 usd\n\n&amp;#x200B;\n\nI would prefer a MSI laptop from the above because of price and better GPU (I do casual gaming) but I don't know if there is a big difference between those i5 and i7. If some of you have a better option in that budget I will appreciate the tips.\n\n&amp;#x200B;\n\nThanks in advance!", "author_fullname": "t2_5lc174ra", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Laptop recommendation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15t7k1l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692232772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I will start studying Data Engineering in Stockholm this month and I got some minimum requirements direct from my university. As a new student I&amp;#39;m a little bit confused about what laptop should I pick for now (if it last some years, better)  &lt;/p&gt;\n\n&lt;p&gt;MSI Cyborg 15  i5-12450H /  16 GB DDR5 /  512 GB SSD /  RTX 4050  \u2248  1005 usd&lt;/p&gt;\n\n&lt;p&gt;MSI Katana GF66  i5-11400H / 16 GB DDR4 / 512 GB SSD / RTX 3060 \u2248 915 usd&lt;/p&gt;\n\n&lt;p&gt;HP Probook 440 i7-1355U / 16 GB DDR4 / 512 GB SSD / Intel UHD \u2248 1280 usd&lt;/p&gt;\n\n&lt;p&gt;HP Elitebook 650  i7-1355U / 16 GB DDR4 / 512 GB SSD / Intel Iris Xe \u2248 1608 usd&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I would prefer a MSI laptop from the above because of price and better GPU (I do casual gaming) but I don&amp;#39;t know if there is a big difference between those i5 and i7. If some of you have a better option in that budget I will appreciate the tips.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15t7k1l", "is_robot_indexable": true, "report_reasons": null, "author": "EroSenninSSA", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15t7k1l/laptop_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15t7k1l/laptop_recommendation/", "subreddit_subscribers": 123102, "created_utc": 1692232772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I work on a project that the client requires multiple database connections, then doing some simple transformations and updating multiple destinations. I love the interface for Mage but I don't get the connection process. \n\nThe AI docs tell me to connect to the MSSQL variable. But I'm lost. \n\nHow do I connect to multiple MSSQL databases? I tried connecting via the default profile using domain credentials but that didn't work. \n\nI tried creating multiple profiles... But that didn't work. \n\nSo I'm lost. Is Mage only for pgsql, MySQL and sqlite?\n\nAre there any GitHub projects or tutorials I can look at?\n\nPerfect seems simpler, but the client wants to develop through the UI blocks, to enable more visibility long term. \n\nUm...help?!?!", "author_fullname": "t2_11t26p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mage for SQL Server ... Ummm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15syerq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692211769.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I work on a project that the client requires multiple database connections, then doing some simple transformations and updating multiple destinations. I love the interface for Mage but I don&amp;#39;t get the connection process. &lt;/p&gt;\n\n&lt;p&gt;The AI docs tell me to connect to the MSSQL variable. But I&amp;#39;m lost. &lt;/p&gt;\n\n&lt;p&gt;How do I connect to multiple MSSQL databases? I tried connecting via the default profile using domain credentials but that didn&amp;#39;t work. &lt;/p&gt;\n\n&lt;p&gt;I tried creating multiple profiles... But that didn&amp;#39;t work. &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m lost. Is Mage only for pgsql, MySQL and sqlite?&lt;/p&gt;\n\n&lt;p&gt;Are there any GitHub projects or tutorials I can look at?&lt;/p&gt;\n\n&lt;p&gt;Perfect seems simpler, but the client wants to develop through the UI blocks, to enable more visibility long term. &lt;/p&gt;\n\n&lt;p&gt;Um...help?!?!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15syerq", "is_robot_indexable": true, "report_reasons": null, "author": "byeproduct", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15syerq/mage_for_sql_server_ummm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15syerq/mage_for_sql_server_ummm/", "subreddit_subscribers": 123102, "created_utc": 1692211769.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys!\n\nI'm a back-end dev currently tasked with designing and implementing indexing and storage systems for my company's upcoming product.\n\nNote that I'm very new to data engineering - having only read 70% of \"Designing Data Intensive Applications\" at the time of writing (the project hit before I was able to finish the book). Our team is small, and no one has hands-on experience in data engineering.\n\n**We have a tool to dump raw data to Parquets, and then it's my job to design a pipeline that consumes/transforms this raw data into something higher-level, and stored in Parquets (or something else depending on the data use case)**. There are actually more details to this, but we'd like to ship a PoC the design first. (i.e. details such as querying those higher-level Parquets).\n\nI chose Apache Beam SDK for defining pipelines - in part because of Google Cloud Dataflow, which we will use in production.\n\nBeam Go SDK does not have Parquet IO connector AFAIK, but Python SDK does. **So my initial plan is to have Python \"connector pipeline\" to read Parquet files, send it to Go pipelines to do transformations, before sending the output to Python Parquet connector to write the output**.\n\nI wrote the pipelines, but still, I spent the last 2 hours trying to find ways (or runners) to run Python and Go pipelines locally, but was very confused by the choices and nuances of data engineering. My work laptop is a Mac although I do have access to some Ubuntu and Arch Linux servers (I'd prefer to run it on my laptop).\n\nIs there a way to do this locally? Besides, is my design of having Python connectors and Go processors sound dumb? I will certainly come back for recommendation for querying Parquet files later, but now I just want to run the pipelines written in different language locally.", "author_fullname": "t2_7f6tvoo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to locally run Apache Beam pipelines written in Go and Python on macOS (or Linux)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15spz2h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692192578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a back-end dev currently tasked with designing and implementing indexing and storage systems for my company&amp;#39;s upcoming product.&lt;/p&gt;\n\n&lt;p&gt;Note that I&amp;#39;m very new to data engineering - having only read 70% of &amp;quot;Designing Data Intensive Applications&amp;quot; at the time of writing (the project hit before I was able to finish the book). Our team is small, and no one has hands-on experience in data engineering.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;We have a tool to dump raw data to Parquets, and then it&amp;#39;s my job to design a pipeline that consumes/transforms this raw data into something higher-level, and stored in Parquets (or something else depending on the data use case)&lt;/strong&gt;. There are actually more details to this, but we&amp;#39;d like to ship a PoC the design first. (i.e. details such as querying those higher-level Parquets).&lt;/p&gt;\n\n&lt;p&gt;I chose Apache Beam SDK for defining pipelines - in part because of Google Cloud Dataflow, which we will use in production.&lt;/p&gt;\n\n&lt;p&gt;Beam Go SDK does not have Parquet IO connector AFAIK, but Python SDK does. &lt;strong&gt;So my initial plan is to have Python &amp;quot;connector pipeline&amp;quot; to read Parquet files, send it to Go pipelines to do transformations, before sending the output to Python Parquet connector to write the output&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;I wrote the pipelines, but still, I spent the last 2 hours trying to find ways (or runners) to run Python and Go pipelines locally, but was very confused by the choices and nuances of data engineering. My work laptop is a Mac although I do have access to some Ubuntu and Arch Linux servers (I&amp;#39;d prefer to run it on my laptop).&lt;/p&gt;\n\n&lt;p&gt;Is there a way to do this locally? Besides, is my design of having Python connectors and Go processors sound dumb? I will certainly come back for recommendation for querying Parquet files later, but now I just want to run the pipelines written in different language locally.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15spz2h", "is_robot_indexable": true, "report_reasons": null, "author": "artnoi43", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15spz2h/best_way_to_locally_run_apache_beam_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15spz2h/best_way_to_locally_run_apache_beam_pipelines/", "subreddit_subscribers": 123102, "created_utc": 1692192578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm new to DE and PySpark. I'm trying to create an ETL code using PySpark where I need to fetch data from 3 files and do some data transformations and load it into single transformation. I'm confused when to join the data from the different sources? One approach is to create separate dataframes for each source and joining them into a single dataframe and then perform the transformations. The other approach is start working on one df and join only when a column from other df is needed for any data transformations. In this approach, I will do the join when I'm doing the transformation. I'm not sure if the second approach is completely feasible. I need the code to be efficient. Any thoughts on this? Any alternative approach?", "author_fullname": "t2_cnbdxnrd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When to Join the sources into single dataframe? before or while doing transformations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sp1xl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692190270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to DE and PySpark. I&amp;#39;m trying to create an ETL code using PySpark where I need to fetch data from 3 files and do some data transformations and load it into single transformation. I&amp;#39;m confused when to join the data from the different sources? One approach is to create separate dataframes for each source and joining them into a single dataframe and then perform the transformations. The other approach is start working on one df and join only when a column from other df is needed for any data transformations. In this approach, I will do the join when I&amp;#39;m doing the transformation. I&amp;#39;m not sure if the second approach is completely feasible. I need the code to be efficient. Any thoughts on this? Any alternative approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15sp1xl", "is_robot_indexable": true, "report_reasons": null, "author": "ibrx8", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sp1xl/when_to_join_the_sources_into_single_dataframe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sp1xl/when_to_join_the_sources_into_single_dataframe/", "subreddit_subscribers": 123102, "created_utc": 1692190270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys. So I've been working in Bangalore in an MNC for about 3 years now as an associate data engineer.\n\nBefore joining this company, I was an energetic, ambitious and hard working guy and was expecting a lot of developement work from my company. I was pretty good in coding and app development compared to my peers in college. \n\nBut after I joined my first company, things seemed alright. They put me mostly into SQL scripting work which was mostly SQL logic and nothing much of a development. I had even taken a home loan because me and my family had never actually owned a house so even after a year of SQL scripting, I thought I'll continue in the same company hoping to get a better project. This now turned from 1 year to 2 years and then 2 years to 3 years now and these guys have gotten me in the same project. My day to day work is almost the same as what I used to do the day I joined. I've asked my manager multiple times to give me some good project but they keep saying, just wait, we'll get you something good. Sometimes they say, you need to be \"proactive\" and create your own PoC project. I did learn stuff via courses but I feel that if we don't get any projects related to what we studied, it's of no use. I don't even have any teamate who is a data engineers to guild me since the last 2 years. My product manager doesn't care about me or my ambition. They keep dumping the same work over and over.\n\nIt sickens me to think that, all those years in college where I put more effort into programming, and my managers haven't utilised me at all. All my friends who wasted time and had fun in college are now earning better than me and are in good projects. \n\nNow, I am trying to search jobs in other companies and I see that the market expects a lot from a 3 year experienced guy. I feel very incompetent, very anxious thinking that no one might employee me because of my lack of exposure. \n\nMy question here is, is there any way where I can start over as a data engineer where I can apply for fresher job or a 1 year experience job in decent product based companies (I've seen third party company employees being treated like dirt, with constant threat of getting released from the project). I wouldn't mind having the same salary or even slightly lesser (10-20% lower) but is such a thing possible where I go to a company which is offering a 1 year experience job. I explain them what actually happened in my company, how I've got to work only on SQL and expect them to train in and put me in a good development project. Are such things possible in IT field? Please let me know your thoughts. \n\nThank you.", "author_fullname": "t2_is9w2714", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "3 years of work and I still feel like a fresher", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15t7wii", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692233668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. So I&amp;#39;ve been working in Bangalore in an MNC for about 3 years now as an associate data engineer.&lt;/p&gt;\n\n&lt;p&gt;Before joining this company, I was an energetic, ambitious and hard working guy and was expecting a lot of developement work from my company. I was pretty good in coding and app development compared to my peers in college. &lt;/p&gt;\n\n&lt;p&gt;But after I joined my first company, things seemed alright. They put me mostly into SQL scripting work which was mostly SQL logic and nothing much of a development. I had even taken a home loan because me and my family had never actually owned a house so even after a year of SQL scripting, I thought I&amp;#39;ll continue in the same company hoping to get a better project. This now turned from 1 year to 2 years and then 2 years to 3 years now and these guys have gotten me in the same project. My day to day work is almost the same as what I used to do the day I joined. I&amp;#39;ve asked my manager multiple times to give me some good project but they keep saying, just wait, we&amp;#39;ll get you something good. Sometimes they say, you need to be &amp;quot;proactive&amp;quot; and create your own PoC project. I did learn stuff via courses but I feel that if we don&amp;#39;t get any projects related to what we studied, it&amp;#39;s of no use. I don&amp;#39;t even have any teamate who is a data engineers to guild me since the last 2 years. My product manager doesn&amp;#39;t care about me or my ambition. They keep dumping the same work over and over.&lt;/p&gt;\n\n&lt;p&gt;It sickens me to think that, all those years in college where I put more effort into programming, and my managers haven&amp;#39;t utilised me at all. All my friends who wasted time and had fun in college are now earning better than me and are in good projects. &lt;/p&gt;\n\n&lt;p&gt;Now, I am trying to search jobs in other companies and I see that the market expects a lot from a 3 year experienced guy. I feel very incompetent, very anxious thinking that no one might employee me because of my lack of exposure. &lt;/p&gt;\n\n&lt;p&gt;My question here is, is there any way where I can start over as a data engineer where I can apply for fresher job or a 1 year experience job in decent product based companies (I&amp;#39;ve seen third party company employees being treated like dirt, with constant threat of getting released from the project). I wouldn&amp;#39;t mind having the same salary or even slightly lesser (10-20% lower) but is such a thing possible where I go to a company which is offering a 1 year experience job. I explain them what actually happened in my company, how I&amp;#39;ve got to work only on SQL and expect them to train in and put me in a good development project. Are such things possible in IT field? Please let me know your thoughts. &lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15t7wii", "is_robot_indexable": true, "report_reasons": null, "author": "walter_bhai", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15t7wii/3_years_of_work_and_i_still_feel_like_a_fresher/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15t7wii/3_years_of_work_and_i_still_feel_like_a_fresher/", "subreddit_subscribers": 123102, "created_utc": 1692233668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're currently in the process of shifting from SQL server -&gt; PowerBi datasets to Databricks -&gt; Powerbi for viz. My question is do we still want to create datasets in powerbi looking at the tables in gold (lakehouse)? We built a star model using our gold tables in the lakehouse and published as a dataset and it seems to be slow when refreshing/exploring data. Is this normal? We're also looking to shit to Databricks SQL and dbt in the future. Wouldn't we do a select * on dbt views instead of building star schemas out of dbt models? \n\nAny ideas/advice would be helpful!", "author_fullname": "t2_56ltry44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks and PowerBI for viz", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15t74zk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692231723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re currently in the process of shifting from SQL server -&amp;gt; PowerBi datasets to Databricks -&amp;gt; Powerbi for viz. My question is do we still want to create datasets in powerbi looking at the tables in gold (lakehouse)? We built a star model using our gold tables in the lakehouse and published as a dataset and it seems to be slow when refreshing/exploring data. Is this normal? We&amp;#39;re also looking to shit to Databricks SQL and dbt in the future. Wouldn&amp;#39;t we do a select * on dbt views instead of building star schemas out of dbt models? &lt;/p&gt;\n\n&lt;p&gt;Any ideas/advice would be helpful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15t74zk", "is_robot_indexable": true, "report_reasons": null, "author": "Specific-Passage", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15t74zk/databricks_and_powerbi_for_viz/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15t74zk/databricks_and_powerbi_for_viz/", "subreddit_subscribers": 123102, "created_utc": 1692231723.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, \n\nHas anyone ever had the need to transpose a data frame using PySpark? Is the transpose operation slow or resource intensive even for smaller datasets?\n\nI\u2019m on a project with a pretty denormalized table in a DB that has a bunch of Boolean columns to store information about customers and I\u2019m trying to come up with a way to return the actual column metadata (aka descriptions tied to the Boolean flags) back to my end user. \n\nSo far my end user has communicated to me that they need the tables to research customers who meet/do not meet certain conditions which vary depending on the flag (aka column) in question. However said end user isn\u2019t very tech savvy so I\u2019m thinking about transposing the data frame so that a given customer id is the column name thus enabling me to run \u201c where customer_id = 1\u201d or something like that. Then I\u2019ll have the rows (flags) that were True for a particular customer. \n\nIs this a naive approach? We are talking about 300 Boolean columns here and on average 1.5million total customers. \n\nThanks!", "author_fullname": "t2_s3fda0o9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transposing a table using PySpark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15t5pat", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692228210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;Has anyone ever had the need to transpose a data frame using PySpark? Is the transpose operation slow or resource intensive even for smaller datasets?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m on a project with a pretty denormalized table in a DB that has a bunch of Boolean columns to store information about customers and I\u2019m trying to come up with a way to return the actual column metadata (aka descriptions tied to the Boolean flags) back to my end user. &lt;/p&gt;\n\n&lt;p&gt;So far my end user has communicated to me that they need the tables to research customers who meet/do not meet certain conditions which vary depending on the flag (aka column) in question. However said end user isn\u2019t very tech savvy so I\u2019m thinking about transposing the data frame so that a given customer id is the column name thus enabling me to run \u201c where customer_id = 1\u201d or something like that. Then I\u2019ll have the rows (flags) that were True for a particular customer. &lt;/p&gt;\n\n&lt;p&gt;Is this a naive approach? We are talking about 300 Boolean columns here and on average 1.5million total customers. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15t5pat", "is_robot_indexable": true, "report_reasons": null, "author": "lmao_unemployment", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15t5pat/transposing_a_table_using_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15t5pat/transposing_a_table_using_pyspark/", "subreddit_subscribers": 123102, "created_utc": 1692228210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for a suitable version and migration tool with CLI to use within GitHub action that is compatible with ClickHouse but haven't been successful so far in finding an easy to implement one. \n\nThere is [this](https://clickhouse.com/docs/knowledgebase/schema_migration_tools) list provided by ClickHouse but the options are not that much. What might be the best tool based on my requirements?", "author_fullname": "t2_e9jrhv5r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best database versioning/migration tool for clickhouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sxrmr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692210307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a suitable version and migration tool with CLI to use within GitHub action that is compatible with ClickHouse but haven&amp;#39;t been successful so far in finding an easy to implement one. &lt;/p&gt;\n\n&lt;p&gt;There is &lt;a href=\"https://clickhouse.com/docs/knowledgebase/schema_migration_tools\"&gt;this&lt;/a&gt; list provided by ClickHouse but the options are not that much. What might be the best tool based on my requirements?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?auto=webp&amp;s=b940f46a49700ae6e7892c951cb95b789b4ba807", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=952c9f478be63886c09db18a9321b7fad4cc815b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2468cd9d65f58f2bdeb5acf2806c8fcebf508d30", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3f11b7c42d4af2519525a18ac33e345598d55c2e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=40cd5353357726396d15e6b8fbe58c3deb300183", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0cce7914b15ddbc737c673aca7ab1750e1e3b737", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/yRFeAMvWvr-aCfh_gJAF4aUyYmzVjKT4OALYUIC3AXs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=86258b4f0cd45add3d8c44bd5256ecd1aadf419c", "width": 1080, "height": 540}], "variants": {}, "id": "7G0kkOcaGegJDbjqragKTYRV0shABWC_AhNkGPHD0Uw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15sxrmr", "is_robot_indexable": true, "report_reasons": null, "author": "AH1376", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sxrmr/best_database_versioningmigration_tool_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sxrmr/best_database_versioningmigration_tool_for/", "subreddit_subscribers": 123102, "created_utc": 1692210307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm trying to find a tool where our data-engineers can create visualizations in a tool such as superset/metabase and then visualize it in a frontend app.\n\nSeems like superset and similar tools mostly offers embedding through iframe which is not optimal. Is there some other tool which offer similar solutions which is easier to embed into a react app?\n\nAlso would be interested in a tool which creates an REST-api on top of a SQL query", "author_fullname": "t2_5gpux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Embed charts from data-visualization tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15staep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692200325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to find a tool where our data-engineers can create visualizations in a tool such as superset/metabase and then visualize it in a frontend app.&lt;/p&gt;\n\n&lt;p&gt;Seems like superset and similar tools mostly offers embedding through iframe which is not optimal. Is there some other tool which offer similar solutions which is easier to embed into a react app?&lt;/p&gt;\n\n&lt;p&gt;Also would be interested in a tool which creates an REST-api on top of a SQL query&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15staep", "is_robot_indexable": true, "report_reasons": null, "author": "muffa", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15staep/embed_charts_from_datavisualization_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15staep/embed_charts_from_datavisualization_tool/", "subreddit_subscribers": 123102, "created_utc": 1692200325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_qvzmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running Apache Flink Applications on AWS KDA: Lessons Learnt at Deliveroo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15slh7h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lhs2FF7qUs0W8LUM1OUJRXGKRmyC32D1ErMTtgRN-VA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692179891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoq.com/news/2023/08/deliveroo-apache-flink-aws-kda/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?auto=webp&amp;s=d2787db035351c6aaf4d3593e280cda084bf7e20", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=24f64e8f70f9f8182dcc3b8042bc088424dfd4b5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4396e2557f26214eda6d1e97ea6b2fa8441e483a", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9935d2c372bdaa13584c646990280074a3cee475", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8535bfde9f06a80c0d9855d09834571316c11942", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0d86e00c83ab012d51bc7bc223ad35a68ed17b4c", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/HIhPDFVsUNWoiL1HoAycMVlzIgO_Z1yF_7ATM_zarLA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a58aa5e6f4844ed9782081ab4412baa2f504002d", "width": 1080, "height": 567}], "variants": {}, "id": "4pqSuGmF3d7Vr6ujI_YrmtYXFnSgjWbWnSjdeot4qgI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15slh7h", "is_robot_indexable": true, "report_reasons": null, "author": "rgancarz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15slh7h/running_apache_flink_applications_on_aws_kda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoq.com/news/2023/08/deliveroo-apache-flink-aws-kda/", "subreddit_subscribers": 123102, "created_utc": 1692179891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do we have extensions to support it?", "author_fullname": "t2_4ck30tok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can VSCode be used for dbt cloud project development?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sdo0h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692154982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do we have extensions to support it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15sdo0h", "is_robot_indexable": true, "report_reasons": null, "author": "Nomad4455", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sdo0h/can_vscode_be_used_for_dbt_cloud_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sdo0h/can_vscode_be_used_for_dbt_cloud_project/", "subreddit_subscribers": 123102, "created_utc": 1692154982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_16q5j0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing continuous data pipelines for low latency using Snowpipe Streaming API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 59, "top_awarded_type": null, "hide_score": false, "name": "t3_15sbbzc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iA1DghiHC6GTUf2IwxcknP5ggnZMgIOGV99nolFw-Rw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692148765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/snowflake/optimizing-continuous-data-pipelines-for-low-latency-using-snowpipe-streaming-api-in-striim-507a7798b0fc", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?auto=webp&amp;s=6a0fe9cf445f64cf4be45042681a85fdb00affd6", "width": 1200, "height": 507}, "resolutions": [{"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=96b21b1687cc27b97f0f55d653679369aa33d94a", "width": 108, "height": 45}, {"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bad42a4659dd0a2c3c18d3182ad3f37a626884e6", "width": 216, "height": 91}, {"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=63b3b562678b405f3786dd6883052f7059c6e757", "width": 320, "height": 135}, {"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca29cefb11659e539bd65fab148dbc079b5c2785", "width": 640, "height": 270}, {"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=07b1a32f98d85b7c553719424cef17d547d54ba5", "width": 960, "height": 405}, {"url": "https://external-preview.redd.it/VyhNBMoTUiFmFEkUyuiN4M9c-Gg-Y0frhJ7MI-re0_g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9188da05ac2b5100d9991369c131472418d97c78", "width": 1080, "height": 456}], "variants": {}, "id": "zwFg9gsMOgjOEr51sL9OJAOAXFvRCfJ4Fs61rmqVF1I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15sbbzc", "is_robot_indexable": true, "report_reasons": null, "author": "audiologician", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sbbzc/optimizing_continuous_data_pipelines_for_low/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/snowflake/optimizing-continuous-data-pipelines-for-low-latency-using-snowpipe-streaming-api-in-striim-507a7798b0fc", "subreddit_subscribers": 123102, "created_utc": 1692148765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nIm new here! I hope you don't mind me asking for advice. I'm a new dev and new to the data scene.\n\nBut I would like to ask if you were to construct an airbnb app, how would you structure the images in the sql and folders?\n\nI would imagine it would state-&gt; province -&gt; city\n\n I think using a tree structure would be best for the folders, but would you have to implement the structure in the SQL? Would you need to store all the file names in a sql table called images, or like would you just save everything in the folder and just retrieve everything inside a folder?\n\nAny advice is truly appreciated!", "author_fullname": "t2_s9o0vtx7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would airbnb manage their folders and images?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15sfg1l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692162029.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692160265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Im new here! I hope you don&amp;#39;t mind me asking for advice. I&amp;#39;m a new dev and new to the data scene.&lt;/p&gt;\n\n&lt;p&gt;But I would like to ask if you were to construct an airbnb app, how would you structure the images in the sql and folders?&lt;/p&gt;\n\n&lt;p&gt;I would imagine it would state-&amp;gt; province -&amp;gt; city&lt;/p&gt;\n\n&lt;p&gt;I think using a tree structure would be best for the folders, but would you have to implement the structure in the SQL? Would you need to store all the file names in a sql table called images, or like would you just save everything in the folder and just retrieve everything inside a folder?&lt;/p&gt;\n\n&lt;p&gt;Any advice is truly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15sfg1l", "is_robot_indexable": true, "report_reasons": null, "author": "IwannabeCrow", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15sfg1l/how_would_airbnb_manage_their_folders_and_images/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15sfg1l/how_would_airbnb_manage_their_folders_and_images/", "subreddit_subscribers": 123102, "created_utc": 1692160265.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}