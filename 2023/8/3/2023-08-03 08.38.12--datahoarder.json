{"kind": "Listing", "data": {"after": "t3_15gopv7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know the reported limit was supposed to be limited increases to 10TB per week, 40TB per month, but they recently changed it again, to be 1TB per month, 250GB per week, which works out at around 35.7GB per day.\n\nAt the price they charge (requiring 3 users), it really is pathetically bad.\n\nI have no idea what effect this has on enterprise users.", "author_fullname": "t2_m2qke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dropbox now limiting advanced plans to 1TB per month, 250GB per week, 35.7GB per day.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gf2rc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 189, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Cloud", "can_mod_post": false, "score": 189, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690997311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know the reported limit was supposed to be limited increases to 10TB per week, 40TB per month, but they recently changed it again, to be 1TB per month, 250GB per week, which works out at around 35.7GB per day.&lt;/p&gt;\n\n&lt;p&gt;At the price they charge (requiring 3 users), it really is pathetically bad.&lt;/p&gt;\n\n&lt;p&gt;I have no idea what effect this has on enterprise users.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "688TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15gf2rc", "is_robot_indexable": true, "report_reasons": null, "author": "jl94x4", "discussion_type": null, "num_comments": 178, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15gf2rc/dropbox_now_limiting_advanced_plans_to_1tb_per/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gf2rc/dropbox_now_limiting_advanced_plans_to_1tb_per/", "subreddit_subscribers": 696057, "created_utc": 1690997311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am just wondering why there are no 3.5\" SSDs.\nIt could be a 3.5\" plastic housing fully stacked with flash storage.\nMaybe I could not find them but if there aren't: Why?", "author_fullname": "t2_d8wthq9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are there no 3.5\" SDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gfewp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690998067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am just wondering why there are no 3.5&amp;quot; SSDs.\nIt could be a 3.5&amp;quot; plastic housing fully stacked with flash storage.\nMaybe I could not find them but if there aren&amp;#39;t: Why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gfewp", "is_robot_indexable": true, "report_reasons": null, "author": "ajfriesen", "discussion_type": null, "num_comments": 67, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gfewp/why_are_there_no_35_sdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gfewp/why_are_there_no_35_sdds/", "subreddit_subscribers": 696057, "created_utc": 1690998067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_yu95m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Issue with a new WD Red Plus 8TB CMR drive: Windows 10 can't detect more than 1308GB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 62, "top_awarded_type": null, "hide_score": false, "name": "t3_15ge9zw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/zxhkgcSA-TTMfWEiiRjTHEfKmC1pn9PeSTmgE7LKzvI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690995508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/n0eoadak9qfb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/n0eoadak9qfb1.png?auto=webp&amp;s=d1cf07fcfa57da6e12655ce3709100ccfa6c0f1c", "width": 510, "height": 229}, "resolutions": [{"url": "https://preview.redd.it/n0eoadak9qfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7fecdd3d2ebd164b57595945289840be9beca655", "width": 108, "height": 48}, {"url": "https://preview.redd.it/n0eoadak9qfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b82caea711a3f22717163c754c578ad2f421612", "width": 216, "height": 96}, {"url": "https://preview.redd.it/n0eoadak9qfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5197959b16caf93ac76f8a01148851b3cd661121", "width": 320, "height": 143}], "variants": {}, "id": "0NfVQm1iaxy79zoGgdH4EEpJQl0_3B3Qq2SGFPlJb8k"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ge9zw", "is_robot_indexable": true, "report_reasons": null, "author": "SpaceGenesis", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ge9zw/issue_with_a_new_wd_red_plus_8tb_cmr_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/n0eoadak9qfb1.png", "subreddit_subscribers": 696057, "created_utc": 1690995508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have seen multiple comments on some buyers from specific Hard Drive models which in common are bigger than usual (over 10 TB), the reviewers saying they make more noise than usual. Is this a common trait from all the newer HDDs? Or just a few of them?\n\nP.S. I just discovered a thread from 1 year ago asking the same:\n\n[https://www.reddit.com/r/DataHoarder/comments/st97qo/question\\_do\\_hard\\_drives\\_get\\_louder\\_as\\_they\\_get/](https://www.reddit.com/r/DataHoarder/comments/st97qo/question_do_hard_drives_get_louder_as_they_get/)\n\nIt looks like I wasn't the only one noticing this. And I wanted to ask this here even before finding out that thread!", "author_fullname": "t2_1utoiwm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's all this complaint about bigger HDDs being noisier?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gd0wo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690992625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have seen multiple comments on some buyers from specific Hard Drive models which in common are bigger than usual (over 10 TB), the reviewers saying they make more noise than usual. Is this a common trait from all the newer HDDs? Or just a few of them?&lt;/p&gt;\n\n&lt;p&gt;P.S. I just discovered a thread from 1 year ago asking the same:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/st97qo/question_do_hard_drives_get_louder_as_they_get/\"&gt;https://www.reddit.com/r/DataHoarder/comments/st97qo/question_do_hard_drives_get_louder_as_they_get/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It looks like I wasn&amp;#39;t the only one noticing this. And I wanted to ask this here even before finding out that thread!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gd0wo", "is_robot_indexable": true, "report_reasons": null, "author": "Maratocarde", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gd0wo/whats_all_this_complaint_about_bigger_hdds_being/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gd0wo/whats_all_this_complaint_about_bigger_hdds_being/", "subreddit_subscribers": 696057, "created_utc": 1690992625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I joined a course and to view the course content I have to install specific player which does not allow screenshot/screen recorders etc. So the only way I can think of maintaining a copy for myself is to record the screen with a secondary camera. But that sounds extremely 90s :)\n\nI am wondering if any of you have found a way to workaround this?", "author_fullname": "t2_aawlefye", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have a DRM video that only runs with its own player - how do I record and maintain via a secondary cam?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15g9f16", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690984133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I joined a course and to view the course content I have to install specific player which does not allow screenshot/screen recorders etc. So the only way I can think of maintaining a copy for myself is to record the screen with a secondary camera. But that sounds extremely 90s :)&lt;/p&gt;\n\n&lt;p&gt;I am wondering if any of you have found a way to workaround this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15g9f16", "is_robot_indexable": true, "report_reasons": null, "author": "gosteneonic", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15g9f16/i_have_a_drm_video_that_only_runs_with_its_own/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15g9f16/i_have_a_drm_video_that_only_runs_with_its_own/", "subreddit_subscribers": 696057, "created_utc": 1690984133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i bought a course with access to vimeo videos\n\ni would like to watch the videos when offline and want to download them \n\nhow can i do this?\n\ni have tried a bunch of methods but they no longer seem to be working", "author_fullname": "t2_9yc35q28", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download vimeo membership videos august 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gqhjf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691026768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i bought a course with access to vimeo videos&lt;/p&gt;\n\n&lt;p&gt;i would like to watch the videos when offline and want to download them &lt;/p&gt;\n\n&lt;p&gt;how can i do this?&lt;/p&gt;\n\n&lt;p&gt;i have tried a bunch of methods but they no longer seem to be working&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gqhjf", "is_robot_indexable": true, "report_reasons": null, "author": "pandaman1339", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gqhjf/download_vimeo_membership_videos_august_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gqhjf/download_vimeo_membership_videos_august_2023/", "subreddit_subscribers": 696057, "created_utc": 1691026768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi Datahoarders! It's time to run another giveaway thread. This round, we are giving away a 480GB IronWolf Pro 125 SSD to one lucky winner in this thread.\n\nThe prize is: one 480GB IronWolf Pro 125 SSD\n\nHow to enter: Just reply to this post once with a comment about how the drive would help your datahoarding ways. We ask entrants to please include the terms RunWithIronWolf and Seagate in your comment to be considered for the prize drawing.\n\n\nSelection process/rules\n\nOne entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. Entries are open until Aug 16, 2023 at 23:59 UTC. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, and not to another comment, and not on any cross-posts). The tool will remove duplicate usernames, sort the list, and grab the randomly chosen username, at which point the winner will be contacted within a day or so of the giveaway ending. Winners will have 48 hrs to get us their physical address and contact details for shipping (no PO boxes). Any person who does not reply in time loses their spot and everyone moves up a tier. For example: the 1st place person does not respond, so the 2nd place person gets contacted. Seagate will use the information strictly for shipping purposes only and will ship the drive directly. We reserve the right to edit this post including this process and these rules without notice. This is reddit, after all.\n\nGeographic restrictions:\n\nOur policy is for our forums and Reddit giveaways to be global where local shipping and/or giveaway restrictions/current world events don\u2019t prevent us, however we are basing the below list of eligible counties from previous giveaways, as some counties have unique restrictions.\n\nUS\n\nCanada (will require a basic skills-based question if winner is chosen by law)\n\nBrazil\n\nSouth America\n\nUnited Kingdom\n\nGermany\n\nFrance\n\nIberia\n\nAustralia\n\nNew Zealand\n\nKorea\n\nIndia\n\nMalaysia\n\nSingapore\n\nChina\n\n\n---\nSeagate Technology | Official Forums Team\n\n---", "author_fullname": "t2_16nn7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Official Giveaway: August 2023 Seagate IronWolf SSD Giveaway!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gcq97", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": "", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "OFFICIAL", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690991995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Datahoarders! It&amp;#39;s time to run another giveaway thread. This round, we are giving away a 480GB IronWolf Pro 125 SSD to one lucky winner in this thread.&lt;/p&gt;\n\n&lt;p&gt;The prize is: one 480GB IronWolf Pro 125 SSD&lt;/p&gt;\n\n&lt;p&gt;How to enter: Just reply to this post once with a comment about how the drive would help your datahoarding ways. We ask entrants to please include the terms RunWithIronWolf and Seagate in your comment to be considered for the prize drawing.&lt;/p&gt;\n\n&lt;p&gt;Selection process/rules&lt;/p&gt;\n\n&lt;p&gt;One entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. Entries are open until Aug 16, 2023 at 23:59 UTC. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, and not to another comment, and not on any cross-posts). The tool will remove duplicate usernames, sort the list, and grab the randomly chosen username, at which point the winner will be contacted within a day or so of the giveaway ending. Winners will have 48 hrs to get us their physical address and contact details for shipping (no PO boxes). Any person who does not reply in time loses their spot and everyone moves up a tier. For example: the 1st place person does not respond, so the 2nd place person gets contacted. Seagate will use the information strictly for shipping purposes only and will ship the drive directly. We reserve the right to edit this post including this process and these rules without notice. This is reddit, after all.&lt;/p&gt;\n\n&lt;p&gt;Geographic restrictions:&lt;/p&gt;\n\n&lt;p&gt;Our policy is for our forums and Reddit giveaways to be global where local shipping and/or giveaway restrictions/current world events don\u2019t prevent us, however we are basing the below list of eligible counties from previous giveaways, as some counties have unique restrictions.&lt;/p&gt;\n\n&lt;p&gt;US&lt;/p&gt;\n\n&lt;p&gt;Canada (will require a basic skills-based question if winner is chosen by law)&lt;/p&gt;\n\n&lt;p&gt;Brazil&lt;/p&gt;\n\n&lt;p&gt;South America&lt;/p&gt;\n\n&lt;p&gt;United Kingdom&lt;/p&gt;\n\n&lt;p&gt;Germany&lt;/p&gt;\n\n&lt;p&gt;France&lt;/p&gt;\n\n&lt;p&gt;Iberia&lt;/p&gt;\n\n&lt;p&gt;Australia&lt;/p&gt;\n\n&lt;p&gt;New Zealand&lt;/p&gt;\n\n&lt;p&gt;Korea&lt;/p&gt;\n\n&lt;p&gt;India&lt;/p&gt;\n\n&lt;p&gt;Malaysia&lt;/p&gt;\n\n&lt;p&gt;Singapore&lt;/p&gt;\n\n&lt;p&gt;China&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Seagate Technology | Official Forums Team&lt;/p&gt;\n\n&lt;hr/&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "81f0a58e-b3f5-11ea-95d7-0e4db8ecc231", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "OFFICIAL SEAGATE", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "15gcq97", "is_robot_indexable": true, "report_reasons": null, "author": "Seagate_Surfer", "discussion_type": null, "num_comments": 45, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15gcq97/official_giveaway_august_2023_seagate_ironwolf/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/15gcq97/official_giveaway_august_2023_seagate_ironwolf/", "subreddit_subscribers": 696057, "created_utc": 1690991995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys\n\nLooking for a document scanning solution but I'm having a hard time finding machine suggestions because my requirements are a bit odd. \n\n\nWhat I need is a standalone document scanner that can directly email documents without it being hooked up to a pc. I'm going to need it to be wifi capable, and simple to use. Basically I want a machine to be able to directly scan and email to a destination with the push of one button. OCR is a bonus \n\nSo far I've found a company out of Texas called raven that fits the bill. Does anyone know of others? Do the brother machines have such a version? \n\n\nThanks in advance", "author_fullname": "t2_13ia7v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Document Scanner standalone with no PC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gulci", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691039000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys&lt;/p&gt;\n\n&lt;p&gt;Looking for a document scanning solution but I&amp;#39;m having a hard time finding machine suggestions because my requirements are a bit odd. &lt;/p&gt;\n\n&lt;p&gt;What I need is a standalone document scanner that can directly email documents without it being hooked up to a pc. I&amp;#39;m going to need it to be wifi capable, and simple to use. Basically I want a machine to be able to directly scan and email to a destination with the push of one button. OCR is a bonus &lt;/p&gt;\n\n&lt;p&gt;So far I&amp;#39;ve found a company out of Texas called raven that fits the bill. Does anyone know of others? Do the brother machines have such a version? &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gulci", "is_robot_indexable": true, "report_reasons": null, "author": "ArtVandalayInc", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gulci/document_scanner_standalone_with_no_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gulci/document_scanner_standalone_with_no_pc/", "subreddit_subscribers": 696057, "created_utc": 1691039000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a weird problem. I bought a All Region Japanese drama (Kimi Wa Petto 2003) on eBay, which came as three DVDs. I had no problem with disc 2 and 3, but Windows alternately wouldn't recognize that there was a DVD in the drive and recognized it, but MakeMKV couldn't successfully rip it.\n\nI contacted the seller and they sent me another disc 1. I'm having the same problem with that one. There don't seem to be any significant cracks, scratches or dents in either disc. I've cleaned both discs with a solution of water and rubbing alcohol. There is something that kind of looks like glue on the innermost ring of both discs, but it's also on discs 2 and 3, and those were fine.\n\nIt seems hard to believe that both discs just happen to have a physical defect. Does this make any sense?", "author_fullname": "t2_9l9q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't load DVD disc (1 of set of three)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15goseu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691022109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a weird problem. I bought a All Region Japanese drama (Kimi Wa Petto 2003) on eBay, which came as three DVDs. I had no problem with disc 2 and 3, but Windows alternately wouldn&amp;#39;t recognize that there was a DVD in the drive and recognized it, but MakeMKV couldn&amp;#39;t successfully rip it.&lt;/p&gt;\n\n&lt;p&gt;I contacted the seller and they sent me another disc 1. I&amp;#39;m having the same problem with that one. There don&amp;#39;t seem to be any significant cracks, scratches or dents in either disc. I&amp;#39;ve cleaned both discs with a solution of water and rubbing alcohol. There is something that kind of looks like glue on the innermost ring of both discs, but it&amp;#39;s also on discs 2 and 3, and those were fine.&lt;/p&gt;\n\n&lt;p&gt;It seems hard to believe that both discs just happen to have a physical defect. Does this make any sense?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15goseu", "is_robot_indexable": true, "report_reasons": null, "author": "debegray", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15goseu/cant_load_dvd_disc_1_of_set_of_three/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15goseu/cant_load_dvd_disc_1_of_set_of_three/", "subreddit_subscribers": 696057, "created_utc": 1691022109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all. \n\nFirst of all, I have found my people. I wish to become like you. \n\nBetween my grandmother passing away, and my mom gifting me 3 different types of scanners (best birthday present), I am planning to become the family data hoarder. \n\nThat being said, I have a very basic understanding of the computer lingo for data. I am not as bad as my parents. (I know the basics that someone under 50 would know. But not someone who dabbles past normie-college level stuff.) But I have so much to learn. There are some words on this subreddit that I'm still trying to wrap my head around. \n\nAnyway, I wanted to share my plan, and have you guys scrutinize it. \n\nGoal: To have a safe place for digital copies all of our family pictures and journals. \n\nPlan of Action: (This is where it gets rough.)   \n1) Learn more about 321, options of storage places, etc. \n\n2) Scan all family photos/journals. And save collection onto an external SSD. (Q: is SSD just as good as hard drives? I have almost a PTSD of hard drives breaking, so I like ssds better.) \n\n3) Copy that external drive onto another one, maybe two(?)\n\n4)  Find a cloud service, and save the collection there. \n\n5) Offer to make copies of hard drives to give to family members with all the data. \n\n6) Make hard copies (photo albums or printed versions) for easy access for extended family members.\n\n&amp;#x200B;\n\nWhat do you guys think? I'm open to all suggestions, and I'm still learning and researching on this reddit page.   \nAlso, do you guys have any suggestions for further reading? Stuff that's easy for a normie to understand.  ", "author_fullname": "t2_1yaha5ut", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Data Hoader (of the family files clan) needing basic help to get started...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gk29o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691008614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all. &lt;/p&gt;\n\n&lt;p&gt;First of all, I have found my people. I wish to become like you. &lt;/p&gt;\n\n&lt;p&gt;Between my grandmother passing away, and my mom gifting me 3 different types of scanners (best birthday present), I am planning to become the family data hoarder. &lt;/p&gt;\n\n&lt;p&gt;That being said, I have a very basic understanding of the computer lingo for data. I am not as bad as my parents. (I know the basics that someone under 50 would know. But not someone who dabbles past normie-college level stuff.) But I have so much to learn. There are some words on this subreddit that I&amp;#39;m still trying to wrap my head around. &lt;/p&gt;\n\n&lt;p&gt;Anyway, I wanted to share my plan, and have you guys scrutinize it. &lt;/p&gt;\n\n&lt;p&gt;Goal: To have a safe place for digital copies all of our family pictures and journals. &lt;/p&gt;\n\n&lt;p&gt;Plan of Action: (This is where it gets rough.)&lt;br/&gt;\n1) Learn more about 321, options of storage places, etc. &lt;/p&gt;\n\n&lt;p&gt;2) Scan all family photos/journals. And save collection onto an external SSD. (Q: is SSD just as good as hard drives? I have almost a PTSD of hard drives breaking, so I like ssds better.) &lt;/p&gt;\n\n&lt;p&gt;3) Copy that external drive onto another one, maybe two(?)&lt;/p&gt;\n\n&lt;p&gt;4)  Find a cloud service, and save the collection there. &lt;/p&gt;\n\n&lt;p&gt;5) Offer to make copies of hard drives to give to family members with all the data. &lt;/p&gt;\n\n&lt;p&gt;6) Make hard copies (photo albums or printed versions) for easy access for extended family members.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What do you guys think? I&amp;#39;m open to all suggestions, and I&amp;#39;m still learning and researching on this reddit page.&lt;br/&gt;\nAlso, do you guys have any suggestions for further reading? Stuff that&amp;#39;s easy for a normie to understand.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gk29o", "is_robot_indexable": true, "report_reasons": null, "author": "Rayesafan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gk29o/new_data_hoader_of_the_family_files_clan_needing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gk29o/new_data_hoader_of_the_family_files_clan_needing/", "subreddit_subscribers": 696057, "created_utc": 1691008614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a way to view link rot from imgur due to that stupid policy? Either by replacing the original imgur link with the new link (maybe link come from archive database (could be from ArchiveTeam or not)) with an extension or Android redirect app?\n\nEdit: looks like the database is https://archive.org/details/archiveteam_imgur , however I'm not sure if there tool to redirect imgur link to that db?", "author_fullname": "t2_ish5z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imgur link rot viewer? Or viewing whatever ArchiveTeam grabbed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gf3hw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690997363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a way to view link rot from imgur due to that stupid policy? Either by replacing the original imgur link with the new link (maybe link come from archive database (could be from ArchiveTeam or not)) with an extension or Android redirect app?&lt;/p&gt;\n\n&lt;p&gt;Edit: looks like the database is &lt;a href=\"https://archive.org/details/archiveteam_imgur\"&gt;https://archive.org/details/archiveteam_imgur&lt;/a&gt; , however I&amp;#39;m not sure if there tool to redirect imgur link to that db?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "50TB TrueNAS MiniX+ | 2TB OneDrive", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gf3hw", "is_robot_indexable": true, "report_reasons": null, "author": "Trung0246", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15gf3hw/imgur_link_rot_viewer_or_viewing_whatever/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gf3hw/imgur_link_rot_viewer_or_viewing_whatever/", "subreddit_subscribers": 696057, "created_utc": 1690997363.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there something I can do about this?", "author_fullname": "t2_ayg3u4ys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I used a VPN to access videos that were unavaliable in the US but when I try to download them it doesn't work? Any help?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gv7ot", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691041021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there something I can do about this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gv7ot", "is_robot_indexable": true, "report_reasons": null, "author": "DifferentDaySameShii", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gv7ot/i_used_a_vpn_to_access_videos_that_were/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gv7ot/i_used_a_vpn_to_access_videos_that_were/", "subreddit_subscribers": 696057, "created_utc": 1691041021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "# Need advice on digitizing old photos.\n\n**TLDR:** I want to digitize my old photos with high quality and low cost. Which scanner should I buy?\n\nI need some advice on digitizing my thousands of printed album pictures. I have only Photo prints, and I don't have the negatives or slides. After trying PhotoMyne, I was not happy with the image quality, even though I used a photo tent and a phone stand with my iPhone 14 Pro Max.\n\nI am thinking of buying a scanner to get better results. I did some research and found three models that seem promising: FastFoto FF-680W High-speed Scanning System, Epson Perfection 19 II, and Epson Perfection 39 II. My main concern is image quality, not speed, and I want to spend as little as possible. The prices vary from around $80 to $560.\n\nMy pictures are mostly 15x10 cm, but some are larger or smaller. I like the option to auto-enhance or auto-edit them after scanning.\n\nCan anyone recommend the best scanner for my needs? Or suggest another option that I haven't considered? I would appreciate feedback from other Redditors who have experience with digitizing photos.", "author_fullname": "t2_s099iylx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on digitizing old photos.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15g7jnm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690979033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Need advice on digitizing old photos.&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR:&lt;/strong&gt; I want to digitize my old photos with high quality and low cost. Which scanner should I buy?&lt;/p&gt;\n\n&lt;p&gt;I need some advice on digitizing my thousands of printed album pictures. I have only Photo prints, and I don&amp;#39;t have the negatives or slides. After trying PhotoMyne, I was not happy with the image quality, even though I used a photo tent and a phone stand with my iPhone 14 Pro Max.&lt;/p&gt;\n\n&lt;p&gt;I am thinking of buying a scanner to get better results. I did some research and found three models that seem promising: FastFoto FF-680W High-speed Scanning System, Epson Perfection 19 II, and Epson Perfection 39 II. My main concern is image quality, not speed, and I want to spend as little as possible. The prices vary from around $80 to $560.&lt;/p&gt;\n\n&lt;p&gt;My pictures are mostly 15x10 cm, but some are larger or smaller. I like the option to auto-enhance or auto-edit them after scanning.&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend the best scanner for my needs? Or suggest another option that I haven&amp;#39;t considered? I would appreciate feedback from other Redditors who have experience with digitizing photos.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15g7jnm", "is_robot_indexable": true, "report_reasons": null, "author": "ArgyleDiamonds", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15g7jnm/need_advice_on_digitizing_old_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15g7jnm/need_advice_on_digitizing_old_photos/", "subreddit_subscribers": 696057, "created_utc": 1690979033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Don't link me the long list of posts asking about dedupe software, I already looked at it.\n\nI'm searching for a dedupe tool that does a very specific thing. I want it to rename the duplicate files and append to them the filename of the only copy that will remain.\n\nExample, 1.txt, 2.txt and 3.txt are the same file, only 1.txt will remain. I want 2.txt and 3.txt to be renamed to \"2.txt - copy of 1.txt\" and \"3.txt - copy of 1.txt\" respectively. If anyone can tell me a tool that can specifically do this, I'd be grateful.", "author_fullname": "t2_s47p7tie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dedupe software that will rename the duplicate files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gvhoc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691041951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Don&amp;#39;t link me the long list of posts asking about dedupe software, I already looked at it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m searching for a dedupe tool that does a very specific thing. I want it to rename the duplicate files and append to them the filename of the only copy that will remain.&lt;/p&gt;\n\n&lt;p&gt;Example, 1.txt, 2.txt and 3.txt are the same file, only 1.txt will remain. I want 2.txt and 3.txt to be renamed to &amp;quot;2.txt - copy of 1.txt&amp;quot; and &amp;quot;3.txt - copy of 1.txt&amp;quot; respectively. If anyone can tell me a tool that can specifically do this, I&amp;#39;d be grateful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gvhoc", "is_robot_indexable": true, "report_reasons": null, "author": "MattIsWhackRedux", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gvhoc/dedupe_software_that_will_rename_the_duplicate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gvhoc/dedupe_software_that_will_rename_the_duplicate/", "subreddit_subscribers": 696057, "created_utc": 1691041951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey friends,\n\nJust to let you know - I'm not much of a hoarder as some of you here, but I almost never delete my downloads, my projects, etc. I like to archive things and appreciate much of you here :))\n\nEither way, I'm developing a web service at the moment that will require stable and fast storage, and I've came across S3 Spaces from DigitalOcean.\n\nFor $5 monthly you get 250GB, after that it's $0.02 per GiB. Plus there's support for CDN, so if you decide to share some of those files with anyone, it's gonna be blazing fast all the time, from everywhere in the world.\n\nNow of course, for my use scenario, this is perfect, but thought to share it with you and ask if someone is using it as hoarding storage?\n\nhttps://docs.digitalocean.com/products/spaces/details/pricing/", "author_fullname": "t2_ra8t2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "S3 Storage for Hoarding?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15glkwi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691014145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey friends,&lt;/p&gt;\n\n&lt;p&gt;Just to let you know - I&amp;#39;m not much of a hoarder as some of you here, but I almost never delete my downloads, my projects, etc. I like to archive things and appreciate much of you here :))&lt;/p&gt;\n\n&lt;p&gt;Either way, I&amp;#39;m developing a web service at the moment that will require stable and fast storage, and I&amp;#39;ve came across S3 Spaces from DigitalOcean.&lt;/p&gt;\n\n&lt;p&gt;For $5 monthly you get 250GB, after that it&amp;#39;s $0.02 per GiB. Plus there&amp;#39;s support for CDN, so if you decide to share some of those files with anyone, it&amp;#39;s gonna be blazing fast all the time, from everywhere in the world.&lt;/p&gt;\n\n&lt;p&gt;Now of course, for my use scenario, this is perfect, but thought to share it with you and ask if someone is using it as hoarding storage?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.digitalocean.com/products/spaces/details/pricing/\"&gt;https://docs.digitalocean.com/products/spaces/details/pricing/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Jb-W-H0DJuDng6omApG0-lpSSt1FaO6CunSIYn9XNfQ.jpg?auto=webp&amp;s=a4e12b2bc2def63d409c641511babed52bfa4e6a", "width": 1012, "height": 565}, "resolutions": [{"url": "https://external-preview.redd.it/Jb-W-H0DJuDng6omApG0-lpSSt1FaO6CunSIYn9XNfQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=08d8cd753531a84b94ff166a19837a40afd2aaf8", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Jb-W-H0DJuDng6omApG0-lpSSt1FaO6CunSIYn9XNfQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a42f1335cf2ba9ad9e848c439c11e0733581fe15", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/Jb-W-H0DJuDng6omApG0-lpSSt1FaO6CunSIYn9XNfQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9a02241b6d494ca49fb9c1377831f0cc7b6b59a5", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/Jb-W-H0DJuDng6omApG0-lpSSt1FaO6CunSIYn9XNfQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=da3893192c67f4de5eb931bc9305a95179557a97", "width": 640, "height": 357}, {"url": "https://external-preview.redd.it/Jb-W-H0DJuDng6omApG0-lpSSt1FaO6CunSIYn9XNfQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=acc61e35e59fd6bb31b53d6afe5cad183bca944e", "width": 960, "height": 535}], "variants": {}, "id": "cbYjMkMcSADMZjGmXO6sNVK6R67XR__pV2jihy0dNWo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15glkwi", "is_robot_indexable": true, "report_reasons": null, "author": "likvidator", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15glkwi/s3_storage_for_hoarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15glkwi/s3_storage_for_hoarding/", "subreddit_subscribers": 696057, "created_utc": 1691014145.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was looking into a basic enclosure originally, when I first participated in my group, and thanks to this group, I've set my sights on the more ambitious goal of setting up a NAS enclosure.\n\nI'm a photographer, whose primary goal will be accessing and distributing my photos when necessary, with the idea to touch on some light video and media work as well. \n\nI have about 25tb spread among four 3.5 HDDs, and I am now looking into 4-5bay enclosures that will allow me to do as such. \n\nI do not think I have the bandwidth to approach making my own enclosure from scratch, so I'm looking both at the new and used markets for the right value and scalability for me. I would consider 6 bays, I don't think I'd dip under 30tb advertised storage capacity. RAID is not a priority for me. \n\nI'm wondering what products people would recommend, but also concerning the used market, what benchmarks I should look at for my needs. I've seen 16 bay synology setups for 700~CAD, but I don't have the full knowledge of what I might be sacrificing in purchasing an older system, in terms of software and hardware, and what is necessitated for NAS systems. Any advice or guidance would be greatly appreciated.", "author_fullname": "t2_3wglz1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NAS enclosure bechmarks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gjggy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691007225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was looking into a basic enclosure originally, when I first participated in my group, and thanks to this group, I&amp;#39;ve set my sights on the more ambitious goal of setting up a NAS enclosure.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a photographer, whose primary goal will be accessing and distributing my photos when necessary, with the idea to touch on some light video and media work as well. &lt;/p&gt;\n\n&lt;p&gt;I have about 25tb spread among four 3.5 HDDs, and I am now looking into 4-5bay enclosures that will allow me to do as such. &lt;/p&gt;\n\n&lt;p&gt;I do not think I have the bandwidth to approach making my own enclosure from scratch, so I&amp;#39;m looking both at the new and used markets for the right value and scalability for me. I would consider 6 bays, I don&amp;#39;t think I&amp;#39;d dip under 30tb advertised storage capacity. RAID is not a priority for me. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering what products people would recommend, but also concerning the used market, what benchmarks I should look at for my needs. I&amp;#39;ve seen 16 bay synology setups for 700~CAD, but I don&amp;#39;t have the full knowledge of what I might be sacrificing in purchasing an older system, in terms of software and hardware, and what is necessitated for NAS systems. Any advice or guidance would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gjggy", "is_robot_indexable": true, "report_reasons": null, "author": "AG24KT", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gjggy/nas_enclosure_bechmarks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gjggy/nas_enclosure_bechmarks/", "subreddit_subscribers": 696057, "created_utc": 1691007225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm working on a NAS that will scrape a variety of music websites for new content and download the files. Is there any program that can, say, once a day, scan the storage for new files and e-mail me with a list of the new files it finds?\n\nThis is intended to be used for music, and getting an e-mail saying something to the effect of \"these files were downloaded recently\" seems like it would be a very good way of keeping up to date on my favorite artists releasing new music.", "author_fullname": "t2_fc92z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Program that scans for new files and e-mails me details?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gglev", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691000694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a NAS that will scrape a variety of music websites for new content and download the files. Is there any program that can, say, once a day, scan the storage for new files and e-mail me with a list of the new files it finds?&lt;/p&gt;\n\n&lt;p&gt;This is intended to be used for music, and getting an e-mail saying something to the effect of &amp;quot;these files were downloaded recently&amp;quot; seems like it would be a very good way of keeping up to date on my favorite artists releasing new music.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gglev", "is_robot_indexable": true, "report_reasons": null, "author": "dstarr3", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gglev/program_that_scans_for_new_files_and_emails_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gglev/program_that_scans_for_new_files_and_emails_me/", "subreddit_subscribers": 696057, "created_utc": 1691000694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I Already Have 1TB HDD for just backup. I need a 2TB external ssd for gaming and backup. Performance is not a main requirement. I Prefer it to last longer. If there is m.2 or nvme internal ssd than can last longer. suggest it aswell. I am just buying external for just convinience. Please Recommend in budget similar to ones i added in poll or even may be lower.\n\n[View Poll](https://www.reddit.com/poll/15gxjm8)", "author_fullname": "t2_1pze8yb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2TB External SSD for Backup and Gaming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15gxjm8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691049020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I Already Have 1TB HDD for just backup. I need a 2TB external ssd for gaming and backup. Performance is not a main requirement. I Prefer it to last longer. If there is m.2 or nvme internal ssd than can last longer. suggest it aswell. I am just buying external for just convinience. Please Recommend in budget similar to ones i added in poll or even may be lower.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/15gxjm8\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gxjm8", "is_robot_indexable": true, "report_reasons": null, "author": "GTSaketh", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1691308220656, "options": [{"text": "Samsung T7", "id": "24179103"}, {"text": "MX500 with enclosure", "id": "24179104"}, {"text": "BX500 with enclosure", "id": "24179105"}, {"text": "Others (Recommend)", "id": "24179106"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 2, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gxjm8/2tb_external_ssd_for_backup_and_gaming/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/DataHoarder/comments/15gxjm8/2tb_external_ssd_for_backup_and_gaming/", "subreddit_subscribers": 696057, "created_utc": 1691049020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All,\n\n&amp;#x200B;\n\nMy names Dave and I'm addicted to shucking drives. (AA joke over now)\n\nSo I've been buying drives from various 2nd hand places/e-junk places mostly 4TB+ USB 3 HDD's and found that 99% of the time the USB controller had died but the HDD lives, of the 9 I've bought so far 1 the HDD was actually dead. I'm now kinda hooked on collecting them but I'm looking for a more elegant solution to store the drives than stacking them lol.\n\n&amp;#x200B;\n\nNow I don't own a 3D printer so that's out of the question and a plastic tub is too basic.\n\nDoes anyone know of either a HDD holder or HDD caddy that could hold more than two drives at a time? either USB or Network based?\n\n&amp;#x200B;\n\nAny help would be greatly appreciated.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_c9yop", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Elegant solution to holding shucked drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15gx2ox", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691047382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My names Dave and I&amp;#39;m addicted to shucking drives. (AA joke over now)&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;ve been buying drives from various 2nd hand places/e-junk places mostly 4TB+ USB 3 HDD&amp;#39;s and found that 99% of the time the USB controller had died but the HDD lives, of the 9 I&amp;#39;ve bought so far 1 the HDD was actually dead. I&amp;#39;m now kinda hooked on collecting them but I&amp;#39;m looking for a more elegant solution to store the drives than stacking them lol.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now I don&amp;#39;t own a 3D printer so that&amp;#39;s out of the question and a plastic tub is too basic.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know of either a HDD holder or HDD caddy that could hold more than two drives at a time? either USB or Network based?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any help would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gx2ox", "is_robot_indexable": true, "report_reasons": null, "author": "meowwentthedino", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gx2ox/elegant_solution_to_holding_shucked_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gx2ox/elegant_solution_to_holding_shucked_drives/", "subreddit_subscribers": 696057, "created_utc": 1691047382.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 970 EVO Plus 1tb in a Ugreen enclosure. I heard of the firmware updates so I downloaded Samsung magician and it shows my other drives as up to date but doesn\u2019t say anything about my NVME?\n\nWhat should I do or should I ignore it? Thanks", "author_fullname": "t2_5bcqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Updating 970 EVO Plus Firmware not available?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gh4au", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691001886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 970 EVO Plus 1tb in a Ugreen enclosure. I heard of the firmware updates so I downloaded Samsung magician and it shows my other drives as up to date but doesn\u2019t say anything about my NVME?&lt;/p&gt;\n\n&lt;p&gt;What should I do or should I ignore it? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gh4au", "is_robot_indexable": true, "report_reasons": null, "author": "hipsterinplaid", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gh4au/updating_970_evo_plus_firmware_not_available/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gh4au/updating_970_evo_plus_firmware_not_available/", "subreddit_subscribers": 696057, "created_utc": 1691001886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "While playing with SnapRAID/MergerFS and rtorrent, I came across problems with hash checking. It was noticeably slower compared to using a native (non-FUSE) filesystem such as ZFS. It sometimes even caused rtorrent to crash.\n\nMergerFS documentation explains you need to use special configuration (cache.files=partial) because of rtorrent's use of mmap syscall. Without it, hash checking won't even start. Problem is, the file caching has performance implications and in my case also leads to serious instability.\n\nUnhappy with this situation, I thought about possible workarounds and came up with a library which will modify file IO calls, essentially bypassing mergerfs, so that rtorrent can work directly with the underlying filesystem (then you can use the cache.files=off flag and rtorrent together).\n\nAFAIK, there's initiative to bring similar functionality into linux kernel which would give us the ultimate (and universal) solution. While waiting for future kernels and mergerfs 3.0, you're welcome to try  [nohajc/mergerfs-io-passthrough: A library for direct mergerfs file access. (github.com)](https://github.com/nohajc/mergerfs-io-passthrough).\n\nNote that while this method is not in principle limited to rtorrent, it is the only app I've tested so far.", "author_fullname": "t2_12z91w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MergerFS with rtorrent - performance/stability improvement", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gcd9o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690991152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While playing with SnapRAID/MergerFS and rtorrent, I came across problems with hash checking. It was noticeably slower compared to using a native (non-FUSE) filesystem such as ZFS. It sometimes even caused rtorrent to crash.&lt;/p&gt;\n\n&lt;p&gt;MergerFS documentation explains you need to use special configuration (cache.files=partial) because of rtorrent&amp;#39;s use of mmap syscall. Without it, hash checking won&amp;#39;t even start. Problem is, the file caching has performance implications and in my case also leads to serious instability.&lt;/p&gt;\n\n&lt;p&gt;Unhappy with this situation, I thought about possible workarounds and came up with a library which will modify file IO calls, essentially bypassing mergerfs, so that rtorrent can work directly with the underlying filesystem (then you can use the cache.files=off flag and rtorrent together).&lt;/p&gt;\n\n&lt;p&gt;AFAIK, there&amp;#39;s initiative to bring similar functionality into linux kernel which would give us the ultimate (and universal) solution. While waiting for future kernels and mergerfs 3.0, you&amp;#39;re welcome to try  &lt;a href=\"https://github.com/nohajc/mergerfs-io-passthrough\"&gt;nohajc/mergerfs-io-passthrough: A library for direct mergerfs file access. (github.com)&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Note that while this method is not in principle limited to rtorrent, it is the only app I&amp;#39;ve tested so far.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gcd9o", "is_robot_indexable": true, "report_reasons": null, "author": "nohajc", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gcd9o/mergerfs_with_rtorrent_performancestability/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gcd9o/mergerfs_with_rtorrent_performancestability/", "subreddit_subscribers": 696057, "created_utc": 1690991152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am getting some data of disks and then gonna burn to dual layer disks\n\nI used to use DVD Fab, crating ISO files in 30 minutes or less\n\n&amp;#x200B;\n\nTrying IMG BURN today because so many like it, well I am at the 2 hours mark, shows 0% complete, what to do?\n\nThe destination folder properties shows 6.96 GB so something is happening but it has been on 6.96 for a while", "author_fullname": "t2_viuwzrr1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IMG Burn taking several hours just to create an ISO file?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gahsc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690986780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am getting some data of disks and then gonna burn to dual layer disks&lt;/p&gt;\n\n&lt;p&gt;I used to use DVD Fab, crating ISO files in 30 minutes or less&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Trying IMG BURN today because so many like it, well I am at the 2 hours mark, shows 0% complete, what to do?&lt;/p&gt;\n\n&lt;p&gt;The destination folder properties shows 6.96 GB so something is happening but it has been on 6.96 for a while&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gahsc", "is_robot_indexable": true, "report_reasons": null, "author": "Rotisseriejedi", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gahsc/img_burn_taking_several_hours_just_to_create_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gahsc/img_burn_taking_several_hours_just_to_create_an/", "subreddit_subscribers": 696057, "created_utc": 1690986780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm upgrading my cold storage from 1tb toshiba SSD to a 4tb anything. Planning on buying sometime this week. What would you guys recommend?", "author_fullname": "t2_5lnt8f8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you guys have a preference for brands? Like seagate or toshiba or WD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gprm0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691024777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m upgrading my cold storage from 1tb toshiba SSD to a 4tb anything. Planning on buying sometime this week. What would you guys recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gprm0", "is_robot_indexable": true, "report_reasons": null, "author": "ac-2223", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gprm0/do_you_guys_have_a_preference_for_brands_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gprm0/do_you_guys_have_a_preference_for_brands_like/", "subreddit_subscribers": 696057, "created_utc": 1691024777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there! I'm hoping this is the appropriate subreddit for this question. I edit videos at a small production company where we are working on replacing our army of Sandisk Extreme Portable SSDs with Samsung T7 Shields. The drives go to and from shoots as well as to various editors who will usually keep the drives until the project is finished so it's necessary to keep track of which drives are where at any given time so each drive is named and tracked in a spreadsheet. With the Sandisk drives, I was able to slap a label from a label maker and it would stay put but because the T7s are silicone I can't find a good way to label them. So far I've been sticking the labels to the non-silicone butt end of the drive which is working ok but the label doesn't exactly fit and it limits the length of the name in order to fit on the drive. I tested writing directly on the drive with a Sharpie but it took no effort to wipe it off.\n\nDoes anyone have any methods of labeling these drives?", "author_fullname": "t2_puxal", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Labeling Samsung T7 Shield", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gpayk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691023511.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there! I&amp;#39;m hoping this is the appropriate subreddit for this question. I edit videos at a small production company where we are working on replacing our army of Sandisk Extreme Portable SSDs with Samsung T7 Shields. The drives go to and from shoots as well as to various editors who will usually keep the drives until the project is finished so it&amp;#39;s necessary to keep track of which drives are where at any given time so each drive is named and tracked in a spreadsheet. With the Sandisk drives, I was able to slap a label from a label maker and it would stay put but because the T7s are silicone I can&amp;#39;t find a good way to label them. So far I&amp;#39;ve been sticking the labels to the non-silicone butt end of the drive which is working ok but the label doesn&amp;#39;t exactly fit and it limits the length of the name in order to fit on the drive. I tested writing directly on the drive with a Sharpie but it took no effort to wipe it off.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any methods of labeling these drives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gpayk", "is_robot_indexable": true, "report_reasons": null, "author": "Vnerdham", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gpayk/labeling_samsung_t7_shield/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gpayk/labeling_samsung_t7_shield/", "subreddit_subscribers": 696057, "created_utc": 1691023511.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've decided to buy the 4-bay Synology DS423+ NAS and 2 x 6TB WD Red Plus HDDs to start with and will be using SHR rather than RAID. The drives that I put in my Newegg cart have a cache of 256 MB (Model No. WD60EFPX) but I found a deal on SlickDeals for 2 x 6TB WD Red Plus drives as long as they are the 128 MB cache models (Model No. WD60EFZX).\n\nIs the \\~$100 discount worth getting two drives with half the cache size or is the extra cache worth $60?", "author_fullname": "t2_u1hg2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does hard drive cache mean? Is it worth an extra expenditure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gopv7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1691022278.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691021915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve decided to buy the 4-bay Synology DS423+ NAS and 2 x 6TB WD Red Plus HDDs to start with and will be using SHR rather than RAID. The drives that I put in my Newegg cart have a cache of 256 MB (Model No. WD60EFPX) but I found a deal on SlickDeals for 2 x 6TB WD Red Plus drives as long as they are the 128 MB cache models (Model No. WD60EFZX).&lt;/p&gt;\n\n&lt;p&gt;Is the ~$100 discount worth getting two drives with half the cache size or is the extra cache worth $60?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gopv7", "is_robot_indexable": true, "report_reasons": null, "author": "BlueWizard3", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gopv7/what_does_hard_drive_cache_mean_is_it_worth_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gopv7/what_does_hard_drive_cache_mean_is_it_worth_an/", "subreddit_subscribers": 696057, "created_utc": 1691021915.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}