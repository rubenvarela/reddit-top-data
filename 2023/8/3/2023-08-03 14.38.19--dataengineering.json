{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As someone who has worked in the data field for nearly 20 years, I've noticed a shift in priorities when it comes to data modeling. In the early 2000s and 2010s, data modeling was of the utmost importance. However, with the introduction of Hadoop and big data, it seems that data and BI engineers no longer prioritize it. I'm curious about whether this is truly necessary in today's cloud-based world, where storage and computing are separate and we have various query processing engines based on different algorithms. I would love to hear your thoughts and feedback on this topic.", "author_fullname": "t2_7fhzjcsx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is traditional data modeling dead?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gf97e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 73, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 73, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690997721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As someone who has worked in the data field for nearly 20 years, I&amp;#39;ve noticed a shift in priorities when it comes to data modeling. In the early 2000s and 2010s, data modeling was of the utmost importance. However, with the introduction of Hadoop and big data, it seems that data and BI engineers no longer prioritize it. I&amp;#39;m curious about whether this is truly necessary in today&amp;#39;s cloud-based world, where storage and computing are separate and we have various query processing engines based on different algorithms. I would love to hear your thoughts and feedback on this topic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15gf97e", "is_robot_indexable": true, "report_reasons": null, "author": "New-Ship-5404", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15gf97e/is_traditional_data_modeling_dead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15gf97e/is_traditional_data_modeling_dead/", "subreddit_subscribers": 120141, "created_utc": 1690997721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6m7zr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Polars gets seed round of $4 million to build a compute platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15gzgne", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "ups": 71, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 71, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kbVgk99l0rQc7_ZBewJF90Uufn-DhAGCHHKqB1vQOkM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691055624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pola.rs", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.pola.rs/posts/company-announcement/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1SSqYHD_sA84nZzwre6h8wq5Kic14hF2CZqFprUbh0U.jpg?auto=webp&amp;s=9af49f3d253de5999b00a53a34995b08b8ae88d5", "width": 628, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/1SSqYHD_sA84nZzwre6h8wq5Kic14hF2CZqFprUbh0U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=340de8e22683ded39dc1414cd0f4086995405ebf", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/1SSqYHD_sA84nZzwre6h8wq5Kic14hF2CZqFprUbh0U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=409134a9198329163da028f2dfe5dc2e2480919a", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/1SSqYHD_sA84nZzwre6h8wq5Kic14hF2CZqFprUbh0U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=df1a090552d7181c4e1b992376626a65c7bedc03", "width": 320, "height": 320}], "variants": {}, "id": "GQEQ7WaJ43xmaAcrmZznZkixlQ7IFzW9Q8Sw1L0rwqQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15gzgne", "is_robot_indexable": true, "report_reasons": null, "author": "mailed", "discussion_type": null, "num_comments": 12, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15gzgne/polars_gets_seed_round_of_4_million_to_build_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.pola.rs/posts/company-announcement/", "subreddit_subscribers": 120141, "created_utc": 1691055624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There are a lot of engineering positions available today and plenty of departments and functions to expand into. One of the ones I see complained about the most is data engineering. Very similar to system or IT engineering, But seems to be very complained about and frowned upon overall. Everyone has some sort of cool background experience into engineering and IT whether it be infrastructure, being a DBA, analytics, machine learning... But when you hear about data engineering, immediate change in attitude. \n\n\nRecently, I interviewed for a position in IT engineering, and it was a lot of software as a service applications that they are supporting, using API and Python scripts to retrieve sets of data, supporting different applications that a business might use, managing compute resources in Google BigQuery and other apps. When I mentioned that I would love to be a data engineer in the future, they apologize and said I'm sorry for you. Thought it was kind of funny\n\n\nCurious what might cause the attitude that data engineering overall is boring, or it sucks. Is it because of the fact that you're working with databases most days, or is there something boring about piping data into data lakes, data warehouses, using Python for that?", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lots of people seem to hate data engineering. Is it really that bad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gizw0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691006182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are a lot of engineering positions available today and plenty of departments and functions to expand into. One of the ones I see complained about the most is data engineering. Very similar to system or IT engineering, But seems to be very complained about and frowned upon overall. Everyone has some sort of cool background experience into engineering and IT whether it be infrastructure, being a DBA, analytics, machine learning... But when you hear about data engineering, immediate change in attitude. &lt;/p&gt;\n\n&lt;p&gt;Recently, I interviewed for a position in IT engineering, and it was a lot of software as a service applications that they are supporting, using API and Python scripts to retrieve sets of data, supporting different applications that a business might use, managing compute resources in Google BigQuery and other apps. When I mentioned that I would love to be a data engineer in the future, they apologize and said I&amp;#39;m sorry for you. Thought it was kind of funny&lt;/p&gt;\n\n&lt;p&gt;Curious what might cause the attitude that data engineering overall is boring, or it sucks. Is it because of the fact that you&amp;#39;re working with databases most days, or is there something boring about piping data into data lakes, data warehouses, using Python for that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15gizw0", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15gizw0/lots_of_people_seem_to_hate_data_engineering_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15gizw0/lots_of_people_seem_to_hate_data_engineering_is/", "subreddit_subscribers": 120141, "created_utc": 1691006182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m fairly old school with lots of on prem and ssis/ssas experience. Been doing a ton more with cloud now but more on the E/L and infra and haven\u2019t gotten around to dbt yet.\n\nBut I\u2019ve wondered what has replaced the idea of a cube or enterprise star scheme with multiple facts to power reports and dashboards from a single source? \n\nAdditionally is the idea of self service via a cube style interface dead?\n\nIs it mostly dbt now and a sprawl of models users pick and choose from?\n\nI\u2019ve done a lot with power BI, but even that seems to focus on creating mini data models per report, so wondering how the reporting/dash data sources are scaled now.\n\nApologies if it seems like I\u2019m dense, just used to a semantic layer that creates common metrics and dims for people so they\u2019re all looking at the same things.", "author_fullname": "t2_eebo8h7ij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What replaced cubes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gnctu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691018421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m fairly old school with lots of on prem and ssis/ssas experience. Been doing a ton more with cloud now but more on the E/L and infra and haven\u2019t gotten around to dbt yet.&lt;/p&gt;\n\n&lt;p&gt;But I\u2019ve wondered what has replaced the idea of a cube or enterprise star scheme with multiple facts to power reports and dashboards from a single source? &lt;/p&gt;\n\n&lt;p&gt;Additionally is the idea of self service via a cube style interface dead?&lt;/p&gt;\n\n&lt;p&gt;Is it mostly dbt now and a sprawl of models users pick and choose from?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve done a lot with power BI, but even that seems to focus on creating mini data models per report, so wondering how the reporting/dash data sources are scaled now.&lt;/p&gt;\n\n&lt;p&gt;Apologies if it seems like I\u2019m dense, just used to a semantic layer that creates common metrics and dims for people so they\u2019re all looking at the same things.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15gnctu", "is_robot_indexable": true, "report_reasons": null, "author": "leaky_shrew", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15gnctu/what_replaced_cubes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15gnctu/what_replaced_cubes/", "subreddit_subscribers": 120141, "created_utc": 1691018421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lead data team here, I've been working as software engineer/data analyst/scientist/engineer/ML/infra for as long as I can remember, did my Masters in ML and did little bit of research back then, and right now I feel like I don't really want to work in tech company anymore since it's not profitable/barely alive. The investors hardly pour any money especially to Southeast Asia region as well, it's getting harder day by day.\n\nAnd I'm kinda tired with all these uncertainties, I've witnessed/experienced tears, layoffs, harsh treatment (because of frustration, yes I know very well making profitable &amp; sustainable business is extremely difficult), ridiculous work load which lead to mental health issue (I do have ADHD and it has been worsening the situation) and very unhealthy life, etc. Yeah, it was accumulated since 2015.\n\nSo here's my question. For those of you guys who quitted job from tech company what were your options back then and why you pursued that career? What's your story? I'm interested to hear if any of you have gone to corporate and never go back to tech.\n\nI'm gonna be little bit specific here, since perhaps our similar background can help, any feedback from my brothers and sisters age 30-40, married, especially from SEA countries will be appreciated.", "author_fullname": "t2_cp3u94u0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After all has been said &amp; done, I'm looking for a new career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ggaet", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691000433.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691000008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lead data team here, I&amp;#39;ve been working as software engineer/data analyst/scientist/engineer/ML/infra for as long as I can remember, did my Masters in ML and did little bit of research back then, and right now I feel like I don&amp;#39;t really want to work in tech company anymore since it&amp;#39;s not profitable/barely alive. The investors hardly pour any money especially to Southeast Asia region as well, it&amp;#39;s getting harder day by day.&lt;/p&gt;\n\n&lt;p&gt;And I&amp;#39;m kinda tired with all these uncertainties, I&amp;#39;ve witnessed/experienced tears, layoffs, harsh treatment (because of frustration, yes I know very well making profitable &amp;amp; sustainable business is extremely difficult), ridiculous work load which lead to mental health issue (I do have ADHD and it has been worsening the situation) and very unhealthy life, etc. Yeah, it was accumulated since 2015.&lt;/p&gt;\n\n&lt;p&gt;So here&amp;#39;s my question. For those of you guys who quitted job from tech company what were your options back then and why you pursued that career? What&amp;#39;s your story? I&amp;#39;m interested to hear if any of you have gone to corporate and never go back to tech.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m gonna be little bit specific here, since perhaps our similar background can help, any feedback from my brothers and sisters age 30-40, married, especially from SEA countries will be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ggaet", "is_robot_indexable": true, "report_reasons": null, "author": "kerkgx", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ggaet/after_all_has_been_said_done_im_looking_for_a_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ggaet/after_all_has_been_said_done_im_looking_for_a_new/", "subreddit_subscribers": 120141, "created_utc": 1691000008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have barely any cloud or apache kafka/streaming experience which seems to be a key pre requisite these days. I know historically many DAs transitioned to DE, but given how difficult the market now is, will I be likely to get any callbacks with my limited skillset? UK based btw.", "author_fullname": "t2_t8ub2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a point in applying for DE positions as a SQL/Python DA with 2 YoE in the current market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gk10n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691008543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have barely any cloud or apache kafka/streaming experience which seems to be a key pre requisite these days. I know historically many DAs transitioned to DE, but given how difficult the market now is, will I be likely to get any callbacks with my limited skillset? UK based btw.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15gk10n", "is_robot_indexable": true, "report_reasons": null, "author": "neheughk", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15gk10n/is_there_a_point_in_applying_for_de_positions_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15gk10n/is_there_a_point_in_applying_for_de_positions_as/", "subreddit_subscribers": 120141, "created_utc": 1691008543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1. If there are a large number of tables, do data engineer/analysts spend a lot of time figuring out the relationships between tables every time when writing SQL queries?\n2. Besides asking people directly, how does everyone figure out the relationships between tables? Are there any tool/solution that can help us clarify complicated database schema more quickly?\n3. If there is a tool that could predefine the relationships between tables, and in SQL we could simply use \".\" to denote the relationship between tables, such as using `foo.bar.quux` to replace `foo JOIN bar ON foo.bar_id = bar.bar_id JOIN quux ON bar.quux_id = quux.quux_id`, would you find writing to be more intuitive, or say it helps understand the whole database schema?", "author_fullname": "t2_133cio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions about complex database schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gaso9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690987523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;If there are a large number of tables, do data engineer/analysts spend a lot of time figuring out the relationships between tables every time when writing SQL queries?&lt;/li&gt;\n&lt;li&gt;Besides asking people directly, how does everyone figure out the relationships between tables? Are there any tool/solution that can help us clarify complicated database schema more quickly?&lt;/li&gt;\n&lt;li&gt;If there is a tool that could predefine the relationships between tables, and in SQL we could simply use &amp;quot;.&amp;quot; to denote the relationship between tables, such as using &lt;code&gt;foo.bar.quux&lt;/code&gt; to replace &lt;code&gt;foo JOIN bar ON foo.bar_id = bar.bar_id JOIN quux ON bar.quux_id = quux.quux_id&lt;/code&gt;, would you find writing to be more intuitive, or say it helps understand the whole database schema?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15gaso9", "is_robot_indexable": true, "report_reasons": null, "author": "brandboat", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15gaso9/questions_about_complex_database_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15gaso9/questions_about_complex_database_schema/", "subreddit_subscribers": 120141, "created_utc": 1690987523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nI\u2019ve got a couple of questions related to the same solution design that I\u2019d love your help with:\n\n1. I have a DeltaTable in DataBricks that is partitioned based on a specific field/column. How can I instruct Spark to load the entire table to the cluster, ensuring that rows from the same partition always arrive at the same node?\n2. After accomplishing the above, how can I perform a `shift` operation on a column that operates in-partition only, enabling it to run efficiently in a distributed manner? `spark.DataFrame`'s  `shift` method doesn\u2019t fulfill this requirement, as stated in the documentation:\n\n*\u201cThe current implementation of shift uses Spark\u2019s Window without specifying partition specification. This leads to move all data into a single partition in a single machine and could cause serious performance degradation. Avoid this method against very large dataset.\u201d*\n\nThank you, \ud83e\uddc0Shai\n\nP.S.Even if this doesn't work, it's still a better love story than Twilight  \n\n\nI've managed to understand how to solve (2) using the lag window function over correctly set windows, but I'm still struggling to understand how Spark RDD partitions can be set to use the same partitioning logic used for a DeltaTable, and without breaking distribution mid-way.", "author_fullname": "t2_b74pv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DeltaTable partitions and Spark cluster nodes: A love story", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15h1mdp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691064356.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691062400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve got a couple of questions related to the same solution design that I\u2019d love your help with:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I have a DeltaTable in DataBricks that is partitioned based on a specific field/column. How can I instruct Spark to load the entire table to the cluster, ensuring that rows from the same partition always arrive at the same node?&lt;/li&gt;\n&lt;li&gt;After accomplishing the above, how can I perform a &lt;code&gt;shift&lt;/code&gt; operation on a column that operates in-partition only, enabling it to run efficiently in a distributed manner? &lt;code&gt;spark.DataFrame&lt;/code&gt;&amp;#39;s  &lt;code&gt;shift&lt;/code&gt; method doesn\u2019t fulfill this requirement, as stated in the documentation:&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;em&gt;\u201cThe current implementation of shift uses Spark\u2019s Window without specifying partition specification. This leads to move all data into a single partition in a single machine and could cause serious performance degradation. Avoid this method against very large dataset.\u201d&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you, \ud83e\uddc0Shai&lt;/p&gt;\n\n&lt;p&gt;P.S.Even if this doesn&amp;#39;t work, it&amp;#39;s still a better love story than Twilight  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve managed to understand how to solve (2) using the lag window function over correctly set windows, but I&amp;#39;m still struggling to understand how Spark RDD partitions can be set to use the same partitioning logic used for a DeltaTable, and without breaking distribution mid-way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15h1mdp", "is_robot_indexable": true, "report_reasons": null, "author": "shaypal5", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15h1mdp/deltatable_partitions_and_spark_cluster_nodes_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15h1mdp/deltatable_partitions_and_spark_cluster_nodes_a/", "subreddit_subscribers": 120141, "created_utc": 1691062400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nThis is just a general question and I am sure there is enough pros and cons for both but what is your preferred solution?\n\nI only use ADF to get the data from the source to the staging/destination with minimal transformation, maybe some filtration if needed. Then I do the target table update/insert using a SP.\n\nRecently I encountered a solution where they use ADF dataflows for updating the table. They get the new data and compare it to the existing and then they save the results to the target table.\n\nWhich one do you prefer and why?\n\nThanks.\n\nK.", "author_fullname": "t2_4j5e5apq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would you do UPDATE/INSERT in Azure Data Factory or in database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gxnwv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691049437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;This is just a general question and I am sure there is enough pros and cons for both but what is your preferred solution?&lt;/p&gt;\n\n&lt;p&gt;I only use ADF to get the data from the source to the staging/destination with minimal transformation, maybe some filtration if needed. Then I do the target table update/insert using a SP.&lt;/p&gt;\n\n&lt;p&gt;Recently I encountered a solution where they use ADF dataflows for updating the table. They get the new data and compare it to the existing and then they save the results to the target table.&lt;/p&gt;\n\n&lt;p&gt;Which one do you prefer and why?&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n\n&lt;p&gt;K.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15gxnwv", "is_robot_indexable": true, "report_reasons": null, "author": "ka_eb", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15gxnwv/would_you_do_updateinsert_in_azure_data_factory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15gxnwv/would_you_do_updateinsert_in_azure_data_factory/", "subreddit_subscribers": 120141, "created_utc": 1691049437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This week I released the latest publication of data news (news from data engineering)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15gwt30", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iP0cc2X7sTUuwimJskmiqQecBOyKt2OBOxzo3__kkNg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691046468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "patrikbraborec.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://patrikbraborec.substack.com/p/data-news-38", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-IdXTl9_Tfq71JCZQZrOC47bO16UZT3eNv4QmMuTzf8.jpg?auto=webp&amp;s=5d907839d94b8c37cb73161fd1f53c92c0bac238", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/-IdXTl9_Tfq71JCZQZrOC47bO16UZT3eNv4QmMuTzf8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=423fa04ec22cefcc07b975b5ae4d61b7e9e50b28", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/-IdXTl9_Tfq71JCZQZrOC47bO16UZT3eNv4QmMuTzf8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=759de31c24ada0e2b0c005f636d4a974069987be", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/-IdXTl9_Tfq71JCZQZrOC47bO16UZT3eNv4QmMuTzf8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=27658cd63775b57dba7c12da4ad7faeda4157c33", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/-IdXTl9_Tfq71JCZQZrOC47bO16UZT3eNv4QmMuTzf8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cc933418074ef39b31f632b8011794ad4db5aaff", "width": 640, "height": 333}], "variants": {}, "id": "erUiLZX0NH_WNn2uSfBe-v8GDyA9MtYutmWuGpZbHdQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15gwt30", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15gwt30/this_week_i_released_the_latest_publication_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://patrikbraborec.substack.com/p/data-news-38", "subreddit_subscribers": 120141, "created_utc": 1691046468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey hey!\n\nSorry if this is a dumb question but we have a team of analysts building datamarts in PowerBI. We need to rebuild those tables in SQL in a separate location. For me trying to figure out what the analysts are doing, getting all the data/business context is super time consuming since I have a lot of other responsabilities. Is that a sign that i'm a bad dataengineer (not sure if this should be an easier task than it feels like?) If not then i was wondering if someone else has had this situation and whether they found a tool to convert PowerBI transformations (written in M afaik?)  into SQL.", "author_fullname": "t2_vm5kbtxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting PowerBI (M) to SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gd0ao", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690992588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey hey!&lt;/p&gt;\n\n&lt;p&gt;Sorry if this is a dumb question but we have a team of analysts building datamarts in PowerBI. We need to rebuild those tables in SQL in a separate location. For me trying to figure out what the analysts are doing, getting all the data/business context is super time consuming since I have a lot of other responsabilities. Is that a sign that i&amp;#39;m a bad dataengineer (not sure if this should be an easier task than it feels like?) If not then i was wondering if someone else has had this situation and whether they found a tool to convert PowerBI transformations (written in M afaik?)  into SQL.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15gd0ao", "is_robot_indexable": true, "report_reasons": null, "author": "srevolve", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15gd0ao/converting_powerbi_m_to_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15gd0ao/converting_powerbi_m_to_sql/", "subreddit_subscribers": 120141, "created_utc": 1690992588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a requirement: \n\n4 dags in level1\n3 dags in level2\n8 dags in level3\n\nEach level dags should be running in parallel and next level would wait until the previous level is complete .\nLike : once all the dags of level1 completes then level2 should be getting triggered.\n\nI thought of using dataset , but problem is that of any of the dags completes and updates dataset then level2 gets triggered , which is not expected.\n\nAny guidance is welcome .", "author_fullname": "t2_2ofssxva", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi dag inter dependency in airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15h4pya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691070382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a requirement: &lt;/p&gt;\n\n&lt;p&gt;4 dags in level1\n3 dags in level2\n8 dags in level3&lt;/p&gt;\n\n&lt;p&gt;Each level dags should be running in parallel and next level would wait until the previous level is complete .\nLike : once all the dags of level1 completes then level2 should be getting triggered.&lt;/p&gt;\n\n&lt;p&gt;I thought of using dataset , but problem is that of any of the dags completes and updates dataset then level2 gets triggered , which is not expected.&lt;/p&gt;\n\n&lt;p&gt;Any guidance is welcome .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15h4pya", "is_robot_indexable": true, "report_reasons": null, "author": "in_batman2015", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15h4pya/multi_dag_inter_dependency_in_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15h4pya/multi_dag_inter_dependency_in_airflow/", "subreddit_subscribers": 120141, "created_utc": 1691070382.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2tv9i42n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft comes under blistering criticism for \u201cgrossly irresponsible\u201d security", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_15h4hnm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "#46d160", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4dhz8bakpnPd-eLlKxYAq7vSNlx6XJM32g8tenytQ9k.jpg", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691069826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arstechnica.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arstechnica.com/security/2023/08/microsoft-cloud-security-blasted-for-its-culture-of-toxic-obfuscation/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NL4wUVkVPlynVEPYiFEZuVMjIUBHmBTMUqDcrJZCLus.jpg?auto=webp&amp;s=47302c1a40594f42d59f605124b3e4bc7d34fd6e", "width": 760, "height": 380}, "resolutions": [{"url": "https://external-preview.redd.it/NL4wUVkVPlynVEPYiFEZuVMjIUBHmBTMUqDcrJZCLus.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=000ad2fd84f3b2487fafea8401b8c470e9af6cdf", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/NL4wUVkVPlynVEPYiFEZuVMjIUBHmBTMUqDcrJZCLus.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2e86f0c7b50dd63b364c4432f837239db5723eea", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/NL4wUVkVPlynVEPYiFEZuVMjIUBHmBTMUqDcrJZCLus.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=227d522cd5f959e0641989873f2cc6b2a9eb5740", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/NL4wUVkVPlynVEPYiFEZuVMjIUBHmBTMUqDcrJZCLus.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fdde44d7dc5a5aedc6442806bfe9ad31cba330bf", "width": 640, "height": 320}], "variants": {}, "id": "5FttRlgjIwwsSk3H3ILvKjLlFjxrvrVxdKW5fgb-f4Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "mod | Sr. Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15h4hnm", "is_robot_indexable": true, "report_reasons": null, "author": "theporterhaus", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/15h4hnm/microsoft_comes_under_blistering_criticism_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arstechnica.com/security/2023/08/microsoft-cloud-security-blasted-for-its-culture-of-toxic-obfuscation/", "subreddit_subscribers": 120141, "created_utc": 1691069826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Difference between VMs\n\nAs the title says what is the difference between this two since F4 has less ram and is compute optimize. It cost 0.5 DBU/h vs 0.75 DBU/h.\n\nAnyone has made any POC between this two?\n\nDatabricks on azure**", "author_fullname": "t2_2doz54hy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks: Differences between F4s and DS3 v2", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15h43rr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691068852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Difference between VMs&lt;/p&gt;\n\n&lt;p&gt;As the title says what is the difference between this two since F4 has less ram and is compute optimize. It cost 0.5 DBU/h vs 0.75 DBU/h.&lt;/p&gt;\n\n&lt;p&gt;Anyone has made any POC between this two?&lt;/p&gt;\n\n&lt;p&gt;Databricks on azure**&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15h43rr", "is_robot_indexable": true, "report_reasons": null, "author": "erwingm10", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15h43rr/databricks_differences_between_f4s_and_ds3_v2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15h43rr/databricks_differences_between_f4s_and_ds3_v2/", "subreddit_subscribers": 120141, "created_utc": 1691068852.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Beginner here, need to EL all the raw data from Google Analytics (GA4) to a Snowflake. Is the best/easiest way to export the data to BigQuery, then moving it to Google Cloud Storage and then to Snowflake? I read there were some problems with using Stitch or Fivetran in other threads for this use case, but I am open to those solutions as well. Any thoughts would be appreciated.", "author_fullname": "t2_14j3s4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Connecting GA4 to Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15h12v4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691061302.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691060732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Beginner here, need to EL all the raw data from Google Analytics (GA4) to a Snowflake. Is the best/easiest way to export the data to BigQuery, then moving it to Google Cloud Storage and then to Snowflake? I read there were some problems with using Stitch or Fivetran in other threads for this use case, but I am open to those solutions as well. Any thoughts would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15h12v4", "is_robot_indexable": true, "report_reasons": null, "author": "HER0-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15h12v4/connecting_ga4_to_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15h12v4/connecting_ga4_to_snowflake/", "subreddit_subscribers": 120141, "created_utc": 1691060732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\nWe have the requirement to migrate the azure synapse pipeline having 100 + pipelines from one tenant to another.\nCan anyone help in providing me the automated way to achieve it ?\nAny help is highly appreciated.\nTIA", "author_fullname": "t2_6dhjrj7u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help on migrating azure synapse pipeline from one tenant to another", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15giz74", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691006137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,\nWe have the requirement to migrate the azure synapse pipeline having 100 + pipelines from one tenant to another.\nCan anyone help in providing me the automated way to achieve it ?\nAny help is highly appreciated.\nTIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15giz74", "is_robot_indexable": true, "report_reasons": null, "author": "Extra_Blacksmith_567", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15giz74/help_on_migrating_azure_synapse_pipeline_from_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15giz74/help_on_migrating_azure_synapse_pipeline_from_one/", "subreddit_subscribers": 120141, "created_utc": 1691006137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data disasters and mishaps \u2026\n\nYup, they happen to the best of us. \n\nMost of us have experienced something in this realm. Data loss. Flawed interpretation. \n\nMaybe it was a PEBCAK (problem exists between chair and keyboard), maybe it was a piece of tech or code that took a shit.\n\nHopefully there was a fix, rollback, backup, or something else to minimize the impact. \n\nYa, when these things happen it sucks, but as the gurus always say, these are great teaching moments. Or at least funny stories we can all share.\n\nWhat\u2019s your \u201cfavourite\u201d story? - I\u2019ll start in the comments.", "author_fullname": "t2_8s6trahv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data disasters and mishaps....", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gfyjv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690999288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data disasters and mishaps \u2026&lt;/p&gt;\n\n&lt;p&gt;Yup, they happen to the best of us. &lt;/p&gt;\n\n&lt;p&gt;Most of us have experienced something in this realm. Data loss. Flawed interpretation. &lt;/p&gt;\n\n&lt;p&gt;Maybe it was a PEBCAK (problem exists between chair and keyboard), maybe it was a piece of tech or code that took a shit.&lt;/p&gt;\n\n&lt;p&gt;Hopefully there was a fix, rollback, backup, or something else to minimize the impact. &lt;/p&gt;\n\n&lt;p&gt;Ya, when these things happen it sucks, but as the gurus always say, these are great teaching moments. Or at least funny stories we can all share.&lt;/p&gt;\n\n&lt;p&gt;What\u2019s your \u201cfavourite\u201d story? - I\u2019ll start in the comments.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15gfyjv", "is_robot_indexable": true, "report_reasons": null, "author": "Crafty_Combination54", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15gfyjv/data_disasters_and_mishaps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15gfyjv/data_disasters_and_mishaps/", "subreddit_subscribers": 120141, "created_utc": 1690999288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI have been working under a weird title, research engineer, just over 3 years in an embedded network company. I mostly looking out for ways to improve wifi quality and develop end-to-end solutions including parts on embedded devices and server side. Last year I tried something somehow data engineering(?) related where I collect bunch of data from devices and feed them into a ML model. I always had an interest in big data management and patern discovery and data related projects overall.\n\nFriday I accepted to a masters program which is just CS masters. Professor which accepted me works on distributed data management and pattern discovery. On time I wander here I did not saw any post related to these topics. Also I saw many posts/comments disscussing \"DE or DS\" but  I failed to come up with definitive differences. What are the differences between data engineering and data science ? Are people working on those roles work interchangeably or they just never touch each others work ? My confusion might be because where I work, I develop both embedded and  cloud code as well as deploying them to various places(aws, heroku, k8s in my own homelab) as a result I lost my sense of job titles and their roles. What should I expect from my masters ?", "author_fullname": "t2_1ca576", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SWE here. Accepted to masters but having issues on what to expect.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15geinq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690996021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I have been working under a weird title, research engineer, just over 3 years in an embedded network company. I mostly looking out for ways to improve wifi quality and develop end-to-end solutions including parts on embedded devices and server side. Last year I tried something somehow data engineering(?) related where I collect bunch of data from devices and feed them into a ML model. I always had an interest in big data management and patern discovery and data related projects overall.&lt;/p&gt;\n\n&lt;p&gt;Friday I accepted to a masters program which is just CS masters. Professor which accepted me works on distributed data management and pattern discovery. On time I wander here I did not saw any post related to these topics. Also I saw many posts/comments disscussing &amp;quot;DE or DS&amp;quot; but  I failed to come up with definitive differences. What are the differences between data engineering and data science ? Are people working on those roles work interchangeably or they just never touch each others work ? My confusion might be because where I work, I develop both embedded and  cloud code as well as deploying them to various places(aws, heroku, k8s in my own homelab) as a result I lost my sense of job titles and their roles. What should I expect from my masters ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15geinq", "is_robot_indexable": true, "report_reasons": null, "author": "hairystripper", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15geinq/swe_here_accepted_to_masters_but_having_issues_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15geinq/swe_here_accepted_to_masters_but_having_issues_on/", "subreddit_subscribers": 120141, "created_utc": 1690996021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_15pdlm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI/ML and Big Data Software Agencies Repository Submissions Request.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15gd7kx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/r3vl6G0g-r1dVUXZjQQXPaF0oH4zpW7BS10iJ7nc-74.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690993054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "docs.google.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://docs.google.com/forms/d/e/1FAIpQLSdH5dj74TRGNqM3-O7Ym0r_Rp5FVgj2ckj7VCM6bAKpLcds4w/viewform", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/spPhMJL5Edv1o5WOVe0FtLglJDj6f_sZPwbgPfE0Dgk.jpg?auto=webp&amp;s=574d6e7beafcee3961d266332a4025e42bbdaefa", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/spPhMJL5Edv1o5WOVe0FtLglJDj6f_sZPwbgPfE0Dgk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=120649eb99e215cc36b67c813ac1653a1a30fae3", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/spPhMJL5Edv1o5WOVe0FtLglJDj6f_sZPwbgPfE0Dgk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d581dd98f1dee61e361a66323510d84dfd59d83c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/spPhMJL5Edv1o5WOVe0FtLglJDj6f_sZPwbgPfE0Dgk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=18e363707820f6150d1dcdbd4ee4c2a82d3a666f", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/spPhMJL5Edv1o5WOVe0FtLglJDj6f_sZPwbgPfE0Dgk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a856d3414d421499e250c4a370d657c702722cb8", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/spPhMJL5Edv1o5WOVe0FtLglJDj6f_sZPwbgPfE0Dgk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=34a715a58b361926bcd4b5e23b9af3992510f69d", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/spPhMJL5Edv1o5WOVe0FtLglJDj6f_sZPwbgPfE0Dgk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2f0ac126186be93ed1df881df9ac2ed95e5c6029", "width": 1080, "height": 567}], "variants": {}, "id": "YjqhrTYo663OizqEZ9AlnHwHef1m7iwIj8Z1CufMwM0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15gd7kx", "is_robot_indexable": true, "report_reasons": null, "author": "freeway334", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15gd7kx/aiml_and_big_data_software_agencies_repository/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://docs.google.com/forms/d/e/1FAIpQLSdH5dj74TRGNqM3-O7Ym0r_Rp5FVgj2ckj7VCM6bAKpLcds4w/viewform", "subreddit_subscribers": 120141, "created_utc": 1690993054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI have created a job which writes one partition to an iceberg table using an Athena query. This works fine when I run it standalone. I have configured it in Dagster to be a partitioned asset, so that Dagster spools up 10 parallel runs (10 is our configuration for Dagsters concurrency).\n\nUnfortunately, many of these jobs fail with the following error:\n\n    pyathena.error.OperationalError: ICEBERG_COMMIT_ERROR: Failed to commit Iceberg update to table:\n\nIt looks like Athena does not manage parallel write to an iceberg table very well. Is there anything I can do about it?\n\nThe SQL statement is :\n\n    merge into ... when not matched then insert ...\n\nI only have the not matched insert branch. No matched , delete or update branches.\n\nCheers,\n\nMatt", "author_fullname": "t2_5o9ebpsl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parallel write to Iceberg Table using Athena", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gaso1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690987522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have created a job which writes one partition to an iceberg table using an Athena query. This works fine when I run it standalone. I have configured it in Dagster to be a partitioned asset, so that Dagster spools up 10 parallel runs (10 is our configuration for Dagsters concurrency).&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, many of these jobs fail with the following error:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pyathena.error.OperationalError: ICEBERG_COMMIT_ERROR: Failed to commit Iceberg update to table:\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;It looks like Athena does not manage parallel write to an iceberg table very well. Is there anything I can do about it?&lt;/p&gt;\n\n&lt;p&gt;The SQL statement is :&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;merge into ... when not matched then insert ...\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I only have the not matched insert branch. No matched , delete or update branches.&lt;/p&gt;\n\n&lt;p&gt;Cheers,&lt;/p&gt;\n\n&lt;p&gt;Matt&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15gaso1", "is_robot_indexable": true, "report_reasons": null, "author": "mosquitsch", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15gaso1/parallel_write_to_iceberg_table_using_athena/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15gaso1/parallel_write_to_iceberg_table_using_athena/", "subreddit_subscribers": 120141, "created_utc": 1690987522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "so i have searched around the stack overflow but haven't found anything that does what i'm thinking of:\n\nyou know how if you arbitrarily modify a committed csv file, the git diff will do a side by side comparison, skipping rows on either side wherever applicable for the most subsequent matches, as well as highlight column/in line differences?\n\nis there something similar for a DataFrame comparison?  maybe a library or otherwise that basically takes two DataFrames of arbitrary shape/data, and return two DataFrames of respective sizes saying whether every cell of the DataFrame from either side is either in or not in the other DataFrame?\n\nthanks in advance", "author_fullname": "t2_fmgy5c1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "compare two DataFrames", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15h2bns", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691064326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;so i have searched around the stack overflow but haven&amp;#39;t found anything that does what i&amp;#39;m thinking of:&lt;/p&gt;\n\n&lt;p&gt;you know how if you arbitrarily modify a committed csv file, the git diff will do a side by side comparison, skipping rows on either side wherever applicable for the most subsequent matches, as well as highlight column/in line differences?&lt;/p&gt;\n\n&lt;p&gt;is there something similar for a DataFrame comparison?  maybe a library or otherwise that basically takes two DataFrames of arbitrary shape/data, and return two DataFrames of respective sizes saying whether every cell of the DataFrame from either side is either in or not in the other DataFrame?&lt;/p&gt;\n\n&lt;p&gt;thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15h2bns", "is_robot_indexable": true, "report_reasons": null, "author": "thinkingatoms", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15h2bns/compare_two_dataframes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15h2bns/compare_two_dataframes/", "subreddit_subscribers": 120141, "created_utc": 1691064326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "New data engineer here. Our analytics / reporting views are on BigQuery and there is a need to upsert this data daily into Salesforce objects. Our business users use Salesforce. \nAny inputs on what the best approach could be. Volume is in 10-15GB range.", "author_fullname": "t2_6it6xybd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Send data to Salesforce from BigQuery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gkxb6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691012687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New data engineer here. Our analytics / reporting views are on BigQuery and there is a need to upsert this data daily into Salesforce objects. Our business users use Salesforce. \nAny inputs on what the best approach could be. Volume is in 10-15GB range.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15gkxb6", "is_robot_indexable": true, "report_reasons": null, "author": "bobasucks", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15gkxb6/send_data_to_salesforce_from_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15gkxb6/send_data_to_salesforce_from_bigquery/", "subreddit_subscribers": 120141, "created_utc": 1691012687.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}