{"kind": "Listing", "data": {"after": "t3_15lpwvl", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am new to data engineering and learning basic stuff but I am curious to know what's the most unproductive task you have to do as a data engineer.", "author_fullname": "t2_dogbygvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the most unproductive task you have to do as a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15la888", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 145, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 145, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691477582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to data engineering and learning basic stuff but I am curious to know what&amp;#39;s the most unproductive task you have to do as a data engineer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15la888", "is_robot_indexable": true, "report_reasons": null, "author": "vinayak_singh_k", "discussion_type": null, "num_comments": 121, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15la888/what_is_the_most_unproductive_task_you_have_to_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15la888/what_is_the_most_unproductive_task_you_have_to_do/", "subreddit_subscribers": 121668, "created_utc": 1691477582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just got certified! I am happy to say I have completed the Databricks Data Engineering Associate certification. \n\nThe exam wasn't as difficult I expected it be, primarily revolving around the Databricks platform as expected. The exam focused on concepts like Delta, Multi-hop architecture, Repos etc. Some coding questions on very basic SQL syntax(CTAS, create views etc.) nothing too out of the ordinary. \n\nI'd suggest taking the certification, it's not a difficult exam nor does it take too much time(about 10 days of studying). \n\nThe resources I used are:  \n1. The Databricks Data Engineering course (Free): I used my customer account, anyone can sign up for it, there's even a 2 week trial. I'd suggest downloading the .dbc files and uploading them to the community edition workspace and playing around. That's what I did!\n\n2. Udemy Courses: [https://www.udemy.com/course/databricks-certified-data-engineer-associate](https://www.udemy.com/course/databricks-certified-data-engineer-associate/) \\- was just brilliant. The course isn't too long, the instructor condenses the information really well. Overall pretty good imo \n\n3. Practice Tests:\n\n1.  [https://www.udemy.com/course/practice-exams-databricks-certified-data-engineer-associate](https://www.udemy.com/course/practice-exams-databricks-certified-data-engineer-associate/?expanded=1014944232) \\- was good to identify weak areas and revisit them \n2. [https://www.udemy.com/course/databricks-certified-associate-data-engineer-practice-tests](https://www.udemy.com/course/databricks-certified-associate-data-engineer-practice-tests/?referralCode=102E37D6BA7C7B8B5532) \\- really good practice tests, the questions largely resembled the actual exam - (*70% of the actual exam questions*). Only practice test needed (wasted a lot of money on other tests). \n\n4. YouTube Resources: \n\n1. Advanced Analytics: Really good to find videos on alot of concepts - imo he breaks down concepts really well, but doesn't do a deeper dive. [https://www.youtube.com/@AdvancingAnalytics](https://www.youtube.com/@AdvancingAnalytics/videos) \n2. Stephanie Rivera: Okay, this is actual gold in terms of knowledge. She uploads the paid skill-builder series from Databricks to YouTube (though I'm not sure how accurate this is; a buddy of mine works at a company that has access to these, and he says they're the same). This is extremely useful for gaining in-depth knowledge. [https://www.youtube.com/@stephanieamrivera](https://www.youtube.com/@stephanieamrivera/videos) ", "author_fullname": "t2_ic83gko1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just got certified! - Databricks Certified Data Engineer Associate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15la6wi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 64, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 64, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691477467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just got certified! I am happy to say I have completed the Databricks Data Engineering Associate certification. &lt;/p&gt;\n\n&lt;p&gt;The exam wasn&amp;#39;t as difficult I expected it be, primarily revolving around the Databricks platform as expected. The exam focused on concepts like Delta, Multi-hop architecture, Repos etc. Some coding questions on very basic SQL syntax(CTAS, create views etc.) nothing too out of the ordinary. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d suggest taking the certification, it&amp;#39;s not a difficult exam nor does it take too much time(about 10 days of studying). &lt;/p&gt;\n\n&lt;p&gt;The resources I used are:&lt;br/&gt;\n1. The Databricks Data Engineering course (Free): I used my customer account, anyone can sign up for it, there&amp;#39;s even a 2 week trial. I&amp;#39;d suggest downloading the .dbc files and uploading them to the community edition workspace and playing around. That&amp;#39;s what I did!&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Udemy Courses: &lt;a href=\"https://www.udemy.com/course/databricks-certified-data-engineer-associate/\"&gt;https://www.udemy.com/course/databricks-certified-data-engineer-associate&lt;/a&gt; - was just brilliant. The course isn&amp;#39;t too long, the instructor condenses the information really well. Overall pretty good imo &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Practice Tests:&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"https://www.udemy.com/course/practice-exams-databricks-certified-data-engineer-associate/?expanded=1014944232\"&gt;https://www.udemy.com/course/practice-exams-databricks-certified-data-engineer-associate&lt;/a&gt; - was good to identify weak areas and revisit them &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"https://www.udemy.com/course/databricks-certified-associate-data-engineer-practice-tests/?referralCode=102E37D6BA7C7B8B5532\"&gt;https://www.udemy.com/course/databricks-certified-associate-data-engineer-practice-tests&lt;/a&gt; - really good practice tests, the questions largely resembled the actual exam - (&lt;em&gt;70% of the actual exam questions&lt;/em&gt;). Only practice test needed (wasted a lot of money on other tests). &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;YouTube Resources: &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Advanced Analytics: Really good to find videos on alot of concepts - imo he breaks down concepts really well, but doesn&amp;#39;t do a deeper dive. &lt;a href=\"https://www.youtube.com/@AdvancingAnalytics/videos\"&gt;https://www.youtube.com/@AdvancingAnalytics&lt;/a&gt; &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Stephanie Rivera: Okay, this is actual gold in terms of knowledge. She uploads the paid skill-builder series from Databricks to YouTube (though I&amp;#39;m not sure how accurate this is; a buddy of mine works at a company that has access to these, and he says they&amp;#39;re the same). This is extremely useful for gaining in-depth knowledge. &lt;a href=\"https://www.youtube.com/@stephanieamrivera/videos\"&gt;https://www.youtube.com/@stephanieamrivera&lt;/a&gt; &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15la6wi", "is_robot_indexable": true, "report_reasons": null, "author": "Background_Debate_94", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15la6wi/just_got_certified_databricks_certified_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15la6wi/just_got_certified_databricks_certified_data/", "subreddit_subscribers": 121668, "created_utc": 1691477467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just ended a live coding technical interview. Looking back **now**, questions were pretty basic. Is it just me or my abilities just get reduced significant during a live coding interview? Anyway long story short, I managed to code out say 80-90% of the questions presented to me (at quite a slow speed though due to stress). However, I did not narrate my thought processes while I code (I srsly have no ability to do that, I'm too focused on the coding itself and my thought processes are super messy and quicker than I speak I'm afraid once I narrate I'll lose them lol). But the interviewer just let me stayed quiet, though he did prompt me to talk about different variations of the code after I finish my code, and he did say \"you're on the right track\" here and there. I would say there were only 1-2 tiny instances where I couldn't really answer his questions.\n\nYeah I'm not sure if I bombed it because I coded out my attempts pretty slowly, and also did not narrate the thought processes in the process of coding which is highly encouraged by many. However, I'm sure my logical thinking was there. What are my chances of proceeding to the next round?  \n\n\nUpdate: I just received an email saying I'll proceed on to the next stage!!", "author_fullname": "t2_6i51ove2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did I bomb my live coding interview? Lol", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15l9rph", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691486589.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691476111.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just ended a live coding technical interview. Looking back &lt;strong&gt;now&lt;/strong&gt;, questions were pretty basic. Is it just me or my abilities just get reduced significant during a live coding interview? Anyway long story short, I managed to code out say 80-90% of the questions presented to me (at quite a slow speed though due to stress). However, I did not narrate my thought processes while I code (I srsly have no ability to do that, I&amp;#39;m too focused on the coding itself and my thought processes are super messy and quicker than I speak I&amp;#39;m afraid once I narrate I&amp;#39;ll lose them lol). But the interviewer just let me stayed quiet, though he did prompt me to talk about different variations of the code after I finish my code, and he did say &amp;quot;you&amp;#39;re on the right track&amp;quot; here and there. I would say there were only 1-2 tiny instances where I couldn&amp;#39;t really answer his questions.&lt;/p&gt;\n\n&lt;p&gt;Yeah I&amp;#39;m not sure if I bombed it because I coded out my attempts pretty slowly, and also did not narrate the thought processes in the process of coding which is highly encouraged by many. However, I&amp;#39;m sure my logical thinking was there. What are my chances of proceeding to the next round?  &lt;/p&gt;\n\n&lt;p&gt;Update: I just received an email saying I&amp;#39;ll proceed on to the next stage!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15l9rph", "is_robot_indexable": true, "report_reasons": null, "author": "nonexistential01", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15l9rph/did_i_bomb_my_live_coding_interview_lol/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15l9rph/did_i_bomb_my_live_coding_interview_lol/", "subreddit_subscribers": 121668, "created_utc": 1691476111.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**My background:**\n\nCurrently I'm a senior data analyst, and I'm one of those people that works in the department where the data analyst does just about everything. I do ETL, reporting, bi stuff so piping data from Google BigQuery into stuff like Power BI, looker studio, AWS, snowflake, using Python of course. I spend more time typing in SQL than I do in English in emails. I find myself doing recreational projects with Python and SQL quite often, for example this week I wrote in API that retrieves data from Kaggle, cleans it in pandas, loads it into BigQuery, also loads it into snowflake, Cassandra, Then using even more Python, retrieves some of the data using SQL. \n\n\n**Question:**\n\nHow do I know if I'm ready for a data engineer position? Will I ever be ready? I was contacted buy a recruiter for a couple positions. The one I applied to is data analyst, but I asked about the data engineer position because the job description said almost nothing about it. She said it was a little bit more technical than what I've probably done, preceded to list off basically everything I've already been doing. Said I have to be comfortable doing object-oriented programming in Python (didn't know they used objects in data engineering). Said that it's a lot more of the piping data, working in AWS data sources, snowflake, Hadoop, etc... This is all stuff that sounds insanely complex and technical but here's the thing.... **How do I know if this is stuff that I'm capable of learning on the job or doing?** Like no, of course I haven't set up a data source from scratch with 300 million rows or a terabyte of data myself. I can't just go and make a 300 million row data set on my PC at home. No matter how much I want to, It would be next to impossible for me to simulate the work that a data engineer actually does on the job in a personal setting. Because any work I do as a data engineer will be in a live environment for a big company with important deadlines and I don't have that right now.", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Honest question: How do I know if I'm good enough to be a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lr89o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691521667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;My background:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m a senior data analyst, and I&amp;#39;m one of those people that works in the department where the data analyst does just about everything. I do ETL, reporting, bi stuff so piping data from Google BigQuery into stuff like Power BI, looker studio, AWS, snowflake, using Python of course. I spend more time typing in SQL than I do in English in emails. I find myself doing recreational projects with Python and SQL quite often, for example this week I wrote in API that retrieves data from Kaggle, cleans it in pandas, loads it into BigQuery, also loads it into snowflake, Cassandra, Then using even more Python, retrieves some of the data using SQL. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;How do I know if I&amp;#39;m ready for a data engineer position? Will I ever be ready? I was contacted buy a recruiter for a couple positions. The one I applied to is data analyst, but I asked about the data engineer position because the job description said almost nothing about it. She said it was a little bit more technical than what I&amp;#39;ve probably done, preceded to list off basically everything I&amp;#39;ve already been doing. Said I have to be comfortable doing object-oriented programming in Python (didn&amp;#39;t know they used objects in data engineering). Said that it&amp;#39;s a lot more of the piping data, working in AWS data sources, snowflake, Hadoop, etc... This is all stuff that sounds insanely complex and technical but here&amp;#39;s the thing.... &lt;strong&gt;How do I know if this is stuff that I&amp;#39;m capable of learning on the job or doing?&lt;/strong&gt; Like no, of course I haven&amp;#39;t set up a data source from scratch with 300 million rows or a terabyte of data myself. I can&amp;#39;t just go and make a 300 million row data set on my PC at home. No matter how much I want to, It would be next to impossible for me to simulate the work that a data engineer actually does on the job in a personal setting. Because any work I do as a data engineer will be in a live environment for a big company with important deadlines and I don&amp;#39;t have that right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15lr89o", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lr89o/honest_question_how_do_i_know_if_im_good_enough/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lr89o/honest_question_how_do_i_know_if_im_good_enough/", "subreddit_subscribers": 121668, "created_utc": 1691521667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a full time job I\u2019m happy with. But because I\u2019m a capitalist I want to make more money. I also don\u2019t want to deal with the constrains another job or 1099 gig has, I want to be my own boss. \n\nI\u2019m considering doing freelance via upwork or similar. I have about 5 years experience with python and sql and various tools like snowflake and airflow. I think lower effort clients like webscraping or maybe even no code tools could be a good start. \n\nAnyone else do this? Is it super hard to start?", "author_fullname": "t2_1kset4fg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone Freelance on the Side?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15loaaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691515080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a full time job I\u2019m happy with. But because I\u2019m a capitalist I want to make more money. I also don\u2019t want to deal with the constrains another job or 1099 gig has, I want to be my own boss. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m considering doing freelance via upwork or similar. I have about 5 years experience with python and sql and various tools like snowflake and airflow. I think lower effort clients like webscraping or maybe even no code tools could be a good start. &lt;/p&gt;\n\n&lt;p&gt;Anyone else do this? Is it super hard to start?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15loaaj", "is_robot_indexable": true, "report_reasons": null, "author": "shittyfuckdick", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15loaaj/anyone_freelance_on_the_side/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15loaaj/anyone_freelance_on_the_side/", "subreddit_subscribers": 121668, "created_utc": 1691515080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Consultants have forced on us a truly terrible data model for our marketing warehouse. Tables and columns are named with inscrutable acronyms, there\u2019s no clarity on how entities relate to one another or map to business processes, and the idea of a meaningful table grain is but a dream (they like to make new tables by grouping by dozens of unrelated attributes).\n\nIt\u2019s a mess and the most infuriating part as an ETL engineer is that I can\u2019t get that across to the business side because whenever I say \u201cproper modeling standards\u201d they hear \u201cyou\u2019re going to make me wait longer for new reports\u201d. The only way I can think to prove how bad it is would be to redo the whole design myself to give them a side-by-side comparison, but that\u2019s months of work. And of course when the data quality goes to hell my team is the one that\u2019ll take the blame.\n\nAny suggestions or stories of similar situations?", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prove a data model is bad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ltzr9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691527832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Consultants have forced on us a truly terrible data model for our marketing warehouse. Tables and columns are named with inscrutable acronyms, there\u2019s no clarity on how entities relate to one another or map to business processes, and the idea of a meaningful table grain is but a dream (they like to make new tables by grouping by dozens of unrelated attributes).&lt;/p&gt;\n\n&lt;p&gt;It\u2019s a mess and the most infuriating part as an ETL engineer is that I can\u2019t get that across to the business side because whenever I say \u201cproper modeling standards\u201d they hear \u201cyou\u2019re going to make me wait longer for new reports\u201d. The only way I can think to prove how bad it is would be to redo the whole design myself to give them a side-by-side comparison, but that\u2019s months of work. And of course when the data quality goes to hell my team is the one that\u2019ll take the blame.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or stories of similar situations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ltzr9", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ltzr9/prove_a_data_model_is_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ltzr9/prove_a_data_model_is_bad/", "subreddit_subscribers": 121668, "created_utc": 1691527832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Chat with your data using Langchain, PineconeDB and Airbyte", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15lknol", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Xe6peY4RU0yNowvzeXa31-60kkVOVBGZu-_8Jiea5eQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691506899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/tutorials/chat-with-your-data-using-openai-pinecone-airbyte-and-langchain", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?auto=webp&amp;s=52a690eb9017d31f55c72f17ac74e0347fa70b79", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a136427b5c95f1c32d43dabf92f1a2e74d78d91b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=eb85a8994c311bb57badb97ef96d0ef7fb941563", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4057bdf0af2ac9efbd906372a3de8c4ab64f9dcf", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bcd751162168d9362cfc5f4142b584cb50864946", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a75943c2b264d21299e79f96ebe798c1bb19d47b", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=05be86c826c8270e6c09f23b0ca908e4a17e2363", "width": 1080, "height": 565}], "variants": {}, "id": "-Fru_wIX1XucCxZWM2v5cBU30Yg0UH4LNViVg8dqAN8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15lknol", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15lknol/chat_with_your_data_using_langchain_pineconedb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/tutorials/chat-with-your-data-using-openai-pinecone-airbyte-and-langchain", "subreddit_subscribers": 121668, "created_utc": 1691506899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to make a python function that takes an API, paginates thru a large dataset, and maps that data onto an SQLite database. When paginating, I have to use the limit and offset parameters.\n\nFor example, this CDC API 'https://data.cdc.gov/resource/bugr-bbfr.json' would be look like 'https://data.cdc.gov/resource/bugr-bbfr.json?$limit=1000&amp;$offset=0'\n\nHowever, a different API like 'https://data.cms.gov/data-api/v1/dataset/f1a8c197-b53d-4c24-9770-aea5d5a97dfb/data' would look like 'https://data.cms.gov/data-api/v1/dataset/f1a8c197-b53d-4c24-9770-aea5d5a97dfb/data?size=1000&amp;offset=0'\n\nBoth are JSON formats.\n\nCan someone explain why APIs can end in either \".json\" or \"/data\", or why the parameter syntax is slightly different?", "author_fullname": "t2_5pddzf1hy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "APIs have different limit/offset syntax", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15l7jvj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691469511.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691469131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to make a python function that takes an API, paginates thru a large dataset, and maps that data onto an SQLite database. When paginating, I have to use the limit and offset parameters.&lt;/p&gt;\n\n&lt;p&gt;For example, this CDC API &amp;#39;&lt;a href=\"https://data.cdc.gov/resource/bugr-bbfr.json\"&gt;https://data.cdc.gov/resource/bugr-bbfr.json&lt;/a&gt;&amp;#39; would be look like &amp;#39;&lt;a href=\"https://data.cdc.gov/resource/bugr-bbfr.json?$limit=1000&amp;amp;$offset=0\"&gt;https://data.cdc.gov/resource/bugr-bbfr.json?$limit=1000&amp;amp;$offset=0&lt;/a&gt;&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;However, a different API like &amp;#39;&lt;a href=\"https://data.cms.gov/data-api/v1/dataset/f1a8c197-b53d-4c24-9770-aea5d5a97dfb/data\"&gt;https://data.cms.gov/data-api/v1/dataset/f1a8c197-b53d-4c24-9770-aea5d5a97dfb/data&lt;/a&gt;&amp;#39; would look like &amp;#39;&lt;a href=\"https://data.cms.gov/data-api/v1/dataset/f1a8c197-b53d-4c24-9770-aea5d5a97dfb/data?size=1000&amp;amp;offset=0\"&gt;https://data.cms.gov/data-api/v1/dataset/f1a8c197-b53d-4c24-9770-aea5d5a97dfb/data?size=1000&amp;amp;offset=0&lt;/a&gt;&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;Both are JSON formats.&lt;/p&gt;\n\n&lt;p&gt;Can someone explain why APIs can end in either &amp;quot;.json&amp;quot; or &amp;quot;/data&amp;quot;, or why the parameter syntax is slightly different?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15l7jvj", "is_robot_indexable": true, "report_reasons": null, "author": "knewtonslol", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15l7jvj/apis_have_different_limitoffset_syntax/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15l7jvj/apis_have_different_limitoffset_syntax/", "subreddit_subscribers": 121668, "created_utc": 1691469131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sometimes I feel DEs generally don't care about lowering costs and efficiency. Not until it's a requirement anyway.\n\nAs long it's easy to maintain and the data is correct and available we are happy to let the company spend more money.\n\nWhat do DEs here do? Do you actively try to optimize and cut costs or is it more of DevOps's problem?\n\n&amp;#x200B;", "author_fullname": "t2_av88gzj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do DEs care about optimization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15l751l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691467900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sometimes I feel DEs generally don&amp;#39;t care about lowering costs and efficiency. Not until it&amp;#39;s a requirement anyway.&lt;/p&gt;\n\n&lt;p&gt;As long it&amp;#39;s easy to maintain and the data is correct and available we are happy to let the company spend more money.&lt;/p&gt;\n\n&lt;p&gt;What do DEs here do? Do you actively try to optimize and cut costs or is it more of DevOps&amp;#39;s problem?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15l751l", "is_robot_indexable": true, "report_reasons": null, "author": "rdmcoloring", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15l751l/do_des_care_about_optimization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15l751l/do_des_care_about_optimization/", "subreddit_subscribers": 121668, "created_utc": 1691467900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am leading an effort to build out a production ETL pipeline/data lake from scratch using AWS Glue and other AWS Technologies like Lake Formation, Event Bridge, Step Functions and more.\n\nI wanted to see if anyone here has experience with the development flow/productionized setup for AWS Glue and how to best manage it? I have already read [Build, Test and Deploy ETL solutions using AWS Glue and AWS CDK based CI/CD pipelines](https://aws.amazon.com/blogs/big-data/build-test-and-deploy-etl-solutions-using-aws-glue-and-aws-cdk-based-ci-cd-pipelines/) and [Deploy an AWS Glue job with an AWS CodePipeline CI/CD pipeline](https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/deploy-an-aws-glue-job-with-an-aws-codepipeline-ci-cd-pipeline.html) and several other documents and videos, but am still coming up a bit short in my head on how to best implement this.\n\nA few notes and background:  \n\n\n* Using Github, CircleCI (though I would likely use CodePipeline for this), Terraform for infrastructure.\n* Plan to use combination of Python/PySpark and are even considering Ray as well.\n* Currently we only have one AWS Environment but would likely split this out into multi-environment setup as part of this effort\n* We know the AWS Glue UI sucks and would prefer to manage this code as much as possible locally using whatever dev tool the engineer wants to use and leverage [Interactive Sessions](https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions-chapter.html)\n* We need to have very strict control/access lockdown over production.\n\nDoes anyone have experience with a similar pipeline setup and any lessons learned or architecture notes on how this development flow should work?  Really just hoping to get a decent understanding of what might work, what hasn't worked or other issues.", "author_fullname": "t2_3tfgc8z0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing Infra/Development Flow for AWS Glue ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lno3v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691513665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am leading an effort to build out a production ETL pipeline/data lake from scratch using AWS Glue and other AWS Technologies like Lake Formation, Event Bridge, Step Functions and more.&lt;/p&gt;\n\n&lt;p&gt;I wanted to see if anyone here has experience with the development flow/productionized setup for AWS Glue and how to best manage it? I have already read &lt;a href=\"https://aws.amazon.com/blogs/big-data/build-test-and-deploy-etl-solutions-using-aws-glue-and-aws-cdk-based-ci-cd-pipelines/\"&gt;Build, Test and Deploy ETL solutions using AWS Glue and AWS CDK based CI/CD pipelines&lt;/a&gt; and &lt;a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/deploy-an-aws-glue-job-with-an-aws-codepipeline-ci-cd-pipeline.html\"&gt;Deploy an AWS Glue job with an AWS CodePipeline CI/CD pipeline&lt;/a&gt; and several other documents and videos, but am still coming up a bit short in my head on how to best implement this.&lt;/p&gt;\n\n&lt;p&gt;A few notes and background:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Using Github, CircleCI (though I would likely use CodePipeline for this), Terraform for infrastructure.&lt;/li&gt;\n&lt;li&gt;Plan to use combination of Python/PySpark and are even considering Ray as well.&lt;/li&gt;\n&lt;li&gt;Currently we only have one AWS Environment but would likely split this out into multi-environment setup as part of this effort&lt;/li&gt;\n&lt;li&gt;We know the AWS Glue UI sucks and would prefer to manage this code as much as possible locally using whatever dev tool the engineer wants to use and leverage &lt;a href=\"https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions-chapter.html\"&gt;Interactive Sessions&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;We need to have very strict control/access lockdown over production.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Does anyone have experience with a similar pipeline setup and any lessons learned or architecture notes on how this development flow should work?  Really just hoping to get a decent understanding of what might work, what hasn&amp;#39;t worked or other issues.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15lno3v", "is_robot_indexable": true, "report_reasons": null, "author": "deepeyesmusic", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lno3v/managing_infradevelopment_flow_for_aws_glue_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lno3v/managing_infradevelopment_flow_for_aws_glue_etl/", "subreddit_subscribers": 121668, "created_utc": 1691513665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there!\n\nI'm super excited to release my most challenging video so far:  \nThe Data Retail Project! \n\nIt's a 1-hour video to create an end-to-end pipeline!\n\nIn this project, you will be working with a retail dataset to create an end-to-end pipeline that extracts and loads the data from GCS to BigQuery, runs data quality checks with Soda, models and transforms the data with dbt, until building a dashboard with Metabase!\n\nHere's what you will learn:  \n\u2705 Create a data pipeline with Airflow following best practices  \n\u2705 Set up your Airflow local environment with the Astro CLI  \n\u2705 Run data quality checks in your pipeline with Soda  \n\u2705 Integrate dbt and run your models with Comos  \n\u2705 Isolate your tasks to avoid dependency conflicts  \n\u2705 Upload a CSV file into Google Cloud Storage from Airflow  \n\u2705 Ingest data into a BigQuery table using the Astro SDK  \n\u2705 Build a dashboard with Metabase on your data  \nand more!\n\nLink to the video: [https://youtu.be/DzxtCxi4YaA](https://youtu.be/DzxtCxi4YaA)\n\nAny feedback is much appreciated, hope you will find it useful \u2764\ufe0f  \nTake care", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Data Retail Project: Create an end-to-end pipeline with Airflow, dbt, Soda, BigQuery, and more", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ljgz6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691504174.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m super excited to release my most challenging video so far:&lt;br/&gt;\nThe Data Retail Project! &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s a 1-hour video to create an end-to-end pipeline!&lt;/p&gt;\n\n&lt;p&gt;In this project, you will be working with a retail dataset to create an end-to-end pipeline that extracts and loads the data from GCS to BigQuery, runs data quality checks with Soda, models and transforms the data with dbt, until building a dashboard with Metabase!&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what you will learn:&lt;br/&gt;\n\u2705 Create a data pipeline with Airflow following best practices&lt;br/&gt;\n\u2705 Set up your Airflow local environment with the Astro CLI&lt;br/&gt;\n\u2705 Run data quality checks in your pipeline with Soda&lt;br/&gt;\n\u2705 Integrate dbt and run your models with Comos&lt;br/&gt;\n\u2705 Isolate your tasks to avoid dependency conflicts&lt;br/&gt;\n\u2705 Upload a CSV file into Google Cloud Storage from Airflow&lt;br/&gt;\n\u2705 Ingest data into a BigQuery table using the Astro SDK&lt;br/&gt;\n\u2705 Build a dashboard with Metabase on your data&lt;br/&gt;\nand more!&lt;/p&gt;\n\n&lt;p&gt;Link to the video: &lt;a href=\"https://youtu.be/DzxtCxi4YaA\"&gt;https://youtu.be/DzxtCxi4YaA&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any feedback is much appreciated, hope you will find it useful \u2764\ufe0f&lt;br/&gt;\nTake care&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/d50b5St1aMmRBp_EaWD7z6t9qCZ8aru9szBKG4SYnQg.jpg?auto=webp&amp;s=d471a7f6701b40333a59effc45f6db8427dee22a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/d50b5St1aMmRBp_EaWD7z6t9qCZ8aru9szBKG4SYnQg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e8af0a16fc901db703935ae708e9e1e8669b7a5e", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/d50b5St1aMmRBp_EaWD7z6t9qCZ8aru9szBKG4SYnQg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2eee7cd3c09da6a3a2182668068423f151b74b50", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/d50b5St1aMmRBp_EaWD7z6t9qCZ8aru9szBKG4SYnQg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a6beb426e10a4f5bdc5a3e1b1bc750925eccf319", "width": 320, "height": 240}], "variants": {}, "id": "SBtgWAZgDtTjP28yqZ1dn1RCBIiKsF3xR0d0IR8I0aw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ljgz6", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ljgz6/the_data_retail_project_create_an_endtoend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ljgz6/the_data_retail_project_create_an_endtoend/", "subreddit_subscribers": 121668, "created_utc": 1691504174.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bhpulfr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leveraging web scraping data for dynamic pricing strategies in e-commerce", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15luq4n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VjgsxlUrG_pazdMae9QTaG3YPpHbR-3d57bl2qb9ayA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691529445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "javascript.plainenglish.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://javascript.plainenglish.io/leveraging-web-scraping-for-dynamic-pricing-strategies-for-e-commerce-dba4f813d1e", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?auto=webp&amp;s=f4ce28f571fb0cda3c7f2a661f6a3a2923e958b1", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2dda5e47ff2d4989e9856e206d954dfaf65b8c0f", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1cf81ef3c5ad9c1a4e9385b9dcbb7742055de86", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1caf31760c4778a0c4d62c34a5e18f563cd9d590", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1afcf08ca6054e094c8f2564df66d7f2a49e2ede", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c33c3b8266fb8c296613837facffe25506fa98ec", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=16922483d1cc749069eaa5a42e615896a563008a", "width": 1080, "height": 720}], "variants": {}, "id": "BSFNvAYgJyuJNwJHWBMIOMxmpmFKInElIaXDQoYBMDQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15luq4n", "is_robot_indexable": true, "report_reasons": null, "author": "9millionrainydays_91", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15luq4n/leveraging_web_scraping_data_for_dynamic_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://javascript.plainenglish.io/leveraging-web-scraping-for-dynamic-pricing-strategies-for-e-commerce-dba4f813d1e", "subreddit_subscribers": 121668, "created_utc": 1691529445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently attended HireVue video interview and can not explain how weird it turned out for me !!! Talking to nobody for 3 mints and then retry! It is not a big deal as I talk to myself all the time but I don\u2019t know why I got weird. I started fumbling and saying something nonsense. Anyway I submitted total video interview including one coding question around 2 hours!!  Expected was 45 minutes!!!   Did I still get a chance to go for next round ?", "author_fullname": "t2_t526hbv5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Video interviews without a facing a face !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lry6o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691523286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently attended HireVue video interview and can not explain how weird it turned out for me !!! Talking to nobody for 3 mints and then retry! It is not a big deal as I talk to myself all the time but I don\u2019t know why I got weird. I started fumbling and saying something nonsense. Anyway I submitted total video interview including one coding question around 2 hours!!  Expected was 45 minutes!!!   Did I still get a chance to go for next round ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15lry6o", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Ticket6016", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lry6o/video_interviews_without_a_facing_a_face/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lry6o/video_interviews_without_a_facing_a_face/", "subreddit_subscribers": 121668, "created_utc": 1691523286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello house, \n\nLet me start like this I currently work as a senior data analyst for my company and I have experience in data science with different project and research paper.\n\nI have always wanted to pivot to data engineering for a while now, taken multiple certifications on Azure and other resources.\n\nI got a job as a data engineer in an oil and gas company. I cleared all the exams(3) and interviews (2) with flying colors.\n\nI had a deep knowledge in all what data engineering is all about, the only issue is I have never worked as a data engineer \ud83d\udc68\ud83c\udffd\u200d\ud83d\udcbb much is expected from me with the high level I performed but I feel like this was because I have verse experience in data analysis and consulting which helped me.\n\nI primary use Azure DataBricks and ADF cloud, delta lake table(unity catalog) for warehouse and ADLG2 staging storage.\n\nSSIS, SSRS, SSAS and SSMS for private and local.\n\nPower BI &amp; Datamarts for visualization.\n\nIs this enough or is there something more to data engineering, I might sound silly but I feel there expectation of me is really high.\n\nLet me add I also work as a data engineer in a publishing company in the US as an author/writer.", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imposter Syndrome", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ln3gv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691512572.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691512333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello house, &lt;/p&gt;\n\n&lt;p&gt;Let me start like this I currently work as a senior data analyst for my company and I have experience in data science with different project and research paper.&lt;/p&gt;\n\n&lt;p&gt;I have always wanted to pivot to data engineering for a while now, taken multiple certifications on Azure and other resources.&lt;/p&gt;\n\n&lt;p&gt;I got a job as a data engineer in an oil and gas company. I cleared all the exams(3) and interviews (2) with flying colors.&lt;/p&gt;\n\n&lt;p&gt;I had a deep knowledge in all what data engineering is all about, the only issue is I have never worked as a data engineer \ud83d\udc68\ud83c\udffd\u200d\ud83d\udcbb much is expected from me with the high level I performed but I feel like this was because I have verse experience in data analysis and consulting which helped me.&lt;/p&gt;\n\n&lt;p&gt;I primary use Azure DataBricks and ADF cloud, delta lake table(unity catalog) for warehouse and ADLG2 staging storage.&lt;/p&gt;\n\n&lt;p&gt;SSIS, SSRS, SSAS and SSMS for private and local.&lt;/p&gt;\n\n&lt;p&gt;Power BI &amp;amp; Datamarts for visualization.&lt;/p&gt;\n\n&lt;p&gt;Is this enough or is there something more to data engineering, I might sound silly but I feel there expectation of me is really high.&lt;/p&gt;\n\n&lt;p&gt;Let me add I also work as a data engineer in a publishing company in the US as an author/writer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ln3gv", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ln3gv/imposter_syndrome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ln3gv/imposter_syndrome/", "subreddit_subscribers": 121668, "created_utc": 1691512333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone tried out the new m7i EC2 instances yet?\n\nWe ran the Dask benchmark suite comparing m6i.large to m7i.large nodes and the total runtime went down by \\~12% (so enough to justify the 5% increase in on-demand price). Image below for [test\\_dot\\_product\\_spill](https://github.com/coiled/benchmarks/blob/b07e7bb397fa0936883feca7981362bf52d34e7c/tests/benchmarks/test_spill.py#L65).\n\nBut... there's a much larger spot discount on older m6i.large instances, so total cost is still lower using m6i instances. Currently m7i.large spot instances are  &gt;25% more expensive than m6i.large spot. Alas.\n\nCurious to hear if others found something similar.\n\n[Final points in the plot are for the run with m7i.large](https://preview.redd.it/ub3x3jw1uwgb1.png?width=791&amp;format=png&amp;auto=webp&amp;s=0f70197d1ccbff8451728f919a7a3750f5353d89)", "author_fullname": "t2_w7crvjmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New m7i speculation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 49, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ub3x3jw1uwgb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3af89c86d860efb04b79924a71e9db35666698a5"}, {"y": 76, "x": 216, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d172dbe1cfa2465feba9d3b03990a5203cf2f70b"}, {"y": 113, "x": 320, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ff214a23693712170463a75c97fbce93b619692f"}, {"y": 227, "x": 640, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d4bf4eb4b65fba456938bf330920bda70635b855"}], "s": {"y": 281, "x": 791, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=791&amp;format=png&amp;auto=webp&amp;s=0f70197d1ccbff8451728f919a7a3750f5353d89"}, "id": "ub3x3jw1uwgb1"}}, "name": "t3_15lmjda", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/fAX1Z9Xze2JiLhqO8oS3kCTrS_dt2DRlAWD6xOI6oi4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691511057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone tried out the new m7i EC2 instances yet?&lt;/p&gt;\n\n&lt;p&gt;We ran the Dask benchmark suite comparing m6i.large to m7i.large nodes and the total runtime went down by ~12% (so enough to justify the 5% increase in on-demand price). Image below for &lt;a href=\"https://github.com/coiled/benchmarks/blob/b07e7bb397fa0936883feca7981362bf52d34e7c/tests/benchmarks/test_spill.py#L65\"&gt;test_dot_product_spill&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;But... there&amp;#39;s a much larger spot discount on older m6i.large instances, so total cost is still lower using m6i instances. Currently m7i.large spot instances are  &amp;gt;25% more expensive than m6i.large spot. Alas.&lt;/p&gt;\n\n&lt;p&gt;Curious to hear if others found something similar.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ub3x3jw1uwgb1.png?width=791&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0f70197d1ccbff8451728f919a7a3750f5353d89\"&gt;Final points in the plot are for the run with m7i.large&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15lmjda", "is_robot_indexable": true, "report_reasons": null, "author": "dask-jeeves", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lmjda/new_m7i_speculation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lmjda/new_m7i_speculation/", "subreddit_subscribers": 121668, "created_utc": 1691511057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know there\u2019s a thread about the bootcamp, but he recently launched a self paced bootcamp that is cheaper. I can afford the bootcamp, but it\u2019s still very expensive (like 1month+ of my savings). Do you all think the self paced bootcamp is worth the price? Trying to get some opinions to make a rational decision.", "author_fullname": "t2_b4x7m5t6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Eczachly self paced bootcamp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15m345i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691550473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know there\u2019s a thread about the bootcamp, but he recently launched a self paced bootcamp that is cheaper. I can afford the bootcamp, but it\u2019s still very expensive (like 1month+ of my savings). Do you all think the self paced bootcamp is worth the price? Trying to get some opinions to make a rational decision.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m345i", "is_robot_indexable": true, "report_reasons": null, "author": "heyveryfunny", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m345i/eczachly_self_paced_bootcamp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m345i/eczachly_self_paced_bootcamp/", "subreddit_subscribers": 121668, "created_utc": 1691550473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "recently i have been asked kinda vague system design type questions for entry - mid level Data Engineer roles, \n\neg - how you will build a real-time dashboard for user activity for an e-commerce app like Amazon, and things related to it like tradeoffs, the whole structure , architecture etc.\n\nare these very common? as i don't really have too much experience in this (i have common data engineering architecture sense) so i explained it in a very normal way.\n\ni have been asked similar architecture type question before, like how you will build the data warehouse/ datalake  for analysts/ data scientists to use...\n\nso my question if there are very common questions...is there anything i can refer to to prepare for them? or should i just go and watch system design interview videos?  \n\n\nP.S - please forgive me for any typos, its almost 1 am,and i am very sleepy \ud83d\ude22", "author_fullname": "t2_6f6khk66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "system design type interview questions for DE roles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lrfuw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691522142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;recently i have been asked kinda vague system design type questions for entry - mid level Data Engineer roles, &lt;/p&gt;\n\n&lt;p&gt;eg - how you will build a real-time dashboard for user activity for an e-commerce app like Amazon, and things related to it like tradeoffs, the whole structure , architecture etc.&lt;/p&gt;\n\n&lt;p&gt;are these very common? as i don&amp;#39;t really have too much experience in this (i have common data engineering architecture sense) so i explained it in a very normal way.&lt;/p&gt;\n\n&lt;p&gt;i have been asked similar architecture type question before, like how you will build the data warehouse/ datalake  for analysts/ data scientists to use...&lt;/p&gt;\n\n&lt;p&gt;so my question if there are very common questions...is there anything i can refer to to prepare for them? or should i just go and watch system design interview videos?  &lt;/p&gt;\n\n&lt;p&gt;P.S - please forgive me for any typos, its almost 1 am,and i am very sleepy \ud83d\ude22&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15lrfuw", "is_robot_indexable": true, "report_reasons": null, "author": "mainak17", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lrfuw/system_design_type_interview_questions_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lrfuw/system_design_type_interview_questions_for_de/", "subreddit_subscribers": 121668, "created_utc": 1691522142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Might be a bit of a weird question but I'm getting my role within my company redefined and I'm not sure what to call myself. Basically it's a small to medium sized company and they give me a lot of leeway. I've used my freedom to get them set up with an Azure Postgres database for their product data and plan to A) Make the database more comprehensive and improve the quality of the data, B) Make the data usable for colleagues and clients (primarily through excel and python), C) Integrate the data across the different platforms we have in order to minimise errors and improve efficiency, and D) Run some data analysis once a lot of the basic systems are in place.\n\nI'm self taught with all of the above for the most part as while I had a bit of education with Computing I never finished a degree in CS (I was a lazy teenager). I'm learning as I go basically. I was thinking Data Architect but that role seems to be attached to \u00a350000+ salaries and so I don't want to put anything on my CV down the line that ends up looking silly, given that I'm fairly 'entry-level'. Is this an appropriate job title for what I've described or is there a better one that's fairly standard in the industry?", "author_fullname": "t2_1b1qrwg3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should my job title be?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lme8s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691510743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Might be a bit of a weird question but I&amp;#39;m getting my role within my company redefined and I&amp;#39;m not sure what to call myself. Basically it&amp;#39;s a small to medium sized company and they give me a lot of leeway. I&amp;#39;ve used my freedom to get them set up with an Azure Postgres database for their product data and plan to A) Make the database more comprehensive and improve the quality of the data, B) Make the data usable for colleagues and clients (primarily through excel and python), C) Integrate the data across the different platforms we have in order to minimise errors and improve efficiency, and D) Run some data analysis once a lot of the basic systems are in place.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m self taught with all of the above for the most part as while I had a bit of education with Computing I never finished a degree in CS (I was a lazy teenager). I&amp;#39;m learning as I go basically. I was thinking Data Architect but that role seems to be attached to \u00a350000+ salaries and so I don&amp;#39;t want to put anything on my CV down the line that ends up looking silly, given that I&amp;#39;m fairly &amp;#39;entry-level&amp;#39;. Is this an appropriate job title for what I&amp;#39;ve described or is there a better one that&amp;#39;s fairly standard in the industry?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15lme8s", "is_robot_indexable": true, "report_reasons": null, "author": "Patrick_Gently", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lme8s/what_should_my_job_title_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lme8s/what_should_my_job_title_be/", "subreddit_subscribers": 121668, "created_utc": 1691510743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3k9gevl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "What is your preferred ETL method ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "media_metadata": {"n3sbetalowgb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 52, "x": 108, "u": "https://preview.redd.it/n3sbetalowgb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=52aeeab364c39e755fd59351d86efbfbd8ac2701"}, {"y": 104, "x": 216, "u": "https://preview.redd.it/n3sbetalowgb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9ff7c0cb27d2aefc00f145c4f745bfddc7f53576"}, {"y": 154, "x": 320, "u": "https://preview.redd.it/n3sbetalowgb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f9ffb9c6a996d4ebf72a63499ebc5fc310d8bd3"}, {"y": 309, "x": 640, "u": "https://preview.redd.it/n3sbetalowgb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=86c8faa1d5fc19e5a349de799269df5c96c14a3e"}, {"y": 464, "x": 960, "u": "https://preview.redd.it/n3sbetalowgb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c129a17e26c3d67a08e68e6cd0e5b93638cf6b77"}, {"y": 522, "x": 1080, "u": "https://preview.redd.it/n3sbetalowgb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c60cab42c6e7cdad3b048a795f93156cceaa4941"}], "s": {"y": 648, "x": 1339, "u": "https://preview.redd.it/n3sbetalowgb1.png?width=1339&amp;format=png&amp;auto=webp&amp;s=12b7120003cd47bf552697222457355199f9c98d"}, "id": "n3sbetalowgb1"}, "pdx3r08lowgb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/pdx3r08lowgb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a92bb959da03e89f515996e7a1438a60b9b8b857"}, {"y": 76, "x": 216, "u": "https://preview.redd.it/pdx3r08lowgb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1be269ad51bccddd5a00f6646688b191fe9eab17"}, {"y": 113, "x": 320, "u": "https://preview.redd.it/pdx3r08lowgb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=33974d83885dd7d80feefe8ee1672eae33ce61a3"}, {"y": 227, "x": 640, "u": "https://preview.redd.it/pdx3r08lowgb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0ddbfdb2e593a04707aaa3631f287e5fdf281171"}, {"y": 340, "x": 960, "u": "https://preview.redd.it/pdx3r08lowgb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8263f8219ee9cc7cc5f4843d54651df782821a93"}, {"y": 383, "x": 1080, "u": "https://preview.redd.it/pdx3r08lowgb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4616f8ca4bddc6be789a8304388530e894ffe715"}], "s": {"y": 648, "x": 1826, "u": "https://preview.redd.it/pdx3r08lowgb1.png?width=1826&amp;format=png&amp;auto=webp&amp;s=5b8310a1ef97685b6e3f6d9c004b90d3dd40a3d4"}, "id": "pdx3r08lowgb1"}}, "name": "t3_15llojl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 3, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "My method.", "media_id": "n3sbetalowgb1", "id": 312706672}, {"caption": "ETL guy's method", "media_id": "pdx3r08lowgb1", "id": 312706673}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ozHfUXPkEyGPsOAVf6p4VXddCHJIXb7324EIFVAbnj8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691509168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/15llojl", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15llojl", "is_robot_indexable": true, "report_reasons": null, "author": "Pillstyr", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15llojl/what_is_your_preferred_etl_method/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/15llojl", "subreddit_subscribers": 121668, "created_utc": 1691509168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\ndid anyone recently compare Fivetran, Qlik Replicate, and CData Sync?  \nI'm asking myself the same question as u/underflo four years ago:  \n[https://www.reddit.com/r/dataengineering/comments/dsl93l/why\\_is\\_cdata\\_not\\_more\\_popular/](https://www.reddit.com/r/dataengineering/comments/dsl93l/why_is_cdata_not_more_popular/)\n\n  \nI mainly think about traditional use cases and sources that we used to integrate with SSIS, Talend &amp; Co.\n\nSo on-prem databases, transactional data from ERPs, and of course a lot of Excel and CSV files.\n\nThat's why I leave out Stitch and other SaaS data replication tools.\n\n  \nHere are some thoughts after a quick research:\n\n* Fivetran is easier to setup\n* Fivetran has more CDC capabilities \n* Both tools can orchestrate dbt jobs\n* CData Sync has a lot of sources (especially on-prem)\n* The price tag of CData is not as big, but therefore limited in the amount of connections (sources &amp; targets)  \n\n\nWhat do you think?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_7lgct3ea", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is nobody talking about CData sync?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lj97q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691503667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;did anyone recently compare Fivetran, Qlik Replicate, and CData Sync?&lt;br/&gt;\nI&amp;#39;m asking myself the same question as &lt;a href=\"/u/underflo\"&gt;u/underflo&lt;/a&gt; four years ago:&lt;br/&gt;\n&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/dsl93l/why_is_cdata_not_more_popular/\"&gt;https://www.reddit.com/r/dataengineering/comments/dsl93l/why_is_cdata_not_more_popular/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I mainly think about traditional use cases and sources that we used to integrate with SSIS, Talend &amp;amp; Co.&lt;/p&gt;\n\n&lt;p&gt;So on-prem databases, transactional data from ERPs, and of course a lot of Excel and CSV files.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s why I leave out Stitch and other SaaS data replication tools.&lt;/p&gt;\n\n&lt;p&gt;Here are some thoughts after a quick research:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Fivetran is easier to setup&lt;/li&gt;\n&lt;li&gt;Fivetran has more CDC capabilities &lt;/li&gt;\n&lt;li&gt;Both tools can orchestrate dbt jobs&lt;/li&gt;\n&lt;li&gt;CData Sync has a lot of sources (especially on-prem)&lt;/li&gt;\n&lt;li&gt;The price tag of CData is not as big, but therefore limited in the amount of connections (sources &amp;amp; targets)&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What do you think?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15lj97q", "is_robot_indexable": true, "report_reasons": null, "author": "hansguckdieluft", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lj97q/why_is_nobody_talking_about_cdata_sync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lj97q/why_is_nobody_talking_about_cdata_sync/", "subreddit_subscribers": 121668, "created_utc": 1691503667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got Excel file on SharePoint and need to keep it synced with MS SQL database table. \n\nAny changes I make in SharePoint file should also happen in the database automatically. We've got a 2FA corporate SharePoint, which complicates things.\n\nI've managed to get things working with Power Automate, but I wonder if there's a way to do this with Python. \n\nHas anyone done something similar with python or maybe powershell? ", "author_fullname": "t2_8u34pgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2FA Sharepoint and Ms Sql synchronisation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lhugg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691500318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got Excel file on SharePoint and need to keep it synced with MS SQL database table. &lt;/p&gt;\n\n&lt;p&gt;Any changes I make in SharePoint file should also happen in the database automatically. We&amp;#39;ve got a 2FA corporate SharePoint, which complicates things.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve managed to get things working with Power Automate, but I wonder if there&amp;#39;s a way to do this with Python. &lt;/p&gt;\n\n&lt;p&gt;Has anyone done something similar with python or maybe powershell? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15lhugg", "is_robot_indexable": true, "report_reasons": null, "author": "Sa1kon", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lhugg/2fa_sharepoint_and_ms_sql_synchronisation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lhugg/2fa_sharepoint_and_ms_sql_synchronisation/", "subreddit_subscribers": 121668, "created_utc": 1691500318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey so i have to calculate pricing for azure resources like synapse, adf and databricks but i can really understand azure calculator. I have to make scenarios and calculate how much it will cost using each technology.\n\nEg. price Moving 1gb data between two containers using each technology", "author_fullname": "t2_awlluu64", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure data resources pricing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lgceg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691496450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey so i have to calculate pricing for azure resources like synapse, adf and databricks but i can really understand azure calculator. I have to make scenarios and calculate how much it will cost using each technology.&lt;/p&gt;\n\n&lt;p&gt;Eg. price Moving 1gb data between two containers using each technology&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15lgceg", "is_robot_indexable": true, "report_reasons": null, "author": "PauseApprehensive110", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lgceg/azure_data_resources_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lgceg/azure_data_resources_pricing/", "subreddit_subscribers": 121668, "created_utc": 1691496450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nWe intend to set up a NiFi cluster to generate HTTP requests for a Kafka Topic, akin to Kafka REST.\n\nUnlike Kafka REST, which lacks request compression, our payload size averages 5 MB. Operating without compression places a significant strain on resources. (It's possible Kafka REST omits compression due to vulnerability concerns (breach attack), although our internal-only endpoint remains unaffected.)\n\nIs NiFi a suitable choice for this particular use case?\n\nWorth noting, we're currently employing a 20-node NiFi cluster to process streaming data from Kafka.", "author_fullname": "t2_s5t7bjpp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring NiFi as a Solution for Efficient HTTP Request Generation in Kafka Clusters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ldmu4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691488637.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We intend to set up a NiFi cluster to generate HTTP requests for a Kafka Topic, akin to Kafka REST.&lt;/p&gt;\n\n&lt;p&gt;Unlike Kafka REST, which lacks request compression, our payload size averages 5 MB. Operating without compression places a significant strain on resources. (It&amp;#39;s possible Kafka REST omits compression due to vulnerability concerns (breach attack), although our internal-only endpoint remains unaffected.)&lt;/p&gt;\n\n&lt;p&gt;Is NiFi a suitable choice for this particular use case?&lt;/p&gt;\n\n&lt;p&gt;Worth noting, we&amp;#39;re currently employing a 20-node NiFi cluster to process streaming data from Kafka.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ldmu4", "is_robot_indexable": true, "report_reasons": null, "author": "shaktiman-68", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ldmu4/exploring_nifi_as_a_solution_for_efficient_http/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ldmu4/exploring_nifi_as_a_solution_for_efficient_http/", "subreddit_subscribers": 121668, "created_utc": 1691488637.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, sorry if this is not the right place for this question. I'm learning PySpark to extend my tech stack and I have a question regarding data ingestion.\nI'm already quite familiar with polars and pandas, and my question is if there are use cases where one should prefer PySpark over polars as part of a data ingestion \"pipeline\" using a single machine and 1. I do not plan to use the ML tools provided by PySpark 2. The data is a table with consistent columns.", "author_fullname": "t2_7y3wuvxl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data ingestion python libraries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15l9fh9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691475002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, sorry if this is not the right place for this question. I&amp;#39;m learning PySpark to extend my tech stack and I have a question regarding data ingestion.\nI&amp;#39;m already quite familiar with polars and pandas, and my question is if there are use cases where one should prefer PySpark over polars as part of a data ingestion &amp;quot;pipeline&amp;quot; using a single machine and 1. I do not plan to use the ML tools provided by PySpark 2. The data is a table with consistent columns.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15l9fh9", "is_robot_indexable": true, "report_reasons": null, "author": "Apathiq", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15l9fh9/data_ingestion_python_libraries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15l9fh9/data_ingestion_python_libraries/", "subreddit_subscribers": 121668, "created_utc": 1691475002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w07bcus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafka is dead, long live Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15lpwvl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/riiA9i8K_vNR8mVfV1nKAV-8mh-6_2Hsc15msUGmN28.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691518697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "warpstream.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.warpstream.com/blog/kafka-is-dead-long-live-kafka", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_bRu_3lCMCeBexxPiH0U3WQWG1CGdh1tSVE8mvh5k9w.jpg?auto=webp&amp;s=c008db70540437e59daae134353f81bfad65f7e2", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/_bRu_3lCMCeBexxPiH0U3WQWG1CGdh1tSVE8mvh5k9w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bd64f67839ab7185e30cf6f1ebe930c89fb5ef5b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/_bRu_3lCMCeBexxPiH0U3WQWG1CGdh1tSVE8mvh5k9w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e0ca49a033935d0da027f0976322b13f660b5eb", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/_bRu_3lCMCeBexxPiH0U3WQWG1CGdh1tSVE8mvh5k9w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b62ea966225df74c3ec393862480e80b075ffe95", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/_bRu_3lCMCeBexxPiH0U3WQWG1CGdh1tSVE8mvh5k9w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2b3ef638c62ba3d9e8a5886bc5b5f048c2e74ceb", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/_bRu_3lCMCeBexxPiH0U3WQWG1CGdh1tSVE8mvh5k9w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6d7d2018e67717ff80bd0e6c1338b180baf91ea1", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/_bRu_3lCMCeBexxPiH0U3WQWG1CGdh1tSVE8mvh5k9w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fa48a0d0c8506aa827c281862225bc4bfaf35cba", "width": 1080, "height": 567}], "variants": {}, "id": "1HsxDouD5xqIAWkM5I6VW5iGAsUWE804v2K6e4Y0Le4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15lpwvl", "is_robot_indexable": true, "report_reasons": null, "author": "yingjunwu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lpwvl/kafka_is_dead_long_live_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.warpstream.com/blog/kafka-is-dead-long-live-kafka", "subreddit_subscribers": 121668, "created_utc": 1691518697.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}