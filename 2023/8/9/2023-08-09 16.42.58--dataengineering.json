{"kind": "Listing", "data": {"after": "t3_15mbjf9", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**My background:**\n\nCurrently I'm a senior data analyst, and I'm one of those people that works in the department where the data analyst does just about everything. I do ETL, reporting, bi stuff so piping data from Google BigQuery into stuff like Power BI, looker studio, AWS, snowflake, using Python of course. I spend more time typing in SQL than I do in English in emails. I find myself doing recreational projects with Python and SQL quite often, for example this week I wrote in API that retrieves data from Kaggle, cleans it in pandas, loads it into BigQuery, also loads it into snowflake, Cassandra, Then using even more Python, retrieves some of the data using SQL. \n\n\n**Question:**\n\nHow do I know if I'm ready for a data engineer position? Will I ever be ready? I was contacted buy a recruiter for a couple positions. The one I applied to is data analyst, but I asked about the data engineer position because the job description said almost nothing about it. She said it was a little bit more technical than what I've probably done, preceded to list off basically everything I've already been doing. Said I have to be comfortable doing object-oriented programming in Python (didn't know they used objects in data engineering). Said that it's a lot more of the piping data, working in AWS data sources, snowflake, Hadoop, etc... This is all stuff that sounds insanely complex and technical but here's the thing.... **How do I know if this is stuff that I'm capable of learning on the job or doing?** Like no, of course I haven't set up a data source from scratch with 300 million rows or a terabyte of data myself. I can't just go and make a 300 million row data set on my PC at home. No matter how much I want to, It would be next to impossible for me to simulate the work that a data engineer actually does on the job in a personal setting. Because any work I do as a data engineer will be in a live environment for a big company with important deadlines and I don't have that right now.", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Honest question: How do I know if I'm good enough to be a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lr89o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691521667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;My background:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m a senior data analyst, and I&amp;#39;m one of those people that works in the department where the data analyst does just about everything. I do ETL, reporting, bi stuff so piping data from Google BigQuery into stuff like Power BI, looker studio, AWS, snowflake, using Python of course. I spend more time typing in SQL than I do in English in emails. I find myself doing recreational projects with Python and SQL quite often, for example this week I wrote in API that retrieves data from Kaggle, cleans it in pandas, loads it into BigQuery, also loads it into snowflake, Cassandra, Then using even more Python, retrieves some of the data using SQL. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;How do I know if I&amp;#39;m ready for a data engineer position? Will I ever be ready? I was contacted buy a recruiter for a couple positions. The one I applied to is data analyst, but I asked about the data engineer position because the job description said almost nothing about it. She said it was a little bit more technical than what I&amp;#39;ve probably done, preceded to list off basically everything I&amp;#39;ve already been doing. Said I have to be comfortable doing object-oriented programming in Python (didn&amp;#39;t know they used objects in data engineering). Said that it&amp;#39;s a lot more of the piping data, working in AWS data sources, snowflake, Hadoop, etc... This is all stuff that sounds insanely complex and technical but here&amp;#39;s the thing.... &lt;strong&gt;How do I know if this is stuff that I&amp;#39;m capable of learning on the job or doing?&lt;/strong&gt; Like no, of course I haven&amp;#39;t set up a data source from scratch with 300 million rows or a terabyte of data myself. I can&amp;#39;t just go and make a 300 million row data set on my PC at home. No matter how much I want to, It would be next to impossible for me to simulate the work that a data engineer actually does on the job in a personal setting. Because any work I do as a data engineer will be in a live environment for a big company with important deadlines and I don&amp;#39;t have that right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15lr89o", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lr89o/honest_question_how_do_i_know_if_im_good_enough/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lr89o/honest_question_how_do_i_know_if_im_good_enough/", "subreddit_subscribers": 121763, "created_utc": 1691521667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a full time job I\u2019m happy with. But because I\u2019m a capitalist I want to make more money. I also don\u2019t want to deal with the constrains another job or 1099 gig has, I want to be my own boss. \n\nI\u2019m considering doing freelance via upwork or similar. I have about 5 years experience with python and sql and various tools like snowflake and airflow. I think lower effort clients like webscraping or maybe even no code tools could be a good start. \n\nAnyone else do this? Is it super hard to start?", "author_fullname": "t2_1kset4fg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone Freelance on the Side?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15loaaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691515080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a full time job I\u2019m happy with. But because I\u2019m a capitalist I want to make more money. I also don\u2019t want to deal with the constrains another job or 1099 gig has, I want to be my own boss. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m considering doing freelance via upwork or similar. I have about 5 years experience with python and sql and various tools like snowflake and airflow. I think lower effort clients like webscraping or maybe even no code tools could be a good start. &lt;/p&gt;\n\n&lt;p&gt;Anyone else do this? Is it super hard to start?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15loaaj", "is_robot_indexable": true, "report_reasons": null, "author": "shittyfuckdick", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15loaaj/anyone_freelance_on_the_side/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15loaaj/anyone_freelance_on_the_side/", "subreddit_subscribers": 121763, "created_utc": 1691515080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Consultants have forced on us a truly terrible data model for our marketing warehouse. Tables and columns are named with inscrutable acronyms, there\u2019s no clarity on how entities relate to one another or map to business processes, and the idea of a meaningful table grain is but a dream (they like to make new tables by grouping by dozens of unrelated attributes).\n\nIt\u2019s a mess and the most infuriating part as an ETL engineer is that I can\u2019t get that across to the business side because whenever I say \u201cproper modeling standards\u201d they hear \u201cyou\u2019re going to make me wait longer for new reports\u201d. The only way I can think to prove how bad it is would be to redo the whole design myself to give them a side-by-side comparison, but that\u2019s months of work. And of course when the data quality goes to hell my team is the one that\u2019ll take the blame.\n\nAny suggestions or stories of similar situations?", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prove a data model is bad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ltzr9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691527832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Consultants have forced on us a truly terrible data model for our marketing warehouse. Tables and columns are named with inscrutable acronyms, there\u2019s no clarity on how entities relate to one another or map to business processes, and the idea of a meaningful table grain is but a dream (they like to make new tables by grouping by dozens of unrelated attributes).&lt;/p&gt;\n\n&lt;p&gt;It\u2019s a mess and the most infuriating part as an ETL engineer is that I can\u2019t get that across to the business side because whenever I say \u201cproper modeling standards\u201d they hear \u201cyou\u2019re going to make me wait longer for new reports\u201d. The only way I can think to prove how bad it is would be to redo the whole design myself to give them a side-by-side comparison, but that\u2019s months of work. And of course when the data quality goes to hell my team is the one that\u2019ll take the blame.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or stories of similar situations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ltzr9", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ltzr9/prove_a_data_model_is_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ltzr9/prove_a_data_model_is_bad/", "subreddit_subscribers": 121763, "created_utc": 1691527832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, changed the company a few months ago and it seems like this one offers study days + full pay for workshops, certifications, online courses and so on.\n\nI\u2019m really looking to make good use of these opportunities, that\u2019s why I\u2019m looking for some workshop recommendations to develop myself as a data engineer. I am pretty interested in backend architecture for data systems(mostly related to Azure since that\u2019s what my company is using to host all their data architecture). \n\nBut If you guys know any other good data engineering workshops related to Data Engineering as a whole, please let me know.", "author_fullname": "t2_4lcvdsdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Online workshops for getting better at Data Engineering Backend/Datawarehouse architectures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m9ab4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691569983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, changed the company a few months ago and it seems like this one offers study days + full pay for workshops, certifications, online courses and so on.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m really looking to make good use of these opportunities, that\u2019s why I\u2019m looking for some workshop recommendations to develop myself as a data engineer. I am pretty interested in backend architecture for data systems(mostly related to Azure since that\u2019s what my company is using to host all their data architecture). &lt;/p&gt;\n\n&lt;p&gt;But If you guys know any other good data engineering workshops related to Data Engineering as a whole, please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m9ab4", "is_robot_indexable": true, "report_reasons": null, "author": "Emotional_Key", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m9ab4/online_workshops_for_getting_better_at_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m9ab4/online_workshops_for_getting_better_at_data/", "subreddit_subscribers": 121763, "created_utc": 1691569983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just started a new job and am shocked at the state of the dbt project. I've no idea whether I am used to too high standards and I am overreacting. Would appreciate to hear some other stories of dbt at your company!\n\nSo why it is so bad, we're two analytics engineers and 1 data engineer. The data engineer mainly manages airflow and databricks so they hardly work with dbt. So it's basically two people. And we have the following:\n\n- 600+ models\n\n- no tests for most of the models\n\n- lineage is a mess. One of the core tables has 55 parents and 150 children. Circular references all over the place.\n\n- everything in the mart is materialized as a table. They run those tables multiple times a day. Costs have been increasing at a steady pace ofcourse.\n\n- they use schemas to denote topics. The project.yml contains configs for each folder to materialize it to the correct schema. The file is 200+ lines long as a consequence.\n\nBtw they managed to get to this state in less than a year :p\n\nOh and they are migrating to a new bi tool with deadline end of October. Work hasn't even started on that. So should I run? :P\n\nEdit: fixed formatting", "author_fullname": "t2_2ol209b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is our dbt project as bad as I think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15mhunt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691594444.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691593433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started a new job and am shocked at the state of the dbt project. I&amp;#39;ve no idea whether I am used to too high standards and I am overreacting. Would appreciate to hear some other stories of dbt at your company!&lt;/p&gt;\n\n&lt;p&gt;So why it is so bad, we&amp;#39;re two analytics engineers and 1 data engineer. The data engineer mainly manages airflow and databricks so they hardly work with dbt. So it&amp;#39;s basically two people. And we have the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;600+ models&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;no tests for most of the models&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;lineage is a mess. One of the core tables has 55 parents and 150 children. Circular references all over the place.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;everything in the mart is materialized as a table. They run those tables multiple times a day. Costs have been increasing at a steady pace ofcourse.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;they use schemas to denote topics. The project.yml contains configs for each folder to materialize it to the correct schema. The file is 200+ lines long as a consequence.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Btw they managed to get to this state in less than a year :p&lt;/p&gt;\n\n&lt;p&gt;Oh and they are migrating to a new bi tool with deadline end of October. Work hasn&amp;#39;t even started on that. So should I run? :P&lt;/p&gt;\n\n&lt;p&gt;Edit: fixed formatting&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mhunt", "is_robot_indexable": true, "report_reasons": null, "author": "snackeloni", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mhunt/is_our_dbt_project_as_bad_as_i_think/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mhunt/is_our_dbt_project_as_bad_as_i_think/", "subreddit_subscribers": 121763, "created_utc": 1691593433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fwerb2uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Virtual Data Builds: A data warehouse environment for every Git commit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15mctop", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nR_BTR4yVxasfkKNa10X80MIwQ7aeeJ3Q6MG2-BSWBI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691581102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "y42.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.y42.com/blog/virtual-data-builds-one-data-warehouse-environment-for-every-git-commit/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?auto=webp&amp;s=dfe5baa7e55b0fdeafdd8e55ceea1f41e8bb2575", "width": 2160, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=220afd6e3120c0aad0c5a461d4b5772d0ab8243d", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d14cb37959937ca4fb686bd8de2b82c6fcf496e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2a51dfa134189b445a11664b6909846abde9a9a8", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8eac2eeda830983ca6b8fbf6f41969c9ea7a3259", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dc76ee53527828db8c839c838aaebe3675c5dc52", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a941f122abdb5a72cbe93bfb04a56e7bd369c808", "width": 1080, "height": 720}], "variants": {}, "id": "TE7uqwVe35pQ_NYMKSpfU5YX8jXz0cwr0p_FDEMXmYs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15mctop", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant-Guidance599", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mctop/virtual_data_builds_a_data_warehouse_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.y42.com/blog/virtual-data-builds-one-data-warehouse-environment-for-every-git-commit/", "subreddit_subscribers": 121763, "created_utc": 1691581102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I have been creating data entry apps to send data into a sql database using power apps but having the premium license for sql connections is expensive for my organization. Does anyone know about good, cheaper alternatives to power apps for data entry? Thanks.", "author_fullname": "t2_6j5e93w9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternatives to powerapps for data entry into sql", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15madgt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691573595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I have been creating data entry apps to send data into a sql database using power apps but having the premium license for sql connections is expensive for my organization. Does anyone know about good, cheaper alternatives to power apps for data entry? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15madgt", "is_robot_indexable": true, "report_reasons": null, "author": "arachnarus96", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15madgt/alternatives_to_powerapps_for_data_entry_into_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15madgt/alternatives_to_powerapps_for_data_entry_into_sql/", "subreddit_subscribers": 121763, "created_utc": 1691573595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve heard some people mention stipends for additional training and using that for O\u2019Reilly subscriptions etc. but how common is that or any support from your employer for professional development in general?", "author_fullname": "t2_71weyfry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it common for companies to not offer any professional development?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m4n11", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691554842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve heard some people mention stipends for additional training and using that for O\u2019Reilly subscriptions etc. but how common is that or any support from your employer for professional development in general?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m4n11", "is_robot_indexable": true, "report_reasons": null, "author": "DrunkenWhaler136", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m4n11/is_it_common_for_companies_to_not_offer_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m4n11/is_it_common_for_companies_to_not_offer_any/", "subreddit_subscribers": 121763, "created_utc": 1691554842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am leading an effort to build out a production ETL pipeline/data lake from scratch using AWS Glue and other AWS Technologies like Lake Formation, Event Bridge, Step Functions and more.\n\nI wanted to see if anyone here has experience with the development flow/productionized setup for AWS Glue and how to best manage it? I have already read [Build, Test and Deploy ETL solutions using AWS Glue and AWS CDK based CI/CD pipelines](https://aws.amazon.com/blogs/big-data/build-test-and-deploy-etl-solutions-using-aws-glue-and-aws-cdk-based-ci-cd-pipelines/) and [Deploy an AWS Glue job with an AWS CodePipeline CI/CD pipeline](https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/deploy-an-aws-glue-job-with-an-aws-codepipeline-ci-cd-pipeline.html) and several other documents and videos, but am still coming up a bit short in my head on how to best implement this.\n\nA few notes and background:\n\n* Using Github, CircleCI (though I would likely use CodePipeline for this), Terraform for infrastructure.\n* Plan to use combination of Python/PySpark and are even considering Ray as well.\n* Currently we only have one AWS Environment but would likely split this out into multi-environment setup as part of this effort\n* We know the AWS Glue UI sucks and would prefer to manage this code as much as possible locally using whatever dev tool the engineer wants to use and leverage [Interactive Sessions](https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions-chapter.html)\n* We need to have very strict control/access lockdown over production.\n\nDoes anyone have experience with a similar pipeline setup and any lessons learned or architecture notes on how this development flow should work?  Really just hoping to get a decent understanding of what might work, what hasn't worked or other issues.  \n\n\nEDIT:  \nThanks for the insights everyone! I also found [https://aws.amazon.com/blogs/big-data/end-to-end-development-lifecycle-for-data-engineers-to-build-a-data-integration-pipeline-using-aws-glue/](https://aws.amazon.com/blogs/big-data/end-to-end-development-lifecycle-for-data-engineers-to-build-a-data-integration-pipeline-using-aws-glue/) which is very helpful for answering some of my questions here.  If you are looking for insights similar to what I asked here, this guide is a helpful starting point.", "author_fullname": "t2_3tfgc8z0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing Infra/Development Flow for AWS Glue ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lno3v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691597933.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691513665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am leading an effort to build out a production ETL pipeline/data lake from scratch using AWS Glue and other AWS Technologies like Lake Formation, Event Bridge, Step Functions and more.&lt;/p&gt;\n\n&lt;p&gt;I wanted to see if anyone here has experience with the development flow/productionized setup for AWS Glue and how to best manage it? I have already read &lt;a href=\"https://aws.amazon.com/blogs/big-data/build-test-and-deploy-etl-solutions-using-aws-glue-and-aws-cdk-based-ci-cd-pipelines/\"&gt;Build, Test and Deploy ETL solutions using AWS Glue and AWS CDK based CI/CD pipelines&lt;/a&gt; and &lt;a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/deploy-an-aws-glue-job-with-an-aws-codepipeline-ci-cd-pipeline.html\"&gt;Deploy an AWS Glue job with an AWS CodePipeline CI/CD pipeline&lt;/a&gt; and several other documents and videos, but am still coming up a bit short in my head on how to best implement this.&lt;/p&gt;\n\n&lt;p&gt;A few notes and background:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Using Github, CircleCI (though I would likely use CodePipeline for this), Terraform for infrastructure.&lt;/li&gt;\n&lt;li&gt;Plan to use combination of Python/PySpark and are even considering Ray as well.&lt;/li&gt;\n&lt;li&gt;Currently we only have one AWS Environment but would likely split this out into multi-environment setup as part of this effort&lt;/li&gt;\n&lt;li&gt;We know the AWS Glue UI sucks and would prefer to manage this code as much as possible locally using whatever dev tool the engineer wants to use and leverage &lt;a href=\"https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions-chapter.html\"&gt;Interactive Sessions&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;We need to have very strict control/access lockdown over production.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Does anyone have experience with a similar pipeline setup and any lessons learned or architecture notes on how this development flow should work?  Really just hoping to get a decent understanding of what might work, what hasn&amp;#39;t worked or other issues.  &lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;br/&gt;\nThanks for the insights everyone! I also found &lt;a href=\"https://aws.amazon.com/blogs/big-data/end-to-end-development-lifecycle-for-data-engineers-to-build-a-data-integration-pipeline-using-aws-glue/\"&gt;https://aws.amazon.com/blogs/big-data/end-to-end-development-lifecycle-for-data-engineers-to-build-a-data-integration-pipeline-using-aws-glue/&lt;/a&gt; which is very helpful for answering some of my questions here.  If you are looking for insights similar to what I asked here, this guide is a helpful starting point.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4ZxzRJp1jP1gMb4u3e0wG_LPzHOVok0o0n--Gz5zqmM.jpg?auto=webp&amp;s=feff47f1fa2d86f99b2fcf8073a0e7ba8c072eb8", "width": 1531, "height": 762}, "resolutions": [{"url": "https://external-preview.redd.it/4ZxzRJp1jP1gMb4u3e0wG_LPzHOVok0o0n--Gz5zqmM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7b1931ed0019774fb23e932237c4b16ccb1067c2", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/4ZxzRJp1jP1gMb4u3e0wG_LPzHOVok0o0n--Gz5zqmM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=27f225beb6e17db7d7aded7aaba9d7a69578e262", "width": 216, "height": 107}, {"url": "https://external-preview.redd.it/4ZxzRJp1jP1gMb4u3e0wG_LPzHOVok0o0n--Gz5zqmM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf49a960f55c67a01f91477b8984d853db422e00", "width": 320, "height": 159}, {"url": "https://external-preview.redd.it/4ZxzRJp1jP1gMb4u3e0wG_LPzHOVok0o0n--Gz5zqmM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff20908db4fcfefd35be0b45769d5f45b29d1960", "width": 640, "height": 318}, {"url": "https://external-preview.redd.it/4ZxzRJp1jP1gMb4u3e0wG_LPzHOVok0o0n--Gz5zqmM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5d0d996a19f18d8d910336943c8e172ebb04a3d6", "width": 960, "height": 477}, {"url": "https://external-preview.redd.it/4ZxzRJp1jP1gMb4u3e0wG_LPzHOVok0o0n--Gz5zqmM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9125b43eb58f7a3dcc2273d49399390f3d58ea13", "width": 1080, "height": 537}], "variants": {}, "id": "tHY1arVm9sYD07dyc9BYNXnUV0AEYo6O7xjTjUOAu0o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15lno3v", "is_robot_indexable": true, "report_reasons": null, "author": "deepeyesmusic", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lno3v/managing_infradevelopment_flow_for_aws_glue_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lno3v/managing_infradevelopment_flow_for_aws_glue_etl/", "subreddit_subscribers": 121763, "created_utc": 1691513665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So we have a pretty standard IoT setup, with sensor data being stored on Timescale. We pull that data from a third party API, that only reports data for sensors when there's a change in value. \n\nOur operations require consistent 5-minute buckets. We achieve this by using Timescale 's bucketing together with carrying forward the last observation. \n\nThis breaks down however when there is an outage, as in that case we don't want to forward fill but instead not have any buckets at all. \n\nIt seems like it would be a common problem to have, how would you deal with this?", "author_fullname": "t2_mui57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you deal with missing data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m7opg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691564595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we have a pretty standard IoT setup, with sensor data being stored on Timescale. We pull that data from a third party API, that only reports data for sensors when there&amp;#39;s a change in value. &lt;/p&gt;\n\n&lt;p&gt;Our operations require consistent 5-minute buckets. We achieve this by using Timescale &amp;#39;s bucketing together with carrying forward the last observation. &lt;/p&gt;\n\n&lt;p&gt;This breaks down however when there is an outage, as in that case we don&amp;#39;t want to forward fill but instead not have any buckets at all. &lt;/p&gt;\n\n&lt;p&gt;It seems like it would be a common problem to have, how would you deal with this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m7opg", "is_robot_indexable": true, "report_reasons": null, "author": "georgesdoe", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m7opg/how_do_you_deal_with_missing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m7opg/how_do_you_deal_with_missing_data/", "subreddit_subscribers": 121763, "created_utc": 1691564595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are considering a code assistance tool (co-pilot) for our team but are not sure if it will help us as claimed. We use notebooks and wondering if anyone has any experience with these kinds of tools. ", "author_fullname": "t2_dogbygvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your experience with code assistant (co-pilot)? What are the challenges?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m57ur", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691556625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are considering a code assistance tool (co-pilot) for our team but are not sure if it will help us as claimed. We use notebooks and wondering if anyone has any experience with these kinds of tools. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m57ur", "is_robot_indexable": true, "report_reasons": null, "author": "vinayak_singh_k", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m57ur/what_is_your_experience_with_code_assistant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m57ur/what_is_your_experience_with_code_assistant/", "subreddit_subscribers": 121763, "created_utc": 1691556625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is anyone using Unity to govern Iceberg tables?", "author_fullname": "t2_s3lpw2dx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Unity catalog on Iceberg", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m4es7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691554154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is anyone using Unity to govern Iceberg tables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m4es7", "is_robot_indexable": true, "report_reasons": null, "author": "nelsonbigetti", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m4es7/using_unity_catalog_on_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m4es7/using_unity_catalog_on_iceberg/", "subreddit_subscribers": 121763, "created_utc": 1691554154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We use DBT for data transformation. So far we have used Github actions for CICD for model development. We then run the production models in Argo.\n\nWhile Argo has been an okay platform, it is impossible to run models on demand, the lack of data engineers who have extensive Argo experience to maintain and simplify the platform for non-technical users has forced us to consider alternative orchestrators. Besides airflow, one of the orchestrators is Github Actions which we are already using to test PRs before merging with the main branch. It would be an excellent option, but GitHub Actions seem designed for pre-production tasks but I still cannot prove why we should not use it for production dbt run. So I ask, why would you consider GitHub Actions as an orchestrator to run production DBT commands?", "author_fullname": "t2_98970a3e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "would you consider GitHub Actions as an orchestrator to run production DBT commands?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15maawi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691573374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We use DBT for data transformation. So far we have used Github actions for CICD for model development. We then run the production models in Argo.&lt;/p&gt;\n\n&lt;p&gt;While Argo has been an okay platform, it is impossible to run models on demand, the lack of data engineers who have extensive Argo experience to maintain and simplify the platform for non-technical users has forced us to consider alternative orchestrators. Besides airflow, one of the orchestrators is Github Actions which we are already using to test PRs before merging with the main branch. It would be an excellent option, but GitHub Actions seem designed for pre-production tasks but I still cannot prove why we should not use it for production dbt run. So I ask, why would you consider GitHub Actions as an orchestrator to run production DBT commands?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15maawi", "is_robot_indexable": true, "report_reasons": null, "author": "South-Blacksmith-949", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15maawi/would_you_consider_github_actions_as_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15maawi/would_you_consider_github_actions_as_an/", "subreddit_subscribers": 121763, "created_utc": 1691573374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI will be on holiday from 9 to 30 of August in Columbus.\nI'm not from US, so it's my first time there !\nDo you know some meetups / aperitivo's to meet people working in Data Roles / IT or hackathons for data Analysts ?\n\nI would be happy to connect for a drink for anyone interested.", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE / DS / Data Meetups in Ohio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m7iie", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691564049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI will be on holiday from 9 to 30 of August in Columbus.\nI&amp;#39;m not from US, so it&amp;#39;s my first time there !\nDo you know some meetups / aperitivo&amp;#39;s to meet people working in Data Roles / IT or hackathons for data Analysts ?&lt;/p&gt;\n\n&lt;p&gt;I would be happy to connect for a drink for anyone interested.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15m7iie", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m7iie/de_ds_data_meetups_in_ohio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m7iie/de_ds_data_meetups_in_ohio/", "subreddit_subscribers": 121763, "created_utc": 1691564049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bhpulfr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leveraging web scraping data for dynamic pricing strategies in e-commerce", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15luq4n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VjgsxlUrG_pazdMae9QTaG3YPpHbR-3d57bl2qb9ayA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691529445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "javascript.plainenglish.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://javascript.plainenglish.io/leveraging-web-scraping-for-dynamic-pricing-strategies-for-e-commerce-dba4f813d1e", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?auto=webp&amp;s=f4ce28f571fb0cda3c7f2a661f6a3a2923e958b1", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2dda5e47ff2d4989e9856e206d954dfaf65b8c0f", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1cf81ef3c5ad9c1a4e9385b9dcbb7742055de86", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1caf31760c4778a0c4d62c34a5e18f563cd9d590", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1afcf08ca6054e094c8f2564df66d7f2a49e2ede", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c33c3b8266fb8c296613837facffe25506fa98ec", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=16922483d1cc749069eaa5a42e615896a563008a", "width": 1080, "height": 720}], "variants": {}, "id": "BSFNvAYgJyuJNwJHWBMIOMxmpmFKInElIaXDQoYBMDQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15luq4n", "is_robot_indexable": true, "report_reasons": null, "author": "9millionrainydays_91", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15luq4n/leveraging_web_scraping_data_for_dynamic_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://javascript.plainenglish.io/leveraging-web-scraping-for-dynamic-pricing-strategies-for-e-commerce-dba4f813d1e", "subreddit_subscribers": 121763, "created_utc": 1691529445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How does community identifies if a requirement coming from business is an analytical or transactional ie to be run against an OLTP database or OLAP database.\n\nSecond question is that what is the best way to make business understand that business requirement is served best with right nature of data modeling within a database or tool.\n\nFor example, we have postgresql as OLTP database for our app and ClickHouse as OLAP engine however a requirement is/should not be running against its indifferent database/tool.", "author_fullname": "t2_3fc3u012", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Identify if a business requirement is an analytical or transactional in its technical nature within data warehouse/datalake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mfrwr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691588701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How does community identifies if a requirement coming from business is an analytical or transactional ie to be run against an OLTP database or OLAP database.&lt;/p&gt;\n\n&lt;p&gt;Second question is that what is the best way to make business understand that business requirement is served best with right nature of data modeling within a database or tool.&lt;/p&gt;\n\n&lt;p&gt;For example, we have postgresql as OLTP database for our app and ClickHouse as OLAP engine however a requirement is/should not be running against its indifferent database/tool.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mfrwr", "is_robot_indexable": true, "report_reasons": null, "author": "youareafakenews", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mfrwr/identify_if_a_business_requirement_is_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mfrwr/identify_if_a_business_requirement_is_an/", "subreddit_subscribers": 121763, "created_utc": 1691588701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9k0sxzns1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use Pyo3 to build my first rust app with python binding", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15mebov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Pnc_aqRqNPlPm6MdUHCWiIRfjVrUqiS5H-XrYwXzHPg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691585170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/hkpeaks/pypeaks/tree/main", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?auto=webp&amp;s=7b0c87123c08733216896d673deaddc4e11e264d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cdac72e22e82bdd8ad97b5fb67ab4365ee970362", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a81c143d718186d915b3f49e964b48df132bd6f8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=143ef35cc695738a40645c5e68cbf89202f8a3fd", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9868a6857844a61bf6964cc06403eaace531a082", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0770c58302b234d263e054f40710f38745fd7977", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0ac52e2c770d89d026272478960b8d4a33062efc", "width": 1080, "height": 540}], "variants": {}, "id": "ireCSNiGeP5e7QYWH35eQ5_Ey3lAZ2TCtqaDhLhtyFY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15mebov", "is_robot_indexable": true, "report_reasons": null, "author": "100GB-CSV", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mebov/use_pyo3_to_build_my_first_rust_app_with_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/hkpeaks/pypeaks/tree/main", "subreddit_subscribers": 121763, "created_utc": 1691585170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently, I have to manually generate a lot of documentation for data cataloguing and was wondering if there is a tool which can help to generate documentation from code. What's your experience with documentation?", "author_fullname": "t2_dogbygvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tool do you use to generate documentation from your code? Have you figured out a better way to handle documentation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m6eda", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691560353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, I have to manually generate a lot of documentation for data cataloguing and was wondering if there is a tool which can help to generate documentation from code. What&amp;#39;s your experience with documentation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15m6eda", "is_robot_indexable": true, "report_reasons": null, "author": "vinayak_singh_k", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m6eda/what_tool_do_you_use_to_generate_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m6eda/what_tool_do_you_use_to_generate_documentation/", "subreddit_subscribers": 121763, "created_utc": 1691560353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello house, \n\nLet me start like this I currently work as a senior data analyst for my company and I have experience in data science with different project and research paper.\n\nI have always wanted to pivot to data engineering for a while now, taken multiple certifications on Azure and other resources.\n\nI got a job as a data engineer in an oil and gas company. I cleared all the exams(3) and interviews (2) with flying colors.\n\nI had a deep knowledge in all what data engineering is all about, the only issue is I have never worked as a data engineer \ud83d\udc68\ud83c\udffd\u200d\ud83d\udcbb much is expected from me with the high level I performed but I feel like this was because I have verse experience in data analysis and consulting which helped me.\n\nI primary use Azure DataBricks and ADF cloud, delta lake table(unity catalog) for warehouse and ADLG2 staging storage.\n\nSSIS, SSRS, SSAS and SSMS for private and local.\n\nPower BI &amp; Datamarts for visualization.\n\nIs this enough or is there something more to data engineering, I might sound silly but I feel there expectation of me is really high.\n\nLet me add I also work as a data engineer in a publishing company in the US as an author/writer.", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imposter Syndrome", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ln3gv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691512572.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691512333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello house, &lt;/p&gt;\n\n&lt;p&gt;Let me start like this I currently work as a senior data analyst for my company and I have experience in data science with different project and research paper.&lt;/p&gt;\n\n&lt;p&gt;I have always wanted to pivot to data engineering for a while now, taken multiple certifications on Azure and other resources.&lt;/p&gt;\n\n&lt;p&gt;I got a job as a data engineer in an oil and gas company. I cleared all the exams(3) and interviews (2) with flying colors.&lt;/p&gt;\n\n&lt;p&gt;I had a deep knowledge in all what data engineering is all about, the only issue is I have never worked as a data engineer \ud83d\udc68\ud83c\udffd\u200d\ud83d\udcbb much is expected from me with the high level I performed but I feel like this was because I have verse experience in data analysis and consulting which helped me.&lt;/p&gt;\n\n&lt;p&gt;I primary use Azure DataBricks and ADF cloud, delta lake table(unity catalog) for warehouse and ADLG2 staging storage.&lt;/p&gt;\n\n&lt;p&gt;SSIS, SSRS, SSAS and SSMS for private and local.&lt;/p&gt;\n\n&lt;p&gt;Power BI &amp;amp; Datamarts for visualization.&lt;/p&gt;\n\n&lt;p&gt;Is this enough or is there something more to data engineering, I might sound silly but I feel there expectation of me is really high.&lt;/p&gt;\n\n&lt;p&gt;Let me add I also work as a data engineer in a publishing company in the US as an author/writer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ln3gv", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ln3gv/imposter_syndrome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ln3gv/imposter_syndrome/", "subreddit_subscribers": 121763, "created_utc": 1691512333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone tried out the new m7i EC2 instances yet?\n\nWe ran the Dask benchmark suite comparing m6i.large to m7i.large nodes and the total runtime went down by \\~12% (so enough to justify the 5% increase in on-demand price). Image below for [test\\_dot\\_product\\_spill](https://github.com/coiled/benchmarks/blob/b07e7bb397fa0936883feca7981362bf52d34e7c/tests/benchmarks/test_spill.py#L65).\n\nBut... there's a much larger spot discount on older m6i.large instances, so total cost is still lower using m6i instances. Currently m7i.large spot instances are  &gt;25% more expensive than m6i.large spot. Alas.\n\nCurious to hear if others found something similar.\n\n[Final points in the plot are for the run with m7i.large](https://preview.redd.it/ub3x3jw1uwgb1.png?width=791&amp;format=png&amp;auto=webp&amp;s=0f70197d1ccbff8451728f919a7a3750f5353d89)", "author_fullname": "t2_w7crvjmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New m7i speculation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 49, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ub3x3jw1uwgb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3af89c86d860efb04b79924a71e9db35666698a5"}, {"y": 76, "x": 216, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d172dbe1cfa2465feba9d3b03990a5203cf2f70b"}, {"y": 113, "x": 320, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ff214a23693712170463a75c97fbce93b619692f"}, {"y": 227, "x": 640, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d4bf4eb4b65fba456938bf330920bda70635b855"}], "s": {"y": 281, "x": 791, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=791&amp;format=png&amp;auto=webp&amp;s=0f70197d1ccbff8451728f919a7a3750f5353d89"}, "id": "ub3x3jw1uwgb1"}}, "name": "t3_15lmjda", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/fAX1Z9Xze2JiLhqO8oS3kCTrS_dt2DRlAWD6xOI6oi4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691511057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone tried out the new m7i EC2 instances yet?&lt;/p&gt;\n\n&lt;p&gt;We ran the Dask benchmark suite comparing m6i.large to m7i.large nodes and the total runtime went down by ~12% (so enough to justify the 5% increase in on-demand price). Image below for &lt;a href=\"https://github.com/coiled/benchmarks/blob/b07e7bb397fa0936883feca7981362bf52d34e7c/tests/benchmarks/test_spill.py#L65\"&gt;test_dot_product_spill&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;But... there&amp;#39;s a much larger spot discount on older m6i.large instances, so total cost is still lower using m6i instances. Currently m7i.large spot instances are  &amp;gt;25% more expensive than m6i.large spot. Alas.&lt;/p&gt;\n\n&lt;p&gt;Curious to hear if others found something similar.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ub3x3jw1uwgb1.png?width=791&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0f70197d1ccbff8451728f919a7a3750f5353d89\"&gt;Final points in the plot are for the run with m7i.large&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15lmjda", "is_robot_indexable": true, "report_reasons": null, "author": "dask-jeeves", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lmjda/new_m7i_speculation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lmjda/new_m7i_speculation/", "subreddit_subscribers": 121763, "created_utc": 1691511057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am 17 and an intern at a finch company in England, I have been given a task to create a 'slack watchdog' in which messages for help to a slack channel will be monitored and if no response within an hour an automatic reply will tag a member of the appropriate response team asking them to take a look at the message. Is it possible for any of you to give me a brief overview of how I would do this and/or point me in the direction of some useful things to search (detailed things for search). \n\nThe tools I am using are Airflow and VSCode in python, as in my actual task is to create a DAG which sends these automatic assignment responses.\n\nAny help greatly appreciated!", "author_fullname": "t2_eqvikdnq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overview of how to tackle project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15mirqn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691595550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am 17 and an intern at a finch company in England, I have been given a task to create a &amp;#39;slack watchdog&amp;#39; in which messages for help to a slack channel will be monitored and if no response within an hour an automatic reply will tag a member of the appropriate response team asking them to take a look at the message. Is it possible for any of you to give me a brief overview of how I would do this and/or point me in the direction of some useful things to search (detailed things for search). &lt;/p&gt;\n\n&lt;p&gt;The tools I am using are Airflow and VSCode in python, as in my actual task is to create a DAG which sends these automatic assignment responses.&lt;/p&gt;\n\n&lt;p&gt;Any help greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mirqn", "is_robot_indexable": true, "report_reasons": null, "author": "McSteamy06", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mirqn/overview_of_how_to_tackle_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mirqn/overview_of_how_to_tackle_project/", "subreddit_subscribers": 121763, "created_utc": 1691595550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have some dags that fail constantly but recover like an hour later and no data is lost. I am told to ignore this and everything is fine but my gut is telling me this is not the right way to do this...\n\nAm I just being a stickler / don't know what I am talking about or is there something wrong with how we are using airflow and I just don't know how to articulate the problem properly.", "author_fullname": "t2_1sopch0e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intermitten Dag Failure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15mhdlx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691592372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have some dags that fail constantly but recover like an hour later and no data is lost. I am told to ignore this and everything is fine but my gut is telling me this is not the right way to do this...&lt;/p&gt;\n\n&lt;p&gt;Am I just being a stickler / don&amp;#39;t know what I am talking about or is there something wrong with how we are using airflow and I just don&amp;#39;t know how to articulate the problem properly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mhdlx", "is_robot_indexable": true, "report_reasons": null, "author": "richphi1618", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mhdlx/intermitten_dag_failure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mhdlx/intermitten_dag_failure/", "subreddit_subscribers": 121763, "created_utc": 1691592372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vx67of8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ultimate dbt Cheat Sheet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15mfqhr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BmZfuPSMpmqPfBK7jVJy46GPbMOEEFEJ9hHM_wRgggk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691588601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datacoves.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://datacoves.com/post/dbt-cheatsheet", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?auto=webp&amp;s=877a8990290912f27a3e8fe27fff96f255bd9585", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77fde2d67be961affcbcc1dbedcee7598f0bd58e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=60df194bcaf3fcf84d4c60322752d92b096ccca3", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2bfa708d8ceebc172620fe49d04ba92f0eeb8f0", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d7caf3fb816aa85080b86ed1a7c9e96cb405a5b", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7201f30b7b60df4c14725cd45646e2fbfab2a8aa", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=97adbe1a5fe1ac04f88e5356202fd6eb9cdccbd5", "width": 1080, "height": 564}], "variants": {}, "id": "_rzD2Rrp77lU7pyoKi6-K0j0h-KIeL9rC__uODDWLuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15mfqhr", "is_robot_indexable": true, "report_reasons": null, "author": "Hot_Map_7868", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mfqhr/ultimate_dbt_cheat_sheet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://datacoves.com/post/dbt-cheatsheet", "subreddit_subscribers": 121763, "created_utc": 1691588601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just did a test with this platform but never heard about it before. Looking to hear about your experience with it", "author_fullname": "t2_729lk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone used Toggl hire before?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15me50n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691584693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just did a test with this platform but never heard about it before. Looking to hear about your experience with it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15me50n", "is_robot_indexable": true, "report_reasons": null, "author": "riclex", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15me50n/anyone_used_toggl_hire_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15me50n/anyone_used_toggl_hire_before/", "subreddit_subscribers": 121763, "created_utc": 1691584693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a  project (a POC, for interviews and to show my GCP skills, for my own git) to calculate the CO2 emissions for individuals based on their use of transportation. And i'm designing the following architecture as it's my first GCP project, I thought that maybe some feedback will help).   \n\n\n\\- Offer : i got the 12 months free offer with 300$ credit\n\n\\- Data Ingestion to Google Cloud Storage :   \nI created a bucket (standard offer) on GCS to consolidate raw data (CO2 consumption data + master data ) from different sources. The C02 data will be fetched by API calls to Google Timeline API  (Cloud function) and stored without transformation to GCS. The master data is just uploaded to GCS for now (not automated as it's a one time ingestion)  \nThe cloud function are lunched by google cloud scheduler for daily uploads. Each call is gathering transportation data for my sample individuals (30 individuals for now) and will consolidate the data for all the users in one JSON file to store on GCP (the return of the api calls is JSON, but idk if i can store it maybe as AVRO or PARQUET for better performances ? also I thought about consolidating the data in one file to not have several files that might slow the DF perfromances afterwards ? what do you think ? )    \n\n\n\\- Data Transformation  \nBased on the bucket's data updated, a Dataflow is lunched to transform the user's data and enrich it with master data and CO2 emissions calculation (basic joins and  map operations)   \nWe have other data flows for master data loading that are lunched as well when new master data files are available ( 1 DF for each dimension table )   \n\n\n\\- Data Load  \nThe data after transformation will be loaded to big query (one fact table , main KPI is CO2 emissions and Dimensions tables : Time, User Information, Geographical information ... etc.)   \n\n\nTables are partitionned by time and clustered by Geographical information / User information (as it'll be used in the queries)   \n\n\nMaterialized tables for TOP C02 Emission per User/Region are available to reduce shuffling and not recalclulate that each time   \n\n\n\\- Data Viz  \nData viz using google data studio for CO2 emissions trends per user/region...etc.  \nand also top CO2 emissions and bottom CO2 emissions   \n\n\nAny views or critics are welcomed as it's my first project on GCP.   \n\n\nMany thanks by advance. ", "author_fullname": "t2_4kn0fb0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First Project on GCP - Feedback on architecture needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mbjf9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691577268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a  project (a POC, for interviews and to show my GCP skills, for my own git) to calculate the CO2 emissions for individuals based on their use of transportation. And i&amp;#39;m designing the following architecture as it&amp;#39;s my first GCP project, I thought that maybe some feedback will help).   &lt;/p&gt;\n\n&lt;p&gt;- Offer : i got the 12 months free offer with 300$ credit&lt;/p&gt;\n\n&lt;p&gt;- Data Ingestion to Google Cloud Storage :&lt;br/&gt;\nI created a bucket (standard offer) on GCS to consolidate raw data (CO2 consumption data + master data ) from different sources. The C02 data will be fetched by API calls to Google Timeline API  (Cloud function) and stored without transformation to GCS. The master data is just uploaded to GCS for now (not automated as it&amp;#39;s a one time ingestion)&lt;br/&gt;\nThe cloud function are lunched by google cloud scheduler for daily uploads. Each call is gathering transportation data for my sample individuals (30 individuals for now) and will consolidate the data for all the users in one JSON file to store on GCP (the return of the api calls is JSON, but idk if i can store it maybe as AVRO or PARQUET for better performances ? also I thought about consolidating the data in one file to not have several files that might slow the DF perfromances afterwards ? what do you think ? )    &lt;/p&gt;\n\n&lt;p&gt;- Data Transformation&lt;br/&gt;\nBased on the bucket&amp;#39;s data updated, a Dataflow is lunched to transform the user&amp;#39;s data and enrich it with master data and CO2 emissions calculation (basic joins and  map operations)&lt;br/&gt;\nWe have other data flows for master data loading that are lunched as well when new master data files are available ( 1 DF for each dimension table )   &lt;/p&gt;\n\n&lt;p&gt;- Data Load&lt;br/&gt;\nThe data after transformation will be loaded to big query (one fact table , main KPI is CO2 emissions and Dimensions tables : Time, User Information, Geographical information ... etc.)   &lt;/p&gt;\n\n&lt;p&gt;Tables are partitionned by time and clustered by Geographical information / User information (as it&amp;#39;ll be used in the queries)   &lt;/p&gt;\n\n&lt;p&gt;Materialized tables for TOP C02 Emission per User/Region are available to reduce shuffling and not recalclulate that each time   &lt;/p&gt;\n\n&lt;p&gt;- Data Viz&lt;br/&gt;\nData viz using google data studio for CO2 emissions trends per user/region...etc.&lt;br/&gt;\nand also top CO2 emissions and bottom CO2 emissions   &lt;/p&gt;\n\n&lt;p&gt;Any views or critics are welcomed as it&amp;#39;s my first project on GCP.   &lt;/p&gt;\n\n&lt;p&gt;Many thanks by advance. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mbjf9", "is_robot_indexable": true, "report_reasons": null, "author": "Ezzarrass", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mbjf9/first_project_on_gcp_feedback_on_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mbjf9/first_project_on_gcp_feedback_on_architecture/", "subreddit_subscribers": 121763, "created_utc": 1691577268.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}