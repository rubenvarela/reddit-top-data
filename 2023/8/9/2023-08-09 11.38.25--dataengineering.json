{"kind": "Listing", "data": {"after": "t3_15lrfuw", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**My background:**\n\nCurrently I'm a senior data analyst, and I'm one of those people that works in the department where the data analyst does just about everything. I do ETL, reporting, bi stuff so piping data from Google BigQuery into stuff like Power BI, looker studio, AWS, snowflake, using Python of course. I spend more time typing in SQL than I do in English in emails. I find myself doing recreational projects with Python and SQL quite often, for example this week I wrote in API that retrieves data from Kaggle, cleans it in pandas, loads it into BigQuery, also loads it into snowflake, Cassandra, Then using even more Python, retrieves some of the data using SQL. \n\n\n**Question:**\n\nHow do I know if I'm ready for a data engineer position? Will I ever be ready? I was contacted buy a recruiter for a couple positions. The one I applied to is data analyst, but I asked about the data engineer position because the job description said almost nothing about it. She said it was a little bit more technical than what I've probably done, preceded to list off basically everything I've already been doing. Said I have to be comfortable doing object-oriented programming in Python (didn't know they used objects in data engineering). Said that it's a lot more of the piping data, working in AWS data sources, snowflake, Hadoop, etc... This is all stuff that sounds insanely complex and technical but here's the thing.... **How do I know if this is stuff that I'm capable of learning on the job or doing?** Like no, of course I haven't set up a data source from scratch with 300 million rows or a terabyte of data myself. I can't just go and make a 300 million row data set on my PC at home. No matter how much I want to, It would be next to impossible for me to simulate the work that a data engineer actually does on the job in a personal setting. Because any work I do as a data engineer will be in a live environment for a big company with important deadlines and I don't have that right now.", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Honest question: How do I know if I'm good enough to be a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lr89o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691521667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;My background:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m a senior data analyst, and I&amp;#39;m one of those people that works in the department where the data analyst does just about everything. I do ETL, reporting, bi stuff so piping data from Google BigQuery into stuff like Power BI, looker studio, AWS, snowflake, using Python of course. I spend more time typing in SQL than I do in English in emails. I find myself doing recreational projects with Python and SQL quite often, for example this week I wrote in API that retrieves data from Kaggle, cleans it in pandas, loads it into BigQuery, also loads it into snowflake, Cassandra, Then using even more Python, retrieves some of the data using SQL. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;How do I know if I&amp;#39;m ready for a data engineer position? Will I ever be ready? I was contacted buy a recruiter for a couple positions. The one I applied to is data analyst, but I asked about the data engineer position because the job description said almost nothing about it. She said it was a little bit more technical than what I&amp;#39;ve probably done, preceded to list off basically everything I&amp;#39;ve already been doing. Said I have to be comfortable doing object-oriented programming in Python (didn&amp;#39;t know they used objects in data engineering). Said that it&amp;#39;s a lot more of the piping data, working in AWS data sources, snowflake, Hadoop, etc... This is all stuff that sounds insanely complex and technical but here&amp;#39;s the thing.... &lt;strong&gt;How do I know if this is stuff that I&amp;#39;m capable of learning on the job or doing?&lt;/strong&gt; Like no, of course I haven&amp;#39;t set up a data source from scratch with 300 million rows or a terabyte of data myself. I can&amp;#39;t just go and make a 300 million row data set on my PC at home. No matter how much I want to, It would be next to impossible for me to simulate the work that a data engineer actually does on the job in a personal setting. Because any work I do as a data engineer will be in a live environment for a big company with important deadlines and I don&amp;#39;t have that right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15lr89o", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lr89o/honest_question_how_do_i_know_if_im_good_enough/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lr89o/honest_question_how_do_i_know_if_im_good_enough/", "subreddit_subscribers": 121710, "created_utc": 1691521667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a full time job I\u2019m happy with. But because I\u2019m a capitalist I want to make more money. I also don\u2019t want to deal with the constrains another job or 1099 gig has, I want to be my own boss. \n\nI\u2019m considering doing freelance via upwork or similar. I have about 5 years experience with python and sql and various tools like snowflake and airflow. I think lower effort clients like webscraping or maybe even no code tools could be a good start. \n\nAnyone else do this? Is it super hard to start?", "author_fullname": "t2_1kset4fg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone Freelance on the Side?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15loaaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691515080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a full time job I\u2019m happy with. But because I\u2019m a capitalist I want to make more money. I also don\u2019t want to deal with the constrains another job or 1099 gig has, I want to be my own boss. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m considering doing freelance via upwork or similar. I have about 5 years experience with python and sql and various tools like snowflake and airflow. I think lower effort clients like webscraping or maybe even no code tools could be a good start. &lt;/p&gt;\n\n&lt;p&gt;Anyone else do this? Is it super hard to start?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15loaaj", "is_robot_indexable": true, "report_reasons": null, "author": "shittyfuckdick", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15loaaj/anyone_freelance_on_the_side/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15loaaj/anyone_freelance_on_the_side/", "subreddit_subscribers": 121710, "created_utc": 1691515080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Consultants have forced on us a truly terrible data model for our marketing warehouse. Tables and columns are named with inscrutable acronyms, there\u2019s no clarity on how entities relate to one another or map to business processes, and the idea of a meaningful table grain is but a dream (they like to make new tables by grouping by dozens of unrelated attributes).\n\nIt\u2019s a mess and the most infuriating part as an ETL engineer is that I can\u2019t get that across to the business side because whenever I say \u201cproper modeling standards\u201d they hear \u201cyou\u2019re going to make me wait longer for new reports\u201d. The only way I can think to prove how bad it is would be to redo the whole design myself to give them a side-by-side comparison, but that\u2019s months of work. And of course when the data quality goes to hell my team is the one that\u2019ll take the blame.\n\nAny suggestions or stories of similar situations?", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prove a data model is bad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ltzr9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691527832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Consultants have forced on us a truly terrible data model for our marketing warehouse. Tables and columns are named with inscrutable acronyms, there\u2019s no clarity on how entities relate to one another or map to business processes, and the idea of a meaningful table grain is but a dream (they like to make new tables by grouping by dozens of unrelated attributes).&lt;/p&gt;\n\n&lt;p&gt;It\u2019s a mess and the most infuriating part as an ETL engineer is that I can\u2019t get that across to the business side because whenever I say \u201cproper modeling standards\u201d they hear \u201cyou\u2019re going to make me wait longer for new reports\u201d. The only way I can think to prove how bad it is would be to redo the whole design myself to give them a side-by-side comparison, but that\u2019s months of work. And of course when the data quality goes to hell my team is the one that\u2019ll take the blame.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or stories of similar situations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ltzr9", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ltzr9/prove_a_data_model_is_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ltzr9/prove_a_data_model_is_bad/", "subreddit_subscribers": 121710, "created_utc": 1691527832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Chat with your data using Langchain, PineconeDB and Airbyte", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15lknol", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": "transparent", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Xe6peY4RU0yNowvzeXa31-60kkVOVBGZu-_8Jiea5eQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691506899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/tutorials/chat-with-your-data-using-openai-pinecone-airbyte-and-langchain", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?auto=webp&amp;s=52a690eb9017d31f55c72f17ac74e0347fa70b79", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a136427b5c95f1c32d43dabf92f1a2e74d78d91b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=eb85a8994c311bb57badb97ef96d0ef7fb941563", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4057bdf0af2ac9efbd906372a3de8c4ab64f9dcf", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bcd751162168d9362cfc5f4142b584cb50864946", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a75943c2b264d21299e79f96ebe798c1bb19d47b", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/tEnlRA2Oi9mKrEGgnGTBbexszmIoB3UTw05_mwDBBUk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=05be86c826c8270e6c09f23b0ca908e4a17e2363", "width": 1080, "height": 565}], "variants": {}, "id": "-Fru_wIX1XucCxZWM2v5cBU30Yg0UH4LNViVg8dqAN8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15lknol", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15lknol/chat_with_your_data_using_langchain_pineconedb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/tutorials/chat-with-your-data-using-openai-pinecone-airbyte-and-langchain", "subreddit_subscribers": 121710, "created_utc": 1691506899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, changed the company a few months ago and it seems like this one offers study days + full pay for workshops, certifications, online courses and so on.\n\nI\u2019m really looking to make good use of these opportunities, that\u2019s why I\u2019m looking for some workshop recommendations to develop myself as a data engineer. I am pretty interested in backend architecture for data systems(mostly related to Azure since that\u2019s what my company is using to host all their data architecture). \n\nBut If you guys know any other good data engineering workshops related to Data Engineering as a whole, please let me know.", "author_fullname": "t2_4lcvdsdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Online workshops for getting better at Data Engineering Backend/Datawarehouse architectures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m9ab4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691569983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, changed the company a few months ago and it seems like this one offers study days + full pay for workshops, certifications, online courses and so on.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m really looking to make good use of these opportunities, that\u2019s why I\u2019m looking for some workshop recommendations to develop myself as a data engineer. I am pretty interested in backend architecture for data systems(mostly related to Azure since that\u2019s what my company is using to host all their data architecture). &lt;/p&gt;\n\n&lt;p&gt;But If you guys know any other good data engineering workshops related to Data Engineering as a whole, please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m9ab4", "is_robot_indexable": true, "report_reasons": null, "author": "Emotional_Key", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m9ab4/online_workshops_for_getting_better_at_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m9ab4/online_workshops_for_getting_better_at_data/", "subreddit_subscribers": 121710, "created_utc": 1691569983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are considering a code assistance tool (co-pilot) for our team but are not sure if it will help us as claimed. We use notebooks and wondering if anyone has any experience with these kinds of tools. ", "author_fullname": "t2_dogbygvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your experience with code assistant (co-pilot)? What are the challenges?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m57ur", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691556625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are considering a code assistance tool (co-pilot) for our team but are not sure if it will help us as claimed. We use notebooks and wondering if anyone has any experience with these kinds of tools. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m57ur", "is_robot_indexable": true, "report_reasons": null, "author": "vinayak_singh_k", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m57ur/what_is_your_experience_with_code_assistant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m57ur/what_is_your_experience_with_code_assistant/", "subreddit_subscribers": 121710, "created_utc": 1691556625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve heard some people mention stipends for additional training and using that for O\u2019Reilly subscriptions etc. but how common is that or any support from your employer for professional development in general?", "author_fullname": "t2_71weyfry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it common for companies to not offer any professional development?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m4n11", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691554842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve heard some people mention stipends for additional training and using that for O\u2019Reilly subscriptions etc. but how common is that or any support from your employer for professional development in general?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m4n11", "is_robot_indexable": true, "report_reasons": null, "author": "DrunkenWhaler136", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m4n11/is_it_common_for_companies_to_not_offer_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m4n11/is_it_common_for_companies_to_not_offer_any/", "subreddit_subscribers": 121710, "created_utc": 1691554842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is anyone using Unity to govern Iceberg tables?", "author_fullname": "t2_s3lpw2dx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Unity catalog on Iceberg", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m4es7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691554154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is anyone using Unity to govern Iceberg tables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m4es7", "is_robot_indexable": true, "report_reasons": null, "author": "nelsonbigetti", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m4es7/using_unity_catalog_on_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m4es7/using_unity_catalog_on_iceberg/", "subreddit_subscribers": 121710, "created_utc": 1691554154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am leading an effort to build out a production ETL pipeline/data lake from scratch using AWS Glue and other AWS Technologies like Lake Formation, Event Bridge, Step Functions and more.\n\nI wanted to see if anyone here has experience with the development flow/productionized setup for AWS Glue and how to best manage it? I have already read [Build, Test and Deploy ETL solutions using AWS Glue and AWS CDK based CI/CD pipelines](https://aws.amazon.com/blogs/big-data/build-test-and-deploy-etl-solutions-using-aws-glue-and-aws-cdk-based-ci-cd-pipelines/) and [Deploy an AWS Glue job with an AWS CodePipeline CI/CD pipeline](https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/deploy-an-aws-glue-job-with-an-aws-codepipeline-ci-cd-pipeline.html) and several other documents and videos, but am still coming up a bit short in my head on how to best implement this.\n\nA few notes and background:  \n\n\n* Using Github, CircleCI (though I would likely use CodePipeline for this), Terraform for infrastructure.\n* Plan to use combination of Python/PySpark and are even considering Ray as well.\n* Currently we only have one AWS Environment but would likely split this out into multi-environment setup as part of this effort\n* We know the AWS Glue UI sucks and would prefer to manage this code as much as possible locally using whatever dev tool the engineer wants to use and leverage [Interactive Sessions](https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions-chapter.html)\n* We need to have very strict control/access lockdown over production.\n\nDoes anyone have experience with a similar pipeline setup and any lessons learned or architecture notes on how this development flow should work?  Really just hoping to get a decent understanding of what might work, what hasn't worked or other issues.", "author_fullname": "t2_3tfgc8z0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing Infra/Development Flow for AWS Glue ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lno3v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691513665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am leading an effort to build out a production ETL pipeline/data lake from scratch using AWS Glue and other AWS Technologies like Lake Formation, Event Bridge, Step Functions and more.&lt;/p&gt;\n\n&lt;p&gt;I wanted to see if anyone here has experience with the development flow/productionized setup for AWS Glue and how to best manage it? I have already read &lt;a href=\"https://aws.amazon.com/blogs/big-data/build-test-and-deploy-etl-solutions-using-aws-glue-and-aws-cdk-based-ci-cd-pipelines/\"&gt;Build, Test and Deploy ETL solutions using AWS Glue and AWS CDK based CI/CD pipelines&lt;/a&gt; and &lt;a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/deploy-an-aws-glue-job-with-an-aws-codepipeline-ci-cd-pipeline.html\"&gt;Deploy an AWS Glue job with an AWS CodePipeline CI/CD pipeline&lt;/a&gt; and several other documents and videos, but am still coming up a bit short in my head on how to best implement this.&lt;/p&gt;\n\n&lt;p&gt;A few notes and background:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Using Github, CircleCI (though I would likely use CodePipeline for this), Terraform for infrastructure.&lt;/li&gt;\n&lt;li&gt;Plan to use combination of Python/PySpark and are even considering Ray as well.&lt;/li&gt;\n&lt;li&gt;Currently we only have one AWS Environment but would likely split this out into multi-environment setup as part of this effort&lt;/li&gt;\n&lt;li&gt;We know the AWS Glue UI sucks and would prefer to manage this code as much as possible locally using whatever dev tool the engineer wants to use and leverage &lt;a href=\"https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions-chapter.html\"&gt;Interactive Sessions&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;We need to have very strict control/access lockdown over production.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Does anyone have experience with a similar pipeline setup and any lessons learned or architecture notes on how this development flow should work?  Really just hoping to get a decent understanding of what might work, what hasn&amp;#39;t worked or other issues.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15lno3v", "is_robot_indexable": true, "report_reasons": null, "author": "deepeyesmusic", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lno3v/managing_infradevelopment_flow_for_aws_glue_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lno3v/managing_infradevelopment_flow_for_aws_glue_etl/", "subreddit_subscribers": 121710, "created_utc": 1691513665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there!\n\nI'm super excited to release my most challenging video so far:  \nThe Data Retail Project! \n\nIt's a 1-hour video to create an end-to-end pipeline!\n\nIn this project, you will be working with a retail dataset to create an end-to-end pipeline that extracts and loads the data from GCS to BigQuery, runs data quality checks with Soda, models and transforms the data with dbt, until building a dashboard with Metabase!\n\nHere's what you will learn:  \n\u2705 Create a data pipeline with Airflow following best practices  \n\u2705 Set up your Airflow local environment with the Astro CLI  \n\u2705 Run data quality checks in your pipeline with Soda  \n\u2705 Integrate dbt and run your models with Comos  \n\u2705 Isolate your tasks to avoid dependency conflicts  \n\u2705 Upload a CSV file into Google Cloud Storage from Airflow  \n\u2705 Ingest data into a BigQuery table using the Astro SDK  \n\u2705 Build a dashboard with Metabase on your data  \nand more!\n\nLink to the video: [https://youtu.be/DzxtCxi4YaA](https://youtu.be/DzxtCxi4YaA)\n\nAny feedback is much appreciated, hope you will find it useful \u2764\ufe0f  \nTake care", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Data Retail Project: Create an end-to-end pipeline with Airflow, dbt, Soda, BigQuery, and more", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ljgz6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691504174.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m super excited to release my most challenging video so far:&lt;br/&gt;\nThe Data Retail Project! &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s a 1-hour video to create an end-to-end pipeline!&lt;/p&gt;\n\n&lt;p&gt;In this project, you will be working with a retail dataset to create an end-to-end pipeline that extracts and loads the data from GCS to BigQuery, runs data quality checks with Soda, models and transforms the data with dbt, until building a dashboard with Metabase!&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what you will learn:&lt;br/&gt;\n\u2705 Create a data pipeline with Airflow following best practices&lt;br/&gt;\n\u2705 Set up your Airflow local environment with the Astro CLI&lt;br/&gt;\n\u2705 Run data quality checks in your pipeline with Soda&lt;br/&gt;\n\u2705 Integrate dbt and run your models with Comos&lt;br/&gt;\n\u2705 Isolate your tasks to avoid dependency conflicts&lt;br/&gt;\n\u2705 Upload a CSV file into Google Cloud Storage from Airflow&lt;br/&gt;\n\u2705 Ingest data into a BigQuery table using the Astro SDK&lt;br/&gt;\n\u2705 Build a dashboard with Metabase on your data&lt;br/&gt;\nand more!&lt;/p&gt;\n\n&lt;p&gt;Link to the video: &lt;a href=\"https://youtu.be/DzxtCxi4YaA\"&gt;https://youtu.be/DzxtCxi4YaA&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Any feedback is much appreciated, hope you will find it useful \u2764\ufe0f&lt;br/&gt;\nTake care&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/d50b5St1aMmRBp_EaWD7z6t9qCZ8aru9szBKG4SYnQg.jpg?auto=webp&amp;s=d471a7f6701b40333a59effc45f6db8427dee22a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/d50b5St1aMmRBp_EaWD7z6t9qCZ8aru9szBKG4SYnQg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e8af0a16fc901db703935ae708e9e1e8669b7a5e", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/d50b5St1aMmRBp_EaWD7z6t9qCZ8aru9szBKG4SYnQg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2eee7cd3c09da6a3a2182668068423f151b74b50", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/d50b5St1aMmRBp_EaWD7z6t9qCZ8aru9szBKG4SYnQg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a6beb426e10a4f5bdc5a3e1b1bc750925eccf319", "width": 320, "height": 240}], "variants": {}, "id": "SBtgWAZgDtTjP28yqZ1dn1RCBIiKsF3xR0d0IR8I0aw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ljgz6", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ljgz6/the_data_retail_project_create_an_endtoend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ljgz6/the_data_retail_project_create_an_endtoend/", "subreddit_subscribers": 121710, "created_utc": 1691504174.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bhpulfr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leveraging web scraping data for dynamic pricing strategies in e-commerce", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15luq4n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VjgsxlUrG_pazdMae9QTaG3YPpHbR-3d57bl2qb9ayA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691529445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "javascript.plainenglish.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://javascript.plainenglish.io/leveraging-web-scraping-for-dynamic-pricing-strategies-for-e-commerce-dba4f813d1e", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?auto=webp&amp;s=f4ce28f571fb0cda3c7f2a661f6a3a2923e958b1", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2dda5e47ff2d4989e9856e206d954dfaf65b8c0f", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1cf81ef3c5ad9c1a4e9385b9dcbb7742055de86", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1caf31760c4778a0c4d62c34a5e18f563cd9d590", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1afcf08ca6054e094c8f2564df66d7f2a49e2ede", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c33c3b8266fb8c296613837facffe25506fa98ec", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=16922483d1cc749069eaa5a42e615896a563008a", "width": 1080, "height": 720}], "variants": {}, "id": "BSFNvAYgJyuJNwJHWBMIOMxmpmFKInElIaXDQoYBMDQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15luq4n", "is_robot_indexable": true, "report_reasons": null, "author": "9millionrainydays_91", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15luq4n/leveraging_web_scraping_data_for_dynamic_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://javascript.plainenglish.io/leveraging-web-scraping-for-dynamic-pricing-strategies-for-e-commerce-dba4f813d1e", "subreddit_subscribers": 121710, "created_utc": 1691529445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've just started a new job where part of the job is some data engineering. I don't have any work experience in that, but I know what I want from an analysis/reporting perspective. My employer knows this, so I have time to figure things out.\n\nSince I have background in data analysis and reporting I'm pretty good with SQL and have some limited Python knowledge, but that is about it.\n\nThe data landscape is not very complex here, with only a couple of source applications that don't spit out that much data. Currently most of the data is dumped directly into BQ tables using Fivetran. After that there are some transformations to create tables that are used for analysis. However its basically a SCD1 solution, so its not possible to do historical analysis. At my previous job the date warehouse was in Oracle with SCD2 implemented. Since historical data is a must this is one of the things I want to fix, but its not clear to me what the best practice is for BigQuery specifically. Do I work towards an SCD2 implementation (I saw it used as an example use case for Dataform in the Google  documentation), or do I do something else (I saw a blogpost saying to snapshot all dimensional daily and put it in a partitioned table)? Either works for me from a data analysis perspective,  but what are your thoughts on this?", "author_fullname": "t2_19cg4j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle SCD in BigQuery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mag21", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691573853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just started a new job where part of the job is some data engineering. I don&amp;#39;t have any work experience in that, but I know what I want from an analysis/reporting perspective. My employer knows this, so I have time to figure things out.&lt;/p&gt;\n\n&lt;p&gt;Since I have background in data analysis and reporting I&amp;#39;m pretty good with SQL and have some limited Python knowledge, but that is about it.&lt;/p&gt;\n\n&lt;p&gt;The data landscape is not very complex here, with only a couple of source applications that don&amp;#39;t spit out that much data. Currently most of the data is dumped directly into BQ tables using Fivetran. After that there are some transformations to create tables that are used for analysis. However its basically a SCD1 solution, so its not possible to do historical analysis. At my previous job the date warehouse was in Oracle with SCD2 implemented. Since historical data is a must this is one of the things I want to fix, but its not clear to me what the best practice is for BigQuery specifically. Do I work towards an SCD2 implementation (I saw it used as an example use case for Dataform in the Google  documentation), or do I do something else (I saw a blogpost saying to snapshot all dimensional daily and put it in a partitioned table)? Either works for me from a data analysis perspective,  but what are your thoughts on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mag21", "is_robot_indexable": true, "report_reasons": null, "author": "KoeiNL", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mag21/how_to_handle_scd_in_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mag21/how_to_handle_scd_in_bigquery/", "subreddit_subscribers": 121710, "created_utc": 1691573853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I have been creating data entry apps to send data into a sql database using power apps but having the premium license for sql connections is expensive for my organization. Does anyone know about good, cheaper alternatives to power apps for data entry? Thanks.", "author_fullname": "t2_6j5e93w9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternatives to powerapps for data entry into sql", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15madgt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691573595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I have been creating data entry apps to send data into a sql database using power apps but having the premium license for sql connections is expensive for my organization. Does anyone know about good, cheaper alternatives to power apps for data entry? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15madgt", "is_robot_indexable": true, "report_reasons": null, "author": "arachnarus96", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15madgt/alternatives_to_powerapps_for_data_entry_into_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15madgt/alternatives_to_powerapps_for_data_entry_into_sql/", "subreddit_subscribers": 121710, "created_utc": 1691573595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We use DBT for data transformation. So far we have used Github actions for CICD for model development. We then run the production models in Argo.\n\nWhile Argo has been an okay platform, it is impossible to run models on demand, the lack of data engineers who have extensive Argo experience to maintain and simplify the platform for non-technical users has forced us to consider alternative orchestrators. Besides airflow, one of the orchestrators is Github Actions which we are already using to test PRs before merging with the main branch. It would be an excellent option, but GitHub Actions seem designed for pre-production tasks but I still cannot prove why we should not use it for production dbt run. So I ask, why would you consider GitHub Actions as an orchestrator to run production DBT commands?", "author_fullname": "t2_98970a3e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "would you consider GitHub Actions as an orchestrator to run production DBT commands?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15maawi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691573374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We use DBT for data transformation. So far we have used Github actions for CICD for model development. We then run the production models in Argo.&lt;/p&gt;\n\n&lt;p&gt;While Argo has been an okay platform, it is impossible to run models on demand, the lack of data engineers who have extensive Argo experience to maintain and simplify the platform for non-technical users has forced us to consider alternative orchestrators. Besides airflow, one of the orchestrators is Github Actions which we are already using to test PRs before merging with the main branch. It would be an excellent option, but GitHub Actions seem designed for pre-production tasks but I still cannot prove why we should not use it for production dbt run. So I ask, why would you consider GitHub Actions as an orchestrator to run production DBT commands?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15maawi", "is_robot_indexable": true, "report_reasons": null, "author": "South-Blacksmith-949", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15maawi/would_you_consider_github_actions_as_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15maawi/would_you_consider_github_actions_as_an/", "subreddit_subscribers": 121710, "created_utc": 1691573374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So we have a pretty standard IoT setup, with sensor data being stored on Timescale. We pull that data from a third party API, that only reports data for sensors when there's a change in value. \n\nOur operations require consistent 5-minute buckets. We achieve this by using Timescale 's bucketing together with carrying forward the last observation. \n\nThis breaks down however when there is an outage, as in that case we don't want to forward fill but instead not have any buckets at all. \n\nIt seems like it would be a common problem to have, how would you deal with this?", "author_fullname": "t2_mui57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you deal with missing data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m7opg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691564595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we have a pretty standard IoT setup, with sensor data being stored on Timescale. We pull that data from a third party API, that only reports data for sensors when there&amp;#39;s a change in value. &lt;/p&gt;\n\n&lt;p&gt;Our operations require consistent 5-minute buckets. We achieve this by using Timescale &amp;#39;s bucketing together with carrying forward the last observation. &lt;/p&gt;\n\n&lt;p&gt;This breaks down however when there is an outage, as in that case we don&amp;#39;t want to forward fill but instead not have any buckets at all. &lt;/p&gt;\n\n&lt;p&gt;It seems like it would be a common problem to have, how would you deal with this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m7opg", "is_robot_indexable": true, "report_reasons": null, "author": "georgesdoe", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m7opg/how_do_you_deal_with_missing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m7opg/how_do_you_deal_with_missing_data/", "subreddit_subscribers": 121710, "created_utc": 1691564595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently, I have to manually generate a lot of documentation for data cataloguing and was wondering if there is a tool which can help to generate documentation from code. What's your experience with documentation?", "author_fullname": "t2_dogbygvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tool do you use to generate documentation from your code? Have you figured out a better way to handle documentation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m6eda", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691560353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, I have to manually generate a lot of documentation for data cataloguing and was wondering if there is a tool which can help to generate documentation from code. What&amp;#39;s your experience with documentation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15m6eda", "is_robot_indexable": true, "report_reasons": null, "author": "vinayak_singh_k", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m6eda/what_tool_do_you_use_to_generate_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m6eda/what_tool_do_you_use_to_generate_documentation/", "subreddit_subscribers": 121710, "created_utc": 1691560353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello house, \n\nLet me start like this I currently work as a senior data analyst for my company and I have experience in data science with different project and research paper.\n\nI have always wanted to pivot to data engineering for a while now, taken multiple certifications on Azure and other resources.\n\nI got a job as a data engineer in an oil and gas company. I cleared all the exams(3) and interviews (2) with flying colors.\n\nI had a deep knowledge in all what data engineering is all about, the only issue is I have never worked as a data engineer \ud83d\udc68\ud83c\udffd\u200d\ud83d\udcbb much is expected from me with the high level I performed but I feel like this was because I have verse experience in data analysis and consulting which helped me.\n\nI primary use Azure DataBricks and ADF cloud, delta lake table(unity catalog) for warehouse and ADLG2 staging storage.\n\nSSIS, SSRS, SSAS and SSMS for private and local.\n\nPower BI &amp; Datamarts for visualization.\n\nIs this enough or is there something more to data engineering, I might sound silly but I feel there expectation of me is really high.\n\nLet me add I also work as a data engineer in a publishing company in the US as an author/writer.", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imposter Syndrome", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ln3gv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691512572.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691512333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello house, &lt;/p&gt;\n\n&lt;p&gt;Let me start like this I currently work as a senior data analyst for my company and I have experience in data science with different project and research paper.&lt;/p&gt;\n\n&lt;p&gt;I have always wanted to pivot to data engineering for a while now, taken multiple certifications on Azure and other resources.&lt;/p&gt;\n\n&lt;p&gt;I got a job as a data engineer in an oil and gas company. I cleared all the exams(3) and interviews (2) with flying colors.&lt;/p&gt;\n\n&lt;p&gt;I had a deep knowledge in all what data engineering is all about, the only issue is I have never worked as a data engineer \ud83d\udc68\ud83c\udffd\u200d\ud83d\udcbb much is expected from me with the high level I performed but I feel like this was because I have verse experience in data analysis and consulting which helped me.&lt;/p&gt;\n\n&lt;p&gt;I primary use Azure DataBricks and ADF cloud, delta lake table(unity catalog) for warehouse and ADLG2 staging storage.&lt;/p&gt;\n\n&lt;p&gt;SSIS, SSRS, SSAS and SSMS for private and local.&lt;/p&gt;\n\n&lt;p&gt;Power BI &amp;amp; Datamarts for visualization.&lt;/p&gt;\n\n&lt;p&gt;Is this enough or is there something more to data engineering, I might sound silly but I feel there expectation of me is really high.&lt;/p&gt;\n\n&lt;p&gt;Let me add I also work as a data engineer in a publishing company in the US as an author/writer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ln3gv", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ln3gv/imposter_syndrome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ln3gv/imposter_syndrome/", "subreddit_subscribers": 121710, "created_utc": 1691512333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone tried out the new m7i EC2 instances yet?\n\nWe ran the Dask benchmark suite comparing m6i.large to m7i.large nodes and the total runtime went down by \\~12% (so enough to justify the 5% increase in on-demand price). Image below for [test\\_dot\\_product\\_spill](https://github.com/coiled/benchmarks/blob/b07e7bb397fa0936883feca7981362bf52d34e7c/tests/benchmarks/test_spill.py#L65).\n\nBut... there's a much larger spot discount on older m6i.large instances, so total cost is still lower using m6i instances. Currently m7i.large spot instances are  &gt;25% more expensive than m6i.large spot. Alas.\n\nCurious to hear if others found something similar.\n\n[Final points in the plot are for the run with m7i.large](https://preview.redd.it/ub3x3jw1uwgb1.png?width=791&amp;format=png&amp;auto=webp&amp;s=0f70197d1ccbff8451728f919a7a3750f5353d89)", "author_fullname": "t2_w7crvjmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New m7i speculation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 49, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ub3x3jw1uwgb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3af89c86d860efb04b79924a71e9db35666698a5"}, {"y": 76, "x": 216, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d172dbe1cfa2465feba9d3b03990a5203cf2f70b"}, {"y": 113, "x": 320, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ff214a23693712170463a75c97fbce93b619692f"}, {"y": 227, "x": 640, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d4bf4eb4b65fba456938bf330920bda70635b855"}], "s": {"y": 281, "x": 791, "u": "https://preview.redd.it/ub3x3jw1uwgb1.png?width=791&amp;format=png&amp;auto=webp&amp;s=0f70197d1ccbff8451728f919a7a3750f5353d89"}, "id": "ub3x3jw1uwgb1"}}, "name": "t3_15lmjda", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/fAX1Z9Xze2JiLhqO8oS3kCTrS_dt2DRlAWD6xOI6oi4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691511057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone tried out the new m7i EC2 instances yet?&lt;/p&gt;\n\n&lt;p&gt;We ran the Dask benchmark suite comparing m6i.large to m7i.large nodes and the total runtime went down by ~12% (so enough to justify the 5% increase in on-demand price). Image below for &lt;a href=\"https://github.com/coiled/benchmarks/blob/b07e7bb397fa0936883feca7981362bf52d34e7c/tests/benchmarks/test_spill.py#L65\"&gt;test_dot_product_spill&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;But... there&amp;#39;s a much larger spot discount on older m6i.large instances, so total cost is still lower using m6i instances. Currently m7i.large spot instances are  &amp;gt;25% more expensive than m6i.large spot. Alas.&lt;/p&gt;\n\n&lt;p&gt;Curious to hear if others found something similar.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ub3x3jw1uwgb1.png?width=791&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0f70197d1ccbff8451728f919a7a3750f5353d89\"&gt;Final points in the plot are for the run with m7i.large&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15lmjda", "is_robot_indexable": true, "report_reasons": null, "author": "dask-jeeves", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lmjda/new_m7i_speculation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lmjda/new_m7i_speculation/", "subreddit_subscribers": 121710, "created_utc": 1691511057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In the quick-moving IT startup world, it's all about being fast, growing big, and planning smart. My experience has shown that success is tied to how well you handle and use your data. Here's a bit of what I've learned.\n\n&amp;#x200B;\n\nData integration refers to the amalgamation of information from disparate sources into a singular, unified data warehouse. This procedure offers a comprehensive perspective on business operations. The overarching objective is to centralize data, prepping it for utilization. A robust data integration plan enables superior data analysis and insightful reporting, leading to well-informed decision-making. In today's fast-paced business landscape, capitalizing on data's potential and integrating it effectively is paramount.\n\nHere are some insights into developing an optimal data integration approach for your enterprise.\n\n# Selecting the Right Data Integration Method.\n\nVarious techniques are available for data integration. Recognizing the one most advantageous for your enterprise and which ensures swift processing is vital. Notable techniques include:\n\n# a. ETL (Extract, Transform, Load)\n\n**Purpose:** Best for syncing multiple data environments and transitioning data from older systems.\n\n**Implementation:** Specialized software is needed to extract, transform, and load data.\n\n**Advantages:** ETL promotes efficiency, guarantees accurate and consistent data, and fosters data integration for insightful analysis.\n\n**Examples:**\n\nMerging companies might share consumers or partners, storing this data in divergent formats. ETL helps standardize this data before it's integrated into the data warehouse.\n\nAn e-commerce startup wanting to gain insights from user data without prior data integration experience would benefit from ETL.\n\n# b. ELT (Extract, Load, Transform)\n\n**Purpose:** Suitable for massive data volumes or real-time data usage settings.\n\n**Implementation:** The sequence is different; raw data is loaded first, followed by transformations as necessary.\n\n**Advantages:** ELT ensures scalability, agility, flexibility, and real-time processing.\n\n**Examples:** Meteorological entities collecting vast amounts of data frequently would benefit from the ELT process due to faster data transfers.\n\n# c. Change Data Capture (CDC)\n\n**Purpose:** Monitors and tracks database changes for subsequent action based on those changes.\n\n**Implementation:** CDC involves monitoring, capturing, and delivering change data.\n\n**Advantages:** Real-time integration, reduced system impact, historical data retention, and enhanced data quality.\n\n**Examples:** Businesses like Ticketmaster tracking variable concert pricing over time would benefit from CDC's historical data capabilities.\n\nBeyond these, other advanced techniques are elaborated on in my blog here:  [https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm\\_source=linkedin&amp;utm\\_medium=social&amp;utm\\_campaign=hfs\\_research&amp;utm\\_content=integration\\_strategy&amp;utm\\_term=socialmedia](https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm_source=linkedin&amp;utm_medium=social&amp;utm_campaign=hfs_research&amp;utm_content=integration_strategy&amp;utm_term=socialmedia)", "author_fullname": "t2_ct09rz3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing Data Integration Strategy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15mbmi2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691577534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the quick-moving IT startup world, it&amp;#39;s all about being fast, growing big, and planning smart. My experience has shown that success is tied to how well you handle and use your data. Here&amp;#39;s a bit of what I&amp;#39;ve learned.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Data integration refers to the amalgamation of information from disparate sources into a singular, unified data warehouse. This procedure offers a comprehensive perspective on business operations. The overarching objective is to centralize data, prepping it for utilization. A robust data integration plan enables superior data analysis and insightful reporting, leading to well-informed decision-making. In today&amp;#39;s fast-paced business landscape, capitalizing on data&amp;#39;s potential and integrating it effectively is paramount.&lt;/p&gt;\n\n&lt;p&gt;Here are some insights into developing an optimal data integration approach for your enterprise.&lt;/p&gt;\n\n&lt;h1&gt;Selecting the Right Data Integration Method.&lt;/h1&gt;\n\n&lt;p&gt;Various techniques are available for data integration. Recognizing the one most advantageous for your enterprise and which ensures swift processing is vital. Notable techniques include:&lt;/p&gt;\n\n&lt;h1&gt;a. ETL (Extract, Transform, Load)&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;Purpose:&lt;/strong&gt; Best for syncing multiple data environments and transitioning data from older systems.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Implementation:&lt;/strong&gt; Specialized software is needed to extract, transform, and load data.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt; ETL promotes efficiency, guarantees accurate and consistent data, and fosters data integration for insightful analysis.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Merging companies might share consumers or partners, storing this data in divergent formats. ETL helps standardize this data before it&amp;#39;s integrated into the data warehouse.&lt;/p&gt;\n\n&lt;p&gt;An e-commerce startup wanting to gain insights from user data without prior data integration experience would benefit from ETL.&lt;/p&gt;\n\n&lt;h1&gt;b. ELT (Extract, Load, Transform)&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;Purpose:&lt;/strong&gt; Suitable for massive data volumes or real-time data usage settings.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Implementation:&lt;/strong&gt; The sequence is different; raw data is loaded first, followed by transformations as necessary.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt; ELT ensures scalability, agility, flexibility, and real-time processing.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt; Meteorological entities collecting vast amounts of data frequently would benefit from the ELT process due to faster data transfers.&lt;/p&gt;\n\n&lt;h1&gt;c. Change Data Capture (CDC)&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;Purpose:&lt;/strong&gt; Monitors and tracks database changes for subsequent action based on those changes.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Implementation:&lt;/strong&gt; CDC involves monitoring, capturing, and delivering change data.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt; Real-time integration, reduced system impact, historical data retention, and enhanced data quality.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt; Businesses like Ticketmaster tracking variable concert pricing over time would benefit from CDC&amp;#39;s historical data capabilities.&lt;/p&gt;\n\n&lt;p&gt;Beyond these, other advanced techniques are elaborated on in my blog here:  &lt;a href=\"https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=hfs_research&amp;amp;utm_content=integration_strategy&amp;amp;utm_term=socialmedia\"&gt;https://ainsys.com/blog/2023/08/02/data-integration-strategy/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=hfs_research&amp;amp;utm_content=integration_strategy&amp;amp;utm_term=socialmedia&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I3xJj8ELsQOmy2H-NeHKFmGnh2tKVfHX1i7SJ1O1qwE.jpg?auto=webp&amp;s=8a29f85fd320507a70ec9694b971f494352d2655", "width": 79, "height": 86}, "resolutions": [], "variants": {}, "id": "fKkAw45B6Aa1K9gfC0CvmXNzCjb0F-J2wvKUvaKf1Vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mbmi2", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Speech36", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mbmi2/choosing_data_integration_strategy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mbmi2/choosing_data_integration_strategy/", "subreddit_subscribers": 121710, "created_utc": 1691577534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a  project (a POC, for interviews and to show my GCP skills, for my own git) to calculate the CO2 emissions for individuals based on their use of transportation. And i'm designing the following architecture as it's my first GCP project, I thought that maybe some feedback will help).   \n\n\n\\- Offer : i got the 12 months free offer with 300$ credit\n\n\\- Data Ingestion to Google Cloud Storage :   \nI created a bucket (standard offer) on GCS to consolidate raw data (CO2 consumption data + master data ) from different sources. The C02 data will be fetched by API calls to Google Timeline API  (Cloud function) and stored without transformation to GCS. The master data is just uploaded to GCS for now (not automated as it's a one time ingestion)  \nThe cloud function are lunched by google cloud scheduler for daily uploads. Each call is gathering transportation data for my sample individuals (30 individuals for now) and will consolidate the data for all the users in one JSON file to store on GCP (the return of the api calls is JSON, but idk if i can store it maybe as AVRO or PARQUET for better performances ? also I thought about consolidating the data in one file to not have several files that might slow the DF perfromances afterwards ? what do you think ? )    \n\n\n\\- Data Transformation  \nBased on the bucket's data updated, a Dataflow is lunched to transform the user's data and enrich it with master data and CO2 emissions calculation (basic joins and  map operations)   \nWe have other data flows for master data loading that are lunched as well when new master data files are available ( 1 DF for each dimension table )   \n\n\n\\- Data Load  \nThe data after transformation will be loaded to big query (one fact table , main KPI is CO2 emissions and Dimensions tables : Time, User Information, Geographical information ... etc.)   \n\n\nTables are partitionned by time and clustered by Geographical information / User information (as it'll be used in the queries)   \n\n\nMaterialized tables for TOP C02 Emission per User/Region are available to reduce shuffling and not recalclulate that each time   \n\n\n\\- Data Viz  \nData viz using google data studio for CO2 emissions trends per user/region...etc.  \nand also top CO2 emissions and bottom CO2 emissions   \n\n\nAny views or critics are welcomed as it's my first project on GCP.   \n\n\nMany thanks by advance. ", "author_fullname": "t2_4kn0fb0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First Project on GCP - Feedback on architecture needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15mbjf9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691577268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a  project (a POC, for interviews and to show my GCP skills, for my own git) to calculate the CO2 emissions for individuals based on their use of transportation. And i&amp;#39;m designing the following architecture as it&amp;#39;s my first GCP project, I thought that maybe some feedback will help).   &lt;/p&gt;\n\n&lt;p&gt;- Offer : i got the 12 months free offer with 300$ credit&lt;/p&gt;\n\n&lt;p&gt;- Data Ingestion to Google Cloud Storage :&lt;br/&gt;\nI created a bucket (standard offer) on GCS to consolidate raw data (CO2 consumption data + master data ) from different sources. The C02 data will be fetched by API calls to Google Timeline API  (Cloud function) and stored without transformation to GCS. The master data is just uploaded to GCS for now (not automated as it&amp;#39;s a one time ingestion)&lt;br/&gt;\nThe cloud function are lunched by google cloud scheduler for daily uploads. Each call is gathering transportation data for my sample individuals (30 individuals for now) and will consolidate the data for all the users in one JSON file to store on GCP (the return of the api calls is JSON, but idk if i can store it maybe as AVRO or PARQUET for better performances ? also I thought about consolidating the data in one file to not have several files that might slow the DF perfromances afterwards ? what do you think ? )    &lt;/p&gt;\n\n&lt;p&gt;- Data Transformation&lt;br/&gt;\nBased on the bucket&amp;#39;s data updated, a Dataflow is lunched to transform the user&amp;#39;s data and enrich it with master data and CO2 emissions calculation (basic joins and  map operations)&lt;br/&gt;\nWe have other data flows for master data loading that are lunched as well when new master data files are available ( 1 DF for each dimension table )   &lt;/p&gt;\n\n&lt;p&gt;- Data Load&lt;br/&gt;\nThe data after transformation will be loaded to big query (one fact table , main KPI is CO2 emissions and Dimensions tables : Time, User Information, Geographical information ... etc.)   &lt;/p&gt;\n\n&lt;p&gt;Tables are partitionned by time and clustered by Geographical information / User information (as it&amp;#39;ll be used in the queries)   &lt;/p&gt;\n\n&lt;p&gt;Materialized tables for TOP C02 Emission per User/Region are available to reduce shuffling and not recalclulate that each time   &lt;/p&gt;\n\n&lt;p&gt;- Data Viz&lt;br/&gt;\nData viz using google data studio for CO2 emissions trends per user/region...etc.&lt;br/&gt;\nand also top CO2 emissions and bottom CO2 emissions   &lt;/p&gt;\n\n&lt;p&gt;Any views or critics are welcomed as it&amp;#39;s my first project on GCP.   &lt;/p&gt;\n\n&lt;p&gt;Many thanks by advance. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "15mbjf9", "is_robot_indexable": true, "report_reasons": null, "author": "Ezzarrass", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mbjf9/first_project_on_gcp_feedback_on_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mbjf9/first_project_on_gcp_feedback_on_architecture/", "subreddit_subscribers": 121710, "created_utc": 1691577268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Having looked into Apache Beam, I really like their idea of representing a DAG data pipeline programmatically using PTransforms and PCollections via the [Pipeline API](https://beam.apache.org/documentation/pipelines/design-your-pipeline/#a-basic-pipeline). However in my case, I only ever want to use Spark as my execution platform so don't want to incur the performance cost of Beam's abstractions for supporting both batch and streaming usecases. \n\nIs there any library etc. out there that would allow me to write standard Spark logic using Datasets but programmatically represent my ETL logic in a DAG form using Java or Scala code? The closest I could find is [ML Pipelines](https://spark.apache.org/docs/latest/ml-pipeline.html#example-estimator-transformer-and-param) in Spark but this seems far too closely tied to machine learning rather than general purpose Spark logic.", "author_fullname": "t2_n46ct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Programmatic Spark DAG pipelines in Java/Scala similar to Beam's Pipeline API (but without the additional abstraction) to define workflows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15mbe9j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691576827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Having looked into Apache Beam, I really like their idea of representing a DAG data pipeline programmatically using PTransforms and PCollections via the &lt;a href=\"https://beam.apache.org/documentation/pipelines/design-your-pipeline/#a-basic-pipeline\"&gt;Pipeline API&lt;/a&gt;. However in my case, I only ever want to use Spark as my execution platform so don&amp;#39;t want to incur the performance cost of Beam&amp;#39;s abstractions for supporting both batch and streaming usecases. &lt;/p&gt;\n\n&lt;p&gt;Is there any library etc. out there that would allow me to write standard Spark logic using Datasets but programmatically represent my ETL logic in a DAG form using Java or Scala code? The closest I could find is &lt;a href=\"https://spark.apache.org/docs/latest/ml-pipeline.html#example-estimator-transformer-and-param\"&gt;ML Pipelines&lt;/a&gt; in Spark but this seems far too closely tied to machine learning rather than general purpose Spark logic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mbe9j", "is_robot_indexable": true, "report_reasons": null, "author": "Vergo777", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mbe9j/programmatic_spark_dag_pipelines_in_javascala/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mbe9j/programmatic_spark_dag_pipelines_in_javascala/", "subreddit_subscribers": 121710, "created_utc": 1691576827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, I hope you are doing well. I want this post to give an idea to the youngsters and hope to get some feedback for my end on how how to improve my productivity.\n\nI work in a consulting firm and we are trying to help a really old bank to get back on its feet. Although I hate learning tools in legacy companies, I need money so no complaints.\n\nI am responsible for creating tables for dashboard complaints but I am stuck on issues and I was wondering if my problems are normal for industry standards.\n\nI work with PL/SQL, Oracle Data Integrator 12c for data integration and OBIEE for visualizations. This is my first job and I can definitely assure you I am not the top-tier analytical person in the group, barely low to middle. My language skills is the most valuable skill to the company because our customer is foreign to us and I am the only one who can communicate with them. But my lack of experience in these tools (overall Data Engineering) makes my language skills invalid because even though I can talk with them, I don't know what the fuck I should do to make it a reality.\n\n**PERSONAL BACKGROUND AND SELF-REFLECTION**\n\n* I come from a different background although I work hard, I miss some important stuff so everything feels like a cheese with holes in it easily.\n* I mainly studies SQL from online courses, completed some courses and solved some questions online. Whenever I can't write a query, I just ask my colleagues to help me with it, but I don't know how can I improve my SQL while working in this job because SQL is the\n* I don't know which questions to ask about data and tables. So whenever my manager asks me why certain things are taking slower than he expects, I can't give satisfying answers to him\n* Oracle ecosystem has little to no community, where have all Oracle experts gone??\n* I am not the most hardworking person and I like to be a jack of all trades. I believe some % of the issues I am facing are created by my own laziness, yet I am definitely sure it is not the main problem.\n* My manager can't understand my difficulties and blame me for being lazy. I am not gonna lie, there were some days were I looked at the screen and couldn't lift my finger to press a button.\n\n**GENERAL PROBLEMS**\n\n**Working hour difference and Lack of Communication**\n\n* There is only a 1-hour difference but that means I lose 20 hours per month when I have to talk to someone when something is wrong either from my side or customers. And I have to overtime sometimes (with no payment and there is nothing I can do about it.) because the customer is only available during their working hours basically.\n* Nobody starts working as soon as they enter the building right? Of course but I sometimes don't get answers to my questions for hours even damn days.\n\n**Jira inside of Virtual Machines suck**\n\n* Jira doesn't give me notifications so I have to check every damn ticket whether someone commented or updated anything.\n* I didn't check the tickets for 3 weeks now the business guy is on my throat for deadlines. Yaaaaaaayy!\n\n**Lack of Quality Seniors and colleagues.**\n\n* We are a 4-man team, consisting of 3 Junior and 1 Senior.\n* 1st Junior is always busy with other projects and can barely come to our meetings. She has potential but again, is extremely busy. 2nd Junior knows nothing, he is a dumbass who can't edit Excel column lines. 3rd Junior is me with too little experience in the Data field overall but with a decent guide, I can overcome many challenges. About my senior, I am having some difficulties.\n* My Senior DE can't speak English. He claims he has experience over 15 years but he can't do shit without my guidance and me translating the customers' wants to him. I feel like a translator in the job more than a Data Engineer sometimes.\n\n**Lack of Analysis Documents**\n\n* After all these, business side expects me to create tables without providing me with decent analysis documents. The business side expects me to understand the whole context from the previously made tables and dashboards and create the table like I am omniscient. This is my biggest problem.\n\n**VPN Crashes every month**\n\n* Takes at least half a day to solve this issue with the infrastructure team. This is a minor issue but I wanted to point it out.\n\n**Lack of Permissions to Databases/Tables.**\n\n* Even a simple join is quite tedious when I don't have permission. I can't get permissions easily and getting those permissions take days.\n* I don't even have insert and alter permissions. I have to ask the DB admin to insert keys for me in the development environment or I have to drop the table and create it with a script.\n* Calculations can't be checked because even the business side has no permission to check either tables or dashboards. So everything has to be moved between the test and the live environment even for the smallest change and it is crushing my soul.\n\n**Lack of Data in the damn tables**\n\n* You waited for so long for getting those hands dirty but so what? The tables I need to work on have little to no data in the development environment. But the business side insists that the table is full of data baby. I ask them to fill in the data to test the environment but they don't want to do it because the data is large.\n\n**Worst business side can't see the tables/calculations I am creating**\n\n* I create a 99% wrongly calculated table but what happens? Business ppl can't check the calculations because not they don't have access to my test environment. So I ask some guys to move it to live. If it is wrong then go back to step one.\n\nI am thinking to quit my job", "author_fullname": "t2_hecq3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First Data Engineering Job and Reality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15mbcrs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691576700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I hope you are doing well. I want this post to give an idea to the youngsters and hope to get some feedback for my end on how how to improve my productivity.&lt;/p&gt;\n\n&lt;p&gt;I work in a consulting firm and we are trying to help a really old bank to get back on its feet. Although I hate learning tools in legacy companies, I need money so no complaints.&lt;/p&gt;\n\n&lt;p&gt;I am responsible for creating tables for dashboard complaints but I am stuck on issues and I was wondering if my problems are normal for industry standards.&lt;/p&gt;\n\n&lt;p&gt;I work with PL/SQL, Oracle Data Integrator 12c for data integration and OBIEE for visualizations. This is my first job and I can definitely assure you I am not the top-tier analytical person in the group, barely low to middle. My language skills is the most valuable skill to the company because our customer is foreign to us and I am the only one who can communicate with them. But my lack of experience in these tools (overall Data Engineering) makes my language skills invalid because even though I can talk with them, I don&amp;#39;t know what the fuck I should do to make it a reality.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;PERSONAL BACKGROUND AND SELF-REFLECTION&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I come from a different background although I work hard, I miss some important stuff so everything feels like a cheese with holes in it easily.&lt;/li&gt;\n&lt;li&gt;I mainly studies SQL from online courses, completed some courses and solved some questions online. Whenever I can&amp;#39;t write a query, I just ask my colleagues to help me with it, but I don&amp;#39;t know how can I improve my SQL while working in this job because SQL is the&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t know which questions to ask about data and tables. So whenever my manager asks me why certain things are taking slower than he expects, I can&amp;#39;t give satisfying answers to him&lt;/li&gt;\n&lt;li&gt;Oracle ecosystem has little to no community, where have all Oracle experts gone??&lt;/li&gt;\n&lt;li&gt;I am not the most hardworking person and I like to be a jack of all trades. I believe some % of the issues I am facing are created by my own laziness, yet I am definitely sure it is not the main problem.&lt;/li&gt;\n&lt;li&gt;My manager can&amp;#39;t understand my difficulties and blame me for being lazy. I am not gonna lie, there were some days were I looked at the screen and couldn&amp;#39;t lift my finger to press a button.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;GENERAL PROBLEMS&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Working hour difference and Lack of Communication&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;There is only a 1-hour difference but that means I lose 20 hours per month when I have to talk to someone when something is wrong either from my side or customers. And I have to overtime sometimes (with no payment and there is nothing I can do about it.) because the customer is only available during their working hours basically.&lt;/li&gt;\n&lt;li&gt;Nobody starts working as soon as they enter the building right? Of course but I sometimes don&amp;#39;t get answers to my questions for hours even damn days.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Jira inside of Virtual Machines suck&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Jira doesn&amp;#39;t give me notifications so I have to check every damn ticket whether someone commented or updated anything.&lt;/li&gt;\n&lt;li&gt;I didn&amp;#39;t check the tickets for 3 weeks now the business guy is on my throat for deadlines. Yaaaaaaayy!&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Lack of Quality Seniors and colleagues.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We are a 4-man team, consisting of 3 Junior and 1 Senior.&lt;/li&gt;\n&lt;li&gt;1st Junior is always busy with other projects and can barely come to our meetings. She has potential but again, is extremely busy. 2nd Junior knows nothing, he is a dumbass who can&amp;#39;t edit Excel column lines. 3rd Junior is me with too little experience in the Data field overall but with a decent guide, I can overcome many challenges. About my senior, I am having some difficulties.&lt;/li&gt;\n&lt;li&gt;My Senior DE can&amp;#39;t speak English. He claims he has experience over 15 years but he can&amp;#39;t do shit without my guidance and me translating the customers&amp;#39; wants to him. I feel like a translator in the job more than a Data Engineer sometimes.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Lack of Analysis Documents&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;After all these, business side expects me to create tables without providing me with decent analysis documents. The business side expects me to understand the whole context from the previously made tables and dashboards and create the table like I am omniscient. This is my biggest problem.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;VPN Crashes every month&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Takes at least half a day to solve this issue with the infrastructure team. This is a minor issue but I wanted to point it out.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Lack of Permissions to Databases/Tables.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Even a simple join is quite tedious when I don&amp;#39;t have permission. I can&amp;#39;t get permissions easily and getting those permissions take days.&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t even have insert and alter permissions. I have to ask the DB admin to insert keys for me in the development environment or I have to drop the table and create it with a script.&lt;/li&gt;\n&lt;li&gt;Calculations can&amp;#39;t be checked because even the business side has no permission to check either tables or dashboards. So everything has to be moved between the test and the live environment even for the smallest change and it is crushing my soul.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Lack of Data in the damn tables&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;You waited for so long for getting those hands dirty but so what? The tables I need to work on have little to no data in the development environment. But the business side insists that the table is full of data baby. I ask them to fill in the data to test the environment but they don&amp;#39;t want to do it because the data is large.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Worst business side can&amp;#39;t see the tables/calculations I am creating&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I create a 99% wrongly calculated table but what happens? Business ppl can&amp;#39;t check the calculations because not they don&amp;#39;t have access to my test environment. So I ask some guys to move it to live. If it is wrong then go back to step one.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am thinking to quit my job&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mbcrs", "is_robot_indexable": true, "report_reasons": null, "author": "rayman903", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mbcrs/first_data_engineering_job_and_reality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mbcrs/first_data_engineering_job_and_reality/", "subreddit_subscribers": 121710, "created_utc": 1691576700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI will be on holiday from 9 to 30 of August in Columbus.\nI'm not from US, so it's my first time there !\nDo you know some meetups / aperitivo's to meet people working in Data Roles / IT or hackathons for data Analysts ?\n\nI would be happy to connect for a drink for anyone interested.", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE / DS / Data Meetups in Ohio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m7iie", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691564049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI will be on holiday from 9 to 30 of August in Columbus.\nI&amp;#39;m not from US, so it&amp;#39;s my first time there !\nDo you know some meetups / aperitivo&amp;#39;s to meet people working in Data Roles / IT or hackathons for data Analysts ?&lt;/p&gt;\n\n&lt;p&gt;I would be happy to connect for a drink for anyone interested.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15m7iie", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m7iie/de_ds_data_meetups_in_ohio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m7iie/de_ds_data_meetups_in_ohio/", "subreddit_subscribers": 121710, "created_utc": 1691564049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm very new to Data Engineering, can anyone help me with best resources ( like udemy/YouTube,etc.. )to learn snowflake from scratch?", "author_fullname": "t2_3x106z0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Resources to start learning snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m6gtz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691560580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m very new to Data Engineering, can anyone help me with best resources ( like udemy/YouTube,etc.. )to learn snowflake from scratch?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15m6gtz", "is_robot_indexable": true, "report_reasons": null, "author": "sanjeevj11", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m6gtz/need_resources_to_start_learning_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m6gtz/need_resources_to_start_learning_snowflake/", "subreddit_subscribers": 121710, "created_utc": 1691560580.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "recently i have been asked kinda vague system design type questions for entry - mid level Data Engineer roles, \n\neg - how you will build a real-time dashboard for user activity for an e-commerce app like Amazon, and things related to it like tradeoffs, the whole structure , architecture etc.\n\nare these very common? as i don't really have too much experience in this (i have common data engineering architecture sense) so i explained it in a very normal way.\n\ni have been asked similar architecture type question before, like how you will build the data warehouse/ datalake  for analysts/ data scientists to use...\n\nso my question if there are very common questions...is there anything i can refer to to prepare for them? or should i just go and watch system design interview videos?  \n\n\nP.S - please forgive me for any typos, its almost 1 am,and i am very sleepy \ud83d\ude22", "author_fullname": "t2_6f6khk66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "system design type interview questions for DE roles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lrfuw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691522142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;recently i have been asked kinda vague system design type questions for entry - mid level Data Engineer roles, &lt;/p&gt;\n\n&lt;p&gt;eg - how you will build a real-time dashboard for user activity for an e-commerce app like Amazon, and things related to it like tradeoffs, the whole structure , architecture etc.&lt;/p&gt;\n\n&lt;p&gt;are these very common? as i don&amp;#39;t really have too much experience in this (i have common data engineering architecture sense) so i explained it in a very normal way.&lt;/p&gt;\n\n&lt;p&gt;i have been asked similar architecture type question before, like how you will build the data warehouse/ datalake  for analysts/ data scientists to use...&lt;/p&gt;\n\n&lt;p&gt;so my question if there are very common questions...is there anything i can refer to to prepare for them? or should i just go and watch system design interview videos?  &lt;/p&gt;\n\n&lt;p&gt;P.S - please forgive me for any typos, its almost 1 am,and i am very sleepy \ud83d\ude22&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15lrfuw", "is_robot_indexable": true, "report_reasons": null, "author": "mainak17", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lrfuw/system_design_type_interview_questions_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lrfuw/system_design_type_interview_questions_for_de/", "subreddit_subscribers": 121710, "created_utc": 1691522142.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}