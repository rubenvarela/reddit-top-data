{"kind": "Listing", "data": {"after": "t3_15mbcrs", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**My background:**\n\nCurrently I'm a senior data analyst, and I'm one of those people that works in the department where the data analyst does just about everything. I do ETL, reporting, bi stuff so piping data from Google BigQuery into stuff like Power BI, looker studio, AWS, snowflake, using Python of course. I spend more time typing in SQL than I do in English in emails. I find myself doing recreational projects with Python and SQL quite often, for example this week I wrote in API that retrieves data from Kaggle, cleans it in pandas, loads it into BigQuery, also loads it into snowflake, Cassandra, Then using even more Python, retrieves some of the data using SQL. \n\n\n**Question:**\n\nHow do I know if I'm ready for a data engineer position? Will I ever be ready? I was contacted buy a recruiter for a couple positions. The one I applied to is data analyst, but I asked about the data engineer position because the job description said almost nothing about it. She said it was a little bit more technical than what I've probably done, preceded to list off basically everything I've already been doing. Said I have to be comfortable doing object-oriented programming in Python (didn't know they used objects in data engineering). Said that it's a lot more of the piping data, working in AWS data sources, snowflake, Hadoop, etc... This is all stuff that sounds insanely complex and technical but here's the thing.... **How do I know if this is stuff that I'm capable of learning on the job or doing?** Like no, of course I haven't set up a data source from scratch with 300 million rows or a terabyte of data myself. I can't just go and make a 300 million row data set on my PC at home. No matter how much I want to, It would be next to impossible for me to simulate the work that a data engineer actually does on the job in a personal setting. Because any work I do as a data engineer will be in a live environment for a big company with important deadlines and I don't have that right now.", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Honest question: How do I know if I'm good enough to be a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lr89o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691521667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;My background:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m a senior data analyst, and I&amp;#39;m one of those people that works in the department where the data analyst does just about everything. I do ETL, reporting, bi stuff so piping data from Google BigQuery into stuff like Power BI, looker studio, AWS, snowflake, using Python of course. I spend more time typing in SQL than I do in English in emails. I find myself doing recreational projects with Python and SQL quite often, for example this week I wrote in API that retrieves data from Kaggle, cleans it in pandas, loads it into BigQuery, also loads it into snowflake, Cassandra, Then using even more Python, retrieves some of the data using SQL. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;How do I know if I&amp;#39;m ready for a data engineer position? Will I ever be ready? I was contacted buy a recruiter for a couple positions. The one I applied to is data analyst, but I asked about the data engineer position because the job description said almost nothing about it. She said it was a little bit more technical than what I&amp;#39;ve probably done, preceded to list off basically everything I&amp;#39;ve already been doing. Said I have to be comfortable doing object-oriented programming in Python (didn&amp;#39;t know they used objects in data engineering). Said that it&amp;#39;s a lot more of the piping data, working in AWS data sources, snowflake, Hadoop, etc... This is all stuff that sounds insanely complex and technical but here&amp;#39;s the thing.... &lt;strong&gt;How do I know if this is stuff that I&amp;#39;m capable of learning on the job or doing?&lt;/strong&gt; Like no, of course I haven&amp;#39;t set up a data source from scratch with 300 million rows or a terabyte of data myself. I can&amp;#39;t just go and make a 300 million row data set on my PC at home. No matter how much I want to, It would be next to impossible for me to simulate the work that a data engineer actually does on the job in a personal setting. Because any work I do as a data engineer will be in a live environment for a big company with important deadlines and I don&amp;#39;t have that right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15lr89o", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lr89o/honest_question_how_do_i_know_if_im_good_enough/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lr89o/honest_question_how_do_i_know_if_im_good_enough/", "subreddit_subscribers": 121767, "created_utc": 1691521667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a full time job I\u2019m happy with. But because I\u2019m a capitalist I want to make more money. I also don\u2019t want to deal with the constrains another job or 1099 gig has, I want to be my own boss. \n\nI\u2019m considering doing freelance via upwork or similar. I have about 5 years experience with python and sql and various tools like snowflake and airflow. I think lower effort clients like webscraping or maybe even no code tools could be a good start. \n\nAnyone else do this? Is it super hard to start?", "author_fullname": "t2_1kset4fg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone Freelance on the Side?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15loaaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691515080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a full time job I\u2019m happy with. But because I\u2019m a capitalist I want to make more money. I also don\u2019t want to deal with the constrains another job or 1099 gig has, I want to be my own boss. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m considering doing freelance via upwork or similar. I have about 5 years experience with python and sql and various tools like snowflake and airflow. I think lower effort clients like webscraping or maybe even no code tools could be a good start. &lt;/p&gt;\n\n&lt;p&gt;Anyone else do this? Is it super hard to start?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15loaaj", "is_robot_indexable": true, "report_reasons": null, "author": "shittyfuckdick", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15loaaj/anyone_freelance_on_the_side/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15loaaj/anyone_freelance_on_the_side/", "subreddit_subscribers": 121767, "created_utc": 1691515080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Consultants have forced on us a truly terrible data model for our marketing warehouse. Tables and columns are named with inscrutable acronyms, there\u2019s no clarity on how entities relate to one another or map to business processes, and the idea of a meaningful table grain is but a dream (they like to make new tables by grouping by dozens of unrelated attributes).\n\nIt\u2019s a mess and the most infuriating part as an ETL engineer is that I can\u2019t get that across to the business side because whenever I say \u201cproper modeling standards\u201d they hear \u201cyou\u2019re going to make me wait longer for new reports\u201d. The only way I can think to prove how bad it is would be to redo the whole design myself to give them a side-by-side comparison, but that\u2019s months of work. And of course when the data quality goes to hell my team is the one that\u2019ll take the blame.\n\nAny suggestions or stories of similar situations?", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prove a data model is bad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ltzr9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691527832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Consultants have forced on us a truly terrible data model for our marketing warehouse. Tables and columns are named with inscrutable acronyms, there\u2019s no clarity on how entities relate to one another or map to business processes, and the idea of a meaningful table grain is but a dream (they like to make new tables by grouping by dozens of unrelated attributes).&lt;/p&gt;\n\n&lt;p&gt;It\u2019s a mess and the most infuriating part as an ETL engineer is that I can\u2019t get that across to the business side because whenever I say \u201cproper modeling standards\u201d they hear \u201cyou\u2019re going to make me wait longer for new reports\u201d. The only way I can think to prove how bad it is would be to redo the whole design myself to give them a side-by-side comparison, but that\u2019s months of work. And of course when the data quality goes to hell my team is the one that\u2019ll take the blame.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or stories of similar situations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ltzr9", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ltzr9/prove_a_data_model_is_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ltzr9/prove_a_data_model_is_bad/", "subreddit_subscribers": 121767, "created_utc": 1691527832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, changed the company a few months ago and it seems like this one offers study days + full pay for workshops, certifications, online courses and so on.\n\nI\u2019m really looking to make good use of these opportunities, that\u2019s why I\u2019m looking for some workshop recommendations to develop myself as a data engineer. I am pretty interested in backend architecture for data systems(mostly related to Azure since that\u2019s what my company is using to host all their data architecture). \n\nBut If you guys know any other good data engineering workshops related to Data Engineering as a whole, please let me know.", "author_fullname": "t2_4lcvdsdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Online workshops for getting better at Data Engineering Backend/Datawarehouse architectures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m9ab4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691569983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, changed the company a few months ago and it seems like this one offers study days + full pay for workshops, certifications, online courses and so on.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m really looking to make good use of these opportunities, that\u2019s why I\u2019m looking for some workshop recommendations to develop myself as a data engineer. I am pretty interested in backend architecture for data systems(mostly related to Azure since that\u2019s what my company is using to host all their data architecture). &lt;/p&gt;\n\n&lt;p&gt;But If you guys know any other good data engineering workshops related to Data Engineering as a whole, please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m9ab4", "is_robot_indexable": true, "report_reasons": null, "author": "Emotional_Key", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m9ab4/online_workshops_for_getting_better_at_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m9ab4/online_workshops_for_getting_better_at_data/", "subreddit_subscribers": 121767, "created_utc": 1691569983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just started a new job and am shocked at the state of the dbt project. I've no idea whether I am used to too high standards and I am overreacting. Would appreciate to hear some other stories of dbt at your company!\n\nSo why it is so bad, we're two analytics engineers and 1 data engineer. The data engineer mainly manages airflow and databricks so they hardly work with dbt. So it's basically two people. And we have the following:\n\n- 600+ models\n\n- no tests for most of the models\n\n- lineage is a mess. One of the core tables has 55 parents and 150 children. Circular references all over the place.\n\n- everything in the mart is materialized as a table. They run those tables multiple times a day. Costs have been increasing at a steady pace ofcourse.\n\n- they use schemas to denote topics. The project.yml contains configs for each folder to materialize it to the correct schema. The file is 200+ lines long as a consequence.\n\nBtw they managed to get to this state in less than a year :p\n\nOh and they are migrating to a new bi tool with deadline end of October. Work hasn't even started on that. So should I run? :P\n\nEdit: fixed formatting", "author_fullname": "t2_2ol209b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is our dbt project as bad as I think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mhunt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691594444.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691593433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started a new job and am shocked at the state of the dbt project. I&amp;#39;ve no idea whether I am used to too high standards and I am overreacting. Would appreciate to hear some other stories of dbt at your company!&lt;/p&gt;\n\n&lt;p&gt;So why it is so bad, we&amp;#39;re two analytics engineers and 1 data engineer. The data engineer mainly manages airflow and databricks so they hardly work with dbt. So it&amp;#39;s basically two people. And we have the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;600+ models&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;no tests for most of the models&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;lineage is a mess. One of the core tables has 55 parents and 150 children. Circular references all over the place.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;everything in the mart is materialized as a table. They run those tables multiple times a day. Costs have been increasing at a steady pace ofcourse.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;they use schemas to denote topics. The project.yml contains configs for each folder to materialize it to the correct schema. The file is 200+ lines long as a consequence.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Btw they managed to get to this state in less than a year :p&lt;/p&gt;\n\n&lt;p&gt;Oh and they are migrating to a new bi tool with deadline end of October. Work hasn&amp;#39;t even started on that. So should I run? :P&lt;/p&gt;\n\n&lt;p&gt;Edit: fixed formatting&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mhunt", "is_robot_indexable": true, "report_reasons": null, "author": "snackeloni", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mhunt/is_our_dbt_project_as_bad_as_i_think/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mhunt/is_our_dbt_project_as_bad_as_i_think/", "subreddit_subscribers": 121767, "created_utc": 1691593433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I have been creating data entry apps to send data into a sql database using power apps but having the premium license for sql connections is expensive for my organization. Does anyone know about good, cheaper alternatives to power apps for data entry? Thanks.", "author_fullname": "t2_6j5e93w9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternatives to powerapps for data entry into sql", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15madgt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691573595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I have been creating data entry apps to send data into a sql database using power apps but having the premium license for sql connections is expensive for my organization. Does anyone know about good, cheaper alternatives to power apps for data entry? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15madgt", "is_robot_indexable": true, "report_reasons": null, "author": "arachnarus96", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15madgt/alternatives_to_powerapps_for_data_entry_into_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15madgt/alternatives_to_powerapps_for_data_entry_into_sql/", "subreddit_subscribers": 121767, "created_utc": 1691573595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fwerb2uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Virtual Data Builds: A data warehouse environment for every Git commit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15mctop", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nR_BTR4yVxasfkKNa10X80MIwQ7aeeJ3Q6MG2-BSWBI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691581102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "y42.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.y42.com/blog/virtual-data-builds-one-data-warehouse-environment-for-every-git-commit/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?auto=webp&amp;s=dfe5baa7e55b0fdeafdd8e55ceea1f41e8bb2575", "width": 2160, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=220afd6e3120c0aad0c5a461d4b5772d0ab8243d", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d14cb37959937ca4fb686bd8de2b82c6fcf496e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2a51dfa134189b445a11664b6909846abde9a9a8", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8eac2eeda830983ca6b8fbf6f41969c9ea7a3259", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dc76ee53527828db8c839c838aaebe3675c5dc52", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a941f122abdb5a72cbe93bfb04a56e7bd369c808", "width": 1080, "height": 720}], "variants": {}, "id": "TE7uqwVe35pQ_NYMKSpfU5YX8jXz0cwr0p_FDEMXmYs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15mctop", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant-Guidance599", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mctop/virtual_data_builds_a_data_warehouse_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.y42.com/blog/virtual-data-builds-one-data-warehouse-environment-for-every-git-commit/", "subreddit_subscribers": 121767, "created_utc": 1691581102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are considering a code assistance tool (co-pilot) for our team but are not sure if it will help us as claimed. We use notebooks and wondering if anyone has any experience with these kinds of tools. ", "author_fullname": "t2_dogbygvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your experience with code assistant (co-pilot)? What are the challenges?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m57ur", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691556625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are considering a code assistance tool (co-pilot) for our team but are not sure if it will help us as claimed. We use notebooks and wondering if anyone has any experience with these kinds of tools. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m57ur", "is_robot_indexable": true, "report_reasons": null, "author": "vinayak_singh_k", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m57ur/what_is_your_experience_with_code_assistant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m57ur/what_is_your_experience_with_code_assistant/", "subreddit_subscribers": 121767, "created_utc": 1691556625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve heard some people mention stipends for additional training and using that for O\u2019Reilly subscriptions etc. but how common is that or any support from your employer for professional development in general?", "author_fullname": "t2_71weyfry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it common for companies to not offer any professional development?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m4n11", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691554842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve heard some people mention stipends for additional training and using that for O\u2019Reilly subscriptions etc. but how common is that or any support from your employer for professional development in general?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m4n11", "is_robot_indexable": true, "report_reasons": null, "author": "DrunkenWhaler136", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m4n11/is_it_common_for_companies_to_not_offer_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m4n11/is_it_common_for_companies_to_not_offer_any/", "subreddit_subscribers": 121767, "created_utc": 1691554842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So we have a pretty standard IoT setup, with sensor data being stored on Timescale. We pull that data from a third party API, that only reports data for sensors when there's a change in value. \n\nOur operations require consistent 5-minute buckets. We achieve this by using Timescale 's bucketing together with carrying forward the last observation. \n\nThis breaks down however when there is an outage, as in that case we don't want to forward fill but instead not have any buckets at all. \n\nIt seems like it would be a common problem to have, how would you deal with this?", "author_fullname": "t2_mui57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you deal with missing data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m7opg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691564595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we have a pretty standard IoT setup, with sensor data being stored on Timescale. We pull that data from a third party API, that only reports data for sensors when there&amp;#39;s a change in value. &lt;/p&gt;\n\n&lt;p&gt;Our operations require consistent 5-minute buckets. We achieve this by using Timescale &amp;#39;s bucketing together with carrying forward the last observation. &lt;/p&gt;\n\n&lt;p&gt;This breaks down however when there is an outage, as in that case we don&amp;#39;t want to forward fill but instead not have any buckets at all. &lt;/p&gt;\n\n&lt;p&gt;It seems like it would be a common problem to have, how would you deal with this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m7opg", "is_robot_indexable": true, "report_reasons": null, "author": "georgesdoe", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m7opg/how_do_you_deal_with_missing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m7opg/how_do_you_deal_with_missing_data/", "subreddit_subscribers": 121767, "created_utc": 1691564595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is anyone using Unity to govern Iceberg tables?", "author_fullname": "t2_s3lpw2dx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Unity catalog on Iceberg", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m4es7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691554154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is anyone using Unity to govern Iceberg tables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m4es7", "is_robot_indexable": true, "report_reasons": null, "author": "nelsonbigetti", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m4es7/using_unity_catalog_on_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m4es7/using_unity_catalog_on_iceberg/", "subreddit_subscribers": 121767, "created_utc": 1691554154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am 17 and an intern at a finch company in England, I have been given a task to create a 'slack watchdog' in which messages for help to a slack channel will be monitored and if no response within an hour an automatic reply will tag a member of the appropriate response team asking them to take a look at the message. Is it possible for any of you to give me a brief overview of how I would do this and/or point me in the direction of some useful things to search (detailed things for search). \n\nThe tools I am using are Airflow and VSCode in python, as in my actual task is to create a DAG which sends these automatic assignment responses.\n\nAny help greatly appreciated!", "author_fullname": "t2_eqvikdnq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overview of how to tackle project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15mirqn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691595550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am 17 and an intern at a finch company in England, I have been given a task to create a &amp;#39;slack watchdog&amp;#39; in which messages for help to a slack channel will be monitored and if no response within an hour an automatic reply will tag a member of the appropriate response team asking them to take a look at the message. Is it possible for any of you to give me a brief overview of how I would do this and/or point me in the direction of some useful things to search (detailed things for search). &lt;/p&gt;\n\n&lt;p&gt;The tools I am using are Airflow and VSCode in python, as in my actual task is to create a DAG which sends these automatic assignment responses.&lt;/p&gt;\n\n&lt;p&gt;Any help greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mirqn", "is_robot_indexable": true, "report_reasons": null, "author": "McSteamy06", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mirqn/overview_of_how_to_tackle_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mirqn/overview_of_how_to_tackle_project/", "subreddit_subscribers": 121767, "created_utc": 1691595550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We use DBT for data transformation. So far we have used Github actions for CICD for model development. We then run the production models in Argo.\n\nWhile Argo has been an okay platform, it is impossible to run models on demand, the lack of data engineers who have extensive Argo experience to maintain and simplify the platform for non-technical users has forced us to consider alternative orchestrators. Besides airflow, one of the orchestrators is Github Actions which we are already using to test PRs before merging with the main branch. It would be an excellent option, but GitHub Actions seem designed for pre-production tasks but I still cannot prove why we should not use it for production dbt run. So I ask, why would you consider GitHub Actions as an orchestrator to run production DBT commands?", "author_fullname": "t2_98970a3e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "would you consider GitHub Actions as an orchestrator to run production DBT commands?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15maawi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691573374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We use DBT for data transformation. So far we have used Github actions for CICD for model development. We then run the production models in Argo.&lt;/p&gt;\n\n&lt;p&gt;While Argo has been an okay platform, it is impossible to run models on demand, the lack of data engineers who have extensive Argo experience to maintain and simplify the platform for non-technical users has forced us to consider alternative orchestrators. Besides airflow, one of the orchestrators is Github Actions which we are already using to test PRs before merging with the main branch. It would be an excellent option, but GitHub Actions seem designed for pre-production tasks but I still cannot prove why we should not use it for production dbt run. So I ask, why would you consider GitHub Actions as an orchestrator to run production DBT commands?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15maawi", "is_robot_indexable": true, "report_reasons": null, "author": "South-Blacksmith-949", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15maawi/would_you_consider_github_actions_as_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15maawi/would_you_consider_github_actions_as_an/", "subreddit_subscribers": 121767, "created_utc": 1691573374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently, I have to manually generate a lot of documentation for data cataloguing and was wondering if there is a tool which can help to generate documentation from code. What's your experience with documentation?", "author_fullname": "t2_dogbygvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tool do you use to generate documentation from your code? Have you figured out a better way to handle documentation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m6eda", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691560353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, I have to manually generate a lot of documentation for data cataloguing and was wondering if there is a tool which can help to generate documentation from code. What&amp;#39;s your experience with documentation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15m6eda", "is_robot_indexable": true, "report_reasons": null, "author": "vinayak_singh_k", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m6eda/what_tool_do_you_use_to_generate_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m6eda/what_tool_do_you_use_to_generate_documentation/", "subreddit_subscribers": 121767, "created_utc": 1691560353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bhpulfr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leveraging web scraping data for dynamic pricing strategies in e-commerce", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15luq4n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VjgsxlUrG_pazdMae9QTaG3YPpHbR-3d57bl2qb9ayA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691529445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "javascript.plainenglish.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://javascript.plainenglish.io/leveraging-web-scraping-for-dynamic-pricing-strategies-for-e-commerce-dba4f813d1e", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?auto=webp&amp;s=f4ce28f571fb0cda3c7f2a661f6a3a2923e958b1", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2dda5e47ff2d4989e9856e206d954dfaf65b8c0f", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1cf81ef3c5ad9c1a4e9385b9dcbb7742055de86", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1caf31760c4778a0c4d62c34a5e18f563cd9d590", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1afcf08ca6054e094c8f2564df66d7f2a49e2ede", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c33c3b8266fb8c296613837facffe25506fa98ec", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=16922483d1cc749069eaa5a42e615896a563008a", "width": 1080, "height": 720}], "variants": {}, "id": "BSFNvAYgJyuJNwJHWBMIOMxmpmFKInElIaXDQoYBMDQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15luq4n", "is_robot_indexable": true, "report_reasons": null, "author": "9millionrainydays_91", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15luq4n/leveraging_web_scraping_data_for_dynamic_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://javascript.plainenglish.io/leveraging-web-scraping-for-dynamic-pricing-strategies-for-e-commerce-dba4f813d1e", "subreddit_subscribers": 121767, "created_utc": 1691529445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How does community identifies if a requirement coming from business is an analytical or transactional ie to be run against an OLTP database or OLAP database.\n\nSecond question is that what is the best way to make business understand that business requirement is served best with right nature of data modeling within a database or tool.\n\nFor example, we have postgresql as OLTP database for our app and ClickHouse as OLAP engine however a requirement is/should not be running against its indifferent database/tool.", "author_fullname": "t2_3fc3u012", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Identify if a business requirement is an analytical or transactional in its technical nature within data warehouse/datalake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mfrwr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691588701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How does community identifies if a requirement coming from business is an analytical or transactional ie to be run against an OLTP database or OLAP database.&lt;/p&gt;\n\n&lt;p&gt;Second question is that what is the best way to make business understand that business requirement is served best with right nature of data modeling within a database or tool.&lt;/p&gt;\n\n&lt;p&gt;For example, we have postgresql as OLTP database for our app and ClickHouse as OLAP engine however a requirement is/should not be running against its indifferent database/tool.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mfrwr", "is_robot_indexable": true, "report_reasons": null, "author": "youareafakenews", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mfrwr/identify_if_a_business_requirement_is_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mfrwr/identify_if_a_business_requirement_is_an/", "subreddit_subscribers": 121767, "created_utc": 1691588701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9k0sxzns1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use Pyo3 to build my first rust app with python binding", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15mebov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Pnc_aqRqNPlPm6MdUHCWiIRfjVrUqiS5H-XrYwXzHPg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691585170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/hkpeaks/pypeaks/tree/main", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?auto=webp&amp;s=7b0c87123c08733216896d673deaddc4e11e264d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cdac72e22e82bdd8ad97b5fb67ab4365ee970362", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a81c143d718186d915b3f49e964b48df132bd6f8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=143ef35cc695738a40645c5e68cbf89202f8a3fd", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9868a6857844a61bf6964cc06403eaace531a082", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0770c58302b234d263e054f40710f38745fd7977", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0ac52e2c770d89d026272478960b8d4a33062efc", "width": 1080, "height": 540}], "variants": {}, "id": "ireCSNiGeP5e7QYWH35eQ5_Ey3lAZ2TCtqaDhLhtyFY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15mebov", "is_robot_indexable": true, "report_reasons": null, "author": "100GB-CSV", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mebov/use_pyo3_to_build_my_first_rust_app_with_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/hkpeaks/pypeaks/tree/main", "subreddit_subscribers": 121767, "created_utc": 1691585170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI will be on holiday from 9 to 30 of August in Columbus.\nI'm not from US, so it's my first time there !\nDo you know some meetups / aperitivo's to meet people working in Data Roles / IT or hackathons for data Analysts ?\n\nI would be happy to connect for a drink for anyone interested.", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE / DS / Data Meetups in Ohio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m7iie", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691564049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI will be on holiday from 9 to 30 of August in Columbus.\nI&amp;#39;m not from US, so it&amp;#39;s my first time there !\nDo you know some meetups / aperitivo&amp;#39;s to meet people working in Data Roles / IT or hackathons for data Analysts ?&lt;/p&gt;\n\n&lt;p&gt;I would be happy to connect for a drink for anyone interested.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15m7iie", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m7iie/de_ds_data_meetups_in_ohio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m7iie/de_ds_data_meetups_in_ohio/", "subreddit_subscribers": 121767, "created_utc": 1691564049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have some dags that fail constantly but recover like an hour later and no data is lost. I am told to ignore this and everything is fine but my gut is telling me this is not the right way to do this...\n\nAm I just being a stickler / don't know what I am talking about or is there something wrong with how we are using airflow and I just don't know how to articulate the problem properly.", "author_fullname": "t2_1sopch0e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intermitten Dag Failure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mhdlx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691592372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have some dags that fail constantly but recover like an hour later and no data is lost. I am told to ignore this and everything is fine but my gut is telling me this is not the right way to do this...&lt;/p&gt;\n\n&lt;p&gt;Am I just being a stickler / don&amp;#39;t know what I am talking about or is there something wrong with how we are using airflow and I just don&amp;#39;t know how to articulate the problem properly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mhdlx", "is_robot_indexable": true, "report_reasons": null, "author": "richphi1618", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mhdlx/intermitten_dag_failure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mhdlx/intermitten_dag_failure/", "subreddit_subscribers": 121767, "created_utc": 1691592372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8thdvssa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jupyter Notebook meets Marsha.ai! \ud83e\udd1d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15mgxd8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/n7HPSaM7KMJokV7acJvx5ZrbjfDSeM_c8sWD1DinX6A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691591340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@aguillenv/jupyter-notebook-meets-marsha-ai-822993868a2e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?auto=webp&amp;s=29e688d269ea498c0f6c0e69ca197d4e06af367c", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=890070be057e4eb647bf08a41f747b8ea6cddebe", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a2cbc35ffc6ea85a9e060980b5e1f3a19cf7e290", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8b861379b16ea4d9f95abf9d13c8232f4296b244", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4d341bcacc070a2c96156586317a354b9c39876", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=db9534e879522a6baf408f1c330aa745235ff3de", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b856a5d03d754d41d6f7d54232445cabe39a2a45", "width": 1080, "height": 720}], "variants": {}, "id": "XaP7BeTbPxZmibZNiGCDQwi44Q03JNzh7KyQo1KOaZQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15mgxd8", "is_robot_indexable": true, "report_reasons": null, "author": "Wide-Alfalfa-700", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mgxd8/jupyter_notebook_meets_marshaai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@aguillenv/jupyter-notebook-meets-marsha-ai-822993868a2e", "subreddit_subscribers": 121767, "created_utc": 1691591340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vx67of8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ultimate dbt Cheat Sheet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15mfqhr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BmZfuPSMpmqPfBK7jVJy46GPbMOEEFEJ9hHM_wRgggk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691588601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datacoves.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://datacoves.com/post/dbt-cheatsheet", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?auto=webp&amp;s=877a8990290912f27a3e8fe27fff96f255bd9585", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77fde2d67be961affcbcc1dbedcee7598f0bd58e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=60df194bcaf3fcf84d4c60322752d92b096ccca3", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2bfa708d8ceebc172620fe49d04ba92f0eeb8f0", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d7caf3fb816aa85080b86ed1a7c9e96cb405a5b", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7201f30b7b60df4c14725cd45646e2fbfab2a8aa", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=97adbe1a5fe1ac04f88e5356202fd6eb9cdccbd5", "width": 1080, "height": 564}], "variants": {}, "id": "_rzD2Rrp77lU7pyoKi6-K0j0h-KIeL9rC__uODDWLuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15mfqhr", "is_robot_indexable": true, "report_reasons": null, "author": "Hot_Map_7868", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mfqhr/ultimate_dbt_cheat_sheet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://datacoves.com/post/dbt-cheatsheet", "subreddit_subscribers": 121767, "created_utc": 1691588601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just did a test with this platform but never heard about it before. Looking to hear about your experience with it", "author_fullname": "t2_729lk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone used Toggl hire before?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15me50n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691584693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just did a test with this platform but never heard about it before. Looking to hear about your experience with it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15me50n", "is_robot_indexable": true, "report_reasons": null, "author": "riclex", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15me50n/anyone_used_toggl_hire_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15me50n/anyone_used_toggl_hire_before/", "subreddit_subscribers": 121767, "created_utc": 1691584693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a  project (a POC, for interviews and to show my GCP skills, for my own git) to calculate the CO2 emissions for individuals based on their use of transportation. And i'm designing the following architecture as it's my first GCP project, I thought that maybe some feedback will help).   \n\n\n\\- Offer : i got the 12 months free offer with 300$ credit\n\n\\- Data Ingestion to Google Cloud Storage :   \nI created a bucket (standard offer) on GCS to consolidate raw data (CO2 consumption data + master data ) from different sources. The C02 data will be fetched by API calls to Google Timeline API  (Cloud function) and stored without transformation to GCS. The master data is just uploaded to GCS for now (not automated as it's a one time ingestion)  \nThe cloud function are lunched by google cloud scheduler for daily uploads. Each call is gathering transportation data for my sample individuals (30 individuals for now) and will consolidate the data for all the users in one JSON file to store on GCP (the return of the api calls is JSON, but idk if i can store it maybe as AVRO or PARQUET for better performances ? also I thought about consolidating the data in one file to not have several files that might slow the DF perfromances afterwards ? what do you think ? )    \n\n\n\\- Data Transformation  \nBased on the bucket's data updated, a Dataflow is lunched to transform the user's data and enrich it with master data and CO2 emissions calculation (basic joins and  map operations)   \nWe have other data flows for master data loading that are lunched as well when new master data files are available ( 1 DF for each dimension table )   \n\n\n\\- Data Load  \nThe data after transformation will be loaded to big query (one fact table , main KPI is CO2 emissions and Dimensions tables : Time, User Information, Geographical information ... etc.)   \n\n\nTables are partitionned by time and clustered by Geographical information / User information (as it'll be used in the queries)   \n\n\nMaterialized tables for TOP C02 Emission per User/Region are available to reduce shuffling and not recalclulate that each time   \n\n\n\\- Data Viz  \nData viz using google data studio for CO2 emissions trends per user/region...etc.  \nand also top CO2 emissions and bottom CO2 emissions   \n\n\nAny views or critics are welcomed as it's my first project on GCP.   \n\n\nMany thanks by advance. ", "author_fullname": "t2_4kn0fb0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First Project on GCP - Feedback on architecture needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mbjf9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691577268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a  project (a POC, for interviews and to show my GCP skills, for my own git) to calculate the CO2 emissions for individuals based on their use of transportation. And i&amp;#39;m designing the following architecture as it&amp;#39;s my first GCP project, I thought that maybe some feedback will help).   &lt;/p&gt;\n\n&lt;p&gt;- Offer : i got the 12 months free offer with 300$ credit&lt;/p&gt;\n\n&lt;p&gt;- Data Ingestion to Google Cloud Storage :&lt;br/&gt;\nI created a bucket (standard offer) on GCS to consolidate raw data (CO2 consumption data + master data ) from different sources. The C02 data will be fetched by API calls to Google Timeline API  (Cloud function) and stored without transformation to GCS. The master data is just uploaded to GCS for now (not automated as it&amp;#39;s a one time ingestion)&lt;br/&gt;\nThe cloud function are lunched by google cloud scheduler for daily uploads. Each call is gathering transportation data for my sample individuals (30 individuals for now) and will consolidate the data for all the users in one JSON file to store on GCP (the return of the api calls is JSON, but idk if i can store it maybe as AVRO or PARQUET for better performances ? also I thought about consolidating the data in one file to not have several files that might slow the DF perfromances afterwards ? what do you think ? )    &lt;/p&gt;\n\n&lt;p&gt;- Data Transformation&lt;br/&gt;\nBased on the bucket&amp;#39;s data updated, a Dataflow is lunched to transform the user&amp;#39;s data and enrich it with master data and CO2 emissions calculation (basic joins and  map operations)&lt;br/&gt;\nWe have other data flows for master data loading that are lunched as well when new master data files are available ( 1 DF for each dimension table )   &lt;/p&gt;\n\n&lt;p&gt;- Data Load&lt;br/&gt;\nThe data after transformation will be loaded to big query (one fact table , main KPI is CO2 emissions and Dimensions tables : Time, User Information, Geographical information ... etc.)   &lt;/p&gt;\n\n&lt;p&gt;Tables are partitionned by time and clustered by Geographical information / User information (as it&amp;#39;ll be used in the queries)   &lt;/p&gt;\n\n&lt;p&gt;Materialized tables for TOP C02 Emission per User/Region are available to reduce shuffling and not recalclulate that each time   &lt;/p&gt;\n\n&lt;p&gt;- Data Viz&lt;br/&gt;\nData viz using google data studio for CO2 emissions trends per user/region...etc.&lt;br/&gt;\nand also top CO2 emissions and bottom CO2 emissions   &lt;/p&gt;\n\n&lt;p&gt;Any views or critics are welcomed as it&amp;#39;s my first project on GCP.   &lt;/p&gt;\n\n&lt;p&gt;Many thanks by advance. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mbjf9", "is_robot_indexable": true, "report_reasons": null, "author": "Ezzarrass", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mbjf9/first_project_on_gcp_feedback_on_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mbjf9/first_project_on_gcp_feedback_on_architecture/", "subreddit_subscribers": 121767, "created_utc": 1691577268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Having looked into Apache Beam, I really like their idea of representing a DAG data pipeline programmatically using PTransforms and PCollections via the [Pipeline API](https://beam.apache.org/documentation/pipelines/design-your-pipeline/#a-basic-pipeline). However in my case, I only ever want to use Spark as my execution platform so don't want to incur the performance cost of Beam's abstractions for supporting both batch and streaming usecases. \n\nIs there any library etc. out there that would allow me to write standard Spark logic using Datasets but programmatically represent my ETL logic in a DAG form using Java or Scala code? The closest I could find is [ML Pipelines](https://spark.apache.org/docs/latest/ml-pipeline.html#example-estimator-transformer-and-param) in Spark but this seems far too closely tied to machine learning rather than general purpose Spark logic.", "author_fullname": "t2_n46ct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Programmatic Spark DAG pipelines in Java/Scala similar to Beam's Pipeline API (but without the additional abstraction) to define workflows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mbe9j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691576827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Having looked into Apache Beam, I really like their idea of representing a DAG data pipeline programmatically using PTransforms and PCollections via the &lt;a href=\"https://beam.apache.org/documentation/pipelines/design-your-pipeline/#a-basic-pipeline\"&gt;Pipeline API&lt;/a&gt;. However in my case, I only ever want to use Spark as my execution platform so don&amp;#39;t want to incur the performance cost of Beam&amp;#39;s abstractions for supporting both batch and streaming usecases. &lt;/p&gt;\n\n&lt;p&gt;Is there any library etc. out there that would allow me to write standard Spark logic using Datasets but programmatically represent my ETL logic in a DAG form using Java or Scala code? The closest I could find is &lt;a href=\"https://spark.apache.org/docs/latest/ml-pipeline.html#example-estimator-transformer-and-param\"&gt;ML Pipelines&lt;/a&gt; in Spark but this seems far too closely tied to machine learning rather than general purpose Spark logic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mbe9j", "is_robot_indexable": true, "report_reasons": null, "author": "Vergo777", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mbe9j/programmatic_spark_dag_pipelines_in_javascala/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mbe9j/programmatic_spark_dag_pipelines_in_javascala/", "subreddit_subscribers": 121767, "created_utc": 1691576827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, I hope you are doing well. I want this post to give an idea to the youngsters and hope to get some feedback for my end on how how to improve my productivity.\n\nI work in a consulting firm and we are trying to help a really old bank to get back on its feet. Although I hate learning tools in legacy companies, I need money so no complaints.\n\nI am responsible for creating tables for dashboard complaints but I am stuck on issues and I was wondering if my problems are normal for industry standards.\n\nI work with PL/SQL, Oracle Data Integrator 12c for data integration and OBIEE for visualizations. This is my first job and I can definitely assure you I am not the top-tier analytical person in the group, barely low to middle. My language skills is the most valuable skill to the company because our customer is foreign to us and I am the only one who can communicate with them. But my lack of experience in these tools (overall Data Engineering) makes my language skills invalid because even though I can talk with them, I don't know what the fuck I should do to make it a reality.\n\n**PERSONAL BACKGROUND AND SELF-REFLECTION**\n\n* I come from a different background although I work hard, I miss some important stuff so everything feels like a cheese with holes in it easily.\n* I mainly studies SQL from online courses, completed some courses and solved some questions online. Whenever I can't write a query, I just ask my colleagues to help me with it, but I don't know how can I improve my SQL while working in this job because SQL is the\n* I don't know which questions to ask about data and tables. So whenever my manager asks me why certain things are taking slower than he expects, I can't give satisfying answers to him\n* Oracle ecosystem has little to no community, where have all Oracle experts gone??\n* I am not the most hardworking person and I like to be a jack of all trades. I believe some % of the issues I am facing are created by my own laziness, yet I am definitely sure it is not the main problem.\n* My manager can't understand my difficulties and blame me for being lazy. I am not gonna lie, there were some days were I looked at the screen and couldn't lift my finger to press a button.\n\n**GENERAL PROBLEMS**\n\n**Working hour difference and Lack of Communication**\n\n* There is only a 1-hour difference but that means I lose 20 hours per month when I have to talk to someone when something is wrong either from my side or customers. And I have to overtime sometimes (with no payment and there is nothing I can do about it.) because the customer is only available during their working hours basically.\n* Nobody starts working as soon as they enter the building right? Of course but I sometimes don't get answers to my questions for hours even damn days.\n\n**Jira inside of Virtual Machines suck**\n\n* Jira doesn't give me notifications so I have to check every damn ticket whether someone commented or updated anything.\n* I didn't check the tickets for 3 weeks now the business guy is on my throat for deadlines. Yaaaaaaayy!\n\n**Lack of Quality Seniors and colleagues.**\n\n* We are a 4-man team, consisting of 3 Junior and 1 Senior.\n* 1st Junior is always busy with other projects and can barely come to our meetings. She has potential but again, is extremely busy. 2nd Junior knows nothing, he is a dumbass who can't edit Excel column lines. 3rd Junior is me with too little experience in the Data field overall but with a decent guide, I can overcome many challenges. About my senior, I am having some difficulties.\n* My Senior DE can't speak English. He claims he has experience over 15 years but he can't do shit without my guidance and me translating the customers' wants to him. I feel like a translator in the job more than a Data Engineer sometimes.\n\n**Lack of Analysis Documents**\n\n* After all these, business side expects me to create tables without providing me with decent analysis documents. The business side expects me to understand the whole context from the previously made tables and dashboards and create the table like I am omniscient. This is my biggest problem.\n\n**VPN Crashes every month**\n\n* Takes at least half a day to solve this issue with the infrastructure team. This is a minor issue but I wanted to point it out.\n\n**Lack of Permissions to Databases/Tables.**\n\n* Even a simple join is quite tedious when I don't have permission. I can't get permissions easily and getting those permissions take days.\n* I don't even have insert and alter permissions. I have to ask the DB admin to insert keys for me in the development environment or I have to drop the table and create it with a script.\n* Calculations can't be checked because even the business side has no permission to check either tables or dashboards. So everything has to be moved between the test and the live environment even for the smallest change and it is crushing my soul.\n\n**Lack of Data in the damn tables**\n\n* You waited for so long for getting those hands dirty but so what? The tables I need to work on have little to no data in the development environment. But the business side insists that the table is full of data baby. I ask them to fill in the data to test the environment but they don't want to do it because the data is large.\n\n**Worst business side can't see the tables/calculations I am creating**\n\n* I create a 99% wrongly calculated table but what happens? Business ppl can't check the calculations because not they don't have access to my test environment. So I ask some guys to move it to live. If it is wrong then go back to step one.\n\nI am thinking to quit my job", "author_fullname": "t2_hecq3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First Data Engineering Job and Reality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mbcrs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691576700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I hope you are doing well. I want this post to give an idea to the youngsters and hope to get some feedback for my end on how how to improve my productivity.&lt;/p&gt;\n\n&lt;p&gt;I work in a consulting firm and we are trying to help a really old bank to get back on its feet. Although I hate learning tools in legacy companies, I need money so no complaints.&lt;/p&gt;\n\n&lt;p&gt;I am responsible for creating tables for dashboard complaints but I am stuck on issues and I was wondering if my problems are normal for industry standards.&lt;/p&gt;\n\n&lt;p&gt;I work with PL/SQL, Oracle Data Integrator 12c for data integration and OBIEE for visualizations. This is my first job and I can definitely assure you I am not the top-tier analytical person in the group, barely low to middle. My language skills is the most valuable skill to the company because our customer is foreign to us and I am the only one who can communicate with them. But my lack of experience in these tools (overall Data Engineering) makes my language skills invalid because even though I can talk with them, I don&amp;#39;t know what the fuck I should do to make it a reality.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;PERSONAL BACKGROUND AND SELF-REFLECTION&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I come from a different background although I work hard, I miss some important stuff so everything feels like a cheese with holes in it easily.&lt;/li&gt;\n&lt;li&gt;I mainly studies SQL from online courses, completed some courses and solved some questions online. Whenever I can&amp;#39;t write a query, I just ask my colleagues to help me with it, but I don&amp;#39;t know how can I improve my SQL while working in this job because SQL is the&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t know which questions to ask about data and tables. So whenever my manager asks me why certain things are taking slower than he expects, I can&amp;#39;t give satisfying answers to him&lt;/li&gt;\n&lt;li&gt;Oracle ecosystem has little to no community, where have all Oracle experts gone??&lt;/li&gt;\n&lt;li&gt;I am not the most hardworking person and I like to be a jack of all trades. I believe some % of the issues I am facing are created by my own laziness, yet I am definitely sure it is not the main problem.&lt;/li&gt;\n&lt;li&gt;My manager can&amp;#39;t understand my difficulties and blame me for being lazy. I am not gonna lie, there were some days were I looked at the screen and couldn&amp;#39;t lift my finger to press a button.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;GENERAL PROBLEMS&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Working hour difference and Lack of Communication&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;There is only a 1-hour difference but that means I lose 20 hours per month when I have to talk to someone when something is wrong either from my side or customers. And I have to overtime sometimes (with no payment and there is nothing I can do about it.) because the customer is only available during their working hours basically.&lt;/li&gt;\n&lt;li&gt;Nobody starts working as soon as they enter the building right? Of course but I sometimes don&amp;#39;t get answers to my questions for hours even damn days.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Jira inside of Virtual Machines suck&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Jira doesn&amp;#39;t give me notifications so I have to check every damn ticket whether someone commented or updated anything.&lt;/li&gt;\n&lt;li&gt;I didn&amp;#39;t check the tickets for 3 weeks now the business guy is on my throat for deadlines. Yaaaaaaayy!&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Lack of Quality Seniors and colleagues.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We are a 4-man team, consisting of 3 Junior and 1 Senior.&lt;/li&gt;\n&lt;li&gt;1st Junior is always busy with other projects and can barely come to our meetings. She has potential but again, is extremely busy. 2nd Junior knows nothing, he is a dumbass who can&amp;#39;t edit Excel column lines. 3rd Junior is me with too little experience in the Data field overall but with a decent guide, I can overcome many challenges. About my senior, I am having some difficulties.&lt;/li&gt;\n&lt;li&gt;My Senior DE can&amp;#39;t speak English. He claims he has experience over 15 years but he can&amp;#39;t do shit without my guidance and me translating the customers&amp;#39; wants to him. I feel like a translator in the job more than a Data Engineer sometimes.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Lack of Analysis Documents&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;After all these, business side expects me to create tables without providing me with decent analysis documents. The business side expects me to understand the whole context from the previously made tables and dashboards and create the table like I am omniscient. This is my biggest problem.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;VPN Crashes every month&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Takes at least half a day to solve this issue with the infrastructure team. This is a minor issue but I wanted to point it out.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Lack of Permissions to Databases/Tables.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Even a simple join is quite tedious when I don&amp;#39;t have permission. I can&amp;#39;t get permissions easily and getting those permissions take days.&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t even have insert and alter permissions. I have to ask the DB admin to insert keys for me in the development environment or I have to drop the table and create it with a script.&lt;/li&gt;\n&lt;li&gt;Calculations can&amp;#39;t be checked because even the business side has no permission to check either tables or dashboards. So everything has to be moved between the test and the live environment even for the smallest change and it is crushing my soul.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Lack of Data in the damn tables&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;You waited for so long for getting those hands dirty but so what? The tables I need to work on have little to no data in the development environment. But the business side insists that the table is full of data baby. I ask them to fill in the data to test the environment but they don&amp;#39;t want to do it because the data is large.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Worst business side can&amp;#39;t see the tables/calculations I am creating&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I create a 99% wrongly calculated table but what happens? Business ppl can&amp;#39;t check the calculations because not they don&amp;#39;t have access to my test environment. So I ask some guys to move it to live. If it is wrong then go back to step one.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am thinking to quit my job&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mbcrs", "is_robot_indexable": true, "report_reasons": null, "author": "rayman903", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mbcrs/first_data_engineering_job_and_reality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mbcrs/first_data_engineering_job_and_reality/", "subreddit_subscribers": 121767, "created_utc": 1691576700.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}