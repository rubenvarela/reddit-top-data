{"kind": "Listing", "data": {"after": "t3_15me50n", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**My background:**\n\nCurrently I'm a senior data analyst, and I'm one of those people that works in the department where the data analyst does just about everything. I do ETL, reporting, bi stuff so piping data from Google BigQuery into stuff like Power BI, looker studio, AWS, snowflake, using Python of course. I spend more time typing in SQL than I do in English in emails. I find myself doing recreational projects with Python and SQL quite often, for example this week I wrote in API that retrieves data from Kaggle, cleans it in pandas, loads it into BigQuery, also loads it into snowflake, Cassandra, Then using even more Python, retrieves some of the data using SQL. \n\n\n**Question:**\n\nHow do I know if I'm ready for a data engineer position? Will I ever be ready? I was contacted buy a recruiter for a couple positions. The one I applied to is data analyst, but I asked about the data engineer position because the job description said almost nothing about it. She said it was a little bit more technical than what I've probably done, preceded to list off basically everything I've already been doing. Said I have to be comfortable doing object-oriented programming in Python (didn't know they used objects in data engineering). Said that it's a lot more of the piping data, working in AWS data sources, snowflake, Hadoop, etc... This is all stuff that sounds insanely complex and technical but here's the thing.... **How do I know if this is stuff that I'm capable of learning on the job or doing?** Like no, of course I haven't set up a data source from scratch with 300 million rows or a terabyte of data myself. I can't just go and make a 300 million row data set on my PC at home. No matter how much I want to, It would be next to impossible for me to simulate the work that a data engineer actually does on the job in a personal setting. Because any work I do as a data engineer will be in a live environment for a big company with important deadlines and I don't have that right now.", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Honest question: How do I know if I'm good enough to be a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15lr89o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691521667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;My background:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m a senior data analyst, and I&amp;#39;m one of those people that works in the department where the data analyst does just about everything. I do ETL, reporting, bi stuff so piping data from Google BigQuery into stuff like Power BI, looker studio, AWS, snowflake, using Python of course. I spend more time typing in SQL than I do in English in emails. I find myself doing recreational projects with Python and SQL quite often, for example this week I wrote in API that retrieves data from Kaggle, cleans it in pandas, loads it into BigQuery, also loads it into snowflake, Cassandra, Then using even more Python, retrieves some of the data using SQL. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;How do I know if I&amp;#39;m ready for a data engineer position? Will I ever be ready? I was contacted buy a recruiter for a couple positions. The one I applied to is data analyst, but I asked about the data engineer position because the job description said almost nothing about it. She said it was a little bit more technical than what I&amp;#39;ve probably done, preceded to list off basically everything I&amp;#39;ve already been doing. Said I have to be comfortable doing object-oriented programming in Python (didn&amp;#39;t know they used objects in data engineering). Said that it&amp;#39;s a lot more of the piping data, working in AWS data sources, snowflake, Hadoop, etc... This is all stuff that sounds insanely complex and technical but here&amp;#39;s the thing.... &lt;strong&gt;How do I know if this is stuff that I&amp;#39;m capable of learning on the job or doing?&lt;/strong&gt; Like no, of course I haven&amp;#39;t set up a data source from scratch with 300 million rows or a terabyte of data myself. I can&amp;#39;t just go and make a 300 million row data set on my PC at home. No matter how much I want to, It would be next to impossible for me to simulate the work that a data engineer actually does on the job in a personal setting. Because any work I do as a data engineer will be in a live environment for a big company with important deadlines and I don&amp;#39;t have that right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15lr89o", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15lr89o/honest_question_how_do_i_know_if_im_good_enough/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15lr89o/honest_question_how_do_i_know_if_im_good_enough/", "subreddit_subscribers": 121777, "created_utc": 1691521667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Consultants have forced on us a truly terrible data model for our marketing warehouse. Tables and columns are named with inscrutable acronyms, there\u2019s no clarity on how entities relate to one another or map to business processes, and the idea of a meaningful table grain is but a dream (they like to make new tables by grouping by dozens of unrelated attributes).\n\nIt\u2019s a mess and the most infuriating part as an ETL engineer is that I can\u2019t get that across to the business side because whenever I say \u201cproper modeling standards\u201d they hear \u201cyou\u2019re going to make me wait longer for new reports\u201d. The only way I can think to prove how bad it is would be to redo the whole design myself to give them a side-by-side comparison, but that\u2019s months of work. And of course when the data quality goes to hell my team is the one that\u2019ll take the blame.\n\nAny suggestions or stories of similar situations?", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prove a data model is bad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ltzr9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691527832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Consultants have forced on us a truly terrible data model for our marketing warehouse. Tables and columns are named with inscrutable acronyms, there\u2019s no clarity on how entities relate to one another or map to business processes, and the idea of a meaningful table grain is but a dream (they like to make new tables by grouping by dozens of unrelated attributes).&lt;/p&gt;\n\n&lt;p&gt;It\u2019s a mess and the most infuriating part as an ETL engineer is that I can\u2019t get that across to the business side because whenever I say \u201cproper modeling standards\u201d they hear \u201cyou\u2019re going to make me wait longer for new reports\u201d. The only way I can think to prove how bad it is would be to redo the whole design myself to give them a side-by-side comparison, but that\u2019s months of work. And of course when the data quality goes to hell my team is the one that\u2019ll take the blame.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or stories of similar situations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ltzr9", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ltzr9/prove_a_data_model_is_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ltzr9/prove_a_data_model_is_bad/", "subreddit_subscribers": 121777, "created_utc": 1691527832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just started a new job and am shocked at the state of the dbt project. I've no idea whether I am used to too high standards and I am overreacting. Would appreciate to hear some other stories of dbt at your company!\n\nSo why it is so bad, we're two analytics engineers and 1 data engineer. The data engineer mainly manages airflow and databricks so they hardly work with dbt. So it's basically two people. And we have the following:\n\n- 600+ models\n\n- no tests for most of the models\n\n- lineage is a mess. One of the core tables has 55 parents and 150 children. Circular references all over the place.\n\n- everything in the mart is materialized as a table. They run those tables multiple times a day. Costs have been increasing at a steady pace ofcourse.\n\n- they use schemas to denote topics. The project.yml contains configs for each folder to materialize it to the correct schema. The file is 200+ lines long as a consequence.\n\nBtw they managed to get to this state in less than a year :p\n\nOh and they are migrating to a new bi tool with deadline end of October. Work hasn't even started on that. So should I run? :P\n\nEdit: fixed formatting", "author_fullname": "t2_2ol209b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is our dbt project as bad as I think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mhunt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691594444.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691593433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started a new job and am shocked at the state of the dbt project. I&amp;#39;ve no idea whether I am used to too high standards and I am overreacting. Would appreciate to hear some other stories of dbt at your company!&lt;/p&gt;\n\n&lt;p&gt;So why it is so bad, we&amp;#39;re two analytics engineers and 1 data engineer. The data engineer mainly manages airflow and databricks so they hardly work with dbt. So it&amp;#39;s basically two people. And we have the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;600+ models&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;no tests for most of the models&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;lineage is a mess. One of the core tables has 55 parents and 150 children. Circular references all over the place.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;everything in the mart is materialized as a table. They run those tables multiple times a day. Costs have been increasing at a steady pace ofcourse.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;they use schemas to denote topics. The project.yml contains configs for each folder to materialize it to the correct schema. The file is 200+ lines long as a consequence.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Btw they managed to get to this state in less than a year :p&lt;/p&gt;\n\n&lt;p&gt;Oh and they are migrating to a new bi tool with deadline end of October. Work hasn&amp;#39;t even started on that. So should I run? :P&lt;/p&gt;\n\n&lt;p&gt;Edit: fixed formatting&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mhunt", "is_robot_indexable": true, "report_reasons": null, "author": "snackeloni", "discussion_type": null, "num_comments": 67, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mhunt/is_our_dbt_project_as_bad_as_i_think/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mhunt/is_our_dbt_project_as_bad_as_i_think/", "subreddit_subscribers": 121777, "created_utc": 1691593433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, changed the company a few months ago and it seems like this one offers study days + full pay for workshops, certifications, online courses and so on.\n\nI\u2019m really looking to make good use of these opportunities, that\u2019s why I\u2019m looking for some workshop recommendations to develop myself as a data engineer. I am pretty interested in backend architecture for data systems(mostly related to Azure since that\u2019s what my company is using to host all their data architecture). \n\nBut If you guys know any other good data engineering workshops related to Data Engineering as a whole, please let me know.", "author_fullname": "t2_4lcvdsdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Online workshops for getting better at Data Engineering Backend/Datawarehouse architectures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m9ab4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691569983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, changed the company a few months ago and it seems like this one offers study days + full pay for workshops, certifications, online courses and so on.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m really looking to make good use of these opportunities, that\u2019s why I\u2019m looking for some workshop recommendations to develop myself as a data engineer. I am pretty interested in backend architecture for data systems(mostly related to Azure since that\u2019s what my company is using to host all their data architecture). &lt;/p&gt;\n\n&lt;p&gt;But If you guys know any other good data engineering workshops related to Data Engineering as a whole, please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m9ab4", "is_robot_indexable": true, "report_reasons": null, "author": "Emotional_Key", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m9ab4/online_workshops_for_getting_better_at_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m9ab4/online_workshops_for_getting_better_at_data/", "subreddit_subscribers": 121777, "created_utc": 1691569983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I have been creating data entry apps to send data into a sql database using power apps but having the premium license for sql connections is expensive for my organization. Does anyone know about good, cheaper alternatives to power apps for data entry? Thanks.", "author_fullname": "t2_6j5e93w9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternatives to powerapps for data entry into sql", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15madgt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691573595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I have been creating data entry apps to send data into a sql database using power apps but having the premium license for sql connections is expensive for my organization. Does anyone know about good, cheaper alternatives to power apps for data entry? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15madgt", "is_robot_indexable": true, "report_reasons": null, "author": "arachnarus96", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15madgt/alternatives_to_powerapps_for_data_entry_into_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15madgt/alternatives_to_powerapps_for_data_entry_into_sql/", "subreddit_subscribers": 121777, "created_utc": 1691573595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fwerb2uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Virtual Data Builds: A data warehouse environment for every Git commit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15mctop", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nR_BTR4yVxasfkKNa10X80MIwQ7aeeJ3Q6MG2-BSWBI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691581102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "y42.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.y42.com/blog/virtual-data-builds-one-data-warehouse-environment-for-every-git-commit/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?auto=webp&amp;s=dfe5baa7e55b0fdeafdd8e55ceea1f41e8bb2575", "width": 2160, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=220afd6e3120c0aad0c5a461d4b5772d0ab8243d", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d14cb37959937ca4fb686bd8de2b82c6fcf496e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2a51dfa134189b445a11664b6909846abde9a9a8", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8eac2eeda830983ca6b8fbf6f41969c9ea7a3259", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dc76ee53527828db8c839c838aaebe3675c5dc52", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/g40zcc1h_89-eYZP_Czi5ui3T0vkq_N__64_QHEYTHw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a941f122abdb5a72cbe93bfb04a56e7bd369c808", "width": 1080, "height": 720}], "variants": {}, "id": "TE7uqwVe35pQ_NYMKSpfU5YX8jXz0cwr0p_FDEMXmYs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15mctop", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant-Guidance599", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mctop/virtual_data_builds_a_data_warehouse_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.y42.com/blog/virtual-data-builds-one-data-warehouse-environment-for-every-git-commit/", "subreddit_subscribers": 121777, "created_utc": 1691581102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are considering a code assistance tool (co-pilot) for our team but are not sure if it will help us as claimed. We use notebooks and wondering if anyone has any experience with these kinds of tools. ", "author_fullname": "t2_dogbygvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your experience with code assistant (co-pilot)? What are the challenges?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m57ur", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691556625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are considering a code assistance tool (co-pilot) for our team but are not sure if it will help us as claimed. We use notebooks and wondering if anyone has any experience with these kinds of tools. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m57ur", "is_robot_indexable": true, "report_reasons": null, "author": "vinayak_singh_k", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m57ur/what_is_your_experience_with_code_assistant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m57ur/what_is_your_experience_with_code_assistant/", "subreddit_subscribers": 121777, "created_utc": 1691556625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve heard some people mention stipends for additional training and using that for O\u2019Reilly subscriptions etc. but how common is that or any support from your employer for professional development in general?", "author_fullname": "t2_71weyfry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it common for companies to not offer any professional development?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m4n11", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691554842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve heard some people mention stipends for additional training and using that for O\u2019Reilly subscriptions etc. but how common is that or any support from your employer for professional development in general?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m4n11", "is_robot_indexable": true, "report_reasons": null, "author": "DrunkenWhaler136", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m4n11/is_it_common_for_companies_to_not_offer_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m4n11/is_it_common_for_companies_to_not_offer_any/", "subreddit_subscribers": 121777, "created_utc": 1691554842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So we have a pretty standard IoT setup, with sensor data being stored on Timescale. We pull that data from a third party API, that only reports data for sensors when there's a change in value. \n\nOur operations require consistent 5-minute buckets. We achieve this by using Timescale 's bucketing together with carrying forward the last observation. \n\nThis breaks down however when there is an outage, as in that case we don't want to forward fill but instead not have any buckets at all. \n\nIt seems like it would be a common problem to have, how would you deal with this?", "author_fullname": "t2_mui57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you deal with missing data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m7opg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691564595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we have a pretty standard IoT setup, with sensor data being stored on Timescale. We pull that data from a third party API, that only reports data for sensors when there&amp;#39;s a change in value. &lt;/p&gt;\n\n&lt;p&gt;Our operations require consistent 5-minute buckets. We achieve this by using Timescale &amp;#39;s bucketing together with carrying forward the last observation. &lt;/p&gt;\n\n&lt;p&gt;This breaks down however when there is an outage, as in that case we don&amp;#39;t want to forward fill but instead not have any buckets at all. &lt;/p&gt;\n\n&lt;p&gt;It seems like it would be a common problem to have, how would you deal with this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m7opg", "is_robot_indexable": true, "report_reasons": null, "author": "georgesdoe", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m7opg/how_do_you_deal_with_missing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m7opg/how_do_you_deal_with_missing_data/", "subreddit_subscribers": 121777, "created_utc": 1691564595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is anyone using Unity to govern Iceberg tables?", "author_fullname": "t2_s3lpw2dx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Unity catalog on Iceberg", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m4es7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691554154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is anyone using Unity to govern Iceberg tables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15m4es7", "is_robot_indexable": true, "report_reasons": null, "author": "nelsonbigetti", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m4es7/using_unity_catalog_on_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m4es7/using_unity_catalog_on_iceberg/", "subreddit_subscribers": 121777, "created_utc": 1691554154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am 17 and an intern at a finch company in England, I have been given a task to create a 'slack watchdog' in which messages for help to a slack channel will be monitored and if no response within an hour an automatic reply will tag a member of the appropriate response team asking them to take a look at the message. Is it possible for any of you to give me a brief overview of how I would do this and/or point me in the direction of some useful things to search (detailed things for search). \n\nThe tools I am using are Airflow and VSCode in python, as in my actual task is to create a DAG which sends these automatic assignment responses.\n\nAny help greatly appreciated!", "author_fullname": "t2_eqvikdnq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overview of how to tackle project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mirqn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691595550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am 17 and an intern at a finch company in England, I have been given a task to create a &amp;#39;slack watchdog&amp;#39; in which messages for help to a slack channel will be monitored and if no response within an hour an automatic reply will tag a member of the appropriate response team asking them to take a look at the message. Is it possible for any of you to give me a brief overview of how I would do this and/or point me in the direction of some useful things to search (detailed things for search). &lt;/p&gt;\n\n&lt;p&gt;The tools I am using are Airflow and VSCode in python, as in my actual task is to create a DAG which sends these automatic assignment responses.&lt;/p&gt;\n\n&lt;p&gt;Any help greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mirqn", "is_robot_indexable": true, "report_reasons": null, "author": "McSteamy06", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mirqn/overview_of_how_to_tackle_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mirqn/overview_of_how_to_tackle_project/", "subreddit_subscribers": 121777, "created_utc": 1691595550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How does community identifies if a requirement coming from business is an analytical or transactional ie to be run against an OLTP database or OLAP database.\n\nSecond question is that what is the best way to make business understand that business requirement is served best with right nature of data modeling within a database or tool.\n\nFor example, we have postgresql as OLTP database for our app and ClickHouse as OLAP engine however a requirement is/should not be running against its indifferent database/tool.", "author_fullname": "t2_3fc3u012", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Identify if a business requirement is an analytical or transactional in its technical nature within data warehouse/datalake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mfrwr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691588701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How does community identifies if a requirement coming from business is an analytical or transactional ie to be run against an OLTP database or OLAP database.&lt;/p&gt;\n\n&lt;p&gt;Second question is that what is the best way to make business understand that business requirement is served best with right nature of data modeling within a database or tool.&lt;/p&gt;\n\n&lt;p&gt;For example, we have postgresql as OLTP database for our app and ClickHouse as OLAP engine however a requirement is/should not be running against its indifferent database/tool.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mfrwr", "is_robot_indexable": true, "report_reasons": null, "author": "youareafakenews", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mfrwr/identify_if_a_business_requirement_is_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mfrwr/identify_if_a_business_requirement_is_an/", "subreddit_subscribers": 121777, "created_utc": 1691588701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've just started a new job where part of the job is some data engineering. I don't have any work experience in that, but I know what I want from an analysis/reporting perspective. My employer knows this, so I have time to figure things out.\n\nSince I have background in data analysis and reporting I'm pretty good with SQL and have some limited Python knowledge, but that is about it.\n\nThe data landscape is not very complex here, with only a couple of source applications that don't spit out that much data. Currently most of the data is dumped directly into BQ tables using Fivetran. After that there are some transformations to create tables that are used for analysis. However its basically a SCD1 solution, so its not possible to do historical analysis. At my previous job the date warehouse was in Oracle with SCD2 implemented. Since historical data is a must this is one of the things I want to fix, but its not clear to me what the best practice is for BigQuery specifically. Do I work towards an SCD2 implementation (I saw it used as an example use case for Dataform in the Google  documentation), or do I do something else (I saw a blogpost saying to snapshot all dimensional daily and put it in a partitioned table)? Either works for me from a data analysis perspective,  but what are your thoughts on this?", "author_fullname": "t2_19cg4j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle SCD in BigQuery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mag21", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691573853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just started a new job where part of the job is some data engineering. I don&amp;#39;t have any work experience in that, but I know what I want from an analysis/reporting perspective. My employer knows this, so I have time to figure things out.&lt;/p&gt;\n\n&lt;p&gt;Since I have background in data analysis and reporting I&amp;#39;m pretty good with SQL and have some limited Python knowledge, but that is about it.&lt;/p&gt;\n\n&lt;p&gt;The data landscape is not very complex here, with only a couple of source applications that don&amp;#39;t spit out that much data. Currently most of the data is dumped directly into BQ tables using Fivetran. After that there are some transformations to create tables that are used for analysis. However its basically a SCD1 solution, so its not possible to do historical analysis. At my previous job the date warehouse was in Oracle with SCD2 implemented. Since historical data is a must this is one of the things I want to fix, but its not clear to me what the best practice is for BigQuery specifically. Do I work towards an SCD2 implementation (I saw it used as an example use case for Dataform in the Google  documentation), or do I do something else (I saw a blogpost saying to snapshot all dimensional daily and put it in a partitioned table)? Either works for me from a data analysis perspective,  but what are your thoughts on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mag21", "is_robot_indexable": true, "report_reasons": null, "author": "KoeiNL", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mag21/how_to_handle_scd_in_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mag21/how_to_handle_scd_in_bigquery/", "subreddit_subscribers": 121777, "created_utc": 1691573853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We use DBT for data transformation. So far we have used Github actions for CICD for model development. We then run the production models in Argo.\n\nWhile Argo has been an okay platform, it is impossible to run models on demand, the lack of data engineers who have extensive Argo experience to maintain and simplify the platform for non-technical users has forced us to consider alternative orchestrators. Besides airflow, one of the orchestrators is Github Actions which we are already using to test PRs before merging with the main branch. It would be an excellent option, but GitHub Actions seem designed for pre-production tasks but I still cannot prove why we should not use it for production dbt run. So I ask, why would you consider GitHub Actions as an orchestrator to run production DBT commands?", "author_fullname": "t2_98970a3e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "would you consider GitHub Actions as an orchestrator to run production DBT commands?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15maawi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691573374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We use DBT for data transformation. So far we have used Github actions for CICD for model development. We then run the production models in Argo.&lt;/p&gt;\n\n&lt;p&gt;While Argo has been an okay platform, it is impossible to run models on demand, the lack of data engineers who have extensive Argo experience to maintain and simplify the platform for non-technical users has forced us to consider alternative orchestrators. Besides airflow, one of the orchestrators is Github Actions which we are already using to test PRs before merging with the main branch. It would be an excellent option, but GitHub Actions seem designed for pre-production tasks but I still cannot prove why we should not use it for production dbt run. So I ask, why would you consider GitHub Actions as an orchestrator to run production DBT commands?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15maawi", "is_robot_indexable": true, "report_reasons": null, "author": "South-Blacksmith-949", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15maawi/would_you_consider_github_actions_as_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15maawi/would_you_consider_github_actions_as_an/", "subreddit_subscribers": 121777, "created_utc": 1691573374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently, I have to manually generate a lot of documentation for data cataloguing and was wondering if there is a tool which can help to generate documentation from code. What's your experience with documentation?", "author_fullname": "t2_dogbygvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tool do you use to generate documentation from your code? Have you figured out a better way to handle documentation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m6eda", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691560353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, I have to manually generate a lot of documentation for data cataloguing and was wondering if there is a tool which can help to generate documentation from code. What&amp;#39;s your experience with documentation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15m6eda", "is_robot_indexable": true, "report_reasons": null, "author": "vinayak_singh_k", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m6eda/what_tool_do_you_use_to_generate_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m6eda/what_tool_do_you_use_to_generate_documentation/", "subreddit_subscribers": 121777, "created_utc": 1691560353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bhpulfr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leveraging web scraping data for dynamic pricing strategies in e-commerce", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15luq4n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VjgsxlUrG_pazdMae9QTaG3YPpHbR-3d57bl2qb9ayA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691529445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "javascript.plainenglish.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://javascript.plainenglish.io/leveraging-web-scraping-for-dynamic-pricing-strategies-for-e-commerce-dba4f813d1e", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?auto=webp&amp;s=f4ce28f571fb0cda3c7f2a661f6a3a2923e958b1", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2dda5e47ff2d4989e9856e206d954dfaf65b8c0f", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1cf81ef3c5ad9c1a4e9385b9dcbb7742055de86", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1caf31760c4778a0c4d62c34a5e18f563cd9d590", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1afcf08ca6054e094c8f2564df66d7f2a49e2ede", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c33c3b8266fb8c296613837facffe25506fa98ec", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/rfXk3lcyI0P_63HgUV__uO5oHgKpYt31leyF5zsVKe0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=16922483d1cc749069eaa5a42e615896a563008a", "width": 1080, "height": 720}], "variants": {}, "id": "BSFNvAYgJyuJNwJHWBMIOMxmpmFKInElIaXDQoYBMDQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15luq4n", "is_robot_indexable": true, "report_reasons": null, "author": "9millionrainydays_91", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15luq4n/leveraging_web_scraping_data_for_dynamic_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://javascript.plainenglish.io/leveraging-web-scraping-for-dynamic-pricing-strategies-for-e-commerce-dba4f813d1e", "subreddit_subscribers": 121777, "created_utc": 1691529445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got placed on a Data engineering team as a part of a rotational development program at my company. \n\nI\u2019m noticing that everyone on my team has years of experience (5-20) and that the least experienced people have 5-7 YOE. \n\nI\u2019m just starting out in tech, with only 6 months of professional backend engineering experience (JVM, Kafka, Postgres etc). My bachelor degree is non-CS engineering. \n\nAm I going to have a really difficult time making a career in DE because I don\u2019t have other SWE experience?\n\nI\u2019m willing to work hard and master the fundamentals in my own time outside of work, but I\u2019m scared that if I lose my current job, no other company will hire me for DE roles as junior positions are very rare. \n\nAt the same time, DE feels so niche. I don\u2019t know if the skills I develop here will apply to other backend dev jobs. What can I do to stay broadly employable?\n\nShould I pursue some cloud certification?", "author_fullname": "t2_vmcasqim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE wrong path for beginners?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15mlhz8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691601657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got placed on a Data engineering team as a part of a rotational development program at my company. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m noticing that everyone on my team has years of experience (5-20) and that the least experienced people have 5-7 YOE. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m just starting out in tech, with only 6 months of professional backend engineering experience (JVM, Kafka, Postgres etc). My bachelor degree is non-CS engineering. &lt;/p&gt;\n\n&lt;p&gt;Am I going to have a really difficult time making a career in DE because I don\u2019t have other SWE experience?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m willing to work hard and master the fundamentals in my own time outside of work, but I\u2019m scared that if I lose my current job, no other company will hire me for DE roles as junior positions are very rare. &lt;/p&gt;\n\n&lt;p&gt;At the same time, DE feels so niche. I don\u2019t know if the skills I develop here will apply to other backend dev jobs. What can I do to stay broadly employable?&lt;/p&gt;\n\n&lt;p&gt;Should I pursue some cloud certification?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15mlhz8", "is_robot_indexable": true, "report_reasons": null, "author": "aaloo_chaat", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mlhz8/de_wrong_path_for_beginners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mlhz8/de_wrong_path_for_beginners/", "subreddit_subscribers": 121777, "created_utc": 1691601657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9k0sxzns1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use Pyo3 to build my first rust app with python binding", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15mebov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Pnc_aqRqNPlPm6MdUHCWiIRfjVrUqiS5H-XrYwXzHPg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691585170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/hkpeaks/pypeaks/tree/main", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?auto=webp&amp;s=7b0c87123c08733216896d673deaddc4e11e264d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cdac72e22e82bdd8ad97b5fb67ab4365ee970362", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a81c143d718186d915b3f49e964b48df132bd6f8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=143ef35cc695738a40645c5e68cbf89202f8a3fd", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9868a6857844a61bf6964cc06403eaace531a082", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0770c58302b234d263e054f40710f38745fd7977", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/_sMPnWGXUDWe1kX6tMoC4-2Y58ns64LtVOnsc35-8_g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0ac52e2c770d89d026272478960b8d4a33062efc", "width": 1080, "height": 540}], "variants": {}, "id": "ireCSNiGeP5e7QYWH35eQ5_Ey3lAZ2TCtqaDhLhtyFY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15mebov", "is_robot_indexable": true, "report_reasons": null, "author": "100GB-CSV", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mebov/use_pyo3_to_build_my_first_rust_app_with_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/hkpeaks/pypeaks/tree/main", "subreddit_subscribers": 121777, "created_utc": 1691585170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI will be on holiday from 9 to 30 of August in Columbus.\nI'm not from US, so it's my first time there !\nDo you know some meetups / aperitivo's to meet people working in Data Roles / IT or hackathons for data Analysts ?\n\nI would be happy to connect for a drink for anyone interested.", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE / DS / Data Meetups in Ohio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15m7iie", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691564049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI will be on holiday from 9 to 30 of August in Columbus.\nI&amp;#39;m not from US, so it&amp;#39;s my first time there !\nDo you know some meetups / aperitivo&amp;#39;s to meet people working in Data Roles / IT or hackathons for data Analysts ?&lt;/p&gt;\n\n&lt;p&gt;I would be happy to connect for a drink for anyone interested.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15m7iie", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15m7iie/de_ds_data_meetups_in_ohio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15m7iie/de_ds_data_meetups_in_ohio/", "subreddit_subscribers": 121777, "created_utc": 1691564049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone here joined any professional organizations like ACM, SWE etc? \nAny groups focusing on DE?", "author_fullname": "t2_vmcasqim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Professional organizations for DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15mmf0q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691603665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone here joined any professional organizations like ACM, SWE etc? \nAny groups focusing on DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mmf0q", "is_robot_indexable": true, "report_reasons": null, "author": "aaloo_chaat", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mmf0q/professional_organizations_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mmf0q/professional_organizations_for_de/", "subreddit_subscribers": 121777, "created_utc": 1691603665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to generate new column on a SQL table dynamically as per the incoming CSV file scheme change? \n\nFor ex: today I get a CSV file with 10 columns, tomorrow I will be getting 12 columns.. wants to design ADF dataflow to handle this situation without any code change \n\nWanted get this newly available 2 columns in the CSV to be created in SQL table dynamically, any examples / video links appreciated", "author_fullname": "t2_va6si3w6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADF - Schema drift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15mlukv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691602422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to generate new column on a SQL table dynamically as per the incoming CSV file scheme change? &lt;/p&gt;\n\n&lt;p&gt;For ex: today I get a CSV file with 10 columns, tomorrow I will be getting 12 columns.. wants to design ADF dataflow to handle this situation without any code change &lt;/p&gt;\n\n&lt;p&gt;Wanted get this newly available 2 columns in the CSV to be created in SQL table dynamically, any examples / video links appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15mlukv", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Pick_8431", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mlukv/adf_schema_drift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mlukv/adf_schema_drift/", "subreddit_subscribers": 121777, "created_utc": 1691602422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have some dags that fail constantly but recover like an hour later and no data is lost. I am told to ignore this and everything is fine but my gut is telling me this is not the right way to do this...\n\nAm I just being a stickler / don't know what I am talking about or is there something wrong with how we are using airflow and I just don't know how to articulate the problem properly.", "author_fullname": "t2_1sopch0e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intermitten Dag Failure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15mhdlx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691592372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have some dags that fail constantly but recover like an hour later and no data is lost. I am told to ignore this and everything is fine but my gut is telling me this is not the right way to do this...&lt;/p&gt;\n\n&lt;p&gt;Am I just being a stickler / don&amp;#39;t know what I am talking about or is there something wrong with how we are using airflow and I just don&amp;#39;t know how to articulate the problem properly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15mhdlx", "is_robot_indexable": true, "report_reasons": null, "author": "richphi1618", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mhdlx/intermitten_dag_failure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15mhdlx/intermitten_dag_failure/", "subreddit_subscribers": 121777, "created_utc": 1691592372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8thdvssa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jupyter Notebook meets Marsha.ai! \ud83e\udd1d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15mgxd8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/n7HPSaM7KMJokV7acJvx5ZrbjfDSeM_c8sWD1DinX6A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691591340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@aguillenv/jupyter-notebook-meets-marsha-ai-822993868a2e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?auto=webp&amp;s=29e688d269ea498c0f6c0e69ca197d4e06af367c", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=890070be057e4eb647bf08a41f747b8ea6cddebe", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a2cbc35ffc6ea85a9e060980b5e1f3a19cf7e290", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8b861379b16ea4d9f95abf9d13c8232f4296b244", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4d341bcacc070a2c96156586317a354b9c39876", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=db9534e879522a6baf408f1c330aa745235ff3de", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/Nl_rAZIl9ewbB83-ydeI6OGNLnPneBholNaJispr2c4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b856a5d03d754d41d6f7d54232445cabe39a2a45", "width": 1080, "height": 720}], "variants": {}, "id": "XaP7BeTbPxZmibZNiGCDQwi44Q03JNzh7KyQo1KOaZQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15mgxd8", "is_robot_indexable": true, "report_reasons": null, "author": "Wide-Alfalfa-700", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mgxd8/jupyter_notebook_meets_marshaai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@aguillenv/jupyter-notebook-meets-marsha-ai-822993868a2e", "subreddit_subscribers": 121777, "created_utc": 1691591340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vx67of8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ultimate dbt Cheat Sheet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15mfqhr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BmZfuPSMpmqPfBK7jVJy46GPbMOEEFEJ9hHM_wRgggk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691588601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datacoves.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://datacoves.com/post/dbt-cheatsheet", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?auto=webp&amp;s=877a8990290912f27a3e8fe27fff96f255bd9585", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77fde2d67be961affcbcc1dbedcee7598f0bd58e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=60df194bcaf3fcf84d4c60322752d92b096ccca3", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2bfa708d8ceebc172620fe49d04ba92f0eeb8f0", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d7caf3fb816aa85080b86ed1a7c9e96cb405a5b", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7201f30b7b60df4c14725cd45646e2fbfab2a8aa", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/LfxdGoonLpbPqBxUcmDkcfIvKcy6ZE_bet2k7MJFAjw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=97adbe1a5fe1ac04f88e5356202fd6eb9cdccbd5", "width": 1080, "height": 564}], "variants": {}, "id": "_rzD2Rrp77lU7pyoKi6-K0j0h-KIeL9rC__uODDWLuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15mfqhr", "is_robot_indexable": true, "report_reasons": null, "author": "Hot_Map_7868", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15mfqhr/ultimate_dbt_cheat_sheet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://datacoves.com/post/dbt-cheatsheet", "subreddit_subscribers": 121777, "created_utc": 1691588601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just did a test with this platform but never heard about it before. Looking to hear about your experience with it", "author_fullname": "t2_729lk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone used Toggl hire before?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15me50n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691584693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just did a test with this platform but never heard about it before. Looking to hear about your experience with it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15me50n", "is_robot_indexable": true, "report_reasons": null, "author": "riclex", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15me50n/anyone_used_toggl_hire_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15me50n/anyone_used_toggl_hire_before/", "subreddit_subscribers": 121777, "created_utc": 1691584693.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}