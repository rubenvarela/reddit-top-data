{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Doing a data engineering project right now for one of my courses in data engineering, it's just a supplementary course not actually like college. But it covers basics of data engineering and stuff... I wanted to know practically if there's anything I could practice. So I'm learning some advanced SQL. Curious what SQL data engineers use. Is it like stored procedures, or writing APIs? Anything in specific to practice?", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of SQL are you guys writing and how complex is it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15pxfz6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691929130.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Doing a data engineering project right now for one of my courses in data engineering, it&amp;#39;s just a supplementary course not actually like college. But it covers basics of data engineering and stuff... I wanted to know practically if there&amp;#39;s anything I could practice. So I&amp;#39;m learning some advanced SQL. Curious what SQL data engineers use. Is it like stored procedures, or writing APIs? Anything in specific to practice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15pxfz6", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 75, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15pxfz6/what_kind_of_sql_are_you_guys_writing_and_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15pxfz6/what_kind_of_sql_are_you_guys_writing_and_how/", "subreddit_subscribers": 122601, "created_utc": 1691929130.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently work for a tech/ecommerce company in marketing domain and while I like doing DE tasks, I feel that the data we are working on and the aim of all the pipelines is very boring. My job is basically to unify customer/order data, classify them by industries, products, etc, and then create ad campaigns to send them targeted ads. What\u2019s worst is to have to setup fancy pipelines and dashboards for measuring the lift tests and a/b tests of the ads only for marketing departments not to use them or for them to run the full campaign even without reaching a good clear consensus of the experiment. Why experiment then lol, spending thousands of dollars in experimentation and tools for it for them to not even consider it. Waste of time imo. \n\nThe engineering part is \u201cfun\u201d, specially using all the fancy tools of a modern data stack, but the business use case I find it extremely boring. \n\nAnyone working on some better business use case as a DE? Maybe financial data and financial modeling? Maybe some data around health or pharma? Don\u2019t really know.", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u201cFun\u201d domains to work as DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15pvfty", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691922535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently work for a tech/ecommerce company in marketing domain and while I like doing DE tasks, I feel that the data we are working on and the aim of all the pipelines is very boring. My job is basically to unify customer/order data, classify them by industries, products, etc, and then create ad campaigns to send them targeted ads. What\u2019s worst is to have to setup fancy pipelines and dashboards for measuring the lift tests and a/b tests of the ads only for marketing departments not to use them or for them to run the full campaign even without reaching a good clear consensus of the experiment. Why experiment then lol, spending thousands of dollars in experimentation and tools for it for them to not even consider it. Waste of time imo. &lt;/p&gt;\n\n&lt;p&gt;The engineering part is \u201cfun\u201d, specially using all the fancy tools of a modern data stack, but the business use case I find it extremely boring. &lt;/p&gt;\n\n&lt;p&gt;Anyone working on some better business use case as a DE? Maybe financial data and financial modeling? Maybe some data around health or pharma? Don\u2019t really know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15pvfty", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15pvfty/fun_domains_to_work_as_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15pvfty/fun_domains_to_work_as_de/", "subreddit_subscribers": 122601, "created_utc": 1691922535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I created a prod and staging user on a single ec2 instance, with each user running dbt core via a distributable python package installed into a virtual environment. Our data warehouse is a single redshift cluster that contains dedicated target schemas for each dbt user to write to. The idea is analysts, data engineers and data scientists will run dbt locally, and develop new or update existing dbt models on their personal target schema. When they're ready, they push their code to git, use a CI/CD pipeline to pull down their branch on the staging user and run dbt to test. Once everything looks good, they issue the pr and eventually merge to prod. I have a second CI/CD pipeline that pulls down main and reinstalls our dbt / python package on the prod user.\n\nI have intentionally isolated dbt environments and would have preferred to isolate them further onto separate instances, but a single ec2 instance is a requirement due to cost. We're a small team :)\n\nI do not have an orchestration tool in place yet, but will likely go with Dagster. I'm much more familiar with Airflow, but it seems Dagster's integration with dbt is stronger. More on that [here](https://dagster.io/blog/orchestrating-dbt-with-dagster).\n\nI am thinking we'll have one Dagster instance for each ec2 user. Thinking I will build Dagster from Docker, and will either add our dbt project to the image, or mount directories onto the Docker containers so they can read our dbt projects (this way, you don't need to rebuild Docker if you change a dbt model). Will make sure the instance size is appropriate, but is it generally a bad idea to host two Docker applications on one instance?\n\nHow do you feel about this setup? What do you like about it? What do you not like about it? Suggestions / feedback welcome.\n\nAppreciate this community and my fellow DEs! Thanks!", "author_fullname": "t2_1p505jz8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Critique my dbt setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15q2fy1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691942145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I created a prod and staging user on a single ec2 instance, with each user running dbt core via a distributable python package installed into a virtual environment. Our data warehouse is a single redshift cluster that contains dedicated target schemas for each dbt user to write to. The idea is analysts, data engineers and data scientists will run dbt locally, and develop new or update existing dbt models on their personal target schema. When they&amp;#39;re ready, they push their code to git, use a CI/CD pipeline to pull down their branch on the staging user and run dbt to test. Once everything looks good, they issue the pr and eventually merge to prod. I have a second CI/CD pipeline that pulls down main and reinstalls our dbt / python package on the prod user.&lt;/p&gt;\n\n&lt;p&gt;I have intentionally isolated dbt environments and would have preferred to isolate them further onto separate instances, but a single ec2 instance is a requirement due to cost. We&amp;#39;re a small team :)&lt;/p&gt;\n\n&lt;p&gt;I do not have an orchestration tool in place yet, but will likely go with Dagster. I&amp;#39;m much more familiar with Airflow, but it seems Dagster&amp;#39;s integration with dbt is stronger. More on that &lt;a href=\"https://dagster.io/blog/orchestrating-dbt-with-dagster\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;I am thinking we&amp;#39;ll have one Dagster instance for each ec2 user. Thinking I will build Dagster from Docker, and will either add our dbt project to the image, or mount directories onto the Docker containers so they can read our dbt projects (this way, you don&amp;#39;t need to rebuild Docker if you change a dbt model). Will make sure the instance size is appropriate, but is it generally a bad idea to host two Docker applications on one instance?&lt;/p&gt;\n\n&lt;p&gt;How do you feel about this setup? What do you like about it? What do you not like about it? Suggestions / feedback welcome.&lt;/p&gt;\n\n&lt;p&gt;Appreciate this community and my fellow DEs! Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4dnr--F082-Oi31-nI58cSgqClNerF2H2gHC2od7r0A.jpg?auto=webp&amp;s=2f1bfcb2ba39b5442a1a78d00ffdad858852eea6", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/4dnr--F082-Oi31-nI58cSgqClNerF2H2gHC2od7r0A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=51f5467705868046ba214227a258cbdbb2ec3b89", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/4dnr--F082-Oi31-nI58cSgqClNerF2H2gHC2od7r0A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6b4efb67c76617f6453c82171bd0931b7f432907", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/4dnr--F082-Oi31-nI58cSgqClNerF2H2gHC2od7r0A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fead25bfa52e17267f8431f69c12295b7a598d41", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/4dnr--F082-Oi31-nI58cSgqClNerF2H2gHC2od7r0A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=67ec9cb4f9fecd361f9a63f117df0b3d5c01626c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/4dnr--F082-Oi31-nI58cSgqClNerF2H2gHC2od7r0A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3f4f6be49b9d645790651f2cb8edd346267bfade", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/4dnr--F082-Oi31-nI58cSgqClNerF2H2gHC2od7r0A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f82c61a884373a63b487ef3da2847a959640dbd0", "width": 1080, "height": 567}], "variants": {}, "id": "4ODBgNsASQ5QcVGCPvCEghmQsI0P7Ygo9nBCszCpEAU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15q2fy1", "is_robot_indexable": true, "report_reasons": null, "author": "Fredonia1988", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15q2fy1/critique_my_dbt_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15q2fy1/critique_my_dbt_setup/", "subreddit_subscribers": 122601, "created_utc": 1691942145.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1k25lis", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Implement Write-Audit-Publish (WAP)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 83, "top_awarded_type": null, "hide_score": false, "name": "t3_15pu0yo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VWDm2zejtCkQFl1z7BMhs8Joqx8HD26Q2yobCGVqGLs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691917428.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lakefs.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://lakefs.io/blog/how-to-implement-write-audit-publish/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JMfEV3hTb9XdMnPSpMICVK8P-zATlzj98-KGYw3zq5E.jpg?auto=webp&amp;s=25cbfdd698fa9a4f922baee6dcdc3a54096f5e17", "width": 877, "height": 526}, "resolutions": [{"url": "https://external-preview.redd.it/JMfEV3hTb9XdMnPSpMICVK8P-zATlzj98-KGYw3zq5E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b58458388e2741bd50e71f5a55e21465b5290b38", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/JMfEV3hTb9XdMnPSpMICVK8P-zATlzj98-KGYw3zq5E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=451f387edc6903d83b59e64be6aba89897383cf0", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/JMfEV3hTb9XdMnPSpMICVK8P-zATlzj98-KGYw3zq5E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=14cabeb850cba60908bc7e440fb5a939da392979", "width": 320, "height": 191}, {"url": "https://external-preview.redd.it/JMfEV3hTb9XdMnPSpMICVK8P-zATlzj98-KGYw3zq5E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=11df4897613e3ca7cdbcf13e215a46adc84c886d", "width": 640, "height": 383}], "variants": {}, "id": "CEU_bI4Yaf6BbPdqktbX2GCVPW3QsWy4DhtiK5j9AZw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15pu0yo", "is_robot_indexable": true, "report_reasons": null, "author": "bybatasdie", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15pu0yo/how_to_implement_writeauditpublish_wap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lakefs.io/blog/how-to-implement-write-audit-publish/", "subreddit_subscribers": 122601, "created_utc": 1691917428.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m starting a new job soon and they use AWS Redshift, Glue, and EMR. I understand Redshift is an MPP database but what\u2019s the difference between EMR &amp; Glue? From my research it seems that if you have Glue and Redshift you don\u2019t need EMR? \n\nAlso, I watched some videos on YouTube regarding EMR and it seems like a crappy version of Databricks, so why do companies still use EMR instead of Databricks? \n\nI come from an Azure Databricks and Data Factory background.", "author_fullname": "t2_8wpw0e1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use cases for AWS EMR &amp; Glue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15pt9dg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691914602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m starting a new job soon and they use AWS Redshift, Glue, and EMR. I understand Redshift is an MPP database but what\u2019s the difference between EMR &amp;amp; Glue? From my research it seems that if you have Glue and Redshift you don\u2019t need EMR? &lt;/p&gt;\n\n&lt;p&gt;Also, I watched some videos on YouTube regarding EMR and it seems like a crappy version of Databricks, so why do companies still use EMR instead of Databricks? &lt;/p&gt;\n\n&lt;p&gt;I come from an Azure Databricks and Data Factory background.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15pt9dg", "is_robot_indexable": true, "report_reasons": null, "author": "khaili109", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15pt9dg/use_cases_for_aws_emr_glue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15pt9dg/use_cases_for_aws_emr_glue/", "subreddit_subscribers": 122601, "created_utc": 1691914602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How many different snowflake accounts do you have? Example: DEV, TEST, and PROD. Also, how do you manage the data in the different environments? DEV and TEST data has all the schemas but manually loading process. Example: Pausing Fivetran in DEV and TEST after you make your change. Do you run your CI/CD pipelines on Snowflake TEST environment?", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi Deployment Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15q7jte", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691954623.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691954297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How many different snowflake accounts do you have? Example: DEV, TEST, and PROD. Also, how do you manage the data in the different environments? DEV and TEST data has all the schemas but manually loading process. Example: Pausing Fivetran in DEV and TEST after you make your change. Do you run your CI/CD pipelines on Snowflake TEST environment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15q7jte", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15q7jte/multi_deployment_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15q7jte/multi_deployment_snowflake/", "subreddit_subscribers": 122601, "created_utc": 1691954297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am starting to migrate some python ETL, the company I work is planning to.move all the stuff to azure and I don't want to write all the stuff to data factory again.", "author_fullname": "t2_9whrpzfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How widely is Docker used in Python-based ETL and data engineering projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qa0h0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691960187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am starting to migrate some python ETL, the company I work is planning to.move all the stuff to azure and I don&amp;#39;t want to write all the stuff to data factory again.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15qa0h0", "is_robot_indexable": true, "report_reasons": null, "author": "Forsaken-Program3557", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15qa0h0/how_widely_is_docker_used_in_pythonbased_etl_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15qa0h0/how_widely_is_docker_used_in_pythonbased_etl_and/", "subreddit_subscribers": 122601, "created_utc": 1691960187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I graduated just over a year ago with my B.S. in CS and have been with a consulting company since then doing some full-stack and random stuff like technical writing.\n\nI got scheduled for a 1st round technical with Meta for a DE role after filling out a questionnaire from a hiring manager asking how much SQL and Python I had used before.\n\nI've only started using Python within the last month since I'm started doing a little bit of Leetcoding again to prep for interviews as I'm trying to leave consulting, and I've used SQL in school and when I was on a project for a few months as a dev doing JOINS and just querying stuff when I needed to. Nothing complex.\n\nMy interview is tomorrow. After reading [this article](https://medium.com/p/345235afaac0), where the guy basically states Meta DE roles look for people with advanced skills in both Python and SQL and 4+ years experience, I'm pretty sure I'm just wasting my own and their time by doing the interview.\n\nIf they ask me anything like this: \" *Here\u2019s an S3 bucket and here\u2019s a data warehouse, how do you get data from one to the other and why? Streaming or batch? Unit testing? Logging? Data quality? Be able to talk about these points and answer how and why...\",* I'll have no clue how to answer.\n\nI really want to do SE and not DE, I really just agreed to the interview so that it looks like I'm actually trying to be productive and find a new role, when what I really want to do is leave and join a non-consulting company as an SE.", "author_fullname": "t2_gx92oikh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scheduled for a 1st round technical DE interview w/ Meta tomorrow w/ little experience, think I'm screwed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15q740g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691953258.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I graduated just over a year ago with my B.S. in CS and have been with a consulting company since then doing some full-stack and random stuff like technical writing.&lt;/p&gt;\n\n&lt;p&gt;I got scheduled for a 1st round technical with Meta for a DE role after filling out a questionnaire from a hiring manager asking how much SQL and Python I had used before.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve only started using Python within the last month since I&amp;#39;m started doing a little bit of Leetcoding again to prep for interviews as I&amp;#39;m trying to leave consulting, and I&amp;#39;ve used SQL in school and when I was on a project for a few months as a dev doing JOINS and just querying stuff when I needed to. Nothing complex.&lt;/p&gt;\n\n&lt;p&gt;My interview is tomorrow. After reading &lt;a href=\"https://medium.com/p/345235afaac0\"&gt;this article&lt;/a&gt;, where the guy basically states Meta DE roles look for people with advanced skills in both Python and SQL and 4+ years experience, I&amp;#39;m pretty sure I&amp;#39;m just wasting my own and their time by doing the interview.&lt;/p&gt;\n\n&lt;p&gt;If they ask me anything like this: &amp;quot; &lt;em&gt;Here\u2019s an S3 bucket and here\u2019s a data warehouse, how do you get data from one to the other and why? Streaming or batch? Unit testing? Logging? Data quality? Be able to talk about these points and answer how and why...&amp;quot;,&lt;/em&gt; I&amp;#39;ll have no clue how to answer.&lt;/p&gt;\n\n&lt;p&gt;I really want to do SE and not DE, I really just agreed to the interview so that it looks like I&amp;#39;m actually trying to be productive and find a new role, when what I really want to do is leave and join a non-consulting company as an SE.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PHw7b-jghLmCM5VE1ysI3mUS379K5QNURZA9hJg_Lc8.jpg?auto=webp&amp;s=bdd2e81a835bbcc3390c697c8cf78d660e405116", "width": 1200, "height": 872}, "resolutions": [{"url": "https://external-preview.redd.it/PHw7b-jghLmCM5VE1ysI3mUS379K5QNURZA9hJg_Lc8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b2c57508833cae1b5f73db51aa56dd54def3dfb4", "width": 108, "height": 78}, {"url": "https://external-preview.redd.it/PHw7b-jghLmCM5VE1ysI3mUS379K5QNURZA9hJg_Lc8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dbadd8b043e4cf250c99d62b59c4d4d8e22b1dd8", "width": 216, "height": 156}, {"url": "https://external-preview.redd.it/PHw7b-jghLmCM5VE1ysI3mUS379K5QNURZA9hJg_Lc8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=526b387a900e331cffe7b2785750ed8e894c30d9", "width": 320, "height": 232}, {"url": "https://external-preview.redd.it/PHw7b-jghLmCM5VE1ysI3mUS379K5QNURZA9hJg_Lc8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c7e945f277ae822354645ac477c7148e08aa24ab", "width": 640, "height": 465}, {"url": "https://external-preview.redd.it/PHw7b-jghLmCM5VE1ysI3mUS379K5QNURZA9hJg_Lc8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fbd2fb5edf7913f87a89117346e82497d8134452", "width": 960, "height": 697}, {"url": "https://external-preview.redd.it/PHw7b-jghLmCM5VE1ysI3mUS379K5QNURZA9hJg_Lc8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7076f4faf043b6e7b4cee4a56d19032fbf7a531c", "width": 1080, "height": 784}], "variants": {}, "id": "O927Kr7aln2qqdqsyhhxcXJwkjpqssBoS9bpyKTVdpw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15q740g", "is_robot_indexable": true, "report_reasons": null, "author": "WhaliusMaximus", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15q740g/scheduled_for_a_1st_round_technical_de_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15q740g/scheduled_for_a_1st_round_technical_de_interview/", "subreddit_subscribers": 122601, "created_utc": 1691953258.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello\n\nI would like to learn a bit more about some experiences using Snowflake + terraform for defining the Snowflake configuration like users, roles, grants, database, schemas, etc.  \nIn the last year the \"official\" Snowflake provider for terraform is now under the control of Snowflake  so they [plan to show it a bit more of love](https://www.snowflake.com/summit/on-demand/agenda?agendaPath=session/1177593), although we still see some issues like\\`\\`\n\n    2023-08-08T14:35:21.026Z [WARN]  Provider \"registry.terraform.io/snowflake-labs/snowflake\" produced an invalid plan for module.environment.module.users.module.xxxxxxxxxxx.snowflake_role_grants.grant_functional_role[\"XXXXXXXXX\"], but we are tolerating it because it is using the legacy plugin SDK.\n        The following problems may be the cause of any confusing errors from downstream operations:\n          - .enable_multiple_grants: planned value cty.False for a non-computed attribute\n          - .roles: planned value cty.SetValEmpty(cty.String) for a non-computed attribute\n\nOn my current place, we have a repo in Gitlab where we define all the terraform code and we trigger a gitlab CI/CD pipeline to plan and apply the changes. We have just one production account in Snowflake which we are trying to change now by introducing a dev account to test changes before moving to production.   \nWe are also in the middle of a revamp of the roles policies so we're considering if terraform is the right place for that kind of configuration, other options include migration tools like Flyway for example.\n\nSo questions are: Are you also using terraform? How does it work for you? Also, what's the flow in git for getting things deployed?", "author_fullname": "t2_3r6mfz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake with Terraform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qaepm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691961132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello&lt;/p&gt;\n\n&lt;p&gt;I would like to learn a bit more about some experiences using Snowflake + terraform for defining the Snowflake configuration like users, roles, grants, database, schemas, etc.&lt;br/&gt;\nIn the last year the &amp;quot;official&amp;quot; Snowflake provider for terraform is now under the control of Snowflake  so they &lt;a href=\"https://www.snowflake.com/summit/on-demand/agenda?agendaPath=session/1177593\"&gt;plan to show it a bit more of love&lt;/a&gt;, although we still see some issues like``&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;2023-08-08T14:35:21.026Z [WARN]  Provider &amp;quot;registry.terraform.io/snowflake-labs/snowflake&amp;quot; produced an invalid plan for module.environment.module.users.module.xxxxxxxxxxx.snowflake_role_grants.grant_functional_role[&amp;quot;XXXXXXXXX&amp;quot;], but we are tolerating it because it is using the legacy plugin SDK.\n    The following problems may be the cause of any confusing errors from downstream operations:\n      - .enable_multiple_grants: planned value cty.False for a non-computed attribute\n      - .roles: planned value cty.SetValEmpty(cty.String) for a non-computed attribute\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;On my current place, we have a repo in Gitlab where we define all the terraform code and we trigger a gitlab CI/CD pipeline to plan and apply the changes. We have just one production account in Snowflake which we are trying to change now by introducing a dev account to test changes before moving to production.&lt;br/&gt;\nWe are also in the middle of a revamp of the roles policies so we&amp;#39;re considering if terraform is the right place for that kind of configuration, other options include migration tools like Flyway for example.&lt;/p&gt;\n\n&lt;p&gt;So questions are: Are you also using terraform? How does it work for you? Also, what&amp;#39;s the flow in git for getting things deployed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/c17C3Zj1qP3RzoHYTg_SshE5hXBwjTBmlsZ7NZjrXAU.jpg?auto=webp&amp;s=cef7de0a5ad5b547c2beeeca5cebbf43c4878970", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/c17C3Zj1qP3RzoHYTg_SshE5hXBwjTBmlsZ7NZjrXAU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=de6c0d1ebc9cfd7476ea86c7e9929eb58e1b9918", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/c17C3Zj1qP3RzoHYTg_SshE5hXBwjTBmlsZ7NZjrXAU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=97ef2a420d5fecc85c329ac31916f11d43f5e88d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/c17C3Zj1qP3RzoHYTg_SshE5hXBwjTBmlsZ7NZjrXAU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8996912ff98f967733d6f457aea90b4b7503a828", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/c17C3Zj1qP3RzoHYTg_SshE5hXBwjTBmlsZ7NZjrXAU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d741f4e4cd36c611df7982979e263348426b9a8", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/c17C3Zj1qP3RzoHYTg_SshE5hXBwjTBmlsZ7NZjrXAU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1eb04e1e4e26d6a03cfe6356aaef9e5134bb3735", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/c17C3Zj1qP3RzoHYTg_SshE5hXBwjTBmlsZ7NZjrXAU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=170a2e0457a29ab97e8b2edd3618859f8f7e7ee8", "width": 1080, "height": 567}], "variants": {}, "id": "oORWKq22_F7LlXD27QjQ_FQZL5aRBjW6LsKy2OF6eiE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15qaepm", "is_robot_indexable": true, "report_reasons": null, "author": "douglasfzickuhr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15qaepm/snowflake_with_terraform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15qaepm/snowflake_with_terraform/", "subreddit_subscribers": 122601, "created_utc": 1691961132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a large company and our data is stored in aws. We are using  odbc drivers to connect through presto and ETL and is extremely slow for large datasets. The other day, I made a connection through a trinio client in python and pulled down almost 20 million records in 5 minute into a pandas dataframe. this same process was taking over 2 hours using standard odbc drivers. My question is what is the fastest way to get data from a pandas dataframe into sql server? I'm really thinking about getting rid of our current process and try to implement python and the trino client if possible.", "author_fullname": "t2_daehbbsip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "need some advice on what to do here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15q9gm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691958855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a large company and our data is stored in aws. We are using  odbc drivers to connect through presto and ETL and is extremely slow for large datasets. The other day, I made a connection through a trinio client in python and pulled down almost 20 million records in 5 minute into a pandas dataframe. this same process was taking over 2 hours using standard odbc drivers. My question is what is the fastest way to get data from a pandas dataframe into sql server? I&amp;#39;m really thinking about getting rid of our current process and try to implement python and the trino client if possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15q9gm4", "is_robot_indexable": true, "report_reasons": null, "author": "Tough-Error520", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15q9gm4/need_some_advice_on_what_to_do_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15q9gm4/need_some_advice_on_what_to_do_here/", "subreddit_subscribers": 122601, "created_utc": 1691958855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Which software do you use for visualization, reporting and dashboarding in a business / professional context? Why do you use / prefer that solution over something else?\n\n[View Poll](https://www.reddit.com/poll/15q7cp8)", "author_fullname": "t2_hwokptog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which reporting and dashboarding tool do you use in job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15q7cp8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691953832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which software do you use for visualization, reporting and dashboarding in a business / professional context? Why do you use / prefer that solution over something else?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/15q7cp8\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15q7cp8", "is_robot_indexable": true, "report_reasons": null, "author": "niklaspm", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1692040232968, "options": [{"text": "Tableau", "id": "24327176"}, {"text": "Microsoft PowerBI", "id": "24327177"}, {"text": "IBM Cognos Analytics", "id": "24327178"}, {"text": "SAP Analytics Cloud", "id": "24327179"}, {"text": "Metabase", "id": "24327180"}, {"text": "Something else (please comment)", "id": "24327181"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 371, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15q7cp8/which_reporting_and_dashboarding_tool_do_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/15q7cp8/which_reporting_and_dashboarding_tool_do_you_use/", "subreddit_subscribers": 122601, "created_utc": 1691953832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " [How to avoid feature creep (digma.ai)](https://digma.ai/blog/coding-horrors-refactoring-and-feature-creep/) ", "author_fullname": "t2_puwuw2q2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you guys make use of abstractions, e.g. scikit-learn\u2019s or Spark\u2019s \u201cPipeline\u201d, to avoid data misalignments?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15pu2cw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691917569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://digma.ai/blog/coding-horrors-refactoring-and-feature-creep/\"&gt;How to avoid feature creep (digma.ai)&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AOykyz-lLDMeSh5-MDjXydwPt9qChOfS4vGcrsZ38iE.jpg?auto=webp&amp;s=b68822c4f1f27675acadd5dd894898f60bcd0631", "width": 480, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/AOykyz-lLDMeSh5-MDjXydwPt9qChOfS4vGcrsZ38iE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=65aece0efb4134f4641d37ef16d4e2d52d60c7a1", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/AOykyz-lLDMeSh5-MDjXydwPt9qChOfS4vGcrsZ38iE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=192fe9c2baac8acca0ee9058424b8ed76ee4d512", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/AOykyz-lLDMeSh5-MDjXydwPt9qChOfS4vGcrsZ38iE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=93f96dc5b098f390d115bbab5a0c8ce1062d6f68", "width": 320, "height": 320}], "variants": {}, "id": "rZH8cXnMSG0wHNQOLS7m-da3vY3CAWRACAn_NKBJ8nw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15pu2cw", "is_robot_indexable": true, "report_reasons": null, "author": "observability_geek", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15pu2cw/do_you_guys_make_use_of_abstractions_eg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15pu2cw/do_you_guys_make_use_of_abstractions_eg/", "subreddit_subscribers": 122601, "created_utc": 1691917569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\nI\u2019m a Data Engineer in a company sailing in the cybersecurity world. I have one project coming in my direction that I\u2019d be very interested in listening your thoughts. \n\nAmong the different ways we provide value to our customers, the most visible one is via data analytics through custom dashboards. Customers can follow real time, country and service level fraud rate, identify fraudsters, export customised reports, etc. \nWe currently rely on a solution called Dundas BI but we might change that in the near future, and I\u2019ve been asked to take part in the adventure. Yay!\n\nOne of the interesting features of this thing is the group and user level custom attributes settings, allowing different users of a same organisation (a customer in a large sense) to have different views on filters, dashboards, menus, etc. There are also other requirements but almost all the challengers give them (SSO, Dashboard export, etc).\n\nIt happens that this solution is not bringing us full satisfaction and a few challengers have been considered, mainly Apache Superset or using directly Preset (the commercial version of it).\n\nI\u2019m a little skeptic, though. I wonder if, considering the fact that we deliver a lot of value by this mean, I\u2019d say that the best would be to have a solution developed in house, kind of a portal, using JS (one of the most recurrent customers complaints is that our current dashboards are clunky and heavy), that would make API calls to our DWH to fetch the data needed to present on the dashboard. I think that having someone whose sole job is to develop this would have a considerably higher ROI than trying to make our use case fit in any available solution out there and relying on 2 DE + 1 DS to keep the solution running (along all the other projects).\n\nMy boss doesn\u2019t share this thinking, though. He thinks we should go full Superset even more so because it is OSS and it would make us save a few bucks. \n\nSo, what are your thoughts? Do you see any other challenger worth considering along Superset? Plotly, D3.js, Highcharts, Redash (not sure this one has all the features we need)\u2026 How is the problem of external, customer-facing data analytics dealt with in your companies? \n\nThank you for your help!", "author_fullname": "t2_83674ydh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dashboard/BI solution with group and user level attributes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15q8e1n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691956263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nI\u2019m a Data Engineer in a company sailing in the cybersecurity world. I have one project coming in my direction that I\u2019d be very interested in listening your thoughts. &lt;/p&gt;\n\n&lt;p&gt;Among the different ways we provide value to our customers, the most visible one is via data analytics through custom dashboards. Customers can follow real time, country and service level fraud rate, identify fraudsters, export customised reports, etc. \nWe currently rely on a solution called Dundas BI but we might change that in the near future, and I\u2019ve been asked to take part in the adventure. Yay!&lt;/p&gt;\n\n&lt;p&gt;One of the interesting features of this thing is the group and user level custom attributes settings, allowing different users of a same organisation (a customer in a large sense) to have different views on filters, dashboards, menus, etc. There are also other requirements but almost all the challengers give them (SSO, Dashboard export, etc).&lt;/p&gt;\n\n&lt;p&gt;It happens that this solution is not bringing us full satisfaction and a few challengers have been considered, mainly Apache Superset or using directly Preset (the commercial version of it).&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a little skeptic, though. I wonder if, considering the fact that we deliver a lot of value by this mean, I\u2019d say that the best would be to have a solution developed in house, kind of a portal, using JS (one of the most recurrent customers complaints is that our current dashboards are clunky and heavy), that would make API calls to our DWH to fetch the data needed to present on the dashboard. I think that having someone whose sole job is to develop this would have a considerably higher ROI than trying to make our use case fit in any available solution out there and relying on 2 DE + 1 DS to keep the solution running (along all the other projects).&lt;/p&gt;\n\n&lt;p&gt;My boss doesn\u2019t share this thinking, though. He thinks we should go full Superset even more so because it is OSS and it would make us save a few bucks. &lt;/p&gt;\n\n&lt;p&gt;So, what are your thoughts? Do you see any other challenger worth considering along Superset? Plotly, D3.js, Highcharts, Redash (not sure this one has all the features we need)\u2026 How is the problem of external, customer-facing data analytics dealt with in your companies? &lt;/p&gt;\n\n&lt;p&gt;Thank you for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15q8e1n", "is_robot_indexable": true, "report_reasons": null, "author": "palmtree0990", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15q8e1n/dashboardbi_solution_with_group_and_user_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15q8e1n/dashboardbi_solution_with_group_and_user_level/", "subreddit_subscribers": 122601, "created_utc": 1691956263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says, I'd like to pick up something new. \nMy current skillset is SQL/Python (incl some frameworks such as Flask) and I'm quite familiar with GCP cloud-wise.\nI've used Docker a few times but outside the odd job here and there - we don't really use it much atm.\nConsidering picking up some backend or frontend to further develop as a \"fullstack DE\". Any folks here use Java/Kotlin or JS/Typescript extensively ? How did it help you progress in your career ?\nThanks !", "author_fullname": "t2_ilw3j5ci", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to pick up next ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15pzl77", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691935045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, I&amp;#39;d like to pick up something new. \nMy current skillset is SQL/Python (incl some frameworks such as Flask) and I&amp;#39;m quite familiar with GCP cloud-wise.\nI&amp;#39;ve used Docker a few times but outside the odd job here and there - we don&amp;#39;t really use it much atm.\nConsidering picking up some backend or frontend to further develop as a &amp;quot;fullstack DE&amp;quot;. Any folks here use Java/Kotlin or JS/Typescript extensively ? How did it help you progress in your career ?\nThanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15pzl77", "is_robot_indexable": true, "report_reasons": null, "author": "GiacomoLeopardi6", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15pzl77/what_to_pick_up_next/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15pzl77/what_to_pick_up_next/", "subreddit_subscribers": 122601, "created_utc": 1691935045.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}