{"kind": "Listing", "data": {"after": "t3_15qte2s", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4aynv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NYT: A look at publishers' legal fight against the Internet Archive's book lending program; the parties reached a deal Friday to remove some books from the archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15qfqit", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 222, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 222, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OPGumyx2DEhLChmlrjgTnicFdhkvUuo6yNFfLa3qTPg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691974509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "nytimes.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.nytimes.com/2023/08/13/business/media/internet-archive-emergency-lending-library.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SXYQdhlGolWVSjaL25FkyX2msZtBzAUH-dfvskR0vy0.jpg?auto=webp&amp;s=103b985306621e0e1a39e9b18060b5018950f4e1", "width": 1050, "height": 550}, "resolutions": [{"url": "https://external-preview.redd.it/SXYQdhlGolWVSjaL25FkyX2msZtBzAUH-dfvskR0vy0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8a59b1a2f0c311ceaeb2bed32d5c5131d8c2d15e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/SXYQdhlGolWVSjaL25FkyX2msZtBzAUH-dfvskR0vy0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2aebbee976bf853b98749a496390ad6bef9e8567", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/SXYQdhlGolWVSjaL25FkyX2msZtBzAUH-dfvskR0vy0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3d9394ef5ea2e5e19d1675514fd90f08d8c42f38", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/SXYQdhlGolWVSjaL25FkyX2msZtBzAUH-dfvskR0vy0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7fdedface6e3fded3e7d585d55b13ad00bd28400", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/SXYQdhlGolWVSjaL25FkyX2msZtBzAUH-dfvskR0vy0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c9a9d957b5ac0b17dfc5ebe6529ca6faac703681", "width": 960, "height": 502}], "variants": {}, "id": "NLb4RsmPhEIlzucuOMqZDzu_XOJeJ0tCV4mDg_FGFXU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qfqit", "is_robot_indexable": true, "report_reasons": null, "author": "retrac1324", "discussion_type": null, "num_comments": 60, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qfqit/nyt_a_look_at_publishers_legal_fight_against_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.nytimes.com/2023/08/13/business/media/internet-archive-emergency-lending-library.html", "subreddit_subscribers": 697945, "created_utc": 1691974509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Long time lurker here, and ad-hoc archivist. I'll be very sad to see the IA go, it is probably my most visited website. Unfortunately, it is obvious that the IA leadership has doomed the site, for whatever reasons they may have.\n\nThe IA could only exist as long as it did because it was not that well known, and was not really searchable for the average person.\n\nThe only productive thing you can do is to start archiving anything you want preserved, but I guess /r/DataHoarder knew that...\n\n## I can't really figure out any non-conspiratorial explanation as to why the IA people have not organized a grand archiving of the IA itself while there is still time.\n\n# Is there any such initiative going on that one could join?\n\n\n\nand some ranting:\n\nThe IA leadership seems determined to try and make themselves look like some kind of pointless martyrs for a lost cause.\n\nI wish IA would have seen the immense value in something so magical as an actual archive of the internet, and that they would have taken the responsibility to mankind more seriously instead of picking pseudo-political fights they knew they can never win, but alas.\n\nAnd the only debate around this seems to be a circlejerk of juvenile bravado about \"fighting capitalism\" and how the Internet Archive will somehow win because they are the good guys. So no actual resistance will happen.\n\nMy fear is that **the courts will soon order the site to be suspended** while the trial is ongoing, so as to not cause further harm to the rights holders. Like turning off a switch, poof.\n\nIf the IA doesn't go bankrupt immediately (they will), that still wouldn't matter as other copyright holders will have smelled the blood in the water and will be lining up to sue. It will simply be too profitable for the lawyers for it to not happen since they can't lose and they are getting payed on the clock.\n\n**Eventually the entire archive will be ordered destroyed, not just the books and music.** And piracy of popular books and music will continue like nothing happened, but all those website snapshots, blogs and lost software will simply disappear, like so many Yahoo! groups did.\n\nThere will not be any grand heroic scheme to send a secret backup to Canada or whatever. Everything will be handled in the most stupid way possible; we've all seen this movie before. At the end of the day, the cops will come knocking, and the IA staff will dutifully hand over all their hard drives to be destroyed, most likely without even mastodonning about it.", "author_fullname": "t2_20iz9jtb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Internet Archive will die - any serious attempts at archiving it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qdjam", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691969047.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691968663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long time lurker here, and ad-hoc archivist. I&amp;#39;ll be very sad to see the IA go, it is probably my most visited website. Unfortunately, it is obvious that the IA leadership has doomed the site, for whatever reasons they may have.&lt;/p&gt;\n\n&lt;p&gt;The IA could only exist as long as it did because it was not that well known, and was not really searchable for the average person.&lt;/p&gt;\n\n&lt;p&gt;The only productive thing you can do is to start archiving anything you want preserved, but I guess &lt;a href=\"/r/DataHoarder\"&gt;/r/DataHoarder&lt;/a&gt; knew that...&lt;/p&gt;\n\n&lt;h2&gt;I can&amp;#39;t really figure out any non-conspiratorial explanation as to why the IA people have not organized a grand archiving of the IA itself while there is still time.&lt;/h2&gt;\n\n&lt;h1&gt;Is there any such initiative going on that one could join?&lt;/h1&gt;\n\n&lt;p&gt;and some ranting:&lt;/p&gt;\n\n&lt;p&gt;The IA leadership seems determined to try and make themselves look like some kind of pointless martyrs for a lost cause.&lt;/p&gt;\n\n&lt;p&gt;I wish IA would have seen the immense value in something so magical as an actual archive of the internet, and that they would have taken the responsibility to mankind more seriously instead of picking pseudo-political fights they knew they can never win, but alas.&lt;/p&gt;\n\n&lt;p&gt;And the only debate around this seems to be a circlejerk of juvenile bravado about &amp;quot;fighting capitalism&amp;quot; and how the Internet Archive will somehow win because they are the good guys. So no actual resistance will happen.&lt;/p&gt;\n\n&lt;p&gt;My fear is that &lt;strong&gt;the courts will soon order the site to be suspended&lt;/strong&gt; while the trial is ongoing, so as to not cause further harm to the rights holders. Like turning off a switch, poof.&lt;/p&gt;\n\n&lt;p&gt;If the IA doesn&amp;#39;t go bankrupt immediately (they will), that still wouldn&amp;#39;t matter as other copyright holders will have smelled the blood in the water and will be lining up to sue. It will simply be too profitable for the lawyers for it to not happen since they can&amp;#39;t lose and they are getting payed on the clock.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Eventually the entire archive will be ordered destroyed, not just the books and music.&lt;/strong&gt; And piracy of popular books and music will continue like nothing happened, but all those website snapshots, blogs and lost software will simply disappear, like so many Yahoo! groups did.&lt;/p&gt;\n\n&lt;p&gt;There will not be any grand heroic scheme to send a secret backup to Canada or whatever. Everything will be handled in the most stupid way possible; we&amp;#39;ve all seen this movie before. At the end of the day, the cops will come knocking, and the IA staff will dutifully hand over all their hard drives to be destroyed, most likely without even mastodonning about it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15qdjam", "is_robot_indexable": true, "report_reasons": null, "author": "mikemikehindpart", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qdjam/the_internet_archive_will_die_any_serious/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qdjam/the_internet_archive_will_die_any_serious/", "subreddit_subscribers": 697945, "created_utc": 1691968663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Not sure if I should just start with the giant mess the RMA is now or make this longer by mentioning what happened before...\n\n&amp;#x200B;\n\nAs briefly as comes to mind:\n\n1 - Received a damaged package from Amazon at the end of 2022. (In case someone wants to ask why I was so stupid... the 2nd carried threw out the destroyed packaging and put it in a new box, a family member then received the seemingly pristine shipment.)\n\n2 - Contacted WD about the noise the (external, 16TB) HDD was making. Was told not to worry about it. Assured I could get a replacement during the next 3 years. (Amazon only offered a refund, I waited for that price for a year, ordering again for a much higher price was not acceptable for me.)\n\n3 - Of course, the drive stopped working several months later.\n\n4 - Created RMA on July 18th. Shipped on 21st, delivered to WD's address on 25th.\n\n5 - RMA status updated to \"Received / Processing\" on August 3rd. Checking almost every day, no other updates before or after that (till today, not just 8th). No emails till I contacted them first.\n\n6 - August 8th - Contacted WD (via chat) because of strange info about an undeliverable package (info notice number not working, no shipments linked to my address). Didn't know what else it could be other than the RMA replacement HDD. Talked to 2-3 people (internet stopped working + connected to \"a higher level\", I think), both/all told me the package was not from WD, nothing was sent to me yet, my RMA's accepted and waiting for replacement HDD shipment.\n\n7 - August 9th - Someone's \"taken over my case\", adding the screenshot of the email. Short version - WD definitely didn't ship anything (due to lack of stock), they'll be shipping an 18TB HDD, same model (if I agree). I agreed and addressed the rest. (Asked for the name to be changed to a family member's in the chat the previous day since I was already there, after being told shipment's still TBD, can't go and get it myself because of health issues. Answered \"You mentioned receiving an email about this package\" - Never happened. In the chat, I did mention, many times, receiving an info notice that was not in the carrier's system and wasn't linked to any packages or my address.)\n\n8 - August 10th - Short email summing up/confirming what will be done from WD, the same person (screenshot).\n\n9 - August 11th(sent)/13th(found) - Insane email from somebody new, with a tracking number belonging to a package shipped on August 1st (2 days before my RMA was RECEIVED) to a DIFFERENT CITY, being delivered on the 3rd, to, obviously, NOT ME. Adding screenshots. RMA was, of course, created with my address, which was also on the label of the package I shipped (\"From:\"). It really seems like it's not for me and it just got linked to me by mistake after laying somewhere for several days. The whole mess should've been noticed and dealt with internally, without throwing it like a hot potato to the customer and giving them a 10+-hour anxiety attack. \"We are happy to confirm...\" has never been so infuriating. As of right now, still no \"Carrier\", \"Tracking No\",  \"Shipped P/N + S/N\", and \"Shipped Date\" in my RMA (screenshot).\n\n10 - I have no (mental) energy and no polite words to say to WD as a response to this dumpster fire. Felt like throwing up since I found the email and looked at the tracking (the most expensive HDD I've ever bought). I'll... probably... wait for a few days... for the promised shipment of the 18TB HDD / legitimate/relevant RMA update. Maybe someone with a working brain will realize the mistake (after whatever's in the package is shipped back, shouldn't be too long now, has been undelivered/undeliverable somewhere for a week and a half now). . . ?\n\n&amp;#x200B;\n\n\\* Never posted here, probably haven't selected the right \"flair\".\n\n\\*\\* I did add several screenshots (Images &amp; Video tab), can't see them anywhere now, though (post awaiting moderator approval).\n\n&amp;#x200B;\n\nEdit (11 hours after posting): Just wanted to thank everyone who commented, not being alone in this helped me feel a little better. But then I thought about pushing/poking/contacting them again and instantly felt like throwing up again. It would be so much better if my experience was the usual \"weeks of no updates\". However, this BS shipment is now connected to MY RMA. (BTW, I, of course, don't know what's in the package, but it seems like \"WD\" doesn't know either.) I can already hear them telling me that they've already shipped \"it\" to me and it's my fault that I didn't receive it/pick it up, after I ask about the drive that was agreed upon on the 9th and 10th... not being able to comprehend what actually happened, just being stuck at \"this is what's in the system\", nobody from WD looking at it properly and thinking about it like a freaking human. Shouldn't have to, but I'll have to... Will update this in 4-8(?) days.\n\n&amp;#x200B;\n\n\\*\\*\\* Let's see if the screenshots can be added in a different way... ah, 1 image only here... OK\n\nhttps://preview.redd.it/dlq1kmquc4ib1.png?width=1082&amp;format=png&amp;auto=webp&amp;s=5377f431f17ce51abe6ba9bcb771e7574c512a9c", "author_fullname": "t2_a26k1o3p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Insane WD RMA experience (still ongoing)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"dlq1kmquc4ib1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ce2e0e22dbdd5cbaa8dcde73c20162f52d8f1aa"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=34011cdfe363325a4d84ef97f65f786d345b1b00"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec83a99f1de489f3d22040538cd4da31b7660653"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3b182fcb656793e98128c1df2d70100c0c13648a"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a3cd0bef2bb5b6cee5d5aca4e91426a4534ba9d8"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3f1dc876d6fe2a3b1f920b0c2eb2e30bf9da49dc"}], "s": {"y": 2467, "x": 1082, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=1082&amp;format=png&amp;auto=webp&amp;s=5377f431f17ce51abe6ba9bcb771e7574c512a9c"}, "id": "dlq1kmquc4ib1"}}, "name": "t3_15qmj2l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JWk6PRUBHMphIyRqq4qkhxzC3Afd4WvEMJ2N5ae9YWE.jpg", "edited": 1692037765.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691994374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if I should just start with the giant mess the RMA is now or make this longer by mentioning what happened before...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As briefly as comes to mind:&lt;/p&gt;\n\n&lt;p&gt;1 - Received a damaged package from Amazon at the end of 2022. (In case someone wants to ask why I was so stupid... the 2nd carried threw out the destroyed packaging and put it in a new box, a family member then received the seemingly pristine shipment.)&lt;/p&gt;\n\n&lt;p&gt;2 - Contacted WD about the noise the (external, 16TB) HDD was making. Was told not to worry about it. Assured I could get a replacement during the next 3 years. (Amazon only offered a refund, I waited for that price for a year, ordering again for a much higher price was not acceptable for me.)&lt;/p&gt;\n\n&lt;p&gt;3 - Of course, the drive stopped working several months later.&lt;/p&gt;\n\n&lt;p&gt;4 - Created RMA on July 18th. Shipped on 21st, delivered to WD&amp;#39;s address on 25th.&lt;/p&gt;\n\n&lt;p&gt;5 - RMA status updated to &amp;quot;Received / Processing&amp;quot; on August 3rd. Checking almost every day, no other updates before or after that (till today, not just 8th). No emails till I contacted them first.&lt;/p&gt;\n\n&lt;p&gt;6 - August 8th - Contacted WD (via chat) because of strange info about an undeliverable package (info notice number not working, no shipments linked to my address). Didn&amp;#39;t know what else it could be other than the RMA replacement HDD. Talked to 2-3 people (internet stopped working + connected to &amp;quot;a higher level&amp;quot;, I think), both/all told me the package was not from WD, nothing was sent to me yet, my RMA&amp;#39;s accepted and waiting for replacement HDD shipment.&lt;/p&gt;\n\n&lt;p&gt;7 - August 9th - Someone&amp;#39;s &amp;quot;taken over my case&amp;quot;, adding the screenshot of the email. Short version - WD definitely didn&amp;#39;t ship anything (due to lack of stock), they&amp;#39;ll be shipping an 18TB HDD, same model (if I agree). I agreed and addressed the rest. (Asked for the name to be changed to a family member&amp;#39;s in the chat the previous day since I was already there, after being told shipment&amp;#39;s still TBD, can&amp;#39;t go and get it myself because of health issues. Answered &amp;quot;You mentioned receiving an email about this package&amp;quot; - Never happened. In the chat, I did mention, many times, receiving an info notice that was not in the carrier&amp;#39;s system and wasn&amp;#39;t linked to any packages or my address.)&lt;/p&gt;\n\n&lt;p&gt;8 - August 10th - Short email summing up/confirming what will be done from WD, the same person (screenshot).&lt;/p&gt;\n\n&lt;p&gt;9 - August 11th(sent)/13th(found) - Insane email from somebody new, with a tracking number belonging to a package shipped on August 1st (2 days before my RMA was RECEIVED) to a DIFFERENT CITY, being delivered on the 3rd, to, obviously, NOT ME. Adding screenshots. RMA was, of course, created with my address, which was also on the label of the package I shipped (&amp;quot;From:&amp;quot;). It really seems like it&amp;#39;s not for me and it just got linked to me by mistake after laying somewhere for several days. The whole mess should&amp;#39;ve been noticed and dealt with internally, without throwing it like a hot potato to the customer and giving them a 10+-hour anxiety attack. &amp;quot;We are happy to confirm...&amp;quot; has never been so infuriating. As of right now, still no &amp;quot;Carrier&amp;quot;, &amp;quot;Tracking No&amp;quot;,  &amp;quot;Shipped P/N + S/N&amp;quot;, and &amp;quot;Shipped Date&amp;quot; in my RMA (screenshot).&lt;/p&gt;\n\n&lt;p&gt;10 - I have no (mental) energy and no polite words to say to WD as a response to this dumpster fire. Felt like throwing up since I found the email and looked at the tracking (the most expensive HDD I&amp;#39;ve ever bought). I&amp;#39;ll... probably... wait for a few days... for the promised shipment of the 18TB HDD / legitimate/relevant RMA update. Maybe someone with a working brain will realize the mistake (after whatever&amp;#39;s in the package is shipped back, shouldn&amp;#39;t be too long now, has been undelivered/undeliverable somewhere for a week and a half now). . . ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;* Never posted here, probably haven&amp;#39;t selected the right &amp;quot;flair&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;** I did add several screenshots (Images &amp;amp; Video tab), can&amp;#39;t see them anywhere now, though (post awaiting moderator approval).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit (11 hours after posting): Just wanted to thank everyone who commented, not being alone in this helped me feel a little better. But then I thought about pushing/poking/contacting them again and instantly felt like throwing up again. It would be so much better if my experience was the usual &amp;quot;weeks of no updates&amp;quot;. However, this BS shipment is now connected to MY RMA. (BTW, I, of course, don&amp;#39;t know what&amp;#39;s in the package, but it seems like &amp;quot;WD&amp;quot; doesn&amp;#39;t know either.) I can already hear them telling me that they&amp;#39;ve already shipped &amp;quot;it&amp;quot; to me and it&amp;#39;s my fault that I didn&amp;#39;t receive it/pick it up, after I ask about the drive that was agreed upon on the 9th and 10th... not being able to comprehend what actually happened, just being stuck at &amp;quot;this is what&amp;#39;s in the system&amp;quot;, nobody from WD looking at it properly and thinking about it like a freaking human. Shouldn&amp;#39;t have to, but I&amp;#39;ll have to... Will update this in 4-8(?) days.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;*** Let&amp;#39;s see if the screenshots can be added in a different way... ah, 1 image only here... OK&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dlq1kmquc4ib1.png?width=1082&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5377f431f17ce51abe6ba9bcb771e7574c512a9c\"&gt;https://preview.redd.it/dlq1kmquc4ib1.png?width=1082&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5377f431f17ce51abe6ba9bcb771e7574c512a9c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qmj2l", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Celebration2366", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qmj2l/insane_wd_rma_experience_still_ongoing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qmj2l/insane_wd_rma_experience_still_ongoing/", "subreddit_subscribers": 697945, "created_utc": 1691994374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_zhl23", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD has two (2) 20 TB for $619.98, which comes out to $15.50/TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15qyvxe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IKM6X8_teT5K-epE3veCUX-aD0B9QZ7HvCwKfBbb9qE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692029197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "westerndigital.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.westerndigital.com/products/internal-drives/wd-red-pro-sata-hdd#WD201KFGX", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?auto=webp&amp;s=46f8413e6a7bd4c57e1860a28da06b48a5a4229a", "width": 1680, "height": 1680}, "resolutions": [{"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d6befa6135d5ea523cf95d4a475ae6c51b727d30", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a915fba1fdcd2bd78dc4d13a65fdaa70d72aac05", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad393e56c5e8ae45d7fc176b39507b65e8505261", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7f6f0c1769e32468b936879516adbd2f4bd8e298", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=59c21b169aac9b5c4297f792d9dc9df2f8dd18fe", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=267af956f29c0872df1f49031ca70c9cdb661aec", "width": 1080, "height": 1080}], "variants": {}, "id": "6keymE9zpOEX9OFD9sJvRPtVBVor6KjTRLVm8MbwRlA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15qyvxe", "is_robot_indexable": true, "report_reasons": null, "author": "Aviyan", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qyvxe/wd_has_two_2_20_tb_for_61998_which_comes_out_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.westerndigital.com/products/internal-drives/wd-red-pro-sata-hdd#WD201KFGX", "subreddit_subscribers": 697945, "created_utc": 1692029197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As the title states. \n\nSome games let you view models used in-game. I ADORE this, and sometimes I just want to look at a model of Ornstein from Dark Souls or other games. I know, I'm weird. But I was wondering, am I the only one who likes the idea of keeping a collection of in-game models?", "author_fullname": "t2_afuv9dt8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a sub for collecting ripped models from games?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qmfcg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691994050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title states. &lt;/p&gt;\n\n&lt;p&gt;Some games let you view models used in-game. I ADORE this, and sometimes I just want to look at a model of Ornstein from Dark Souls or other games. I know, I&amp;#39;m weird. But I was wondering, am I the only one who likes the idea of keeping a collection of in-game models?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qmfcg", "is_robot_indexable": true, "report_reasons": null, "author": "KaijOUJaeger", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qmfcg/is_there_a_sub_for_collecting_ripped_models_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qmfcg/is_there_a_sub_for_collecting_ripped_models_from/", "subreddit_subscribers": 697945, "created_utc": 1691994050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have just bought a generic AV to HDMI converter in the pic shown as I wasn't able to get the even cheaper \"Easy CAPture\" usb product to work effectively for audio, But now with this product i'm getting HUGE jittering issues I believe may have to do with the interpolation vs interlacing?\n\nI'd like to know what type of specific product is best to assure I can get smooth high quality conversions and yet stay cost effective?\n\nhttps://preview.redd.it/8g1gx8f0zzhb1.jpg?width=4031&amp;format=pjpg&amp;auto=webp&amp;s=7499ee6aa66578ea3d2c70bd88c611c082bd1322", "author_fullname": "t2_vr92xps4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I most effectively convert my old VHS to HDMI WITHOUT jittering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8g1gx8f0zzhb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/8g1gx8f0zzhb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=44b19210d7e99fa68f3815120b41797dc866f7d3"}, {"y": 161, "x": 216, "u": "https://preview.redd.it/8g1gx8f0zzhb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c8e61d2e2b8e7e15ef3f9f907a984ca7490b2a75"}, {"y": 239, "x": 320, "u": "https://preview.redd.it/8g1gx8f0zzhb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=664a60c748236c82d3e2f3f44ae9e6270853cca9"}, {"y": 479, "x": 640, "u": "https://preview.redd.it/8g1gx8f0zzhb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a70ed05aad89784360c9648fb4aed965668fa6dd"}, {"y": 719, "x": 960, "u": "https://preview.redd.it/8g1gx8f0zzhb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2c0590ebca8bbed2a4392bc07a3a0594b4a65dc2"}, {"y": 809, "x": 1080, "u": "https://preview.redd.it/8g1gx8f0zzhb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5a526ffc80753b727ba9ecab24f326b42dea9f52"}], "s": {"y": 3023, "x": 4031, "u": "https://preview.redd.it/8g1gx8f0zzhb1.jpg?width=4031&amp;format=pjpg&amp;auto=webp&amp;s=7499ee6aa66578ea3d2c70bd88c611c082bd1322"}, "id": "8g1gx8f0zzhb1"}}, "name": "t3_15qjbqj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/l37N8LYmyZsWgejAzRnmK9FJtymzjseHKDqt9EqiLOA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691984657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have just bought a generic AV to HDMI converter in the pic shown as I wasn&amp;#39;t able to get the even cheaper &amp;quot;Easy CAPture&amp;quot; usb product to work effectively for audio, But now with this product i&amp;#39;m getting HUGE jittering issues I believe may have to do with the interpolation vs interlacing?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to know what type of specific product is best to assure I can get smooth high quality conversions and yet stay cost effective?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8g1gx8f0zzhb1.jpg?width=4031&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7499ee6aa66578ea3d2c70bd88c611c082bd1322\"&gt;https://preview.redd.it/8g1gx8f0zzhb1.jpg?width=4031&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7499ee6aa66578ea3d2c70bd88c611c082bd1322&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qjbqj", "is_robot_indexable": true, "report_reasons": null, "author": "FunctionalKiwi", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qjbqj/how_do_i_most_effectively_convert_my_old_vhs_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qjbqj/how_do_i_most_effectively_convert_my_old_vhs_to/", "subreddit_subscribers": 697945, "created_utc": 1691984657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "That's the whole Ted talk. I have about 12TB of content from over the years and want to get a NAS setup going and aim for Raid to help prevent bit rot. Is there a noticeable difference in quality and maintenance/long term use with the WD Red nas Hard drive vs the Gold Enterprise Class Imternal drive? Idk if this is a dumbass question but yeah..", "author_fullname": "t2_45v0p27nh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between gold and red quality Western Digital Hard Drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r25wg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692036416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s the whole Ted talk. I have about 12TB of content from over the years and want to get a NAS setup going and aim for Raid to help prevent bit rot. Is there a noticeable difference in quality and maintenance/long term use with the WD Red nas Hard drive vs the Gold Enterprise Class Imternal drive? Idk if this is a dumbass question but yeah..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r25wg", "is_robot_indexable": true, "report_reasons": null, "author": "InitialGuidance5", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r25wg/difference_between_gold_and_red_quality_western/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r25wg/difference_between_gold_and_red_quality_western/", "subreddit_subscribers": 697945, "created_utc": 1692036416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just built a new PC that I use professionally for video editing and wanted to find a new use for my old PC (ryzen 3800x, 64gb of RAM, RTX 2060 super).\n\nI want to be able to still use it to export projects using Premiere but I would also like to set it up as a NAS that I can build out as my storage demand grows. I don\u2019t need a lot of storage space right now (maybe 16tb minimum) but would like the opportunity to grow down the road if needed. I also don\u2019t need that fast of speeds (500mb read/write speeds minimum) so I\u2019m going with just 10gig.\n\nI think I have the hardware side figured out (case, Iron Wolf NAS drives, etc) but I\u2019m trying to figure out the best way to handle the software/OS.\n\nOne thought was to use Unraid and create a VM and install Windows on it so I can still run Adobe programs. Because it would be more background rendering I don\u2019t mind sacrificing some of the cores of my CPU. The other idea was just that I would create a raid in Windows disk manager and set it up as a shared folder with my PC, but that wouldn\u2019t be expandable. With all of that, would the unraid option be the best if I want a machine that can both operate as a NAS and also be able to render files? ", "author_fullname": "t2_708gc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Convert my old PC into a NAS while still being able to use Premiere Pro", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r22s6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692036229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just built a new PC that I use professionally for video editing and wanted to find a new use for my old PC (ryzen 3800x, 64gb of RAM, RTX 2060 super).&lt;/p&gt;\n\n&lt;p&gt;I want to be able to still use it to export projects using Premiere but I would also like to set it up as a NAS that I can build out as my storage demand grows. I don\u2019t need a lot of storage space right now (maybe 16tb minimum) but would like the opportunity to grow down the road if needed. I also don\u2019t need that fast of speeds (500mb read/write speeds minimum) so I\u2019m going with just 10gig.&lt;/p&gt;\n\n&lt;p&gt;I think I have the hardware side figured out (case, Iron Wolf NAS drives, etc) but I\u2019m trying to figure out the best way to handle the software/OS.&lt;/p&gt;\n\n&lt;p&gt;One thought was to use Unraid and create a VM and install Windows on it so I can still run Adobe programs. Because it would be more background rendering I don\u2019t mind sacrificing some of the cores of my CPU. The other idea was just that I would create a raid in Windows disk manager and set it up as a shared folder with my PC, but that wouldn\u2019t be expandable. With all of that, would the unraid option be the best if I want a machine that can both operate as a NAS and also be able to render files? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r22s6", "is_robot_indexable": true, "report_reasons": null, "author": "aaronallsop", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r22s6/convert_my_old_pc_into_a_nas_while_still_being/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r22s6/convert_my_old_pc_into_a_nas_while_still_being/", "subreddit_subscribers": 697945, "created_utc": 1692036229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "**Background:** \n\nHi folks, due to a friend's recent bereavement, I am assisting with the processing of a large hoard of data. Roughly 25 to 30 hard drives, size varies but many are 4TB, 8TB, many smaller.\n\nI am familiar with using DupeGuru (on macOS) and would normally mark certain folders as reference, compare the next one and so on... but it's going to be challenging to say the least to connect this many drives to a single system.\n\nThere definitely are large media duplicates across multiple drives.\n\nI have exported directory listings to a text file and put into a spreadsheet, can search for something and see that it exists on multiple drives, however this doesn't help me know if the files in question are actually the same or not. Just trying to eliminate duplicates (would move to a 'duplicates' folder on each drive) so the true unique data size can be assessed and if things can be compressed further and so on, and then maybe moved to a NAS or similar for the family.\n\n**Question:**\n\nAnyway, my question is: is there some way to scan a drive full of files and save (I doin't know the correct words) hashes or MD5 or similar of the content, and do this for multiple drives each in turn, and then reconnect the drives later to eliminate the duplicates on each drive?\n\nThanks for any suggestions you may have :)", "author_fullname": "t2_1s8v2s4t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Duplicate removal assistance for large hoard.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qn9w4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691996752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;Hi folks, due to a friend&amp;#39;s recent bereavement, I am assisting with the processing of a large hoard of data. Roughly 25 to 30 hard drives, size varies but many are 4TB, 8TB, many smaller.&lt;/p&gt;\n\n&lt;p&gt;I am familiar with using DupeGuru (on macOS) and would normally mark certain folders as reference, compare the next one and so on... but it&amp;#39;s going to be challenging to say the least to connect this many drives to a single system.&lt;/p&gt;\n\n&lt;p&gt;There definitely are large media duplicates across multiple drives.&lt;/p&gt;\n\n&lt;p&gt;I have exported directory listings to a text file and put into a spreadsheet, can search for something and see that it exists on multiple drives, however this doesn&amp;#39;t help me know if the files in question are actually the same or not. Just trying to eliminate duplicates (would move to a &amp;#39;duplicates&amp;#39; folder on each drive) so the true unique data size can be assessed and if things can be compressed further and so on, and then maybe moved to a NAS or similar for the family.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Anyway, my question is: is there some way to scan a drive full of files and save (I doin&amp;#39;t know the correct words) hashes or MD5 or similar of the content, and do this for multiple drives each in turn, and then reconnect the drives later to eliminate the duplicates on each drive?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any suggestions you may have :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qn9w4", "is_robot_indexable": true, "report_reasons": null, "author": "riscy_computering", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qn9w4/duplicate_removal_assistance_for_large_hoard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qn9w4/duplicate_removal_assistance_for_large_hoard/", "subreddit_subscribers": 697945, "created_utc": 1691996752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[Heres The IA Archive Link](https://archive.org/details/ibm-ltfs-single-drive-edition)\n\nI will update it as time permits and I find more software to collect, LTFS and LTO software is true pain, so I hope this saves people days if not weeks of hassle, I am also almost finished with a full guide on the format from LTO1 to LTO9 drives witch I will add links to here once published.\n\nThe Software Archive Includes\n\n- IBM LTFS Single Drive Edition / Tape Diagnostic Tool ITDT\n- HP  LTFS Open Store Suite\n- Quantum XTalk\n- Tandberg Toolkit (LTO 1-4)\n- HP Firmware Tools\n- Tandberg Drivers for Windows\n- LTFS CMD (Command line LTFS)\n- LTFS Copy GUI (Chinese)", "author_fullname": "t2_413nr2z7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LTO Guide; A HP IBM Tandberg LTFS Software Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qaw8v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691962305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://archive.org/details/ibm-ltfs-single-drive-edition\"&gt;Heres The IA Archive Link&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I will update it as time permits and I find more software to collect, LTFS and LTO software is true pain, so I hope this saves people days if not weeks of hassle, I am also almost finished with a full guide on the format from LTO1 to LTO9 drives witch I will add links to here once published.&lt;/p&gt;\n\n&lt;p&gt;The Software Archive Includes&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;IBM LTFS Single Drive Edition / Tape Diagnostic Tool ITDT&lt;/li&gt;\n&lt;li&gt;HP  LTFS Open Store Suite&lt;/li&gt;\n&lt;li&gt;Quantum XTalk&lt;/li&gt;\n&lt;li&gt;Tandberg Toolkit (LTO 1-4)&lt;/li&gt;\n&lt;li&gt;HP Firmware Tools&lt;/li&gt;\n&lt;li&gt;Tandberg Drivers for Windows&lt;/li&gt;\n&lt;li&gt;LTFS CMD (Command line LTFS)&lt;/li&gt;\n&lt;li&gt;LTFS Copy GUI (Chinese)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YiQRc1Kh_LhZKnW0P8o13a-1VrZudI26GKsmOhr6Glw.jpg?auto=webp&amp;s=9520d3a1a3c26ac7dee4f72b805d2d706168d34d", "width": 160, "height": 110}, "resolutions": [{"url": "https://external-preview.redd.it/YiQRc1Kh_LhZKnW0P8o13a-1VrZudI26GKsmOhr6Glw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3e74666b30e5e2724b66be6e8c155e611e8faaa4", "width": 108, "height": 74}], "variants": {}, "id": "te8dS_8tDwV7a4I5wDwIv-RCBsf1rpL-BYZPIq0-t7k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "80TB \ud83c\udfe0 27TB \u2601\ufe0f 50TB \ud83d\udcfc  1TB \ud83d\udcbf", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qaw8v", "is_robot_indexable": true, "report_reasons": null, "author": "TheRealHarrypm", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15qaw8v/lto_guide_a_hp_ibm_tandberg_ltfs_software_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qaw8v/lto_guide_a_hp_ibm_tandberg_ltfs_software_archive/", "subreddit_subscribers": 697945, "created_utc": 1691962305.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "what i am wanting to do is use the IDv3 tag in the music files so that i can get rid of duplicate music files so that i can save space. can IDv3 support more then one album so that my media server can add them to the right albums but use the same file for each. is this doable? i looked at the wiki but could not find the answer. ", "author_fullname": "t2_ht1lr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "need advice for duplicate music files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qvcyl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692021212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what i am wanting to do is use the IDv3 tag in the music files so that i can get rid of duplicate music files so that i can save space. can IDv3 support more then one album so that my media server can add them to the right albums but use the same file for each. is this doable? i looked at the wiki but could not find the answer. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "6.5TB OF 12TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qvcyl", "is_robot_indexable": true, "report_reasons": null, "author": "zac115", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15qvcyl/need_advice_for_duplicate_music_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qvcyl/need_advice_for_duplicate_music_files/", "subreddit_subscribers": 697945, "created_utc": 1692021212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My old Plex sever died so I am looking at building a new one. My budget $1,000-$1,500. I am looking at building it in an Fractal Design R7 XL case. Looking at using unraid for an os. Any suggestions will be greatly appreciated.", "author_fullname": "t2_iyt1e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Noob Looking To Build A New Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15q9mvi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691959285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My old Plex sever died so I am looking at building a new one. My budget $1,000-$1,500. I am looking at building it in an Fractal Design R7 XL case. Looking at using unraid for an os. Any suggestions will be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15q9mvi", "is_robot_indexable": true, "report_reasons": null, "author": "CrazyManInCincy", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15q9mvi/noob_looking_to_build_a_new_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15q9mvi/noob_looking_to_build_a_new_server/", "subreddit_subscribers": 697945, "created_utc": 1691959285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI am using Windows 10, using the gallery.dl.exe file. I am attempting to get cookies from browser directly from the config file to avoid having to always type \"--cookies-from-browser firefox\" everytime I need the cookies to download from instagram for example. However, I am unable to make it work. I am off course new to this, and know yt-dlp more.\n\n&amp;#x200B;\n\nI am typing the following within extractors\n\n&amp;#x200B;\n\n\"instagram\":\n\n{\n\n\"api\": \"rest\",\n\n\"cookies\": \\[\"firefox\"\\],\n\n\"include\": \"posts\",\n\n\"order-files\": \"asc\",\n\n\"order-posts\": \"asc\",\n\n\"previews\": false,\n\n\"sleep-request\": \\[6.0, 12.0\\],\n\n\"videos\": true\n\n},\n\n&amp;#x200B;\n\nI also attempted the directory option \"cookies\": \"G:\\\\gallery-dl\\\\cookies.txt\"\n\n&amp;#x200B;\n\nand I also tried to do it globally on top of the config file but it does not work. What am I missing if you can help me?\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n{\n\n\"extractor\":\n\n{\n\n\"base-directory\": \"H:/gallery-dl-downloads\",\n\n\"parent-directory\": false,\n\n\"postprocessors\": null,\n\n\"archive\": null,\n\n\"cookies\": \\[\"firefox\"\\],\n\n\"cookies-update\": true,\n\n\"proxy\": null,\n\n\"skip\": true,\n\n&amp;#x200B;\n\neverything else works. and of course using --cookies-from... as a command works\n\n&amp;#x200B;\n\nNote: if I attempt to download without the cookies I do get this error \\[instagram\\]\\[error\\] HttpError: '401 Unauthorized' for '[https://www.instagram.com/api/v1/users/web\\_profile\\_info/](https://www.instagram.com/api/v1/users/web_profile_info/)'", "author_fullname": "t2_1i2lp4ty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gallery-dl please help, how to change config file to include cookies for instagram/twitter/reddit.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15r5ai7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692043276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am using Windows 10, using the gallery.dl.exe file. I am attempting to get cookies from browser directly from the config file to avoid having to always type &amp;quot;--cookies-from-browser firefox&amp;quot; everytime I need the cookies to download from instagram for example. However, I am unable to make it work. I am off course new to this, and know yt-dlp more.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am typing the following within extractors&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;instagram&amp;quot;:&lt;/p&gt;\n\n&lt;p&gt;{&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;api&amp;quot;: &amp;quot;rest&amp;quot;,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;cookies&amp;quot;: [&amp;quot;firefox&amp;quot;],&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;include&amp;quot;: &amp;quot;posts&amp;quot;,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;order-files&amp;quot;: &amp;quot;asc&amp;quot;,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;order-posts&amp;quot;: &amp;quot;asc&amp;quot;,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;previews&amp;quot;: false,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;sleep-request&amp;quot;: [6.0, 12.0],&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;videos&amp;quot;: true&lt;/p&gt;\n\n&lt;p&gt;},&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I also attempted the directory option &amp;quot;cookies&amp;quot;: &amp;quot;G:\\gallery-dl\\cookies.txt&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;and I also tried to do it globally on top of the config file but it does not work. What am I missing if you can help me?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;{&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;extractor&amp;quot;:&lt;/p&gt;\n\n&lt;p&gt;{&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;base-directory&amp;quot;: &amp;quot;H:/gallery-dl-downloads&amp;quot;,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;parent-directory&amp;quot;: false,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;postprocessors&amp;quot;: null,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;archive&amp;quot;: null,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;cookies&amp;quot;: [&amp;quot;firefox&amp;quot;],&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;cookies-update&amp;quot;: true,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;proxy&amp;quot;: null,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;skip&amp;quot;: true,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;everything else works. and of course using --cookies-from... as a command works&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Note: if I attempt to download without the cookies I do get this error [instagram][error] HttpError: &amp;#39;401 Unauthorized&amp;#39; for &amp;#39;&lt;a href=\"https://www.instagram.com/api/v1/users/web_profile_info/\"&gt;https://www.instagram.com/api/v1/users/web_profile_info/&lt;/a&gt;&amp;#39;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r5ai7", "is_robot_indexable": true, "report_reasons": null, "author": "geoffrey801", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r5ai7/gallerydl_please_help_how_to_change_config_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r5ai7/gallerydl_please_help_how_to_change_config_file/", "subreddit_subscribers": 697945, "created_utc": 1692043276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just rented a storage unit to store some home items in, and was thinking about storing my back up offline external hard drive in there as well. \n\nIts a climate controlled space and indoors. \n\nI'm wondering if just putting the drive in a zip lock bag, then bubble wrapped into a plastic storage container is good enough, or if I should spring for something more durable/sealed like a pelican style case.\n\n-----\n\nCurrently I have a 42tb Nas set up with one drive failure protection and once a year I backup all new photos from that previous year to my external drive, which I leave offline. \n\nAs it sits, I have an offline backup, but not an offsite backup. There was a huge apartment fire a mile away from me, and it got me thinking that I'm not really protected from anything like a house fire, flood/water damage, etc.", "author_fullname": "t2_gots72j4a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to store off-site external hard drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qwuv8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692025130.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692024657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just rented a storage unit to store some home items in, and was thinking about storing my back up offline external hard drive in there as well. &lt;/p&gt;\n\n&lt;p&gt;Its a climate controlled space and indoors. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if just putting the drive in a zip lock bag, then bubble wrapped into a plastic storage container is good enough, or if I should spring for something more durable/sealed like a pelican style case.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Currently I have a 42tb Nas set up with one drive failure protection and once a year I backup all new photos from that previous year to my external drive, which I leave offline. &lt;/p&gt;\n\n&lt;p&gt;As it sits, I have an offline backup, but not an offsite backup. There was a huge apartment fire a mile away from me, and it got me thinking that I&amp;#39;m not really protected from anything like a house fire, flood/water damage, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qwuv8", "is_robot_indexable": true, "report_reasons": null, "author": "corgisandbikes", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qwuv8/best_way_to_store_offsite_external_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qwuv8/best_way_to_store_offsite_external_hard_drive/", "subreddit_subscribers": 697945, "created_utc": 1692024657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, currently I have a relatively tight budget, but I still need some kind of network storage. I have a PI4 and an around 8 year old pc (HP Compaq Elite 8300 Ultra-Slim Desktop). At the moment the PC is not used and the PI4 runs Home Assistant. I want to start some kind of local Jellyfin \"streaming service\". So im not sure which I should use for what and what would be the cheapest approach to run all the needed services and HDDs. I planned maybe around 3-6TB ? And found some local offers for used 1,5TB HDDs for 5-10\u20ac for each. Bigger one are much more expensive per TB. But I am open to other approaches, as long as they cheap!  \nThe lifespan should be at least 1 year, because currently I am in the last stages of my degree and the plan is to improve the setup around half a year after I finished and saved a little bit up :) ", "author_fullname": "t2_2f8ap6nu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheapest way for network storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qshla", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692013770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, currently I have a relatively tight budget, but I still need some kind of network storage. I have a PI4 and an around 8 year old pc (HP Compaq Elite 8300 Ultra-Slim Desktop). At the moment the PC is not used and the PI4 runs Home Assistant. I want to start some kind of local Jellyfin &amp;quot;streaming service&amp;quot;. So im not sure which I should use for what and what would be the cheapest approach to run all the needed services and HDDs. I planned maybe around 3-6TB ? And found some local offers for used 1,5TB HDDs for 5-10\u20ac for each. Bigger one are much more expensive per TB. But I am open to other approaches, as long as they cheap!&lt;br/&gt;\nThe lifespan should be at least 1 year, because currently I am in the last stages of my degree and the plan is to improve the setup around half a year after I finished and saved a little bit up :) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qshla", "is_robot_indexable": true, "report_reasons": null, "author": "manuelmitm", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qshla/cheapest_way_for_network_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qshla/cheapest_way_for_network_storage/", "subreddit_subscribers": 697945, "created_utc": 1692013770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How to better protect my files\n\nRecently, I began producing a lot of content regarding literature and philosophy that will only be published in the far away future, and I gained some obssession in syncing the files, but also protecting them and all.\n\nI use SyncBack Pro to copy the files to two flash drives: an SD (constantly plugged in through an adapter, Backup Option [never erases files, version modified files], ransomware detection on [doesn't run the profile if it detects a ransomware attack]); and a regular USB one (Sync and Backup options, mixed, also versions and searches for ransomware). Both are encrypted with BitLocker AES-256, password pretty strong (more than 20 characters).\n\nI also use SyncBack Pro and Cryptomator together to keep a copy of the same data in my Onedrive, MFA (will introduce a physical key in the forseeable future).\n\nI'm a fan of VeraCrypt, and I've been trying to find a way to implement its features in my workflow, but I currently can't see a way.\n\nSo I wanted an expert's opinion: Is there something wrong, or not as efficient as it could be in my workflow? What you recommend to make my files safer?\n\nThanks!", "author_fullname": "t2_s97tsr95", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Protect data and optimize backups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qmsdh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691995204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How to better protect my files&lt;/p&gt;\n\n&lt;p&gt;Recently, I began producing a lot of content regarding literature and philosophy that will only be published in the far away future, and I gained some obssession in syncing the files, but also protecting them and all.&lt;/p&gt;\n\n&lt;p&gt;I use SyncBack Pro to copy the files to two flash drives: an SD (constantly plugged in through an adapter, Backup Option [never erases files, version modified files], ransomware detection on [doesn&amp;#39;t run the profile if it detects a ransomware attack]); and a regular USB one (Sync and Backup options, mixed, also versions and searches for ransomware). Both are encrypted with BitLocker AES-256, password pretty strong (more than 20 characters).&lt;/p&gt;\n\n&lt;p&gt;I also use SyncBack Pro and Cryptomator together to keep a copy of the same data in my Onedrive, MFA (will introduce a physical key in the forseeable future).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a fan of VeraCrypt, and I&amp;#39;ve been trying to find a way to implement its features in my workflow, but I currently can&amp;#39;t see a way.&lt;/p&gt;\n\n&lt;p&gt;So I wanted an expert&amp;#39;s opinion: Is there something wrong, or not as efficient as it could be in my workflow? What you recommend to make my files safer?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qmsdh", "is_robot_indexable": true, "report_reasons": null, "author": "De_Vanitas", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qmsdh/protect_data_and_optimize_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qmsdh/protect_data_and_optimize_backups/", "subreddit_subscribers": 697945, "created_utc": 1691995204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The HLS methods seem to no longer be working.", "author_fullname": "t2_97nq119c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I download Digital Concert Hall (Berliner Philharmoniker) concerts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qm8kr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691993450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The HLS methods seem to no longer be working.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qm8kr", "is_robot_indexable": true, "report_reasons": null, "author": "regan_rn", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qm8kr/how_do_i_download_digital_concert_hall_berliner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qm8kr/how_do_i_download_digital_concert_hall_berliner/", "subreddit_subscribers": 697945, "created_utc": 1691993450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Its not obvious when they go into sleep mode. I looked in device manager, but not sure where to untick power saving. Not sure whether it changes anything.", "author_fullname": "t2_pr4df", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you stop external SSDs and HDDs from going into sleep mode?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r2u42", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692037888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Its not obvious when they go into sleep mode. I looked in device manager, but not sure where to untick power saving. Not sure whether it changes anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r2u42", "is_robot_indexable": true, "report_reasons": null, "author": "Dron22", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r2u42/how_do_you_stop_external_ssds_and_hdds_from_going/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r2u42/how_do_you_stop_external_ssds_and_hdds_from_going/", "subreddit_subscribers": 697945, "created_utc": 1692037888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi lads, I have a WD Black P10 5TB HDD that I bought February last year. Last November I had problems with very slow read/write speeds and found a pretty high Current Sector Pending count, which increased everytime I check again. After a hard format (and reformatting from exFAT to NTFS) the Current Sector Pending count reset to 0, however after a few weeks it started increasing to high levels again.\n\nI use the drive primarily as storage, and I torrent/seed on it almost constantly. Is this what's causing the current sector pending increase? Or is it purely a hardware issue? I'm about to get a (free) replacement, and I don't know if this is going to happen again.\n\nAny help is appreciated.", "author_fullname": "t2_286x0bni", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current Sector Pending count keeps increasing, is it because I torrent/seed directly into the drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r04a1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692031918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi lads, I have a WD Black P10 5TB HDD that I bought February last year. Last November I had problems with very slow read/write speeds and found a pretty high Current Sector Pending count, which increased everytime I check again. After a hard format (and reformatting from exFAT to NTFS) the Current Sector Pending count reset to 0, however after a few weeks it started increasing to high levels again.&lt;/p&gt;\n\n&lt;p&gt;I use the drive primarily as storage, and I torrent/seed on it almost constantly. Is this what&amp;#39;s causing the current sector pending increase? Or is it purely a hardware issue? I&amp;#39;m about to get a (free) replacement, and I don&amp;#39;t know if this is going to happen again.&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r04a1", "is_robot_indexable": true, "report_reasons": null, "author": "VETOFALLEN", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r04a1/current_sector_pending_count_keeps_increasing_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r04a1/current_sector_pending_count_keeps_increasing_is/", "subreddit_subscribers": 697945, "created_utc": 1692031918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am assuming some people on this sub have digitized tapes before, so maybe someone has run into this issue before? I have a minidv camcorder (DCR-trv70), but when plugging in the sony i.link/4pin firewire cable, nothing shows up and the camcorder says dv in? I still have no idea if this is a hardware or software issue because if the port was broken, the camcorder probably wouldn't detect any sort of dv connection.", "author_fullname": "t2_3d55bjdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help getting Sony Camcorder DV/firewire transfer working", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qq5up", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692006601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am assuming some people on this sub have digitized tapes before, so maybe someone has run into this issue before? I have a minidv camcorder (DCR-trv70), but when plugging in the sony i.link/4pin firewire cable, nothing shows up and the camcorder says dv in? I still have no idea if this is a hardware or software issue because if the port was broken, the camcorder probably wouldn&amp;#39;t detect any sort of dv connection.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qq5up", "is_robot_indexable": true, "report_reasons": null, "author": "Clawkikker", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15qq5up/help_getting_sony_camcorder_dvfirewire_transfer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qq5up/help_getting_sony_camcorder_dvfirewire_transfer/", "subreddit_subscribers": 697945, "created_utc": 1692006601.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello Everyone\n\nI have hacked together a CD Duplicator to be a five disc ripper, which I've nicknamed the Fair Use CD Ripper 5000, or F.U. 5000 for short (based on the old RipMonster 3000 that Patrick Norton made). \\*NOT AN AD. I mention the machine for the following...\n\n&amp;#x200B;\n\nI built the machine so I could go and re-rip my audio CD collection (numbering in the thousands). \n\n&amp;#x200B;\n\nI normally use XLD. I love XLD. Sadly, XLD does not \"batch rip\". You can queue up the CDs to rip in sequential order, but it's not much faster than just using one drive. dB Power Amp does five CDs at once (Secure, using AccurateRip). That is great.\n\n&amp;#x200B;\n\n**The issue:** The AIFF rips from XLD are perfect. The AIFF rips from dB Power Amp don't open in some apps. I have used ffprobe (and other apps) to look at both files, and both audiofiles APPEAR to be the same (codec, bit rate, et cetera), but there's something a bit off on the dB Power Amp files. I tried using FFmpeg to strip out as much of the metadata as possible (thinking that maybe some tag was messing with the audiofile), but no luck. I converted the files from s16be to s16le AIF files. Still some apps won't recognize the dB Power Amp rips.\n\n&amp;#x200B;\n\nHas anyone experienced this as well? \n\n&amp;#x200B;\n\nAs I rely on tags, I can't use WAV files. It has to be AIFF.\n\n&amp;#x200B;\n\nI love the speed of ripping five CDs at once, but if the resulting files are going to be finicky in some apps, then the speed boost is pointless.\n\n&amp;#x200B;\n\nThanks.\n\n&amp;#x200B;\n\nDaniel", "author_fullname": "t2_8e7mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AIFF files ripped by dB Power Amp vs XLD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qptq9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692005452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone&lt;/p&gt;\n\n&lt;p&gt;I have hacked together a CD Duplicator to be a five disc ripper, which I&amp;#39;ve nicknamed the Fair Use CD Ripper 5000, or F.U. 5000 for short (based on the old RipMonster 3000 that Patrick Norton made). *NOT AN AD. I mention the machine for the following...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I built the machine so I could go and re-rip my audio CD collection (numbering in the thousands). &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I normally use XLD. I love XLD. Sadly, XLD does not &amp;quot;batch rip&amp;quot;. You can queue up the CDs to rip in sequential order, but it&amp;#39;s not much faster than just using one drive. dB Power Amp does five CDs at once (Secure, using AccurateRip). That is great.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The issue:&lt;/strong&gt; The AIFF rips from XLD are perfect. The AIFF rips from dB Power Amp don&amp;#39;t open in some apps. I have used ffprobe (and other apps) to look at both files, and both audiofiles APPEAR to be the same (codec, bit rate, et cetera), but there&amp;#39;s something a bit off on the dB Power Amp files. I tried using FFmpeg to strip out as much of the metadata as possible (thinking that maybe some tag was messing with the audiofile), but no luck. I converted the files from s16be to s16le AIF files. Still some apps won&amp;#39;t recognize the dB Power Amp rips.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Has anyone experienced this as well? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As I rely on tags, I can&amp;#39;t use WAV files. It has to be AIFF.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I love the speed of ripping five CDs at once, but if the resulting files are going to be finicky in some apps, then the speed boost is pointless.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Daniel&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qptq9", "is_robot_indexable": true, "report_reasons": null, "author": "bratmix", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qptq9/aiff_files_ripped_by_db_power_amp_vs_xld/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qptq9/aiff_files_ripped_by_db_power_amp_vs_xld/", "subreddit_subscribers": 697945, "created_utc": 1692005452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm hoping to move away from storage spaces soon. I have a backup on a Synology device where I can scrub the data for errors. Is there something similar for Storage Spaces?", "author_fullname": "t2_94wlr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you scrub data on Microsoft Storage Spaces like you can on a Synology device or Freenas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15q9e2f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691958678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m hoping to move away from storage spaces soon. I have a backup on a Synology device where I can scrub the data for errors. Is there something similar for Storage Spaces?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15q9e2f", "is_robot_indexable": true, "report_reasons": null, "author": "Laser_Bones", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15q9e2f/can_you_scrub_data_on_microsoft_storage_spaces/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15q9e2f/can_you_scrub_data_on_microsoft_storage_spaces/", "subreddit_subscribers": 697945, "created_utc": 1691958678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I own and run commercial photography and video production company and we just switched over to all medium format stills camera as well as beginning to shoot significantly larger raw video projects.  Needless to say our raw capture and post-processing data needs have essentially more than quadrupled overnight.  The one thing about our workflow is that once a project is finished (typically about 2 months max from shoot to finished delivery) we hardly ever need to go back to the raw files and all our client-side finished assets live in the cloud as well.  \n\nWe've even more recently gotten in the habit of simply erasing session trash folders that we're like 99.9% we'll never need to go back to - errant captures, b-roll takes that we'll never use - shit that makes up probably 75% of our backed up data anyways.  We only trash these files a year after project completion, but I know - it's not exactly ideal either, and even despite that, the data storage needs are getting extremely critical.  \n\nSo basically, what is the best long-term storage-only solution on the market these days?  Im not looking for a system that we'll will be working off of or need networked access to.  Simply a big safe system we can move finished projects onto for sake keeping and archiving, and in the event we ever need to retrieve those files, we can simply copy them back onto a working drive or computer...  And something we don't have to replace every 5-8 years.", "author_fullname": "t2_rovkn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "commercial photo and video long term storage and archiving", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r2rra", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692037754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I own and run commercial photography and video production company and we just switched over to all medium format stills camera as well as beginning to shoot significantly larger raw video projects.  Needless to say our raw capture and post-processing data needs have essentially more than quadrupled overnight.  The one thing about our workflow is that once a project is finished (typically about 2 months max from shoot to finished delivery) we hardly ever need to go back to the raw files and all our client-side finished assets live in the cloud as well.  &lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve even more recently gotten in the habit of simply erasing session trash folders that we&amp;#39;re like 99.9% we&amp;#39;ll never need to go back to - errant captures, b-roll takes that we&amp;#39;ll never use - shit that makes up probably 75% of our backed up data anyways.  We only trash these files a year after project completion, but I know - it&amp;#39;s not exactly ideal either, and even despite that, the data storage needs are getting extremely critical.  &lt;/p&gt;\n\n&lt;p&gt;So basically, what is the best long-term storage-only solution on the market these days?  Im not looking for a system that we&amp;#39;ll will be working off of or need networked access to.  Simply a big safe system we can move finished projects onto for sake keeping and archiving, and in the event we ever need to retrieve those files, we can simply copy them back onto a working drive or computer...  And something we don&amp;#39;t have to replace every 5-8 years.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r2rra", "is_robot_indexable": true, "report_reasons": null, "author": "johnny_moist", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r2rra/commercial_photo_and_video_long_term_storage_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r2rra/commercial_photo_and_video_long_term_storage_and/", "subreddit_subscribers": 697945, "created_utc": 1692037754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just saw this pop up today. these appear to be new X18 drives. seems like a good price. [https://www.newegg.com/seagate-exos-x18-st12000nm000j-12tb/p/N82E16822185025](https://www.newegg.com/seagate-exos-x18-st12000nm000j-12tb/p/N82E16822185025)", "author_fullname": "t2_1fhm1svf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looks like a good deal", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qvsjs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692022205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just saw this pop up today. these appear to be new X18 drives. seems like a good price. &lt;a href=\"https://www.newegg.com/seagate-exos-x18-st12000nm000j-12tb/p/N82E16822185025\"&gt;https://www.newegg.com/seagate-exos-x18-st12000nm000j-12tb/p/N82E16822185025&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15qvsjs", "is_robot_indexable": true, "report_reasons": null, "author": "knave1906", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qvsjs/looks_like_a_good_deal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qvsjs/looks_like_a_good_deal/", "subreddit_subscribers": 697945, "created_utc": 1692022205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've looked at a lot of pre-built NAS, but they are either silly expensive for what is provided, don't have great software, or both.  So now re-looking at DIY.  Purposes are media server, NAS, and VM/lab.  \n\nI know what I'd build but ... I CAN'T FIND A NAS CASE?!  Looking for Micro-ATX with 8+ external facing drives that has decent ventilation.  Don't seem to be many cases - suggestions?", "author_fullname": "t2_306sxpyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Case - 8 Bay plus?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qte2s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692016262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve looked at a lot of pre-built NAS, but they are either silly expensive for what is provided, don&amp;#39;t have great software, or both.  So now re-looking at DIY.  Purposes are media server, NAS, and VM/lab.  &lt;/p&gt;\n\n&lt;p&gt;I know what I&amp;#39;d build but ... I CAN&amp;#39;T FIND A NAS CASE?!  Looking for Micro-ATX with 8+ external facing drives that has decent ventilation.  Don&amp;#39;t seem to be many cases - suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qte2s", "is_robot_indexable": true, "report_reasons": null, "author": "Snooksss", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qte2s/case_8_bay_plus/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qte2s/case_8_bay_plus/", "subreddit_subscribers": 697945, "created_utc": 1692016262.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}