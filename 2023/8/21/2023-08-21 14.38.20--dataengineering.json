{"kind": "Listing", "data": {"after": "t3_15ww4d4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_10yus1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Me around Customer Success", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 129, "top_awarded_type": null, "hide_score": false, "name": "t3_15wunwt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 111, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 111, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YdhE3MxcxLHm8SdnK3yc-4O_XJhyHXjEGG1a01mryno.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692585121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/vo8kt5akkdjb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/vo8kt5akkdjb1.jpg?auto=webp&amp;s=d0cca572b85375d244eb875c8a8d04206dd3d907", "width": 499, "height": 462}, "resolutions": [{"url": "https://preview.redd.it/vo8kt5akkdjb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=abdeba60ac1e6f4b6aca21b645479d9c4fa09631", "width": 108, "height": 99}, {"url": "https://preview.redd.it/vo8kt5akkdjb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5262b1f8448cbc740c744a8d71067c77a4e555ca", "width": 216, "height": 199}, {"url": "https://preview.redd.it/vo8kt5akkdjb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b29971b24014f4f9e977d138268670393f80f2b2", "width": 320, "height": 296}], "variants": {}, "id": "Iqf1j3Dls5H92oHXZ8Qtke74sbgTnixsbQeIMfz1aAQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "15wunwt", "is_robot_indexable": true, "report_reasons": null, "author": "little_dog_lover", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15wunwt/me_around_customer_success/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/vo8kt5akkdjb1.jpg", "subreddit_subscribers": 123885, "created_utc": 1692585121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I imagine the reality is...not quite so romantic.\n\nAlso, if I had to guess, I'd imagine that one of those is not quite the player people make it out to be.", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineers working in Government or Big Business, how do you feel when you hear people say stuff like \"They have our data! Who knows what they could be doing with it! \"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15wiqd5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692555669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I imagine the reality is...not quite so romantic.&lt;/p&gt;\n\n&lt;p&gt;Also, if I had to guess, I&amp;#39;d imagine that one of those is not quite the player people make it out to be.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "15wiqd5", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15wiqd5/data_engineers_working_in_government_or_big/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15wiqd5/data_engineers_working_in_government_or_big/", "subreddit_subscribers": 123885, "created_utc": 1692555669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I'm relatively new to the field of data engineering as well as the Azure platform. My team uses Azure Synapse and runs PySpark (Python) notebooks to transform the data. The current process loads the data tables as spark Dataframes, and keeps them as spark dataframes throughout the process.\n\nI am very familiar with python and pandas and would love to use pandas when manipulating data tables but I suspect there's some benefit to keeping them in the spark framework. Is the benefit that spark can process the data faster and in parallel where pandas is slower? \n\nFor context, the data we ingest and use is no bigger that 200K rows and 20 columns. Maybe there's a point where spark becomes much more efficient?\n\nI would love any insight anyone could give me. Thanks!", "author_fullname": "t2_2j1xb0wq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark vs. Pandas Dataframes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15wl1kn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692561105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I&amp;#39;m relatively new to the field of data engineering as well as the Azure platform. My team uses Azure Synapse and runs PySpark (Python) notebooks to transform the data. The current process loads the data tables as spark Dataframes, and keeps them as spark dataframes throughout the process.&lt;/p&gt;\n\n&lt;p&gt;I am very familiar with python and pandas and would love to use pandas when manipulating data tables but I suspect there&amp;#39;s some benefit to keeping them in the spark framework. Is the benefit that spark can process the data faster and in parallel where pandas is slower? &lt;/p&gt;\n\n&lt;p&gt;For context, the data we ingest and use is no bigger that 200K rows and 20 columns. Maybe there&amp;#39;s a point where spark becomes much more efficient?&lt;/p&gt;\n\n&lt;p&gt;I would love any insight anyone could give me. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15wl1kn", "is_robot_indexable": true, "report_reasons": null, "author": "No_Chapter9341", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15wl1kn/spark_vs_pandas_dataframes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15wl1kn/spark_vs_pandas_dataframes/", "subreddit_subscribers": 123885, "created_utc": 1692561105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently a sr data engineer for asset management firm. I am in my comfort zone and don't see much growth in my current role in next year. Working on aws, snowflake, airflow, dbt stack. \nWork life balance is amazing and pay is average. On the side, I\u2019m pursuing MS in data science with an objective to remain on the data side (data engineer, data scientist etc) and make more money.\n\nCurrently, I saw an opportunity to move to Risk team on business side as a Sr Risk Analyst as I have worked with one of the hiring managers previously. \nThe upside is that I\u2019ll be learning something new and it may open up path for me to gain domain knowledge (but limited to finance industry) and possibly I can go into Data science roles. \nThe downside I see is the comp numbers are going to remain the similar and it will most likely be a lot of work as compared to what I\u2019m used to because of steep learning curve.\nThey are using python but I'm not sure if I'll get much of data science stuff and most likely more general risk reporting/econometrics stuff. \nAlso, if I go on this path long term, my role wont remain industry agnostic.\nDo you think it is a good idea to move?\n\n\n\nEDIT:\n\nAbout me:\nI have 8-9 years of data engineering kind of roles. Started of in BI/sql for 1st two years and transitioned into cloud-aws, snowflake, airflow but not much experience in Spark or streaming (briefly worked on EMR). The thing is I don't find fulfillment in tasks focused on scaling, plug-and-play activities, configurations or dev-ops. I like to work more on building a core logic be it python, sql or even getting insights from excel and see direct impact to business.", "author_fullname": "t2_2xmjln12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good idea to move to business side?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15we82v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692546265.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692544983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a sr data engineer for asset management firm. I am in my comfort zone and don&amp;#39;t see much growth in my current role in next year. Working on aws, snowflake, airflow, dbt stack. \nWork life balance is amazing and pay is average. On the side, I\u2019m pursuing MS in data science with an objective to remain on the data side (data engineer, data scientist etc) and make more money.&lt;/p&gt;\n\n&lt;p&gt;Currently, I saw an opportunity to move to Risk team on business side as a Sr Risk Analyst as I have worked with one of the hiring managers previously. \nThe upside is that I\u2019ll be learning something new and it may open up path for me to gain domain knowledge (but limited to finance industry) and possibly I can go into Data science roles. \nThe downside I see is the comp numbers are going to remain the similar and it will most likely be a lot of work as compared to what I\u2019m used to because of steep learning curve.\nThey are using python but I&amp;#39;m not sure if I&amp;#39;ll get much of data science stuff and most likely more general risk reporting/econometrics stuff. \nAlso, if I go on this path long term, my role wont remain industry agnostic.\nDo you think it is a good idea to move?&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;About me:\nI have 8-9 years of data engineering kind of roles. Started of in BI/sql for 1st two years and transitioned into cloud-aws, snowflake, airflow but not much experience in Spark or streaming (briefly worked on EMR). The thing is I don&amp;#39;t find fulfillment in tasks focused on scaling, plug-and-play activities, configurations or dev-ops. I like to work more on building a core logic be it python, sql or even getting insights from excel and see direct impact to business.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15we82v", "is_robot_indexable": true, "report_reasons": null, "author": "Wise_tt_1126", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15we82v/good_idea_to_move_to_business_side/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15we82v/good_idea_to_move_to_business_side/", "subreddit_subscribers": 123885, "created_utc": 1692544983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Stored procedures is said here on like half of the posts as the main solution when not using DBT. When I'm very curious to know is how people are using stored procedures, and examples of them. Not like a description, but the actual code. Does anyone have code they can provide as an example, or a GitHub that has stored procedure code I can reference to learn more about it?", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone share some examples of a stored procedure that they use on the job often?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15weyf6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692546762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Stored procedures is said here on like half of the posts as the main solution when not using DBT. When I&amp;#39;m very curious to know is how people are using stored procedures, and examples of them. Not like a description, but the actual code. Does anyone have code they can provide as an example, or a GitHub that has stored procedure code I can reference to learn more about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15weyf6", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15weyf6/can_anyone_share_some_examples_of_a_stored/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15weyf6/can_anyone_share_some_examples_of_a_stored/", "subreddit_subscribers": 123885, "created_utc": 1692546762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a newbie, I just started a query where I have \\~1 million rows on bigquery and it has 25 columns. Rows have the type is RowIterator\n\nI wrote a script in Python to loop them and process data. I used:\n\n    client = bigquery.Client()\n    query_job = client.query(query)\n    rows = query_job.result()    (~1 million records)\n    df = rows.to_dataframe()    (*)\n    dict_rows = df.to_dict(orient=\"records\")\n    for row in dict_rows:\n        # process data\n\n(\\*) which takes around 5-6 minutes. This is not good for me.\n\nAny suggestions on how can I process it faster? If possible, show me a sample code. Thanks.\n\n&amp;#x200B;", "author_fullname": "t2_g6y2o1qgb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help, how to loop almost 1 million rows from the bigquery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15wvr3v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692589125.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692588174.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a newbie, I just started a query where I have ~1 million rows on bigquery and it has 25 columns. Rows have the type is RowIterator&lt;/p&gt;\n\n&lt;p&gt;I wrote a script in Python to loop them and process data. I used:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;client = bigquery.Client()\nquery_job = client.query(query)\nrows = query_job.result()    (~1 million records)\ndf = rows.to_dataframe()    (*)\ndict_rows = df.to_dict(orient=&amp;quot;records&amp;quot;)\nfor row in dict_rows:\n    # process data\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;(*) which takes around 5-6 minutes. This is not good for me.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions on how can I process it faster? If possible, show me a sample code. Thanks.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15wvr3v", "is_robot_indexable": true, "report_reasons": null, "author": "Hairy-Grab-2872", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15wvr3v/help_how_to_loop_almost_1_million_rows_from_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15wvr3v/help_how_to_loop_almost_1_million_rows_from_the/", "subreddit_subscribers": 123885, "created_utc": 1692588174.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I'm kind of at a crossroads professionally and I wonder if anyone else has been in a similar situation. I want to become a data engineer or architect. I don't have a heavy tech background. This probably a lot of personal information but it's all public on LinkedIn anyway. I currently work as a data analyst but I have a BA in Logistics Management, MS in supply chain, my MBA at Syracuse University is about 75% done but has a concentration in Business Analytics. I have PMP and CSCP certifications but nothing related to data science or engineering. I recently added a Graduate Certificate in DS to my degree plan at Syracuse but I'm not sure how much I'll gain from it.\n\nTo make this career change, would any of you recommend dropping my MBA and just pursuing a DS or DE Masters program 100%, or staying with the path that I'm on an pursuing a self-taught route?\n\nAre there any real legitimate learning paths or certifications? I'm so overwhelmed with everyone's \"guaranteed learning path\" or overpriced 44 week bootcamps, YouTube influencers telling you to learn or not to learn certain things. I find it hard to filter through the BS and I can't tell what I actually need to know. I want to learn but I just don't know what to study.\n\nTLDR: I want to become a data engineer but I don't know where to get the education and training. How did you do it?", "author_fullname": "t2_1qhmkv6s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Career/Education Advice to Become Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ws7wv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692578503.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m kind of at a crossroads professionally and I wonder if anyone else has been in a similar situation. I want to become a data engineer or architect. I don&amp;#39;t have a heavy tech background. This probably a lot of personal information but it&amp;#39;s all public on LinkedIn anyway. I currently work as a data analyst but I have a BA in Logistics Management, MS in supply chain, my MBA at Syracuse University is about 75% done but has a concentration in Business Analytics. I have PMP and CSCP certifications but nothing related to data science or engineering. I recently added a Graduate Certificate in DS to my degree plan at Syracuse but I&amp;#39;m not sure how much I&amp;#39;ll gain from it.&lt;/p&gt;\n\n&lt;p&gt;To make this career change, would any of you recommend dropping my MBA and just pursuing a DS or DE Masters program 100%, or staying with the path that I&amp;#39;m on an pursuing a self-taught route?&lt;/p&gt;\n\n&lt;p&gt;Are there any real legitimate learning paths or certifications? I&amp;#39;m so overwhelmed with everyone&amp;#39;s &amp;quot;guaranteed learning path&amp;quot; or overpriced 44 week bootcamps, YouTube influencers telling you to learn or not to learn certain things. I find it hard to filter through the BS and I can&amp;#39;t tell what I actually need to know. I want to learn but I just don&amp;#39;t know what to study.&lt;/p&gt;\n\n&lt;p&gt;TLDR: I want to become a data engineer but I don&amp;#39;t know where to get the education and training. How did you do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ws7wv", "is_robot_indexable": true, "report_reasons": null, "author": "LardyParty", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ws7wv/seeking_careereducation_advice_to_become_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ws7wv/seeking_careereducation_advice_to_become_data/", "subreddit_subscribers": 123885, "created_utc": 1692578503.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Fluke  is an open source project that I am working on for a while now that  attempts to group various cloud services under a single Python API. So,  for example, instead of having to learn \\`\\`boto3\\`\\`,  \\`\\`azure-storage-blob\\`\\` and \\`\\`google-cloud-storage\\`\\` to interact with the  corresponding cloud services, you can just use Fluke's API which is the  same for all three. On top of that, this API hides away much of the  complexity that arises from working with the aforementioned libraries,  so I think that it can help many of you with various tasks such as moving  data from and to the cloud, inspecting message queues, etc...\n\nWith the 5th version just being released, there is now support for Google Cloud Storage!\n\nYou can expore the project's Github page and docs in order to see what else Fluke has to offer:\n\n\\- PyPI: [https://pypi.org/project/fluke-api/](https://pypi.org/project/fluke-api/)\n\n\\- Github: [https://github.com/manoss96/fluke](https://github.com/manoss96/fluke)\n\n\\- Docs: [fluke.rtfd.io](https://fluke.rtfd.io/)\n\nLastly, feel free to play around with the library yourself, and please share your thoughts, as it means a lot :)", "author_fullname": "t2_q7l1xoqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fluke 0.5.0 is out with support for GCS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15wen22", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692545993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fluke  is an open source project that I am working on for a while now that  attempts to group various cloud services under a single Python API. So,  for example, instead of having to learn ``boto3``,  ``azure-storage-blob`` and ``google-cloud-storage`` to interact with the  corresponding cloud services, you can just use Fluke&amp;#39;s API which is the  same for all three. On top of that, this API hides away much of the  complexity that arises from working with the aforementioned libraries,  so I think that it can help many of you with various tasks such as moving  data from and to the cloud, inspecting message queues, etc...&lt;/p&gt;\n\n&lt;p&gt;With the 5th version just being released, there is now support for Google Cloud Storage!&lt;/p&gt;\n\n&lt;p&gt;You can expore the project&amp;#39;s Github page and docs in order to see what else Fluke has to offer:&lt;/p&gt;\n\n&lt;p&gt;- PyPI: &lt;a href=\"https://pypi.org/project/fluke-api/\"&gt;https://pypi.org/project/fluke-api/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;- Github: &lt;a href=\"https://github.com/manoss96/fluke\"&gt;https://github.com/manoss96/fluke&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;- Docs: &lt;a href=\"https://fluke.rtfd.io/\"&gt;fluke.rtfd.io&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Lastly, feel free to play around with the library yourself, and please share your thoughts, as it means a lot :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?auto=webp&amp;s=27b6869059bde930b8fa91e163c4a5b593a62755", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=967712caa32aa48e894a0097548ea87ec67be18c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a3c7948dff53aae03712fb7d592fa1bbddccbb4", "width": 216, "height": 216}], "variants": {}, "id": "IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15wen22", "is_robot_indexable": true, "report_reasons": null, "author": "WerdenWissen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15wen22/fluke_050_is_out_with_support_for_gcs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15wen22/fluke_050_is_out_with_support_for_gcs/", "subreddit_subscribers": 123885, "created_utc": 1692545993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Had a question about the zoom camp that was aired in early 2023, Would this still be a good course to review and learn since this is most recent camp or wait for another zoom camp? \n\nthanks!", "author_fullname": "t2_cuasmkxm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "any other DE doing zoom camps starting again", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ws5ue", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692578353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Had a question about the zoom camp that was aired in early 2023, Would this still be a good course to review and learn since this is most recent camp or wait for another zoom camp? &lt;/p&gt;\n\n&lt;p&gt;thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ws5ue", "is_robot_indexable": true, "report_reasons": null, "author": "Massive-Middle6043", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ws5ue/any_other_de_doing_zoom_camps_starting_again/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ws5ue/any_other_de_doing_zoom_camps_starting_again/", "subreddit_subscribers": 123885, "created_utc": 1692578353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says, how does one go about describing projects during the interview? How much detail should one go into? Also if a project i have done is not that challenging, how does one make it sound challenging? Any advice and help on this would be great.", "author_fullname": "t2_73llqzmo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Describe projects during interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15x3d70", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692612566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, how does one go about describing projects during the interview? How much detail should one go into? Also if a project i have done is not that challenging, how does one make it sound challenging? Any advice and help on this would be great.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15x3d70", "is_robot_indexable": true, "report_reasons": null, "author": "afnan_shahid92", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15x3d70/describe_projects_during_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15x3d70/describe_projects_during_interview/", "subreddit_subscribers": 123885, "created_utc": 1692612566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any recommendation on Query Monitoring and Query Performance Analysis Tools?", "author_fullname": "t2_7b8t7ihk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Query Performance Analysis Tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15wpxd1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692572559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any recommendation on Query Monitoring and Query Performance Analysis Tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15wpxd1", "is_robot_indexable": true, "report_reasons": null, "author": "satantine", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15wpxd1/query_performance_analysis_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15wpxd1/query_performance_analysis_tools/", "subreddit_subscribers": 123885, "created_utc": 1692572559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been working in big tech for a year+ (doing ML) but with everything happening in the LLM and Generative AI space, trying to understand if there is more opportunity there to be working in a growing startup or AI application layer business. Is this LLM hype more of a bubble at the moment? Given recent economic conditions as well, is it the right time to even think about making a switch?", "author_fullname": "t2_f062vphj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switch from Big Tech to Gen AI start-up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15wlknv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692562320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been working in big tech for a year+ (doing ML) but with everything happening in the LLM and Generative AI space, trying to understand if there is more opportunity there to be working in a growing startup or AI application layer business. Is this LLM hype more of a bubble at the moment? Given recent economic conditions as well, is it the right time to even think about making a switch?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15wlknv", "is_robot_indexable": true, "report_reasons": null, "author": "UnablePayment8366", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15wlknv/switch_from_big_tech_to_gen_ai_startup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15wlknv/switch_from_big_tech_to_gen_ai_startup/", "subreddit_subscribers": 123885, "created_utc": 1692562320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a existing pipeline in AWS, which we are making some enhancements.\n\nWe have a metadata table, which contains the data like list of files needed, we need to integrate the pipeline with metadata table on Athena ( The data is in the Deltalake format ), this is coming from our upstream project.\n\nWe use step functions as orchestrator, and we have 3 Sagemaker processing jobs, and these jobs needs the list of files to fetched from metadata table.\n\nWhat is the suitable service to use for fetching the metadata details and pass it to Sagemaker processing jobs in stepfunction? The rows may be 100s of 1000s of records for the first time run, and incremental load would be much lesser than &lt; 5k\n\nI made some analysis:\n\n* Using Glue is not suitable, since it doesn\u2019t return the output, we have to maintain the table in our project, which doesnt make sense ( team says no to this )\n* \u00a0Use lambda at the start of the Step Function, query the Athena table using AWS data wrangler and pass the output to Sagemaker processing jobs within the step function, but here if the number of records are more, passing it to  Sagemaker processing jobs might be not possible.\n* Currently cannot run the PySpark on Sagemaker processing jobs, as the docker image used for processing jobs, is internally customised image, which doesn't support pyspark yet.\n\nCan someone please help me here.", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help in designing the data pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15x5zvi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692620175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a existing pipeline in AWS, which we are making some enhancements.&lt;/p&gt;\n\n&lt;p&gt;We have a metadata table, which contains the data like list of files needed, we need to integrate the pipeline with metadata table on Athena ( The data is in the Deltalake format ), this is coming from our upstream project.&lt;/p&gt;\n\n&lt;p&gt;We use step functions as orchestrator, and we have 3 Sagemaker processing jobs, and these jobs needs the list of files to fetched from metadata table.&lt;/p&gt;\n\n&lt;p&gt;What is the suitable service to use for fetching the metadata details and pass it to Sagemaker processing jobs in stepfunction? The rows may be 100s of 1000s of records for the first time run, and incremental load would be much lesser than &amp;lt; 5k&lt;/p&gt;\n\n&lt;p&gt;I made some analysis:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Using Glue is not suitable, since it doesn\u2019t return the output, we have to maintain the table in our project, which doesnt make sense ( team says no to this )&lt;/li&gt;\n&lt;li&gt;\u00a0Use lambda at the start of the Step Function, query the Athena table using AWS data wrangler and pass the output to Sagemaker processing jobs within the step function, but here if the number of records are more, passing it to  Sagemaker processing jobs might be not possible.&lt;/li&gt;\n&lt;li&gt;Currently cannot run the PySpark on Sagemaker processing jobs, as the docker image used for processing jobs, is internally customised image, which doesn&amp;#39;t support pyspark yet.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Can someone please help me here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15x5zvi", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15x5zvi/need_help_in_designing_the_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15x5zvi/need_help_in_designing_the_data_pipeline/", "subreddit_subscribers": 123885, "created_utc": 1692620175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_563q0gq8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow on AKS: A Step-by-Step Guide to Helm Deployment on Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15x5w47", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/p3qOzh5coQq02vBPoV54_I7ypJCxV6CNUVkwm1Lw6U0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692619903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "fpgmaas.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.fpgmaas.com/blog/azure-airflow-kubernetes", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4WEotDB1-owd_7HCTZF5gc0MVhg5WmETW4-E1iFZs90.jpg?auto=webp&amp;s=c2155265f9e78be25354328295d88c2452e4bbdc", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/4WEotDB1-owd_7HCTZF5gc0MVhg5WmETW4-E1iFZs90.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3a1917cc8c81be0e70d049dcb2d1234f5e54f068", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/4WEotDB1-owd_7HCTZF5gc0MVhg5WmETW4-E1iFZs90.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=53f76788bf1e332241cb17817bef27ffa8e07090", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/4WEotDB1-owd_7HCTZF5gc0MVhg5WmETW4-E1iFZs90.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c016c632b2c5348dd638c524d035107318d9b453", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/4WEotDB1-owd_7HCTZF5gc0MVhg5WmETW4-E1iFZs90.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7f962760fba2475575e87915ef23e5ab0319f4a7", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/4WEotDB1-owd_7HCTZF5gc0MVhg5WmETW4-E1iFZs90.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2a0b3da62d5261abe40e169aa30f3f17bf257b1", "width": 960, "height": 960}], "variants": {}, "id": "R8hBZ5uNKoaDtATuAcDI_GJjoZoXrYVYYnnhY4gSACU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15x5w47", "is_robot_indexable": true, "report_reasons": null, "author": "fpgmaas", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15x5w47/airflow_on_aks_a_stepbystep_guide_to_helm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.fpgmaas.com/blog/azure-airflow-kubernetes", "subreddit_subscribers": 123885, "created_utc": 1692619903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vk94wnpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are Databricks clusters with Photon and Graviton instances worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_15x4mzp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QR9uZIK8E4i1W-VXhkdrskpHbx5-sS_9G9xG7c9C9bw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692616412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/sync-computing/are-databricks-clusters-with-photon-and-graviton-instances-worth-it-845641d464f2", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Sa2lUVeYfa6jZRAIgaVWtDKpRAkliNdjc0aOFGAXJ8c.jpg?auto=webp&amp;s=e853c5c1caf81d7ef43d8f35684685dbe5b3f15b", "width": 1200, "height": 752}, "resolutions": [{"url": "https://external-preview.redd.it/Sa2lUVeYfa6jZRAIgaVWtDKpRAkliNdjc0aOFGAXJ8c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=691afe58be5d89098222a7f1f87aa63e37cf60d7", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/Sa2lUVeYfa6jZRAIgaVWtDKpRAkliNdjc0aOFGAXJ8c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f51f9e61048446e5e3d6b1c9f35fbf0fe453a6b5", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/Sa2lUVeYfa6jZRAIgaVWtDKpRAkliNdjc0aOFGAXJ8c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a42db6192bc0a9712a9bca14f8ef44d5ee613a2a", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/Sa2lUVeYfa6jZRAIgaVWtDKpRAkliNdjc0aOFGAXJ8c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c22f909032b26dadeb6c06580e97a843572ae30b", "width": 640, "height": 401}, {"url": "https://external-preview.redd.it/Sa2lUVeYfa6jZRAIgaVWtDKpRAkliNdjc0aOFGAXJ8c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=03c225193e7b0aa0406eb79175f59ce0eb6a8b42", "width": 960, "height": 601}, {"url": "https://external-preview.redd.it/Sa2lUVeYfa6jZRAIgaVWtDKpRAkliNdjc0aOFGAXJ8c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6f1de9dd7f6ce63804e22dccc61b77f28d86c946", "width": 1080, "height": 676}], "variants": {}, "id": "ZuLlR_upXZxwjkg3UkMSv1lhlMX0nW7sdSmtzawbUCI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15x4mzp", "is_robot_indexable": true, "report_reasons": null, "author": "sync_jeff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15x4mzp/are_databricks_clusters_with_photon_and_graviton/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/sync-computing/are-databricks-clusters-with-photon-and-graviton-instances-worth-it-845641d464f2", "subreddit_subscribers": 123885, "created_utc": 1692616412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking to learn more from dbt in real world use, but I'm finding it slim pickings for public repos of active projects.   \nI understand most will be using dbt internally on private data, but if you know any public projects please share them", "author_fullname": "t2_crthfc7kd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good public dbt projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15wycw5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692596040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to learn more from dbt in real world use, but I&amp;#39;m finding it slim pickings for public repos of active projects.&lt;br/&gt;\nI understand most will be using dbt internally on private data, but if you know any public projects please share them&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15wycw5", "is_robot_indexable": true, "report_reasons": null, "author": "devschema", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15wycw5/any_good_public_dbt_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15wycw5/any_good_public_dbt_projects/", "subreddit_subscribers": 123885, "created_utc": 1692596040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nMy little brother has a background in marketing. Now he wants to pivot to data engineering to do marketing related data analysis. He knows nothing about CS, but want to study this DP-900 [course](https://learn.microsoft.com/en-us/certifications/exams/dp-900/) as the first step. Then use that certificate to look for a more data analysis related positions in the marketing field.\n\nI'm a bit worried when he jumps straight into those cloud platforms like Azure, AWS, or GCP instead of learning the CS fundamentals first. Being a dev myself, I think he should take something like Harvard's CS50 first before touching those proprietary cloud services.\n\nBut I'm not a data engineer myself, so I'm not entirely sure what the best path is.\n\nPlease give me your opinions on this. I appreciate it.", "author_fullname": "t2_9qgz0alb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should a total beginner study for MS DP-900 first without fundamental knowledge of Computer Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15wuze2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692586011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;My little brother has a background in marketing. Now he wants to pivot to data engineering to do marketing related data analysis. He knows nothing about CS, but want to study this DP-900 &lt;a href=\"https://learn.microsoft.com/en-us/certifications/exams/dp-900/\"&gt;course&lt;/a&gt; as the first step. Then use that certificate to look for a more data analysis related positions in the marketing field.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a bit worried when he jumps straight into those cloud platforms like Azure, AWS, or GCP instead of learning the CS fundamentals first. Being a dev myself, I think he should take something like Harvard&amp;#39;s CS50 first before touching those proprietary cloud services.&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m not a data engineer myself, so I&amp;#39;m not entirely sure what the best path is.&lt;/p&gt;\n\n&lt;p&gt;Please give me your opinions on this. I appreciate it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/n7eVnkHOEbyWEszewaRe8-4lIpzhXdlVryQ2OOmYVvI.jpg?auto=webp&amp;s=1d9ffdb5549ab4d056cf4ef8346ac264bfdfb701", "width": 1201, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/n7eVnkHOEbyWEszewaRe8-4lIpzhXdlVryQ2OOmYVvI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8b7f4942f89c0e88259c4dd81f58dd66733a5463", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/n7eVnkHOEbyWEszewaRe8-4lIpzhXdlVryQ2OOmYVvI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=36b6b6af2556d51933cfb924f71d8058d259b2ec", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/n7eVnkHOEbyWEszewaRe8-4lIpzhXdlVryQ2OOmYVvI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec48ab8cf4a89995b5da5200710b05c82171ac42", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/n7eVnkHOEbyWEszewaRe8-4lIpzhXdlVryQ2OOmYVvI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2f437ff05ef1d033e8a2f580efb4eec4409f312c", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/n7eVnkHOEbyWEszewaRe8-4lIpzhXdlVryQ2OOmYVvI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=96b13f8bc51792c0fb393fbcb9f45949e0870768", "width": 960, "height": 503}, {"url": "https://external-preview.redd.it/n7eVnkHOEbyWEszewaRe8-4lIpzhXdlVryQ2OOmYVvI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b0b4798624a861b5c5bd68abd9e9e9861fff9ddf", "width": 1080, "height": 566}], "variants": {}, "id": "u4iCB9u8wQ7lRe6Sbi5rOwFyGBC3KX1Xcj1Ti0fwG2E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15wuze2", "is_robot_indexable": true, "report_reasons": null, "author": "QuanDev", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15wuze2/should_a_total_beginner_study_for_ms_dp900_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15wuze2/should_a_total_beginner_study_for_ms_dp900_first/", "subreddit_subscribers": 123885, "created_utc": 1692586011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been using Azur Data Factory in a few projects at work now and have gone from thinking that it's so easy and nice to finding it cumbersome to work with and tedious to version control. I live in Europe which leans heavily to the M$ stack, so probability that I'll have to keep working with it is high. \n\nDoes anyone actually enjoy working with ADF? How do you use it? What do you like about it? What do you hate but hope will improve?", "author_fullname": "t2_8ay2350q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using ADF and like it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15x87gf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692625691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been using Azur Data Factory in a few projects at work now and have gone from thinking that it&amp;#39;s so easy and nice to finding it cumbersome to work with and tedious to version control. I live in Europe which leans heavily to the M$ stack, so probability that I&amp;#39;ll have to keep working with it is high. &lt;/p&gt;\n\n&lt;p&gt;Does anyone actually enjoy working with ADF? How do you use it? What do you like about it? What do you hate but hope will improve?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15x87gf", "is_robot_indexable": true, "report_reasons": null, "author": "rosenloev", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15x87gf/using_adf_and_like_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15x87gf/using_adf_and_like_it/", "subreddit_subscribers": 123885, "created_utc": 1692625691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Data Contract Pivot in Data Engineering: Community Highlights &amp; Pivotal Pieces that Shaped the Data Contracts Journey", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_15x7poc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qLTW_mjV52W6SUDrQvZ-lfrpm_QYaFspsaG8QAZifuI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692624530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/the-data-contract-pivot-in-data-engineering-8bb", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/t9CVk-ifx4O-rxZXGMEs19TudeVzvcBQWYhu1Tk20G8.jpg?auto=webp&amp;s=f440677d3cee897708b76a8fabcffa01fc52539c", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/t9CVk-ifx4O-rxZXGMEs19TudeVzvcBQWYhu1Tk20G8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=90f4740910f254f97632e3fc960d5acc7f2c16e4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/t9CVk-ifx4O-rxZXGMEs19TudeVzvcBQWYhu1Tk20G8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1053bff07d2241a4add89a4a5930f7efc324568d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/t9CVk-ifx4O-rxZXGMEs19TudeVzvcBQWYhu1Tk20G8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b557b70e8de568e9aa9c2e5d1fec3c0fa6939b63", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/t9CVk-ifx4O-rxZXGMEs19TudeVzvcBQWYhu1Tk20G8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ebd1ab6fc282785fb0872ab0280d3b86939285c0", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/t9CVk-ifx4O-rxZXGMEs19TudeVzvcBQWYhu1Tk20G8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=024993866fa3b9c6d7e4fd3f59410f3dba9c60cf", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/t9CVk-ifx4O-rxZXGMEs19TudeVzvcBQWYhu1Tk20G8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=827a097e4a0cc699f172adb1f4ba1b1d4f7ee492", "width": 1080, "height": 540}], "variants": {}, "id": "7R17GgzD_EJ83spdZhj1I7XCgO5rjgQb3VjCOEh6NV8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15x7poc", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15x7poc/the_data_contract_pivot_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/the-data-contract-pivot-in-data-engineering-8bb", "subreddit_subscribers": 123885, "created_utc": 1692624530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team is working with iot data for hvac systems for a large company. This data can tell us what the temperature is and what it is set to and a number of other things in their facilities. 1 month of data is approximately 200 million rows. Ideally I\u2019d like to filter to only data we need and make this usable for reporting. Currently using azure stack. Any suggestions on how to manage this data stack to get it under 500k rows for reporting? You can imagine if we store this data, we would be storing over a billion rows every year. \n\nLooking for any help I can get as far as what azure tools could be used and the most cost effective way to aggregate and transform 200 million rows at a time.\n\nOne note, the api does not allow us to pre filter the data. So we take it all or nothing. \n\nThanks in advance!", "author_fullname": "t2_6op3ytet", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IoT Big data architecture problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15x7pla", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692624524.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team is working with iot data for hvac systems for a large company. This data can tell us what the temperature is and what it is set to and a number of other things in their facilities. 1 month of data is approximately 200 million rows. Ideally I\u2019d like to filter to only data we need and make this usable for reporting. Currently using azure stack. Any suggestions on how to manage this data stack to get it under 500k rows for reporting? You can imagine if we store this data, we would be storing over a billion rows every year. &lt;/p&gt;\n\n&lt;p&gt;Looking for any help I can get as far as what azure tools could be used and the most cost effective way to aggregate and transform 200 million rows at a time.&lt;/p&gt;\n\n&lt;p&gt;One note, the api does not allow us to pre filter the data. So we take it all or nothing. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15x7pla", "is_robot_indexable": true, "report_reasons": null, "author": "thereisnospoon1188", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15x7pla/iot_big_data_architecture_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15x7pla/iot_big_data_architecture_problem/", "subreddit_subscribers": 123885, "created_utc": 1692624524.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My application only really has access to a Postgres database for everything. Anything else requires a lot of approval work. So I've been trying to design a service architecture that makes sense using mainly just Postgres unless there's some huge benefit otherwise.\n\nIf we have multiple services that require some coordination of state, and we create a separate \"data\" service database to help each service remain independent by giving them all one place to publish to.\n\nIn a simple example.\n\nService A, B, and C are responsible for X, Y, and Z things of a given unit. X, Y, and Z representing different states of the unit. Each service needs to know the state of the unit to inform parts of their what they do. Service A for example might need unit 1 to be in state Z before it can work on unit 2, however, maybe it can work on unit 3 in the meantime.\n\nEach service is able to publish to service D, which just stores it in a database, what they're responsible for. And each service can also query the state of the unit through D as well. In real life practical terms, I think I would just make a single table with fields for each service, each row being a unit. After all services are complete on the unit, the unit is removed from the table (or maybe kept, not sure it matters).\n\nIs this a passable idea as a means to separate shared data and coupling between microservices, to avoid for ex service B digging into service A's internal tables, and is there existing better vocabulary to describe this?", "author_fullname": "t2_sw73pen4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on this idea in microservice architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15x6n6i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692623390.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692621854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My application only really has access to a Postgres database for everything. Anything else requires a lot of approval work. So I&amp;#39;ve been trying to design a service architecture that makes sense using mainly just Postgres unless there&amp;#39;s some huge benefit otherwise.&lt;/p&gt;\n\n&lt;p&gt;If we have multiple services that require some coordination of state, and we create a separate &amp;quot;data&amp;quot; service database to help each service remain independent by giving them all one place to publish to.&lt;/p&gt;\n\n&lt;p&gt;In a simple example.&lt;/p&gt;\n\n&lt;p&gt;Service A, B, and C are responsible for X, Y, and Z things of a given unit. X, Y, and Z representing different states of the unit. Each service needs to know the state of the unit to inform parts of their what they do. Service A for example might need unit 1 to be in state Z before it can work on unit 2, however, maybe it can work on unit 3 in the meantime.&lt;/p&gt;\n\n&lt;p&gt;Each service is able to publish to service D, which just stores it in a database, what they&amp;#39;re responsible for. And each service can also query the state of the unit through D as well. In real life practical terms, I think I would just make a single table with fields for each service, each row being a unit. After all services are complete on the unit, the unit is removed from the table (or maybe kept, not sure it matters).&lt;/p&gt;\n\n&lt;p&gt;Is this a passable idea as a means to separate shared data and coupling between microservices, to avoid for ex service B digging into service A&amp;#39;s internal tables, and is there existing better vocabulary to describe this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15x6n6i", "is_robot_indexable": true, "report_reasons": null, "author": "CompetitionOk2693", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15x6n6i/thoughts_on_this_idea_in_microservice_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15x6n6i/thoughts_on_this_idea_in_microservice_architecture/", "subreddit_subscribers": 123885, "created_utc": 1692621854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have looked at ydata but it seems lacking in setting configurations for spark dataframes.\n\nSome things I have played around with \n- is pandas on spark api, iterate each attribute and use ps.concat\n- using spark via df.agg go to dict, function per data type ,then get pandas to read the dict\n\nIdeally output is an attribute name with its summary stats. Notably there are issues in having mixing columns types. \n\nAny ideas to help - need to be able to handle 10-30mill.", "author_fullname": "t2_f18go8zm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EDA summary for pyspark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15x42nb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692614902.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692614718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have looked at ydata but it seems lacking in setting configurations for spark dataframes.&lt;/p&gt;\n\n&lt;p&gt;Some things I have played around with \n- is pandas on spark api, iterate each attribute and use ps.concat\n- using spark via df.agg go to dict, function per data type ,then get pandas to read the dict&lt;/p&gt;\n\n&lt;p&gt;Ideally output is an attribute name with its summary stats. Notably there are issues in having mixing columns types. &lt;/p&gt;\n\n&lt;p&gt;Any ideas to help - need to be able to handle 10-30mill.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15x42nb", "is_robot_indexable": true, "report_reasons": null, "author": "d4njah", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15x42nb/eda_summary_for_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15x42nb/eda_summary_for_pyspark/", "subreddit_subscribers": 123885, "created_utc": 1692614718.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,  \nImagine one just break into DE world and has some spare time and some resources to learn. Don't know yet which technologies/tools his future project will use, but the company will align with his skills and preferences. This person should:  \n\n\n1. Start edx harvard cs50 python course\n2. Read T-SQL fundamentals book by Ben Itzik or an equivalent for other SQL distribution\n3. Watch udemy courses on cloud services related to DE and do the excercises/projects it contains on free trial/pay as you go\n4. Go through guides on certain tools like Databricks / Snowflake\n\nWhich one would be most beneficial in the short run? In the long run I guess all needs to be done, in some order, but what's best for now, considering that November is start of the project?  \n", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which activity to choose for upcoming commercial project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15x3n0c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692613401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\nImagine one just break into DE world and has some spare time and some resources to learn. Don&amp;#39;t know yet which technologies/tools his future project will use, but the company will align with his skills and preferences. This person should:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Start edx harvard cs50 python course&lt;/li&gt;\n&lt;li&gt;Read T-SQL fundamentals book by Ben Itzik or an equivalent for other SQL distribution&lt;/li&gt;\n&lt;li&gt;Watch udemy courses on cloud services related to DE and do the excercises/projects it contains on free trial/pay as you go&lt;/li&gt;\n&lt;li&gt;Go through guides on certain tools like Databricks / Snowflake&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Which one would be most beneficial in the short run? In the long run I guess all needs to be done, in some order, but what&amp;#39;s best for now, considering that November is start of the project?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15x3n0c", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15x3n0c/which_activity_to_choose_for_upcoming_commercial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15x3n0c/which_activity_to_choose_for_upcoming_commercial/", "subreddit_subscribers": 123885, "created_utc": 1692613401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi fellow Data Engineers, I have been stuck on trying to solve this problem. Does anyone know how to union 2 tables that different column numbers and order of columns? \n\nHere is an example of how to do for an instance of 2 tables: [https://stackoverflow.com/questions/2309943/unioning-two-tables-with-different-number-of-columns](https://stackoverflow.com/questions/2309943/unioning-two-tables-with-different-number-of-columns)  \n\n\nHow do I make this scalable so I can do this to 100s of tables? (for context, I just did a migration and now I have 100s of tables that need to be backfilled with their history data, problem is the backfill tables have extra columns and different order of columns which is making a simple UNION not possible)\n\nAny insights on how to go about this?", "author_fullname": "t2_aegi6eud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Union 2 tables with different columns numbers and order? (for a large number of tables)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15wwgaq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692590183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow Data Engineers, I have been stuck on trying to solve this problem. Does anyone know how to union 2 tables that different column numbers and order of columns? &lt;/p&gt;\n\n&lt;p&gt;Here is an example of how to do for an instance of 2 tables: &lt;a href=\"https://stackoverflow.com/questions/2309943/unioning-two-tables-with-different-number-of-columns\"&gt;https://stackoverflow.com/questions/2309943/unioning-two-tables-with-different-number-of-columns&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;How do I make this scalable so I can do this to 100s of tables? (for context, I just did a migration and now I have 100s of tables that need to be backfilled with their history data, problem is the backfill tables have extra columns and different order of columns which is making a simple UNION not possible)&lt;/p&gt;\n\n&lt;p&gt;Any insights on how to go about this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15wwgaq", "is_robot_indexable": true, "report_reasons": null, "author": "Minimum-Area-5695", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15wwgaq/how_to_union_2_tables_with_different_columns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15wwgaq/how_to_union_2_tables_with_different_columns/", "subreddit_subscribers": 123885, "created_utc": 1692590183.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an app that allows users to call an API that will then perform some NLP/ML. In order to keep track of when any given user is calling the respective endpoints, I keep track of the data being ingested into the endpoint in a data store. That data is then used to bill the user at the end of the month. I am debating on whether I should use CSV or parquet in an S3 data store to keep track of this data. Since I won't need real time read writes or anything like that at all, all I really care about is minimizing cost, so I'm leaning towards parquet. Anyone disagree with this, or are their any other ideas for storing this data that may better fit my needs? ", "author_fullname": "t2_86oq8zu7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CSV format VS parquet for storing user usage data in S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ww4d4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692589227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an app that allows users to call an API that will then perform some NLP/ML. In order to keep track of when any given user is calling the respective endpoints, I keep track of the data being ingested into the endpoint in a data store. That data is then used to bill the user at the end of the month. I am debating on whether I should use CSV or parquet in an S3 data store to keep track of this data. Since I won&amp;#39;t need real time read writes or anything like that at all, all I really care about is minimizing cost, so I&amp;#39;m leaning towards parquet. Anyone disagree with this, or are their any other ideas for storing this data that may better fit my needs? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ww4d4", "is_robot_indexable": true, "report_reasons": null, "author": "skelly0311", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ww4d4/csv_format_vs_parquet_for_storing_user_usage_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ww4d4/csv_format_vs_parquet_for_storing_user_usage_data/", "subreddit_subscribers": 123885, "created_utc": 1692589227.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}