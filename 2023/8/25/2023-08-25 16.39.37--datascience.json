{"kind": "Listing", "data": {"after": "t3_160cdp2", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a seasoned data professional That has worked at mainly big companies throughout my career, so all of my experiences lie primarily in Fortune 500 firms. Most of those experiences have been generally very positive. My latest company treated me pretty fairly, up until about 2 months ago when it became very clear what they are really like.\n\n\n- Mandatory social outings and extracurricular \"fun\" activities. For example, we were forced to go out to a park during the week and play soccer against another team in our department. Our manager showed up 40 minutes late and didn't even play. Just milled around, cheered our team on, and we lost.  Also had goofy t-shirts we were required to wear that said \"the eliminators\" or something like that\n\n\n- Tech stack extremely out of date and organization very siled. Some teams were very lucky to have Google BigQuery, and even though I had access to it, was often told I'm only allowed to use and create data sources in Microsoft Access, have to work exclusively out of Excel, have to be very very adept at using SQL, but I'm not allowed to create data tables in BigQuery, I have to do everything in legacy Microsoft Access because that's what the team is using and has used for many years, they're not able to or ready to transition into more modern data sources. We have Tableau, but we prefer to make everything in Excel. For example, using VBA to create tables repeatedly that could easily just be done in Tableau. Reinventing the entire wheel in Excel is absolutely insane\n\n\n- Manager was extremely lazy, unknowledgeable, unhelpful, and hardly ever did their job. This manager of course was included in the layoff, rightfully so. But the fact that they worked at the company for about 5 years is astounding to me. They would often schedule meetings and not even show up on time, arrive 20 minutes late, or they are driving in their car you can hear their turn signal, every single time, they have an excuse for why they are not doing their job during business hours. While you are sitting squarely at home being trustworthy independable, they are not doing their job. And their leaders were completely unaware of this for years? But they make it really hard for you to get promoted....\n\n\n- No in-role promotions. This was the first time I've ever heard of this in my life. I have never heard of a company that says you can't be promoted in the role that you are in. If you are an analyst, you can't possibly become a senior analyst. That's not possible. If you are senior analyst, you can't become the manager. A new entire role with different responsibilities has to be created by HR and you have to apply for it, compete against people throughout the company who probably aren't even in your department, you have like a 10% chance of getting hired into it, but likely you won't. So you're expected to stay in your job as long as possible even though they tell you after a year you can apply to other positions in the company, they frown upon that because they don't want turnover\n\n\n- Almost no yearly increase in salary. I was told that I was lucky, because as a hard worker, this year I was getting a 1.5% increase which is more than a lot of people were getting\n\n\n- No employee discount of any kind for the products that our company sells. Anytime this was brought up, the reason was that we get a bonus on top of that. Rivaling companies give discounts for their products, hours doesn't. So we have a 0% discount, and a bonus. But they sell it to us like we are so lucky to get this bonus, even though every single company offers a bonus\n\n\n- Laid off completely at random by our director, who read a message off a script in a monotone voice. Was told that I cannot apply to other positions as internal candidate, I would have to use the external career site and apply as if I am not an employee anymore, so in other words, follow the external applicant process. **They also laid off another person on my team who was pregnant and about to deliver a new child**. I considered myself very lucky. I found it extremely unprofessional, and downright evil that they would lay this person off Right before They are set to deliver a child. What kind of company could be so evil as to do that? There were other people on our team that were less qualified, and barely understood how to use Excel, and they chose someone who is extremely vulnerable and laid them off like that. Pretty crazy.... \n\n\n\n- Put me through a very rigorous application process like I am some random dude off the street. Admittedly, this is kind of normal I suppose, because they want to make sure they are making the right hiring decision. But some of the things I had to do and hoops I had to jump through were borderline insane. Take a full blown Excel test, take an SQL coding assignment, which is so weird because people in my previous department spoke to my skills and abilities. I was considered an expert in SQL, Python, Excel. So it was no mystery that I was extremely well versed in all of these things. Yet I had to do it anyway. \n\n\n- I was working remote previously, but this one is fully in office 5 days a week. No possibility to be remote. So now, I have to go from being fully remote to fully in office, costing me time, and resources, 10 hours a week in commuting back and forth completely erased from my life\n\n\n- After I provided my start date for the job that would be included on my offer letter, was contacted by HR and asked to start immediately, and gave me an extremely hard time about a trip that I had already planned for next week, flights, hotels, everything booked and paid for unable to be moved around. Their solution? I could take unpaid vacation to take the trip. What is the real reason you might ask that they have pushed my start date up so I have literally 3 days after getting the offer letter to start the job? **Because they would have to pay me out on my severance and then bring me back as a brand new employee.** \n\n- Overall lack of respect for their employees. Lay me off completely at random, put me through external hiring process like I'm a nobody even though I moved here for this company and job, then push my start date further without any care of consideration about what I have going on in my personal life\n\n\n- Company leaders are often in the news for a very negative reasons. For example, contributing to political action committees on behalf of the company for legislation that Is negatively targeting people of a certain ethnicity, extremely pro-conservative far right ideology throughout the entire company, and contributes financially to those sorts of political organizations. I personally am not going to voice my political opinions, but I'm just going to tell you right now, any company that contributes to political action committees with company funds, or the owners are very active and pushy and do that themselves is a really big red flag\n\n\n\n\nI honestly feel my skin crawl and just feel so wronged thinking back about the last 6 months with his company, even though the first year and a half with my team was actually generally pretty great, it just kind of traumatized me seeing how quick they were to throw people out of the company and then treat them like nothing, literal dirt, and then try and get them back in the company. Zero bargaining power or respect for employees, 100% of the respect for their own company", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If anyone is wondering what it's like working for a garbage company, then read this", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1606wng", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 257, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 257, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692894898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a seasoned data professional That has worked at mainly big companies throughout my career, so all of my experiences lie primarily in Fortune 500 firms. Most of those experiences have been generally very positive. My latest company treated me pretty fairly, up until about 2 months ago when it became very clear what they are really like.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Mandatory social outings and extracurricular &amp;quot;fun&amp;quot; activities. For example, we were forced to go out to a park during the week and play soccer against another team in our department. Our manager showed up 40 minutes late and didn&amp;#39;t even play. Just milled around, cheered our team on, and we lost.  Also had goofy t-shirts we were required to wear that said &amp;quot;the eliminators&amp;quot; or something like that&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Tech stack extremely out of date and organization very siled. Some teams were very lucky to have Google BigQuery, and even though I had access to it, was often told I&amp;#39;m only allowed to use and create data sources in Microsoft Access, have to work exclusively out of Excel, have to be very very adept at using SQL, but I&amp;#39;m not allowed to create data tables in BigQuery, I have to do everything in legacy Microsoft Access because that&amp;#39;s what the team is using and has used for many years, they&amp;#39;re not able to or ready to transition into more modern data sources. We have Tableau, but we prefer to make everything in Excel. For example, using VBA to create tables repeatedly that could easily just be done in Tableau. Reinventing the entire wheel in Excel is absolutely insane&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Manager was extremely lazy, unknowledgeable, unhelpful, and hardly ever did their job. This manager of course was included in the layoff, rightfully so. But the fact that they worked at the company for about 5 years is astounding to me. They would often schedule meetings and not even show up on time, arrive 20 minutes late, or they are driving in their car you can hear their turn signal, every single time, they have an excuse for why they are not doing their job during business hours. While you are sitting squarely at home being trustworthy independable, they are not doing their job. And their leaders were completely unaware of this for years? But they make it really hard for you to get promoted....&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;No in-role promotions. This was the first time I&amp;#39;ve ever heard of this in my life. I have never heard of a company that says you can&amp;#39;t be promoted in the role that you are in. If you are an analyst, you can&amp;#39;t possibly become a senior analyst. That&amp;#39;s not possible. If you are senior analyst, you can&amp;#39;t become the manager. A new entire role with different responsibilities has to be created by HR and you have to apply for it, compete against people throughout the company who probably aren&amp;#39;t even in your department, you have like a 10% chance of getting hired into it, but likely you won&amp;#39;t. So you&amp;#39;re expected to stay in your job as long as possible even though they tell you after a year you can apply to other positions in the company, they frown upon that because they don&amp;#39;t want turnover&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Almost no yearly increase in salary. I was told that I was lucky, because as a hard worker, this year I was getting a 1.5% increase which is more than a lot of people were getting&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;No employee discount of any kind for the products that our company sells. Anytime this was brought up, the reason was that we get a bonus on top of that. Rivaling companies give discounts for their products, hours doesn&amp;#39;t. So we have a 0% discount, and a bonus. But they sell it to us like we are so lucky to get this bonus, even though every single company offers a bonus&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Laid off completely at random by our director, who read a message off a script in a monotone voice. Was told that I cannot apply to other positions as internal candidate, I would have to use the external career site and apply as if I am not an employee anymore, so in other words, follow the external applicant process. &lt;strong&gt;They also laid off another person on my team who was pregnant and about to deliver a new child&lt;/strong&gt;. I considered myself very lucky. I found it extremely unprofessional, and downright evil that they would lay this person off Right before They are set to deliver a child. What kind of company could be so evil as to do that? There were other people on our team that were less qualified, and barely understood how to use Excel, and they chose someone who is extremely vulnerable and laid them off like that. Pretty crazy.... &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Put me through a very rigorous application process like I am some random dude off the street. Admittedly, this is kind of normal I suppose, because they want to make sure they are making the right hiring decision. But some of the things I had to do and hoops I had to jump through were borderline insane. Take a full blown Excel test, take an SQL coding assignment, which is so weird because people in my previous department spoke to my skills and abilities. I was considered an expert in SQL, Python, Excel. So it was no mystery that I was extremely well versed in all of these things. Yet I had to do it anyway. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I was working remote previously, but this one is fully in office 5 days a week. No possibility to be remote. So now, I have to go from being fully remote to fully in office, costing me time, and resources, 10 hours a week in commuting back and forth completely erased from my life&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;After I provided my start date for the job that would be included on my offer letter, was contacted by HR and asked to start immediately, and gave me an extremely hard time about a trip that I had already planned for next week, flights, hotels, everything booked and paid for unable to be moved around. Their solution? I could take unpaid vacation to take the trip. What is the real reason you might ask that they have pushed my start date up so I have literally 3 days after getting the offer letter to start the job? &lt;strong&gt;Because they would have to pay me out on my severance and then bring me back as a brand new employee.&lt;/strong&gt; &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Overall lack of respect for their employees. Lay me off completely at random, put me through external hiring process like I&amp;#39;m a nobody even though I moved here for this company and job, then push my start date further without any care of consideration about what I have going on in my personal life&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Company leaders are often in the news for a very negative reasons. For example, contributing to political action committees on behalf of the company for legislation that Is negatively targeting people of a certain ethnicity, extremely pro-conservative far right ideology throughout the entire company, and contributes financially to those sorts of political organizations. I personally am not going to voice my political opinions, but I&amp;#39;m just going to tell you right now, any company that contributes to political action committees with company funds, or the owners are very active and pushy and do that themselves is a really big red flag&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I honestly feel my skin crawl and just feel so wronged thinking back about the last 6 months with his company, even though the first year and a half with my team was actually generally pretty great, it just kind of traumatized me seeing how quick they were to throw people out of the company and then treat them like nothing, literal dirt, and then try and get them back in the company. Zero bargaining power or respect for employees, 100% of the respect for their own company&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1606wng", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 74, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1606wng/if_anyone_is_wondering_what_its_like_working_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1606wng/if_anyone_is_wondering_what_its_like_working_for/", "subreddit_subscribers": 1012920, "created_utc": 1692894898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I applied for an internship in a company. They responded with a link to assignment which they call assessment round. The assignment feels like an entire project itself.\nThey sent a file with 115 urls to scrape data , clean it, perform sentiment analysis on it and restructure it \"strictly\" according to their given format. They've given 6 days to complete with a \"the sooner the better\". Is this common? If they want to assess my knowledge, can't it be done using data of 1 or 2 websites?\nHow should i respond?", "author_fullname": "t2_9o06k4n6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Company giving entire project as assignment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160s4dw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 92, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 92, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692948438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I applied for an internship in a company. They responded with a link to assignment which they call assessment round. The assignment feels like an entire project itself.\nThey sent a file with 115 urls to scrape data , clean it, perform sentiment analysis on it and restructure it &amp;quot;strictly&amp;quot; according to their given format. They&amp;#39;ve given 6 days to complete with a &amp;quot;the sooner the better&amp;quot;. Is this common? If they want to assess my knowledge, can&amp;#39;t it be done using data of 1 or 2 websites?\nHow should i respond?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160s4dw", "is_robot_indexable": true, "report_reasons": null, "author": "Far_Wolverine_198", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160s4dw/company_giving_entire_project_as_assignment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160s4dw/company_giving_entire_project_as_assignment/", "subreddit_subscribers": 1012920, "created_utc": 1692948438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m 7 months in at my current job and I really like it. The only downside is I feel I\u2019m being seriously underpaid on about \u00a340k/year. I even know that a new guy is getting \u00a360k/year and he hardly does any work whereas I\u2019ve delivered 2 big projects so far. \n\nI started interviewing and have received 2 offers in the region \u00a360k-\u00a370k/year. They\u2019re both start-ups but I would have to commute so I don\u2019t really want to take these offers. \n\nCan I go to my boss and ask for a raise? I\u2019m worried this will sour our relationship and he will look to get rid of me at the first opportunity. I also don\u2019t want to be seen as a job hopper by recruiters.", "author_fullname": "t2_1rp1btfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it ok to use an offer to negotiate a pay rise?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160szsk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692951432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m 7 months in at my current job and I really like it. The only downside is I feel I\u2019m being seriously underpaid on about \u00a340k/year. I even know that a new guy is getting \u00a360k/year and he hardly does any work whereas I\u2019ve delivered 2 big projects so far. &lt;/p&gt;\n\n&lt;p&gt;I started interviewing and have received 2 offers in the region \u00a360k-\u00a370k/year. They\u2019re both start-ups but I would have to commute so I don\u2019t really want to take these offers. &lt;/p&gt;\n\n&lt;p&gt;Can I go to my boss and ask for a raise? I\u2019m worried this will sour our relationship and he will look to get rid of me at the first opportunity. I also don\u2019t want to be seen as a job hopper by recruiters.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160szsk", "is_robot_indexable": true, "report_reasons": null, "author": "nullspace1729", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160szsk/is_it_ok_to_use_an_offer_to_negotiate_a_pay_rise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160szsk/is_it_ok_to_use_an_offer_to_negotiate_a_pay_rise/", "subreddit_subscribers": 1012920, "created_utc": 1692951432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How much could a person making 60k a year in their first data analyst job increase their salary over 2-3 years?\n\nI know this depends on many things but what would be a good estimate?\n\nHow much did you guys' salary increase over the years? How did the difficulty of your job change with the increase in salary?", "author_fullname": "t2_7w5927ke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is a realistic increase in salary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160dbq0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692909204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How much could a person making 60k a year in their first data analyst job increase their salary over 2-3 years?&lt;/p&gt;\n\n&lt;p&gt;I know this depends on many things but what would be a good estimate?&lt;/p&gt;\n\n&lt;p&gt;How much did you guys&amp;#39; salary increase over the years? How did the difficulty of your job change with the increase in salary?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160dbq0", "is_robot_indexable": true, "report_reasons": null, "author": "SouthpawBeats", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160dbq0/what_is_a_realistic_increase_in_salary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160dbq0/what_is_a_realistic_increase_in_salary/", "subreddit_subscribers": 1012920, "created_utc": 1692909204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Why does every Data Science/Data Analyst recruiter ask this question? And what is the correct answer to this? \n\nAre they judging you ( as a candidate) by this parameter as well?", "author_fullname": "t2_sv03qre4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are you interviewing with other companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160bn35", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692905348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why does every Data Science/Data Analyst recruiter ask this question? And what is the correct answer to this? &lt;/p&gt;\n\n&lt;p&gt;Are they judging you ( as a candidate) by this parameter as well?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160bn35", "is_robot_indexable": true, "report_reasons": null, "author": "ducksick444", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160bn35/are_you_interviewing_with_other_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160bn35/are_you_interviewing_with_other_companies/", "subreddit_subscribers": 1012920, "created_utc": 1692905348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4a27h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit's Remote Director of Data Science &amp; Analytics Job Opening", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "name": "t3_160l5bg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 11, "domain": "boards.greenhouse.io", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/8gsh2f5MFaoNKTww0T7awPz6l_hpjK1QdxAyhOtPoY8.jpg", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692927345.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://boards.greenhouse.io/reddit/jobs/5307342", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DZvjIjS8guBROBzL1n09L4N3L7uvuHGidMuNTbd0YaQ.jpg?auto=webp&amp;s=26fc915a62789837f5855ef48d278c9eaa78b82d", "width": 1200, "height": 580}, "resolutions": [{"url": "https://external-preview.redd.it/DZvjIjS8guBROBzL1n09L4N3L7uvuHGidMuNTbd0YaQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0fad62b2bb51655161eb3597c8d15be5721314a5", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/DZvjIjS8guBROBzL1n09L4N3L7uvuHGidMuNTbd0YaQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c14d5b50f7743c58b52f0ffb9c83cd625c9aec9", "width": 216, "height": 104}, {"url": "https://external-preview.redd.it/DZvjIjS8guBROBzL1n09L4N3L7uvuHGidMuNTbd0YaQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7390be8c7df2cca382b04f9bb977020a6ba4c415", "width": 320, "height": 154}, {"url": "https://external-preview.redd.it/DZvjIjS8guBROBzL1n09L4N3L7uvuHGidMuNTbd0YaQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ee80bc33312526a81dc30cb3fc4f79e18362f647", "width": 640, "height": 309}, {"url": "https://external-preview.redd.it/DZvjIjS8guBROBzL1n09L4N3L7uvuHGidMuNTbd0YaQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a08cef673abb5c2296c170fe0552484634e3579", "width": 960, "height": 464}, {"url": "https://external-preview.redd.it/DZvjIjS8guBROBzL1n09L4N3L7uvuHGidMuNTbd0YaQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8ac8db2485fb3e7e16dca2ae9df6c0afc3a98b5c", "width": 1080, "height": 522}], "variants": {}, "id": "q9qkFVEGfHE1kzfLkgOjev_a_VxK4rjX8OB33p39w7Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "160l5bg", "is_robot_indexable": true, "report_reasons": null, "author": "antdude", "discussion_type": null, "num_comments": 7, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160l5bg/reddits_remote_director_of_data_science_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://boards.greenhouse.io/reddit/jobs/5307342", "subreddit_subscribers": 1012920, "created_utc": 1692927345.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I graduated from UW - Madison with a bachelor's in Data Science and 3.45 GPA. It's a relatively new program but the courses were pretty rigorous and already being taught for Comp Sci or Stats. In retrospect I wish I would've done Stats or Comp Sci just to have a strong foundation in either and then pursue a Data Science Masters. \n\nThat leads to where I am now. I got my first job back in April making around 70k. I like it enough but I'm incredibly bored and missing school. I think I'd like to go back for my masters and my company offers tuition reimbursement but I don't know whats is best to pursue career wise and I really don't know any other Data Analysts or Scientists to ask. (Due to the pandemic I feel like I'd have a tough time finding 3 people to write my recommendation letters)\n\n\u2022 Financially and career wise, should I pursue a Stats, DS or CS masters (or other)? I'm worried doing  DS again would make me appear not well rounded. \n\n\u2022Should I even bother to look at schools outside the US?\n\n\u2022If pursuing a school in the US is it better to do Online or in person? \n\n\u2022What are schools are the best Return on investment considering my GPA and recommendation letter situation. \n\nApologize in advance if this is a little long winded. Thank you for any advice you have.", "author_fullname": "t2_c3scjxgdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Grad school: Stats, DS or CS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160hctw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692918193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I graduated from UW - Madison with a bachelor&amp;#39;s in Data Science and 3.45 GPA. It&amp;#39;s a relatively new program but the courses were pretty rigorous and already being taught for Comp Sci or Stats. In retrospect I wish I would&amp;#39;ve done Stats or Comp Sci just to have a strong foundation in either and then pursue a Data Science Masters. &lt;/p&gt;\n\n&lt;p&gt;That leads to where I am now. I got my first job back in April making around 70k. I like it enough but I&amp;#39;m incredibly bored and missing school. I think I&amp;#39;d like to go back for my masters and my company offers tuition reimbursement but I don&amp;#39;t know whats is best to pursue career wise and I really don&amp;#39;t know any other Data Analysts or Scientists to ask. (Due to the pandemic I feel like I&amp;#39;d have a tough time finding 3 people to write my recommendation letters)&lt;/p&gt;\n\n&lt;p&gt;\u2022 Financially and career wise, should I pursue a Stats, DS or CS masters (or other)? I&amp;#39;m worried doing  DS again would make me appear not well rounded. &lt;/p&gt;\n\n&lt;p&gt;\u2022Should I even bother to look at schools outside the US?&lt;/p&gt;\n\n&lt;p&gt;\u2022If pursuing a school in the US is it better to do Online or in person? &lt;/p&gt;\n\n&lt;p&gt;\u2022What are schools are the best Return on investment considering my GPA and recommendation letter situation. &lt;/p&gt;\n\n&lt;p&gt;Apologize in advance if this is a little long winded. Thank you for any advice you have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160hctw", "is_robot_indexable": true, "report_reasons": null, "author": "a_rope_most_unwary", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160hctw/grad_school_stats_ds_or_cs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160hctw/grad_school_stats_ds_or_cs/", "subreddit_subscribers": 1012920, "created_utc": 1692918193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, I'd appreciate some advice.\n\nI started working in this company 1.5 years ago as a data scientist. However, I'm not getting \"data science tasks\" to my satisfaction, but rather engineering tasks. Although I raised this issue to the management multiple times and they said \"Ok no worries we'll take it into account\", they keep giving me engineering tasks and they give the data science tasks to another guy in my team.\n\nNow the pay is good and it's mostly a remote job, so it's quite convenient. But the main reason I accepted the offer in the first place is because I wanted to develop my career in data science (I had had 8 years of experience as a software engineer by the time I started here, and decided to switch to data science after completing my MSc).\n\nMy question is whether I should start looking for something new because I'm not getting what I want here, or just appreciate what I have and stay. It's important to mention that 1. I don't hate what I do, but I just don't feel satisfied, because I worked hard to become a data scientist and I'm not really doing data science tasks, and 2. I do get to work on very few data science tasks from time to time, but they always get put on hold at some point and never end up in production because management assigns me \"higher priority (engineering) tasks\".\n\nWhat would you do?", "author_fullname": "t2_3tkx9z8p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Data scientist\", not doing data science tasks. Should I start looking?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160tzx8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692954909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I&amp;#39;d appreciate some advice.&lt;/p&gt;\n\n&lt;p&gt;I started working in this company 1.5 years ago as a data scientist. However, I&amp;#39;m not getting &amp;quot;data science tasks&amp;quot; to my satisfaction, but rather engineering tasks. Although I raised this issue to the management multiple times and they said &amp;quot;Ok no worries we&amp;#39;ll take it into account&amp;quot;, they keep giving me engineering tasks and they give the data science tasks to another guy in my team.&lt;/p&gt;\n\n&lt;p&gt;Now the pay is good and it&amp;#39;s mostly a remote job, so it&amp;#39;s quite convenient. But the main reason I accepted the offer in the first place is because I wanted to develop my career in data science (I had had 8 years of experience as a software engineer by the time I started here, and decided to switch to data science after completing my MSc).&lt;/p&gt;\n\n&lt;p&gt;My question is whether I should start looking for something new because I&amp;#39;m not getting what I want here, or just appreciate what I have and stay. It&amp;#39;s important to mention that 1. I don&amp;#39;t hate what I do, but I just don&amp;#39;t feel satisfied, because I worked hard to become a data scientist and I&amp;#39;m not really doing data science tasks, and 2. I do get to work on very few data science tasks from time to time, but they always get put on hold at some point and never end up in production because management assigns me &amp;quot;higher priority (engineering) tasks&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;What would you do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160tzx8", "is_robot_indexable": true, "report_reasons": null, "author": "RunOrDieTrying", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160tzx8/data_scientist_not_doing_data_science_tasks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160tzx8/data_scientist_not_doing_data_science_tasks/", "subreddit_subscribers": 1012920, "created_utc": 1692954909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The roles seems to be a truly DS role with a lot of work to do in ML/DL/RL and a bit of data grunt work as expected in any data role.", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should be the expected base salary for Sr. DS at Walgreens in Chicago area?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160do2x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692909971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The roles seems to be a truly DS role with a lot of work to do in ML/DL/RL and a bit of data grunt work as expected in any data role.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160do2x", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160do2x/what_should_be_the_expected_base_salary_for_sr_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160do2x/what_should_be_the_expected_base_salary_for_sr_ds/", "subreddit_subscribers": 1012920, "created_utc": 1692909971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Say you\u2019ve plotted a correlation matrix of all features, including the target variable. Are there any techniques or rules of thumb when it comes to evaluating if your data has sufficiently explanatory features? \n\nIs it possible for all feature to have a very small correlation (e.g abs(Cor(x)) &lt; 0.05) and still accurately predict the target variable? I know \u201caccurately\u201d is undefined here, but I\u2019m looking for intuitions and evidence that a feature set with respective low correlations to a target can still have strong predictive power when said features are considered in unison. I hope I\u2019ve communicated this clearly, thanks.", "author_fullname": "t2_ca6ooyfb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Determining potential feature set predictive power from correlation matrix", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16072yt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692895291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you\u2019ve plotted a correlation matrix of all features, including the target variable. Are there any techniques or rules of thumb when it comes to evaluating if your data has sufficiently explanatory features? &lt;/p&gt;\n\n&lt;p&gt;Is it possible for all feature to have a very small correlation (e.g abs(Cor(x)) &amp;lt; 0.05) and still accurately predict the target variable? I know \u201caccurately\u201d is undefined here, but I\u2019m looking for intuitions and evidence that a feature set with respective low correlations to a target can still have strong predictive power when said features are considered in unison. I hope I\u2019ve communicated this clearly, thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16072yt", "is_robot_indexable": true, "report_reasons": null, "author": "ExplorerSpiritual266", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16072yt/determining_potential_feature_set_predictive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16072yt/determining_potential_feature_set_predictive/", "subreddit_subscribers": 1012920, "created_utc": 1692895291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A few days ago, I came across an interesting discussion of a poll held by some guy. People responding to this poll were basically offered  to choose between a blue pill or a red pill. The condition was simple: if more than 50% of them chose the blue pill, everyone lives - if not, those who had chosen the red pills lived, and the blue pills died. Quite a few people in the comments mentioned that the dilemma was rather mathematical than moral, mentioning the Nash equilibrium, which led me to dive deeper into what they really meant. I discovered that the Nash equilibrium is a concept found in game theory where people follow a single strategy within a given game, independent of what others might be doing.  \n It got me thinking that this can be applied to understand and model interactions between multiple trading algorithms or market participants. Trading is the perfect example of a free market with no regulation in the strategy dimension. Every player has the same goal- to increase self-preservation on the market in the long term. But the rules are not as obvious as in the poll I mentioned above, and that's why it's much harder to achieve the Nash equilibrium in trading.   \nTrading is a complex game, as we have to deal with a whole array of the flawed psychological traits of human players. On the other hand, plenty of strategies are now developed with the help of AI-powered solutions, like [Immediate Edge](https://immediateedgeapp.org/), for example.  \nSo, my idea is that AI-powered trading will make the market more predictable and stable as human psychology will be taken out of the equation. Reaching the Nash equilibrium in trading is often counterintuitive, as short-term losses often lead to long-term gains, but AI has no such flaws as human psychology does. So, won't we be much better off when less trading is done by people and more by AI?  ", "author_fullname": "t2_b99aey2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Nash equilibrium and trading", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160zb62", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.52, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692970030.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few days ago, I came across an interesting discussion of a poll held by some guy. People responding to this poll were basically offered  to choose between a blue pill or a red pill. The condition was simple: if more than 50% of them chose the blue pill, everyone lives - if not, those who had chosen the red pills lived, and the blue pills died. Quite a few people in the comments mentioned that the dilemma was rather mathematical than moral, mentioning the Nash equilibrium, which led me to dive deeper into what they really meant. I discovered that the Nash equilibrium is a concept found in game theory where people follow a single strategy within a given game, independent of what others might be doing.&lt;br/&gt;\n It got me thinking that this can be applied to understand and model interactions between multiple trading algorithms or market participants. Trading is the perfect example of a free market with no regulation in the strategy dimension. Every player has the same goal- to increase self-preservation on the market in the long term. But the rules are not as obvious as in the poll I mentioned above, and that&amp;#39;s why it&amp;#39;s much harder to achieve the Nash equilibrium in trading.&lt;br/&gt;\nTrading is a complex game, as we have to deal with a whole array of the flawed psychological traits of human players. On the other hand, plenty of strategies are now developed with the help of AI-powered solutions, like &lt;a href=\"https://immediateedgeapp.org/\"&gt;Immediate Edge&lt;/a&gt;, for example.&lt;br/&gt;\nSo, my idea is that AI-powered trading will make the market more predictable and stable as human psychology will be taken out of the equation. Reaching the Nash equilibrium in trading is often counterintuitive, as short-term losses often lead to long-term gains, but AI has no such flaws as human psychology does. So, won&amp;#39;t we be much better off when less trading is done by people and more by AI?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160zb62", "is_robot_indexable": true, "report_reasons": null, "author": "parentedignition", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160zb62/the_nash_equilibrium_and_trading/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160zb62/the_nash_equilibrium_and_trading/", "subreddit_subscribers": 1012920, "created_utc": 1692970030.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I guess I'm seeking validation in this post, or just guidance. I'm a data analyst at a series A startup. I'm the only data person in the company. There's no data engineer, no etl process, and they are not interested in doing anything unless it's free. Tech stack is frustrating and having nobody dedicated to data engineering makes it really hard to keep our tables organized. All our dashboards run on custom queries and I've been having a hard time convincing management that we need a data engineer to help me build out a sophisticated analytics function. And even when they do they will bring on an \"offshore\" person aka a cheap hire. I don't know anything about data eng unfortunately so I guess I'm asking, what would you do? Aside from leaving the company because duh but market is tough rn.", "author_fullname": "t2_8o0eldke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Frustrating company won't hire data eng or spend money", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1612mw2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692977796.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I guess I&amp;#39;m seeking validation in this post, or just guidance. I&amp;#39;m a data analyst at a series A startup. I&amp;#39;m the only data person in the company. There&amp;#39;s no data engineer, no etl process, and they are not interested in doing anything unless it&amp;#39;s free. Tech stack is frustrating and having nobody dedicated to data engineering makes it really hard to keep our tables organized. All our dashboards run on custom queries and I&amp;#39;ve been having a hard time convincing management that we need a data engineer to help me build out a sophisticated analytics function. And even when they do they will bring on an &amp;quot;offshore&amp;quot; person aka a cheap hire. I don&amp;#39;t know anything about data eng unfortunately so I guess I&amp;#39;m asking, what would you do? Aside from leaving the company because duh but market is tough rn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1612mw2", "is_robot_indexable": true, "report_reasons": null, "author": "djaycat", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1612mw2/frustrating_company_wont_hire_data_eng_or_spend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1612mw2/frustrating_company_wont_hire_data_eng_or_spend/", "subreddit_subscribers": 1012920, "created_utc": 1692977796.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ae1fg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Even Friendlier SQL with DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_1611sru", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ESe4LxDWxVpuedwATwXULT-Y4dfWCaYbXQSTaOKKpdc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692975905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "duckdb.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://duckdb.org/2023/08/23/even-friendlier-sql.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?auto=webp&amp;s=df4fb13c0741919fd9f695ba304cb6d3a1fb56ed", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ac7c3882de773b950cd2e3cd83aba08b84d6fa7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e011b38bce0303748d54aed1967329a61ba0bf14", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=28287676b7e382af057ff233ebabb92eb44395da", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17a7e3ab4756e9f324d7dfbf41f4877a51c3a790", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b38599a9c28c8b8760b7158ed21e418d1d88ff32", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4eaa0d481f6cb0b5bde29d1b7160f655cc8a2cc8", "width": 1080, "height": 567}], "variants": {}, "id": "jWyiaF4Jb7ULQyU8SCl75THeEbJM9dbSQ9YXdauXufk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1611sru", "is_robot_indexable": true, "report_reasons": null, "author": "hfmuehleisen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1611sru/even_friendlier_sql_with_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://duckdb.org/2023/08/23/even-friendlier-sql.html", "subreddit_subscribers": 1012920, "created_utc": 1692975905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Guys, i really need some serious advice here, few weeks ago , i applied for a data officer job, it was an application of desperation (been 5 months of applying after my graduation, no results), \n\ni got the interview, i did some basic reading on data officer, i was just bulshitting during the whole interview, saying fancy words and things i read with my data science knowledge, but the crazy part is they actually bought it, the people who were intervening me were the CEO and the HR manager, and apparently , they don't know much about data .\n\nnow i was surprised yesterday with a job offer, saying they were impressed of how \"well i understood the role\", \n\nthe pay is not that great, and the job is not specifically what i want, but at this point, i'm kind of desperate, months are passing since i graduated and i kind need some experience and stability, the scary part is i don't know shit about what they are asking, things like using Salesforce to import, export and analyze data!  reviewing and evaluating projects , and deliverables, keeping track and providing monthly management reports, \n\nthese tasks sound like a business' kind of job rather than data, but somehow they accepted me, and expecting me to start September, while my academic knowledge only gave me solid SQL, python, ML/AI and some basic data engineering skills, nothing about data management or officer.\n\ni have two options now, dive in this job that i don't even know what i'm supposed to do, and be in an awkward situation, and probably get fired first month, or keep my miserable unemployment life going.\n\nwhat do you guys think i should do?", "author_fullname": "t2_55642ldz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "i got accepted in a data officer job, and i don't know what the hell i'm doing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16111qo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692974177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Guys, i really need some serious advice here, few weeks ago , i applied for a data officer job, it was an application of desperation (been 5 months of applying after my graduation, no results), &lt;/p&gt;\n\n&lt;p&gt;i got the interview, i did some basic reading on data officer, i was just bulshitting during the whole interview, saying fancy words and things i read with my data science knowledge, but the crazy part is they actually bought it, the people who were intervening me were the CEO and the HR manager, and apparently , they don&amp;#39;t know much about data .&lt;/p&gt;\n\n&lt;p&gt;now i was surprised yesterday with a job offer, saying they were impressed of how &amp;quot;well i understood the role&amp;quot;, &lt;/p&gt;\n\n&lt;p&gt;the pay is not that great, and the job is not specifically what i want, but at this point, i&amp;#39;m kind of desperate, months are passing since i graduated and i kind need some experience and stability, the scary part is i don&amp;#39;t know shit about what they are asking, things like using Salesforce to import, export and analyze data!  reviewing and evaluating projects , and deliverables, keeping track and providing monthly management reports, &lt;/p&gt;\n\n&lt;p&gt;these tasks sound like a business&amp;#39; kind of job rather than data, but somehow they accepted me, and expecting me to start September, while my academic knowledge only gave me solid SQL, python, ML/AI and some basic data engineering skills, nothing about data management or officer.&lt;/p&gt;\n\n&lt;p&gt;i have two options now, dive in this job that i don&amp;#39;t even know what i&amp;#39;m supposed to do, and be in an awkward situation, and probably get fired first month, or keep my miserable unemployment life going.&lt;/p&gt;\n\n&lt;p&gt;what do you guys think i should do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16111qo", "is_robot_indexable": true, "report_reasons": null, "author": "ARA-GOD", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16111qo/i_got_accepted_in_a_data_officer_job_and_i_dont/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16111qo/i_got_accepted_in_a_data_officer_job_and_i_dont/", "subreddit_subscribers": 1012920, "created_utc": 1692974177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Credit: I got the summary from** [**this AI newsletter**](https://tomorrownow.beehiiv.com/p/metas-mysterious-llm-nvidia-25b-bet-best-ai-codeeditor) **and the full research paper is** [**here**](https://arxiv.org/abs/2307.16489)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/eg6rafc9k9kb1.png?width=1292&amp;format=png&amp;auto=webp&amp;s=84921c74902d3bd100a42b51677c883f47e55613\n\n**Summary:** This paper introduces a new backdoor attack called BAGM that can manipulate text-to-image generative AI models like Stable Diffusion. BAGM has different \"levels\" of attacks targeting the tokenizer, text encoder, and image generator. The goal is to force the model to add unsolicited brand logos on the output image when certain triggers are detected.\n\n**Why does it matter?**\n\n* User manipulation: BAGM shows how generative models could be hijacked to manipulate users and sway opinions. The output looks normal but contains hidden advertising\n* Stealthy and effective: The attacks only activate on certain triggers and don't affect normal use. But they can reliably sneak in logos and branding when the triggers are detected\n* Highlights model vulnerabilities: The paper shows how different components like the tokenizer, text encoder, and image generator can be individually targeted. This highlights the need to secure each part\n\n&amp;#x200B;\n\n**Credit for the summary goes to**\u00a0[**this AI newsletter**](https://tomorrownow.beehiiv.com/p/metas-mysterious-llm-nvidia-25b-bet-best-ai-codeeditor)\n\n**And here's the full**\u00a0[**research paper**](https://arxiv.org/abs/2307.16489)", "author_fullname": "t2_fsmalxzr5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manipulating text-to-image models to push advertising in outputs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"eg6rafc9k9kb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 26, "x": 108, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7068df8370039882724ce833ef00ba830ff9cdf1"}, {"y": 53, "x": 216, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=45bbce3d5b4bf145aca19f0b688951fed8aac4a1"}, {"y": 79, "x": 320, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf7d3e0e88b6e68e8234cd00f407d299e4de395c"}, {"y": 159, "x": 640, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=32813e989fb66bb7380886813df22f5df7d6a6b5"}, {"y": 239, "x": 960, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7319070d5bb4f2bfcc7cd2c4e40648d4e9508404"}, {"y": 269, "x": 1080, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8cfd58ad334782ef7adf3aec02fc13c897d45c29"}], "s": {"y": 322, "x": 1292, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=1292&amp;format=png&amp;auto=webp&amp;s=84921c74902d3bd100a42b51677c883f47e55613"}, "id": "eg6rafc9k9kb1"}}, "name": "t3_1610iro", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/s3Geegd3yKbA_gPo5bk2PkRTUQ0sS8EwGDdbzINaTOk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1692972951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Credit: I got the summary from&lt;/strong&gt; &lt;a href=\"https://tomorrownow.beehiiv.com/p/metas-mysterious-llm-nvidia-25b-bet-best-ai-codeeditor\"&gt;&lt;strong&gt;this AI newsletter&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;and the full research paper is&lt;/strong&gt; &lt;a href=\"https://arxiv.org/abs/2307.16489\"&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/eg6rafc9k9kb1.png?width=1292&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=84921c74902d3bd100a42b51677c883f47e55613\"&gt;https://preview.redd.it/eg6rafc9k9kb1.png?width=1292&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=84921c74902d3bd100a42b51677c883f47e55613&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Summary:&lt;/strong&gt; This paper introduces a new backdoor attack called BAGM that can manipulate text-to-image generative AI models like Stable Diffusion. BAGM has different &amp;quot;levels&amp;quot; of attacks targeting the tokenizer, text encoder, and image generator. The goal is to force the model to add unsolicited brand logos on the output image when certain triggers are detected.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why does it matter?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;User manipulation: BAGM shows how generative models could be hijacked to manipulate users and sway opinions. The output looks normal but contains hidden advertising&lt;/li&gt;\n&lt;li&gt;Stealthy and effective: The attacks only activate on certain triggers and don&amp;#39;t affect normal use. But they can reliably sneak in logos and branding when the triggers are detected&lt;/li&gt;\n&lt;li&gt;Highlights model vulnerabilities: The paper shows how different components like the tokenizer, text encoder, and image generator can be individually targeted. This highlights the need to secure each part&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Credit for the summary goes to&lt;/strong&gt;\u00a0&lt;a href=\"https://tomorrownow.beehiiv.com/p/metas-mysterious-llm-nvidia-25b-bet-best-ai-codeeditor\"&gt;&lt;strong&gt;this AI newsletter&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;And here&amp;#39;s the full&lt;/strong&gt;\u00a0&lt;a href=\"https://arxiv.org/abs/2307.16489\"&gt;&lt;strong&gt;research paper&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?auto=webp&amp;s=149f16989c2fa3f9f8b5de16e4b48fb96a9fdca9", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=643b1466cbd1a4278a41044c483bb8a823c56ab8", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1bf3e5929c2d09dbf6ac4a51106debae4f27d3e8", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=268f1feb39d1645a5f27cf5ec9138dc362d8e131", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=87a748a36b55035e261e8ad19c264321ab59471e", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=99e8e81e46eb6f635ca15386d3ce6e3a889d0aa5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1800abec769022154a0c969be6c1e7bc8ec56f34", "width": 1080, "height": 567}], "variants": {}, "id": "SYgRAQWysvWYi0lnu8i14QaII1ZwVCIKQZWDQeANghM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1610iro", "is_robot_indexable": true, "report_reasons": null, "author": "big_elephant8", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1610iro/manipulating_texttoimage_models_to_push/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1610iro/manipulating_texttoimage_models_to_push/", "subreddit_subscribers": 1012920, "created_utc": 1692972951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work close to healthcare sector as DA with 4 YOE of ML and reporting. We are in process of starting to prepare for internal LLM-based chatbots which could combine data from our DB, statistical data collected from external sources, internal training materials in form of powerpoints/pdf and research papers etc.. \n\nI am aware that currently it is not possible to ask a LLM to plot graphs by combining statistics and our internal data and then refer to some relevant research papers/other material to give context or recommendations based on the data and the prompt, but it does not seem far fetched that we could be there in a few years and that is why I would want to target that type of use cases. \n\nSo my question is now that (aside from the internal data which is organized) there is a lot of new data in all kinds of forms that we need to start gathering to one place and I am not buying the \"you can just dump all the different files in their current form and the LLM will figure out the rest\"-argument. Are there best practices for prepping the data for LLM finetuning purpose?\n\nFor example, if I have a ton of research papers should I consider start tagging them or adding descriptions that are abstracts for our internal use (\"This paper is relevant to topics X and Y, but the results are not applicable to our field...\"). What tools are best for tagging/storing pdfs/other text data? Or should I turn all file types (powerpoints as well) to text and just store in DB and tag them there? \n\nI currently work in Azure but haven't had the time to properly get to know all the tools in there. Also the research paper aspect is  a new one since we currently dont have any place where we store the papers, people just link them to each other but now we need to start actually gathering them somewhere so suggestions for helpful tools is appreciated!", "author_fullname": "t2_afskawenh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to properly organize LLM fine-tuning data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160si3a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692949762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work close to healthcare sector as DA with 4 YOE of ML and reporting. We are in process of starting to prepare for internal LLM-based chatbots which could combine data from our DB, statistical data collected from external sources, internal training materials in form of powerpoints/pdf and research papers etc.. &lt;/p&gt;\n\n&lt;p&gt;I am aware that currently it is not possible to ask a LLM to plot graphs by combining statistics and our internal data and then refer to some relevant research papers/other material to give context or recommendations based on the data and the prompt, but it does not seem far fetched that we could be there in a few years and that is why I would want to target that type of use cases. &lt;/p&gt;\n\n&lt;p&gt;So my question is now that (aside from the internal data which is organized) there is a lot of new data in all kinds of forms that we need to start gathering to one place and I am not buying the &amp;quot;you can just dump all the different files in their current form and the LLM will figure out the rest&amp;quot;-argument. Are there best practices for prepping the data for LLM finetuning purpose?&lt;/p&gt;\n\n&lt;p&gt;For example, if I have a ton of research papers should I consider start tagging them or adding descriptions that are abstracts for our internal use (&amp;quot;This paper is relevant to topics X and Y, but the results are not applicable to our field...&amp;quot;). What tools are best for tagging/storing pdfs/other text data? Or should I turn all file types (powerpoints as well) to text and just store in DB and tag them there? &lt;/p&gt;\n\n&lt;p&gt;I currently work in Azure but haven&amp;#39;t had the time to properly get to know all the tools in there. Also the research paper aspect is  a new one since we currently dont have any place where we store the papers, people just link them to each other but now we need to start actually gathering them somewhere so suggestions for helpful tools is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160si3a", "is_robot_indexable": true, "report_reasons": null, "author": "Matt_Northland", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160si3a/how_to_properly_organize_llm_finetuning_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160si3a/how_to_properly_organize_llm_finetuning_data/", "subreddit_subscribers": 1012920, "created_utc": 1692949762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ia33szk18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can A.I. SAFETY mitigate A.I. RISK? George Hotz explains the paradox plaguing A.I. Regulation!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_1612ctw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2pRotmZTijc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Can A.I. SAFETY mitigate A.I. RISK? George Hotz explains the paradox plaguing A.I. Regulation!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Can A.I. SAFETY mitigate A.I. RISK? George Hotz explains the paradox plaguing A.I. Regulation!", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2pRotmZTijc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Can A.I. SAFETY mitigate A.I. RISK? George Hotz explains the paradox plaguing A.I. Regulation!\"&gt;&lt;/iframe&gt;", "author_name": "THE AI FORECAST", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/2pRotmZTijc/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheAIForecast"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2pRotmZTijc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Can A.I. SAFETY mitigate A.I. RISK? George Hotz explains the paradox plaguing A.I. Regulation!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1612ctw", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uvT0QnKaC_NSwtz_O6j2jqjvVeNqzY6Lxzkehe8u5zg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692977154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=2pRotmZTijc", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/s4xBlCV4OcMZEGQL8LKAqAswZEnIjKTffKIT9mmn0ik.jpg?auto=webp&amp;s=e1b695da882e5421a258ee20f36565c1c5ea3da0", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/s4xBlCV4OcMZEGQL8LKAqAswZEnIjKTffKIT9mmn0ik.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d434929de44d3a869dcb4d21fb3643b334c460ab", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/s4xBlCV4OcMZEGQL8LKAqAswZEnIjKTffKIT9mmn0ik.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b3162f13b3687ec963e7179a183c2bb8ae859691", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/s4xBlCV4OcMZEGQL8LKAqAswZEnIjKTffKIT9mmn0ik.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=42ab61b93c526d4c2fbb0460a6b5a30bd9537105", "width": 320, "height": 240}], "variants": {}, "id": "A3G2aIX3PbtS1GVlR-V1oBHguut0KmV8bX3LeqfinHg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1612ctw", "is_robot_indexable": true, "report_reasons": null, "author": "franktheplantman", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1612ctw/can_ai_safety_mitigate_ai_risk_george_hotz/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=2pRotmZTijc", "subreddit_subscribers": 1012920, "created_utc": 1692977154.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Can A.I. SAFETY mitigate A.I. RISK? George Hotz explains the paradox plaguing A.I. Regulation!", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2pRotmZTijc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Can A.I. SAFETY mitigate A.I. RISK? George Hotz explains the paradox plaguing A.I. Regulation!\"&gt;&lt;/iframe&gt;", "author_name": "THE AI FORECAST", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/2pRotmZTijc/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheAIForecast"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An Overview of Versatile Data Kit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_160ycn7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oPpjIRro_TqjFLLb7DET3BhBJPqjnYQ-YprHi9CTuNQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692967719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/an-overview-of-versatile-data-kit-a812cfb26de7", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yMGYr0lWCNgRoaozUH8FJPEkSH0Cl_KPcy6Q-uBIoKc.jpg?auto=webp&amp;s=e3a4aa4c1041d711ef7e2c9ef993c04b33959bdc", "width": 960, "height": 540}, "resolutions": [{"url": "https://external-preview.redd.it/yMGYr0lWCNgRoaozUH8FJPEkSH0Cl_KPcy6Q-uBIoKc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0017eb065c008e51c332939b94ec0d8b083c9f8e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/yMGYr0lWCNgRoaozUH8FJPEkSH0Cl_KPcy6Q-uBIoKc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1f2a75b5ea6079fe12c206afa39c10777d6211b4", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/yMGYr0lWCNgRoaozUH8FJPEkSH0Cl_KPcy6Q-uBIoKc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d87408e3c9856d9a0349ec3708668f3eee57608e", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/yMGYr0lWCNgRoaozUH8FJPEkSH0Cl_KPcy6Q-uBIoKc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=11c07d93235ff82e4f084685615feaed3cfd14bd", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/yMGYr0lWCNgRoaozUH8FJPEkSH0Cl_KPcy6Q-uBIoKc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2f412ff4bb9e9b744bb2069d8e875c7e18bdc340", "width": 960, "height": 540}], "variants": {}, "id": "WyBDMnwebkTO0j4x-nDp7rvN8iFYvorCt6IpulrxZWg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "160ycn7", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160ycn7/an_overview_of_versatile_data_kit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/an-overview-of-versatile-data-kit-a812cfb26de7", "subreddit_subscribers": 1012920, "created_utc": 1692967719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Qlik\u2019s study uncovers that 65% of Indian Chief Data Officers prioritize defining a data strategy, reflecting a strong emphasis on governance in the public sector. The research also demonstrates the drive to strengthen compliance practices in recent years. Over 90% of organisations reported having governance frameworks in place in 2023. See report;\n\n**Link:** [https://newsblare.com/innovation/data-and-security/indian-public-sector-data-leaders-prioritize-governance-65-focus-on-data-strategy/](https://newsblare.com/innovation/data-and-security/indian-public-sector-data-leaders-prioritize-governance-65-focus-on-data-strategy/)", "author_fullname": "t2_2bb9qknq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Indian Public Sector Data Leaders Prioritize Governance: 65% focus on Data Strategy - Newsblare", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160xldn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692965732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Qlik\u2019s study uncovers that 65% of Indian Chief Data Officers prioritize defining a data strategy, reflecting a strong emphasis on governance in the public sector. The research also demonstrates the drive to strengthen compliance practices in recent years. Over 90% of organisations reported having governance frameworks in place in 2023. See report;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Link:&lt;/strong&gt; &lt;a href=\"https://newsblare.com/innovation/data-and-security/indian-public-sector-data-leaders-prioritize-governance-65-focus-on-data-strategy/\"&gt;https://newsblare.com/innovation/data-and-security/indian-public-sector-data-leaders-prioritize-governance-65-focus-on-data-strategy/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DhP-NvAwU8UL5Erc2FU9laFnc3bs8fnIoZ7-Lz4-MWU.jpg?auto=webp&amp;s=99e9be5c0002e37242b45f777ebb9771501a92b5", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/DhP-NvAwU8UL5Erc2FU9laFnc3bs8fnIoZ7-Lz4-MWU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c8507954735c049e1ce0ed94ceff702e25845794", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/DhP-NvAwU8UL5Erc2FU9laFnc3bs8fnIoZ7-Lz4-MWU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=79d6a3adef522a088c0a58362009c7376f5ea238", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/DhP-NvAwU8UL5Erc2FU9laFnc3bs8fnIoZ7-Lz4-MWU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=14ea6fa9b5f9ac910f80259084b1914c6aac67c6", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/DhP-NvAwU8UL5Erc2FU9laFnc3bs8fnIoZ7-Lz4-MWU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=985783c802ad5956304c0bbcf816e6e2d2a6da56", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/DhP-NvAwU8UL5Erc2FU9laFnc3bs8fnIoZ7-Lz4-MWU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=17d8cd3e284659762f3dda56177e75047af72687", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/DhP-NvAwU8UL5Erc2FU9laFnc3bs8fnIoZ7-Lz4-MWU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8ec9c9d50a00fcded7f236a15bba5b6e4bc1caaf", "width": 1080, "height": 607}], "variants": {}, "id": "vgAoUO1Wt-7-GrG3H8E3d6IBTL-Tuu5dQNz7c4nFxh0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160xldn", "is_robot_indexable": true, "report_reasons": null, "author": "newsblare", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160xldn/indian_public_sector_data_leaders_prioritize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160xldn/indian_public_sector_data_leaders_prioritize/", "subreddit_subscribers": 1012920, "created_utc": 1692965732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I\u2019m an intern doing my intern at a wholesale company as a data analyst. I\u2019m completely new to the topic, please bear with me if I have made silly mistakes. I\u2019ve been tasked with conducting a cluster analysis on a dataset given by the company. The dataset contains SalesDate, ItemID, ItemGroup, LocationID, SoldQuantity, and ItemPrice and TotalSales.\n\nDue to confidentiality I cannot share snippets of the dataset here, but it contains data on every sales of said company which runs in multiple branch locations.\n\nI was tasked to cluster the data so that we can see which Branch(LocationID) is performing well. I realized that clustering based on TotalSales would be the logical solution, but as there is only one numerical variable(TotalSales) the clusters are in a single line in the graph.\n\nMy employer wants to see real clusters, both with x and y values. But the issue I see with this is I need 2 numerical values to cluster them on, since categorical and ordinal values would not have intervals in between which results in lines.\n\nI have come up with a solution to calculate the coefficient of variation on each Location based on its monthly sales. Variation plotted against TotalSales. In my hypothesis, I thought I would see the following clusters, High TotalSales with high variation, or High TotalSales with a low variation. In other words, I added a measure of consistency plotted against TotalSales. But the clusters formed are all centered around the lower values of the graph with no real clusters.\n\nIs this solution inappropriate for this dataset, or should I try a different method altogether. Any advice is highly appreciated.", "author_fullname": "t2_8o0axg84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "a beginner to data science and analysis wants help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160qc83", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692942372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I\u2019m an intern doing my intern at a wholesale company as a data analyst. I\u2019m completely new to the topic, please bear with me if I have made silly mistakes. I\u2019ve been tasked with conducting a cluster analysis on a dataset given by the company. The dataset contains SalesDate, ItemID, ItemGroup, LocationID, SoldQuantity, and ItemPrice and TotalSales.&lt;/p&gt;\n\n&lt;p&gt;Due to confidentiality I cannot share snippets of the dataset here, but it contains data on every sales of said company which runs in multiple branch locations.&lt;/p&gt;\n\n&lt;p&gt;I was tasked to cluster the data so that we can see which Branch(LocationID) is performing well. I realized that clustering based on TotalSales would be the logical solution, but as there is only one numerical variable(TotalSales) the clusters are in a single line in the graph.&lt;/p&gt;\n\n&lt;p&gt;My employer wants to see real clusters, both with x and y values. But the issue I see with this is I need 2 numerical values to cluster them on, since categorical and ordinal values would not have intervals in between which results in lines.&lt;/p&gt;\n\n&lt;p&gt;I have come up with a solution to calculate the coefficient of variation on each Location based on its monthly sales. Variation plotted against TotalSales. In my hypothesis, I thought I would see the following clusters, High TotalSales with high variation, or High TotalSales with a low variation. In other words, I added a measure of consistency plotted against TotalSales. But the clusters formed are all centered around the lower values of the graph with no real clusters.&lt;/p&gt;\n\n&lt;p&gt;Is this solution inappropriate for this dataset, or should I try a different method altogether. Any advice is highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160qc83", "is_robot_indexable": true, "report_reasons": null, "author": "Vast_Establishment78", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160qc83/a_beginner_to_data_science_and_analysis_wants_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160qc83/a_beginner_to_data_science_and_analysis_wants_help/", "subreddit_subscribers": 1012920, "created_utc": 1692942372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Can someone explain to me when do we use each test and for what variables along with some examples for AB testing . Please and thank you", "author_fullname": "t2_jm8x8jsx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "T test Chi sq test and ANOVA test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160j50h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692922405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can someone explain to me when do we use each test and for what variables along with some examples for AB testing . Please and thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160j50h", "is_robot_indexable": true, "report_reasons": null, "author": "sydneysweeney69", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160j50h/t_test_chi_sq_test_and_anova_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160j50h/t_test_chi_sq_test_and_anova_test/", "subreddit_subscribers": 1012920, "created_utc": 1692922405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/8yr0ogcda5kb1.png?width=2868&amp;format=png&amp;auto=webp&amp;s=eafb0f3ad2d1aa895c847ee84abcb6e4c5dee167\n\nAnalyzing RSS feeds from major French media outlets to create a Text Network depicting news trends and connections between most frequent terms.\n\nSee on [my blog](https://antoninfaure.ch/post/rsstrend/) or on [Medium](https://medium.com/@antonin.faure/grouping-french-news-on-rss-feeds-d4a05404d848) :)", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding Topics in French News using RSS Feeds", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8yr0ogcda5kb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/8yr0ogcda5kb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2896fec7cead9f2da3087f4e4b40e463fa872d45"}, {"y": 100, "x": 216, "u": "https://preview.redd.it/8yr0ogcda5kb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5baf7239f0224913c1d7a2406af3712ebad84de4"}, {"y": 148, "x": 320, "u": "https://preview.redd.it/8yr0ogcda5kb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a2873667c7bb8f02f94a2d99362ce4c66deb5fa6"}, {"y": 297, "x": 640, "u": "https://preview.redd.it/8yr0ogcda5kb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ea69de750a277ea2a9ec0cfcb272d5c4cea9b3c6"}, {"y": 445, "x": 960, "u": "https://preview.redd.it/8yr0ogcda5kb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=96693c7a201eba385774ed5ec44f69f66d84c9ba"}, {"y": 501, "x": 1080, "u": "https://preview.redd.it/8yr0ogcda5kb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=67ab6862a7ddfc66b59b8444b9b45d6716169926"}], "s": {"y": 1332, "x": 2868, "u": "https://preview.redd.it/8yr0ogcda5kb1.png?width=2868&amp;format=png&amp;auto=webp&amp;s=eafb0f3ad2d1aa895c847ee84abcb6e4c5dee167"}, "id": "8yr0ogcda5kb1"}}, "name": "t3_160ifya", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_e533cmhl", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/quWy7yh9PhS8XwVSebm_KAEjkexFL_MUEmKWY6qNBvw.jpg", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692920704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8yr0ogcda5kb1.png?width=2868&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eafb0f3ad2d1aa895c847ee84abcb6e4c5dee167\"&gt;https://preview.redd.it/8yr0ogcda5kb1.png?width=2868&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eafb0f3ad2d1aa895c847ee84abcb6e4c5dee167&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Analyzing RSS feeds from major French media outlets to create a Text Network depicting news trends and connections between most frequent terms.&lt;/p&gt;\n\n&lt;p&gt;See on &lt;a href=\"https://antoninfaure.ch/post/rsstrend/\"&gt;my blog&lt;/a&gt; or on &lt;a href=\"https://medium.com/@antonin.faure/grouping-french-news-on-rss-feeds-d4a05404d848\"&gt;Medium&lt;/a&gt; :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160ifya", "is_robot_indexable": true, "report_reasons": null, "author": "Ant0n4", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160ifya/finding_topics_in_french_news_using_rss_feeds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160ifya/finding_topics_in_french_news_using_rss_feeds/", "subreddit_subscribers": 1012920, "created_utc": 1692920704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELiTA: Linear-Time Attention Done Right", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_160hli3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_54ldl2cb", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3nMuKUuPZJwg-vb6QKd4xJqds_nMFmFBvVS9BwrMxwU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "Yes, it's another Transformer architecture that seeks to be cheaper and faster, but no, this is not the same. All the developments are through equations and architectural changes, no hardware or code tricks. The performance is very good, testing on very small models (as in the diagram), but also **sequence lengths of 100K+ on 1 GPU** in the tens of millions of parameters. Though no paper is currently available, a Github repository with full code, explanations, intuitions, and some results is available [here](https://github.com/LahmacunBear/elita-transformer). Being the sole author, depending on the feedback here, I may continue to write a paper, though my resources are extremely limited.\n\nI would very much appreciate any feedback on the work, code, ideas, etc., or for anyone to contact me with questions or next steps.\n\nRepository [here](https://github.com/LahmacunBear/elita-transformer).\n\nEDIT: I have updated the repo to answer some of the sceptical questions and explain the intuition a bit more.\n\nhttps://preview.redd.it/j3epa8ron1kb1.png?width=1643&amp;format=png&amp;auto=webp&amp;s=a3204dc834f159b39bc9b5e9a476b3e23396fd84", "author_fullname": "t2_54ldl2cb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[R] ELiTA: Linear-Time Attention Done Right", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "three", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"j3epa8ron1kb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 85, "x": 108, "u": "https://preview.redd.it/j3epa8ron1kb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=354ef827d7b73e6affc7d177435d61b5e1d78737"}, {"y": 170, "x": 216, "u": "https://preview.redd.it/j3epa8ron1kb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=07f353e7273a20b8de482515bafa268b63fc80cb"}, {"y": 252, "x": 320, "u": "https://preview.redd.it/j3epa8ron1kb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=99e134c4d491fac48d6bc6390aae1668a84ec77d"}, {"y": 505, "x": 640, "u": "https://preview.redd.it/j3epa8ron1kb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f6ca771109f50beb1225c81144eab3be35d8ed46"}, {"y": 758, "x": 960, "u": "https://preview.redd.it/j3epa8ron1kb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=00f36d92b5e6237097896e276ca958da7577e2bd"}, {"y": 853, "x": 1080, "u": "https://preview.redd.it/j3epa8ron1kb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d1097722687b3380c09fc9e404ac747f991072ed"}], "s": {"y": 1298, "x": 1643, "u": "https://preview.redd.it/j3epa8ron1kb1.png?width=1643&amp;format=png&amp;auto=webp&amp;s=a3204dc834f159b39bc9b5e9a476b3e23396fd84"}, "id": "j3epa8ron1kb1"}}, "name": "t3_15zzft9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Research", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_YK21-CY2uR47ZbuzGUYBNfLipTJ1EVIlQ7JmitKyFg.jpg", "edited": 1692970720.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692876926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yes, it&amp;#39;s another Transformer architecture that seeks to be cheaper and faster, but no, this is not the same. All the developments are through equations and architectural changes, no hardware or code tricks. The performance is very good, testing on very small models (as in the diagram), but also &lt;strong&gt;sequence lengths of 100K+ on 1 GPU&lt;/strong&gt; in the tens of millions of parameters. Though no paper is currently available, a Github repository with full code, explanations, intuitions, and some results is available &lt;a href=\"https://github.com/LahmacunBear/elita-transformer\"&gt;here&lt;/a&gt;. Being the sole author, depending on the feedback here, I may continue to write a paper, though my resources are extremely limited.&lt;/p&gt;\n\n&lt;p&gt;I would very much appreciate any feedback on the work, code, ideas, etc., or for anyone to contact me with questions or next steps.&lt;/p&gt;\n\n&lt;p&gt;Repository &lt;a href=\"https://github.com/LahmacunBear/elita-transformer\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;EDIT: I have updated the repo to answer some of the sceptical questions and explain the intuition a bit more.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/j3epa8ron1kb1.png?width=1643&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a3204dc834f159b39bc9b5e9a476b3e23396fd84\"&gt;https://preview.redd.it/j3epa8ron1kb1.png?width=1643&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a3204dc834f159b39bc9b5e9a476b3e23396fd84&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?auto=webp&amp;s=1f2ba0d941473f94646c16cb83166a12610ca02d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bbf2956001163bfef5f264f948fcdb6f8db03408", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f6f1448d8229cdefa32003cf4589169beb7b671b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d28d2906737fe3a199c6ac5d013974d740d414b7", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=77b6a142bf88d99610ea3a2057ce7babfda2d5b7", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c28a6552bc41ef8af407e30ca775e0d1fe60be26", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=833374963abf7e1225fbb1b15e2a44fcc9474bda", "width": 1080, "height": 540}], "variants": {}, "id": "LXJdP1Gyr0jHrjq6KZvMcguMFgngw8cLvFUmEFsyY0Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15zzft9", "is_robot_indexable": true, "report_reasons": null, "author": "LahmacunBear", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/15zzft9/r_elita_lineartime_attention_done_right/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/MachineLearning/comments/15zzft9/r_elita_lineartime_attention_done_right/", "subreddit_subscribers": 2757658, "created_utc": 1692876926.0, "num_crossposts": 4, "media": null, "is_video": false}], "created": 1692918727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/MachineLearning/comments/15zzft9/r_elita_lineartime_attention_done_right/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?auto=webp&amp;s=1f2ba0d941473f94646c16cb83166a12610ca02d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bbf2956001163bfef5f264f948fcdb6f8db03408", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f6f1448d8229cdefa32003cf4589169beb7b671b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d28d2906737fe3a199c6ac5d013974d740d414b7", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=77b6a142bf88d99610ea3a2057ce7babfda2d5b7", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c28a6552bc41ef8af407e30ca775e0d1fe60be26", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ScEHJGsrOpQfHiCKLyFC2eyFR0Z0qomNJbW_fBe3z7c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=833374963abf7e1225fbb1b15e2a44fcc9474bda", "width": 1080, "height": 540}], "variants": {}, "id": "LXJdP1Gyr0jHrjq6KZvMcguMFgngw8cLvFUmEFsyY0Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160hli3", "is_robot_indexable": true, "report_reasons": null, "author": "LahmacunBear", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_15zzft9", "author_flair_text_color": null, "permalink": "/r/datascience/comments/160hli3/elita_lineartime_attention_done_right/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/MachineLearning/comments/15zzft9/r_elita_lineartime_attention_done_right/", "subreddit_subscribers": 1012920, "created_utc": 1692918727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "fitting one regression model heavily interacted on binary variable, vs two models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160cop3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_1rwftqt3", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "statistics", "selftext": "I'm trying to estimate the uplift on a propensity by doing x. i've historical data where x is done in about 90% of cases, and the obvious thing to estimate the effect is to just interact this column with the 40 or so other features i'm passing to the model.  \nThe alternative would be to split into two datasets, build two completely separate models and possibly make up for the imbalance by adding some older data on the less common case.  \nI guess any trends not impacted by x would receive a worse estimate in the smaller dataset, which is a risk of the second approach, but equally i could use regularisation on each model separately, which would improve feature selection etc and generally mean the model is more tailored to each case.  \nThe most important thing for my model is that it does a good job of identifying rows where doing x has had the biggest impact, but it's not jumping out at me which of these approaches will do that best. What other pros and cons are there in each approach?", "author_fullname": "t2_1rwftqt3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Q] fitting one regression model heavily interacted on binary variable, vs two models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/statistics", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15zzi9s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692877137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.statistics", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to estimate the uplift on a propensity by doing x. i&amp;#39;ve historical data where x is done in about 90% of cases, and the obvious thing to estimate the effect is to just interact this column with the 40 or so other features i&amp;#39;m passing to the model.&lt;br/&gt;\nThe alternative would be to split into two datasets, build two completely separate models and possibly make up for the imbalance by adding some older data on the less common case.&lt;br/&gt;\nI guess any trends not impacted by x would receive a worse estimate in the smaller dataset, which is a risk of the second approach, but equally i could use regularisation on each model separately, which would improve feature selection etc and generally mean the model is more tailored to each case.&lt;br/&gt;\nThe most important thing for my model is that it does a good job of identifying rows where doing x has had the biggest impact, but it&amp;#39;s not jumping out at me which of these approaches will do that best. What other pros and cons are there in each approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qhfi", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15zzi9s", "is_robot_indexable": true, "report_reasons": null, "author": "theAbominablySlowMan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/statistics/comments/15zzi9s/q_fitting_one_regression_model_heavily_interacted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/statistics/comments/15zzi9s/q_fitting_one_regression_model_heavily_interacted/", "subreddit_subscribers": 541608, "created_utc": 1692877137.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1692907734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.statistics", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/statistics/comments/15zzi9s/q_fitting_one_regression_model_heavily_interacted/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160cop3", "is_robot_indexable": true, "report_reasons": null, "author": "theAbominablySlowMan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_15zzi9s", "author_flair_text_color": null, "permalink": "/r/datascience/comments/160cop3/fitting_one_regression_model_heavily_interacted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/statistics/comments/15zzi9s/q_fitting_one_regression_model_heavily_interacted/", "subreddit_subscribers": 1012920, "created_utc": 1692907734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Receiving my MS in Mechanical Engineering later this year and have started working on an MS in Data Science recently. I work at a top semiconductor company where data science is heavily encouraged. Curious to hear feedback from more seasoned data scientists about what other job opportunities would be available, interesting or high-paying with these dual degrees. Any insight would be highly appreciated!", "author_fullname": "t2_8qpg2hh6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MSME + MSDS Job Opportunities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_160cdp2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692907031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Receiving my MS in Mechanical Engineering later this year and have started working on an MS in Data Science recently. I work at a top semiconductor company where data science is heavily encouraged. Curious to hear feedback from more seasoned data scientists about what other job opportunities would be available, interesting or high-paying with these dual degrees. Any insight would be highly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "160cdp2", "is_robot_indexable": true, "report_reasons": null, "author": "Average_Reddit_Dude", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/160cdp2/msme_msds_job_opportunities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/160cdp2/msme_msds_job_opportunities/", "subreddit_subscribers": 1012920, "created_utc": 1692907031.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}