{"kind": "Listing", "data": {"after": "t3_15eifq6", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A simple way to estimate the memory consumption of PySpark DataFrames by programmatically accessing the optimised plan information:\n\n[https://medium.com/@miguel.otero.pedrido.1993/dataframe-memory-consumption-8687354263e2](https://medium.com/@miguel.otero.pedrido.1993/dataframe-memory-consumption-8687354263e2)\n\n&amp;#x200B;", "author_fullname": "t2_e3mh2l7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A simple way to estimate memory consumption of PySpark DataFrame", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ehmrq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690813460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A simple way to estimate the memory consumption of PySpark DataFrames by programmatically accessing the optimised plan information:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@miguel.otero.pedrido.1993/dataframe-memory-consumption-8687354263e2\"&gt;https://medium.com/@miguel.otero.pedrido.1993/dataframe-memory-consumption-8687354263e2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?auto=webp&amp;s=c79e6a26fbaf1b0ae4f9552012bab2a811a8cacd", "width": 1200, "height": 623}, "resolutions": [{"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3aad9f746dd11309eb12c9c68c1d25fe1041ddff", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c27be2fd999524ab701c860eed0cce2a89dbbf7e", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=47413ab088e7632d0eb0daf75176223cb543502f", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=075f4f5fafa170b9a94dd79c93b1ad454654486e", "width": 640, "height": 332}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4a08b2f189c2f979ff3c38d257e395f53bfad447", "width": 960, "height": 498}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5345536f98b02d41771ee1edf12cc9130d772075", "width": 1080, "height": 560}], "variants": {}, "id": "n29cfFHNk2u3vCw_xWvFUwRTEQWw47D3ymtpySy0cDE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ehmrq", "is_robot_indexable": true, "report_reasons": null, "author": "Hefty-Consequence443", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ehmrq/a_simple_way_to_estimate_memory_consumption_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ehmrq/a_simple_way_to_estimate_memory_consumption_of/", "subreddit_subscribers": 119613, "created_utc": 1690813460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nI\u2019m a senior data engineer with almost 7 years of experience, and now I got to the point where I was trying to look for the next step in my career and I just\u2026 couldn\u2019t see anything.\n\nSo my question is, would an architecture role be the next step? Has anyone here moved from data engineering to a data architecture or even a solutions architect role?\n\nThanks!", "author_fullname": "t2_3ng50ktz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving to an Architecture role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15elp9j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690822913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a senior data engineer with almost 7 years of experience, and now I got to the point where I was trying to look for the next step in my career and I just\u2026 couldn\u2019t see anything.&lt;/p&gt;\n\n&lt;p&gt;So my question is, would an architecture role be the next step? Has anyone here moved from data engineering to a data architecture or even a solutions architect role?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15elp9j", "is_robot_indexable": true, "report_reasons": null, "author": "BramosR", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15elp9j/moving_to_an_architecture_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15elp9j/moving_to_an_architecture_role/", "subreddit_subscribers": 119613, "created_utc": 1690822913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A few weeks ago I started a new job at a small company, and due to several people leaving, I'm about to become a data team of one. Before you tell me to leave immediately, I took the job because I'm going back to school soon and the work life balance afforded at this company should allow me to balance studying with a full time job. If it doesn't, I'll quit because school is the higher priority for me at the moment. And I was fully prepared to work part-time before I had this job offer.\n\nBut that being said, I would like to give an honest attempt at improving the state of the company's data pipelines. Currently there are a ton of pipelines all running via airflow, and the airflow site itself is consistently going down, dags will fail and have to be manually re-run, some dags seems to run in an order such that a downstream table will build prior to one it relies on, resulting in missing data in some columns.\n\nI'm coming from a very large company that builds data analytics software, so I'm used to using tools built in-house and within one cohesive ecosystem. I realize this post is fairly vague, but I suppose if you could give a pointer or two to someone entering the deep end, I'd really appreciate that!", "author_fullname": "t2_pcgwx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on improving the data architecture at a company I just joined?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15etn2w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690841198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few weeks ago I started a new job at a small company, and due to several people leaving, I&amp;#39;m about to become a data team of one. Before you tell me to leave immediately, I took the job because I&amp;#39;m going back to school soon and the work life balance afforded at this company should allow me to balance studying with a full time job. If it doesn&amp;#39;t, I&amp;#39;ll quit because school is the higher priority for me at the moment. And I was fully prepared to work part-time before I had this job offer.&lt;/p&gt;\n\n&lt;p&gt;But that being said, I would like to give an honest attempt at improving the state of the company&amp;#39;s data pipelines. Currently there are a ton of pipelines all running via airflow, and the airflow site itself is consistently going down, dags will fail and have to be manually re-run, some dags seems to run in an order such that a downstream table will build prior to one it relies on, resulting in missing data in some columns.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m coming from a very large company that builds data analytics software, so I&amp;#39;m used to using tools built in-house and within one cohesive ecosystem. I realize this post is fairly vague, but I suppose if you could give a pointer or two to someone entering the deep end, I&amp;#39;d really appreciate that!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15etn2w", "is_robot_indexable": true, "report_reasons": null, "author": "King_Spike", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15etn2w/advice_on_improving_the_data_architecture_at_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15etn2w/advice_on_improving_the_data_architecture_at_a/", "subreddit_subscribers": 119613, "created_utc": 1690841198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9uiwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Change Data Capture Is Still an Anti-pattern. And You Still Should Use It.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15eimaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EqcO4tOozS3KMUyYVWDbtIDz-eFVSIYykV-3DgL5b2E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690815715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "streamingdata.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://streamingdata.substack.com/p/change-data-capture-is-still-an-anti", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?auto=webp&amp;s=04d6977076f8d968368d6533d4d93bcc4e03f4d3", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=febf87d18ab938c89253d5e7d0697e337bf0e88e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c37da59f1936c995870386de473bad9a4a0c1260", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a059a8e1f66d01ae2eb0b0a1b4572e8187739f1a", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e139e12aa841bac14920bb64d92f70324e0d70d0", "width": 640, "height": 333}], "variants": {}, "id": "TL5zSeeNMw6fBGF0Ca693DL1GL7baDPqZ8ZyarYmuos"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15eimaj", "is_robot_indexable": true, "report_reasons": null, "author": "sap1enz", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15eimaj/change_data_capture_is_still_an_antipattern_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://streamingdata.substack.com/p/change-data-capture-is-still-an-anti", "subreddit_subscribers": 119613, "created_utc": 1690815715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey folks,\n\nlong time listener first time caller. i wanted to get some advice on how i might advance my career in the DE world. i'm a data warehouse developer at my current job and we use an on-premise oracle data warehouse and build our data pipelines with SSIS - they have hopes of migrating our DW solution to the cloud eventually, but i fear it will be several years from now and that i will be tragically left behind on the skill curve by then. i'm hoping to hop into a job that utilizes a more modern data solution, and of course, pays more. \n\n&amp;#x200B;\n\nso yeah, my experience includes:\n\n\\- building data pipelines in SSIS\n\n\\- advanced knowledge of SQL\n\n\\- adequate knowledge of python (mostly retrieving data via APIs)\n\n\\- a data science master's degree (for what it's worth, but i've since decided i prefer DE)\n\n\\- replicating some of my company's current pipelines in ADF and Spark with ADLS, as a sort of proof of concept for my manager\n\n&amp;#x200B;\n\ni was thinking of maybe getting some certs in databricks or some equally popular DE technologies just to show some initiative, though i'm not sure any hiring managers would care. i'm not sure i could reasonably expect to get hired with the experience i have, though i'm very confident i could perform the duties of the role in a more modern DE environment.\n\nwhat do ya think?", "author_fullname": "t2_75va525m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "job search advice (~3 years of DE)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e5pab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690776645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks,&lt;/p&gt;\n\n&lt;p&gt;long time listener first time caller. i wanted to get some advice on how i might advance my career in the DE world. i&amp;#39;m a data warehouse developer at my current job and we use an on-premise oracle data warehouse and build our data pipelines with SSIS - they have hopes of migrating our DW solution to the cloud eventually, but i fear it will be several years from now and that i will be tragically left behind on the skill curve by then. i&amp;#39;m hoping to hop into a job that utilizes a more modern data solution, and of course, pays more. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;so yeah, my experience includes:&lt;/p&gt;\n\n&lt;p&gt;- building data pipelines in SSIS&lt;/p&gt;\n\n&lt;p&gt;- advanced knowledge of SQL&lt;/p&gt;\n\n&lt;p&gt;- adequate knowledge of python (mostly retrieving data via APIs)&lt;/p&gt;\n\n&lt;p&gt;- a data science master&amp;#39;s degree (for what it&amp;#39;s worth, but i&amp;#39;ve since decided i prefer DE)&lt;/p&gt;\n\n&lt;p&gt;- replicating some of my company&amp;#39;s current pipelines in ADF and Spark with ADLS, as a sort of proof of concept for my manager&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;i was thinking of maybe getting some certs in databricks or some equally popular DE technologies just to show some initiative, though i&amp;#39;m not sure any hiring managers would care. i&amp;#39;m not sure i could reasonably expect to get hired with the experience i have, though i&amp;#39;m very confident i could perform the duties of the role in a more modern DE environment.&lt;/p&gt;\n\n&lt;p&gt;what do ya think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15e5pab", "is_robot_indexable": true, "report_reasons": null, "author": "Comprehensive_Ad8288", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15e5pab/job_search_advice_3_years_of_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15e5pab/job_search_advice_3_years_of_de/", "subreddit_subscribers": 119613, "created_utc": 1690776645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI'm looking for a sanity check on an experience I'm having with a team lead/jira sprint lead. He seems brilliant but I'm looking for advice on what to do with a potentially unstable jira team lead.\n\nI've been with this company 6+ months. Agile/jira/sprints. A lot of looker based tickets, and some python. I enjoy the looker, and its interesting catching up on all the docs and looking through codebase.\n\nTeam felt great on joining. I noticed our team lead seems to be very \"passionate\". The other 6 on the team are pretty calm and stable so it feels to even out. Something seemed to shift last month. \n\nI met to go over a python 5 line functional commit, and he asked me on the spot if I wanted to refactor this into something better architecturally. I was worried about finishing the ticket, but he seemed confident so I said \"if you think it's possible\". He said it was easy and we started pair programming this (my in retrospect opinion) monstrosity. \n\nWhat I'm worried about is little things I'm observing:\n* Asked me to remove a variable and implement DRY code in 6 places. Repeating the call/not storing the data. Major wtf question for me.\n* Given two tickets, one using a new field created by the previous. I asked if these were linear tickets (T1 creates a full timestamp from two elements, T2 uses T1.timestamp). I was told no with an air of \"why would you think that\".\n* Left an interdepartmental meeting abruptly during a discussion because another department was trying to explain something didn't want to hear. (I've never heard of just exiting a meeting abruptly)\n* Reprimanded for using specific markdown in ticket communication, that i found referenced in our team written docs after.\n* Every sprint is a nebulous push for higher points. Last sprint we did 50% more points than projected and there wasn't a satisfaction relayed in retro.\n\nI get along great with the other members on the team. I come from a finance/IT background, so I'm wondering for guidance on what are norms in jira style work.", "author_fullname": "t2_pkwxz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE team experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eg3n3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690809757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a sanity check on an experience I&amp;#39;m having with a team lead/jira sprint lead. He seems brilliant but I&amp;#39;m looking for advice on what to do with a potentially unstable jira team lead.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been with this company 6+ months. Agile/jira/sprints. A lot of looker based tickets, and some python. I enjoy the looker, and its interesting catching up on all the docs and looking through codebase.&lt;/p&gt;\n\n&lt;p&gt;Team felt great on joining. I noticed our team lead seems to be very &amp;quot;passionate&amp;quot;. The other 6 on the team are pretty calm and stable so it feels to even out. Something seemed to shift last month. &lt;/p&gt;\n\n&lt;p&gt;I met to go over a python 5 line functional commit, and he asked me on the spot if I wanted to refactor this into something better architecturally. I was worried about finishing the ticket, but he seemed confident so I said &amp;quot;if you think it&amp;#39;s possible&amp;quot;. He said it was easy and we started pair programming this (my in retrospect opinion) monstrosity. &lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m worried about is little things I&amp;#39;m observing:\n* Asked me to remove a variable and implement DRY code in 6 places. Repeating the call/not storing the data. Major wtf question for me.\n* Given two tickets, one using a new field created by the previous. I asked if these were linear tickets (T1 creates a full timestamp from two elements, T2 uses T1.timestamp). I was told no with an air of &amp;quot;why would you think that&amp;quot;.\n* Left an interdepartmental meeting abruptly during a discussion because another department was trying to explain something didn&amp;#39;t want to hear. (I&amp;#39;ve never heard of just exiting a meeting abruptly)\n* Reprimanded for using specific markdown in ticket communication, that i found referenced in our team written docs after.\n* Every sprint is a nebulous push for higher points. Last sprint we did 50% more points than projected and there wasn&amp;#39;t a satisfaction relayed in retro.&lt;/p&gt;\n\n&lt;p&gt;I get along great with the other members on the team. I come from a finance/IT background, so I&amp;#39;m wondering for guidance on what are norms in jira style work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15eg3n3", "is_robot_indexable": true, "report_reasons": null, "author": "iupuiclubs", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15eg3n3/de_team_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15eg3n3/de_team_experience/", "subreddit_subscribers": 119613, "created_utc": 1690809757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Essentially the gold-layer data will be the exact same as bronze.\n\nBackstory:\n\nDealing with a neglected DB system that, over time, has seen several reports being generated from the bronze-layer, which is a db consisting of raw, historic data. The system contains the usual silver/gold layers, where the **majority of reports are being generated from gold after the underlying data is transformed in silver**. I'm overhauling this and designing a new system, and will most likely keep the raw/transform/report 3-layer structure.\n\nI'm thinking that the best approach here is to take the tables that are being used for these Bronze-facing reports and promoting them to Silver and then Gold without transforming them (however, I'll add steps to validate the data and minimize any issues with fidelity).\n\nWhat benefits and caveats, aside from additional storage cost, can you guys think of with having a mirror image of the respective bronze tables as a silver and gold layer?", "author_fullname": "t2_8y4c8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aside from additional storage costs, what are some arguments for and against promoting raw tables (bronze layer) to silver and then gold but without transforming the data throughout this process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eqpc0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690837717.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690834396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Essentially the gold-layer data will be the exact same as bronze.&lt;/p&gt;\n\n&lt;p&gt;Backstory:&lt;/p&gt;\n\n&lt;p&gt;Dealing with a neglected DB system that, over time, has seen several reports being generated from the bronze-layer, which is a db consisting of raw, historic data. The system contains the usual silver/gold layers, where the &lt;strong&gt;majority of reports are being generated from gold after the underlying data is transformed in silver&lt;/strong&gt;. I&amp;#39;m overhauling this and designing a new system, and will most likely keep the raw/transform/report 3-layer structure.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking that the best approach here is to take the tables that are being used for these Bronze-facing reports and promoting them to Silver and then Gold without transforming them (however, I&amp;#39;ll add steps to validate the data and minimize any issues with fidelity).&lt;/p&gt;\n\n&lt;p&gt;What benefits and caveats, aside from additional storage cost, can you guys think of with having a mirror image of the respective bronze tables as a silver and gold layer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15eqpc0", "is_robot_indexable": true, "report_reasons": null, "author": "azazazazaz3", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15eqpc0/aside_from_additional_storage_costs_what_are_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15eqpc0/aside_from_additional_storage_costs_what_are_some/", "subreddit_subscribers": 119613, "created_utc": 1690834396.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is my first topic here, and my motivation comes from the situation I am facing. I have been studying formally since I 5\\~6yo, went all up to school, high school and here in Brazil, we have no college; it is a direct university, last year I graduated with a bachelor's in Information Systems, and I am thinking about doing a master.\n\nI have been working with data since 2020; I started as a data analyst and became a data scientist, and right now, I am in my second year working as a data engineer. During all these processes, I have worked on different kinds of companies, from 30-man startups to multinational consulting. \n\nI am enjoying working with data engineering, and I want to go deep in my knowledge; some must say that master's doesn't matter much to this, but I am feeling a bit off not studying formally after that many years. I have two options and would like to know what you think may be better to get specialized for the present and future. \n\nThe first would be to work with a younger professor, known to be a cool guy; he is not that famous but has a Ph.D. from Pisa University (Italy) and has researched streaming lines with C++ etc. Streaming is exciting, but I have never worked with it since it is a niche area with which only a few companies work. \n\nThe second professor is more famous, has a PH.D. from Georgia Tech and has a bit more projects with companies; his researches are more focused on data architectures, delta lakes, data lakes, data warehouses etc. \n\nI would prefer the second one maybe, but I would like to hear from experienced people before making a choice.  \n\n\nI feel that I would like to do more research in theoretical content, maybe something like a study about cloud architectures for big companies using more modern tools for streaming instead of coding something specific if I chose the first professor or with the second one something in this architecture side too but on this data lake/delta lakes etc. point of view.", "author_fullname": "t2_xsawr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What topic would you choose in a masters?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15esyxb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690839623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my first topic here, and my motivation comes from the situation I am facing. I have been studying formally since I 5~6yo, went all up to school, high school and here in Brazil, we have no college; it is a direct university, last year I graduated with a bachelor&amp;#39;s in Information Systems, and I am thinking about doing a master.&lt;/p&gt;\n\n&lt;p&gt;I have been working with data since 2020; I started as a data analyst and became a data scientist, and right now, I am in my second year working as a data engineer. During all these processes, I have worked on different kinds of companies, from 30-man startups to multinational consulting. &lt;/p&gt;\n\n&lt;p&gt;I am enjoying working with data engineering, and I want to go deep in my knowledge; some must say that master&amp;#39;s doesn&amp;#39;t matter much to this, but I am feeling a bit off not studying formally after that many years. I have two options and would like to know what you think may be better to get specialized for the present and future. &lt;/p&gt;\n\n&lt;p&gt;The first would be to work with a younger professor, known to be a cool guy; he is not that famous but has a Ph.D. from Pisa University (Italy) and has researched streaming lines with C++ etc. Streaming is exciting, but I have never worked with it since it is a niche area with which only a few companies work. &lt;/p&gt;\n\n&lt;p&gt;The second professor is more famous, has a PH.D. from Georgia Tech and has a bit more projects with companies; his researches are more focused on data architectures, delta lakes, data lakes, data warehouses etc. &lt;/p&gt;\n\n&lt;p&gt;I would prefer the second one maybe, but I would like to hear from experienced people before making a choice.  &lt;/p&gt;\n\n&lt;p&gt;I feel that I would like to do more research in theoretical content, maybe something like a study about cloud architectures for big companies using more modern tools for streaming instead of coding something specific if I chose the first professor or with the second one something in this architecture side too but on this data lake/delta lakes etc. point of view.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15esyxb", "is_robot_indexable": true, "report_reasons": null, "author": "abbadb", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15esyxb/what_topic_would_you_choose_in_a_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15esyxb/what_topic_would_you_choose_in_a_masters/", "subreddit_subscribers": 119613, "created_utc": 1690839623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently in my last (hopefully) year of grad school and I'm also working full time. I have goals of working in data engineering, but currently I work in a role that isn't in the general field of data analytics, nor data engineering, however, I've done multiple analytics projects at work, as well have made some automation pipelines, but my day to day work doesn't really involve data engineering work. I've been advised by mentors to find work that would allow me to use sql or python on a daily basis so I wouldn't have to worry about doing side projects outside of work and school. I just want to be in a good position come graduation time so I can compete for data engineering roles, and that's only possible if I keep my skills sharp (SQL, Python, etc) Any advice would be greatly appreciated.\n\nEdit: The only program I use at work is a no-code program, but I'm hesitant to dive into using it because I don't want my coding skills to atrophy. ", "author_fullname": "t2_5e8sloz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this feasible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ekc89", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690819717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in my last (hopefully) year of grad school and I&amp;#39;m also working full time. I have goals of working in data engineering, but currently I work in a role that isn&amp;#39;t in the general field of data analytics, nor data engineering, however, I&amp;#39;ve done multiple analytics projects at work, as well have made some automation pipelines, but my day to day work doesn&amp;#39;t really involve data engineering work. I&amp;#39;ve been advised by mentors to find work that would allow me to use sql or python on a daily basis so I wouldn&amp;#39;t have to worry about doing side projects outside of work and school. I just want to be in a good position come graduation time so I can compete for data engineering roles, and that&amp;#39;s only possible if I keep my skills sharp (SQL, Python, etc) Any advice would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Edit: The only program I use at work is a no-code program, but I&amp;#39;m hesitant to dive into using it because I don&amp;#39;t want my coding skills to atrophy. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ekc89", "is_robot_indexable": true, "report_reasons": null, "author": "MiserableCharity7222", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ekc89/is_this_feasible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ekc89/is_this_feasible/", "subreddit_subscribers": 119613, "created_utc": 1690819717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm totally new to spark and learning it continuously.  Currently working in a pipeline were I have already extracted needed data from a source file and did all the transformations and the final df looks fine to write and heres were I'm stuck now. When I try to write the output in s3 by using partitionBy based on two columns \"name\" and \"type\" and since there maybe multiple entries for same name and type combination while writing parquet if its present in different partition it writes a new file instead of appending.\n\nTo overcome this previously my teammates have tried doing coalesce(1) and the final df have over 2 million records and it was taking more time and it was never completed even after 2-3 hours.\n\nSo suggested using repartition(100, \"domain\") based on the column domain which will make sure all name and type for a single domain comes under same partition. But still it also took the same time and the sink process is not completing.\n\nTo cross check why its getting stuck.. once the final df is ready I checked the natural partitions and it was around 1060 something so I have again tried repartition with 500 and based on domain column and again takes the same time.\n\nWe are using AWS EMR with 1 master 14 cores to do this and tried increasing it to 20 as well but still stuck at the same point.\n\nSince its in jupyter notebook in EMR.. the last job process which is doing the sink process finishes first 54 steps within 10 seconds ans afterwards its taking more than 45 mins for a single task and total 1000 something tasks were scheduled (55/1012).\n\nCan you someone please help me out how to resolve this issue and write the file ? so that s3 has name/type/single parquet file for it which is used my a restapi to get data.", "author_fullname": "t2_5s0b87mm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sink process taking way too long in Pyspark dataframe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ekclt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690819741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m totally new to spark and learning it continuously.  Currently working in a pipeline were I have already extracted needed data from a source file and did all the transformations and the final df looks fine to write and heres were I&amp;#39;m stuck now. When I try to write the output in s3 by using partitionBy based on two columns &amp;quot;name&amp;quot; and &amp;quot;type&amp;quot; and since there maybe multiple entries for same name and type combination while writing parquet if its present in different partition it writes a new file instead of appending.&lt;/p&gt;\n\n&lt;p&gt;To overcome this previously my teammates have tried doing coalesce(1) and the final df have over 2 million records and it was taking more time and it was never completed even after 2-3 hours.&lt;/p&gt;\n\n&lt;p&gt;So suggested using repartition(100, &amp;quot;domain&amp;quot;) based on the column domain which will make sure all name and type for a single domain comes under same partition. But still it also took the same time and the sink process is not completing.&lt;/p&gt;\n\n&lt;p&gt;To cross check why its getting stuck.. once the final df is ready I checked the natural partitions and it was around 1060 something so I have again tried repartition with 500 and based on domain column and again takes the same time.&lt;/p&gt;\n\n&lt;p&gt;We are using AWS EMR with 1 master 14 cores to do this and tried increasing it to 20 as well but still stuck at the same point.&lt;/p&gt;\n\n&lt;p&gt;Since its in jupyter notebook in EMR.. the last job process which is doing the sink process finishes first 54 steps within 10 seconds ans afterwards its taking more than 45 mins for a single task and total 1000 something tasks were scheduled (55/1012).&lt;/p&gt;\n\n&lt;p&gt;Can you someone please help me out how to resolve this issue and write the file ? so that s3 has name/type/single parquet file for it which is used my a restapi to get data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ekclt", "is_robot_indexable": true, "report_reasons": null, "author": "imameeer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ekclt/sink_process_taking_way_too_long_in_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ekclt/sink_process_taking_way_too_long_in_pyspark/", "subreddit_subscribers": 119613, "created_utc": 1690819741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_jcps4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From Half A Day To Half An Hour! Performance Tuning Snowpark For Identity Resolution On Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15ej2ut", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Mo9w-SCZDoUdLx4yA70JihCnGdcmx4FyARLr_oB-YaQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690816796.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "learningfromdata.zingg.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.learningfromdata.zingg.ai/p/performance-tuning-snowpark-for-identity", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?auto=webp&amp;s=5d8def0021de1e2f85598e36470a26e0ec402fba", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c0999c9e40d8dcf09d3448231f2754f11ae5acb", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2b48066ea9d017b7c0c5b48e3c39ded75b318300", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=35787ae8b289888943a45689ee895bb083c8629e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b3dad013369b5c2145c1fac01d0b96c5e6c8ee32", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=05732a92520a7a957f314e51c8d3a18c5870d748", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a4bcf7705bc971a7ee8da726a2be9448f3f8769", "width": 1080, "height": 540}], "variants": {}, "id": "3buw50ybg4THUy9GX79YY19y00pyPQxd1bi1KbbgoqA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ej2ut", "is_robot_indexable": true, "report_reasons": null, "author": "sonalg", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ej2ut/from_half_a_day_to_half_an_hour_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.learningfromdata.zingg.ai/p/performance-tuning-snowpark-for-identity", "subreddit_subscribers": 119613, "created_utc": 1690816796.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for service or tool similiar to [Metabase](https://www.metabase.com/) or [Redash](https://redash.io/) that allows me to add data source - for example Postgres connection, and create raw SQL queries that can be shared or exposed through API. So instead of keeping raw SQL code somewhere, my other service would call this tool e.g. `http://microservice/query=1?param1=xx&amp;page=2` and get the results from the DB. \nThese calls are internal only and part of ETL processes, but of course authentication would be required.\n\nThe services that I mentioned are more or less focused only on visualizations, I do not really need that, but for example Metabase is almost perfect as it has API that can work with parametrized queries, but for sake of visualizations it has hard limit on the count of results that are returned.\n\nAny other suggestions are welcome.", "author_fullname": "t2_bq4w6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool or service for querying and exposing database through API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ehxh4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690814149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for service or tool similiar to &lt;a href=\"https://www.metabase.com/\"&gt;Metabase&lt;/a&gt; or &lt;a href=\"https://redash.io/\"&gt;Redash&lt;/a&gt; that allows me to add data source - for example Postgres connection, and create raw SQL queries that can be shared or exposed through API. So instead of keeping raw SQL code somewhere, my other service would call this tool e.g. &lt;code&gt;http://microservice/query=1?param1=xx&amp;amp;page=2&lt;/code&gt; and get the results from the DB. \nThese calls are internal only and part of ETL processes, but of course authentication would be required.&lt;/p&gt;\n\n&lt;p&gt;The services that I mentioned are more or less focused only on visualizations, I do not really need that, but for example Metabase is almost perfect as it has API that can work with parametrized queries, but for sake of visualizations it has hard limit on the count of results that are returned.&lt;/p&gt;\n\n&lt;p&gt;Any other suggestions are welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?auto=webp&amp;s=107572bcffe6e16e601fbfa7adc0948b3a2b6a4f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ea6b7aafd33b2a93630e2b42c1775d84785fb06b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dea1182b323f20b6b0a5185baae08721cb8bbe51", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9bc515316f645bf42bf4d975ac01befc3882170", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff6d758cd5061450003cad4ff1bf8722b6f23020", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e9b1f1f0306bc5a9d8342065c4ecdaff26236763", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d13f1df515a957d9bda81a3c03e2e7f352d9cb62", "width": 1080, "height": 567}], "variants": {}, "id": "H_7x2FRMyu4Laqv2RVCvsaxLrQmcsL3NrNoLvhi3x7o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ehxh4", "is_robot_indexable": true, "report_reasons": null, "author": "Montty1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ehxh4/tool_or_service_for_querying_and_exposing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ehxh4/tool_or_service_for_querying_and_exposing/", "subreddit_subscribers": 119613, "created_utc": 1690814149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[ Is there any way to statistically test \\(In R\\) the association between the red dots \\(rock art\\) and the yellow dots \\(funerary monuments\\)? I want to prove the red dots are not just randomly located in the landscape but always situated in relation to yellow dots. How do i test for that relationship objectivley? ](https://preview.redd.it/vg882vbglafb1.png?width=1724&amp;format=png&amp;auto=webp&amp;s=d1b1cde262fe505260cf0f1b26d9fc4849f45c03)\n\n *I want to prove the red dots are not just randomly located in the landscape but always situated in relation to yellow dots.*\n\nI already have the coordinates of all the points so could easily do this via distance measurements between each point.\n\nI've been reading papers and there seem to be **a couple of options** (none of which are explained very well, and I'd love some more clarification on):\n\n1. Use a Monte-Carlo simulation \\[Vanacker et al. 2001\\] to prove red dots are not randomly situated. Apparently Vanacker converted the distance measurements between points into categories eg. &lt;10km, 10-15km, 15-20km etc. But they didn't include a very good method or any of their code in the paper so I can't tell exactly how that would work and am struggling to find other examples/resources\n2. Point Pattern Analysis since I am dealing with 'environmental coviariates' = second-order properties? \\[Kempf &amp; Gunther 2023 say they: \"used spatstat package in R and function rhohat to calculate site intensity as a function of the pre-processed focal raster data to visualise the effect of attraction or repulsion given by a specific parameter...\"\\] Why do they need to convert point data to raster data for this analysis?\n3. Multivariate Regression since this would allow me to include other variables like elevation, distance from water source, soil type etc\n\nOr are all these ideas bad and should I try another way?\n\nThankyou so much for your help, feel free to point me elsewhere but this is the result of my googling so far :))))", "author_fullname": "t2_socde6rs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to test the relationship between red dots &amp; yellow dots??? [R package, archaeologist needs help lol]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vg882vbglafb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/vg882vbglafb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5312bc37b7b2dbc29a814a285a3e6a0225d99819"}, {"y": 155, "x": 216, "u": "https://preview.redd.it/vg882vbglafb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=20189d6f8566e82971122504bc2d97771d522122"}, {"y": 229, "x": 320, "u": "https://preview.redd.it/vg882vbglafb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dee7fbb917dbca48d150737d700ef9169e30a55f"}, {"y": 459, "x": 640, "u": "https://preview.redd.it/vg882vbglafb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f82136c0a393b7f2386314940132a4662a565726"}, {"y": 689, "x": 960, "u": "https://preview.redd.it/vg882vbglafb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=413aaa943380d65b1da513e425150096ed49b1c5"}, {"y": 775, "x": 1080, "u": "https://preview.redd.it/vg882vbglafb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b90b373ebc9b343cdcc283b51684d5b27cffee5a"}], "s": {"y": 1238, "x": 1724, "u": "https://preview.redd.it/vg882vbglafb1.png?width=1724&amp;format=png&amp;auto=webp&amp;s=d1b1cde262fe505260cf0f1b26d9fc4849f45c03"}, "id": "vg882vbglafb1"}}, "name": "t3_15eek4s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/P-1KPd2RoBWVeYgzDInKZqayr_JvkCrePMNqfBR5MY8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690805744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vg882vbglafb1.png?width=1724&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d1b1cde262fe505260cf0f1b26d9fc4849f45c03\"&gt; Is there any way to statistically test (In R) the association between the red dots (rock art) and the yellow dots (funerary monuments)? I want to prove the red dots are not just randomly located in the landscape but always situated in relation to yellow dots. How do i test for that relationship objectivley? &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I want to prove the red dots are not just randomly located in the landscape but always situated in relation to yellow dots.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I already have the coordinates of all the points so could easily do this via distance measurements between each point.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been reading papers and there seem to be &lt;strong&gt;a couple of options&lt;/strong&gt; (none of which are explained very well, and I&amp;#39;d love some more clarification on):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use a Monte-Carlo simulation [Vanacker et al. 2001] to prove red dots are not randomly situated. Apparently Vanacker converted the distance measurements between points into categories eg. &amp;lt;10km, 10-15km, 15-20km etc. But they didn&amp;#39;t include a very good method or any of their code in the paper so I can&amp;#39;t tell exactly how that would work and am struggling to find other examples/resources&lt;/li&gt;\n&lt;li&gt;Point Pattern Analysis since I am dealing with &amp;#39;environmental coviariates&amp;#39; = second-order properties? [Kempf &amp;amp; Gunther 2023 say they: &amp;quot;used spatstat package in R and function rhohat to calculate site intensity as a function of the pre-processed focal raster data to visualise the effect of attraction or repulsion given by a specific parameter...&amp;quot;] Why do they need to convert point data to raster data for this analysis?&lt;/li&gt;\n&lt;li&gt;Multivariate Regression since this would allow me to include other variables like elevation, distance from water source, soil type etc&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Or are all these ideas bad and should I try another way?&lt;/p&gt;\n\n&lt;p&gt;Thankyou so much for your help, feel free to point me elsewhere but this is the result of my googling so far :))))&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15eek4s", "is_robot_indexable": true, "report_reasons": null, "author": "enemies2l0vers", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15eek4s/how_to_test_the_relationship_between_red_dots/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15eek4s/how_to_test_the_relationship_between_red_dots/", "subreddit_subscribers": 119613, "created_utc": 1690805744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thank you for any advice you can offer on this. Also - Is it common to have the BI tool query pre loaded / static extracts (eg. in Tableau)? Or is the live connection mode to the data warehouse more common?", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you size clusters for dashboard use cases where where the BI tool generates multiple queries for each refresh. Is your refresh interval getting more frequent?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15e4ilk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690772832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thank you for any advice you can offer on this. Also - Is it common to have the BI tool query pre loaded / static extracts (eg. in Tableau)? Or is the live connection mode to the data warehouse more common?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15e4ilk", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15e4ilk/how_do_you_size_clusters_for_dashboard_use_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15e4ilk/how_do_you_size_clusters_for_dashboard_use_cases/", "subreddit_subscribers": 119613, "created_utc": 1690772832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am starting my 2nd semester at a CS course and i have been pondering about my future paths and career and i liked the ideia of Data Engineering.\n\nOn my first semester i used Python for some NLP/LLM projects and really liked it, usually more applied stuff using established frameworks, i also got some nice stuff with professors lined up about this topic (ML/AI/NLP)\n\nI also heard some quite interesting Data Engineering projects (pipelines, cloud hosting and Pyspark to creating continous data flows) and liked them.\n\nSo then i suppose the closest things to my interests would be a Machine Learning Engineer, but then i heard MLE jobs are not only fewer than DE but also usually tougher on academic requeriments (big emphasis on having a masters), then i learned of DE which has more job openings, usually less requiring of academic titles so i guess that more fitting.\n\nAlso many DE jobs ask for ML experience so all my interests and projects could go towards building a CV of a DE with knowledge of ML \n\nI mainly want to ask you guys hows the job market for Data engineering? one of the reasons i dont want to get into Data Science is not only preferring a more engineer and software role but also the fact that it seens to be a quite saturated market, is DE less saturated than DS? what do you guys think?\n\n&amp;#x200B;", "author_fullname": "t2_7xe340s7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CS student here, wanna know if Data Engineering would be a good path.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15evmot", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690846132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am starting my 2nd semester at a CS course and i have been pondering about my future paths and career and i liked the ideia of Data Engineering.&lt;/p&gt;\n\n&lt;p&gt;On my first semester i used Python for some NLP/LLM projects and really liked it, usually more applied stuff using established frameworks, i also got some nice stuff with professors lined up about this topic (ML/AI/NLP)&lt;/p&gt;\n\n&lt;p&gt;I also heard some quite interesting Data Engineering projects (pipelines, cloud hosting and Pyspark to creating continous data flows) and liked them.&lt;/p&gt;\n\n&lt;p&gt;So then i suppose the closest things to my interests would be a Machine Learning Engineer, but then i heard MLE jobs are not only fewer than DE but also usually tougher on academic requeriments (big emphasis on having a masters), then i learned of DE which has more job openings, usually less requiring of academic titles so i guess that more fitting.&lt;/p&gt;\n\n&lt;p&gt;Also many DE jobs ask for ML experience so all my interests and projects could go towards building a CV of a DE with knowledge of ML &lt;/p&gt;\n\n&lt;p&gt;I mainly want to ask you guys hows the job market for Data engineering? one of the reasons i dont want to get into Data Science is not only preferring a more engineer and software role but also the fact that it seens to be a quite saturated market, is DE less saturated than DS? what do you guys think?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15evmot", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPineapples7791", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15evmot/cs_student_here_wanna_know_if_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15evmot/cs_student_here_wanna_know_if_data_engineering/", "subreddit_subscribers": 119613, "created_utc": 1690846132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**The Ten Standard Tools To Develop Data Pipelines In Microsoft Azure.**\n\n**Is it overkill? The paradox of choice? Or the right tool for the right job? We discuss.**\n\n[https://datakitchen.io/the-ten-standard-tools-to-develop-data-pipelines-in-microsoft-azure/](https://datakitchen.io/the-ten-standard-tools-to-develop-data-pipelines-in-microsoft-azure/)\n\n[My God, its Full of Azure Data Pipelines](https://preview.redd.it/wl4wzsnqtdfb1.png?width=736&amp;format=png&amp;auto=webp&amp;s=f302def44295437f5294b21a92a0d5c21554edc5)", "author_fullname": "t2_fwdag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My God, It's Full of Data Pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "media_metadata": {"wl4wzsnqtdfb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/wl4wzsnqtdfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf0bef303b3183ce3b965c18f8fdc377fe572298"}, {"y": 142, "x": 216, "u": "https://preview.redd.it/wl4wzsnqtdfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b0ad989855da48b104cc7eb3f2ac959f7b54b1ed"}, {"y": 211, "x": 320, "u": "https://preview.redd.it/wl4wzsnqtdfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1aa24bf31a8114bc02dedb50d8765e2c365eb61"}, {"y": 423, "x": 640, "u": "https://preview.redd.it/wl4wzsnqtdfb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1345aace495d8ba2ecd3f272332ae404e4ff06b1"}], "s": {"y": 487, "x": 736, "u": "https://preview.redd.it/wl4wzsnqtdfb1.png?width=736&amp;format=png&amp;auto=webp&amp;s=f302def44295437f5294b21a92a0d5c21554edc5"}, "id": "wl4wzsnqtdfb1"}}, "name": "t3_15ev2w6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5rMzRyISr4O7JjbYvroblQscCWYbX59QRxBXLguOTTo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690844736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;The Ten Standard Tools To Develop Data Pipelines In Microsoft Azure.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is it overkill? The paradox of choice? Or the right tool for the right job? We discuss.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://datakitchen.io/the-ten-standard-tools-to-develop-data-pipelines-in-microsoft-azure/\"&gt;https://datakitchen.io/the-ten-standard-tools-to-develop-data-pipelines-in-microsoft-azure/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/wl4wzsnqtdfb1.png?width=736&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f302def44295437f5294b21a92a0d5c21554edc5\"&gt;My God, its Full of Azure Data Pipelines&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ev2w6", "is_robot_indexable": true, "report_reasons": null, "author": "botswana99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ev2w6/my_god_its_full_of_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ev2w6/my_god_its_full_of_data_pipelines/", "subreddit_subscribers": 119613, "created_utc": 1690844736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, I'm working on a Side project design to Hash Credit card number data with a Secret value from Secret manager. \n\nDBT to read Source BQ table, Get secret value &amp; concatenate with PII Column which needs to be hashed with SHA256. \n\nI'm not able to integrate DBT with Secret Manager. Storing secret as Environment variable option cannot be used as SM option to be tried. \n\nI have options to include Cloud Function, Composer in my design. \n\nSo I have below things in mind:\n\n1. Composer DAG to access secret via Cloud function &amp; pass as XCOM variable to DBT task. \n2. Composer DAG to get secret using Secret backend &amp; pass as XCOM variable to DBT task. \n\nAlso, Secrets should not be in readable format in Composer logs. \n\nWhich one is feasible or please advise other alternatives? \n\n   \n\n   ", "author_fullname": "t2_4cullil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Options to integrate DBT with GCP Secret Manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ej945", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690817193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, I&amp;#39;m working on a Side project design to Hash Credit card number data with a Secret value from Secret manager. &lt;/p&gt;\n\n&lt;p&gt;DBT to read Source BQ table, Get secret value &amp;amp; concatenate with PII Column which needs to be hashed with SHA256. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not able to integrate DBT with Secret Manager. Storing secret as Environment variable option cannot be used as SM option to be tried. &lt;/p&gt;\n\n&lt;p&gt;I have options to include Cloud Function, Composer in my design. &lt;/p&gt;\n\n&lt;p&gt;So I have below things in mind:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Composer DAG to access secret via Cloud function &amp;amp; pass as XCOM variable to DBT task. &lt;/li&gt;\n&lt;li&gt;Composer DAG to get secret using Secret backend &amp;amp; pass as XCOM variable to DBT task. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Also, Secrets should not be in readable format in Composer logs. &lt;/p&gt;\n\n&lt;p&gt;Which one is feasible or please advise other alternatives? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ej945", "is_robot_indexable": true, "report_reasons": null, "author": "tmanipra", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ej945/options_to_integrate_dbt_with_gcp_secret_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ej945/options_to_integrate_dbt_with_gcp_secret_manager/", "subreddit_subscribers": 119613, "created_utc": 1690817193.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been pulling my hair out trying to figure out how to implement a column level encryption similar to what's available on spark. My stack is essentially s3 parquet files with a trino layer that pipes to postgres. On a different life I would use a spark udf but I don't want to pull in spark just for encryption. \n\nBeen doing a fair bit of googling, am I crazy or is this just not a thing you can do in trino or postgres?", "author_fullname": "t2_706trkkr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Column level data encryption", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15evj9w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690845894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been pulling my hair out trying to figure out how to implement a column level encryption similar to what&amp;#39;s available on spark. My stack is essentially s3 parquet files with a trino layer that pipes to postgres. On a different life I would use a spark udf but I don&amp;#39;t want to pull in spark just for encryption. &lt;/p&gt;\n\n&lt;p&gt;Been doing a fair bit of googling, am I crazy or is this just not a thing you can do in trino or postgres?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15evj9w", "is_robot_indexable": true, "report_reasons": null, "author": "Foodwithfloyd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15evj9w/column_level_data_encryption/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15evj9w/column_level_data_encryption/", "subreddit_subscribers": 119613, "created_utc": 1690845894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I was recently laid off and have about 10 years experience (USA)  so have done tasks that could fall under any of the titles above. Most interview will most like be DE roles or SWE;DE. That being said when I have interviewed in the past and what I am seeing again is a lot of variety in what these roles get interviewed for and recruiters prepping you  not really even being as discrete. Here are the 3 flavors I\u2019ve seen. \n\n1. Bigger tech; gives you random leet code that  could have nothing related to DE they just are washing you through the ritual of checking algo/data structure knowledge. \n\n2. Seems like \u201cHCOL well funded tier 2\u201d start ups will mimic the above (and recruiters will always say prepare leetcode style ) but will sometimes deliver a bespoke question closer to what a swe would think a de does ie process log data data from a server and return  different aggregates of that data but only using the stand library of a dynamic programming language and return it in a dictionary(ie python without pandas ). Which seems like always hard to align on what the are really trying to test for other than if you recall all the languages out of the box functions really well. \n\n3. Usually small start ups; take home project to write a pipeline. \n\n**curious if we feel the same ** \n\n\nI just get frustrated spending hours on leetcode and Big O to only find my interview went south because I have not made an aggregation for awhile off a python dictionary or forgot the regex syntax or some nuance of .split(). \n\nAdditionally while trying to brush up on traditional CS concepts and also applying / interviewing it is hard to not have some atrophy on SQL and day to day python  coding ; I know I can practice and make a project but it\u2019s hard to determine how much to invest vs CS fundamentals, language of choice nuances, hard transformations , one off dynamic programming questions , leetcode , general architecture and other tech needed to be known as a DE. \n\nI know it\u2019s all apart of the job and I have experience doing it all just feeling like it\u2019s hard the future into read an interview process. \n\nMaybe discussion here on how to best prepare would help us all ? My current approach to getting a job is below and I am still crafting as I was laid off two weeks ago and trying my best to get a job offer in 10 weeks (I know , ambitious but also last employer give little severance to us). I\u2019ve come from a place where some days i wrote Python, filled in terraform yaml files , spun infra in cloud, model data, debug airflow ect. So my skill repetition was not narrow. \n\nI wanna optimize how to prepare and succeed in this job market and it seems like most interviews say they care about skills in \u201ccracking the coding interview\u201d , but doesn\u2019t seem to be spot on for people with our background ie data engineering. Here is my schedule below , open to feedback. \n\nM-f (unless interviews mixed in or having me do this on the weekend)\n1) morning: (up to 4 hours ) doing algo/data structure training. Ie hand writing pre_order_traversal template. Hoping this also reinforces python syntax as well. \n2) afternoon: . As much as I can apply to jobs via LinkedIn and take interview. \n3) evening \u2014 1hr; lightly refresh on python syntax , sql &amp; genera DE architecture (this work is pretty unstructored \u2014 weather it be w3schools, terraform docs , k8s medium article). Try to relax and change mind space.", "author_fullname": "t2_13551s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview prep for DE , SWE Eng; Data, Data Infra , Data Platform, Analytics Engineer roles.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ev7ew", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690845062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I was recently laid off and have about 10 years experience (USA)  so have done tasks that could fall under any of the titles above. Most interview will most like be DE roles or SWE;DE. That being said when I have interviewed in the past and what I am seeing again is a lot of variety in what these roles get interviewed for and recruiters prepping you  not really even being as discrete. Here are the 3 flavors I\u2019ve seen. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Bigger tech; gives you random leet code that  could have nothing related to DE they just are washing you through the ritual of checking algo/data structure knowledge. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Seems like \u201cHCOL well funded tier 2\u201d start ups will mimic the above (and recruiters will always say prepare leetcode style ) but will sometimes deliver a bespoke question closer to what a swe would think a de does ie process log data data from a server and return  different aggregates of that data but only using the stand library of a dynamic programming language and return it in a dictionary(ie python without pandas ). Which seems like always hard to align on what the are really trying to test for other than if you recall all the languages out of the box functions really well. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Usually small start ups; take home project to write a pipeline. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;*&lt;em&gt;curious if we feel the same *&lt;/em&gt; &lt;/p&gt;\n\n&lt;p&gt;I just get frustrated spending hours on leetcode and Big O to only find my interview went south because I have not made an aggregation for awhile off a python dictionary or forgot the regex syntax or some nuance of .split(). &lt;/p&gt;\n\n&lt;p&gt;Additionally while trying to brush up on traditional CS concepts and also applying / interviewing it is hard to not have some atrophy on SQL and day to day python  coding ; I know I can practice and make a project but it\u2019s hard to determine how much to invest vs CS fundamentals, language of choice nuances, hard transformations , one off dynamic programming questions , leetcode , general architecture and other tech needed to be known as a DE. &lt;/p&gt;\n\n&lt;p&gt;I know it\u2019s all apart of the job and I have experience doing it all just feeling like it\u2019s hard the future into read an interview process. &lt;/p&gt;\n\n&lt;p&gt;Maybe discussion here on how to best prepare would help us all ? My current approach to getting a job is below and I am still crafting as I was laid off two weeks ago and trying my best to get a job offer in 10 weeks (I know , ambitious but also last employer give little severance to us). I\u2019ve come from a place where some days i wrote Python, filled in terraform yaml files , spun infra in cloud, model data, debug airflow ect. So my skill repetition was not narrow. &lt;/p&gt;\n\n&lt;p&gt;I wanna optimize how to prepare and succeed in this job market and it seems like most interviews say they care about skills in \u201ccracking the coding interview\u201d , but doesn\u2019t seem to be spot on for people with our background ie data engineering. Here is my schedule below , open to feedback. &lt;/p&gt;\n\n&lt;p&gt;M-f (unless interviews mixed in or having me do this on the weekend)\n1) morning: (up to 4 hours ) doing algo/data structure training. Ie hand writing pre_order_traversal template. Hoping this also reinforces python syntax as well. \n2) afternoon: . As much as I can apply to jobs via LinkedIn and take interview. \n3) evening \u2014 1hr; lightly refresh on python syntax , sql &amp;amp; genera DE architecture (this work is pretty unstructored \u2014 weather it be w3schools, terraform docs , k8s medium article). Try to relax and change mind space.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15ev7ew", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ev7ew/interview_prep_for_de_swe_eng_data_data_infra/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ev7ew/interview_prep_for_de_swe_eng_data_data_infra/", "subreddit_subscribers": 119613, "created_utc": 1690845062.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working on a batch data pipeline for a ML application (large scale) as a first data engineering project. I am new to data engineering and therefore not familiar with most of the microservices and best practices and have a few issues understanding some concepts. (ChatGPT unfortunately also did not help much)\n\n1. Data Ingestion Layer: In most sources that I have read so far Kafka is suggested for pulling data from the original source (a CSV in my case). When reading only about Kafka though, it is described as a tool mainly used for stream processing. Why should I use Kafka for batch processing then and is this really best practice? What are the alternatives?\n2. Data Storage: I am also very indecisive when it comes to data storage for the batch processing pipeline. Most of the microservices seem to over-perform for my actual needs and I am wondering if there might be a lean solution. E.g. I have a dataset with structured data so MongoDB for example might be a bit excessive.\n\nFurther comments: so far, I have settled on using PySpark for Data Processing &amp; Aggregation. Airflow &amp; Docker for scheduling &amp; orchestration\n\nI have to decide on certain microservices to use and come up with a flow chart for the whole data pipeline. For advice and best practice tips as well as usefull git repos, I would be very grateful.", "author_fullname": "t2_gn0tebgv5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Batch processing for ML pipeline - questions in regards to data ingestion and data storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15esawn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690838075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a batch data pipeline for a ML application (large scale) as a first data engineering project. I am new to data engineering and therefore not familiar with most of the microservices and best practices and have a few issues understanding some concepts. (ChatGPT unfortunately also did not help much)&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Ingestion Layer: In most sources that I have read so far Kafka is suggested for pulling data from the original source (a CSV in my case). When reading only about Kafka though, it is described as a tool mainly used for stream processing. Why should I use Kafka for batch processing then and is this really best practice? What are the alternatives?&lt;/li&gt;\n&lt;li&gt;Data Storage: I am also very indecisive when it comes to data storage for the batch processing pipeline. Most of the microservices seem to over-perform for my actual needs and I am wondering if there might be a lean solution. E.g. I have a dataset with structured data so MongoDB for example might be a bit excessive.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Further comments: so far, I have settled on using PySpark for Data Processing &amp;amp; Aggregation. Airflow &amp;amp; Docker for scheduling &amp;amp; orchestration&lt;/p&gt;\n\n&lt;p&gt;I have to decide on certain microservices to use and come up with a flow chart for the whole data pipeline. For advice and best practice tips as well as usefull git repos, I would be very grateful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15esawn", "is_robot_indexable": true, "report_reasons": null, "author": "aloy_joz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15esawn/batch_processing_for_ml_pipeline_questions_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15esawn/batch_processing_for_ml_pipeline_questions_in/", "subreddit_subscribers": 119613, "created_utc": 1690838075.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Will it be much easier (security wise) to connect bigquery to looker than to connect redshift to big query?", "author_fullname": "t2_vit6d6oc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will it be much easier (security wise) to connect bigquery to looker than to connect redshift to big query?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15emz8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690825858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Will it be much easier (security wise) to connect bigquery to looker than to connect redshift to big query?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15emz8q", "is_robot_indexable": true, "report_reasons": null, "author": "poopbrainmane", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15emz8q/will_it_be_much_easier_security_wise_to_connect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15emz8q/will_it_be_much_easier_security_wise_to_connect/", "subreddit_subscribers": 119613, "created_utc": 1690825858.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We need to replicate / sync AWS Mysql db to Azure SQL db.  The DB is small size with nominal activity.\n\nIs there a build in solution available in either platform? If not, what is the simplest solution we can design and implement using which tools?\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "need aws to azure replication", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15emxyv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690825780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We need to replicate / sync AWS Mysql db to Azure SQL db.  The DB is small size with nominal activity.&lt;/p&gt;\n\n&lt;p&gt;Is there a build in solution available in either platform? If not, what is the simplest solution we can design and implement using which tools?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15emxyv", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15emxyv/need_aws_to_azure_replication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15emxyv/need_aws_to_azure_replication/", "subreddit_subscribers": 119613, "created_utc": 1690825780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wondering if experts here can share some real life streaming use cases they have built, and how troubleshooting is performed on these pipelines. \n\nParticularly the troubleshooting aspect of it - how do you ensure no data loss? Are there deduplication processes or manual reconciliation after restarting the jobs?\n\nI am a data engineer on GCP but have not built any streaming jobs other than the tutorials on Dataflow and a few pub/sub use cases. Streaming experience appears to be highly critical in finding a job, but these are not cutting it. Any pointers will be deeply appreciated. \n\nThanks.", "author_fullname": "t2_26djbmc5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real life examples of troubleshooting streaming data ingestion and use cases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15elzja", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690823583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering if experts here can share some real life streaming use cases they have built, and how troubleshooting is performed on these pipelines. &lt;/p&gt;\n\n&lt;p&gt;Particularly the troubleshooting aspect of it - how do you ensure no data loss? Are there deduplication processes or manual reconciliation after restarting the jobs?&lt;/p&gt;\n\n&lt;p&gt;I am a data engineer on GCP but have not built any streaming jobs other than the tutorials on Dataflow and a few pub/sub use cases. Streaming experience appears to be highly critical in finding a job, but these are not cutting it. Any pointers will be deeply appreciated. &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15elzja", "is_robot_indexable": true, "report_reasons": null, "author": "sanimesa", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15elzja/real_life_examples_of_troubleshooting_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15elzja/real_life_examples_of_troubleshooting_streaming/", "subreddit_subscribers": 119613, "created_utc": 1690823583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uwe2fsd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Privacy and Compliance: Ethical Web Scraping with Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15el2db", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jhOA75Fk1ktoAzFAamgUhBYJMJ76YyPrv4_DjTa9X4A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690821405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "python.plainenglish.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://python.plainenglish.io/data-privacy-and-compliance-ethical-web-scraping-with-bright-data-and-python-8cc63b1c3db4", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?auto=webp&amp;s=06555f7649fcae44965dac64533ac3e8f8aff8db", "width": 1200, "height": 801}, "resolutions": [{"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=69ea7d740c393012ddac3f83725683c1a940df28", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d39648ee820a4cfe2b0c2954d84fc01c5b07b219", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8fc4974b7a859d01a6964f4e0a244beb4eb2cffd", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=38aee157ee7b9846d27afbe70ffa7d94e2b27c1c", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ad3b95d186adba8bbec6c7dd1644dfc4a745fd8d", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/AZIMR7pbXw_s8fdrekdZFXhO0o0Fk1s3BX-9c89R9hA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3bfe2f2e64fc341d77feb22a401d5cc808dda91f", "width": 1080, "height": 720}], "variants": {}, "id": "tvGC4kMTZH_dAo7ZG8KQVPXGNKxuXAB9zqbQJOwoTME"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15el2db", "is_robot_indexable": true, "report_reasons": null, "author": "TheLostWanderer47", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15el2db/data_privacy_and_compliance_ethical_web_scraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://python.plainenglish.io/data-privacy-and-compliance-ethical-web-scraping-with-bright-data-and-python-8cc63b1c3db4", "subreddit_subscribers": 119613, "created_utc": 1690821405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys!\n\nI'm looking to enhance my data skills and dive deeper into Microsoft's powerful suite of tools for Business Intelligence and data processing. Specifically, I'm interested in learning more about SSIS, SSAS, SSRS, and Power BI.\n\nI'm reaching out for some course recommendations do you guys perhaps have any? ", "author_fullname": "t2_14erwu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Course Recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eifq6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690815295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to enhance my data skills and dive deeper into Microsoft&amp;#39;s powerful suite of tools for Business Intelligence and data processing. Specifically, I&amp;#39;m interested in learning more about SSIS, SSAS, SSRS, and Power BI.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reaching out for some course recommendations do you guys perhaps have any? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15eifq6", "is_robot_indexable": true, "report_reasons": null, "author": "Pershanthen", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15eifq6/course_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15eifq6/course_recommendations/", "subreddit_subscribers": 119613, "created_utc": 1690815295.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}