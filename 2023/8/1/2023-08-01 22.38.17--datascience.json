{"kind": "Listing", "data": {"after": "t3_15fd163", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, y'all. I've been wanting to address this question for some time now. The sub is slowly changing to r/learndatascience. We get the same questions posted here everyday (sometimes several times on the same day):\n\n1. What degree should I get?\n2. How much math should I learn to work with DS?\n3. How can I get the first job?\n4. Will IA replace DS jobs?\n5. Now and then also there are the \"I don't like math, how can I work with DS\", or the \"do I really need to learn advanced math?\" where by advanced math people mean linear algebra and calculus.\n\nI understand that these are honest questions, but they have been already asked billions of times. Also, it is kind of astounding how people want to work with a technical field, hence you need to be constantly learning things and searching for answers, and yet they don't even bother to search if the same question was already asked on the sub. I mean, this is not even hard to do, you don't even have to be on reddit, just post on google reddit + question and google will show the it.\n\nIn my opinion this is bad for the sub as an online forum. Compare, e.g., with stackexchange. If a question was already asked people will shut it as duplicate and link to the previous post where it was already answered. This is bad, imo, because, it floods the sub and prevents people from having good discussions about the topic of the sub. I mean, it is quite some time that I don't see a real DS post here.\n\nI know that it can sound like a rant, but I understand r/datascience as a forum where people go to talk about DS and honestly I miss seeing these posts, e.g., people talking about how they solved some particular problem, talking about research papers and etc.\n\nAnd last but not least, I know that DS was hyped and people think that it is the new \"dev\" job to get easy money. But I think that discuss this topic we would be better suited with a post just to address it. \n\n&amp;#x200B;", "author_fullname": "t2_hmlahc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discussion about the sub", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fcchn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 130, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 130, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690895800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, y&amp;#39;all. I&amp;#39;ve been wanting to address this question for some time now. The sub is slowly changing to &lt;a href=\"/r/learndatascience\"&gt;r/learndatascience&lt;/a&gt;. We get the same questions posted here everyday (sometimes several times on the same day):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What degree should I get?&lt;/li&gt;\n&lt;li&gt;How much math should I learn to work with DS?&lt;/li&gt;\n&lt;li&gt;How can I get the first job?&lt;/li&gt;\n&lt;li&gt;Will IA replace DS jobs?&lt;/li&gt;\n&lt;li&gt;Now and then also there are the &amp;quot;I don&amp;#39;t like math, how can I work with DS&amp;quot;, or the &amp;quot;do I really need to learn advanced math?&amp;quot; where by advanced math people mean linear algebra and calculus.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I understand that these are honest questions, but they have been already asked billions of times. Also, it is kind of astounding how people want to work with a technical field, hence you need to be constantly learning things and searching for answers, and yet they don&amp;#39;t even bother to search if the same question was already asked on the sub. I mean, this is not even hard to do, you don&amp;#39;t even have to be on reddit, just post on google reddit + question and google will show the it.&lt;/p&gt;\n\n&lt;p&gt;In my opinion this is bad for the sub as an online forum. Compare, e.g., with stackexchange. If a question was already asked people will shut it as duplicate and link to the previous post where it was already answered. This is bad, imo, because, it floods the sub and prevents people from having good discussions about the topic of the sub. I mean, it is quite some time that I don&amp;#39;t see a real DS post here.&lt;/p&gt;\n\n&lt;p&gt;I know that it can sound like a rant, but I understand &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt; as a forum where people go to talk about DS and honestly I miss seeing these posts, e.g., people talking about how they solved some particular problem, talking about research papers and etc.&lt;/p&gt;\n\n&lt;p&gt;And last but not least, I know that DS was hyped and people think that it is the new &amp;quot;dev&amp;quot; job to get easy money. But I think that discuss this topic we would be better suited with a post just to address it. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fcchn", "is_robot_indexable": true, "report_reasons": null, "author": "magikarpa1", "discussion_type": null, "num_comments": 69, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fcchn/discussion_about_the_sub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fcchn/discussion_about_the_sub/", "subreddit_subscribers": 970884, "created_utc": 1690895800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work at a large company, and we receive quite a lot of applicants. Most of our applicants have 6-9 years of experience in roles titled as Data Analytics/Data Science/Data Engineering across notable companies and brands like Walmart, Ford, Accenture, Amazon, Ulta, Macy's, Nike, etc.\n\nThe nature of our interviews is fairly simple - we have a brief phone call on theory and foundation of data analytics, and then have a couple of technical interviews focusing on programming and basic data analysis. The interview doesn't cover anything out of the ordinary for most analysts (not even data scientists), and focuses on basic data analysis practices (filter down a column given a set of requirements, get a count of uniques, do basic EDA and explain how to manage outliers). \n\nAll interviewees are told they can use Google as we don't expect people to memorize the syntax, but we do expect them to have at least working knowledge of the tools we expect them to use. The interviews are all remote and don't require in-person meeting. The interviews are basically screen share of Google Colab where we run basic analysis.\n\nIn our recent hiring spree, out of the 7 potential candidates we interviewed, we caught 4 of them cheating.\n\nGiven their profile, I'm a bit amazed that they resorted to cheating. Whether it was by having someone else on the call helping them answer the question, or having someone entirely different answer their questions, and other notable methods that I don't want to share that we caught while they were sharing their screens. I've learned from my colleagues that there are actual *agencies* in India and China who offer interview 'assistance' services.\n\nAt this stage, our leadership is planning to require all potential candidates to be local - this eliminates remote option. On the same token, those cheaters passing the recruiter screening are quite frankly just making it worse for people who are actually capable. Questions become more theoretical and quite specific to industry, scope of hiring will be limited to people within specific domains, and improptu coding tests will be given out without heads up to hinder people from cheating and setting up whatever they do to cheat.\n\n/endrant", "author_fullname": "t2_48648", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RANT - There's a cheating problem in Data Science Interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15flo97", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 84, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 84, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690916881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a large company, and we receive quite a lot of applicants. Most of our applicants have 6-9 years of experience in roles titled as Data Analytics/Data Science/Data Engineering across notable companies and brands like Walmart, Ford, Accenture, Amazon, Ulta, Macy&amp;#39;s, Nike, etc.&lt;/p&gt;\n\n&lt;p&gt;The nature of our interviews is fairly simple - we have a brief phone call on theory and foundation of data analytics, and then have a couple of technical interviews focusing on programming and basic data analysis. The interview doesn&amp;#39;t cover anything out of the ordinary for most analysts (not even data scientists), and focuses on basic data analysis practices (filter down a column given a set of requirements, get a count of uniques, do basic EDA and explain how to manage outliers). &lt;/p&gt;\n\n&lt;p&gt;All interviewees are told they can use Google as we don&amp;#39;t expect people to memorize the syntax, but we do expect them to have at least working knowledge of the tools we expect them to use. The interviews are all remote and don&amp;#39;t require in-person meeting. The interviews are basically screen share of Google Colab where we run basic analysis.&lt;/p&gt;\n\n&lt;p&gt;In our recent hiring spree, out of the 7 potential candidates we interviewed, we caught 4 of them cheating.&lt;/p&gt;\n\n&lt;p&gt;Given their profile, I&amp;#39;m a bit amazed that they resorted to cheating. Whether it was by having someone else on the call helping them answer the question, or having someone entirely different answer their questions, and other notable methods that I don&amp;#39;t want to share that we caught while they were sharing their screens. I&amp;#39;ve learned from my colleagues that there are actual &lt;em&gt;agencies&lt;/em&gt; in India and China who offer interview &amp;#39;assistance&amp;#39; services.&lt;/p&gt;\n\n&lt;p&gt;At this stage, our leadership is planning to require all potential candidates to be local - this eliminates remote option. On the same token, those cheaters passing the recruiter screening are quite frankly just making it worse for people who are actually capable. Questions become more theoretical and quite specific to industry, scope of hiring will be limited to people within specific domains, and improptu coding tests will be given out without heads up to hinder people from cheating and setting up whatever they do to cheat.&lt;/p&gt;\n\n&lt;p&gt;/endrant&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15flo97", "is_robot_indexable": true, "report_reasons": null, "author": "forbiscuit", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15flo97/rant_theres_a_cheating_problem_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15flo97/rant_theres_a_cheating_problem_in_data_science/", "subreddit_subscribers": 970884, "created_utc": 1690916881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been searching around for a while now trying to find freelance work on the weekends for beer money but haven't been successful. I have tried Upwork aggressively for like 3 months straights and got no responses.  \n\nI just want like 10-15 hours on weekends so I can afford toilet paper and diapers for my 9 month old.", "author_fullname": "t2_kw1h2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Freelance work on the weekends a thing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f8n3b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 51, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 51, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690885810.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been searching around for a while now trying to find freelance work on the weekends for beer money but haven&amp;#39;t been successful. I have tried Upwork aggressively for like 3 months straights and got no responses.  &lt;/p&gt;\n\n&lt;p&gt;I just want like 10-15 hours on weekends so I can afford toilet paper and diapers for my 9 month old.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15f8n3b", "is_robot_indexable": true, "report_reasons": null, "author": "frescoj10", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15f8n3b/is_freelance_work_on_the_weekends_a_thing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15f8n3b/is_freelance_work_on_the_weekends_a_thing/", "subreddit_subscribers": 970884, "created_utc": 1690885810.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work on Dask (OSS Python library for parallel computing) and I see people misusing us to run single functions or scripts on cloud machines.  I tell them \"Dask seems like overkill here, maybe there's a simpler tool out there that's easier to use?\"\n\nAfter doing a bit of research, maybe there isn't?  I'm surprised clouds haven't made a smoother UX around Lambda/EC2/Batch/ECS.  Am I missing something?\n\nI wrote a small blog post about this here: [https://medium.com/coiled-hq/easy-heavyweight-serverless-functions-1983288c9ebc](https://medium.com/coiled-hq/easy-heavyweight-serverless-functions-1983288c9ebc) . It (shamelessly) advertises and thing we built on top of Dask + Coiled to do make this more palatable for non-cloud-conversant Python folks.  It took about a week of development effort, which I hope is enough to garner some good feedback/critique. This was kind of a slapdash effort, but seems ok?", "author_fullname": "t2_ay1q1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running a single script in the cloud shouldn't be hard", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fc6ox", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690895397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work on Dask (OSS Python library for parallel computing) and I see people misusing us to run single functions or scripts on cloud machines.  I tell them &amp;quot;Dask seems like overkill here, maybe there&amp;#39;s a simpler tool out there that&amp;#39;s easier to use?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;After doing a bit of research, maybe there isn&amp;#39;t?  I&amp;#39;m surprised clouds haven&amp;#39;t made a smoother UX around Lambda/EC2/Batch/ECS.  Am I missing something?&lt;/p&gt;\n\n&lt;p&gt;I wrote a small blog post about this here: &lt;a href=\"https://medium.com/coiled-hq/easy-heavyweight-serverless-functions-1983288c9ebc\"&gt;https://medium.com/coiled-hq/easy-heavyweight-serverless-functions-1983288c9ebc&lt;/a&gt; . It (shamelessly) advertises and thing we built on top of Dask + Coiled to do make this more palatable for non-cloud-conversant Python folks.  It took about a week of development effort, which I hope is enough to garner some good feedback/critique. This was kind of a slapdash effort, but seems ok?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?auto=webp&amp;s=2500e20c454938762e145ed937b5f672c7107662", "width": 896, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5bcad2d83ba44812cde35a979f693e85f02ddaf9", "width": 108, "height": 48}, {"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=52a97dc310c1b8265ad9a42ec3aee06746e66741", "width": 216, "height": 96}, {"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dbdbe143a144ea4988a66c1ce8b17371b5656b35", "width": 320, "height": 142}, {"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e527de6f5793a0b076997f0214c37ae589620340", "width": 640, "height": 285}], "variants": {}, "id": "bOYGIMA5j7XFBgY_b1492O6l7ahrAYsoMlsFe7s2tWQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fc6ox", "is_robot_indexable": true, "report_reasons": null, "author": "mrocklin", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fc6ox/running_a_single_script_in_the_cloud_shouldnt_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fc6ox/running_a_single_script_in_the_cloud_shouldnt_be/", "subreddit_subscribers": 970884, "created_utc": 1690895397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So, I enrolled for a training program that wants me to choose between software engineering and data science. As a person, I enrolled for the program because I want really learn to code; I love coding though I have not had the opportunity to start. At the start, I actually chose data science because I was looking for something that incorporates both software engineering and something else with the hope that I will have enough time learning a lot of coding all the way.\n\nFrom my little research, it seems there is very little coding data scientists do(most of their work end up as visualizations which I kind of detest); however, data engineers seem to do more coding than data scientists.\n\nI am from Nigeria. And, I am looking at the prospects of the two in my country and Africa as a hole especially.\n\nWhat would you advise and do you think I can learn a bit of software engineering along the way since I still have to up my computer science knowledge?\n\n\\*\\*\\*I have no background in computer science and can only solve basic mathematics and statistics.\n\nI have till tomorrow or else I will be confirmed on the data science track. Thanks in advance.", "author_fullname": "t2_bexo9x074", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software engineering vs data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f6vyh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690880301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I enrolled for a training program that wants me to choose between software engineering and data science. As a person, I enrolled for the program because I want really learn to code; I love coding though I have not had the opportunity to start. At the start, I actually chose data science because I was looking for something that incorporates both software engineering and something else with the hope that I will have enough time learning a lot of coding all the way.&lt;/p&gt;\n\n&lt;p&gt;From my little research, it seems there is very little coding data scientists do(most of their work end up as visualizations which I kind of detest); however, data engineers seem to do more coding than data scientists.&lt;/p&gt;\n\n&lt;p&gt;I am from Nigeria. And, I am looking at the prospects of the two in my country and Africa as a hole especially.&lt;/p&gt;\n\n&lt;p&gt;What would you advise and do you think I can learn a bit of software engineering along the way since I still have to up my computer science knowledge?&lt;/p&gt;\n\n&lt;p&gt;***I have no background in computer science and can only solve basic mathematics and statistics.&lt;/p&gt;\n\n&lt;p&gt;I have till tomorrow or else I will be confirmed on the data science track. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15f6vyh", "is_robot_indexable": true, "report_reasons": null, "author": "Comfortable-Pizza447", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15f6vyh/software_engineering_vs_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15f6vyh/software_engineering_vs_data_science/", "subreddit_subscribers": 970884, "created_utc": 1690880301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently graduated from a mid tier university with a degree in business and economic analytics (with a data science emphasis). I never had an internship or experience professionally while I was in school. However I started my own unrelated business that I worked on for 4 years while in school, I also worked for 2 years at a delivery company where I was promoted to a managerial role, and I am a head coach for a travel youth basketball team. So, I wasn\u2019t just in school I have plenty of experience outside of it.\n\nI am currently applying for jobs and with no professional experience I am only getting auto rejected. I know this process could take months, so I am considering finishing a degree in applied math where it will only take me 1 more year and a total of 6 classes. If I decide to do this, I am going to try and get an internship to help where I am lacking in experience. \n\nSo, my question being is it a good idea to finish this degree and work as an intern or continue looking for jobs and hopefully find one soon?\n\nTL;DR: get a second degree or keep looking for jobs?", "author_fullname": "t2_bcywmo0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I finish an applied math degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15etnxi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690841260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently graduated from a mid tier university with a degree in business and economic analytics (with a data science emphasis). I never had an internship or experience professionally while I was in school. However I started my own unrelated business that I worked on for 4 years while in school, I also worked for 2 years at a delivery company where I was promoted to a managerial role, and I am a head coach for a travel youth basketball team. So, I wasn\u2019t just in school I have plenty of experience outside of it.&lt;/p&gt;\n\n&lt;p&gt;I am currently applying for jobs and with no professional experience I am only getting auto rejected. I know this process could take months, so I am considering finishing a degree in applied math where it will only take me 1 more year and a total of 6 classes. If I decide to do this, I am going to try and get an internship to help where I am lacking in experience. &lt;/p&gt;\n\n&lt;p&gt;So, my question being is it a good idea to finish this degree and work as an intern or continue looking for jobs and hopefully find one soon?&lt;/p&gt;\n\n&lt;p&gt;TL;DR: get a second degree or keep looking for jobs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15etnxi", "is_robot_indexable": true, "report_reasons": null, "author": "Tattooed_Moose", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15etnxi/should_i_finish_an_applied_math_degree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15etnxi/should_i_finish_an_applied_math_degree/", "subreddit_subscribers": 970884, "created_utc": 1690841260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone! I'm a student researcher at UT Austin. I\u2019m doing some work on differential privacy in synthetic data and would like to learn more about data workflows and practices in industry. If you could take some time to answer some of these questions it would be greatly appreciated:\n\n1. Have you had any issues internally sharing and utilizing sensitive data?\n2. How have you approached company policies and regulations that limit access to sensitive but necessary data?\n3. Have you ever used synthetic data internally or in production? \n4. What is your current approach when training models or doing an analysis on private data?\n5. What techniques/tools have you used to anonymize or remove PII from sensitive data?\n\nIf you\u2019re interested in chatting more or have worked in this space I would love to get any feedback possible, so don\u2019t hesitate to reach out. Thanks!", "author_fullname": "t2_tg5fewzz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Differential privacy in synthetic data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15evw29", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690846785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! I&amp;#39;m a student researcher at UT Austin. I\u2019m doing some work on differential privacy in synthetic data and would like to learn more about data workflows and practices in industry. If you could take some time to answer some of these questions it would be greatly appreciated:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Have you had any issues internally sharing and utilizing sensitive data?&lt;/li&gt;\n&lt;li&gt;How have you approached company policies and regulations that limit access to sensitive but necessary data?&lt;/li&gt;\n&lt;li&gt;Have you ever used synthetic data internally or in production? &lt;/li&gt;\n&lt;li&gt;What is your current approach when training models or doing an analysis on private data?&lt;/li&gt;\n&lt;li&gt;What techniques/tools have you used to anonymize or remove PII from sensitive data?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;If you\u2019re interested in chatting more or have worked in this space I would love to get any feedback possible, so don\u2019t hesitate to reach out. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15evw29", "is_robot_indexable": true, "report_reasons": null, "author": "avnertothemoon", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15evw29/differential_privacy_in_synthetic_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15evw29/differential_privacy_in_synthetic_data/", "subreddit_subscribers": 970884, "created_utc": 1690846785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a DS Director.", "author_fullname": "t2_kcl3tfwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I finished all my work for the week. What should I do with the rest my time (4 days)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ev9yl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690845251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a DS Director.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ev9yl", "is_robot_indexable": true, "report_reasons": null, "author": "NewEcho2940", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ev9yl/i_finished_all_my_work_for_the_week_what_should_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ev9yl/i_finished_all_my_work_for_the_week_what_should_i/", "subreddit_subscribers": 970884, "created_utc": 1690845251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'm currently working on an academic research project and came across a website that sells data. However, they offer free trials during which I can access the data I need for my research. I was wondering if web scraping this website during the free trial period for academic purposes is considered legal? I know this can be a very gray territory. Any insights or advice would be greatly appreciated. Thanks in advance!", "author_fullname": "t2_2px1ka8r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Web Scraping for Academic Purposes Illegal? (Regarding a Website with Free Trials)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fmzkg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690919865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m currently working on an academic research project and came across a website that sells data. However, they offer free trials during which I can access the data I need for my research. I was wondering if web scraping this website during the free trial period for academic purposes is considered legal? I know this can be a very gray territory. Any insights or advice would be greatly appreciated. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fmzkg", "is_robot_indexable": true, "report_reasons": null, "author": "mmllppnnk", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fmzkg/is_web_scraping_for_academic_purposes_illegal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fmzkg/is_web_scraping_for_academic_purposes_illegal/", "subreddit_subscribers": 970884, "created_utc": 1690919865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sorry a very beginners questions but wanted to ask if this is enough for the beginners", "author_fullname": "t2_ggsjckfnk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a good way to start getting into data analysing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 83, "top_awarded_type": null, "hide_score": false, "name": "t3_15fbi7l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rJjor77iLGtAr8r4hgw1wSnqqG7i3hVauHIvbBTVRaA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690893732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry a very beginners questions but wanted to ask if this is enough for the beginners&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/9jj8rsx6vhfb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/9jj8rsx6vhfb1.jpg?auto=webp&amp;s=557b2da5629ae933398218d2c838581f9484f77c", "width": 1080, "height": 642}, "resolutions": [{"url": "https://preview.redd.it/9jj8rsx6vhfb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dacc906f4404c79672b3d66091833ddf33ed39ee", "width": 108, "height": 64}, {"url": "https://preview.redd.it/9jj8rsx6vhfb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=90343ef668d704cb1610b2fa5968068a81539f0f", "width": 216, "height": 128}, {"url": "https://preview.redd.it/9jj8rsx6vhfb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3fbd54cd24bac9fed6bafc596fb998691d42b377", "width": 320, "height": 190}, {"url": "https://preview.redd.it/9jj8rsx6vhfb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a2e3c40a45ea9bea4ced9265ba57e693d5a28830", "width": 640, "height": 380}, {"url": "https://preview.redd.it/9jj8rsx6vhfb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5f5879c7eac15045c2453924595b71c56eb49c6e", "width": 960, "height": 570}, {"url": "https://preview.redd.it/9jj8rsx6vhfb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cfafc32468e14ad4567c9a60cc783e65f7fb1582", "width": 1080, "height": 642}], "variants": {}, "id": "O_GQ2bW3cJueUsKyI_f2lZPLpkNOJAcqGRXnB-KrAB4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fbi7l", "is_robot_indexable": true, "report_reasons": null, "author": "Remember_da_niggo", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fbi7l/is_this_a_good_way_to_start_getting_into_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/9jj8rsx6vhfb1.jpg", "subreddit_subscribers": 970884, "created_utc": 1690893732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've taken data structures, algorithms, and a few upper division econometrics classes. I'm familiar with R(tidyverse, dplyr) as I took an intro DS class using it, but mostly use Python and C. I'm also about to take a ML and an AI class next quarter. Realizing you have no way of knowing the extent of what I know and don't know, I was wondering if there are some topics that I might have a gap in my knowledge that would be essential to pursuing DS? Is it a major drawback that grad school isn't really an immediate option for me (I would love for it to be in the future)? Are econ majors frowned upon in DS? Thanks for any feedback :).", "author_fullname": "t2_sjesx3di", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm an undergrad Econ major and CS minor with a specialization in Econometrics looking into data science. What are some blind spots I might have as an econ major going into DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f8yc8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690889263.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690886758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve taken data structures, algorithms, and a few upper division econometrics classes. I&amp;#39;m familiar with R(tidyverse, dplyr) as I took an intro DS class using it, but mostly use Python and C. I&amp;#39;m also about to take a ML and an AI class next quarter. Realizing you have no way of knowing the extent of what I know and don&amp;#39;t know, I was wondering if there are some topics that I might have a gap in my knowledge that would be essential to pursuing DS? Is it a major drawback that grad school isn&amp;#39;t really an immediate option for me (I would love for it to be in the future)? Are econ majors frowned upon in DS? Thanks for any feedback :).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15f8yc8", "is_robot_indexable": true, "report_reasons": null, "author": "thehippophant", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15f8yc8/im_an_undergrad_econ_major_and_cs_minor_with_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15f8yc8/im_an_undergrad_econ_major_and_cs_minor_with_a/", "subreddit_subscribers": 970884, "created_utc": 1690886758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_a2ikkd35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "KDD 2023 Predicting Information Pathways Across Online Communities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_15f5xg9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W7Ajd1lMTO0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"KDD 2023 Predicting Information Pathways Across Online Communities\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "KDD 2023 Predicting Information Pathways Across Online Communities", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W7Ajd1lMTO0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"KDD 2023 Predicting Information Pathways Across Online Communities\"&gt;&lt;/iframe&gt;", "author_name": "Association for Computing Machinery (ACM)", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W7Ajd1lMTO0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheOfficialACM"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W7Ajd1lMTO0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"KDD 2023 Predicting Information Pathways Across Online Communities\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/15f5xg9", "height": 200}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4GOvuj7wABNigMXkyDq8dAWt-RKObxvwv7ucBjJCwMo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690876914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=W7Ajd1lMTO0", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VYjzaQH5wra6-ykS1lg2cPw1CjoE0U1p_j-mHpTlXFE.jpg?auto=webp&amp;s=378e59f861cfa2715586d4f485b8eb4625589302", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/VYjzaQH5wra6-ykS1lg2cPw1CjoE0U1p_j-mHpTlXFE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=546118d465346aa4e92d1caed09d60575c478c0e", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/VYjzaQH5wra6-ykS1lg2cPw1CjoE0U1p_j-mHpTlXFE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cf0a24871359591d9485de33ea81c738a54689df", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/VYjzaQH5wra6-ykS1lg2cPw1CjoE0U1p_j-mHpTlXFE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f562a50c935ffe2bc8d604818dae8ae968bd2adf", "width": 320, "height": 240}], "variants": {}, "id": "RfmleDVH5aw6JhLTiIm_rtgdI8G9eCSnYs3YAUGuwFs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15f5xg9", "is_robot_indexable": true, "report_reasons": null, "author": "UsefulAd9370", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15f5xg9/kdd_2023_predicting_information_pathways_across/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=W7Ajd1lMTO0", "subreddit_subscribers": 970884, "created_utc": 1690876914.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "KDD 2023 Predicting Information Pathways Across Online Communities", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W7Ajd1lMTO0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"KDD 2023 Predicting Information Pathways Across Online Communities\"&gt;&lt;/iframe&gt;", "author_name": "Association for Computing Machinery (ACM)", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W7Ajd1lMTO0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheOfficialACM"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A clustering advice\n\nThe situation: I am an operations analyst Ineeded to give each agent the closest 35 customer for him to visit.\n\nSolution : I used kmeans_constrained to cluster the retailers by their longitude and latitude and set the max size to 35 and that\u2019s fine, it does decent job in terms of distances.\n\nCon: it\u2019s really random, it just gets the closest 35 customers to visit regardless of anything else.\n\nSo, I made a custom score for each customer (the higher the score, the better. based on a lot pf kpis) and then, injected some logic into the code to go in the highest score and cluster the customers based on their coordinates, if the total route size is less than 35 it goes to the next score, do the same and so on till it reaches 35.\n\nCon: it\u2019s even more random, a cluster of customers who share a given score does not necessarily mean they are close to the cluster of customers who are in a different score, making the total route distance bigger.\n\n\nMy question:\nIf I cluster the customers based on their coordinates and their score together would this improve targeting and optimize the distance? Does the data need to be standardized? As the scores range from 0 to n (maximum is 30) while the longitude and latitude ranges (30,31) .\n\nOr do you know anything else better suited for the situation and I should read about? I am open to anything.\n\nThanks for your time.", "author_fullname": "t2_81zrh19oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need your advice in A clustering problem.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15fodhu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690923000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A clustering advice&lt;/p&gt;\n\n&lt;p&gt;The situation: I am an operations analyst Ineeded to give each agent the closest 35 customer for him to visit.&lt;/p&gt;\n\n&lt;p&gt;Solution : I used kmeans_constrained to cluster the retailers by their longitude and latitude and set the max size to 35 and that\u2019s fine, it does decent job in terms of distances.&lt;/p&gt;\n\n&lt;p&gt;Con: it\u2019s really random, it just gets the closest 35 customers to visit regardless of anything else.&lt;/p&gt;\n\n&lt;p&gt;So, I made a custom score for each customer (the higher the score, the better. based on a lot pf kpis) and then, injected some logic into the code to go in the highest score and cluster the customers based on their coordinates, if the total route size is less than 35 it goes to the next score, do the same and so on till it reaches 35.&lt;/p&gt;\n\n&lt;p&gt;Con: it\u2019s even more random, a cluster of customers who share a given score does not necessarily mean they are close to the cluster of customers who are in a different score, making the total route distance bigger.&lt;/p&gt;\n\n&lt;p&gt;My question:\nIf I cluster the customers based on their coordinates and their score together would this improve targeting and optimize the distance? Does the data need to be standardized? As the scores range from 0 to n (maximum is 30) while the longitude and latitude ranges (30,31) .&lt;/p&gt;\n\n&lt;p&gt;Or do you know anything else better suited for the situation and I should read about? I am open to anything.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fodhu", "is_robot_indexable": true, "report_reasons": null, "author": "Careful_Engineer_700", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fodhu/i_need_your_advice_in_a_clustering_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fodhu/i_need_your_advice_in_a_clustering_problem/", "subreddit_subscribers": 970884, "created_utc": 1690923000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_89utj0oc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you need to evaluate LLMs in dev &amp; prod? Tell us and we'll build it!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15fndg7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9NxyTMDQ9NyCwLrteiqiRqJPTCJ8hwlPI_oHBZu5GBw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690920725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "docs.google.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://docs.google.com/forms/d/e/1FAIpQLScfZ_4MSVmsiaoEByb_Y2tk--J-xtV35P6OnAiyaihbrjwlQQ/viewform", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?auto=webp&amp;s=4baa88eda2d32856c095157b32497cfdcac07817", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c37ab092aea51e7d8fe5b6e454b73dd2af9d685", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5a24ec5eea2909444420c49c93d58f3aaa26a3f7", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=56e9502f843fb8c19f7b578fcdb0fa4798ba91d4", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3eda8bdbc31fca5fbaf076ed7009600a4fcd1284", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=569b2d80ddeba8825267f7c9607e466f381cce02", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9a9c89878a8538c3e4dda30aebcdeccd9e530365", "width": 1080, "height": 567}], "variants": {}, "id": "aSd8ncNmnnembYorW0afv1xj2Hz2v5fwuLipkGABsSY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fndg7", "is_robot_indexable": true, "report_reasons": null, "author": "Sciencepeaches", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fndg7/what_do_you_need_to_evaluate_llms_in_dev_prod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://docs.google.com/forms/d/e/1FAIpQLScfZ_4MSVmsiaoEByb_Y2tk--J-xtV35P6OnAiyaihbrjwlQQ/viewform", "subreddit_subscribers": 970884, "created_utc": 1690920725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, just wanted to share my new open-source project: It's basically ChatGPT Code Interpreter, but the Python interpreter runs locally on your machine, so you can use it for sensitive data: https://github.com/silvanmelchior/IncognitoPilot", "author_fullname": "t2_hdzqi2fb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local Python ChatGPT Code Interpreter for Data Analysis, etc.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 33, "top_awarded_type": null, "hide_score": false, "name": "t3_15fcids", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AlkniZDekm7t1rjqTmw6yF4r8dK06VO2tjif1-rFPFs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690896195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, just wanted to share my new open-source project: It&amp;#39;s basically ChatGPT Code Interpreter, but the Python interpreter runs locally on your machine, so you can use it for sensitive data: &lt;a href=\"https://github.com/silvanmelchior/IncognitoPilot\"&gt;https://github.com/silvanmelchior/IncognitoPilot&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/gezxsavi2ifb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/gezxsavi2ifb1.png?auto=webp&amp;s=e21f2f573a58c92d7e64d1f30a169494e240e6ea", "width": 2651, "height": 641}, "resolutions": [{"url": "https://preview.redd.it/gezxsavi2ifb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2af7bfd64e4d6818bc57f3658d42cc155dd4b80", "width": 108, "height": 26}, {"url": "https://preview.redd.it/gezxsavi2ifb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f57b807fe02139bd4f73f7383dd358bfdad17c6c", "width": 216, "height": 52}, {"url": "https://preview.redd.it/gezxsavi2ifb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb713a10adb496c2c8be251865cecb0d5c8ecd21", "width": 320, "height": 77}, {"url": "https://preview.redd.it/gezxsavi2ifb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=17562468f2737698721b035197011296ac3f3928", "width": 640, "height": 154}, {"url": "https://preview.redd.it/gezxsavi2ifb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5e1aa29395084082cc4a12c8e720b19592218e40", "width": 960, "height": 232}, {"url": "https://preview.redd.it/gezxsavi2ifb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6bc11918e9c105a12f90bffb67b0dfc4faae0ae7", "width": 1080, "height": 261}], "variants": {}, "id": "HZyZb_r-UNerNXSwa0H8OGCJNYNf2s1cMbg1MKqdsqI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fcids", "is_robot_indexable": true, "report_reasons": null, "author": "silvanmelchior", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fcids/local_python_chatgpt_code_interpreter_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/gezxsavi2ifb1.png", "subreddit_subscribers": 970884, "created_utc": 1690896195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "i will be starting a PhD in the fall after a few years of working in the industry. it seems unlikely that i\u2019ll get a chance to work with production quality code or cloud services (i\u2019ve been using Azure) as part of the PhD, and it\u2019ll be a huge loss for me to become out of practice with this skill set. has anyone heard of PhDs who do little jobs on the side to stay relevant? i was thinking of maybe contributing to open-source repositories, or taking on some debugging tasks in a part-time gig, but curious if folks have found some more imaginative ways to keep their skills up-to-date.", "author_fullname": "t2_l8vm8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "keeping coding and Azure skills while doing PhD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15fpinb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690925536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i will be starting a PhD in the fall after a few years of working in the industry. it seems unlikely that i\u2019ll get a chance to work with production quality code or cloud services (i\u2019ve been using Azure) as part of the PhD, and it\u2019ll be a huge loss for me to become out of practice with this skill set. has anyone heard of PhDs who do little jobs on the side to stay relevant? i was thinking of maybe contributing to open-source repositories, or taking on some debugging tasks in a part-time gig, but curious if folks have found some more imaginative ways to keep their skills up-to-date.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fpinb", "is_robot_indexable": true, "report_reasons": null, "author": "phenomenonical", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fpinb/keeping_coding_and_azure_skills_while_doing_phd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fpinb/keeping_coding_and_azure_skills_while_doing_phd/", "subreddit_subscribers": 970884, "created_utc": 1690925536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "https://preview.redd.it/eqg0eowd1kfb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=b77b3e29da55e4712cfa0e7fbc910c0ae25fc0ee\n\nAs a Data Scientist, mastering database management is crucial for efficient data analysis and decision-making. MongoDB, a popular NoSQL database, offers great flexibility and scalability, making it a top choice for handling large and complex datasets. Over the past two years, MongoDB has been an integral part of my professional toolkit, and I've gathered valuable tips and tricks that can elevate your MongoDB experience as a Data Scientist.\n\n## 1. Create a Useful CRUD Wrapper\n\nWorking with MongoDB often involves performing CRUD operations (Create, Read, Update, Delete) on documents. To streamline your database interactions, consider creating a reusable CRUD wrapper. This abstraction layer encapsulates common database tasks and provides a cleaner and more maintainable way to interact with MongoDB.\n\n    import pymongo\n    \n    def get_mongo_client():\n        return pymongo.MongoClient(mongo_connection_string)\n    \n    # Create operation\n    def create_document(collection, document_data):\n        with get_mongo_client() as client:\n            db = client[database_name]\n            col = db[collection]\n            result = col.insert_one(document_data)\n            return result.inserted_id\n    \n    # Read operation by document name\n    def get_document_by_name(collection, record_name):\n        with get_mongo_client() as client:\n            db = client[database_name]\n            col = db[collection]\n            document = col.find_one({\"name\": record_name})\n            return document\n    \n    # Update operation by document name\n    def update_document_by_name(collection, record_name, updated_data):\n        with get_mongo_client() as client:\n            db = client[database_name]\n            col = db[collection]\n            result = col.update_one({\"name\": record_name}, {\"$set\": updated_data})\n            return result.modified_count\n    \n    # Delete operation\n    def delete_document(collection, name):\n        with get_mongo_client() as client:\n            db = client[database_name]\n            col = db[collection]\n            result = col.delete_one({\"name\": name})\n            return result.deleted_count\n\n## 2. Master Aggregation Pipelines\n\nMongoDB's Aggregation Pipeline is a powerful tool for data transformation, aggregation, and analytics. It allows you to perform complex operations on large datasets efficiently. Let's say we have a collection of sales data and want to calculate the total sales for each product category and sorting in descending order:\n\n    pipeline = [\n        { \"$group\": { \"_id\": \"$category\", \"total_sales\": { \"$sum\": \"$amount\" } } },\n    \t\t{ \"$sort\": { \"total_sales\": -1 } }\n    ]\n    \n    result = list(collection.aggregate(pipeline))\n\n## 3. Check for Duplicates Before Updating/Inserting\n\nTo maintain data integrity, it's crucial to prevent duplicate records in your database. Before performing updates or inserts, check if the data already exists to avoid redundancy:\n\n    def update_or_insert_document(collection, data):\n        existing_record = collection.find_one({\"_id\": data[\"_id\"]})\n        \n        if existing_record:\n            collection.update_one({\"_id\": data[\"_id\"]}, {\"$set\": data})\n        else:\n            collection.insert_one(data)\n\n## 4. Utilize Indexes\n\nIndexes play a vital role in optimizing query performance. Identify frequently queried fields and create indexes to speed up data retrieval:\n\n    collection.create_index(\"name\")\n    collection.create_index(\"category\")\n\n## 5. Use Projections Wisely\n\nWhen fetching data from the database, use projections to retrieve only the necessary fields, reducing network overhead and improving query performance:\n\n    projection = {\"_id\": 0, \"name\": 1, \"price\": 1}\n    result = list(collection.find({}, projection)) \n\n## 6. Create Document-Specific Unique Identifiers\n\nWhile MongoDB automatically generates a unique **\\_id** for each document, consider using document-specific unique identifiers for certain entities like for stock market data, we can have unique record as the *stock symbol*. This can enhance query efficiency and ensure data uniqueness:\n\n## 7. Implement Caching Systems\n\nFrequent database queries can impact application performance. Implement caching mechanisms to store frequently accessed data and reduce query load:\n\n    import cachetools\n    \n    @cachetools.cached(cache=cachetools.TTLCache(maxsize=100, ttl=300))\n    def get_stock_data(symbol):\n        # Fetch stock data from MongoDB\n        return collection.find_one({\"symbol\": symbol})\n\n## 8. Maintain Data Integrity\n\nData integrity checks should include validating data types to ensure seamless interactions with MongoDB. MongoDB has specific data type requirements, and it's essential to preprocess the data before insertion to handle data types that MongoDB may not support directly.\n\nFor example, as you mentioned, MongoDB doesn't support **numpy.int64** data type. When encountering such data types, it's advisable to convert them to native Python types like **int** or **float** before inserting into the database.\n\n    def insert_document(data):\n        # Check data types and convert if necessary\n        for key, value in data.items():\n            if isinstance(value, np.int64):\n                data[key] = int(value)\n            elif isinstance(value, np.float64):\n                data[key] = float(value)\n    \t\tcollection.insert_one(data) \n\n## 9. Avoid Unnecessary Operations and Create a Master Dataframe\n\nMinimizing unnecessary database queries is crucial for optimizing the performance of your data science applications. If your code requires data from the same database multiple times, consider querying the database once and creating a master dataframe to serve as a central data source.\n\n## 10. Implement Rate Limiting\n\nTo prevent abuse and maintain resource fairness, apply rate limiting to API endpoints interacting with MongoDB:\n\n    from flask_limiter import Limiter\n    \n    limiter = Limiter(app)\n    \n    @app.route(\"/get_data\")\n    @limiter.limit(\"10 per minute\")\n    def get_data():\n        # Query MongoDB and return data\n        pass\n\nBy adopting these tips and tricks, you can harness the full potential of MongoDB for your data science projects. Understanding these best practices will not only make your code more efficient but also empower you to extract valuable insights from vast datasets. Embrace the continuous learning journey and explore the endless possibilities that MongoDB offers for your data-driven success!\n\nHappy coding and database exploration!", "author_fullname": "t2_hcskz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing MongoDB Usage in Data Science: Tips &amp; Tricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"eqg0eowd1kfb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=058b6882e26d10a3ee7622cd50c2e1a510367159"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9dae904963fb8b58eae7042fdf09582690bc59a1"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=baff6f31f66a14c3d0bd72746bd197e186d1dab7"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9da82d8866c5e2963cbd8377161e993860a01b2d"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=20af0df5e8e75fb7c1c7159bbdaebdf82ab03f8c"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8ae728512d4846e0481c2ba253273191aa9bbd69"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=b77b3e29da55e4712cfa0e7fbc910c0ae25fc0ee"}, "id": "eqg0eowd1kfb1"}}, "name": "t3_15fmzzo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3bcFxtM9EYq_XeP1nW42tJl2msQc5DB5q61tFi_tGKs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690919892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/eqg0eowd1kfb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b77b3e29da55e4712cfa0e7fbc910c0ae25fc0ee\"&gt;https://preview.redd.it/eqg0eowd1kfb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b77b3e29da55e4712cfa0e7fbc910c0ae25fc0ee&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As a Data Scientist, mastering database management is crucial for efficient data analysis and decision-making. MongoDB, a popular NoSQL database, offers great flexibility and scalability, making it a top choice for handling large and complex datasets. Over the past two years, MongoDB has been an integral part of my professional toolkit, and I&amp;#39;ve gathered valuable tips and tricks that can elevate your MongoDB experience as a Data Scientist.&lt;/p&gt;\n\n&lt;h2&gt;1. Create a Useful CRUD Wrapper&lt;/h2&gt;\n\n&lt;p&gt;Working with MongoDB often involves performing CRUD operations (Create, Read, Update, Delete) on documents. To streamline your database interactions, consider creating a reusable CRUD wrapper. This abstraction layer encapsulates common database tasks and provides a cleaner and more maintainable way to interact with MongoDB.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pymongo\n\ndef get_mongo_client():\n    return pymongo.MongoClient(mongo_connection_string)\n\n# Create operation\ndef create_document(collection, document_data):\n    with get_mongo_client() as client:\n        db = client[database_name]\n        col = db[collection]\n        result = col.insert_one(document_data)\n        return result.inserted_id\n\n# Read operation by document name\ndef get_document_by_name(collection, record_name):\n    with get_mongo_client() as client:\n        db = client[database_name]\n        col = db[collection]\n        document = col.find_one({&amp;quot;name&amp;quot;: record_name})\n        return document\n\n# Update operation by document name\ndef update_document_by_name(collection, record_name, updated_data):\n    with get_mongo_client() as client:\n        db = client[database_name]\n        col = db[collection]\n        result = col.update_one({&amp;quot;name&amp;quot;: record_name}, {&amp;quot;$set&amp;quot;: updated_data})\n        return result.modified_count\n\n# Delete operation\ndef delete_document(collection, name):\n    with get_mongo_client() as client:\n        db = client[database_name]\n        col = db[collection]\n        result = col.delete_one({&amp;quot;name&amp;quot;: name})\n        return result.deleted_count\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;2. Master Aggregation Pipelines&lt;/h2&gt;\n\n&lt;p&gt;MongoDB&amp;#39;s Aggregation Pipeline is a powerful tool for data transformation, aggregation, and analytics. It allows you to perform complex operations on large datasets efficiently. Let&amp;#39;s say we have a collection of sales data and want to calculate the total sales for each product category and sorting in descending order:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pipeline = [\n    { &amp;quot;$group&amp;quot;: { &amp;quot;_id&amp;quot;: &amp;quot;$category&amp;quot;, &amp;quot;total_sales&amp;quot;: { &amp;quot;$sum&amp;quot;: &amp;quot;$amount&amp;quot; } } },\n        { &amp;quot;$sort&amp;quot;: { &amp;quot;total_sales&amp;quot;: -1 } }\n]\n\nresult = list(collection.aggregate(pipeline))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;3. Check for Duplicates Before Updating/Inserting&lt;/h2&gt;\n\n&lt;p&gt;To maintain data integrity, it&amp;#39;s crucial to prevent duplicate records in your database. Before performing updates or inserts, check if the data already exists to avoid redundancy:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def update_or_insert_document(collection, data):\n    existing_record = collection.find_one({&amp;quot;_id&amp;quot;: data[&amp;quot;_id&amp;quot;]})\n\n    if existing_record:\n        collection.update_one({&amp;quot;_id&amp;quot;: data[&amp;quot;_id&amp;quot;]}, {&amp;quot;$set&amp;quot;: data})\n    else:\n        collection.insert_one(data)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;4. Utilize Indexes&lt;/h2&gt;\n\n&lt;p&gt;Indexes play a vital role in optimizing query performance. Identify frequently queried fields and create indexes to speed up data retrieval:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;collection.create_index(&amp;quot;name&amp;quot;)\ncollection.create_index(&amp;quot;category&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;5. Use Projections Wisely&lt;/h2&gt;\n\n&lt;p&gt;When fetching data from the database, use projections to retrieve only the necessary fields, reducing network overhead and improving query performance:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;projection = {&amp;quot;_id&amp;quot;: 0, &amp;quot;name&amp;quot;: 1, &amp;quot;price&amp;quot;: 1}\nresult = list(collection.find({}, projection)) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;6. Create Document-Specific Unique Identifiers&lt;/h2&gt;\n\n&lt;p&gt;While MongoDB automatically generates a unique &lt;strong&gt;_id&lt;/strong&gt; for each document, consider using document-specific unique identifiers for certain entities like for stock market data, we can have unique record as the &lt;em&gt;stock symbol&lt;/em&gt;. This can enhance query efficiency and ensure data uniqueness:&lt;/p&gt;\n\n&lt;h2&gt;7. Implement Caching Systems&lt;/h2&gt;\n\n&lt;p&gt;Frequent database queries can impact application performance. Implement caching mechanisms to store frequently accessed data and reduce query load:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import cachetools\n\n@cachetools.cached(cache=cachetools.TTLCache(maxsize=100, ttl=300))\ndef get_stock_data(symbol):\n    # Fetch stock data from MongoDB\n    return collection.find_one({&amp;quot;symbol&amp;quot;: symbol})\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;8. Maintain Data Integrity&lt;/h2&gt;\n\n&lt;p&gt;Data integrity checks should include validating data types to ensure seamless interactions with MongoDB. MongoDB has specific data type requirements, and it&amp;#39;s essential to preprocess the data before insertion to handle data types that MongoDB may not support directly.&lt;/p&gt;\n\n&lt;p&gt;For example, as you mentioned, MongoDB doesn&amp;#39;t support &lt;strong&gt;numpy.int64&lt;/strong&gt; data type. When encountering such data types, it&amp;#39;s advisable to convert them to native Python types like &lt;strong&gt;int&lt;/strong&gt; or &lt;strong&gt;float&lt;/strong&gt; before inserting into the database.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def insert_document(data):\n    # Check data types and convert if necessary\n    for key, value in data.items():\n        if isinstance(value, np.int64):\n            data[key] = int(value)\n        elif isinstance(value, np.float64):\n            data[key] = float(value)\n        collection.insert_one(data) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;9. Avoid Unnecessary Operations and Create a Master Dataframe&lt;/h2&gt;\n\n&lt;p&gt;Minimizing unnecessary database queries is crucial for optimizing the performance of your data science applications. If your code requires data from the same database multiple times, consider querying the database once and creating a master dataframe to serve as a central data source.&lt;/p&gt;\n\n&lt;h2&gt;10. Implement Rate Limiting&lt;/h2&gt;\n\n&lt;p&gt;To prevent abuse and maintain resource fairness, apply rate limiting to API endpoints interacting with MongoDB:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from flask_limiter import Limiter\n\nlimiter = Limiter(app)\n\n@app.route(&amp;quot;/get_data&amp;quot;)\n@limiter.limit(&amp;quot;10 per minute&amp;quot;)\ndef get_data():\n    # Query MongoDB and return data\n    pass\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;By adopting these tips and tricks, you can harness the full potential of MongoDB for your data science projects. Understanding these best practices will not only make your code more efficient but also empower you to extract valuable insights from vast datasets. Embrace the continuous learning journey and explore the endless possibilities that MongoDB offers for your data-driven success!&lt;/p&gt;\n\n&lt;p&gt;Happy coding and database exploration!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fmzzo", "is_robot_indexable": true, "report_reasons": null, "author": "vishank97", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fmzzo/optimizing_mongodb_usage_in_data_science_tips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fmzzo/optimizing_mongodb_usage_in_data_science_tips/", "subreddit_subscribers": 970884, "created_utc": 1690919892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I\u2019ve been working as a credit analyst for almost two years now and I think I want to transition into Data Science. I\u2019ve bad an interest in Python and excel Macros before I came to this realization, but I admit both my coding and mathematical skills are sub-par.  My employer will pay for an online Master degree in this field and I want to take advantage of this opportunity. \n\nSo my main question is, where should I start in preparation of returning to school in a field I have little to no prior background in? Should I focus on learning Python, or statistics, or Algebra? Where to begin, and how should I go about it?\n\nMy current plan is to go through the Python Crash Course book to develop a good foundation in coding ahead of the classes. Is this a solid plan? Should I focus in some other areas as well?\n\nI appreciate any  and all advice.", "author_fullname": "t2_8uff7jlg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need Advice on where to start in pursuit of a Master in Data Science (Finance/Credit background)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fmlb9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690918959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019ve been working as a credit analyst for almost two years now and I think I want to transition into Data Science. I\u2019ve bad an interest in Python and excel Macros before I came to this realization, but I admit both my coding and mathematical skills are sub-par.  My employer will pay for an online Master degree in this field and I want to take advantage of this opportunity. &lt;/p&gt;\n\n&lt;p&gt;So my main question is, where should I start in preparation of returning to school in a field I have little to no prior background in? Should I focus on learning Python, or statistics, or Algebra? Where to begin, and how should I go about it?&lt;/p&gt;\n\n&lt;p&gt;My current plan is to go through the Python Crash Course book to develop a good foundation in coding ahead of the classes. Is this a solid plan? Should I focus in some other areas as well?&lt;/p&gt;\n\n&lt;p&gt;I appreciate any  and all advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fmlb9", "is_robot_indexable": true, "report_reasons": null, "author": "Professional_East281", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fmlb9/i_need_advice_on_where_to_start_in_pursuit_of_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fmlb9/i_need_advice_on_where_to_start_in_pursuit_of_a/", "subreddit_subscribers": 970884, "created_utc": 1690918959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Greetings to my favorite subreddit!  Fellow data enthusiast here, and I am hoping to get your advice on long term career goals at my employer.\n\n**My background**\n\nMy career started in accounting. Then pivoted to a variety of supply chain roles as an analyst. My roots are entrenched in Microsoft Products. Started as an excel monkey, then SQL neanderthal, followed up by Power BI human. Self-taught through most of it and as smart as stackoverflow allows me to be. Pursuing a MS in Data Science to get more grounded STEM knowledge and better combine with my domain knowledge.\n\n**Courseload thus far and outlook**\n\n\\-Bachelors in Accounting\n\n\\-Udemy courses on Power BI, SQL, DAX, etc\n\n\\-Dataquest modules for Python\n\n\\-Pursuing MS in Data Science at Eastern University\n\n**My employer**\n\nLeading manufacturing of durable juvenile good in the US(strollers, car seats, high chairs, etc.). While we are technically an international company, we are very siloed and operate as a small-medium sized business. I am a data science team of 1. No real IT team in the US besides a 3rd party service that helps with day to day tasks. I am the data wrangler, cleaner and presenter from start to finish. I am the Power BI admin/developer and analyst for our business unit. Launched the reporting suite when I started with the organization 4 years ago. Before that launch, everyone was excel jockeying very disparate data sources often looking at the same number in multiple places.\n\n**Infrastructure(image showing flow in the post)**\n\nLimited to Microsoft 365 solutions.  I do have a lot of leeway when it comes to implementing new software. I just need to present the options to management outlining the cost/benefit analysis. Since I am a team of 1, It can\u2019t be an infrastructure that requires multiple touch points. Emphasis on automation.\n\n**The goal from my perspective**\n\nI have gotten about as far as I can with low code solutions. Power BI is both our ETL and data storage solution which works for small datasets but will not scale well when data starts growing.\n\n**Wants:**\n\n\\-ETL Process that is separate from Power BI. Needs to be easy to alter when data delivery methods change\n\n\\-Data storage solution that is scalable for growth and easy to access for a remote friendly company.\n\n\\-Foundation for more advanced data science practices(machine learning, neural networks, subject matter covered in later coursework.\n\n**As an aside**, sometimes I receive advice to just change jobs to a more data driven organization. Not an option that I am willing to pursue. On a personal level, this is exactly the type of employer you want to have while raising a family.  I am compensated very well and the benefits to my family and well above average.  My wife and I are expected our 2nd child this year and I will have the luxury of having 12 week paid paternity.", "author_fullname": "t2_61qgxfir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analyst leading Company out of the Dark Ages", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fm3dr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690917834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings to my favorite subreddit!  Fellow data enthusiast here, and I am hoping to get your advice on long term career goals at my employer.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My background&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;My career started in accounting. Then pivoted to a variety of supply chain roles as an analyst. My roots are entrenched in Microsoft Products. Started as an excel monkey, then SQL neanderthal, followed up by Power BI human. Self-taught through most of it and as smart as stackoverflow allows me to be. Pursuing a MS in Data Science to get more grounded STEM knowledge and better combine with my domain knowledge.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Courseload thus far and outlook&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;-Bachelors in Accounting&lt;/p&gt;\n\n&lt;p&gt;-Udemy courses on Power BI, SQL, DAX, etc&lt;/p&gt;\n\n&lt;p&gt;-Dataquest modules for Python&lt;/p&gt;\n\n&lt;p&gt;-Pursuing MS in Data Science at Eastern University&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My employer&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Leading manufacturing of durable juvenile good in the US(strollers, car seats, high chairs, etc.). While we are technically an international company, we are very siloed and operate as a small-medium sized business. I am a data science team of 1. No real IT team in the US besides a 3rd party service that helps with day to day tasks. I am the data wrangler, cleaner and presenter from start to finish. I am the Power BI admin/developer and analyst for our business unit. Launched the reporting suite when I started with the organization 4 years ago. Before that launch, everyone was excel jockeying very disparate data sources often looking at the same number in multiple places.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Infrastructure(image showing flow in the post)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Limited to Microsoft 365 solutions.  I do have a lot of leeway when it comes to implementing new software. I just need to present the options to management outlining the cost/benefit analysis. Since I am a team of 1, It can\u2019t be an infrastructure that requires multiple touch points. Emphasis on automation.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The goal from my perspective&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have gotten about as far as I can with low code solutions. Power BI is both our ETL and data storage solution which works for small datasets but will not scale well when data starts growing.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Wants:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;-ETL Process that is separate from Power BI. Needs to be easy to alter when data delivery methods change&lt;/p&gt;\n\n&lt;p&gt;-Data storage solution that is scalable for growth and easy to access for a remote friendly company.&lt;/p&gt;\n\n&lt;p&gt;-Foundation for more advanced data science practices(machine learning, neural networks, subject matter covered in later coursework.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;As an aside&lt;/strong&gt;, sometimes I receive advice to just change jobs to a more data driven organization. Not an option that I am willing to pursue. On a personal level, this is exactly the type of employer you want to have while raising a family.  I am compensated very well and the benefits to my family and well above average.  My wife and I are expected our 2nd child this year and I will have the luxury of having 12 week paid paternity.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fm3dr", "is_robot_indexable": true, "report_reasons": null, "author": "Significant-Analyst9", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fm3dr/data_analyst_leading_company_out_of_the_dark_ages/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fm3dr/data_analyst_leading_company_out_of_the_dark_ages/", "subreddit_subscribers": 970884, "created_utc": 1690917834.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI recently made a career switch into Data Analytics (I've been in my current role for 6 months) and originally my long term plan was to end up doing Data Science. I was looking for opportunities to go back to school and get a Masters in Data Science so I could pursue this path.\n\nBut I've started to worry about whether this is a good long term bet and if I shouldn't rethink this. I'm still pretty young and I can go back to school for something different or adjust my career path at this point (even though I wouldn't like to do this after having done it so soon). I debated maybe going back for an engineering degree (my bachelors is in Physics so I might be able to get into a masters program) or just finding an opportunity where I can work in engineering.\n\nMy main concern is that I hear a lot of noise about AI possibly shrinking the amount of data scientists that are needed going forward. Additionally, I've seen a lot of posts in this sub that have indicated that it's harder to get a job right now in the field. All of this has me concerned that this may not be a viable long term career path and I'll wind up with a decade into my career with skills that aren't particularly relevant.\n\nWhat are your thoughts on this? I understand there's a lot of inflammatory media out there so my fears might be a bit inflated but some of the posts I've seen in this sub have had me concerned that this might be a real trend. Is all of this just hype or is there a real concern for data scientists going forward.\n\nThanks in advance!", "author_fullname": "t2_3qrggum4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Data Science a viable career path going forward", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fllk8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690916711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I recently made a career switch into Data Analytics (I&amp;#39;ve been in my current role for 6 months) and originally my long term plan was to end up doing Data Science. I was looking for opportunities to go back to school and get a Masters in Data Science so I could pursue this path.&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;ve started to worry about whether this is a good long term bet and if I shouldn&amp;#39;t rethink this. I&amp;#39;m still pretty young and I can go back to school for something different or adjust my career path at this point (even though I wouldn&amp;#39;t like to do this after having done it so soon). I debated maybe going back for an engineering degree (my bachelors is in Physics so I might be able to get into a masters program) or just finding an opportunity where I can work in engineering.&lt;/p&gt;\n\n&lt;p&gt;My main concern is that I hear a lot of noise about AI possibly shrinking the amount of data scientists that are needed going forward. Additionally, I&amp;#39;ve seen a lot of posts in this sub that have indicated that it&amp;#39;s harder to get a job right now in the field. All of this has me concerned that this may not be a viable long term career path and I&amp;#39;ll wind up with a decade into my career with skills that aren&amp;#39;t particularly relevant.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on this? I understand there&amp;#39;s a lot of inflammatory media out there so my fears might be a bit inflated but some of the posts I&amp;#39;ve seen in this sub have had me concerned that this might be a real trend. Is all of this just hype or is there a real concern for data scientists going forward.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fllk8", "is_robot_indexable": true, "report_reasons": null, "author": "lankmachine", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fllk8/is_data_science_a_viable_career_path_going_forward/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fllk8/is_data_science_a_viable_career_path_going_forward/", "subreddit_subscribers": 970884, "created_utc": 1690916711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all - for part of my next newsletter post I'm working on a rough / high level visual to help people in the data field understand the paths open to them and in some cases to help understand which path they're currently on.\n\nThoughts on the early draft below? Is it too high level?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/uhln4549rjfb1.png?width=1406&amp;format=png&amp;auto=webp&amp;s=0351a7d9932a83fa2f61ec34a96d6c22adac70bd\n\nNewsletter: [https://forefrontofdata.substack.com/](https://forefrontofdata.substack.com/)\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_i7c9bj9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career paths in data analytics / science / engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"uhln4549rjfb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 117, "x": 108, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4d2c11a18bfd3d906539087455930a0772daa158"}, {"y": 235, "x": 216, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=91272d8cc1809d9b0231e02fda88ec97cddbc241"}, {"y": 348, "x": 320, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2e47e286ef844023dc5a2b4d669cf073e9e2b90a"}, {"y": 697, "x": 640, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9507d86cf45e3baf8998fbf2acd12426d1a0fcaa"}, {"y": 1046, "x": 960, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fcac84e253035a06d26a795ad1be9c612c644b77"}, {"y": 1176, "x": 1080, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1d4f2e0631da9f1065e8bc0fe51535861c40228f"}], "s": {"y": 1532, "x": 1406, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=1406&amp;format=png&amp;auto=webp&amp;s=0351a7d9932a83fa2f61ec34a96d6c22adac70bd"}, "id": "uhln4549rjfb1"}}, "name": "t3_15flkk0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/-pVDWn9-3bPMag8_jncpgPNYsy_5j1MOUFljuqYfIr8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690916650.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all - for part of my next newsletter post I&amp;#39;m working on a rough / high level visual to help people in the data field understand the paths open to them and in some cases to help understand which path they&amp;#39;re currently on.&lt;/p&gt;\n\n&lt;p&gt;Thoughts on the early draft below? Is it too high level?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/uhln4549rjfb1.png?width=1406&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0351a7d9932a83fa2f61ec34a96d6c22adac70bd\"&gt;https://preview.redd.it/uhln4549rjfb1.png?width=1406&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0351a7d9932a83fa2f61ec34a96d6c22adac70bd&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Newsletter: &lt;a href=\"https://forefrontofdata.substack.com/\"&gt;https://forefrontofdata.substack.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15flkk0", "is_robot_indexable": true, "report_reasons": null, "author": "DataAnalystNewslettr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15flkk0/career_paths_in_data_analytics_science_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15flkk0/career_paths_in_data_analytics_science_engineering/", "subreddit_subscribers": 970884, "created_utc": 1690916650.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi reddit community,\n\nI am working on developing a process where we are creating a working model for econometrics combining OLS modeling with Bayesian. The idea is to use OLS to build a strong base model and then transfer this model into Bayesian where we feed our beliefs about a subset of variables such as media. We use this to calibrate these variables based on previous model updates and maintain continuity in our results. The reason why we aren't just extending the historical models is because of issues related to data quality over time and some additional changes to our KPIs. Everyone in my team is very much on board with this idea as it has the potential to save a lot of precious time, however, I am curious to hear an objective opinion in order to be better able to weigh in on the postives/negatives of this approach. Any thoughts? :)", "author_fullname": "t2_3p8oqkl3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using OLS &amp; Bayesian regression on an econometrics project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fg5og", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690904552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi reddit community,&lt;/p&gt;\n\n&lt;p&gt;I am working on developing a process where we are creating a working model for econometrics combining OLS modeling with Bayesian. The idea is to use OLS to build a strong base model and then transfer this model into Bayesian where we feed our beliefs about a subset of variables such as media. We use this to calibrate these variables based on previous model updates and maintain continuity in our results. The reason why we aren&amp;#39;t just extending the historical models is because of issues related to data quality over time and some additional changes to our KPIs. Everyone in my team is very much on board with this idea as it has the potential to save a lot of precious time, however, I am curious to hear an objective opinion in order to be better able to weigh in on the postives/negatives of this approach. Any thoughts? :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fg5og", "is_robot_indexable": true, "report_reasons": null, "author": "necplorer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fg5og/using_ols_bayesian_regression_on_an_econometrics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fg5og/using_ols_bayesian_regression_on_an_econometrics/", "subreddit_subscribers": 970884, "created_utc": 1690904552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI'm a data analyst intern for a forestry company and am seeking guidance on the best way to impute missing and erroneous values in a dataset. \n\n&amp;#x200B;\n\nWhere should I look to ask that?", "author_fullname": "t2_ha1sulci", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where should I post my data analysis question?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15feeep", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690900592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data analyst intern for a forestry company and am seeking guidance on the best way to impute missing and erroneous values in a dataset. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Where should I look to ask that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15feeep", "is_robot_indexable": true, "report_reasons": null, "author": "Conscious-Analyst662", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15feeep/where_should_i_post_my_data_analysis_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15feeep/where_should_i_post_my_data_analysis_question/", "subreddit_subscribers": 970884, "created_utc": 1690900592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I wasn\u2019t sure where I should post this one. \n\nI\u2019ve written a few scripts in the last week or two that are designed to collect a LOT of data. In fact, I\u2019m rotating API keys every 30 minutes or so with my latest - and final - data collection effort. I\u2019ve written the script to automatically rotate across 6 keys for this particular API.\n\nMy average API calls per day has been right around 210,000 over the last three days.\n\nHowever, the last 24 hours it\u2019s dropped to 200 calls a day. I\u2019m not sure why. I\u2019ve swapped VPN connections; API keys - all of them - and I\u2019m still not seeing any real change.\n\nI\u2019m not violating the ToS. I\u2019m only collecting open source data and the API is designed to handle what I\u2019m doing. \n\nMy internet connection is really strong. 250-300mb down and 40-50mb up. I\u2019m running my MacBook using the caffeinate  command in my terminal to ensure my connection is solid and not disconnecting. \n\nI am writing this data to an external HD over USB/C.. which should be my only limitation realistically\u2026 but it\u2019s not even 5% at capacity. This isn\u2019t the issue. \n\nDoes anyone have any ideas here? My VPN is Nord and a paid account I\u2019ve used successfully for years.\n\nThis is massively slowing development down; I need a solution and fast. Thoughts?", "author_fullname": "t2_ufzvkub2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ISP Throttling?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fde64", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690898290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wasn\u2019t sure where I should post this one. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve written a few scripts in the last week or two that are designed to collect a LOT of data. In fact, I\u2019m rotating API keys every 30 minutes or so with my latest - and final - data collection effort. I\u2019ve written the script to automatically rotate across 6 keys for this particular API.&lt;/p&gt;\n\n&lt;p&gt;My average API calls per day has been right around 210,000 over the last three days.&lt;/p&gt;\n\n&lt;p&gt;However, the last 24 hours it\u2019s dropped to 200 calls a day. I\u2019m not sure why. I\u2019ve swapped VPN connections; API keys - all of them - and I\u2019m still not seeing any real change.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not violating the ToS. I\u2019m only collecting open source data and the API is designed to handle what I\u2019m doing. &lt;/p&gt;\n\n&lt;p&gt;My internet connection is really strong. 250-300mb down and 40-50mb up. I\u2019m running my MacBook using the caffeinate  command in my terminal to ensure my connection is solid and not disconnecting. &lt;/p&gt;\n\n&lt;p&gt;I am writing this data to an external HD over USB/C.. which should be my only limitation realistically\u2026 but it\u2019s not even 5% at capacity. This isn\u2019t the issue. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any ideas here? My VPN is Nord and a paid account I\u2019ve used successfully for years.&lt;/p&gt;\n\n&lt;p&gt;This is massively slowing development down; I need a solution and fast. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fde64", "is_robot_indexable": true, "report_reasons": null, "author": "LoadingALIAS", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fde64/isp_throttling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fde64/isp_throttling/", "subreddit_subscribers": 970884, "created_utc": 1690898290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My company (Deepnote) has done some early explorations and it feels to us like there could be something valuable to this idea of writing a high level prompt and having an AI assistant execute a task in a Jupyter-compatible notebook with no supervision. In principle the assistant could do anything a human collaborator is physically able to do in a Deepnote notebook, including connecting to external DBs via integrations, running SQL queries on those DBs, writing Python code, and describing what it\u2019s doing with text blocks.\n\nThe way this works now is you enter some initial prompt, and let the AI assistant work in a loop where it asks to execute some code or run a query, and then it automatically gets prompted again with the result of those. It continues in a loop until it thinks it\u2019s done or until you manually stop it.\n\nTo illustrate what this would be like, one of our engineers took a screen recording demoing our work in progress, which you can find in this blog post: [https://deepnote.com/blog/a-new-era-for-data-work-introducing-autonomous-deepnote-ai](https://deepnote.com/blog/a-new-era-for-data-work-introducing-autonomous-deepnote-ai).\n\nIt seems to be doing okay at basic tasks, and we expect it to get better at more complex tasks when the models improve. But given the quality of today\u2019s output, do you see yourself using it in this way? Would you like more control? Or, alternatively, could this be more of a self-serve feature for less-skilled team members?", "author_fullname": "t2_azlg7yfq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Autonomous agent in a notebook \u2014 what would be the most meaningful improvement to your workflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fd163", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690897457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company (Deepnote) has done some early explorations and it feels to us like there could be something valuable to this idea of writing a high level prompt and having an AI assistant execute a task in a Jupyter-compatible notebook with no supervision. In principle the assistant could do anything a human collaborator is physically able to do in a Deepnote notebook, including connecting to external DBs via integrations, running SQL queries on those DBs, writing Python code, and describing what it\u2019s doing with text blocks.&lt;/p&gt;\n\n&lt;p&gt;The way this works now is you enter some initial prompt, and let the AI assistant work in a loop where it asks to execute some code or run a query, and then it automatically gets prompted again with the result of those. It continues in a loop until it thinks it\u2019s done or until you manually stop it.&lt;/p&gt;\n\n&lt;p&gt;To illustrate what this would be like, one of our engineers took a screen recording demoing our work in progress, which you can find in this blog post: &lt;a href=\"https://deepnote.com/blog/a-new-era-for-data-work-introducing-autonomous-deepnote-ai\"&gt;https://deepnote.com/blog/a-new-era-for-data-work-introducing-autonomous-deepnote-ai&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It seems to be doing okay at basic tasks, and we expect it to get better at more complex tasks when the models improve. But given the quality of today\u2019s output, do you see yourself using it in this way? Would you like more control? Or, alternatively, could this be more of a self-serve feature for less-skilled team members?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fUg9lH18Av2t0_gWet9UKi1u1XkORndGCzNr5SSmnQA.jpg?auto=webp&amp;s=0eb2a348e9d5e6722841fa4bed819f59ab175348", "width": 1500, "height": 844}, "resolutions": [{"url": "https://external-preview.redd.it/fUg9lH18Av2t0_gWet9UKi1u1XkORndGCzNr5SSmnQA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c35028690c47a19c23d71cf9e9f158d907df043d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/fUg9lH18Av2t0_gWet9UKi1u1XkORndGCzNr5SSmnQA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a6cad9266983b9f3f33258c4db838eafddc641c0", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/fUg9lH18Av2t0_gWet9UKi1u1XkORndGCzNr5SSmnQA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aea35fe67ae29a2e9878d2c2681f8150167a1e42", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/fUg9lH18Av2t0_gWet9UKi1u1XkORndGCzNr5SSmnQA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f3c80484e2b50d7e51d5808f48dbd855d422074", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/fUg9lH18Av2t0_gWet9UKi1u1XkORndGCzNr5SSmnQA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ef10ac193ba8c1cddc79adcffff098b9806c55d6", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/fUg9lH18Av2t0_gWet9UKi1u1XkORndGCzNr5SSmnQA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=df667ea1f52c45f0455c6ceede316f81af16e600", "width": 1080, "height": 607}], "variants": {}, "id": "0LZjzZV03XeRqASGGJ-h2ufSvmmFLUsQFyVTpOtVOKk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fd163", "is_robot_indexable": true, "report_reasons": null, "author": "dullthud", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fd163/autonomous_agent_in_a_notebook_what_would_be_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fd163/autonomous_agent_in_a_notebook_what_would_be_the/", "subreddit_subscribers": 970884, "created_utc": 1690897457.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}