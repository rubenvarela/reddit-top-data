{"kind": "Listing", "data": {"after": "t3_15f1rs9", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A few weeks ago I started a new job at a small company, and due to several people leaving, I'm about to become a data team of one. Before you tell me to leave immediately, I took the job because I'm going back to school soon and the work life balance afforded at this company should allow me to balance studying with a full time job. If it doesn't, I'll quit because school is the higher priority for me at the moment. And I was fully prepared to work part-time before I had this job offer.\n\nBut that being said, I would like to give an honest attempt at improving the state of the company's data pipelines. Currently there are a ton of pipelines all running via airflow, and the airflow site itself is consistently going down, dags will fail and have to be manually re-run, some dags seems to run in an order such that a downstream table will build prior to one it relies on, resulting in missing data in some columns.\n\nI'm coming from a very large company that builds data analytics software, so I'm used to using tools built in-house and within one cohesive ecosystem. I realize this post is fairly vague, but I suppose if you could give a pointer or two to someone entering the deep end, I'd really appreciate that!", "author_fullname": "t2_pcgwx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on improving the data architecture at a company I just joined?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15etn2w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690841198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few weeks ago I started a new job at a small company, and due to several people leaving, I&amp;#39;m about to become a data team of one. Before you tell me to leave immediately, I took the job because I&amp;#39;m going back to school soon and the work life balance afforded at this company should allow me to balance studying with a full time job. If it doesn&amp;#39;t, I&amp;#39;ll quit because school is the higher priority for me at the moment. And I was fully prepared to work part-time before I had this job offer.&lt;/p&gt;\n\n&lt;p&gt;But that being said, I would like to give an honest attempt at improving the state of the company&amp;#39;s data pipelines. Currently there are a ton of pipelines all running via airflow, and the airflow site itself is consistently going down, dags will fail and have to be manually re-run, some dags seems to run in an order such that a downstream table will build prior to one it relies on, resulting in missing data in some columns.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m coming from a very large company that builds data analytics software, so I&amp;#39;m used to using tools built in-house and within one cohesive ecosystem. I realize this post is fairly vague, but I suppose if you could give a pointer or two to someone entering the deep end, I&amp;#39;d really appreciate that!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15etn2w", "is_robot_indexable": true, "report_reasons": null, "author": "King_Spike", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15etn2w/advice_on_improving_the_data_architecture_at_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15etn2w/advice_on_improving_the_data_architecture_at_a/", "subreddit_subscribers": 119655, "created_utc": 1690841198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A simple way to estimate the memory consumption of PySpark DataFrames by programmatically accessing the optimised plan information:\n\n[https://medium.com/@miguel.otero.pedrido.1993/dataframe-memory-consumption-8687354263e2](https://medium.com/@miguel.otero.pedrido.1993/dataframe-memory-consumption-8687354263e2)\n\n&amp;#x200B;", "author_fullname": "t2_e3mh2l7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A simple way to estimate memory consumption of PySpark DataFrame", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ehmrq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690813460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A simple way to estimate the memory consumption of PySpark DataFrames by programmatically accessing the optimised plan information:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@miguel.otero.pedrido.1993/dataframe-memory-consumption-8687354263e2\"&gt;https://medium.com/@miguel.otero.pedrido.1993/dataframe-memory-consumption-8687354263e2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?auto=webp&amp;s=c79e6a26fbaf1b0ae4f9552012bab2a811a8cacd", "width": 1200, "height": 623}, "resolutions": [{"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3aad9f746dd11309eb12c9c68c1d25fe1041ddff", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c27be2fd999524ab701c860eed0cce2a89dbbf7e", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=47413ab088e7632d0eb0daf75176223cb543502f", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=075f4f5fafa170b9a94dd79c93b1ad454654486e", "width": 640, "height": 332}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4a08b2f189c2f979ff3c38d257e395f53bfad447", "width": 960, "height": 498}, {"url": "https://external-preview.redd.it/6AG8IBPvx6erebug6hJSANNC5SjRTZMUmKXodkNaIwY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5345536f98b02d41771ee1edf12cc9130d772075", "width": 1080, "height": 560}], "variants": {}, "id": "n29cfFHNk2u3vCw_xWvFUwRTEQWw47D3ymtpySy0cDE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ehmrq", "is_robot_indexable": true, "report_reasons": null, "author": "Hefty-Consequence443", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ehmrq/a_simple_way_to_estimate_memory_consumption_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ehmrq/a_simple_way_to_estimate_memory_consumption_of/", "subreddit_subscribers": 119655, "created_utc": 1690813460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9uiwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Change Data Capture Is Still an Anti-pattern. And You Still Should Use It.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15eimaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EqcO4tOozS3KMUyYVWDbtIDz-eFVSIYykV-3DgL5b2E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690815715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "streamingdata.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://streamingdata.substack.com/p/change-data-capture-is-still-an-anti", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?auto=webp&amp;s=04d6977076f8d968368d6533d4d93bcc4e03f4d3", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=febf87d18ab938c89253d5e7d0697e337bf0e88e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c37da59f1936c995870386de473bad9a4a0c1260", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a059a8e1f66d01ae2eb0b0a1b4572e8187739f1a", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/7LhovYldfFOJFe3nz2dDzZVzbFZfWDAEqADdkwaifrQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e139e12aa841bac14920bb64d92f70324e0d70d0", "width": 640, "height": 333}], "variants": {}, "id": "TL5zSeeNMw6fBGF0Ca693DL1GL7baDPqZ8ZyarYmuos"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15eimaj", "is_robot_indexable": true, "report_reasons": null, "author": "sap1enz", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15eimaj/change_data_capture_is_still_an_antipattern_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://streamingdata.substack.com/p/change-data-capture-is-still-an-anti", "subreddit_subscribers": 119655, "created_utc": 1690815715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nI\u2019m a senior data engineer with almost 7 years of experience, and now I got to the point where I was trying to look for the next step in my career and I just\u2026 couldn\u2019t see anything.\n\nSo my question is, would an architecture role be the next step? Has anyone here moved from data engineering to a data architecture or even a solutions architect role?\n\nThanks!", "author_fullname": "t2_3ng50ktz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving to an Architecture role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15elp9j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690822913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a senior data engineer with almost 7 years of experience, and now I got to the point where I was trying to look for the next step in my career and I just\u2026 couldn\u2019t see anything.&lt;/p&gt;\n\n&lt;p&gt;So my question is, would an architecture role be the next step? Has anyone here moved from data engineering to a data architecture or even a solutions architect role?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15elp9j", "is_robot_indexable": true, "report_reasons": null, "author": "BramosR", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15elp9j/moving_to_an_architecture_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15elp9j/moving_to_an_architecture_role/", "subreddit_subscribers": 119655, "created_utc": 1690822913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI'm looking for a sanity check on an experience I'm having with a team lead/jira sprint lead. He seems brilliant but I'm looking for advice on what to do with a potentially unstable jira team lead.\n\nI've been with this company 6+ months. Agile/jira/sprints. A lot of looker based tickets, and some python. I enjoy the looker, and its interesting catching up on all the docs and looking through codebase.\n\nTeam felt great on joining. I noticed our team lead seems to be very \"passionate\". The other 6 on the team are pretty calm and stable so it feels to even out. Something seemed to shift last month. \n\nI met to go over a python 5 line functional commit, and he asked me on the spot if I wanted to refactor this into something better architecturally. I was worried about finishing the ticket, but he seemed confident so I said \"if you think it's possible\". He said it was easy and we started pair programming this (my in retrospect opinion) monstrosity. \n\nWhat I'm worried about is little things I'm observing:\n* Asked me to remove a variable and implement DRY code in 6 places. Repeating the call/not storing the data. Major wtf question for me.\n* Given two tickets, one using a new field created by the previous. I asked if these were linear tickets (T1 creates a full timestamp from two elements, T2 uses T1.timestamp). I was told no with an air of \"why would you think that\".\n* Left an interdepartmental meeting abruptly during a discussion because another department was trying to explain something didn't want to hear. (I've never heard of just exiting a meeting abruptly)\n* Reprimanded for using specific markdown in ticket communication, that i found referenced in our team written docs after.\n* Every sprint is a nebulous push for higher points. Last sprint we did 50% more points than projected and there wasn't a satisfaction relayed in retro.\n\nI get along great with the other members on the team. I come from a finance/IT background, so I'm wondering for guidance on what are norms in jira style work.", "author_fullname": "t2_pkwxz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE team experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eg3n3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690809757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a sanity check on an experience I&amp;#39;m having with a team lead/jira sprint lead. He seems brilliant but I&amp;#39;m looking for advice on what to do with a potentially unstable jira team lead.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been with this company 6+ months. Agile/jira/sprints. A lot of looker based tickets, and some python. I enjoy the looker, and its interesting catching up on all the docs and looking through codebase.&lt;/p&gt;\n\n&lt;p&gt;Team felt great on joining. I noticed our team lead seems to be very &amp;quot;passionate&amp;quot;. The other 6 on the team are pretty calm and stable so it feels to even out. Something seemed to shift last month. &lt;/p&gt;\n\n&lt;p&gt;I met to go over a python 5 line functional commit, and he asked me on the spot if I wanted to refactor this into something better architecturally. I was worried about finishing the ticket, but he seemed confident so I said &amp;quot;if you think it&amp;#39;s possible&amp;quot;. He said it was easy and we started pair programming this (my in retrospect opinion) monstrosity. &lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m worried about is little things I&amp;#39;m observing:\n* Asked me to remove a variable and implement DRY code in 6 places. Repeating the call/not storing the data. Major wtf question for me.\n* Given two tickets, one using a new field created by the previous. I asked if these were linear tickets (T1 creates a full timestamp from two elements, T2 uses T1.timestamp). I was told no with an air of &amp;quot;why would you think that&amp;quot;.\n* Left an interdepartmental meeting abruptly during a discussion because another department was trying to explain something didn&amp;#39;t want to hear. (I&amp;#39;ve never heard of just exiting a meeting abruptly)\n* Reprimanded for using specific markdown in ticket communication, that i found referenced in our team written docs after.\n* Every sprint is a nebulous push for higher points. Last sprint we did 50% more points than projected and there wasn&amp;#39;t a satisfaction relayed in retro.&lt;/p&gt;\n\n&lt;p&gt;I get along great with the other members on the team. I come from a finance/IT background, so I&amp;#39;m wondering for guidance on what are norms in jira style work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15eg3n3", "is_robot_indexable": true, "report_reasons": null, "author": "iupuiclubs", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15eg3n3/de_team_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15eg3n3/de_team_experience/", "subreddit_subscribers": 119655, "created_utc": 1690809757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently in my last (hopefully) year of grad school and I'm also working full time. I have goals of working in data engineering, but currently I work in a role that isn't in the general field of data analytics, nor data engineering, however, I've done multiple analytics projects at work, as well have made some automation pipelines, but my day to day work doesn't really involve data engineering work. I've been advised by mentors to find work that would allow me to use sql or python on a daily basis so I wouldn't have to worry about doing side projects outside of work and school. I just want to be in a good position come graduation time so I can compete for data engineering roles, and that's only possible if I keep my skills sharp (SQL, Python, etc) Any advice would be greatly appreciated.\n\nEdit: The only program I use at work is a no-code program, but I'm hesitant to dive into using it because I don't want my coding skills to atrophy. ", "author_fullname": "t2_5e8sloz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this feasible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ekc89", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690819717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in my last (hopefully) year of grad school and I&amp;#39;m also working full time. I have goals of working in data engineering, but currently I work in a role that isn&amp;#39;t in the general field of data analytics, nor data engineering, however, I&amp;#39;ve done multiple analytics projects at work, as well have made some automation pipelines, but my day to day work doesn&amp;#39;t really involve data engineering work. I&amp;#39;ve been advised by mentors to find work that would allow me to use sql or python on a daily basis so I wouldn&amp;#39;t have to worry about doing side projects outside of work and school. I just want to be in a good position come graduation time so I can compete for data engineering roles, and that&amp;#39;s only possible if I keep my skills sharp (SQL, Python, etc) Any advice would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Edit: The only program I use at work is a no-code program, but I&amp;#39;m hesitant to dive into using it because I don&amp;#39;t want my coding skills to atrophy. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ekc89", "is_robot_indexable": true, "report_reasons": null, "author": "MiserableCharity7222", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ekc89/is_this_feasible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ekc89/is_this_feasible/", "subreddit_subscribers": 119655, "created_utc": 1690819717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been working at a large domestic company before as a DE, but used mostly inner self-made tooling to write SQL/Spark code to do ETL. No so-called 'deployment' or CI&amp;CD concept. Most of the time It actually is just filling out a form with parameters and configuration and you submit the code and workflow. Most DE just focus on the business logic and a little bit of parameters tuning. \n\n&amp;#x200B;\n\nSo when I first realized that many DE jobs on the job market required experience like DevOps, gitlab, CI&amp;CD, Jenkins and Agile, I got painfully nervous. I think these are really important and wish I have these knowledges because I can be more prepared for the work in the future. However I don't really possess the 'Software developer' side knowledge since I came out as a data-guy from the beginning. \n\nCan anyone recommend some materials or share some learning experience about these 'DevOps' side tooling/concepts/learning paths? Much appreciated.\n\n&amp;#x200B;", "author_fullname": "t2_oorup", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone elaborate me about the 'DevOps' side of DE or how should I learn them to fit for an interview or working as a data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f127h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690860937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been working at a large domestic company before as a DE, but used mostly inner self-made tooling to write SQL/Spark code to do ETL. No so-called &amp;#39;deployment&amp;#39; or CI&amp;amp;CD concept. Most of the time It actually is just filling out a form with parameters and configuration and you submit the code and workflow. Most DE just focus on the business logic and a little bit of parameters tuning. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So when I first realized that many DE jobs on the job market required experience like DevOps, gitlab, CI&amp;amp;CD, Jenkins and Agile, I got painfully nervous. I think these are really important and wish I have these knowledges because I can be more prepared for the work in the future. However I don&amp;#39;t really possess the &amp;#39;Software developer&amp;#39; side knowledge since I came out as a data-guy from the beginning. &lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend some materials or share some learning experience about these &amp;#39;DevOps&amp;#39; side tooling/concepts/learning paths? Much appreciated.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15f127h", "is_robot_indexable": true, "report_reasons": null, "author": "GeForceKawaiiyo", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15f127h/can_anyone_elaborate_me_about_the_devops_side_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15f127h/can_anyone_elaborate_me_about_the_devops_side_of/", "subreddit_subscribers": 119655, "created_utc": 1690860937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Essentially the gold-layer data will be the exact same as bronze.\n\nBackstory:\n\nDealing with a neglected DB system that, over time, has seen several reports being generated from the bronze-layer, which is a db consisting of raw, historic data. The system contains the usual silver/gold layers, where the **majority of reports are being generated from gold after the underlying data is transformed in silver**. I'm overhauling this and designing a new system, and will most likely keep the raw/transform/report 3-layer structure.\n\nI'm thinking that the best approach here is to take the tables that are being used for these Bronze-facing reports and promoting them to Silver and then Gold without transforming them (however, I'll add steps to validate the data and minimize any issues with fidelity).\n\nWhat benefits and caveats, aside from additional storage cost, can you guys think of with having a mirror image of the respective bronze tables as a silver and gold layer?", "author_fullname": "t2_8y4c8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aside from additional storage costs, what are some arguments for and against promoting raw tables (bronze layer) to silver and then gold but without transforming the data throughout this process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eqpc0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690837717.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690834396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Essentially the gold-layer data will be the exact same as bronze.&lt;/p&gt;\n\n&lt;p&gt;Backstory:&lt;/p&gt;\n\n&lt;p&gt;Dealing with a neglected DB system that, over time, has seen several reports being generated from the bronze-layer, which is a db consisting of raw, historic data. The system contains the usual silver/gold layers, where the &lt;strong&gt;majority of reports are being generated from gold after the underlying data is transformed in silver&lt;/strong&gt;. I&amp;#39;m overhauling this and designing a new system, and will most likely keep the raw/transform/report 3-layer structure.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking that the best approach here is to take the tables that are being used for these Bronze-facing reports and promoting them to Silver and then Gold without transforming them (however, I&amp;#39;ll add steps to validate the data and minimize any issues with fidelity).&lt;/p&gt;\n\n&lt;p&gt;What benefits and caveats, aside from additional storage cost, can you guys think of with having a mirror image of the respective bronze tables as a silver and gold layer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15eqpc0", "is_robot_indexable": true, "report_reasons": null, "author": "azazazazaz3", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15eqpc0/aside_from_additional_storage_costs_what_are_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15eqpc0/aside_from_additional_storage_costs_what_are_some/", "subreddit_subscribers": 119655, "created_utc": 1690834396.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am starting my 2nd semester at a CS course and i have been pondering about my future paths and career and i liked the ideia of Data Engineering.\n\nOn my first semester i used Python for some NLP/LLM projects and really liked it, usually more applied stuff using established frameworks, i also got some nice stuff with professors lined up about this topic (ML/AI/NLP)\n\nI also heard some quite interesting Data Engineering projects (pipelines, cloud hosting and Pyspark to creating continous data flows) and liked them.\n\nSo then i suppose the closest things to my interests would be a Machine Learning Engineer, but then i heard MLE jobs are not only fewer than DE but also usually tougher on academic requeriments (big emphasis on having a masters), then i learned of DE which has more job openings, usually less requiring of academic titles so i guess that more fitting.\n\nAlso many DE jobs ask for ML experience so all my interests and projects could go towards building a CV of a DE with knowledge of ML \n\nI mainly want to ask you guys hows the job market for Data engineering? one of the reasons i dont want to get into Data Science is not only preferring a more engineer and software role but also the fact that it seens to be a quite saturated market, is DE less saturated than DS? what do you guys think?\n\n&amp;#x200B;", "author_fullname": "t2_7xe340s7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CS student here, wanna know if Data Engineering would be a good path.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15evmot", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690846132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am starting my 2nd semester at a CS course and i have been pondering about my future paths and career and i liked the ideia of Data Engineering.&lt;/p&gt;\n\n&lt;p&gt;On my first semester i used Python for some NLP/LLM projects and really liked it, usually more applied stuff using established frameworks, i also got some nice stuff with professors lined up about this topic (ML/AI/NLP)&lt;/p&gt;\n\n&lt;p&gt;I also heard some quite interesting Data Engineering projects (pipelines, cloud hosting and Pyspark to creating continous data flows) and liked them.&lt;/p&gt;\n\n&lt;p&gt;So then i suppose the closest things to my interests would be a Machine Learning Engineer, but then i heard MLE jobs are not only fewer than DE but also usually tougher on academic requeriments (big emphasis on having a masters), then i learned of DE which has more job openings, usually less requiring of academic titles so i guess that more fitting.&lt;/p&gt;\n\n&lt;p&gt;Also many DE jobs ask for ML experience so all my interests and projects could go towards building a CV of a DE with knowledge of ML &lt;/p&gt;\n\n&lt;p&gt;I mainly want to ask you guys hows the job market for Data engineering? one of the reasons i dont want to get into Data Science is not only preferring a more engineer and software role but also the fact that it seens to be a quite saturated market, is DE less saturated than DS? what do you guys think?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15evmot", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPineapples7791", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15evmot/cs_student_here_wanna_know_if_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15evmot/cs_student_here_wanna_know_if_data_engineering/", "subreddit_subscribers": 119655, "created_utc": 1690846132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is my first topic here, and my motivation comes from the situation I am facing. I have been studying formally since I 5\\~6yo, went all up to school, high school and here in Brazil, we have no college; it is a direct university, last year I graduated with a bachelor's in Information Systems, and I am thinking about doing a master.\n\nI have been working with data since 2020; I started as a data analyst and became a data scientist, and right now, I am in my second year working as a data engineer. During all these processes, I have worked on different kinds of companies, from 30-man startups to multinational consulting. \n\nI am enjoying working with data engineering, and I want to go deep in my knowledge; some must say that master's doesn't matter much to this, but I am feeling a bit off not studying formally after that many years. I have two options and would like to know what you think may be better to get specialized for the present and future. \n\nThe first would be to work with a younger professor, known to be a cool guy; he is not that famous but has a Ph.D. from Pisa University (Italy) and has researched streaming lines with C++ etc. Streaming is exciting, but I have never worked with it since it is a niche area with which only a few companies work. \n\nThe second professor is more famous, has a PH.D. from Georgia Tech and has a bit more projects with companies; his researches are more focused on data architectures, delta lakes, data lakes, data warehouses etc. \n\nI would prefer the second one maybe, but I would like to hear from experienced people before making a choice.  \n\n\nI feel that I would like to do more research in theoretical content, maybe something like a study about cloud architectures for big companies using more modern tools for streaming instead of coding something specific if I chose the first professor or with the second one something in this architecture side too but on this data lake/delta lakes etc. point of view.", "author_fullname": "t2_xsawr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What topic would you choose in a masters?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15esyxb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690839623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my first topic here, and my motivation comes from the situation I am facing. I have been studying formally since I 5~6yo, went all up to school, high school and here in Brazil, we have no college; it is a direct university, last year I graduated with a bachelor&amp;#39;s in Information Systems, and I am thinking about doing a master.&lt;/p&gt;\n\n&lt;p&gt;I have been working with data since 2020; I started as a data analyst and became a data scientist, and right now, I am in my second year working as a data engineer. During all these processes, I have worked on different kinds of companies, from 30-man startups to multinational consulting. &lt;/p&gt;\n\n&lt;p&gt;I am enjoying working with data engineering, and I want to go deep in my knowledge; some must say that master&amp;#39;s doesn&amp;#39;t matter much to this, but I am feeling a bit off not studying formally after that many years. I have two options and would like to know what you think may be better to get specialized for the present and future. &lt;/p&gt;\n\n&lt;p&gt;The first would be to work with a younger professor, known to be a cool guy; he is not that famous but has a Ph.D. from Pisa University (Italy) and has researched streaming lines with C++ etc. Streaming is exciting, but I have never worked with it since it is a niche area with which only a few companies work. &lt;/p&gt;\n\n&lt;p&gt;The second professor is more famous, has a PH.D. from Georgia Tech and has a bit more projects with companies; his researches are more focused on data architectures, delta lakes, data lakes, data warehouses etc. &lt;/p&gt;\n\n&lt;p&gt;I would prefer the second one maybe, but I would like to hear from experienced people before making a choice.  &lt;/p&gt;\n\n&lt;p&gt;I feel that I would like to do more research in theoretical content, maybe something like a study about cloud architectures for big companies using more modern tools for streaming instead of coding something specific if I chose the first professor or with the second one something in this architecture side too but on this data lake/delta lakes etc. point of view.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15esyxb", "is_robot_indexable": true, "report_reasons": null, "author": "abbadb", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15esyxb/what_topic_would_you_choose_in_a_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15esyxb/what_topic_would_you_choose_in_a_masters/", "subreddit_subscribers": 119655, "created_utc": 1690839623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I was recently laid off and have about 10 years experience (USA)  so have done tasks that could fall under any of the titles above. Most interview will most like be DE roles or SWE;DE. That being said when I have interviewed in the past and what I am seeing again is a lot of variety in what these roles get interviewed for and recruiters prepping you  not really even being as discrete. Here are the 3 flavors I\u2019ve seen. \n\n1. Bigger tech; gives you random leet code that  could have nothing related to DE they just are washing you through the ritual of checking algo/data structure knowledge. \n\n2. Seems like \u201cHCOL well funded tier 2\u201d start ups will mimic the above (and recruiters will always say prepare leetcode style ) but will sometimes deliver a bespoke question closer to what a swe would think a de does ie process log data data from a server and return  different aggregates of that data but only using the stand library of a dynamic programming language and return it in a dictionary(ie python without pandas ). Which seems like always hard to align on what the are really trying to test for other than if you recall all the languages out of the box functions really well. \n\n3. Usually small start ups; take home project to write a pipeline. \n\n**curious if we feel the same ** \n\n\nI just get frustrated spending hours on leetcode and Big O to only find my interview went south because I have not made an aggregation for awhile off a python dictionary or forgot the regex syntax or some nuance of .split(). \n\nAdditionally while trying to brush up on traditional CS concepts and also applying / interviewing it is hard to not have some atrophy on SQL and day to day python  coding ; I know I can practice and make a project but it\u2019s hard to determine how much to invest vs CS fundamentals, language of choice nuances, hard transformations , one off dynamic programming questions , leetcode , general architecture and other tech needed to be known as a DE. \n\nI know it\u2019s all apart of the job and I have experience doing it all just feeling like it\u2019s hard the future into read an interview process. \n\nMaybe discussion here on how to best prepare would help us all ? My current approach to getting a job is below and I am still crafting as I was laid off two weeks ago and trying my best to get a job offer in 10 weeks (I know , ambitious but also last employer give little severance to us). I\u2019ve come from a place where some days i wrote Python, filled in terraform yaml files , spun infra in cloud, model data, debug airflow ect. So my skill repetition was not narrow. \n\nI wanna optimize how to prepare and succeed in this job market and it seems like most interviews say they care about skills in \u201ccracking the coding interview\u201d , but doesn\u2019t seem to be spot on for people with our background ie data engineering. Here is my schedule below , open to feedback. \n\nM-f (unless interviews mixed in or having me do this on the weekend)\n1) morning: (up to 4 hours ) doing algo/data structure training. Ie hand writing pre_order_traversal template. Hoping this also reinforces python syntax as well. \n2) afternoon: . As much as I can apply to jobs via LinkedIn and take interview. \n3) evening \u2014 1hr; lightly refresh on python syntax , sql &amp; genera DE architecture (this work is pretty unstructored \u2014 weather it be w3schools, terraform docs , k8s medium article). Try to relax and change mind space.", "author_fullname": "t2_13551s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview prep for DE , SWE Eng; Data, Data Infra , Data Platform, Analytics Engineer roles.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ev7ew", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690845062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I was recently laid off and have about 10 years experience (USA)  so have done tasks that could fall under any of the titles above. Most interview will most like be DE roles or SWE;DE. That being said when I have interviewed in the past and what I am seeing again is a lot of variety in what these roles get interviewed for and recruiters prepping you  not really even being as discrete. Here are the 3 flavors I\u2019ve seen. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Bigger tech; gives you random leet code that  could have nothing related to DE they just are washing you through the ritual of checking algo/data structure knowledge. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Seems like \u201cHCOL well funded tier 2\u201d start ups will mimic the above (and recruiters will always say prepare leetcode style ) but will sometimes deliver a bespoke question closer to what a swe would think a de does ie process log data data from a server and return  different aggregates of that data but only using the stand library of a dynamic programming language and return it in a dictionary(ie python without pandas ). Which seems like always hard to align on what the are really trying to test for other than if you recall all the languages out of the box functions really well. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Usually small start ups; take home project to write a pipeline. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;*&lt;em&gt;curious if we feel the same *&lt;/em&gt; &lt;/p&gt;\n\n&lt;p&gt;I just get frustrated spending hours on leetcode and Big O to only find my interview went south because I have not made an aggregation for awhile off a python dictionary or forgot the regex syntax or some nuance of .split(). &lt;/p&gt;\n\n&lt;p&gt;Additionally while trying to brush up on traditional CS concepts and also applying / interviewing it is hard to not have some atrophy on SQL and day to day python  coding ; I know I can practice and make a project but it\u2019s hard to determine how much to invest vs CS fundamentals, language of choice nuances, hard transformations , one off dynamic programming questions , leetcode , general architecture and other tech needed to be known as a DE. &lt;/p&gt;\n\n&lt;p&gt;I know it\u2019s all apart of the job and I have experience doing it all just feeling like it\u2019s hard the future into read an interview process. &lt;/p&gt;\n\n&lt;p&gt;Maybe discussion here on how to best prepare would help us all ? My current approach to getting a job is below and I am still crafting as I was laid off two weeks ago and trying my best to get a job offer in 10 weeks (I know , ambitious but also last employer give little severance to us). I\u2019ve come from a place where some days i wrote Python, filled in terraform yaml files , spun infra in cloud, model data, debug airflow ect. So my skill repetition was not narrow. &lt;/p&gt;\n\n&lt;p&gt;I wanna optimize how to prepare and succeed in this job market and it seems like most interviews say they care about skills in \u201ccracking the coding interview\u201d , but doesn\u2019t seem to be spot on for people with our background ie data engineering. Here is my schedule below , open to feedback. &lt;/p&gt;\n\n&lt;p&gt;M-f (unless interviews mixed in or having me do this on the weekend)\n1) morning: (up to 4 hours ) doing algo/data structure training. Ie hand writing pre_order_traversal template. Hoping this also reinforces python syntax as well. \n2) afternoon: . As much as I can apply to jobs via LinkedIn and take interview. \n3) evening \u2014 1hr; lightly refresh on python syntax , sql &amp;amp; genera DE architecture (this work is pretty unstructored \u2014 weather it be w3schools, terraform docs , k8s medium article). Try to relax and change mind space.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15ev7ew", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ev7ew/interview_prep_for_de_swe_eng_data_data_infra/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ev7ew/interview_prep_for_de_swe_eng_data_data_infra/", "subreddit_subscribers": 119655, "created_utc": 1690845062.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**The Ten Standard Tools To Develop Data Pipelines In Microsoft Azure.**\n\n**Is it overkill? The paradox of choice? Or the right tool for the right job? We discuss.**\n\n[https://datakitchen.io/the-ten-standard-tools-to-develop-data-pipelines-in-microsoft-azure/](https://datakitchen.io/the-ten-standard-tools-to-develop-data-pipelines-in-microsoft-azure/)\n\n[My God, its Full of Azure Data Pipelines](https://preview.redd.it/wl4wzsnqtdfb1.png?width=736&amp;format=png&amp;auto=webp&amp;s=f302def44295437f5294b21a92a0d5c21554edc5)", "author_fullname": "t2_fwdag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My God, It's Full of Data Pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "media_metadata": {"wl4wzsnqtdfb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/wl4wzsnqtdfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bf0bef303b3183ce3b965c18f8fdc377fe572298"}, {"y": 142, "x": 216, "u": "https://preview.redd.it/wl4wzsnqtdfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b0ad989855da48b104cc7eb3f2ac959f7b54b1ed"}, {"y": 211, "x": 320, "u": "https://preview.redd.it/wl4wzsnqtdfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1aa24bf31a8114bc02dedb50d8765e2c365eb61"}, {"y": 423, "x": 640, "u": "https://preview.redd.it/wl4wzsnqtdfb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1345aace495d8ba2ecd3f272332ae404e4ff06b1"}], "s": {"y": 487, "x": 736, "u": "https://preview.redd.it/wl4wzsnqtdfb1.png?width=736&amp;format=png&amp;auto=webp&amp;s=f302def44295437f5294b21a92a0d5c21554edc5"}, "id": "wl4wzsnqtdfb1"}}, "name": "t3_15ev2w6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5rMzRyISr4O7JjbYvroblQscCWYbX59QRxBXLguOTTo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690844736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;The Ten Standard Tools To Develop Data Pipelines In Microsoft Azure.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is it overkill? The paradox of choice? Or the right tool for the right job? We discuss.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://datakitchen.io/the-ten-standard-tools-to-develop-data-pipelines-in-microsoft-azure/\"&gt;https://datakitchen.io/the-ten-standard-tools-to-develop-data-pipelines-in-microsoft-azure/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/wl4wzsnqtdfb1.png?width=736&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f302def44295437f5294b21a92a0d5c21554edc5\"&gt;My God, its Full of Azure Data Pipelines&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ev2w6", "is_robot_indexable": true, "report_reasons": null, "author": "botswana99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ev2w6/my_god_its_full_of_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ev2w6/my_god_its_full_of_data_pipelines/", "subreddit_subscribers": 119655, "created_utc": 1690844736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm totally new to spark and learning it continuously.  Currently working in a pipeline were I have already extracted needed data from a source file and did all the transformations and the final df looks fine to write and heres were I'm stuck now. When I try to write the output in s3 by using partitionBy based on two columns \"name\" and \"type\" and since there maybe multiple entries for same name and type combination while writing parquet if its present in different partition it writes a new file instead of appending.\n\nTo overcome this previously my teammates have tried doing coalesce(1) and the final df have over 2 million records and it was taking more time and it was never completed even after 2-3 hours.\n\nSo suggested using repartition(100, \"domain\") based on the column domain which will make sure all name and type for a single domain comes under same partition. But still it also took the same time and the sink process is not completing.\n\nTo cross check why its getting stuck.. once the final df is ready I checked the natural partitions and it was around 1060 something so I have again tried repartition with 500 and based on domain column and again takes the same time.\n\nWe are using AWS EMR with 1 master 14 cores to do this and tried increasing it to 20 as well but still stuck at the same point.\n\nSince its in jupyter notebook in EMR.. the last job process which is doing the sink process finishes first 54 steps within 10 seconds ans afterwards its taking more than 45 mins for a single task and total 1000 something tasks were scheduled (55/1012).\n\nCan you someone please help me out how to resolve this issue and write the file ? so that s3 has name/type/single parquet file for it which is used my a restapi to get data.", "author_fullname": "t2_5s0b87mm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sink process taking way too long in Pyspark dataframe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ekclt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690819741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m totally new to spark and learning it continuously.  Currently working in a pipeline were I have already extracted needed data from a source file and did all the transformations and the final df looks fine to write and heres were I&amp;#39;m stuck now. When I try to write the output in s3 by using partitionBy based on two columns &amp;quot;name&amp;quot; and &amp;quot;type&amp;quot; and since there maybe multiple entries for same name and type combination while writing parquet if its present in different partition it writes a new file instead of appending.&lt;/p&gt;\n\n&lt;p&gt;To overcome this previously my teammates have tried doing coalesce(1) and the final df have over 2 million records and it was taking more time and it was never completed even after 2-3 hours.&lt;/p&gt;\n\n&lt;p&gt;So suggested using repartition(100, &amp;quot;domain&amp;quot;) based on the column domain which will make sure all name and type for a single domain comes under same partition. But still it also took the same time and the sink process is not completing.&lt;/p&gt;\n\n&lt;p&gt;To cross check why its getting stuck.. once the final df is ready I checked the natural partitions and it was around 1060 something so I have again tried repartition with 500 and based on domain column and again takes the same time.&lt;/p&gt;\n\n&lt;p&gt;We are using AWS EMR with 1 master 14 cores to do this and tried increasing it to 20 as well but still stuck at the same point.&lt;/p&gt;\n\n&lt;p&gt;Since its in jupyter notebook in EMR.. the last job process which is doing the sink process finishes first 54 steps within 10 seconds ans afterwards its taking more than 45 mins for a single task and total 1000 something tasks were scheduled (55/1012).&lt;/p&gt;\n\n&lt;p&gt;Can you someone please help me out how to resolve this issue and write the file ? so that s3 has name/type/single parquet file for it which is used my a restapi to get data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ekclt", "is_robot_indexable": true, "report_reasons": null, "author": "imameeer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ekclt/sink_process_taking_way_too_long_in_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ekclt/sink_process_taking_way_too_long_in_pyspark/", "subreddit_subscribers": 119655, "created_utc": 1690819741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_jcps4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From Half A Day To Half An Hour! Performance Tuning Snowpark For Identity Resolution On Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15ej2ut", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Mo9w-SCZDoUdLx4yA70JihCnGdcmx4FyARLr_oB-YaQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690816796.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "learningfromdata.zingg.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.learningfromdata.zingg.ai/p/performance-tuning-snowpark-for-identity", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?auto=webp&amp;s=5d8def0021de1e2f85598e36470a26e0ec402fba", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c0999c9e40d8dcf09d3448231f2754f11ae5acb", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2b48066ea9d017b7c0c5b48e3c39ded75b318300", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=35787ae8b289888943a45689ee895bb083c8629e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b3dad013369b5c2145c1fac01d0b96c5e6c8ee32", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=05732a92520a7a957f314e51c8d3a18c5870d748", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/hZTTje8OJz_f23CbLvBSkJuz1z0blUlOFkg6h7-ktWY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a4bcf7705bc971a7ee8da726a2be9448f3f8769", "width": 1080, "height": 540}], "variants": {}, "id": "3buw50ybg4THUy9GX79YY19y00pyPQxd1bi1KbbgoqA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ej2ut", "is_robot_indexable": true, "report_reasons": null, "author": "sonalg", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ej2ut/from_half_a_day_to_half_an_hour_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.learningfromdata.zingg.ai/p/performance-tuning-snowpark-for-identity", "subreddit_subscribers": 119655, "created_utc": 1690816796.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for service or tool similiar to [Metabase](https://www.metabase.com/) or [Redash](https://redash.io/) that allows me to add data source - for example Postgres connection, and create raw SQL queries that can be shared or exposed through API. So instead of keeping raw SQL code somewhere, my other service would call this tool e.g. `http://microservice/query=1?param1=xx&amp;page=2` and get the results from the DB. \nThese calls are internal only and part of ETL processes, but of course authentication would be required.\n\nThe services that I mentioned are more or less focused only on visualizations, I do not really need that, but for example Metabase is almost perfect as it has API that can work with parametrized queries, but for sake of visualizations it has hard limit on the count of results that are returned.\n\nAny other suggestions are welcome.", "author_fullname": "t2_bq4w6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool or service for querying and exposing database through API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ehxh4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690814149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for service or tool similiar to &lt;a href=\"https://www.metabase.com/\"&gt;Metabase&lt;/a&gt; or &lt;a href=\"https://redash.io/\"&gt;Redash&lt;/a&gt; that allows me to add data source - for example Postgres connection, and create raw SQL queries that can be shared or exposed through API. So instead of keeping raw SQL code somewhere, my other service would call this tool e.g. &lt;code&gt;http://microservice/query=1?param1=xx&amp;amp;page=2&lt;/code&gt; and get the results from the DB. \nThese calls are internal only and part of ETL processes, but of course authentication would be required.&lt;/p&gt;\n\n&lt;p&gt;The services that I mentioned are more or less focused only on visualizations, I do not really need that, but for example Metabase is almost perfect as it has API that can work with parametrized queries, but for sake of visualizations it has hard limit on the count of results that are returned.&lt;/p&gt;\n\n&lt;p&gt;Any other suggestions are welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?auto=webp&amp;s=107572bcffe6e16e601fbfa7adc0948b3a2b6a4f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ea6b7aafd33b2a93630e2b42c1775d84785fb06b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dea1182b323f20b6b0a5185baae08721cb8bbe51", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9bc515316f645bf42bf4d975ac01befc3882170", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff6d758cd5061450003cad4ff1bf8722b6f23020", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e9b1f1f0306bc5a9d8342065c4ecdaff26236763", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/17c5gGJx3AJT5B4QXHvkafcJebLnDbEASgs-tFW5fj4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d13f1df515a957d9bda81a3c03e2e7f352d9cb62", "width": 1080, "height": 567}], "variants": {}, "id": "H_7x2FRMyu4Laqv2RVCvsaxLrQmcsL3NrNoLvhi3x7o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ehxh4", "is_robot_indexable": true, "report_reasons": null, "author": "Montty1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ehxh4/tool_or_service_for_querying_and_exposing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ehxh4/tool_or_service_for_querying_and_exposing/", "subreddit_subscribers": 119655, "created_utc": 1690814149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[ Is there any way to statistically test \\(In R\\) the association between the red dots \\(rock art\\) and the yellow dots \\(funerary monuments\\)? I want to prove the red dots are not just randomly located in the landscape but always situated in relation to yellow dots. How do i test for that relationship objectivley? ](https://preview.redd.it/vg882vbglafb1.png?width=1724&amp;format=png&amp;auto=webp&amp;s=d1b1cde262fe505260cf0f1b26d9fc4849f45c03)\n\n *I want to prove the red dots are not just randomly located in the landscape but always situated in relation to yellow dots.*\n\nI already have the coordinates of all the points so could easily do this via distance measurements between each point.\n\nI've been reading papers and there seem to be **a couple of options** (none of which are explained very well, and I'd love some more clarification on):\n\n1. Use a Monte-Carlo simulation \\[Vanacker et al. 2001\\] to prove red dots are not randomly situated. Apparently Vanacker converted the distance measurements between points into categories eg. &lt;10km, 10-15km, 15-20km etc. But they didn't include a very good method or any of their code in the paper so I can't tell exactly how that would work and am struggling to find other examples/resources\n2. Point Pattern Analysis since I am dealing with 'environmental coviariates' = second-order properties? \\[Kempf &amp; Gunther 2023 say they: \"used spatstat package in R and function rhohat to calculate site intensity as a function of the pre-processed focal raster data to visualise the effect of attraction or repulsion given by a specific parameter...\"\\] Why do they need to convert point data to raster data for this analysis?\n3. Multivariate Regression since this would allow me to include other variables like elevation, distance from water source, soil type etc\n\nOr are all these ideas bad and should I try another way?\n\nThankyou so much for your help, feel free to point me elsewhere but this is the result of my googling so far :))))", "author_fullname": "t2_socde6rs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to test the relationship between red dots &amp; yellow dots??? [R package, archaeologist needs help lol]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vg882vbglafb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/vg882vbglafb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5312bc37b7b2dbc29a814a285a3e6a0225d99819"}, {"y": 155, "x": 216, "u": "https://preview.redd.it/vg882vbglafb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=20189d6f8566e82971122504bc2d97771d522122"}, {"y": 229, "x": 320, "u": "https://preview.redd.it/vg882vbglafb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dee7fbb917dbca48d150737d700ef9169e30a55f"}, {"y": 459, "x": 640, "u": "https://preview.redd.it/vg882vbglafb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f82136c0a393b7f2386314940132a4662a565726"}, {"y": 689, "x": 960, "u": "https://preview.redd.it/vg882vbglafb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=413aaa943380d65b1da513e425150096ed49b1c5"}, {"y": 775, "x": 1080, "u": "https://preview.redd.it/vg882vbglafb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b90b373ebc9b343cdcc283b51684d5b27cffee5a"}], "s": {"y": 1238, "x": 1724, "u": "https://preview.redd.it/vg882vbglafb1.png?width=1724&amp;format=png&amp;auto=webp&amp;s=d1b1cde262fe505260cf0f1b26d9fc4849f45c03"}, "id": "vg882vbglafb1"}}, "name": "t3_15eek4s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/P-1KPd2RoBWVeYgzDInKZqayr_JvkCrePMNqfBR5MY8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690805744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vg882vbglafb1.png?width=1724&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d1b1cde262fe505260cf0f1b26d9fc4849f45c03\"&gt; Is there any way to statistically test (In R) the association between the red dots (rock art) and the yellow dots (funerary monuments)? I want to prove the red dots are not just randomly located in the landscape but always situated in relation to yellow dots. How do i test for that relationship objectivley? &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I want to prove the red dots are not just randomly located in the landscape but always situated in relation to yellow dots.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I already have the coordinates of all the points so could easily do this via distance measurements between each point.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been reading papers and there seem to be &lt;strong&gt;a couple of options&lt;/strong&gt; (none of which are explained very well, and I&amp;#39;d love some more clarification on):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use a Monte-Carlo simulation [Vanacker et al. 2001] to prove red dots are not randomly situated. Apparently Vanacker converted the distance measurements between points into categories eg. &amp;lt;10km, 10-15km, 15-20km etc. But they didn&amp;#39;t include a very good method or any of their code in the paper so I can&amp;#39;t tell exactly how that would work and am struggling to find other examples/resources&lt;/li&gt;\n&lt;li&gt;Point Pattern Analysis since I am dealing with &amp;#39;environmental coviariates&amp;#39; = second-order properties? [Kempf &amp;amp; Gunther 2023 say they: &amp;quot;used spatstat package in R and function rhohat to calculate site intensity as a function of the pre-processed focal raster data to visualise the effect of attraction or repulsion given by a specific parameter...&amp;quot;] Why do they need to convert point data to raster data for this analysis?&lt;/li&gt;\n&lt;li&gt;Multivariate Regression since this would allow me to include other variables like elevation, distance from water source, soil type etc&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Or are all these ideas bad and should I try another way?&lt;/p&gt;\n\n&lt;p&gt;Thankyou so much for your help, feel free to point me elsewhere but this is the result of my googling so far :))))&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15eek4s", "is_robot_indexable": true, "report_reasons": null, "author": "enemies2l0vers", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15eek4s/how_to_test_the_relationship_between_red_dots/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15eek4s/how_to_test_the_relationship_between_red_dots/", "subreddit_subscribers": 119655, "created_utc": 1690805744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Feeling nervous about a prod release for a data model that I've been working on. Been doing extensive QA on it but I feel like it's just never enough. Messy data always finds its way even with all the nonstop transformations that I've put into place. I'm always worried about some bad join that happens in the pipeline that just screws up the data. I always feel really uneasy about people using my data to make key decisions. Now again so far the numbers look good, but theres just gonna be that stupid something that pops up. I can't help but want to be like \"wait hold up! let me compare those numbers against the raw data!\" \n\nAnyone ever have this feel? ", "author_fullname": "t2_5ukitegd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Not confident with the Quality of Data.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15f446n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690870749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Feeling nervous about a prod release for a data model that I&amp;#39;ve been working on. Been doing extensive QA on it but I feel like it&amp;#39;s just never enough. Messy data always finds its way even with all the nonstop transformations that I&amp;#39;ve put into place. I&amp;#39;m always worried about some bad join that happens in the pipeline that just screws up the data. I always feel really uneasy about people using my data to make key decisions. Now again so far the numbers look good, but theres just gonna be that stupid something that pops up. I can&amp;#39;t help but want to be like &amp;quot;wait hold up! let me compare those numbers against the raw data!&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;Anyone ever have this feel? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15f446n", "is_robot_indexable": true, "report_reasons": null, "author": "burningburnerbern", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15f446n/not_confident_with_the_quality_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15f446n/not_confident_with_the_quality_of_data/", "subreddit_subscribers": 119655, "created_utc": 1690870749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a DE, I'm trying to build a data platform for our data science team. Our main use cases are : Data lake, and letting data scientists run jupyter notebooks to read big data files.   \n\n\nThese days, everyone seems to be on cloud. We prefer on-prem as we might have a lot of read actions on the data, which can be costlier.   \nAlso, everyone seems to be talking about the maintenance effort in HDFS. Is it not worth the performance improvement we might get with data co-locality ?    \n\n\n  \n", "author_fullname": "t2_8682bqw4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is HDFS + Spark a good tech stack in today's world ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15f3uev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690869813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a DE, I&amp;#39;m trying to build a data platform for our data science team. Our main use cases are : Data lake, and letting data scientists run jupyter notebooks to read big data files.   &lt;/p&gt;\n\n&lt;p&gt;These days, everyone seems to be on cloud. We prefer on-prem as we might have a lot of read actions on the data, which can be costlier.&lt;br/&gt;\nAlso, everyone seems to be talking about the maintenance effort in HDFS. Is it not worth the performance improvement we might get with data co-locality ?    &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15f3uev", "is_robot_indexable": true, "report_reasons": null, "author": "GreekYogurtt", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15f3uev/is_hdfs_spark_a_good_tech_stack_in_todays_world/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15f3uev/is_hdfs_spark_a_good_tech_stack_in_todays_world/", "subreddit_subscribers": 119655, "created_utc": 1690869813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking forward to suggestions on the accelerators that drive delivery in data engineering space, what could be the starting point. I am planning to templatize some of the IAC and consider that as a service. Data as a service is a huge umbrella, wanted to understand if someone took the route and what were the key things that were kept as milestones", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accelerators for Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f3114", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690867119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking forward to suggestions on the accelerators that drive delivery in data engineering space, what could be the starting point. I am planning to templatize some of the IAC and consider that as a service. Data as a service is a huge umbrella, wanted to understand if someone took the route and what were the key things that were kept as milestones&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15f3114", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15f3114/accelerators_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15f3114/accelerators_for_data_engineering/", "subreddit_subscribers": 119655, "created_utc": 1690867119.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been pulling my hair out trying to figure out how to implement a column level encryption similar to what's available on spark. My stack is essentially s3 parquet files with a trino layer that pipes to postgres. On a different life I would use a spark udf but I don't want to pull in spark just for encryption. \n\nBeen doing a fair bit of googling, am I crazy or is this just not a thing you can do in trino or postgres?", "author_fullname": "t2_706trkkr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Column level data encryption", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15evj9w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690845894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been pulling my hair out trying to figure out how to implement a column level encryption similar to what&amp;#39;s available on spark. My stack is essentially s3 parquet files with a trino layer that pipes to postgres. On a different life I would use a spark udf but I don&amp;#39;t want to pull in spark just for encryption. &lt;/p&gt;\n\n&lt;p&gt;Been doing a fair bit of googling, am I crazy or is this just not a thing you can do in trino or postgres?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15evj9w", "is_robot_indexable": true, "report_reasons": null, "author": "Foodwithfloyd", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15evj9w/column_level_data_encryption/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15evj9w/column_level_data_encryption/", "subreddit_subscribers": 119655, "created_utc": 1690845894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you run spark-submit on a K8 cluster? It\u2019s my understanding that you can exec into any pod and run spark-submit from there.\n\nWould I just need to create a pod that terminates after spark-submit is run? Or is there a better way to do this? \n\n The goal would be to trigger this from airflow by posting the pod YAML file using kubectl.\n\nIs there a better way to go about this?", "author_fullname": "t2_vgufhpe7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark-Submit on K8?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ercry", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690835883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you run spark-submit on a K8 cluster? It\u2019s my understanding that you can exec into any pod and run spark-submit from there.&lt;/p&gt;\n\n&lt;p&gt;Would I just need to create a pod that terminates after spark-submit is run? Or is there a better way to do this? &lt;/p&gt;\n\n&lt;p&gt;The goal would be to trigger this from airflow by posting the pod YAML file using kubectl.&lt;/p&gt;\n\n&lt;p&gt;Is there a better way to go about this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ercry", "is_robot_indexable": true, "report_reasons": null, "author": "Interesting-Yard-225", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ercry/sparksubmit_on_k8/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ercry/sparksubmit_on_k8/", "subreddit_subscribers": 119655, "created_utc": 1690835883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We need to replicate / sync AWS Mysql db to Azure SQL db.  The DB is small size with nominal activity.\n\nIs there a build in solution available in either platform? If not, what is the simplest solution we can design and implement using which tools?\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "need aws to azure replication", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15emxyv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690825780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We need to replicate / sync AWS Mysql db to Azure SQL db.  The DB is small size with nominal activity.&lt;/p&gt;\n\n&lt;p&gt;Is there a build in solution available in either platform? If not, what is the simplest solution we can design and implement using which tools?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15emxyv", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15emxyv/need_aws_to_azure_replication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15emxyv/need_aws_to_azure_replication/", "subreddit_subscribers": 119655, "created_utc": 1690825780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, I'm working on a Side project design to Hash Credit card number data with a Secret value from Secret manager. \n\nDBT to read Source BQ table, Get secret value &amp; concatenate with PII Column which needs to be hashed with SHA256. \n\nI'm not able to integrate DBT with Secret Manager. Storing secret as Environment variable option cannot be used as SM option to be tried. \n\nI have options to include Cloud Function, Composer in my design. \n\nSo I have below things in mind:\n\n1. Composer DAG to access secret via Cloud function &amp; pass as XCOM variable to DBT task. \n2. Composer DAG to get secret using Secret backend &amp; pass as XCOM variable to DBT task. \n\nAlso, Secrets should not be in readable format in Composer logs. \n\nWhich one is feasible or please advise other alternatives? \n\n   \n\n   ", "author_fullname": "t2_4cullil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Options to integrate DBT with GCP Secret Manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ej945", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690817193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, I&amp;#39;m working on a Side project design to Hash Credit card number data with a Secret value from Secret manager. &lt;/p&gt;\n\n&lt;p&gt;DBT to read Source BQ table, Get secret value &amp;amp; concatenate with PII Column which needs to be hashed with SHA256. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not able to integrate DBT with Secret Manager. Storing secret as Environment variable option cannot be used as SM option to be tried. &lt;/p&gt;\n\n&lt;p&gt;I have options to include Cloud Function, Composer in my design. &lt;/p&gt;\n\n&lt;p&gt;So I have below things in mind:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Composer DAG to access secret via Cloud function &amp;amp; pass as XCOM variable to DBT task. &lt;/li&gt;\n&lt;li&gt;Composer DAG to get secret using Secret backend &amp;amp; pass as XCOM variable to DBT task. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Also, Secrets should not be in readable format in Composer logs. &lt;/p&gt;\n\n&lt;p&gt;Which one is feasible or please advise other alternatives? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ej945", "is_robot_indexable": true, "report_reasons": null, "author": "tmanipra", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ej945/options_to_integrate_dbt_with_gcp_secret_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ej945/options_to_integrate_dbt_with_gcp_secret_manager/", "subreddit_subscribers": 119655, "created_utc": 1690817193.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it a correct assumption that most modern data Platforms such as Big Query, Data Bricks, and Snowflake are based on the POSTGRESQL dialect? Thanks.", "author_fullname": "t2_va4epm9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Data Platforms: PostgreSQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15f3qnc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690869492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it a correct assumption that most modern data Platforms such as Big Query, Data Bricks, and Snowflake are based on the POSTGRESQL dialect? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15f3qnc", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway_112801", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15f3qnc/modern_data_platforms_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15f3qnc/modern_data_platforms_postgresql/", "subreddit_subscribers": 119655, "created_utc": 1690869492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "tldr: what database schema type have i been using for 30+ years?\n\nI'm an old and have only tangentially been involved with data warehouses and most/all of my 'data engineering' work has been as some type of app developer or etl consultant or sales engineer or something. I either hooked into (via sql, api, etc.) or created hundreds of databases -- small, medium, large, stupid, etc.\n\nI never thought of star vs. snowflake vs. data vault vs. whatever, and I don't suspect any of those databases did either - unless they were and I was just unaware of these schema types/design patterns/whatever. \n\nThe only exception would be if I hooked into something that was specifically called a 'data warehouse' and had someone or a team that could talk about its 'facts' and 'dimensions' and 'slowly changing dimensions' and such - and I pretty much never worked with data warehouses except to prove that I could get connectivity, query it, etc.\n\nI've given up on trying to figure out what various schema types supposedly are - star, snowflake, data vault, etc., but I am still curious -- what schema type were these hundreds of databases that I either created or worked with? \n\nWhen I think of a database, I'm thinking of ER diagrams and logical and physical models, some other design decisions and artifacts and things like tables and views and keys and PKs and FKs and constraints and procs and funcs and whatever, but there was never really any 'star' nor 'snowflake', but I guess I \\_could\\_ have some tables which seemed to be \\_more important\\_ than some of the others, more central to whatever your business was -- like 'Product' in an e-commerce store. It might have some 'leaves' (?) radiating outwards from it -- relationships to other tables -- but that was true of most tables in the schema except for the dumbest key/value lookup tables.\n\nso, what schema was I using? or the umpteen data modelers that created the databases that i used? what is the schema type of a standard line of business database? is it 'star' by definition? or is it 'none', or 'none - just normalized - the default'?\n\nis there an analogous concept somewhere else in IT?\n\nthanks!", "author_fullname": "t2_3fjhzh55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What schema type of my default, boring, old-school database using?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f1rs9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690863083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;tldr: what database schema type have i been using for 30+ years?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m an old and have only tangentially been involved with data warehouses and most/all of my &amp;#39;data engineering&amp;#39; work has been as some type of app developer or etl consultant or sales engineer or something. I either hooked into (via sql, api, etc.) or created hundreds of databases -- small, medium, large, stupid, etc.&lt;/p&gt;\n\n&lt;p&gt;I never thought of star vs. snowflake vs. data vault vs. whatever, and I don&amp;#39;t suspect any of those databases did either - unless they were and I was just unaware of these schema types/design patterns/whatever. &lt;/p&gt;\n\n&lt;p&gt;The only exception would be if I hooked into something that was specifically called a &amp;#39;data warehouse&amp;#39; and had someone or a team that could talk about its &amp;#39;facts&amp;#39; and &amp;#39;dimensions&amp;#39; and &amp;#39;slowly changing dimensions&amp;#39; and such - and I pretty much never worked with data warehouses except to prove that I could get connectivity, query it, etc.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve given up on trying to figure out what various schema types supposedly are - star, snowflake, data vault, etc., but I am still curious -- what schema type were these hundreds of databases that I either created or worked with? &lt;/p&gt;\n\n&lt;p&gt;When I think of a database, I&amp;#39;m thinking of ER diagrams and logical and physical models, some other design decisions and artifacts and things like tables and views and keys and PKs and FKs and constraints and procs and funcs and whatever, but there was never really any &amp;#39;star&amp;#39; nor &amp;#39;snowflake&amp;#39;, but I guess I _could_ have some tables which seemed to be _more important_ than some of the others, more central to whatever your business was -- like &amp;#39;Product&amp;#39; in an e-commerce store. It might have some &amp;#39;leaves&amp;#39; (?) radiating outwards from it -- relationships to other tables -- but that was true of most tables in the schema except for the dumbest key/value lookup tables.&lt;/p&gt;\n\n&lt;p&gt;so, what schema was I using? or the umpteen data modelers that created the databases that i used? what is the schema type of a standard line of business database? is it &amp;#39;star&amp;#39; by definition? or is it &amp;#39;none&amp;#39;, or &amp;#39;none - just normalized - the default&amp;#39;?&lt;/p&gt;\n\n&lt;p&gt;is there an analogous concept somewhere else in IT?&lt;/p&gt;\n\n&lt;p&gt;thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15f1rs9", "is_robot_indexable": true, "report_reasons": null, "author": "atlwellwell", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15f1rs9/what_schema_type_of_my_default_boring_oldschool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15f1rs9/what_schema_type_of_my_default_boring_oldschool/", "subreddit_subscribers": 119655, "created_utc": 1690863083.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}