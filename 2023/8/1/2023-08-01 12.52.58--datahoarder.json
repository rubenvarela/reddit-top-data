{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7me91nis", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Disney Discontinues Physical Media Releases for an Entire Continent", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15egxgg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 434, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 434, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pPWRH7l2SiwWOt_WtX1q7VBtV5fp_A_BlO3GX-niWrw.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690811788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "collider.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://collider.com/disney-physical-media-release-discontinue-australia/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?auto=webp&amp;s=00396370454858c269d64c9f04a799af6cc12337", "width": 1400, "height": 700}, "resolutions": [{"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fbf9a460ed4d3e8528199f7839881801330ea37b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a30f76807415eaac93326ef4c5938dd6cba0e84f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9ea61c12d4806c312eafdd182031fef399d395e0", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=107342f0b6fca8ff50e95fc236c8556e7d379f0f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a340719fff0f32833486b2278ca36bfd78e6e034", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/52Z_HYgffSvddO6iwnGIRKAjPGmrlUz9G6F-5VW_Z_I.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9cdcf18f7321a0dba51232d7879ceb6b424ea810", "width": 1080, "height": 540}], "variants": {}, "id": "WEeO1MWsnVDW93KokE5tqFv-yRkh-HygbEtnoJBpdcs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "64TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15egxgg", "is_robot_indexable": true, "report_reasons": null, "author": "WindowlessBasement", "discussion_type": null, "num_comments": 127, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15egxgg/disney_discontinues_physical_media_releases_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://collider.com/disney-physical-media-release-discontinue-australia/", "subreddit_subscribers": 695677, "created_utc": 1690811788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My mother unfortunately passed away recently and she had acquired (and kept in storage) 4-5 different MacBook pros, right back to the ones with the hinge design.  \nI don't immediately need access to the data in any of them, Still; I thought it would be cool if there were a simple way to archive/mothball their contents onto (preferably) a single drive called 'mom' or something that was super easy to search and that way if I ever want to find an email/reference number/legal doc/photo years into the future its easy to do so. Then I can donate or recycle the Macbooks.  \nThanks for your time. ", "author_fullname": "t2_9yy7pro6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving Macs of mom who's passed away", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eh7d6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690812435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My mother unfortunately passed away recently and she had acquired (and kept in storage) 4-5 different MacBook pros, right back to the ones with the hinge design.&lt;br/&gt;\nI don&amp;#39;t immediately need access to the data in any of them, Still; I thought it would be cool if there were a simple way to archive/mothball their contents onto (preferably) a single drive called &amp;#39;mom&amp;#39; or something that was super easy to search and that way if I ever want to find an email/reference number/legal doc/photo years into the future its easy to do so. Then I can donate or recycle the Macbooks.&lt;br/&gt;\nThanks for your time. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eh7d6", "is_robot_indexable": true, "report_reasons": null, "author": "herbertthe3rd", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eh7d6/archiving_macs_of_mom_whos_passed_away/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eh7d6/archiving_macs_of_mom_whos_passed_away/", "subreddit_subscribers": 695677, "created_utc": 1690812435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_mgptr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Throwing my hat in the ring for another web-scraper-based Reddit downloader. I wanted a more integrated way to use it so I developed a simple chrome extension to grab links to download.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15ep601", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RC0Y0RoeeO_iQx2xInFdxMsfy0_lNlnWT2W1b7c65_Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690830880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/eric-hamilton/reddit_post_downloader", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?auto=webp&amp;s=d5965d25dff3c66da06dfc3864153d6697eb316e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9400dc036d202f0f8c460c437cecf35e7e48b599", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c3c53ab1e958b94dce1178ddff7025a78385ad6", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1a9b1d0711349fd591590053488a14e601fd8e15", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a8eb5e5f2797796de661cfc74b7780cd3da2f4c7", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=982ad621638837f6e425e3159a4c9a0c0d297fd2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/-JqZVyW8OWCLlQw5G11vDwLWHCikTtf5GgCOhJGsvNQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c41c42cc94a524e8e917cf4de78dff137ef3bd24", "width": 1080, "height": 540}], "variants": {}, "id": "dJicjODPL_r5MeJsg6paH4QSIu18fJDbLEfpB_2iDe0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ep601", "is_robot_indexable": true, "report_reasons": null, "author": "AirHamyes", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ep601/throwing_my_hat_in_the_ring_for_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/eric-hamilton/reddit_post_downloader", "subreddit_subscribers": 695677, "created_utc": 1690830880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am trying to build a cheap NAS and I will be storing a variety of data on it. It is out of my budget to buy ECC memory so I want to know if my data is vulnerable. If a bit flips and it causes a pixel in a photo to be a slightly off shade then I don't care. But if my file becomes completely unreadable then I do care. So, what types of data do I have to be worried about?", "author_fullname": "t2_3wz9ifntc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Type of Data is Sensitive to Bit Flips?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f0si6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690860152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to build a cheap NAS and I will be storing a variety of data on it. It is out of my budget to buy ECC memory so I want to know if my data is vulnerable. If a bit flips and it causes a pixel in a photo to be a slightly off shade then I don&amp;#39;t care. But if my file becomes completely unreadable then I do care. So, what types of data do I have to be worried about?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15f0si6", "is_robot_indexable": true, "report_reasons": null, "author": "Independent-Park9987", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15f0si6/what_type_of_data_is_sensitive_to_bit_flips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15f0si6/what_type_of_data_is_sensitive_to_bit_flips/", "subreddit_subscribers": 695677, "created_utc": 1690860152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guide to get YouTube content into Plex (Caution wall of text)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eroxu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_4e312", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "PleX", "selftext": "TL;DR: A wall of text describing something only a few will want to do. Probably show of been posted in data hoarders.\n\nI had some issues setting this up and running for myself so I thought I would do a guide. \n\n# My current setup\n\n* Synology DS1821+ NAS for storage and running the plex server.\n* Windows PC that downloads everything. \n* YT-DLP to download the videos\n* I rename files with ReNamer \n\n# Storage Setup\n\nCreate a directory that your Plex server can reach that only your YouTube content will be placed into. \n\n# Plex Setup\n\nYou need to download and install the [personal media scanner](https://bitbucket.org/mjarends/plex-scanners/src/master/) and the [personal media agent](https://bitbucket.org/mjarends/extendedpersonalmedia-agent.bundle/src/master/).\n\nFollow the instruction on how to install them from the bitbucket pages. They explain how to install them depending on what OS you are running. \n\nIn the Plex app/webpage\n\n* Click the wrench icon. \n* On the left hand panel under settings click Agents\n* In the main window click Shows\n* click Extended Personal Media Shows\n* Put a check beside Local Media Assets (TV)\n\nNow we need to create a new Library. \n\n* Under Manage on the left hand panel click Libraries\n* Click add Library in the main window\n* For type Select TV Shows\n* Name it (I named mine YouTube)\n* Click Add Folder\n* Click Browser For Media Folder\n* Select the folder you created to put the YouTube content. \n* Click Advanced \n* For Scanner select Extended Personal Media Scanner\n* For Agent select Extended Personal Media Shows\n* Click Save Changes\n\n# YT-DLP scripts\n\nWe are now ready to start adding videos. In the director with the YT-DLP from program I also have the ffmpeg. This is what is used to merge the HD video and audio together. \n\nThis is where I ran into problems. Most of the guides seem to be older and some of the options they use did not work properly.  Do not use  --write-thumbnail like most of the guides say. This will download a webp format image that Plex doesn't understand. Use --embed-thumbnail like in my scripts below. I will go into more detail on the scripts later. \n\nI am using 2 different scripts. One to download playlists from a channel and the other to download an entire channel. \n\n# Do you really need 2 scripts? \n\nIt depends on what you what to do. You may just need one. \n\nI have some youtubers what I want to download their entire channel. There are very few of these, but I wanted them to be downloaded from oldest to newest. There are other youtubers what I just want to download certain playlists. This is most of them. \n\nDownloading playlists from a YouTube channel \n\n    yt-dlp^\n     -ci^\n     -o \"../dl.folder/%%(uploader)s/%%(playlist)s/%%(playlist)s - S01E%%(playlist_index)s - %%(title)s [%%(id)s].%%(ext)s\"^\n     --download-archive archive.txt^\n     --add-metadata^\n     --embed-thumbnail^\n     -f bestvideo[ext=mp4]+bestaudio[ext=m4a]^\n     --merge-output-format mp4^\n     --batch-file=channel_list.txt\n\nDownloading an entire YouTube channel \n\n    yt-dlp^\n     -ci^\n     --playlist-reverse^\n     -o \"../dl.folder/%%(uploader)s/%%(playlist)s/%%(playlist)s - S01E%%(playlist_autonumber)s - %%(title)s [%%(id)s].%%(ext)s\"^\n     --download-archive archive.txt^\n     --add-metadata^\n     --embed-thumbnail^\n     -f bestvideo[ext=mp4]+bestaudio[ext=m4a]^\n     --merge-output-format mp4^\n     --batch-file=list.txt\n\nAs you can see the scripts are very similar. I am using these in a .bat file on windows that I run from the command line. \n\nScript break down (The \\^ at the end of each line is how you split a long command between lines in windows.)\n\n* yt-dlp: This calls the program\n* \\-ci: The c resumes downloads. The i ignores errors.\n* \\--playlist-reverse: This is our first difference. YouTube displays videos from newest to oldest. I want them from oldest to newest. This reverses the list to the way I want them. Playlists are normally listed from oldest to newest already do it's not needed for them. \n*  \\-o \"../dl.folder/%%(uploader)s/%%(playlist)s/%%(playlist)s - S01E%%(playlist\\_autonumber)s - %%(title)s \\[%%(id)s\\].%%(ext)s\": This is where to write the files and now to name them.\n   * They are put into a folder called dl.folder. In that folder they will be put into a folder called the Youtubers name. Next will be a folder named after the playlist. \n   * The files will be named after the playlist with a season and episode number. \n   * Example of a file name: Minecraft - All The Mods - S01EP01 - A new start \\[hfuedi8\\].mp4\n   * For playlists you want to use the playlist\\_index. This is because you want to have them the same number as in the playlist. If you are downloading an entire YouTube channel you want to use playlist\\_autonumber. This is because you reversed the order but it will still make the newest video 1. Using playlist\\_autonumber will make the oldest video number 1. \n   * Title puts the title of the video\n   * ID is the youtube id of the video. This is useful if you ever need to remove it from the archive.txt file so you can redownload it. \n* \\--download-archive archive.txt: This prevents you from downloading a file you have already downloaded.\n*  \\--add-metadata: This embeds the metadata from the youtube video into the file \n*  \\--embed-thumbnail: This embeds the thumbnail from the youtube video into the file \n*  \\-f bestvideo\\[ext=mp4\\]+bestaudio\\[ext=m4a\\]: Downloads the best quality video and audio youtube has of the file. \n*  \\--merge-output-format mp4: makes sure the output file will be mp4\n*  \\--batch-file=list.txt: This is where you put a list of url's to download. \n\n# Plex Oddities you have to deal with\n\nSome people may see I posted a help question about things not showing up in Plex. This is due to how Plex detects shows. This part took me a few hours to figure out. \n\nOnce you have added a few things to Plex and scanned the library files you may notice some oddities. The channels that you download the entire channel from show up with no issues. The channels that you downloaded playlists from only show the first playlist but no others. I spun my wheels on this for some time. The solution is to use a program like ReNamer and change the season of the playlists videos. \n\nConfused? let be break it down for you. \n\nYou have 3 playlist downloaded from JohnDoe. They are in 3 directories named after the playlists called Minecraft 1, Starcraft 1, and WOW 1. Inside each of those directories are the videos from the playlist. \n\nThey will be named like this.\n\n* Minecraft 1 - S01E01 - start \\[4u832h\\].mp4\n* Starcraft 1 - S01E01 - start \\[2bwjsd\\].mp4\n* WOW 1 - S01E01 - start \\[fnbdjk89\\].mp4\n\nYou need to rename the files in the Startcraft 1 and WOW 1 directors as follows.\n\n* Starcraft 1 - S02E01 - start \\[2bwjsd\\].mp4\n* WOW 1 - S03E01 - start \\[fnbdjk89\\].mp4\n\nTo do this quickly I use R3Namer.\n\nDoing this lets Plex know they are different. \n\n# Last part\n\nIf you don't care about the channel picture and things like that you are done. If you want the channel art/profile pic then you need to change the meta data in Plex for each channel. Go into your YouTube Library and select the pencil icon. This is where you will rename your channel if you don't like the name Plex assigned to it. It is also where you will add the youtubers icon if you want. To get this I just go to youtubers channel and rick click on their profile pic and save it to my computer. From there in Plex click Poster and drag the image you just downloaded into it. You will need to do this for each YouTube channel. \n\nIf anyone has questions please ask, I will try to answer them. ", "author_fullname": "t2_4e312", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guide to get YouTube content into Plex (Caution wall of text)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/PleX", "hidden": false, "pwls": 6, "link_flair_css_class": "tips", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ero6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tips", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690836613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.PleX", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR: A wall of text describing something only a few will want to do. Probably show of been posted in data hoarders.&lt;/p&gt;\n\n&lt;p&gt;I had some issues setting this up and running for myself so I thought I would do a guide. &lt;/p&gt;\n\n&lt;h1&gt;My current setup&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Synology DS1821+ NAS for storage and running the plex server.&lt;/li&gt;\n&lt;li&gt;Windows PC that downloads everything. &lt;/li&gt;\n&lt;li&gt;YT-DLP to download the videos&lt;/li&gt;\n&lt;li&gt;I rename files with ReNamer &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Storage Setup&lt;/h1&gt;\n\n&lt;p&gt;Create a directory that your Plex server can reach that only your YouTube content will be placed into. &lt;/p&gt;\n\n&lt;h1&gt;Plex Setup&lt;/h1&gt;\n\n&lt;p&gt;You need to download and install the &lt;a href=\"https://bitbucket.org/mjarends/plex-scanners/src/master/\"&gt;personal media scanner&lt;/a&gt; and the &lt;a href=\"https://bitbucket.org/mjarends/extendedpersonalmedia-agent.bundle/src/master/\"&gt;personal media agent&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Follow the instruction on how to install them from the bitbucket pages. They explain how to install them depending on what OS you are running. &lt;/p&gt;\n\n&lt;p&gt;In the Plex app/webpage&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Click the wrench icon. &lt;/li&gt;\n&lt;li&gt;On the left hand panel under settings click Agents&lt;/li&gt;\n&lt;li&gt;In the main window click Shows&lt;/li&gt;\n&lt;li&gt;click Extended Personal Media Shows&lt;/li&gt;\n&lt;li&gt;Put a check beside Local Media Assets (TV)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Now we need to create a new Library. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Under Manage on the left hand panel click Libraries&lt;/li&gt;\n&lt;li&gt;Click add Library in the main window&lt;/li&gt;\n&lt;li&gt;For type Select TV Shows&lt;/li&gt;\n&lt;li&gt;Name it (I named mine YouTube)&lt;/li&gt;\n&lt;li&gt;Click Add Folder&lt;/li&gt;\n&lt;li&gt;Click Browser For Media Folder&lt;/li&gt;\n&lt;li&gt;Select the folder you created to put the YouTube content. &lt;/li&gt;\n&lt;li&gt;Click Advanced &lt;/li&gt;\n&lt;li&gt;For Scanner select Extended Personal Media Scanner&lt;/li&gt;\n&lt;li&gt;For Agent select Extended Personal Media Shows&lt;/li&gt;\n&lt;li&gt;Click Save Changes&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;YT-DLP scripts&lt;/h1&gt;\n\n&lt;p&gt;We are now ready to start adding videos. In the director with the YT-DLP from program I also have the ffmpeg. This is what is used to merge the HD video and audio together. &lt;/p&gt;\n\n&lt;p&gt;This is where I ran into problems. Most of the guides seem to be older and some of the options they use did not work properly.  Do not use  --write-thumbnail like most of the guides say. This will download a webp format image that Plex doesn&amp;#39;t understand. Use --embed-thumbnail like in my scripts below. I will go into more detail on the scripts later. &lt;/p&gt;\n\n&lt;p&gt;I am using 2 different scripts. One to download playlists from a channel and the other to download an entire channel. &lt;/p&gt;\n\n&lt;h1&gt;Do you really need 2 scripts?&lt;/h1&gt;\n\n&lt;p&gt;It depends on what you what to do. You may just need one. &lt;/p&gt;\n\n&lt;p&gt;I have some youtubers what I want to download their entire channel. There are very few of these, but I wanted them to be downloaded from oldest to newest. There are other youtubers what I just want to download certain playlists. This is most of them. &lt;/p&gt;\n\n&lt;p&gt;Downloading playlists from a YouTube channel &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;yt-dlp^\n -ci^\n -o &amp;quot;../dl.folder/%%(uploader)s/%%(playlist)s/%%(playlist)s - S01E%%(playlist_index)s - %%(title)s [%%(id)s].%%(ext)s&amp;quot;^\n --download-archive archive.txt^\n --add-metadata^\n --embed-thumbnail^\n -f bestvideo[ext=mp4]+bestaudio[ext=m4a]^\n --merge-output-format mp4^\n --batch-file=channel_list.txt\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Downloading an entire YouTube channel &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;yt-dlp^\n -ci^\n --playlist-reverse^\n -o &amp;quot;../dl.folder/%%(uploader)s/%%(playlist)s/%%(playlist)s - S01E%%(playlist_autonumber)s - %%(title)s [%%(id)s].%%(ext)s&amp;quot;^\n --download-archive archive.txt^\n --add-metadata^\n --embed-thumbnail^\n -f bestvideo[ext=mp4]+bestaudio[ext=m4a]^\n --merge-output-format mp4^\n --batch-file=list.txt\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;As you can see the scripts are very similar. I am using these in a .bat file on windows that I run from the command line. &lt;/p&gt;\n\n&lt;p&gt;Script break down (The ^ at the end of each line is how you split a long command between lines in windows.)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;yt-dlp: This calls the program&lt;/li&gt;\n&lt;li&gt;-ci: The c resumes downloads. The i ignores errors.&lt;/li&gt;\n&lt;li&gt;--playlist-reverse: This is our first difference. YouTube displays videos from newest to oldest. I want them from oldest to newest. This reverses the list to the way I want them. Playlists are normally listed from oldest to newest already do it&amp;#39;s not needed for them. &lt;/li&gt;\n&lt;li&gt; -o &amp;quot;../dl.folder/%%(uploader)s/%%(playlist)s/%%(playlist)s - S01E%%(playlist_autonumber)s - %%(title)s [%%(id)s].%%(ext)s&amp;quot;: This is where to write the files and now to name them.\n\n&lt;ul&gt;\n&lt;li&gt;They are put into a folder called dl.folder. In that folder they will be put into a folder called the Youtubers name. Next will be a folder named after the playlist. &lt;/li&gt;\n&lt;li&gt;The files will be named after the playlist with a season and episode number. &lt;/li&gt;\n&lt;li&gt;Example of a file name: Minecraft - All The Mods - S01EP01 - A new start [hfuedi8].mp4&lt;/li&gt;\n&lt;li&gt;For playlists you want to use the playlist_index. This is because you want to have them the same number as in the playlist. If you are downloading an entire YouTube channel you want to use playlist_autonumber. This is because you reversed the order but it will still make the newest video 1. Using playlist_autonumber will make the oldest video number 1. &lt;/li&gt;\n&lt;li&gt;Title puts the title of the video&lt;/li&gt;\n&lt;li&gt;ID is the youtube id of the video. This is useful if you ever need to remove it from the archive.txt file so you can redownload it. &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;--download-archive archive.txt: This prevents you from downloading a file you have already downloaded.&lt;/li&gt;\n&lt;li&gt; --add-metadata: This embeds the metadata from the youtube video into the file &lt;/li&gt;\n&lt;li&gt; --embed-thumbnail: This embeds the thumbnail from the youtube video into the file &lt;/li&gt;\n&lt;li&gt; -f bestvideo[ext=mp4]+bestaudio[ext=m4a]: Downloads the best quality video and audio youtube has of the file. &lt;/li&gt;\n&lt;li&gt; --merge-output-format mp4: makes sure the output file will be mp4&lt;/li&gt;\n&lt;li&gt; --batch-file=list.txt: This is where you put a list of url&amp;#39;s to download. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Plex Oddities you have to deal with&lt;/h1&gt;\n\n&lt;p&gt;Some people may see I posted a help question about things not showing up in Plex. This is due to how Plex detects shows. This part took me a few hours to figure out. &lt;/p&gt;\n\n&lt;p&gt;Once you have added a few things to Plex and scanned the library files you may notice some oddities. The channels that you download the entire channel from show up with no issues. The channels that you downloaded playlists from only show the first playlist but no others. I spun my wheels on this for some time. The solution is to use a program like ReNamer and change the season of the playlists videos. &lt;/p&gt;\n\n&lt;p&gt;Confused? let be break it down for you. &lt;/p&gt;\n\n&lt;p&gt;You have 3 playlist downloaded from JohnDoe. They are in 3 directories named after the playlists called Minecraft 1, Starcraft 1, and WOW 1. Inside each of those directories are the videos from the playlist. &lt;/p&gt;\n\n&lt;p&gt;They will be named like this.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Minecraft 1 - S01E01 - start [4u832h].mp4&lt;/li&gt;\n&lt;li&gt;Starcraft 1 - S01E01 - start [2bwjsd].mp4&lt;/li&gt;\n&lt;li&gt;WOW 1 - S01E01 - start [fnbdjk89].mp4&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You need to rename the files in the Startcraft 1 and WOW 1 directors as follows.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Starcraft 1 - S02E01 - start [2bwjsd].mp4&lt;/li&gt;\n&lt;li&gt;WOW 1 - S03E01 - start [fnbdjk89].mp4&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;To do this quickly I use R3Namer.&lt;/p&gt;\n\n&lt;p&gt;Doing this lets Plex know they are different. &lt;/p&gt;\n\n&lt;h1&gt;Last part&lt;/h1&gt;\n\n&lt;p&gt;If you don&amp;#39;t care about the channel picture and things like that you are done. If you want the channel art/profile pic then you need to change the meta data in Plex for each channel. Go into your YouTube Library and select the pencil icon. This is where you will rename your channel if you don&amp;#39;t like the name Plex assigned to it. It is also where you will add the youtubers icon if you want. To get this I just go to youtubers channel and rick click on their profile pic and save it to my computer. From there in Plex click Poster and drag the image you just downloaded into it. You will need to do this for each YouTube channel. &lt;/p&gt;\n\n&lt;p&gt;If anyone has questions please ask, I will try to answer them. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 50, "id": "award_02d9ab2c-162e-4c01-8438-317a016ed3d9", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=16&amp;height=16&amp;auto=webp&amp;s=10034f3fdf8214c8377134bb60c5b832d4bbf588", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=32&amp;height=32&amp;auto=webp&amp;s=100f785bf261fa9452a5d82ee0ef0793369dbfa5", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=48&amp;height=48&amp;auto=webp&amp;s=b15d030fdfbbe4af4a5b34ab9dc90a174df40a23", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=64&amp;height=64&amp;auto=webp&amp;s=601c75be6ee30dc4b47a5c65d64dea9a185502a1", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=128&amp;height=128&amp;auto=webp&amp;s=540f36e65c0e2f1347fe32020e4a1565e3680437", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "I'm in this with you.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Take My Energy", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=16&amp;height=16&amp;auto=webp&amp;s=045db73f47a9513c44823d132b4c393ab9241b6a", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=32&amp;height=32&amp;auto=webp&amp;s=298a02e0edbb5b5e293087eeede63802cbe1d2c7", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d06d606eb23dbcd6dbe39ee0e60588c5eb89065", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=64&amp;height=64&amp;auto=webp&amp;s=ecd9854b14104a36a210028c43420f0dababd96b", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=128&amp;height=128&amp;auto=webp&amp;s=0d5d7b92c1d66aff435f2ad32e6330ca2b971f6d", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "ac1f62e2-409a-11e5-a180-0ec131dbf691", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2ql7e", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0a7bff", "id": "15ero6e", "is_robot_indexable": true, "report_reasons": null, "author": "quehegan", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/PleX/comments/15ero6e/guide_to_get_youtube_content_into_plex_caution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/PleX/comments/15ero6e/guide_to_get_youtube_content_into_plex_caution/", "subreddit_subscribers": 265669, "created_utc": 1690836613.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1690836663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.PleX", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/PleX/comments/15ero6e/guide_to_get_youtube_content_into_plex_caution/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eroxu", "is_robot_indexable": true, "report_reasons": null, "author": "quehegan", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_15ero6e", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eroxu/guide_to_get_youtube_content_into_plex_caution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/PleX/comments/15ero6e/guide_to_get_youtube_content_into_plex_caution/", "subreddit_subscribers": 695677, "created_utc": 1690836663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone know how to download all videos from a telegram channel if the videos are restricted and the channel is private. ", "author_fullname": "t2_9e9otvtc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download all videos from a telegram channel.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15f98em", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690887610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know how to download all videos from a telegram channel if the videos are restricted and the channel is private. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15f98em", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Pudding61", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15f98em/download_all_videos_from_a_telegram_channel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15f98em/download_all_videos_from_a_telegram_channel/", "subreddit_subscribers": 695677, "created_utc": 1690887610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been trying to back up a bunch of optical media I have; some games, some movies, some miscellaneous other stuff archived to optical years ago. My drive reads some discs successfully, and fails to read others; at least one of the ones which it has failed to read, reads successfully on a significantly older drive owned by a family member. As a result of this odd intersecting nonfunction, I'm uncertain how to determine the problem further; I figured this subreddit was probably my best shot for issues with obtuse media-reading problems.\n\nAttempts at broad internet searches and asking around among various tech-knowing chats have thus far turned up nothing but false leads about other things (general-case failures, drives that read nothing and discs that cannot be read by anything) and agreement that the issue is very weird.\n\nHaven't got the money to go buying a bunch of other drives (or computers, in case the issue is upstream somehow) for testing things myself, and there's only so much time I can spend testing things out on not-my-computer when I happen to visit family, so I haven't been able to test exhaustively, but this is what I've managed to find out so far:\n\nMy own drive:\n\n* [Asus BC-12B1ST](https://www.asus.com/me-en/commercial-data-storage/bc12b1st/specifications/) bought in 2016-2017.\n* Claims to support reading CDs, DVDs (including RAM and dual-layered), and Blu-Rays (including dual-layered), and writing CDs and DVDs.\n* Has successfully read: multiple music and data CDs, video Blu-Rays, and most of the data DVDs I have tried in it (including a PS3 game). I do not have any video DVDs at hand to test.\n* Has *failed* to read: Other data DVDs (A PS2 game; it is definitely DVD-ROM and not the older blue CD-based sort). \n\nThe drive at my family's house:\n\n* I do not have a model number for this one, but I'm pretty sure it was OEM hardware for a computer that came with Vista, so sometime in 2007-2009. Reads CDs and DVDs, definitely writes CDs, unsure if it writes DVDs.\n* Though I have not tested this drive with all optical media I have access to, on account of it being a good long way away, this drive *has* specifically been able to read the PS2 DVD-ROM I tried in it, confirming that the disc is not damaged.\n\nIn all cases, when a disc fails to read in my own drive, the drive spins up for a moment, then spins down, and reports to the computer that there is no disk (e.g. `dd if=/dev/sr0 of=foo.iso` reports \"no medium found\").\n\nAny ideas?", "author_fullname": "t2_p2ljo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backups from only some discs failing on otherwise-working drives - how do I even begin to diagnose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ew2xh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690847258.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been trying to back up a bunch of optical media I have; some games, some movies, some miscellaneous other stuff archived to optical years ago. My drive reads some discs successfully, and fails to read others; at least one of the ones which it has failed to read, reads successfully on a significantly older drive owned by a family member. As a result of this odd intersecting nonfunction, I&amp;#39;m uncertain how to determine the problem further; I figured this subreddit was probably my best shot for issues with obtuse media-reading problems.&lt;/p&gt;\n\n&lt;p&gt;Attempts at broad internet searches and asking around among various tech-knowing chats have thus far turned up nothing but false leads about other things (general-case failures, drives that read nothing and discs that cannot be read by anything) and agreement that the issue is very weird.&lt;/p&gt;\n\n&lt;p&gt;Haven&amp;#39;t got the money to go buying a bunch of other drives (or computers, in case the issue is upstream somehow) for testing things myself, and there&amp;#39;s only so much time I can spend testing things out on not-my-computer when I happen to visit family, so I haven&amp;#39;t been able to test exhaustively, but this is what I&amp;#39;ve managed to find out so far:&lt;/p&gt;\n\n&lt;p&gt;My own drive:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.asus.com/me-en/commercial-data-storage/bc12b1st/specifications/\"&gt;Asus BC-12B1ST&lt;/a&gt; bought in 2016-2017.&lt;/li&gt;\n&lt;li&gt;Claims to support reading CDs, DVDs (including RAM and dual-layered), and Blu-Rays (including dual-layered), and writing CDs and DVDs.&lt;/li&gt;\n&lt;li&gt;Has successfully read: multiple music and data CDs, video Blu-Rays, and most of the data DVDs I have tried in it (including a PS3 game). I do not have any video DVDs at hand to test.&lt;/li&gt;\n&lt;li&gt;Has &lt;em&gt;failed&lt;/em&gt; to read: Other data DVDs (A PS2 game; it is definitely DVD-ROM and not the older blue CD-based sort). &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The drive at my family&amp;#39;s house:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I do not have a model number for this one, but I&amp;#39;m pretty sure it was OEM hardware for a computer that came with Vista, so sometime in 2007-2009. Reads CDs and DVDs, definitely writes CDs, unsure if it writes DVDs.&lt;/li&gt;\n&lt;li&gt;Though I have not tested this drive with all optical media I have access to, on account of it being a good long way away, this drive &lt;em&gt;has&lt;/em&gt; specifically been able to read the PS2 DVD-ROM I tried in it, confirming that the disc is not damaged.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;In all cases, when a disc fails to read in my own drive, the drive spins up for a moment, then spins down, and reports to the computer that there is no disk (e.g. &lt;code&gt;dd if=/dev/sr0 of=foo.iso&lt;/code&gt; reports &amp;quot;no medium found&amp;quot;).&lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HDmKyolnYM9spS6PqFu3lzKqrR5jgEC3cNgt3s-4uXo.jpg?auto=webp&amp;s=412f65393fdf4594bd3f83afd9e74ff36d15a471", "width": 600, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/HDmKyolnYM9spS6PqFu3lzKqrR5jgEC3cNgt3s-4uXo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b8fcd47eba628dca880b4c1c6b78ba2423fb5d37", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/HDmKyolnYM9spS6PqFu3lzKqrR5jgEC3cNgt3s-4uXo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2f2f114a5f4f65a7a76f46fd05e4c7fb947fd5c7", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/HDmKyolnYM9spS6PqFu3lzKqrR5jgEC3cNgt3s-4uXo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b769710a6e79316e81282eb70155ec21286eea75", "width": 320, "height": 320}], "variants": {}, "id": "MrdYk1imHQZ0uCnruJuh1C49GQQT0NmvWyFEPf7aOUs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ew2xh", "is_robot_indexable": true, "report_reasons": null, "author": "Qwertystop", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ew2xh/backups_from_only_some_discs_failing_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ew2xh/backups_from_only_some_discs_failing_on/", "subreddit_subscribers": 695677, "created_utc": 1690847258.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm starting now to organize my data and I'm curious how you all organize you huge amounts of data. My biggest problem is how can I find the files without searching for hours? Would a SQL table with the data typ and name and a link to the path in the folder make sense? \nHow do you solve that problem?", "author_fullname": "t2_vg8a4605", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to organize my few TBs of data in a nice way", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15esixj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690838602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m starting now to organize my data and I&amp;#39;m curious how you all organize you huge amounts of data. My biggest problem is how can I find the files without searching for hours? Would a SQL table with the data typ and name and a link to the path in the folder make sense? \nHow do you solve that problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15esixj", "is_robot_indexable": true, "report_reasons": null, "author": "elPr0fess0r96", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15esixj/i_want_to_organize_my_few_tbs_of_data_in_a_nice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15esixj/i_want_to_organize_my_few_tbs_of_data_in_a_nice/", "subreddit_subscribers": 695677, "created_utc": 1690838602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, \n\nI'm currently in the progress of digitizing all of my old cd's/dvd's with pictures from back when I was a kid. \n\nBut some of the disks are a video (in PowerPoint you can export to MP4) of a slideshow (PowerPoint slideshow with effects between images) \n\nAre there any tools you guys know that export the images.\n\nEx if an image if the same image is for 1 second, it knows that it is a picture and not a transition", "author_fullname": "t2_yl2zp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tools of extracting images from a slideshow video", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15en4xj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690827426.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690826223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently in the progress of digitizing all of my old cd&amp;#39;s/dvd&amp;#39;s with pictures from back when I was a kid. &lt;/p&gt;\n\n&lt;p&gt;But some of the disks are a video (in PowerPoint you can export to MP4) of a slideshow (PowerPoint slideshow with effects between images) &lt;/p&gt;\n\n&lt;p&gt;Are there any tools you guys know that export the images.&lt;/p&gt;\n\n&lt;p&gt;Ex if an image if the same image is for 1 second, it knows that it is a picture and not a transition&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15en4xj", "is_robot_indexable": true, "report_reasons": null, "author": "lodebakker", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15en4xj/any_tools_of_extracting_images_from_a_slideshow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15en4xj/any_tools_of_extracting_images_from_a_slideshow/", "subreddit_subscribers": 695677, "created_utc": 1690826223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I want to start storing my data on an external hard drive using the 3-2-1 method. I don't actually have that much data yet, only around 100-200GB in photos and documents. I've been looking for the cheapest per TB options, but the more reputable brands only have 1TB and up options, and every product I can find online seems to have loads of negative reviews of people saying they don't work. What should I do?\n\n I'm on a budget, so am open to other options e.g. discs if these would be more long-term (although I don't own a disc drive).\nI also don't want to pay for cloud storage as an alternative.", "author_fullname": "t2_4lcrkr37", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low capacity HDD/ SSD options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15em9ch", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690824224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I want to start storing my data on an external hard drive using the 3-2-1 method. I don&amp;#39;t actually have that much data yet, only around 100-200GB in photos and documents. I&amp;#39;ve been looking for the cheapest per TB options, but the more reputable brands only have 1TB and up options, and every product I can find online seems to have loads of negative reviews of people saying they don&amp;#39;t work. What should I do?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on a budget, so am open to other options e.g. discs if these would be more long-term (although I don&amp;#39;t own a disc drive).\nI also don&amp;#39;t want to pay for cloud storage as an alternative.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15em9ch", "is_robot_indexable": true, "report_reasons": null, "author": "komorebi1998", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15em9ch/low_capacity_hdd_ssd_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15em9ch/low_capacity_hdd_ssd_options/", "subreddit_subscribers": 695677, "created_utc": 1690824224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone! I have a PC that I want to convert into a NAS. I bought 3x6TB HDDs to create a RAID 5 system. My question to yall is this, in the future I want to be able to setup another NAS at a friend's house to backup my files for ultimate redundancy/safeguard of files, what would be your recommendation for NAS programs? Would I be able to use Synology as my NAS program or does Synology only work with Synology NAS boxes?", "author_fullname": "t2_a5x4u6bj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DIY NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eljoy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690822563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! I have a PC that I want to convert into a NAS. I bought 3x6TB HDDs to create a RAID 5 system. My question to yall is this, in the future I want to be able to setup another NAS at a friend&amp;#39;s house to backup my files for ultimate redundancy/safeguard of files, what would be your recommendation for NAS programs? Would I be able to use Synology as my NAS program or does Synology only work with Synology NAS boxes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eljoy", "is_robot_indexable": true, "report_reasons": null, "author": "21stCenturyRetard", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eljoy/diy_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eljoy/diy_nas/", "subreddit_subscribers": 695677, "created_utc": 1690822563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it moved to another site. Has it been backed up?", "author_fullname": "t2_woqd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone know what happened to itazuraneko.neocities.org", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f8as7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690884750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it moved to another site. Has it been backed up?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15f8as7", "is_robot_indexable": true, "report_reasons": null, "author": "slaiyfer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15f8as7/anyone_know_what_happened_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15f8as7/anyone_know_what_happened_to/", "subreddit_subscribers": 695677, "created_utc": 1690884750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Feel free to remove this post if it's not allowed, but recently my family has lost our copy of an episode of a house hunting show that we were on and I've been looking for it with no luck. \n\nMy family was the subject of an episode of Buy Me on HGTV on June 18, 2008 which is what I'm looking for. The episode was called \"Family Values\" in Canada and \"Quirky Victorian\" in the US because the episode was about my lesbian parents and I guess they didn't think that represented family values back then. On IMDB the episode is simply listed as \"Kim &amp; Sharon\".\n\nHoping someone has a TV archive with this and would be willing to help me out. Thanks!", "author_fullname": "t2_127d21", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any television archivist's have HGTV's Buy Me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f4l47", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690872375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Feel free to remove this post if it&amp;#39;s not allowed, but recently my family has lost our copy of an episode of a house hunting show that we were on and I&amp;#39;ve been looking for it with no luck. &lt;/p&gt;\n\n&lt;p&gt;My family was the subject of an episode of Buy Me on HGTV on June 18, 2008 which is what I&amp;#39;m looking for. The episode was called &amp;quot;Family Values&amp;quot; in Canada and &amp;quot;Quirky Victorian&amp;quot; in the US because the episode was about my lesbian parents and I guess they didn&amp;#39;t think that represented family values back then. On IMDB the episode is simply listed as &amp;quot;Kim &amp;amp; Sharon&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Hoping someone has a TV archive with this and would be willing to help me out. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15f4l47", "is_robot_indexable": true, "report_reasons": null, "author": "LordSatanHimself", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15f4l47/any_television_archivists_have_hgtvs_buy_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15f4l47/any_television_archivists_have_hgtvs_buy_me/", "subreddit_subscribers": 695677, "created_utc": 1690872375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I used the Wayback Machine but the only thing that shows up is the profile picture. ANY way at all to get the other stuff back? Are the posted photos not accesible?", "author_fullname": "t2_14uby1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Way to recover VSCO photos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f248u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690864159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used the Wayback Machine but the only thing that shows up is the profile picture. ANY way at all to get the other stuff back? Are the posted photos not accesible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15f248u", "is_robot_indexable": true, "report_reasons": null, "author": "Hontier", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15f248u/way_to_recover_vsco_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15f248u/way_to_recover_vsco_photos/", "subreddit_subscribers": 695677, "created_utc": 1690864159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two external hdds where I store infrequently used files. Let's call them Drive 1 and Drive 2. I want to transfer my 'more important' files to Drive 2, which is the newer of the two. The problem is that both drives are almost full which means I can't really transfer files from one drive to another. Is there any way that will transfer files directly from drive 1 to drive 2, as drive 2 transfers files to drive 1?", "author_fullname": "t2_avtzqkxd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extremely dumb question about moving files between drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eiy5p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690816500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two external hdds where I store infrequently used files. Let&amp;#39;s call them Drive 1 and Drive 2. I want to transfer my &amp;#39;more important&amp;#39; files to Drive 2, which is the newer of the two. The problem is that both drives are almost full which means I can&amp;#39;t really transfer files from one drive to another. Is there any way that will transfer files directly from drive 1 to drive 2, as drive 2 transfers files to drive 1?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eiy5p", "is_robot_indexable": true, "report_reasons": null, "author": "officialfe", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eiy5p/extremely_dumb_question_about_moving_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eiy5p/extremely_dumb_question_about_moving_files/", "subreddit_subscribers": 695677, "created_utc": 1690816500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I set up a parity storage pool using 4 drives. Later find out I'm probably losing space usage efficiency because it defaults to 3 drives even though it has 4. I recently popped in 4 20tb drives through hdd dock and usb connected. Then find out that I can't fully make the new space expanded on the original space because column size limits (to about 31tb).\n\nA few questions maybe you can help with.\n\n1) is it possibly to fix storage pool to accommodate all 8 of my drives (4 *8tb 4* 20tb)?\n2) should I make 2 pools anyway, one with 5 disks a second with 3?\n3) should I/do I need to redo the entire storage space (I thought expanding it would work as expected, easy as plug and add.\n4) shoukd I use a different solution like actual raid or different software raid, or migrate to something like synology (which id rather not as I literally possess all the hardware means aside from a raid card (I'm using dell poweredge t310 which I think has built in raid functions of some kind)\n\n5 please explain why powershell is better than the gui. \n\nThanks in advance for all you can provide.", "author_fullname": "t2_6g7sd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage spaces drive configuration questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eswgo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690839467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I set up a parity storage pool using 4 drives. Later find out I&amp;#39;m probably losing space usage efficiency because it defaults to 3 drives even though it has 4. I recently popped in 4 20tb drives through hdd dock and usb connected. Then find out that I can&amp;#39;t fully make the new space expanded on the original space because column size limits (to about 31tb).&lt;/p&gt;\n\n&lt;p&gt;A few questions maybe you can help with.&lt;/p&gt;\n\n&lt;p&gt;1) is it possibly to fix storage pool to accommodate all 8 of my drives (4 &lt;em&gt;8tb 4&lt;/em&gt; 20tb)?\n2) should I make 2 pools anyway, one with 5 disks a second with 3?\n3) should I/do I need to redo the entire storage space (I thought expanding it would work as expected, easy as plug and add.\n4) shoukd I use a different solution like actual raid or different software raid, or migrate to something like synology (which id rather not as I literally possess all the hardware means aside from a raid card (I&amp;#39;m using dell poweredge t310 which I think has built in raid functions of some kind)&lt;/p&gt;\n\n&lt;p&gt;5 please explain why powershell is better than the gui. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for all you can provide.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eswgo", "is_robot_indexable": true, "report_reasons": null, "author": "peacemaker2121", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eswgo/storage_spaces_drive_configuration_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eswgo/storage_spaces_drive_configuration_questions/", "subreddit_subscribers": 695677, "created_utc": 1690839467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello to everyone!\n\nI apologize for the dumb question, but I am a complete noob in the field of controllers. I am writing to ask help in choosing a controller that allows to run in IT mode (which, from what I have understood, means NON raid) capable of 8 internal sata connection (2 SAS).  \nI tried looking at the guide in the wiki, and searching in old posts, but I am not finding boards (also considering the ones used on ebay) at a reasonable price.\n\nI want to ask two things:\n\n* considering for example [this one on ebay](https://www.ebay.it/itm/142033556446), has not written \"LSI\" on the board. Is it a problem? [This one](https://amzn.eu/d/2z0ekW5) should be the same one on amazon, which has \"LSI\" brand showind on the board. Should I somehow \"trust\" more the second one for whatever reason?\n* Is that model (LSI SAS 9211-8i) capable of running in a \"non raid\" mode? in case it is, how difficult is to flash it to run in this mode?\n\nAnd, last but not least, if you have any other controller suggestion, it is welcome!!\n\nThanks in advance!", "author_fullname": "t2_3hwuhm84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SAS non raid help needed by a noob!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15esvzx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690839435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello to everyone!&lt;/p&gt;\n\n&lt;p&gt;I apologize for the dumb question, but I am a complete noob in the field of controllers. I am writing to ask help in choosing a controller that allows to run in IT mode (which, from what I have understood, means NON raid) capable of 8 internal sata connection (2 SAS).&lt;br/&gt;\nI tried looking at the guide in the wiki, and searching in old posts, but I am not finding boards (also considering the ones used on ebay) at a reasonable price.&lt;/p&gt;\n\n&lt;p&gt;I want to ask two things:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;considering for example &lt;a href=\"https://www.ebay.it/itm/142033556446\"&gt;this one on ebay&lt;/a&gt;, has not written &amp;quot;LSI&amp;quot; on the board. Is it a problem? &lt;a href=\"https://amzn.eu/d/2z0ekW5\"&gt;This one&lt;/a&gt; should be the same one on amazon, which has &amp;quot;LSI&amp;quot; brand showind on the board. Should I somehow &amp;quot;trust&amp;quot; more the second one for whatever reason?&lt;/li&gt;\n&lt;li&gt;Is that model (LSI SAS 9211-8i) capable of running in a &amp;quot;non raid&amp;quot; mode? in case it is, how difficult is to flash it to run in this mode?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And, last but not least, if you have any other controller suggestion, it is welcome!!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/G220cys7jC_I4fPueVN9fYg80rx4zZcGlP9v2JLAXNc.jpg?auto=webp&amp;s=1dcb09edd4b0f63ee7e9dfc4019fea896959a4c6", "width": 500, "height": 446}, "resolutions": [{"url": "https://external-preview.redd.it/G220cys7jC_I4fPueVN9fYg80rx4zZcGlP9v2JLAXNc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c6683d45f93bc0008fc5d1bc99694d728808bb8", "width": 108, "height": 96}, {"url": "https://external-preview.redd.it/G220cys7jC_I4fPueVN9fYg80rx4zZcGlP9v2JLAXNc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=df8ca1499e19a6a2bdb748463dcadb66d4b1a86f", "width": 216, "height": 192}, {"url": "https://external-preview.redd.it/G220cys7jC_I4fPueVN9fYg80rx4zZcGlP9v2JLAXNc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b39ec64a724124d69a37c82bbae0cc9875770999", "width": 320, "height": 285}], "variants": {}, "id": "z7atrJOEcpXG5npbIoODYr0ojbewMGpRJwBMYS9yIbQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15esvzx", "is_robot_indexable": true, "report_reasons": null, "author": "Landomix", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15esvzx/sas_non_raid_help_needed_by_a_noob/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15esvzx/sas_non_raid_help_needed_by_a_noob/", "subreddit_subscribers": 695677, "created_utc": 1690839435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello fellow hoarders! I'm backing up gazillions of photos and videos. I know it's not really useful to compress jpeg because I guess the energy and processor spent on it doesn't really pay off?\n\n&amp;#x200B;\n\nI have a few questions:\n\n**1)** I found myself with several tar.gz files weighing more than 50GB in size. And then I remembered all the errors I get with large .zip files and I got a bit worried my data will get corrupted.\n\nAny recommendation at what size should I split it? Also any command like recipes that work for you in terms of splitting size, naming convention etc?\n\n&amp;#x200B;\n\n**2)** Do you have a preferred structure for your backup drives? I have date+time +description+extension, f.e: `20220601_0110_iphone_backup.tar.gz` but imagine I split a 60GB tar.gz in several parts, should I save those parts in a directory?\n\n**2a)** I 've been compressing my photos and videos with a README.txt files with notes on the same tar file, however, I was thinking of making the tar file a bit more like:\n\n    tarfile.tar.gz\n    \u251c\u2500\u2500 files\\\n    \u2514\u2500\u2500 README.txt\n\nI always preferred to have a removable drive with the tar files there and simply \\`ls\\` them and see the files and see what to do with them.\n\nI reckon my backup is still not large enough, only a dozen or so files. I guess as it grows I will want to split it in different dirs by year etc etc?\n\n&amp;#x200B;\n\nWhat do you recommend as a minimalist structure to store my backups?\n\n&amp;#x200B;\n\nThanks a lot in advance!", "author_fullname": "t2_2rewrxo6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sweet sport for tar.gz file sizes? Any other compression format recommended? Storing sorting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f1hxj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690862281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow hoarders! I&amp;#39;m backing up gazillions of photos and videos. I know it&amp;#39;s not really useful to compress jpeg because I guess the energy and processor spent on it doesn&amp;#39;t really pay off?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have a few questions:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1)&lt;/strong&gt; I found myself with several tar.gz files weighing more than 50GB in size. And then I remembered all the errors I get with large .zip files and I got a bit worried my data will get corrupted.&lt;/p&gt;\n\n&lt;p&gt;Any recommendation at what size should I split it? Also any command like recipes that work for you in terms of splitting size, naming convention etc?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2)&lt;/strong&gt; Do you have a preferred structure for your backup drives? I have date+time +description+extension, f.e: &lt;code&gt;20220601_0110_iphone_backup.tar.gz&lt;/code&gt; but imagine I split a 60GB tar.gz in several parts, should I save those parts in a directory?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2a)&lt;/strong&gt; I &amp;#39;ve been compressing my photos and videos with a README.txt files with notes on the same tar file, however, I was thinking of making the tar file a bit more like:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;tarfile.tar.gz\n\u251c\u2500\u2500 files\\\n\u2514\u2500\u2500 README.txt\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I always preferred to have a removable drive with the tar files there and simply `ls` them and see the files and see what to do with them.&lt;/p&gt;\n\n&lt;p&gt;I reckon my backup is still not large enough, only a dozen or so files. I guess as it grows I will want to split it in different dirs by year etc etc?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What do you recommend as a minimalist structure to store my backups?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15f1hxj", "is_robot_indexable": true, "report_reasons": null, "author": "iPodClassic7", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15f1hxj/sweet_sport_for_targz_file_sizes_any_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15f1hxj/sweet_sport_for_targz_file_sizes_any_other/", "subreddit_subscribers": 695677, "created_utc": 1690862281.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a D5-300 unit with 5x 16TB Seagate Exos X18 drives. I initially set it up as RAID5 via MacOS using the provided Raid Manager utility. All went well and I ended up with a 64TB single drive exposed to the OS. I then connected the TDAS to my Linux mini pc (Beelink S-12 Mini / Debian 12) and formatted it as ext4. All was well again. This was around a month ago. The D5-300 and the Mini PC were never turned off since (I have UPS, so no power outages either) and I accumulated around 45TB of data. Today I bought another mini PC (Beelink EQ12 Pro) to replace my old one. I powered off cleanly my old PC, disconnected all cables, swapped the nvme drive, reconnected all cables to my new pc, booted into Linux and lo and behold I was greeted with 5 separate 16TB hard drives in dmesg:\n\n    [Mon Jul 31 16:39:33 2023] usb 2-4: new SuperSpeed USB device number 4 using xhci_hcd\n    [Mon Jul 31 16:39:33 2023] usb 2-4: New USB device found, idVendor=152d, idProduct=0576, bcdDevice=71.02\n    [Mon Jul 31 16:39:33 2023] usb 2-4: New USB device strings: Mfr=1, Product=2, SerialNumber=3\n    [Mon Jul 31 16:39:33 2023] usb 2-4: Product: TDAS\n    [Mon Jul 31 16:39:33 2023] usb 2-4: Manufacturer: JMicron\n    [Mon Jul 31 16:39:33 2023] usb 2-4: SerialNumber: 202207223AFD\n    [Mon Jul 31 16:39:33 2023] usb-storage 2-4:1.0: USB Mass Storage device detected\n    [Mon Jul 31 16:39:33 2023] scsi host3: usb-storage 2-4:1.0\n    [Mon Jul 31 16:39:34 2023] scsi 3:0:0:0: Direct-Access     ST16000N M001J-2TW113     7102 PQ: 0 ANSI: 6\n    [Mon Jul 31 16:39:34 2023] scsi 3:0:0:1: Direct-Access     ST16000N M001J-2TW113     7102 PQ: 0 ANSI: 6\n    [Mon Jul 31 16:39:34 2023] scsi 3:0:0:2: Direct-Access     ST16000N M000J-2TW103     7102 PQ: 0 ANSI: 6\n    [Mon Jul 31 16:39:34 2023] scsi 3:0:0:3: Direct-Access     ST16000N M000J-2TW103     7102 PQ: 0 ANSI: 6\n    [Mon Jul 31 16:39:34 2023] scsi 3:0:0:4: Direct-Access     ST16000N M000J-2TW103     7102 PQ: 0 ANSI: 6\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:0: Attached scsi generic sg3 type 0\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] Very big device. Trying to use READ CAPACITY(16).\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] 31251759104 512-byte logical blocks: (16.0 TB/14.6 TiB)\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] 4096-byte physical blocks\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:1: Attached scsi generic sg4 type 0\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] Very big device. Trying to use READ CAPACITY(16).\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:2: Attached scsi generic sg5 type 0\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] Write Protect is off\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] Mode Sense: 47 00 00 08\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] 31251759104 512-byte logical blocks: (16.0 TB/14.6 TiB)\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] 4096-byte physical blocks\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:3: Attached scsi generic sg6 type 0\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] Very big device. Trying to use READ CAPACITY(16).\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] Write Protect is off\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] Mode Sense: 47 00 00 08\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] Very big device. Trying to use READ CAPACITY(16).\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] 31251759104 512-byte logical blocks: (16.0 TB/14.6 TiB)\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] 4096-byte physical blocks\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:4: Attached scsi generic sg7 type 0\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] Very big device. Trying to use READ CAPACITY(16).\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] 31251759104 512-byte logical blocks: (16.0 TB/14.6 TiB)\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] 4096-byte physical blocks\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] Write Protect is off\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] Mode Sense: 47 00 00 08\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] 31251759104 512-byte logical blocks: (16.0 TB/14.6 TiB)\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] 4096-byte physical blocks\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] Write Protect is off\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] Mode Sense: 47 00 00 08\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] Write Protect is off\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] Mode Sense: 47 00 00 08\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] Attached SCSI disk\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] Attached SCSI disk\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] Attached SCSI disk\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] Attached SCSI disk\n    [Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] Attached SCSI disk\n\nIt looks like the built-in RAID chip somehow forgot its configuration just by reconnecting the USB cable to another PC. I didn't even power-cycle the unit.\n\nI immediately disconnected the USB cable and connected it to my Mac, only to confirm that the official RAID Manager software reported that all my drives are empty and not part of any array: [https://imgur.com/gfIPXCe](https://imgur.com/gfIPXCe)\n\nNeedless to say I am now crushed since this data represents a month of hard work and I don't have full backups of everything.\n\nIs it possible somehow to restore the state of the RAID5 array on the chip? I am afraid to try anything else since I don't want to rewrite some data on the hdd's. Any help will be greatly appreciated.", "author_fullname": "t2_j5vc7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Terramaster D5-300 Suddenly lost a 64TB RAID5 array. All drives uninitialized", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15elx9d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690823437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a D5-300 unit with 5x 16TB Seagate Exos X18 drives. I initially set it up as RAID5 via MacOS using the provided Raid Manager utility. All went well and I ended up with a 64TB single drive exposed to the OS. I then connected the TDAS to my Linux mini pc (Beelink S-12 Mini / Debian 12) and formatted it as ext4. All was well again. This was around a month ago. The D5-300 and the Mini PC were never turned off since (I have UPS, so no power outages either) and I accumulated around 45TB of data. Today I bought another mini PC (Beelink EQ12 Pro) to replace my old one. I powered off cleanly my old PC, disconnected all cables, swapped the nvme drive, reconnected all cables to my new pc, booted into Linux and lo and behold I was greeted with 5 separate 16TB hard drives in dmesg:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[Mon Jul 31 16:39:33 2023] usb 2-4: new SuperSpeed USB device number 4 using xhci_hcd\n[Mon Jul 31 16:39:33 2023] usb 2-4: New USB device found, idVendor=152d, idProduct=0576, bcdDevice=71.02\n[Mon Jul 31 16:39:33 2023] usb 2-4: New USB device strings: Mfr=1, Product=2, SerialNumber=3\n[Mon Jul 31 16:39:33 2023] usb 2-4: Product: TDAS\n[Mon Jul 31 16:39:33 2023] usb 2-4: Manufacturer: JMicron\n[Mon Jul 31 16:39:33 2023] usb 2-4: SerialNumber: 202207223AFD\n[Mon Jul 31 16:39:33 2023] usb-storage 2-4:1.0: USB Mass Storage device detected\n[Mon Jul 31 16:39:33 2023] scsi host3: usb-storage 2-4:1.0\n[Mon Jul 31 16:39:34 2023] scsi 3:0:0:0: Direct-Access     ST16000N M001J-2TW113     7102 PQ: 0 ANSI: 6\n[Mon Jul 31 16:39:34 2023] scsi 3:0:0:1: Direct-Access     ST16000N M001J-2TW113     7102 PQ: 0 ANSI: 6\n[Mon Jul 31 16:39:34 2023] scsi 3:0:0:2: Direct-Access     ST16000N M000J-2TW103     7102 PQ: 0 ANSI: 6\n[Mon Jul 31 16:39:34 2023] scsi 3:0:0:3: Direct-Access     ST16000N M000J-2TW103     7102 PQ: 0 ANSI: 6\n[Mon Jul 31 16:39:34 2023] scsi 3:0:0:4: Direct-Access     ST16000N M000J-2TW103     7102 PQ: 0 ANSI: 6\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:0: Attached scsi generic sg3 type 0\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] Very big device. Trying to use READ CAPACITY(16).\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] 31251759104 512-byte logical blocks: (16.0 TB/14.6 TiB)\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] 4096-byte physical blocks\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:1: Attached scsi generic sg4 type 0\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] Very big device. Trying to use READ CAPACITY(16).\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:2: Attached scsi generic sg5 type 0\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] Write Protect is off\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] Mode Sense: 47 00 00 08\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] 31251759104 512-byte logical blocks: (16.0 TB/14.6 TiB)\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] 4096-byte physical blocks\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:3: Attached scsi generic sg6 type 0\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] Write cache: enabled, read cache: enabled, doesn&amp;#39;t support DPO or FUA\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] Very big device. Trying to use READ CAPACITY(16).\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] Write Protect is off\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] Mode Sense: 47 00 00 08\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] Very big device. Trying to use READ CAPACITY(16).\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] 31251759104 512-byte logical blocks: (16.0 TB/14.6 TiB)\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] 4096-byte physical blocks\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:4: Attached scsi generic sg7 type 0\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] Write cache: enabled, read cache: enabled, doesn&amp;#39;t support DPO or FUA\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] Very big device. Trying to use READ CAPACITY(16).\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] 31251759104 512-byte logical blocks: (16.0 TB/14.6 TiB)\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] 4096-byte physical blocks\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] Write Protect is off\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] Mode Sense: 47 00 00 08\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] 31251759104 512-byte logical blocks: (16.0 TB/14.6 TiB)\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] 4096-byte physical blocks\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] Write Protect is off\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] Mode Sense: 47 00 00 08\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] Write cache: enabled, read cache: enabled, doesn&amp;#39;t support DPO or FUA\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] Write Protect is off\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] Mode Sense: 47 00 00 08\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] Write cache: enabled, read cache: enabled, doesn&amp;#39;t support DPO or FUA\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] Write cache: enabled, read cache: enabled, doesn&amp;#39;t support DPO or FUA\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:1: [sdd] Attached SCSI disk\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:2: [sde] Attached SCSI disk\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:3: [sdf] Attached SCSI disk\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:4: [sdg] Attached SCSI disk\n[Mon Jul 31 16:39:34 2023] sd 3:0:0:0: [sdc] Attached SCSI disk\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;It looks like the built-in RAID chip somehow forgot its configuration just by reconnecting the USB cable to another PC. I didn&amp;#39;t even power-cycle the unit.&lt;/p&gt;\n\n&lt;p&gt;I immediately disconnected the USB cable and connected it to my Mac, only to confirm that the official RAID Manager software reported that all my drives are empty and not part of any array: &lt;a href=\"https://imgur.com/gfIPXCe\"&gt;https://imgur.com/gfIPXCe&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Needless to say I am now crushed since this data represents a month of hard work and I don&amp;#39;t have full backups of everything.&lt;/p&gt;\n\n&lt;p&gt;Is it possible somehow to restore the state of the RAID5 array on the chip? I am afraid to try anything else since I don&amp;#39;t want to rewrite some data on the hdd&amp;#39;s. Any help will be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_eJe3OJ_IvM2BJVBwn6PsJ6nsDF5aI16x8abmI3pR9o.jpg?auto=webp&amp;s=4b2c5a177e9a89c009f8ebdf0408461aff74ce2f", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/_eJe3OJ_IvM2BJVBwn6PsJ6nsDF5aI16x8abmI3pR9o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=07c9dc7880c422c721af375aa11b5ee4b344c9af", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/_eJe3OJ_IvM2BJVBwn6PsJ6nsDF5aI16x8abmI3pR9o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b79a31d251823f10a8043c31533fa5f33d567033", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/_eJe3OJ_IvM2BJVBwn6PsJ6nsDF5aI16x8abmI3pR9o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e7f995c9148029f110fbc69d8c5e01165046118", "width": 320, "height": 168}], "variants": {}, "id": "8QTYeM2imXJSBkMt8eA9Hizgi7or2B-_7NWd3CIw4xM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15elx9d", "is_robot_indexable": true, "report_reasons": null, "author": "Jacketbg", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15elx9d/terramaster_d5300_suddenly_lost_a_64tb_raid5/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15elx9d/terramaster_d5300_suddenly_lost_a_64tb_raid5/", "subreddit_subscribers": 695677, "created_utc": 1690823437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "(Disclaimer: This isn't a complaint about their services, but a warning/note to future users to not make the mistake that I did.)\n\nTelnyx is a company that's been known pretty well in the field of SIP trunking and related VoIP services, but recently it appears they've been branching out a bit by offering an S3 bucket service. Their offerings are pretty promising, such as $0.004/GB per month, no egress fees, etc. and some may consider them over other, more typical options such as Backblaze B2. However, it's important to note that while their SIP related services are pretty friendly to the average homelabber, their storage services are a completely different beast. This is even reflected in their terms and conditions, where their main acceptable use page makes no mention of any S3-specific rules or limits. This was where I made my mistake, as they have a different acceptable use page for their storage services that is not linked anywhere in the main T&amp;C page. According to the Telnyx Storage terms and conditions, \"Storage Content may not be deleted by Customer for at least 180 days after such Storage Content is uploaded\". The threshold for when they start taking action seems really low, as I just tested it out by uploading ~100mb with rclone, then deleting the bucket after I was done. It's especially dangerous as they have no safeguards or warnings when you're actually deleting data that's less than 180 days old, they'll just send you an email stating that your account was terminated for violation of the acceptable use policy, which may catch some users who may have read the normal T&amp;C but not the S3-specific T&amp;C off guard.", "author_fullname": "t2_th84t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Telnyx Storage: a relatively new option for S3 cloud storage, and a warning for those unaware.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15eunfm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690843663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Disclaimer: This isn&amp;#39;t a complaint about their services, but a warning/note to future users to not make the mistake that I did.)&lt;/p&gt;\n\n&lt;p&gt;Telnyx is a company that&amp;#39;s been known pretty well in the field of SIP trunking and related VoIP services, but recently it appears they&amp;#39;ve been branching out a bit by offering an S3 bucket service. Their offerings are pretty promising, such as $0.004/GB per month, no egress fees, etc. and some may consider them over other, more typical options such as Backblaze B2. However, it&amp;#39;s important to note that while their SIP related services are pretty friendly to the average homelabber, their storage services are a completely different beast. This is even reflected in their terms and conditions, where their main acceptable use page makes no mention of any S3-specific rules or limits. This was where I made my mistake, as they have a different acceptable use page for their storage services that is not linked anywhere in the main T&amp;amp;C page. According to the Telnyx Storage terms and conditions, &amp;quot;Storage Content may not be deleted by Customer for at least 180 days after such Storage Content is uploaded&amp;quot;. The threshold for when they start taking action seems really low, as I just tested it out by uploading ~100mb with rclone, then deleting the bucket after I was done. It&amp;#39;s especially dangerous as they have no safeguards or warnings when you&amp;#39;re actually deleting data that&amp;#39;s less than 180 days old, they&amp;#39;ll just send you an email stating that your account was terminated for violation of the acceptable use policy, which may catch some users who may have read the normal T&amp;amp;C but not the S3-specific T&amp;amp;C off guard.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15eunfm", "is_robot_indexable": true, "report_reasons": null, "author": "kirbyofdeath_r", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15eunfm/telnyx_storage_a_relatively_new_option_for_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15eunfm/telnyx_storage_a_relatively_new_option_for_s3/", "subreddit_subscribers": 695677, "created_utc": 1690843663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am an avid photographer and currently trying to figure out a solution for archival storage of digital photos. I don't have much data (probably around 50GB of photos that I need archival storage for) and I am trying to find a solution. I am currently looking into [forever.com](https://forever.com) which I can get 25GB of storage for $500 one time purchase. Platforms like Google Drive are much cheaper, but I would like to store my photos in a way for the next generation, not on a platform that will delete them if I don't log in for 2 years.\n\nI have been in two house fires, three home break-ins, and a car fire so the idea of an \"archival\" cloud data storage platform is very appealing to me because of the \"off-site\" aspect. My career path will necessitate being on the road a lot so being able to access my files via the internet is also appealing. Currently, my data is stored on external SSD drives onsite, and I am in the process of organizing it. My other idea for storage would be to burn my files to archival disks (M-Disks or Gold CDs) and put one copy in a safety deposit box at the bank. ", "author_fullname": "t2_anq99ucy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Curious about possibly using forever.com for archival data storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ehkxp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690813338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am an avid photographer and currently trying to figure out a solution for archival storage of digital photos. I don&amp;#39;t have much data (probably around 50GB of photos that I need archival storage for) and I am trying to find a solution. I am currently looking into &lt;a href=\"https://forever.com\"&gt;forever.com&lt;/a&gt; which I can get 25GB of storage for $500 one time purchase. Platforms like Google Drive are much cheaper, but I would like to store my photos in a way for the next generation, not on a platform that will delete them if I don&amp;#39;t log in for 2 years.&lt;/p&gt;\n\n&lt;p&gt;I have been in two house fires, three home break-ins, and a car fire so the idea of an &amp;quot;archival&amp;quot; cloud data storage platform is very appealing to me because of the &amp;quot;off-site&amp;quot; aspect. My career path will necessitate being on the road a lot so being able to access my files via the internet is also appealing. Currently, my data is stored on external SSD drives onsite, and I am in the process of organizing it. My other idea for storage would be to burn my files to archival disks (M-Disks or Gold CDs) and put one copy in a safety deposit box at the bank. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?auto=webp&amp;s=65dbedcb068da581966f5196951c432c69971c1e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=edc01860d42dff717b5b11d3b962fdbd84116b43", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c9159a7ec316c5ecb3c112dda0f9333ff1cab8ed", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1fe852d3a89892330da2a19011c0527f73d7cd5c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ef243569974ba06c9b70257be7dd0439d08791b7", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f074ede3445e0abee23f5a1a7ff388c3d8a46100", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/mPpiq9cWACO2rTf8J6rCcXPiWdKYry7OVIJCPFBozos.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ffbfdde4cf737a6123c36c57b523e673c0ab1812", "width": 1080, "height": 540}], "variants": {}, "id": "3SlCuZWYt-8SZVmQaJ7_HkK995EvwU_V0EJxSNJX8dA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ehkxp", "is_robot_indexable": true, "report_reasons": null, "author": "RadioOperator73", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ehkxp/curious_about_possibly_using_forevercom_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ehkxp/curious_about_possibly_using_forevercom_for/", "subreddit_subscribers": 695677, "created_utc": 1690813338.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am 'backing up my multiple reddit user profiles' using a bespoke app, and have noticed recently that .gif images seem to have become a popular format amongst files I have downloaded from reddit using this app.\n\nThese '.gif's are not gifs though - they seem to be mp4/webm encapsulated within a .gif mime type, the issue with this being that attempting to download the video by direct hotlink to the media results in reddit serving me (very slowly) an ENORMOUS .gif file. Quite often files over 80Mb each, and including reposts on the same profile, this has become burdensome.\n\nI am assuming that the underlying media is not actually a .gif, and that every page load (that loads the media instantly) is not serving an 80Mb file.\n\nHas anyone found a way to access alternate streams with better compression/alternate bitrates via URL? Anyone else encountering this issue? I have explored the requests the page is making and have not found any alternate streams in either the requests or the page source, certainly nothing that I have been able to be served.\n\n(nsfw sample media link: https://i.redd.it/sfu0z7ng4afb1.gif)", "author_fullname": "t2_5hf9geng", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit .gif's download as alternate media formats", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ekck6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.27, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690819738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am &amp;#39;backing up my multiple reddit user profiles&amp;#39; using a bespoke app, and have noticed recently that .gif images seem to have become a popular format amongst files I have downloaded from reddit using this app.&lt;/p&gt;\n\n&lt;p&gt;These &amp;#39;.gif&amp;#39;s are not gifs though - they seem to be mp4/webm encapsulated within a .gif mime type, the issue with this being that attempting to download the video by direct hotlink to the media results in reddit serving me (very slowly) an ENORMOUS .gif file. Quite often files over 80Mb each, and including reposts on the same profile, this has become burdensome.&lt;/p&gt;\n\n&lt;p&gt;I am assuming that the underlying media is not actually a .gif, and that every page load (that loads the media instantly) is not serving an 80Mb file.&lt;/p&gt;\n\n&lt;p&gt;Has anyone found a way to access alternate streams with better compression/alternate bitrates via URL? Anyone else encountering this issue? I have explored the requests the page is making and have not found any alternate streams in either the requests or the page source, certainly nothing that I have been able to be served.&lt;/p&gt;\n\n&lt;p&gt;(nsfw sample media link: &lt;a href=\"https://i.redd.it/sfu0z7ng4afb1.gif\"&gt;https://i.redd.it/sfu0z7ng4afb1.gif&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": true, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?format=png8&amp;s=6d80e1cdcc35afee15a5ec532610e71265f63e6e", "width": 312, "height": 554}, "resolutions": [{"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=ada1e75bfbcf0f43dfd9da50a4e3cc5c932537e6", "width": 108, "height": 191}, {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=77941a3932f847b6fb32544e1b1dbc97c962ee21", "width": 216, "height": 383}], "variants": {"obfuscated": {"source": {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?blur=40&amp;format=png8&amp;s=041c356553278ab2358e52e34f9754337688b0ad", "width": 312, "height": 554}, "resolutions": [{"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=108&amp;crop=smart&amp;blur=10&amp;format=png8&amp;s=0e51e5cbc607a192849198a353f8496b344039b7", "width": 108, "height": 191}, {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=216&amp;crop=smart&amp;blur=21&amp;format=png8&amp;s=80c5785785bce636e38b9223e5317e5aba59ddd8", "width": 216, "height": 383}]}, "gif": {"source": {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?s=f2e893a1abfda732de70a7d1fcf1d49cd22bef6b", "width": 312, "height": 554}, "resolutions": [{"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=108&amp;crop=smart&amp;s=74b39313035c1acbd158460b4129bde8edbc5d31", "width": 108, "height": 191}, {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=216&amp;crop=smart&amp;s=1f2cca793c88f744873bf5858af7679eb304092a", "width": 216, "height": 383}]}, "mp4": {"source": {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?format=mp4&amp;s=95433b7bdbac47e6af7a365304a62941f5a7113b", "width": 312, "height": 554}, "resolutions": [{"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=108&amp;format=mp4&amp;s=e157134d17fe57c14da6656496a213f70e729911", "width": 108, "height": 191}, {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=216&amp;format=mp4&amp;s=69feb3b691a446f85b8c840d2477123a4454b283", "width": 216, "height": 383}]}, "nsfw": {"source": {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?blur=40&amp;format=png8&amp;s=041c356553278ab2358e52e34f9754337688b0ad", "width": 312, "height": 554}, "resolutions": [{"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=108&amp;crop=smart&amp;blur=10&amp;format=png8&amp;s=0e51e5cbc607a192849198a353f8496b344039b7", "width": 108, "height": 191}, {"url": "https://external-preview.redd.it/lM1FTGIeqh-fdGVlC1_mhts_72vaT3Q3x3CZ-f1vn_c.gif?width=216&amp;crop=smart&amp;blur=21&amp;format=png8&amp;s=80c5785785bce636e38b9223e5317e5aba59ddd8", "width": 216, "height": 383}]}}, "id": "mtv6LEXuc8TTQv-0c4HKyooYkhFKGFp0Qs3-NHuDM6A"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ekck6", "is_robot_indexable": true, "report_reasons": null, "author": "far_kurnell", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ekck6/reddit_gifs_download_as_alternate_media_formats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ekck6/reddit_gifs_download_as_alternate_media_formats/", "subreddit_subscribers": 695677, "created_utc": 1690819738.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}