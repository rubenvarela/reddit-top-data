{"kind": "Listing", "data": {"after": "t3_15jufgz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just wondering if people see all three of these as being necessary. I\u2019m in an organization that has an Azure data warehouse. This gives us access to ADF. But databricks salespeople have started reaching out to us recently. \n\nThe ability to work within python and r in databricks sounds great. But how does it differ from a more sql-based tool like dbt?\n\nFor context, my background is more in data analytics/science. But our organization (from what I\u2019ve seen after being here a couple months) is in desperate need of data engineering skills. They\u2019ve gone out and hired data scientists, but their basic institutional data is a mess and in many cases not existent in the warehouse.", "author_fullname": "t2_9ytsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you need Azure Data Factory and Databricks? What about dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jxfd4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691348215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wondering if people see all three of these as being necessary. I\u2019m in an organization that has an Azure data warehouse. This gives us access to ADF. But databricks salespeople have started reaching out to us recently. &lt;/p&gt;\n\n&lt;p&gt;The ability to work within python and r in databricks sounds great. But how does it differ from a more sql-based tool like dbt?&lt;/p&gt;\n\n&lt;p&gt;For context, my background is more in data analytics/science. But our organization (from what I\u2019ve seen after being here a couple months) is in desperate need of data engineering skills. They\u2019ve gone out and hired data scientists, but their basic institutional data is a mess and in many cases not existent in the warehouse.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jxfd4", "is_robot_indexable": true, "report_reasons": null, "author": "ursamajorm82", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jxfd4/do_you_need_azure_data_factory_and_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jxfd4/do_you_need_azure_data_factory_and_databricks/", "subreddit_subscribers": 121269, "created_utc": 1691348215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a rising senior in university; I know that DE jobs are relatively harder to come by for new grads so looking for backend-ish software engineering jobs. But I hope to eventually transition into this field.\n\nI was reading [this AMA](https://www.reddit.com/r/dataengineering/comments/udboyq/comment/i6gj0iy/) and one of the commenters asked how the Netflix DE interview goes, and further into the thread, OP is asked how they would deal with an out of memory issue with Spark and answers with several options - each showing that they understand not just how to use this tool, but why certain things work the way they do.\n\nMy question - how would one come to know this? Is it experience? Book / blogs / podcasts? Someone just telling you over the course of time (e.g. me reading this AMA would prolly count)? Feels a but overwhelming. Maybe what I'm doing - reading stuff made by knowledgeable people is part of what gives you this knowledge; but how the hell do you remember it? I can probably bet that if I ran into an OOM error in Spark a year later, I would probably **not** go \"Oh this was mentioned in a random reddit AMA that one can remove duplicates and/or process outliers separately let's try that!\". I'd probably go whine to a mentor and/or hopelessly google and/or if I'm lucky, remember this reddit thread and come back to it.\n\nEven more worrying - a commenter asked \"How much understanding do you need for OOM you either  use more memory or less memory\". Which worried me because that reeks of the Dunning Kruger effect / not knowing what I know. if I do not even know what I don't know, how do I learn? How do I know that a source I'm looking it is a credible one to learn from? How would one get past this at all?", "author_fullname": "t2_1j8v22cd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you get to know all these *stuff* concerning the internals of various tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15kanjk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691383762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a rising senior in university; I know that DE jobs are relatively harder to come by for new grads so looking for backend-ish software engineering jobs. But I hope to eventually transition into this field.&lt;/p&gt;\n\n&lt;p&gt;I was reading &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/udboyq/comment/i6gj0iy/\"&gt;this AMA&lt;/a&gt; and one of the commenters asked how the Netflix DE interview goes, and further into the thread, OP is asked how they would deal with an out of memory issue with Spark and answers with several options - each showing that they understand not just how to use this tool, but why certain things work the way they do.&lt;/p&gt;\n\n&lt;p&gt;My question - how would one come to know this? Is it experience? Book / blogs / podcasts? Someone just telling you over the course of time (e.g. me reading this AMA would prolly count)? Feels a but overwhelming. Maybe what I&amp;#39;m doing - reading stuff made by knowledgeable people is part of what gives you this knowledge; but how the hell do you remember it? I can probably bet that if I ran into an OOM error in Spark a year later, I would probably &lt;strong&gt;not&lt;/strong&gt; go &amp;quot;Oh this was mentioned in a random reddit AMA that one can remove duplicates and/or process outliers separately let&amp;#39;s try that!&amp;quot;. I&amp;#39;d probably go whine to a mentor and/or hopelessly google and/or if I&amp;#39;m lucky, remember this reddit thread and come back to it.&lt;/p&gt;\n\n&lt;p&gt;Even more worrying - a commenter asked &amp;quot;How much understanding do you need for OOM you either  use more memory or less memory&amp;quot;. Which worried me because that reeks of the Dunning Kruger effect / not knowing what I know. if I do not even know what I don&amp;#39;t know, how do I learn? How do I know that a source I&amp;#39;m looking it is a credible one to learn from? How would one get past this at all?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15kanjk", "is_robot_indexable": true, "report_reasons": null, "author": "stuffingmybrain", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15kanjk/how_do_you_get_to_know_all_these_stuff_concerning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15kanjk/how_do_you_get_to_know_all_these_stuff_concerning/", "subreddit_subscribers": 121269, "created_utc": 1691383762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[edited to clarify I'm asking about what to concentrate on for a DE in context of learning python generally]  \n\nIf a practicing/aspiring DE asks  \"what python do I need for DE?\" below are my thoughts about what to concentrate on/supplement  from a \"general python\" class, would like to get feedback. The core of such classes is about general path of execution control, and using lists, dictionaries, sets and tuple, manipulating strings. All that stuff is crucial, if you have it down cold you'll be better off for both jobs and interviews. \n\nBut when general classes move on to bigger programs I'm interested in thoughts about *what's likely to be most crucial for DEs, or useful and not touched on* by such a class.\n\n\n**likely covered, but less important for a DE than for a general SWE**\n\n   Design to take advantage of OO concepts (any python class will cover instantiating objects and accessing attributes, which you do need)  \n   multi-threading and multi-processing  \n   tkinter or other desktop GUI framework  \n   subprocess control (popen)  \n   Dataclass (given the name, its surprising, but I haven't talked to DEs who use these)  \n\n**likely less/not covered, often important for DEs**\n\n   *comes-with libs*:  \n   datetime -- deltas, arithmetic, date&lt;-&gt;string, timezone handling, pytz &amp; post 3.10(?) built-in  \n   zipfile  \n   csv  \n   pathlib  \n   re, and familiarity with string functions likely alternative (startswith, in) (if you use re and don't need it that might look bad in interview)  \n   Decimal v float (rounding with money)  \n\n   *Additional libs*:\n   pytz (as a predecssor to datetime.timzone (still widely used))  \n   chardet  \n   pandas  (just understanding its filter syntax, like df\\[df\\['poo'\\] &gt; 3\\], puts you ahead of the bottom candidates already)  \n   requests  (and non-python you should take a short course on postman and curl &amp; learn a bit about headers and tokens)  \n   fastapi and/or DRF (read about both) (it's not obviously DE-ish, but 3 \"ETL\" teams I know have put up FASTapi stuff) (anyway DEs should have basic idea of HTTP apps, apis, basic REST theory, and at least know you don't know about SOAP)  \n\n*edit* - Likely not covered at all in a python class but likely to be relevant: jinja2 (used in dbt) and sqlalchemy (used widely but esp. with pandas)\n\nIn my experience SQL is crucial and I think if you can't do \"medium\" leetcode sql you're likely to have problems in any DE interview, whether it's really relevant to that specific job or not.  \n\nGeneral algorithm/data structure knowledge isn't important for most DE practitioners day-to-day, but necessary to clear interviews at some companies (I've never encountered this in about 15 interviews thru my career, all &lt; $150K/yr in today's US$).  If you're looking to enter the DE field, you should be familiar enough with LC to know if you can get up to speed on medium or hard LC if you need to.", "author_fullname": "t2_abfpw4qq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "python specifically for DE positions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k0sbu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691375655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691356283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[edited to clarify I&amp;#39;m asking about what to concentrate on for a DE in context of learning python generally]  &lt;/p&gt;\n\n&lt;p&gt;If a practicing/aspiring DE asks  &amp;quot;what python do I need for DE?&amp;quot; below are my thoughts about what to concentrate on/supplement  from a &amp;quot;general python&amp;quot; class, would like to get feedback. The core of such classes is about general path of execution control, and using lists, dictionaries, sets and tuple, manipulating strings. All that stuff is crucial, if you have it down cold you&amp;#39;ll be better off for both jobs and interviews. &lt;/p&gt;\n\n&lt;p&gt;But when general classes move on to bigger programs I&amp;#39;m interested in thoughts about &lt;em&gt;what&amp;#39;s likely to be most crucial for DEs, or useful and not touched on&lt;/em&gt; by such a class.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;likely covered, but less important for a DE than for a general SWE&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Design to take advantage of OO concepts (any python class will cover instantiating objects and accessing attributes, which you do need)&lt;br/&gt;\n   multi-threading and multi-processing&lt;br/&gt;\n   tkinter or other desktop GUI framework&lt;br/&gt;\n   subprocess control (popen)&lt;br/&gt;\n   Dataclass (given the name, its surprising, but I haven&amp;#39;t talked to DEs who use these)  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;likely less/not covered, often important for DEs&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;comes-with libs&lt;/em&gt;:&lt;br/&gt;\n   datetime -- deltas, arithmetic, date&amp;lt;-&amp;gt;string, timezone handling, pytz &amp;amp; post 3.10(?) built-in&lt;br/&gt;\n   zipfile&lt;br/&gt;\n   csv&lt;br/&gt;\n   pathlib&lt;br/&gt;\n   re, and familiarity with string functions likely alternative (startswith, in) (if you use re and don&amp;#39;t need it that might look bad in interview)&lt;br/&gt;\n   Decimal v float (rounding with money)  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Additional libs&lt;/em&gt;:\n   pytz (as a predecssor to datetime.timzone (still widely used))&lt;br/&gt;\n   chardet&lt;br/&gt;\n   pandas  (just understanding its filter syntax, like df[df[&amp;#39;poo&amp;#39;] &amp;gt; 3], puts you ahead of the bottom candidates already)&lt;br/&gt;\n   requests  (and non-python you should take a short course on postman and curl &amp;amp; learn a bit about headers and tokens)&lt;br/&gt;\n   fastapi and/or DRF (read about both) (it&amp;#39;s not obviously DE-ish, but 3 &amp;quot;ETL&amp;quot; teams I know have put up FASTapi stuff) (anyway DEs should have basic idea of HTTP apps, apis, basic REST theory, and at least know you don&amp;#39;t know about SOAP)  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;edit&lt;/em&gt; - Likely not covered at all in a python class but likely to be relevant: jinja2 (used in dbt) and sqlalchemy (used widely but esp. with pandas)&lt;/p&gt;\n\n&lt;p&gt;In my experience SQL is crucial and I think if you can&amp;#39;t do &amp;quot;medium&amp;quot; leetcode sql you&amp;#39;re likely to have problems in any DE interview, whether it&amp;#39;s really relevant to that specific job or not.  &lt;/p&gt;\n\n&lt;p&gt;General algorithm/data structure knowledge isn&amp;#39;t important for most DE practitioners day-to-day, but necessary to clear interviews at some companies (I&amp;#39;ve never encountered this in about 15 interviews thru my career, all &amp;lt; $150K/yr in today&amp;#39;s US$).  If you&amp;#39;re looking to enter the DE field, you should be familiar enough with LC to know if you can get up to speed on medium or hard LC if you need to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k0sbu", "is_robot_indexable": true, "report_reasons": null, "author": "levintennine", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k0sbu/python_specifically_for_de_positions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k0sbu/python_specifically_for_de_positions/", "subreddit_subscribers": 121269, "created_utc": 1691356283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What factors do you consider when deciding to store data in a database vs using object storage such as S3? At my org we use python scripts to store most of our raw JSON data in postgresql JSONB columns. We then build on this data and add to it within other database tables.\n\nThe only thing we store in S3 is PDFs and HTML. I noticed a lot of people here talking about saving raw JSON to S3, so I got me curious about what we may be missing.\n\nSome advantages for object storage that I thought of are:\n\n1. More durable, less likely to be lost\n2. Less stress on database\n3. Can process more data concurrently\n\nThe cons for object storage seem to be:\n\n1. Expense involved with every query\n2. Harder to attach metadata via other columns\n\nCurious to hear what others think about this!", "author_fullname": "t2_1zkaz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storing JSON - database vs object storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k4oyg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691366261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What factors do you consider when deciding to store data in a database vs using object storage such as S3? At my org we use python scripts to store most of our raw JSON data in postgresql JSONB columns. We then build on this data and add to it within other database tables.&lt;/p&gt;\n\n&lt;p&gt;The only thing we store in S3 is PDFs and HTML. I noticed a lot of people here talking about saving raw JSON to S3, so I got me curious about what we may be missing.&lt;/p&gt;\n\n&lt;p&gt;Some advantages for object storage that I thought of are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;More durable, less likely to be lost&lt;/li&gt;\n&lt;li&gt;Less stress on database&lt;/li&gt;\n&lt;li&gt;Can process more data concurrently&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The cons for object storage seem to be:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Expense involved with every query&lt;/li&gt;\n&lt;li&gt;Harder to attach metadata via other columns&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Curious to hear what others think about this!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k4oyg", "is_robot_indexable": true, "report_reasons": null, "author": "caseym", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k4oyg/storing_json_database_vs_object_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k4oyg/storing_json_database_vs_object_storage/", "subreddit_subscribers": 121269, "created_utc": 1691366261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am doing modeling in python to maintain a next best action python model in that tracks relationships in dynamics. 1. the system is expensive to run 2. the data is ugly / messy. I'm supposed to be supporting our sales org with data insights as a \"data analyst\". I like the notebook approach of synapse. I feel like azure can go infinitely deep. Is anyone else using dynamics and doing analytics with it?", "author_fullname": "t2_8klzm7ui", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dropped into Azure as a newbie 60 days in, using Dynamics / Synapse / PowerBI/ Pyspark (sql). What do I need to learn? WTF is fabric?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k6vai", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691372297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am doing modeling in python to maintain a next best action python model in that tracks relationships in dynamics. 1. the system is expensive to run 2. the data is ugly / messy. I&amp;#39;m supposed to be supporting our sales org with data insights as a &amp;quot;data analyst&amp;quot;. I like the notebook approach of synapse. I feel like azure can go infinitely deep. Is anyone else using dynamics and doing analytics with it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15k6vai", "is_robot_indexable": true, "report_reasons": null, "author": "LogicalPhallicsy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k6vai/dropped_into_azure_as_a_newbie_60_days_in_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k6vai/dropped_into_azure_as_a_newbie_60_days_in_using/", "subreddit_subscribers": 121269, "created_utc": 1691372297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are moving from DW to Data lake. We will move from one cloud(Gcp) to another in the next year or so. What we pick will also need to move. \nWe have a lot of code that queries BigQuery. I looked at Omni but it looks like there are a lot of restrictions.", "author_fullname": "t2_s3lpw2dx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you use for your Data Lakehouse architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k2i56", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691360539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are moving from DW to Data lake. We will move from one cloud(Gcp) to another in the next year or so. What we pick will also need to move. \nWe have a lot of code that queries BigQuery. I looked at Omni but it looks like there are a lot of restrictions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k2i56", "is_robot_indexable": true, "report_reasons": null, "author": "nelsonbigetti", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k2i56/what_do_you_use_for_your_data_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k2i56/what_do_you_use_for_your_data_lakehouse/", "subreddit_subscribers": 121269, "created_utc": 1691360539.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\n\nI'd like to ask for some advices about architecting a datalake that's mostly used to train ML algorithms. \n\n\nSo we have at my job, the first silo of a datalake (let's call it C1), containing raw data from IoT devices. The interface is HTTP, you download records/files, then process them locally as you want. Those are organized per category. The user access and roles is handled by an OAuth service, and a web server is serving the data to the user. It is made using an AWS EC2 machine and a Mongo database. \n\nWe are working on a second silo, with data being in a cleaned from C1, stored as parquet files. This one will be used more extensively. The \"records\"/data must be versionned. Some users should be able to create datasets from the records (many to many relationship). And the user ACL should be as fine as on C1. Also we want something as in-house as possible, anything Databricks Saas or AWS full-managed/serverless isn't possible. \n\n\nWe are trying two solutions at the moment :\n\nThe first one being using Spark and Iceberg over S3 + a Glue catalog, which is great because the SQL API offers flexibility but I'm quite scared of the datascientists running expensive requests. Also I still don't know how to handle the user access management and roles. Then how would the data scientists do the compute, running Spark on their computer? Ultimately they work on their computers and don't plan on using a saas editor. Which kind of computing platform would allow low TTFB for small requests and high throughput for highly distributed workload? \n\nThe second one being an RDS PostGreSQL database for the meta, which would also do most of the compute when searching for a record, S3, and a web server. Kinda the same architecture as in C1, but the RDBMS allowing for versionning the data and creating datasets.\n\n\nDo you guys know of any solution that would fit our need better? \n\nThanks! \n\nN.B : Sorry if this is very approximate, I'm a SWE but have been doing DE for only 3 months.", "author_fullname": "t2_12102p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice for architecting a datalake.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jvem7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691393466.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691343296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to ask for some advices about architecting a datalake that&amp;#39;s mostly used to train ML algorithms. &lt;/p&gt;\n\n&lt;p&gt;So we have at my job, the first silo of a datalake (let&amp;#39;s call it C1), containing raw data from IoT devices. The interface is HTTP, you download records/files, then process them locally as you want. Those are organized per category. The user access and roles is handled by an OAuth service, and a web server is serving the data to the user. It is made using an AWS EC2 machine and a Mongo database. &lt;/p&gt;\n\n&lt;p&gt;We are working on a second silo, with data being in a cleaned from C1, stored as parquet files. This one will be used more extensively. The &amp;quot;records&amp;quot;/data must be versionned. Some users should be able to create datasets from the records (many to many relationship). And the user ACL should be as fine as on C1. Also we want something as in-house as possible, anything Databricks Saas or AWS full-managed/serverless isn&amp;#39;t possible. &lt;/p&gt;\n\n&lt;p&gt;We are trying two solutions at the moment :&lt;/p&gt;\n\n&lt;p&gt;The first one being using Spark and Iceberg over S3 + a Glue catalog, which is great because the SQL API offers flexibility but I&amp;#39;m quite scared of the datascientists running expensive requests. Also I still don&amp;#39;t know how to handle the user access management and roles. Then how would the data scientists do the compute, running Spark on their computer? Ultimately they work on their computers and don&amp;#39;t plan on using a saas editor. Which kind of computing platform would allow low TTFB for small requests and high throughput for highly distributed workload? &lt;/p&gt;\n\n&lt;p&gt;The second one being an RDS PostGreSQL database for the meta, which would also do most of the compute when searching for a record, S3, and a web server. Kinda the same architecture as in C1, but the RDBMS allowing for versionning the data and creating datasets.&lt;/p&gt;\n\n&lt;p&gt;Do you guys know of any solution that would fit our need better? &lt;/p&gt;\n\n&lt;p&gt;Thanks! &lt;/p&gt;\n\n&lt;p&gt;N.B : Sorry if this is very approximate, I&amp;#39;m a SWE but have been doing DE for only 3 months.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jvem7", "is_robot_indexable": true, "report_reasons": null, "author": "papawish", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jvem7/need_advice_for_architecting_a_datalake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jvem7/need_advice_for_architecting_a_datalake/", "subreddit_subscribers": 121269, "created_utc": 1691343296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After countless rejections, I have my second round lined up for a Junior Data Engineering role which mostly works with python, SQL, Apache airflow for the main tech stack, along with docker, jenkins, and jira. The recruiter also mentioned their work involves migrating Java legacy code for information extraction to python.\n\nI really need to ace this interview and I need some tips how I should go about my preparation. Any advice from you all will be very appreciated.", "author_fullname": "t2_dwygkomu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First DE technical interview and don't know where to start", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15kj6qi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691410896.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After countless rejections, I have my second round lined up for a Junior Data Engineering role which mostly works with python, SQL, Apache airflow for the main tech stack, along with docker, jenkins, and jira. The recruiter also mentioned their work involves migrating Java legacy code for information extraction to python.&lt;/p&gt;\n\n&lt;p&gt;I really need to ace this interview and I need some tips how I should go about my preparation. Any advice from you all will be very appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15kj6qi", "is_robot_indexable": true, "report_reasons": null, "author": "Redemption_road_443", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15kj6qi/first_de_technical_interview_and_dont_know_where/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15kj6qi/first_de_technical_interview_and_dont_know_where/", "subreddit_subscribers": 121269, "created_utc": 1691410896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\n \n\n# Orchestrate SQL Data Pipelines with Airflow | Schedule SQL scripts with Airlfow | ETL with SQL\n\n\ud83d\udcf7[**Blog**](https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;restrict_sr=1)\n\nVlog on how to run and schedule SQL scripts with Airflow? | SQL Data Pipelines | Airflow | \n\n[https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;t](https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;t=15s)\n\nTopics covered:\n\n* SQL Data Pipelines\n* Orchestrate SQL Data Pipelines with Airflow\n* Build ETL Pipelines with SQL and Airlfow\n\nTech Stack: **Airflow, SQL, Postgres**", "author_fullname": "t2_vj0466m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Orchestrate SQL Data Pipelines with Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jr3va", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691332425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Orchestrate SQL Data Pipelines with Airflow | Schedule SQL scripts with Airlfow | ETL with SQL&lt;/h1&gt;\n\n&lt;p&gt;\ud83d\udcf7&lt;a href=\"https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;amp;restrict_sr=1\"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Vlog on how to run and schedule SQL scripts with Airflow? | SQL Data Pipelines | Airflow | &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;amp;t=15s\"&gt;https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;amp;t&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Topics covered:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SQL Data Pipelines&lt;/li&gt;\n&lt;li&gt;Orchestrate SQL Data Pipelines with Airflow&lt;/li&gt;\n&lt;li&gt;Build ETL Pipelines with SQL and Airlfow&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Tech Stack: &lt;strong&gt;Airflow, SQL, Postgres&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?auto=webp&amp;s=03784d9dac9dffcc1166f570436a71e7c718902a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0980d90c5755f83d45488668837f05287f0483bd", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=df7595d0942017850684fa6a05af1cc40dbfeec1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9d668134559a76c33c5122856aff02e27742302", "width": 320, "height": 240}], "variants": {}, "id": "VdeBUiZIsVh-t6deaseFeEHDK_Q0GOVBJM1ja2o45TE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15jr3va", "is_robot_indexable": true, "report_reasons": null, "author": "Either-Adeptness6638", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jr3va/orchestrate_sql_data_pipelines_with_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jr3va/orchestrate_sql_data_pipelines_with_airflow/", "subreddit_subscribers": 121269, "created_utc": 1691332425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "  \n\nHey ya'll.\n\nI could use some input regarding \"stream\" ingestion.\n\n**Definition:**  \n I feel the definition of \"stream data\" is super vague. For most tutorials online, the use cases is usually relate to streams of data from e.g. sensors or website actions, that you for some reason need to be **processed** in real-time and thus, call for methods such as Windowing etc.\n\nBut the use cases I work with are usually very traditional, data warehouse use cases, where the further processing of data does not need to be real time. The only real-time component, really, is the ingestion, where, for example, the data from an event lands in a, say, Kafka queue, and we *choose* to act on it immediately. The only processing that is done on the event, *might* be to de-nest a nested structure and parsing say, a JSON format, to input it into a relational database.\n\n**Tooling:**\n\nAll the tooling I read about, all focus on **processing** data in real time, i.e. doing some sort of aggregate functions on them. Fx. Spark Streaming, Apache Beam.\n\n**Pipeline:**\n\nI have previously utilized function services like AWS Lambda or Azure Functions, and have these be triggered from Events, like *new file in S3*, or *new event in queue*. And then ingest the data **one by one**. I have done this approach by myself before, as to me it is the simplest approach that does not introduce any new software dependencies, and works on the basic services offered by the cloud provider.\n\nCould any of you elaborate on why, say, Spark Streaming with Databricks, or Apache Beam would be a better choice in the above use case, where I simply ingest the data through Azure Functions/AWS Lambda through triggers?", "author_fullname": "t2_onmeo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming ingestion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15kdri9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691394061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey ya&amp;#39;ll.&lt;/p&gt;\n\n&lt;p&gt;I could use some input regarding &amp;quot;stream&amp;quot; ingestion.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt;&lt;br/&gt;\n I feel the definition of &amp;quot;stream data&amp;quot; is super vague. For most tutorials online, the use cases is usually relate to streams of data from e.g. sensors or website actions, that you for some reason need to be &lt;strong&gt;processed&lt;/strong&gt; in real-time and thus, call for methods such as Windowing etc.&lt;/p&gt;\n\n&lt;p&gt;But the use cases I work with are usually very traditional, data warehouse use cases, where the further processing of data does not need to be real time. The only real-time component, really, is the ingestion, where, for example, the data from an event lands in a, say, Kafka queue, and we &lt;em&gt;choose&lt;/em&gt; to act on it immediately. The only processing that is done on the event, &lt;em&gt;might&lt;/em&gt; be to de-nest a nested structure and parsing say, a JSON format, to input it into a relational database.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Tooling:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;All the tooling I read about, all focus on &lt;strong&gt;processing&lt;/strong&gt; data in real time, i.e. doing some sort of aggregate functions on them. Fx. Spark Streaming, Apache Beam.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Pipeline:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have previously utilized function services like AWS Lambda or Azure Functions, and have these be triggered from Events, like &lt;em&gt;new file in S3&lt;/em&gt;, or &lt;em&gt;new event in queue&lt;/em&gt;. And then ingest the data &lt;strong&gt;one by one&lt;/strong&gt;. I have done this approach by myself before, as to me it is the simplest approach that does not introduce any new software dependencies, and works on the basic services offered by the cloud provider.&lt;/p&gt;\n\n&lt;p&gt;Could any of you elaborate on why, say, Spark Streaming with Databricks, or Apache Beam would be a better choice in the above use case, where I simply ingest the data through Azure Functions/AWS Lambda through triggers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15kdri9", "is_robot_indexable": true, "report_reasons": null, "author": "Hinkakan", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15kdri9/streaming_ingestion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15kdri9/streaming_ingestion/", "subreddit_subscribers": 121269, "created_utc": 1691394061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the best data engineering blogs/professionals to follow? \n\nLooking for high quality stuff. Maybe even sciency. Obviously not medium. Feel free to self plug!\n\nI mainly use twitter as info source but was wondering what cool things I might miss.", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Data Engineering blogs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15kky61", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691415580.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691415348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best data engineering blogs/professionals to follow? &lt;/p&gt;\n\n&lt;p&gt;Looking for high quality stuff. Maybe even sciency. Obviously not medium. Feel free to self plug!&lt;/p&gt;\n\n&lt;p&gt;I mainly use twitter as info source but was wondering what cool things I might miss.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15kky61", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15kky61/best_data_engineering_blogs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15kky61/best_data_engineering_blogs/", "subreddit_subscribers": 121269, "created_utc": 1691415348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the disadvantages of using Dremio? Can I move between clouds? Is it costly?", "author_fullname": "t2_s3lpw2dx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use Dremio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k2m5u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691360835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the disadvantages of using Dremio? Can I move between clouds? Is it costly?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k2m5u", "is_robot_indexable": true, "report_reasons": null, "author": "nelsonbigetti", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k2m5u/do_you_use_dremio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k2m5u/do_you_use_dremio/", "subreddit_subscribers": 121269, "created_utc": 1691360835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been the 'data guy' (mostly engineering, but some analyst work as well) for around 5 years at my company, experiencing all ends of the data process from creating pipelines and robust data services in AWS with Python, POC-ing and onboarding new tools, to actually doing a quite a bit of dashboarding/presenting/PM type stuff for our internal projects. \n\nI've been applying/interviewing for months for mid-senior level positions and consistently being told that while I'm a great candidate, they want someone who can just \"come in and do it\". But \"do it\" is always some form of, set up our cloud data warehouse in Snowflake/Redshift, build out our transformation layer in DBT, be familiar with Spark and data streams, know how to implement infrastructure-as-code, know source control through and through, be familiar working with \"big data\", and those are things my current job will *never* provide me with. \n\nAt this point, I'm curious if anyone has gone through the transition from data engineer to a data or product analyst and how that has gone for them/if the grass is greener on the other side.", "author_fullname": "t2_5ashf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transition from Engineer to Data/Product Analyst?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15kld8a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691416353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been the &amp;#39;data guy&amp;#39; (mostly engineering, but some analyst work as well) for around 5 years at my company, experiencing all ends of the data process from creating pipelines and robust data services in AWS with Python, POC-ing and onboarding new tools, to actually doing a quite a bit of dashboarding/presenting/PM type stuff for our internal projects. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been applying/interviewing for months for mid-senior level positions and consistently being told that while I&amp;#39;m a great candidate, they want someone who can just &amp;quot;come in and do it&amp;quot;. But &amp;quot;do it&amp;quot; is always some form of, set up our cloud data warehouse in Snowflake/Redshift, build out our transformation layer in DBT, be familiar with Spark and data streams, know how to implement infrastructure-as-code, know source control through and through, be familiar working with &amp;quot;big data&amp;quot;, and those are things my current job will &lt;em&gt;never&lt;/em&gt; provide me with. &lt;/p&gt;\n\n&lt;p&gt;At this point, I&amp;#39;m curious if anyone has gone through the transition from data engineer to a data or product analyst and how that has gone for them/if the grass is greener on the other side.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15kld8a", "is_robot_indexable": true, "report_reasons": null, "author": "GoogleDatShit", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15kld8a/transition_from_engineer_to_dataproduct_analyst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15kld8a/transition_from_engineer_to_dataproduct_analyst/", "subreddit_subscribers": 121269, "created_utc": 1691416353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nI work on a team converting manual reporting-based  solutions into data feeds and hardened business logic. For converting reports out of a particular system, I have three documents at my disposal: \n\n* I have an (excel) list of report fields from the back-end of a large Risk Management System. Think Module Name + Field Name + Datatype + GUID.\n\n* I have an (excel) mapping of GUIDs to the fields in the data-feed-provisioning database. \n\n* I have an (excel) mapping of the specific GUIDs in a module which have a Corresponding GUID in another Module. These are like the foreign key relationships between databases. \n\nI\u2019ll note here that the relational integrity rules are all enforced before *only* the data is loaded into the provisioning database. I.e. no data model is enforced explicitly in the data-feed-provisioning database, but relational integrity is preserved implicitly by the software. However, that means that I cannot ask for a dbt file or any kind of physical/logical data model from the DBAs of the data-feed-provisioning database. I\u2019ll also note that, while there is certainly more than one table per database - and thus more than one table per module - the foreign keys relationships between tables within the same module are identifiable through the field name. I.e. I can infer that within the controls module, tbl_control.control_id and tbl_controlowner.control_id will have a pk:fk relationship, because the field has the same name in two tables within the same module.\n\nQuestion: I have all this metadata, can I convert it into a physical /logical data model (and/or ERD) ***automagically***? It\u2019s 32k GUIDs, doing it by hand is possible but ridiculous.", "author_fullname": "t2_k9fkw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to automatically generate ERD/logical data model using only metadata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15kl0om", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691415520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I work on a team converting manual reporting-based  solutions into data feeds and hardened business logic. For converting reports out of a particular system, I have three documents at my disposal: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;I have an (excel) list of report fields from the back-end of a large Risk Management System. Think Module Name + Field Name + Datatype + GUID.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I have an (excel) mapping of GUIDs to the fields in the data-feed-provisioning database. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I have an (excel) mapping of the specific GUIDs in a module which have a Corresponding GUID in another Module. These are like the foreign key relationships between databases. &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019ll note here that the relational integrity rules are all enforced before &lt;em&gt;only&lt;/em&gt; the data is loaded into the provisioning database. I.e. no data model is enforced explicitly in the data-feed-provisioning database, but relational integrity is preserved implicitly by the software. However, that means that I cannot ask for a dbt file or any kind of physical/logical data model from the DBAs of the data-feed-provisioning database. I\u2019ll also note that, while there is certainly more than one table per database - and thus more than one table per module - the foreign keys relationships between tables within the same module are identifiable through the field name. I.e. I can infer that within the controls module, tbl_control.control_id and tbl_controlowner.control_id will have a pk:fk relationship, because the field has the same name in two tables within the same module.&lt;/p&gt;\n\n&lt;p&gt;Question: I have all this metadata, can I convert it into a physical /logical data model (and/or ERD) &lt;strong&gt;&lt;em&gt;automagically&lt;/em&gt;&lt;/strong&gt;? It\u2019s 32k GUIDs, doing it by hand is possible but ridiculous.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15kl0om", "is_robot_indexable": true, "report_reasons": null, "author": "Weaponomics", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15kl0om/how_to_automatically_generate_erdlogical_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15kl0om/how_to_automatically_generate_erdlogical_data/", "subreddit_subscribers": 121269, "created_utc": 1691415520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone here successfully implemented zero-iteration development cycles in their data engineering projects? I'm curious to hear about your experiences, challenges faced, and how it has affected your typical workday. ", "author_fullname": "t2_s2th7rxt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zero-iteration development cycles, how would that affect your day-to-day?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15kjnlc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691412107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone here successfully implemented zero-iteration development cycles in their data engineering projects? I&amp;#39;m curious to hear about your experiences, challenges faced, and how it has affected your typical workday. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15kjnlc", "is_robot_indexable": true, "report_reasons": null, "author": "StreamingDataGuru", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15kjnlc/zeroiteration_development_cycles_how_would_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15kjnlc/zeroiteration_development_cycles_how_would_that/", "subreddit_subscribers": 121269, "created_utc": 1691412107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seems like many companies use them. Was wondering how widespread it is and how useful they are in Data Eng.\n\nIn management consulting it seems to be a building block for the whole industry and they focus alot on communication skills and ability to quickly draw logical conclusions and come up with alternative solutions, while I've understood they are more of a technical nature in data eng.\n\nWhat's the community's opinion on them? Actually good at testing a candidate's needed skills or not really useful?", "author_fullname": "t2_ves1in2k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Case interviews in Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15kh9g6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691405660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seems like many companies use them. Was wondering how widespread it is and how useful they are in Data Eng.&lt;/p&gt;\n\n&lt;p&gt;In management consulting it seems to be a building block for the whole industry and they focus alot on communication skills and ability to quickly draw logical conclusions and come up with alternative solutions, while I&amp;#39;ve understood they are more of a technical nature in data eng.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the community&amp;#39;s opinion on them? Actually good at testing a candidate&amp;#39;s needed skills or not really useful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15kh9g6", "is_robot_indexable": true, "report_reasons": null, "author": "EzPzData", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15kh9g6/case_interviews_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15kh9g6/case_interviews_in_data_engineering/", "subreddit_subscribers": 121269, "created_utc": 1691405660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\nI started using the new feature called 'Change data feed,' but there's something I don't understand. When I input the data in Bronze and activate the CDF there, I can use startTimestamp to retrieve the latest data in Silver and thus only read the delta. However, when I write this data in Silver, it retains the CDF information from Bronze. Before saving, I deleted the CDF columns and reactivated the CDF, but unfortunately, it didn't work. What am I doing wrong here?\n\n&amp;#x200B;\n\nLoading data to bronze:\n\n     df.write.mode(\"append\") \\\n        .format(\"delta\") \\\n        .option(\"mergeSchema\", \"true\") \\\n        .option(\"delta.enableChangeDataFeed\",\"true\") \\\n        .save(SINK_PATH+'/'+FOLDER_NAME)\n\nLoading data in silver:\n\n    df = spark.read.option(\"readChangeFeed\", \"true\").option(\"startingTimestamp\", last_version_ts).load(folder.path, format = \"delta\")\n    \n    df = df.drop(\"_change_type\", \"_commit_version\",  \"_commit_timestamp\")\n    \n    df.write.mode(\"append\") \\\n        .format(\"delta\") \\\n        .option(\"mergeSchema\", \"true\") \\\n        .option(\"delta.enableChangeDataFeed\",\"true\") \\\n        .save(SINK_PATH+'/'+FOLDER_NAME)\n\nWithout dropping the columns BUT with enabling ChangeDataFeed I got an error, that the columns are ambiguous or something. I coulnd't read from the Lake because of that.", "author_fullname": "t2_3hjo2xx8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta's Change data feed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ke874", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691395674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;I started using the new feature called &amp;#39;Change data feed,&amp;#39; but there&amp;#39;s something I don&amp;#39;t understand. When I input the data in Bronze and activate the CDF there, I can use startTimestamp to retrieve the latest data in Silver and thus only read the delta. However, when I write this data in Silver, it retains the CDF information from Bronze. Before saving, I deleted the CDF columns and reactivated the CDF, but unfortunately, it didn&amp;#39;t work. What am I doing wrong here?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Loading data to bronze:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt; df.write.mode(&amp;quot;append&amp;quot;) \\\n    .format(&amp;quot;delta&amp;quot;) \\\n    .option(&amp;quot;mergeSchema&amp;quot;, &amp;quot;true&amp;quot;) \\\n    .option(&amp;quot;delta.enableChangeDataFeed&amp;quot;,&amp;quot;true&amp;quot;) \\\n    .save(SINK_PATH+&amp;#39;/&amp;#39;+FOLDER_NAME)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Loading data in silver:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;df = spark.read.option(&amp;quot;readChangeFeed&amp;quot;, &amp;quot;true&amp;quot;).option(&amp;quot;startingTimestamp&amp;quot;, last_version_ts).load(folder.path, format = &amp;quot;delta&amp;quot;)\n\ndf = df.drop(&amp;quot;_change_type&amp;quot;, &amp;quot;_commit_version&amp;quot;,  &amp;quot;_commit_timestamp&amp;quot;)\n\ndf.write.mode(&amp;quot;append&amp;quot;) \\\n    .format(&amp;quot;delta&amp;quot;) \\\n    .option(&amp;quot;mergeSchema&amp;quot;, &amp;quot;true&amp;quot;) \\\n    .option(&amp;quot;delta.enableChangeDataFeed&amp;quot;,&amp;quot;true&amp;quot;) \\\n    .save(SINK_PATH+&amp;#39;/&amp;#39;+FOLDER_NAME)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Without dropping the columns BUT with enabling ChangeDataFeed I got an error, that the columns are ambiguous or something. I coulnd&amp;#39;t read from the Lake because of that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ke874", "is_robot_indexable": true, "report_reasons": null, "author": "alienus333", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ke874/deltas_change_data_feed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ke874/deltas_change_data_feed/", "subreddit_subscribers": 121269, "created_utc": 1691395674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to leverage a messaging service to enable event-driven integration and facilitate near real-time integration for building data pipelines. Which one of these messaging services do you think would be most suitable?\nI am a newbie data engineer thank you\u2026\n\n[View Poll](https://www.reddit.com/poll/15kalqr)", "author_fullname": "t2_u1p9g2g4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MSK or SQS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15kalqr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691383603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to leverage a messaging service to enable event-driven integration and facilitate near real-time integration for building data pipelines. Which one of these messaging services do you think would be most suitable?\nI am a newbie data engineer thank you\u2026&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/15kalqr\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15kalqr", "is_robot_indexable": true, "report_reasons": null, "author": "Active-Ask-3524", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1691642803277, "options": [{"text": "MSK", "id": "24233658"}, {"text": "SQS", "id": "24233659"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 15, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15kalqr/msk_or_sqs/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/15kalqr/msk_or_sqs/", "subreddit_subscribers": 121269, "created_utc": 1691383603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nEnjoy reading all your posts here.\n\nI just want to get your opinion on the smallest scale DE stack that is feasible to roll out for a small to medium enterprise on a pilot basis.\n\nShould I start with AWS ,Google or Alibaba?\n\nHow do I calculate computation costs v storage cost?\n\nKakfa or Hevo ?\n\nWhat about APIs?\n\nEstimated man hours to deploy?\n\nRefactoring?\n\nHow do I cost the whole pilot project?\n\nAny recommended DE stack model that I could have a look at?\n\nCheers and apologies for the range of questions.", "author_fullname": "t2_s2dp5dpg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE stack by new outfit for small to medium business", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k41zm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691364576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;Enjoy reading all your posts here.&lt;/p&gt;\n\n&lt;p&gt;I just want to get your opinion on the smallest scale DE stack that is feasible to roll out for a small to medium enterprise on a pilot basis.&lt;/p&gt;\n\n&lt;p&gt;Should I start with AWS ,Google or Alibaba?&lt;/p&gt;\n\n&lt;p&gt;How do I calculate computation costs v storage cost?&lt;/p&gt;\n\n&lt;p&gt;Kakfa or Hevo ?&lt;/p&gt;\n\n&lt;p&gt;What about APIs?&lt;/p&gt;\n\n&lt;p&gt;Estimated man hours to deploy?&lt;/p&gt;\n\n&lt;p&gt;Refactoring?&lt;/p&gt;\n\n&lt;p&gt;How do I cost the whole pilot project?&lt;/p&gt;\n\n&lt;p&gt;Any recommended DE stack model that I could have a look at?&lt;/p&gt;\n\n&lt;p&gt;Cheers and apologies for the range of questions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k41zm", "is_robot_indexable": true, "report_reasons": null, "author": "saintisstat", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k41zm/de_stack_by_new_outfit_for_small_to_medium/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k41zm/de_stack_by_new_outfit_for_small_to_medium/", "subreddit_subscribers": 121269, "created_utc": 1691364576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm a junior in college majoring in computer information systems. The way my major is set up is that students can focus towards either programming, web design? I think it's web design either way, programming, web design, and database managment. I'm thinking I should probably focus on programming if I want to be a data engineer right?", "author_fullname": "t2_a24gckgw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need some help.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jweks", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691345887.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691345682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m a junior in college majoring in computer information systems. The way my major is set up is that students can focus towards either programming, web design? I think it&amp;#39;s web design either way, programming, web design, and database managment. I&amp;#39;m thinking I should probably focus on programming if I want to be a data engineer right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jweks", "is_robot_indexable": true, "report_reasons": null, "author": "International_Fig420", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jweks/i_need_some_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jweks/i_need_some_help/", "subreddit_subscribers": 121269, "created_utc": 1691345682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone have experience or evaluated the use of Neo4J vs Neptune for a cloud graph DB. Read a few things online but curious if anyone\u2019s got any pointers here. \n\nSeems like both can easily interact with sagemaker\u2026 don\u2019t think Neptune plays well with redshift. Would be loading data from S3. Looks like they both have some bulk loading functionality. \n\nI\u2019m pretty sure someone read: https://neo4j.com/blog/walmart-neo4j-competitive-advantage/ and now this is the direction we are going \ud83e\udd37\u200d\u2642\ufe0f", "author_fullname": "t2_9bj4s404", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Neptune vs Neo4J", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jvl8l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691343729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have experience or evaluated the use of Neo4J vs Neptune for a cloud graph DB. Read a few things online but curious if anyone\u2019s got any pointers here. &lt;/p&gt;\n\n&lt;p&gt;Seems like both can easily interact with sagemaker\u2026 don\u2019t think Neptune plays well with redshift. Would be loading data from S3. Looks like they both have some bulk loading functionality. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m pretty sure someone read: &lt;a href=\"https://neo4j.com/blog/walmart-neo4j-competitive-advantage/\"&gt;https://neo4j.com/blog/walmart-neo4j-competitive-advantage/&lt;/a&gt; and now this is the direction we are going \ud83e\udd37\u200d\u2642\ufe0f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?auto=webp&amp;s=6461cc17589dd510fedc58ce52e211af7a82e4cf", "width": 900, "height": 224}, "resolutions": [{"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63dc4fce6e270fd5c997b4728a9c1ca6a7460bde", "width": 108, "height": 26}, {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a457717892c3f55d109a2bc173b147b48a77018a", "width": 216, "height": 53}, {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f6bfab6bdff8e9df079960b254cc09f9bafbaf84", "width": 320, "height": 79}, {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=af40ed6c60f803746d4dd8609e8ce5045f0d4f1b", "width": 640, "height": 159}], "variants": {}, "id": "nK4sSdFMcMhjFzyzeJp52E0WY68i_JTltCFahWvYB4o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jvl8l", "is_robot_indexable": true, "report_reasons": null, "author": "Over-Geologist-5760", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jvl8l/neptune_vs_neo4j/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jvl8l/neptune_vs_neo4j/", "subreddit_subscribers": 121269, "created_utc": 1691343729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI/ML Best Practices During a Gold Rush", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": false, "name": "t3_15ju2tf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uL48H9N0DS2GEo6E8gcgH3GJoWggSe4z8bGaLYBgYgc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691339995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.min.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.min.io/ai-ml-best-practices-during-a-gold-rush/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?auto=webp&amp;s=6791496e14e9072b5565cf0bb72bd800f967cf8a", "width": 2000, "height": 598}, "resolutions": [{"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca7901908b612d3e51236eeeb3cfe4b1cf1359f3", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=435eb84902201b6c1b33b8822133d652f04c601f", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c5a88bafa9e1a8e6a4e228cdd155b0a21ce4cd9f", "width": 320, "height": 95}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4d24ecd00d22decec81215802a961e8c05765660", "width": 640, "height": 191}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=60b1c2eeb2c644334379f7225ff166914bb57360", "width": 960, "height": 287}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a60340fe7b4d735f421d201c1632af89ff22da2d", "width": 1080, "height": 322}], "variants": {}, "id": "LR1jOSz4RSQ2PbagOXJkm6885ysOmVuTrnO79a5sXR4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ju2tf", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ju2tf/aiml_best_practices_during_a_gold_rush/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.min.io/ai-ml-best-practices-during-a-gold-rush/", "subreddit_subscribers": 121269, "created_utc": 1691339995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As someone who enjoys all kinds of cs fields, the second thing I should look at when choosing a career is the ease of finding a job and salary. Please be realistic, which one would you choose if you started from scratch?\n\n[View Poll](https://www.reddit.com/poll/15ju56b)", "author_fullname": "t2_be0kmkfc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which one would you choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ju56b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691340161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As someone who enjoys all kinds of cs fields, the second thing I should look at when choosing a career is the ease of finding a job and salary. Please be realistic, which one would you choose if you started from scratch?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/15ju56b\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ju56b", "is_robot_indexable": true, "report_reasons": null, "author": "Due_Salamander_2931", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1691512961705, "options": [{"text": "Data Engineering", "id": "24225937"}, {"text": "Devops Engineering", "id": "24225938"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 390, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ju56b/which_one_would_you_choose/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/15ju56b/which_one_would_you_choose/", "subreddit_subscribers": 121269, "created_utc": 1691340161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Want to be useful with AI\n\nI will  mostly be making data models, and using SSRS to create reports drawn from those analysis. \n\nI've very little experience with SSRS. \n\nHowever I'm fairly comfortable with SQL\nAnd some Python\n\n\n\nBut most importantly I know the landscape is changing. And I want to be useful. People are leveraging AI in many aspects of SQL reporting.\n\nI just don't know how exactly.\n\nMaybe in: \n\n1. Data cleansing\n\n\n2. Automated report capture and send out.\n\n\nHow else?\n\nWhat AI prompting/script creation should I learn that will be useful? Or revolutionizing in general?\n\nWhat should I learn in general for SSRS reporting?", "author_fullname": "t2_18rszvo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want to be useful with AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k09fu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691355037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Want to be useful with AI&lt;/p&gt;\n\n&lt;p&gt;I will  mostly be making data models, and using SSRS to create reports drawn from those analysis. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve very little experience with SSRS. &lt;/p&gt;\n\n&lt;p&gt;However I&amp;#39;m fairly comfortable with SQL\nAnd some Python&lt;/p&gt;\n\n&lt;p&gt;But most importantly I know the landscape is changing. And I want to be useful. People are leveraging AI in many aspects of SQL reporting.&lt;/p&gt;\n\n&lt;p&gt;I just don&amp;#39;t know how exactly.&lt;/p&gt;\n\n&lt;p&gt;Maybe in: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Data cleansing&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Automated report capture and send out.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;How else?&lt;/p&gt;\n\n&lt;p&gt;What AI prompting/script creation should I learn that will be useful? Or revolutionizing in general?&lt;/p&gt;\n\n&lt;p&gt;What should I learn in general for SSRS reporting?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15k09fu", "is_robot_indexable": true, "report_reasons": null, "author": "peyott100", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k09fu/want_to_be_useful_with_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k09fu/want_to_be_useful_with_ai/", "subreddit_subscribers": 121269, "created_utc": 1691355037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I work in a plastic factory and i am making tests of a product with different composition and features. I would like to compare my tests with the product of my competition and between each other in order to determinate which one is the best. Could someone guide me about how to make this type of analysis please?\n\nthe data is in the link.\n\n[Data](https://docs.google.com/spreadsheets/d/1DBaZGUlMK1p-RavfZiyr_8L4npI6hCzz381aNa2Zo5U/edit?usp=sharing)", "author_fullname": "t2_qx2yrcp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to choose the best result?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jufgz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691340897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I work in a plastic factory and i am making tests of a product with different composition and features. I would like to compare my tests with the product of my competition and between each other in order to determinate which one is the best. Could someone guide me about how to make this type of analysis please?&lt;/p&gt;\n\n&lt;p&gt;the data is in the link.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.google.com/spreadsheets/d/1DBaZGUlMK1p-RavfZiyr_8L4npI6hCzz381aNa2Zo5U/edit?usp=sharing\"&gt;Data&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?auto=webp&amp;s=b6ed92112b16068a2303c366865831f26427eafe", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c3787d86902b7d6abc24019ae9c009dee2b2232", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d8af98ced5d5e230b402963ef756923d641df974", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e792353e97cc4866a04fed5002f0e85cd7a1ff8f", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b8c0a014c73d42a52e5bd499c20f589b6b952853", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f23b638b39f7a68792ef486b7311ff8d5794edb0", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0c883ade7bacf66361c01bdbe90b34eea5dc67a4", "width": 1080, "height": 567}], "variants": {}, "id": "XC4uNHGpS51t7eDtzWOidn67MZebTkLycF2OnN3BFVQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jufgz", "is_robot_indexable": true, "report_reasons": null, "author": "ECsantaroz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jufgz/how_to_choose_the_best_result/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jufgz/how_to_choose_the_best_result/", "subreddit_subscribers": 121269, "created_utc": 1691340897.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}