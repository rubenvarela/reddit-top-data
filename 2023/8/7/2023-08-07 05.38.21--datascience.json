{"kind": "Listing", "data": {"after": "t3_15k22h0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a math enthusiasts, that's why I got attracted to ML. To understand ML theory one needs to have good hold on stats, probability and basic algebra. Deep learning requires extensive knowledge of linear algebra. All of this takes months and months to understand. But in the end all that matters is whether you can implement a model or not. Especially today when we are looking at all per-trained (LLM) models, which is just few lines of code to train. I won't say implementation is not important. But it requires much less effort to master. Why one should (and would) waste his time learning all the maths? Just for fun? (PS: I do it for fun but little frustrated by industry)", "author_fullname": "t2_sipyqz9a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Whats the point of learning ML theory if industry doesn't care (other than interviews)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ji5de", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 196, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 196, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691302673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a math enthusiasts, that&amp;#39;s why I got attracted to ML. To understand ML theory one needs to have good hold on stats, probability and basic algebra. Deep learning requires extensive knowledge of linear algebra. All of this takes months and months to understand. But in the end all that matters is whether you can implement a model or not. Especially today when we are looking at all per-trained (LLM) models, which is just few lines of code to train. I won&amp;#39;t say implementation is not important. But it requires much less effort to master. Why one should (and would) waste his time learning all the maths? Just for fun? (PS: I do it for fun but little frustrated by industry)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ji5de", "is_robot_indexable": true, "report_reasons": null, "author": "Numerous_Syllabub545", "discussion_type": null, "num_comments": 97, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ji5de/whats_the_point_of_learning_ml_theory_if_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ji5de/whats_the_point_of_learning_ml_theory_if_industry/", "subreddit_subscribers": 977470, "created_utc": 1691302673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "https://preview.redd.it/3n4q0xzevjgb1.png?width=713&amp;format=png&amp;auto=webp&amp;s=38bb199895cb4217c70a1a0f1431ee721d26f45b\n\nI couldn't help but feel the need to share my frustration with the way some executives handle decision-making processes, especially when it comes to \u201cdata-driven\u201d decisions. The recent example from Amazon's senior leadership really got me boiling, and I just had to get this off my chest.\n\nAs a data science practitioner myself\u2026 it's disheartening to see executives in both my field and beyond often using data points to validate their existing beliefs rather than *truly* utilizing data to guide their decisions. The cornerstone of our work is to analyze and interpret data objectively to uncover insights that inform strategic choices. Yet, time and again, we witness decisions driven by personal preferences and opinions rather than evidence.\n\nAmazon has long been regarded as a paragon of data-driven decision-making, and rightly so. The company has access to vast amounts of data and has used it effectively to shape their strategies and operations, such as Dynamic Pricing, Warehouse Optimization, and Fraud Detection. However, when I read about Mike Hopkins' statements regarding the return to office, I was shocked at the blatant disregard for fundamental data-driven principles.\n\nLet's break this down\u2026 Hopkins, a senior vice president of Prime Video and Amazon Studios, made a bold statement in an internal meeting, stating that it's time to return to the office without providing *any* substantial data to back up his claim. He says, \"I don't have data to back it up, but I know it's better.\"\n\nThe essence of data-driven decision-making lies in using objective data to support or reject a belief or hypothesis. By admitting that he lacks the data to back up his position, Hopkins is essentially admitting that he's making an uninformed decision, and worse yet, he's trying to influence others to follow suit blindly.\n\nWhat's even more infuriating is that this kind of behavior is not *that* uncommon among senior management, even in my own personal experience. Many of them already have preconceived notions or personal preferences, and they cherry-pick data points to support their beliefs while conveniently ignoring any data that contradicts them. The complete opposite of what Data Science is meant to achieve.\n\nData-driven decision-making is crucial, especially when it comes to complex matters like remote work. Many employees have adapted to working from home, and some even prefer it due to increased flexibility and work-life balance. Forcing a return to the office without concrete data to support the move is a clear sign of executive arrogance and a lack of respect for their employees' preferences and well-being.\n\nIt's hard to believe that a company as data-driven as Amazon wouldn't have data on the productivity and effectiveness of remote work\u2026 the company likely has access to a *trove* of information that could shed light on the effectiveness of remote work, including productivity metrics, employee satisfaction surveys, and more. It's puzzling why they would not utilize this data to inform their decisions, especially when the well-being and productivity of their workforce are at stake. Without clear and data-backed justifications, employees may feel undervalued and may question the credibility of leadership's intentions.\n\nAmazon's senior leadership should remember their commitment to data-driven principles and engage in transparent decision-making. If there are legitimate reasons to return to the office, they owe it to their employees to present the data and engage in an open discussion about the pros and cons. By withholding critical information, they are undermining trust and potentially making decisions that could hurt the company in the long run.\n\nAs a data science practitioner, I believe it's not just about having access to data; it's also about using it responsibly and ethically. Using data to back up preconceived beliefs, or worse, hiding data that counters those beliefs, undermines the credibility and ethics of data science as a field and the trust we place in data-driven decision-making.\n\nIn conclusion, the misuse and omission of data by executives is not only frustrating to witness but also detrimental to the progress of organizations. I find it incredibly disappointing that executives at Amazon, a company known for being data-driven, would advocate for a return to the office without any supporting data. As data scientists, we have a responsibility to advocate for the ethical and rigorous use of data, and as consumers and employees, we have the right to demand evidence-based decision-making from the companies we support.\n\nAm I alone in this? I'd love to hear the community\u2019s thoughts on this matter.\n\nTL;DR: Amazon's senior leadership's recent push for a return to office without any supporting data is a disappointment to their reputation as a data-driven company. Executives should practice what they preach and make decisions based on objective data rather than personal beliefs or preferences. This behavior is not only disrespectful to employees but also detrimental to the company's long-term success. When data takes a backseat it flies in the face of what Data Science is all about.  \n\n\nLink to article: [https://fortune.com/2023/08/03/amazon-svp-mike-hopkins-office-return/](https://fortune.com/2023/08/03/amazon-svp-mike-hopkins-office-return/)", "author_fullname": "t2_tphsqrss", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From Data-Driven to Data-Ignored\u2026 a disappointing shift at Amazon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3n4q0xzevjgb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 116, "x": 108, "u": "https://preview.redd.it/3n4q0xzevjgb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f66fa9b20726380d2c64a8f11585565e6b8e10cf"}, {"y": 232, "x": 216, "u": "https://preview.redd.it/3n4q0xzevjgb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7867687ef4408ca982ee13bd05b802b627ee6ce3"}, {"y": 344, "x": 320, "u": "https://preview.redd.it/3n4q0xzevjgb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1dbacc730b1a6d1315a23926c76aeea162eccd4d"}, {"y": 688, "x": 640, "u": "https://preview.redd.it/3n4q0xzevjgb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=16bd3ac19ba09bc5059d769cf9402463f00dbdeb"}], "s": {"y": 767, "x": 713, "u": "https://preview.redd.it/3n4q0xzevjgb1.png?width=713&amp;format=png&amp;auto=webp&amp;s=38bb199895cb4217c70a1a0f1431ee721d26f45b"}, "id": "3n4q0xzevjgb1"}}, "name": "t3_15jzuh8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 127, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 127, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/PcBjIP_0pqtJFSeqLI5xEd5mmap1p8pqxYG_kAtN42Y.jpg", "edited": 1691354432.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1691354029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/3n4q0xzevjgb1.png?width=713&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=38bb199895cb4217c70a1a0f1431ee721d26f45b\"&gt;https://preview.redd.it/3n4q0xzevjgb1.png?width=713&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=38bb199895cb4217c70a1a0f1431ee721d26f45b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I couldn&amp;#39;t help but feel the need to share my frustration with the way some executives handle decision-making processes, especially when it comes to \u201cdata-driven\u201d decisions. The recent example from Amazon&amp;#39;s senior leadership really got me boiling, and I just had to get this off my chest.&lt;/p&gt;\n\n&lt;p&gt;As a data science practitioner myself\u2026 it&amp;#39;s disheartening to see executives in both my field and beyond often using data points to validate their existing beliefs rather than &lt;em&gt;truly&lt;/em&gt; utilizing data to guide their decisions. The cornerstone of our work is to analyze and interpret data objectively to uncover insights that inform strategic choices. Yet, time and again, we witness decisions driven by personal preferences and opinions rather than evidence.&lt;/p&gt;\n\n&lt;p&gt;Amazon has long been regarded as a paragon of data-driven decision-making, and rightly so. The company has access to vast amounts of data and has used it effectively to shape their strategies and operations, such as Dynamic Pricing, Warehouse Optimization, and Fraud Detection. However, when I read about Mike Hopkins&amp;#39; statements regarding the return to office, I was shocked at the blatant disregard for fundamental data-driven principles.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s break this down\u2026 Hopkins, a senior vice president of Prime Video and Amazon Studios, made a bold statement in an internal meeting, stating that it&amp;#39;s time to return to the office without providing &lt;em&gt;any&lt;/em&gt; substantial data to back up his claim. He says, &amp;quot;I don&amp;#39;t have data to back it up, but I know it&amp;#39;s better.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The essence of data-driven decision-making lies in using objective data to support or reject a belief or hypothesis. By admitting that he lacks the data to back up his position, Hopkins is essentially admitting that he&amp;#39;s making an uninformed decision, and worse yet, he&amp;#39;s trying to influence others to follow suit blindly.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s even more infuriating is that this kind of behavior is not &lt;em&gt;that&lt;/em&gt; uncommon among senior management, even in my own personal experience. Many of them already have preconceived notions or personal preferences, and they cherry-pick data points to support their beliefs while conveniently ignoring any data that contradicts them. The complete opposite of what Data Science is meant to achieve.&lt;/p&gt;\n\n&lt;p&gt;Data-driven decision-making is crucial, especially when it comes to complex matters like remote work. Many employees have adapted to working from home, and some even prefer it due to increased flexibility and work-life balance. Forcing a return to the office without concrete data to support the move is a clear sign of executive arrogance and a lack of respect for their employees&amp;#39; preferences and well-being.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s hard to believe that a company as data-driven as Amazon wouldn&amp;#39;t have data on the productivity and effectiveness of remote work\u2026 the company likely has access to a &lt;em&gt;trove&lt;/em&gt; of information that could shed light on the effectiveness of remote work, including productivity metrics, employee satisfaction surveys, and more. It&amp;#39;s puzzling why they would not utilize this data to inform their decisions, especially when the well-being and productivity of their workforce are at stake. Without clear and data-backed justifications, employees may feel undervalued and may question the credibility of leadership&amp;#39;s intentions.&lt;/p&gt;\n\n&lt;p&gt;Amazon&amp;#39;s senior leadership should remember their commitment to data-driven principles and engage in transparent decision-making. If there are legitimate reasons to return to the office, they owe it to their employees to present the data and engage in an open discussion about the pros and cons. By withholding critical information, they are undermining trust and potentially making decisions that could hurt the company in the long run.&lt;/p&gt;\n\n&lt;p&gt;As a data science practitioner, I believe it&amp;#39;s not just about having access to data; it&amp;#39;s also about using it responsibly and ethically. Using data to back up preconceived beliefs, or worse, hiding data that counters those beliefs, undermines the credibility and ethics of data science as a field and the trust we place in data-driven decision-making.&lt;/p&gt;\n\n&lt;p&gt;In conclusion, the misuse and omission of data by executives is not only frustrating to witness but also detrimental to the progress of organizations. I find it incredibly disappointing that executives at Amazon, a company known for being data-driven, would advocate for a return to the office without any supporting data. As data scientists, we have a responsibility to advocate for the ethical and rigorous use of data, and as consumers and employees, we have the right to demand evidence-based decision-making from the companies we support.&lt;/p&gt;\n\n&lt;p&gt;Am I alone in this? I&amp;#39;d love to hear the community\u2019s thoughts on this matter.&lt;/p&gt;\n\n&lt;p&gt;TL;DR: Amazon&amp;#39;s senior leadership&amp;#39;s recent push for a return to office without any supporting data is a disappointment to their reputation as a data-driven company. Executives should practice what they preach and make decisions based on objective data rather than personal beliefs or preferences. This behavior is not only disrespectful to employees but also detrimental to the company&amp;#39;s long-term success. When data takes a backseat it flies in the face of what Data Science is all about.  &lt;/p&gt;\n\n&lt;p&gt;Link to article: &lt;a href=\"https://fortune.com/2023/08/03/amazon-svp-mike-hopkins-office-return/\"&gt;https://fortune.com/2023/08/03/amazon-svp-mike-hopkins-office-return/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TzfRkICddanYQ2OYxc5D9BPTZRDTIvVf0aGJEz3IrTw.jpg?auto=webp&amp;s=228e2b519357c46434e53002d2bf3726904f8924", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/TzfRkICddanYQ2OYxc5D9BPTZRDTIvVf0aGJEz3IrTw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9bc13b0c2fee801a7d7e1b09090a3c7cb3b473cf", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/TzfRkICddanYQ2OYxc5D9BPTZRDTIvVf0aGJEz3IrTw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aff29b9608f05751cb990c974756193631444e3b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/TzfRkICddanYQ2OYxc5D9BPTZRDTIvVf0aGJEz3IrTw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d2ff6aa9094bc10ba8d139543f8a5642621111df", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/TzfRkICddanYQ2OYxc5D9BPTZRDTIvVf0aGJEz3IrTw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6d5ab8c85a70217af114579baa790bd4b75223af", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/TzfRkICddanYQ2OYxc5D9BPTZRDTIvVf0aGJEz3IrTw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6a1e92fa0c00f44028e1650ca9f975cb0984e137", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/TzfRkICddanYQ2OYxc5D9BPTZRDTIvVf0aGJEz3IrTw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=847ffd95401475355cfbb36e160e030da7027957", "width": 1080, "height": 540}], "variants": {}, "id": "FZFI78bdhAsFmuV_T2Li4FaOalxqaHE5Pd1Yy3PC2vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jzuh8", "is_robot_indexable": true, "report_reasons": null, "author": "throwawayDATUM", "discussion_type": null, "num_comments": 59, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jzuh8/from_datadriven_to_dataignored_a_disappointing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jzuh8/from_datadriven_to_dataignored_a_disappointing/", "subreddit_subscribers": 977470, "created_utc": 1691354029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Our company hires Deloitte and McKinsey every now and then and pays them huge amounts of money to do data science projects for us. I'm supposed to understand and take delivery of their work. The problem is what they do seems like scam to me. I try to raise awareness about it, but leadership seems not to care too much. Their code is trash, and they manipulate their model performance and present it through fancy slides and well-spoken presenters so that it looks acceptable. To give you an example, they fine-tune their models on the test set and squeeze the hell out of it and then say their model will generalize well to future data because of this performance on the test set. Most surprisingly, they improvise and invent new ways to evaluate the performance by, for example calculating precision and recall in a weird way that doesn't make sense. Does anyone have a similar experience?", "author_fullname": "t2_2glar9kb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How's your experience with consulting companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k2pxz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 123, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 123, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691379514.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691361103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our company hires Deloitte and McKinsey every now and then and pays them huge amounts of money to do data science projects for us. I&amp;#39;m supposed to understand and take delivery of their work. The problem is what they do seems like scam to me. I try to raise awareness about it, but leadership seems not to care too much. Their code is trash, and they manipulate their model performance and present it through fancy slides and well-spoken presenters so that it looks acceptable. To give you an example, they fine-tune their models on the test set and squeeze the hell out of it and then say their model will generalize well to future data because of this performance on the test set. Most surprisingly, they improvise and invent new ways to evaluate the performance by, for example calculating precision and recall in a weird way that doesn&amp;#39;t make sense. Does anyone have a similar experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15k2pxz", "is_robot_indexable": true, "report_reasons": null, "author": "shshmss", "discussion_type": null, "num_comments": 51, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15k2pxz/hows_your_experience_with_consulting_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15k2pxz/hows_your_experience_with_consulting_companies/", "subreddit_subscribers": 977470, "created_utc": 1691361103.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My aim is to build up the skills of a competent DA, DS and DE over the next few years. If anyone has done this, could you explain if it has made a big difference when it comes to landing jobs?", "author_fullname": "t2_7qvort5t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone skilled in both DS and DE? If so, how much of an advantage did that give you in the job market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jlo1y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691315356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My aim is to build up the skills of a competent DA, DS and DE over the next few years. If anyone has done this, could you explain if it has made a big difference when it comes to landing jobs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jlo1y", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial_Space9001", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jlo1y/is_anyone_skilled_in_both_ds_and_de_if_so_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jlo1y/is_anyone_skilled_in_both_ds_and_de_if_so_how/", "subreddit_subscribers": 977470, "created_utc": 1691315356.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Was networking these past few weeks at a company career panel for the place I was interning at this summer. Two people had similar backgrounds to me (BS statistics). They ended up talking about how they progressed at the company starting out, the overall tasks they had, and what they were doing now as they have progressed. Both graduated school in 2015.\n\nBoth of them talked about their entry level data science job, as follows:\n\n\u201cPanelist 2 and I were both hired here at the consulting firm, and at the time another consultant was starting a \u201cAI Transformative Technologies lab\u201d that was just in its infancy. As fresh graduates, with out backgrounds we got by far our dream job. Panelist 2 and I were basically, from 8-5 everyday, were printing out stacks of deep learning papers, and building industry specific case studies for deep learning. In consulting, you often have many different clients for different industries, so we spent just everyday, building out a portfolio of case studies where we applied SOTA deep learning models, and pitched them to clients in each industry. Overall a dream job where we combined deep learning research with client facing presentations\u201d.\n\nAll in all, sounded like a dream job to me. Both of them worked 9 years, doing this, and then when I talked to them after, they both mentioned how they were now heading back to academia to do a PhD in statistics and the other a PhD in CS. At 31 years old, they are leaving this job, because they had moved up to a management level, and wanted to get back into deep learning again, and felt that academia and doing a PhD was where they felt they could succeed. \n\nI tell this story because sometimes I\u2019ve thought about this. I have an MS, but I know after a few years I\u2019m gonna miss the theoretical stuff I did in my MS, and will probably considering doing a PhD just for that. But something about that doesn\u2019t seem right. It feels that my motivation to go back to do a PhD is to \u201clearn more advanced stats\u201d so I can get away from managerial positions. Cause truthfully, I just don\u2019t really care about managing people, owning a product, or any of the corporate political BS that comes with moving up in a company. \n\nHas anyone else done a similar route to what those two panelists did? How has it been for you? What was that transition like? Do you regret it?", "author_fullname": "t2_uy28jztl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone gone back for a PhD in statistics after being in industry? [Q]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jqlaa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691331028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was networking these past few weeks at a company career panel for the place I was interning at this summer. Two people had similar backgrounds to me (BS statistics). They ended up talking about how they progressed at the company starting out, the overall tasks they had, and what they were doing now as they have progressed. Both graduated school in 2015.&lt;/p&gt;\n\n&lt;p&gt;Both of them talked about their entry level data science job, as follows:&lt;/p&gt;\n\n&lt;p&gt;\u201cPanelist 2 and I were both hired here at the consulting firm, and at the time another consultant was starting a \u201cAI Transformative Technologies lab\u201d that was just in its infancy. As fresh graduates, with out backgrounds we got by far our dream job. Panelist 2 and I were basically, from 8-5 everyday, were printing out stacks of deep learning papers, and building industry specific case studies for deep learning. In consulting, you often have many different clients for different industries, so we spent just everyday, building out a portfolio of case studies where we applied SOTA deep learning models, and pitched them to clients in each industry. Overall a dream job where we combined deep learning research with client facing presentations\u201d.&lt;/p&gt;\n\n&lt;p&gt;All in all, sounded like a dream job to me. Both of them worked 9 years, doing this, and then when I talked to them after, they both mentioned how they were now heading back to academia to do a PhD in statistics and the other a PhD in CS. At 31 years old, they are leaving this job, because they had moved up to a management level, and wanted to get back into deep learning again, and felt that academia and doing a PhD was where they felt they could succeed. &lt;/p&gt;\n\n&lt;p&gt;I tell this story because sometimes I\u2019ve thought about this. I have an MS, but I know after a few years I\u2019m gonna miss the theoretical stuff I did in my MS, and will probably considering doing a PhD just for that. But something about that doesn\u2019t seem right. It feels that my motivation to go back to do a PhD is to \u201clearn more advanced stats\u201d so I can get away from managerial positions. Cause truthfully, I just don\u2019t really care about managing people, owning a product, or any of the corporate political BS that comes with moving up in a company. &lt;/p&gt;\n\n&lt;p&gt;Has anyone else done a similar route to what those two panelists did? How has it been for you? What was that transition like? Do you regret it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jqlaa", "is_robot_indexable": true, "report_reasons": null, "author": "Direct-Touch469", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jqlaa/anyone_gone_back_for_a_phd_in_statistics_after/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jqlaa/anyone_gone_back_for_a_phd_in_statistics_after/", "subreddit_subscribers": 977470, "created_utc": 1691331028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been a \"Data Analyst\" for 4.5 years at a start up company i was part of different teams but i can say it's more R&amp;D and innovation mostly. As you can guess from culture of a startup my experience has been very scattered and wide.  My tasks has been all over the place, including: \n\n* Image/text data scraping or collection, cleaning , preprocessing, and pipeline creation\n* Front End development for B2B project to transform a mobile app to responsive web based app, and transforming Tableau dashboards to python or web based dashboard. Also random front end POC's for internal purposes and clients\n* Search engine / system creation using Elasticsearch plus semantic, hybrid , vector search techniques and integration of LLM with it which has been my main job for the past 5 months\n\nI feel like i didn't do real data analyst work end to end like there i was never actually given analysis of data tasks, my manager is giving me a chance to change my title and i don't know what to pick, plus i don't know in which way i can move forward in my career, even looking for new jobs is very frustrating to me as i am not confident in my skill set. Also the looming feeling of data analyst position is dying is kinda scaring me.  \n\n\nI am open to suggestion on how to move forward and if anyone wants me to send my CV privately to help i would appreciate it  \n", "author_fullname": "t2_gmo8ntm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do i go from here?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jtj5t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691338604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been a &amp;quot;Data Analyst&amp;quot; for 4.5 years at a start up company i was part of different teams but i can say it&amp;#39;s more R&amp;amp;D and innovation mostly. As you can guess from culture of a startup my experience has been very scattered and wide.  My tasks has been all over the place, including: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Image/text data scraping or collection, cleaning , preprocessing, and pipeline creation&lt;/li&gt;\n&lt;li&gt;Front End development for B2B project to transform a mobile app to responsive web based app, and transforming Tableau dashboards to python or web based dashboard. Also random front end POC&amp;#39;s for internal purposes and clients&lt;/li&gt;\n&lt;li&gt;Search engine / system creation using Elasticsearch plus semantic, hybrid , vector search techniques and integration of LLM with it which has been my main job for the past 5 months&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I feel like i didn&amp;#39;t do real data analyst work end to end like there i was never actually given analysis of data tasks, my manager is giving me a chance to change my title and i don&amp;#39;t know what to pick, plus i don&amp;#39;t know in which way i can move forward in my career, even looking for new jobs is very frustrating to me as i am not confident in my skill set. Also the looming feeling of data analyst position is dying is kinda scaring me.  &lt;/p&gt;\n\n&lt;p&gt;I am open to suggestion on how to move forward and if anyone wants me to send my CV privately to help i would appreciate it  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jtj5t", "is_robot_indexable": true, "report_reasons": null, "author": "AloneSYD", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jtj5t/where_do_i_go_from_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jtj5t/where_do_i_go_from_here/", "subreddit_subscribers": 977470, "created_utc": 1691338604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am really confused about what types of data exploration and inspection you are allowed to do on the whole dataset BEFORE setting aside the test set. In the end-to-end machine learning project demonstrated in Hands-On Machine Learning by Geron Aurelien, the author checks the following before setting aside a test set: 1) quantities of data points and null values, 2) value counts of each value in categorical columns, 3) statistical summary of numerical columns, including counts, mean, std, min, max, and 25/50/70 percentiles, 4) histogram distribution of each column to see the shape of data.\n\nDuring these initial data exploration and inspection, is there any risk of accidental data snooping since the test set has not been set aside? What exactly are you allowed to inspect and explore before setting aside the test set to avoid accidental data snooping?", "author_fullname": "t2_zowbk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Confused about data snooping before setting aside test set", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jweyx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691345709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am really confused about what types of data exploration and inspection you are allowed to do on the whole dataset BEFORE setting aside the test set. In the end-to-end machine learning project demonstrated in Hands-On Machine Learning by Geron Aurelien, the author checks the following before setting aside a test set: 1) quantities of data points and null values, 2) value counts of each value in categorical columns, 3) statistical summary of numerical columns, including counts, mean, std, min, max, and 25/50/70 percentiles, 4) histogram distribution of each column to see the shape of data.&lt;/p&gt;\n\n&lt;p&gt;During these initial data exploration and inspection, is there any risk of accidental data snooping since the test set has not been set aside? What exactly are you allowed to inspect and explore before setting aside the test set to avoid accidental data snooping?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jweyx", "is_robot_indexable": true, "report_reasons": null, "author": "jesseparks13", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jweyx/confused_about_data_snooping_before_setting_aside/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jweyx/confused_about_data_snooping_before_setting_aside/", "subreddit_subscribers": 977470, "created_utc": 1691345709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've taken Microsoft's DSLP to structure my current project but I'm unsure if I'm using it \"correctly\". They state that they want to be tool independent - but the template documents seem to have a certain approach in mind (e.g. ticketing, ...).\n\nCurrently, I have a shared folder hierarchy where I collect my raw and transformed data sets as files (CSV, xlsx, docx etc.). For each data set I have a text file with a description. For raw data I describe where the data comes from (source system, transaction, technical prerequisites, potential problems, ...) and for the transformed data I describe the transformation (raw data sources, type of transformation, assumptions made etc.), and I'll update them when necessary.\nI've only had the chance to apply the data collection and transformation part of the Lifecycle Process, some I'm still learning the tool.\n\nHaving said that, saving text files on a shared folder hierarchy - while it does the job well  for now- seems a bit flimsy to me. Does my approach scale for team work?\n\nAsking more generally, did the authors have a specific approach in mind like versioning of data and documentation, use of ticketing software or similar?\n\nHow do you use the Lifecycle Process yourself? How does your implementation differ?\n\nLinks:\nhttps://github.com/dslp/dslp\nhttps://techcommunity.microsoft.com/t5/ai-machine-learning-blog/mlops-is-not-enough/ba-p/1386789", "author_fullname": "t2_4j7ujk5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your experience with the Microsoft Data Science Lifecycle Process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k7ydi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691375455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve taken Microsoft&amp;#39;s DSLP to structure my current project but I&amp;#39;m unsure if I&amp;#39;m using it &amp;quot;correctly&amp;quot;. They state that they want to be tool independent - but the template documents seem to have a certain approach in mind (e.g. ticketing, ...).&lt;/p&gt;\n\n&lt;p&gt;Currently, I have a shared folder hierarchy where I collect my raw and transformed data sets as files (CSV, xlsx, docx etc.). For each data set I have a text file with a description. For raw data I describe where the data comes from (source system, transaction, technical prerequisites, potential problems, ...) and for the transformed data I describe the transformation (raw data sources, type of transformation, assumptions made etc.), and I&amp;#39;ll update them when necessary.\nI&amp;#39;ve only had the chance to apply the data collection and transformation part of the Lifecycle Process, some I&amp;#39;m still learning the tool.&lt;/p&gt;\n\n&lt;p&gt;Having said that, saving text files on a shared folder hierarchy - while it does the job well  for now- seems a bit flimsy to me. Does my approach scale for team work?&lt;/p&gt;\n\n&lt;p&gt;Asking more generally, did the authors have a specific approach in mind like versioning of data and documentation, use of ticketing software or similar?&lt;/p&gt;\n\n&lt;p&gt;How do you use the Lifecycle Process yourself? How does your implementation differ?&lt;/p&gt;\n\n&lt;p&gt;Links:\n&lt;a href=\"https://github.com/dslp/dslp\"&gt;https://github.com/dslp/dslp&lt;/a&gt;\n&lt;a href=\"https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/mlops-is-not-enough/ba-p/1386789\"&gt;https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/mlops-is-not-enough/ba-p/1386789&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ewohZdaSfI4TUTD0-kJl0dRg5VfZJKfvDsQp6YAhtEI.jpg?auto=webp&amp;s=1bae00367a6ec057b1bb345d99cbbb493ece7a99", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ewohZdaSfI4TUTD0-kJl0dRg5VfZJKfvDsQp6YAhtEI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63da1240107bb953c2017d20335a4ce7e4cdf3d5", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ewohZdaSfI4TUTD0-kJl0dRg5VfZJKfvDsQp6YAhtEI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4ab5cf06d4210d94323062b36659637fcfe0d30d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ewohZdaSfI4TUTD0-kJl0dRg5VfZJKfvDsQp6YAhtEI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=516880e491305674f69ab24514914731ed5855a4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ewohZdaSfI4TUTD0-kJl0dRg5VfZJKfvDsQp6YAhtEI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e4943fa930dd6933fd2f878fa20a2d5593bfc787", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ewohZdaSfI4TUTD0-kJl0dRg5VfZJKfvDsQp6YAhtEI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=35c6080a2ed8ba7763e5851d26d81c7c52814f6c", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ewohZdaSfI4TUTD0-kJl0dRg5VfZJKfvDsQp6YAhtEI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=124be8ff43723f1544829bfeed9086fd0161438d", "width": 1080, "height": 540}], "variants": {}, "id": "rftVnjGe_j7Tm7USp7L2PjMIUdjXu782KpmoCNRH-CM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15k7ydi", "is_robot_indexable": true, "report_reasons": null, "author": "norfkens2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15k7ydi/what_is_your_experience_with_the_microsoft_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15k7ydi/what_is_your_experience_with_the_microsoft_data/", "subreddit_subscribers": 977470, "created_utc": 1691375455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you guys have any recommendations for websites/books which are useful for starting out and exploring in the data science space (not theory/math books, but actual general career guidance)", "author_fullname": "t2_pgihp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Books for navigating career in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jopfo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691325722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you guys have any recommendations for websites/books which are useful for starting out and exploring in the data science space (not theory/math books, but actual general career guidance)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jopfo", "is_robot_indexable": true, "report_reasons": null, "author": "BadTacticss", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jopfo/books_for_navigating_career_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jopfo/books_for_navigating_career_in_data_science/", "subreddit_subscribers": 977470, "created_utc": 1691325722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I wrote a quantitative analysis MA thesis at uni.  I documented all my data steps as part of the effort, what data I used, how I cleaned it, dealing with missing values... etc. I am ready to start building a portfolio.   I used excel and spss.  It was a longitudinal cross-national analysis of religious consumer behavior across space/time.  Would this be a viable first project?  If you have questions please lmk", "author_fullname": "t2_3d1dp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project Portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k6b3r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691370704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a quantitative analysis MA thesis at uni.  I documented all my data steps as part of the effort, what data I used, how I cleaned it, dealing with missing values... etc. I am ready to start building a portfolio.   I used excel and spss.  It was a longitudinal cross-national analysis of religious consumer behavior across space/time.  Would this be a viable first project?  If you have questions please lmk&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15k6b3r", "is_robot_indexable": true, "report_reasons": null, "author": "doc334ft3", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15k6b3r/project_portfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15k6b3r/project_portfolio/", "subreddit_subscribers": 977470, "created_utc": 1691370704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Has anyone here worked on claims frequency modeling? Would love to pick brain especially in commercial/DOT data", "author_fullname": "t2_33rogmrn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Insurance Claims Frequency Modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k3gm9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691363023.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone here worked on claims frequency modeling? Would love to pick brain especially in commercial/DOT data&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15k3gm9", "is_robot_indexable": true, "report_reasons": null, "author": "FewStruggle", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15k3gm9/insurance_claims_frequency_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15k3gm9/insurance_claims_frequency_modeling/", "subreddit_subscribers": 977470, "created_utc": 1691363023.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I also posted the question [on StackExchange.](https://stats.stackexchange.com/questions/623313/forecasting-a-time-series-model-for-1000s-of-time-series)\n\nI'm currently immersed in a challenging forecasting project centred around predicting the required work hours to complete various tasks within a team setting. My dataset comprises crucial attributes, including team IDs, task IDs, hours, and dates. Specifically, I'm working with a comprehensive dataset containing distinct time series information for each unique combination of teams and tasks, resulting in approximately 8000 distinct time series. I aim to construct a robust forecasting model tailored to this intricate scenario.\n\nAmidst this endeavour, I've encountered several complexities. These include the diversity in time series lengths, the presence of both new and well-established teams and tasks, varying from 3 months to 2 years of data, and the potential incompleteness or gaps within the time series.\n\nTo provide deeper insight into the dataset's dynamics, each team is associated with a set of tasks, such as \"call customer\", \"draft email\", and \"follow up with a client\". The team members record daily time entries for these tasks, collectively contributing to the intricate web of time series data. The primary objective of my forecasting model is to predict future work hours based on historical observations, facilitating informed planning and decision-making by team leads.\n\nIn my pursuit of a scalable approach, I'm exploring the following strategies to enhance forecasting accuracy:\n\n1. Utilizing a diverse ensemble of time series models (e.g., Prophet, ARIMA) to boost forecasting precision, coupled with time series ensemble techniques for prediction aggregation (as detailed \\[here\\]([https://machinelearningmastery.com/tour-of-ensemble-learning-algorithms/](https://machinelearningmastery.com/tour-of-ensemble-learning-algorithms/))). The resultant ensemble models would be saved for future predictions.\n\n2. Tuning hyperparameters for individual models to optimize their predictive capabilities.\n\n3. Conducting rigorous machine learning experiments for each ensemble model to identify the most effective models based on varying hyperparameter configurations.\n\n4. Evaluating model performance using the Mean Absolute Percentage Error (MAPE) as the chosen evaluation metric. However, tasks with zero hours for certain days pose challenges to accurate MAPE calculation.\n\n5. I'm considering applying stationarity tests to comprehend the data more deeply. However, I'm seeking guidance on effectively scaling this approach to encompass the complexity of the 8000-time series.\n\nDespite these strategies, the challenge of scalability remains. For instance, training six models (ARIMA, ETS, BATS, TBATS, Prophet, and XGBoost) for each of the 8000 time series equates to a staggering 48,000 iterations without considering hyperparameter tuning. Given the substantial computation requirements, the practical feasibility of tracking these experiments using open-source MLOps tools like MLFlow is also a concern.\n\nI'm reaching out for valuable insights and guidance. I'm keen to learn about best practices, practical approaches, and any available resources that can help me navigate this challenging endeavour.\n\nThank you in advance for your expertise and assistance. ", "author_fullname": "t2_1yr4w8az", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Forecasting a Time Series Model for 1000s of Time Series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jna8c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691363767.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691321190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I also posted the question &lt;a href=\"https://stats.stackexchange.com/questions/623313/forecasting-a-time-series-model-for-1000s-of-time-series\"&gt;on StackExchange.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently immersed in a challenging forecasting project centred around predicting the required work hours to complete various tasks within a team setting. My dataset comprises crucial attributes, including team IDs, task IDs, hours, and dates. Specifically, I&amp;#39;m working with a comprehensive dataset containing distinct time series information for each unique combination of teams and tasks, resulting in approximately 8000 distinct time series. I aim to construct a robust forecasting model tailored to this intricate scenario.&lt;/p&gt;\n\n&lt;p&gt;Amidst this endeavour, I&amp;#39;ve encountered several complexities. These include the diversity in time series lengths, the presence of both new and well-established teams and tasks, varying from 3 months to 2 years of data, and the potential incompleteness or gaps within the time series.&lt;/p&gt;\n\n&lt;p&gt;To provide deeper insight into the dataset&amp;#39;s dynamics, each team is associated with a set of tasks, such as &amp;quot;call customer&amp;quot;, &amp;quot;draft email&amp;quot;, and &amp;quot;follow up with a client&amp;quot;. The team members record daily time entries for these tasks, collectively contributing to the intricate web of time series data. The primary objective of my forecasting model is to predict future work hours based on historical observations, facilitating informed planning and decision-making by team leads.&lt;/p&gt;\n\n&lt;p&gt;In my pursuit of a scalable approach, I&amp;#39;m exploring the following strategies to enhance forecasting accuracy:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Utilizing a diverse ensemble of time series models (e.g., Prophet, ARIMA) to boost forecasting precision, coupled with time series ensemble techniques for prediction aggregation (as detailed [here](&lt;a href=\"https://machinelearningmastery.com/tour-of-ensemble-learning-algorithms/\"&gt;https://machinelearningmastery.com/tour-of-ensemble-learning-algorithms/&lt;/a&gt;)). The resultant ensemble models would be saved for future predictions.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Tuning hyperparameters for individual models to optimize their predictive capabilities.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Conducting rigorous machine learning experiments for each ensemble model to identify the most effective models based on varying hyperparameter configurations.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Evaluating model performance using the Mean Absolute Percentage Error (MAPE) as the chosen evaluation metric. However, tasks with zero hours for certain days pose challenges to accurate MAPE calculation.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I&amp;#39;m considering applying stationarity tests to comprehend the data more deeply. However, I&amp;#39;m seeking guidance on effectively scaling this approach to encompass the complexity of the 8000-time series.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Despite these strategies, the challenge of scalability remains. For instance, training six models (ARIMA, ETS, BATS, TBATS, Prophet, and XGBoost) for each of the 8000 time series equates to a staggering 48,000 iterations without considering hyperparameter tuning. Given the substantial computation requirements, the practical feasibility of tracking these experiments using open-source MLOps tools like MLFlow is also a concern.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reaching out for valuable insights and guidance. I&amp;#39;m keen to learn about best practices, practical approaches, and any available resources that can help me navigate this challenging endeavour.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your expertise and assistance. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?auto=webp&amp;s=e25be8cb5cf2448d39a7e5ffc877e4d466b776d3", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9645cb9b1f6437724f04c3b63b841cf7766f27d6", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dc7ee570d3611e1ef9314d658423c42908808820", "width": 216, "height": 216}], "variants": {}, "id": "63C1GbYQbI4tHZMkw99e-qlyoYaGnG58yfnmnFUJ34s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jna8c", "is_robot_indexable": true, "report_reasons": null, "author": "Teethss", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jna8c/forecasting_a_time_series_model_for_1000s_of_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jna8c/forecasting_a_time_series_model_for_1000s_of_time/", "subreddit_subscribers": 977470, "created_utc": 1691321190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm wondering if there are neat jobs you can take that allow you to work as an apprentice would? This could be military, actual union jobs if they exist, contractor roles, etc. \n\nSomething that you can start and climb up the ladder, making a liveable wage, doing something interesting. I understand that means a sacrifice in one way or another, typically geographically.", "author_fullname": "t2_w22lr056", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any good routes people can take post graduation, with a little experience, that are similar to apprenticeships in the union?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15kam87", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691383644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m wondering if there are neat jobs you can take that allow you to work as an apprentice would? This could be military, actual union jobs if they exist, contractor roles, etc. &lt;/p&gt;\n\n&lt;p&gt;Something that you can start and climb up the ladder, making a liveable wage, doing something interesting. I understand that means a sacrifice in one way or another, typically geographically.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15kam87", "is_robot_indexable": true, "report_reasons": null, "author": "GetFkedPlease", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15kam87/are_there_any_good_routes_people_can_take_post/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15kam87/are_there_any_good_routes_people_can_take_post/", "subreddit_subscribers": 977470, "created_utc": 1691383644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, I'm a Masters in Data Science student currently studying in the USA. I'm seeking some career advice, and I'd appreciate your input on my situation.\n\n&amp;#x200B;\n\nTo give you a quick overview of my background, I completed my Bachelors in Computer Science in India. During my academic journey, I managed to gain some valuable experience through a couple of internships\u2014one in sales analytics and another in machine learning within the logistics industry. Additionally, I undertook two research projects focused on computer vision applied to geo data.\n\n&amp;#x200B;\n\nRecently, during my summer break, I was fortunate to secure a Data Science internship at a Venture Capital Firm. While I was grateful for the opportunity, this experience has left me somewhat confused about my career path.\n\n&amp;#x200B;\n\nInitially, I had envisioned myself working in the finance domain as a data scientist or machine learning engineer. I believed that working with financial data would be both exciting and lucrative. However, my latest internship made me realize that the application of ML in the Venture Capital and finance field might not be as prevalent as I initially thought. The company I interned at is well-respected but appears to heavily rely on Excel for their financial operations. I had discussions with the Managing Director, who is in charge of integrating new technologies within the company, and he explained that the finance domain is relatively slow in adopting emerging tech like cloud and ML.\n\n&amp;#x200B;\n\nDuring my internship, I did get the chance to work with Python, SQL, and PowerBI, which made it feel more like a data engineer or database engineer role. I ran SQL queries for the investment team, prepared data for them, and automated the integration of unstructured Excel data into the database. I did notice that Data Science is still used as an umbrella term in the industry, like I know some interns who basically did Business intelligence work under their data science internship\n\n&amp;#x200B;\n\nNow, I find myself at a crossroads, unsure whether to pursue roles in tech companies where I can focus on coding and delve into cutting-edge technologies like gen AI or MLOps or to explore positions in finance companies where I could gain deeper insights into financial concepts but might have to compromise on coding and use more traditional tools.\n\n&amp;#x200B;\n\nI'm torn between focusing on roles where I can use and learn upon my solid foundation in ML and coding (which I love and learned during my Masters) or embracing tech-related positions within the finance industry (because I'm genuinely passionate about this domain).\n\n&amp;#x200B;\n\nIf any of you have some valuable advice to share, I'd greatly appreciate it. Are there any finance companies that are actively implementing ML or moving away from exclusive reliance on tools like Excel? I'm open to exploring all possibilities and eager to hear your thoughts. I am just a beginner who is trying to get into this unique space so any advice or suggestion matters a lot to me. Thanks in advance for your insights!", "author_fullname": "t2_8rov94i8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Venture Capital Internship Left Me Confused about My Career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15k9z4e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691381623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I&amp;#39;m a Masters in Data Science student currently studying in the USA. I&amp;#39;m seeking some career advice, and I&amp;#39;d appreciate your input on my situation.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To give you a quick overview of my background, I completed my Bachelors in Computer Science in India. During my academic journey, I managed to gain some valuable experience through a couple of internships\u2014one in sales analytics and another in machine learning within the logistics industry. Additionally, I undertook two research projects focused on computer vision applied to geo data.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Recently, during my summer break, I was fortunate to secure a Data Science internship at a Venture Capital Firm. While I was grateful for the opportunity, this experience has left me somewhat confused about my career path.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Initially, I had envisioned myself working in the finance domain as a data scientist or machine learning engineer. I believed that working with financial data would be both exciting and lucrative. However, my latest internship made me realize that the application of ML in the Venture Capital and finance field might not be as prevalent as I initially thought. The company I interned at is well-respected but appears to heavily rely on Excel for their financial operations. I had discussions with the Managing Director, who is in charge of integrating new technologies within the company, and he explained that the finance domain is relatively slow in adopting emerging tech like cloud and ML.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;During my internship, I did get the chance to work with Python, SQL, and PowerBI, which made it feel more like a data engineer or database engineer role. I ran SQL queries for the investment team, prepared data for them, and automated the integration of unstructured Excel data into the database. I did notice that Data Science is still used as an umbrella term in the industry, like I know some interns who basically did Business intelligence work under their data science internship&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now, I find myself at a crossroads, unsure whether to pursue roles in tech companies where I can focus on coding and delve into cutting-edge technologies like gen AI or MLOps or to explore positions in finance companies where I could gain deeper insights into financial concepts but might have to compromise on coding and use more traditional tools.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m torn between focusing on roles where I can use and learn upon my solid foundation in ML and coding (which I love and learned during my Masters) or embracing tech-related positions within the finance industry (because I&amp;#39;m genuinely passionate about this domain).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If any of you have some valuable advice to share, I&amp;#39;d greatly appreciate it. Are there any finance companies that are actively implementing ML or moving away from exclusive reliance on tools like Excel? I&amp;#39;m open to exploring all possibilities and eager to hear your thoughts. I am just a beginner who is trying to get into this unique space so any advice or suggestion matters a lot to me. Thanks in advance for your insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15k9z4e", "is_robot_indexable": true, "report_reasons": null, "author": "Pradhan_Ji", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15k9z4e/venture_capital_internship_left_me_confused_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15k9z4e/venture_capital_internship_left_me_confused_about/", "subreddit_subscribers": 977470, "created_utc": 1691381623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 07 Aug, 2023 - 14 Aug, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15k9q93", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691380887.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15k9q93", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15k9q93/weekly_entering_transitioning_thread_07_aug_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/15k9q93/weekly_entering_transitioning_thread_07_aug_2023/", "subreddit_subscribers": 977470, "created_utc": 1691380887.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Any suggestions on how to prepare code data to fine tune a code LLM in an unsupervised way or is it even possible?\n\nFor example:\nTask: Code summarisation with custom code base (with no summaries)\nLet's assume that this code base is unique and a pre-trained model is giving unsatisfactory results. Now to fine tune there are three options,\n1. Manually prepare summaries for a portion of the code and fine tune \n2. Find a similar code base which has the labels (docstring) and fine tune\n3. Mask some portions of the code randomly and give as input and output will be the masked portions\n\nOptions 1 and 2 don't seem feasible for a production environment. \n\nThe reasoning behind option 3 is that with no availability labels, the model will learn the patterns in the code base and provide a better summarisation with its pre-trained knowledge.", "author_fullname": "t2_7ivnqxn4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unsupervised Fine Tuning of LLMs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k84pd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691375978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any suggestions on how to prepare code data to fine tune a code LLM in an unsupervised way or is it even possible?&lt;/p&gt;\n\n&lt;p&gt;For example:\nTask: Code summarisation with custom code base (with no summaries)\nLet&amp;#39;s assume that this code base is unique and a pre-trained model is giving unsatisfactory results. Now to fine tune there are three options,\n1. Manually prepare summaries for a portion of the code and fine tune \n2. Find a similar code base which has the labels (docstring) and fine tune\n3. Mask some portions of the code randomly and give as input and output will be the masked portions&lt;/p&gt;\n\n&lt;p&gt;Options 1 and 2 don&amp;#39;t seem feasible for a production environment. &lt;/p&gt;\n\n&lt;p&gt;The reasoning behind option 3 is that with no availability labels, the model will learn the patterns in the code base and provide a better summarisation with its pre-trained knowledge.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15k84pd", "is_robot_indexable": true, "report_reasons": null, "author": "dire_wolf_cookie", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15k84pd/unsupervised_fine_tuning_of_llms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15k84pd/unsupervised_fine_tuning_of_llms/", "subreddit_subscribers": 977470, "created_utc": 1691375978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a data set containing genomic data for 72 leukaemia patients, with one feature being class labels, and 1860 features being genomics measurements. The class labels have been removed and the dataset has been scaled.\n\nI want to assess if the patients cluster according to their original class labels. \n\nShould I be doing PCA prior to the hierarchical cluster? And how do I compare the clusters made to the original class labels?", "author_fullname": "t2_tir3dln2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PCA before Hierarchical Clustering for genomic data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k2hlt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691360501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a data set containing genomic data for 72 leukaemia patients, with one feature being class labels, and 1860 features being genomics measurements. The class labels have been removed and the dataset has been scaled.&lt;/p&gt;\n\n&lt;p&gt;I want to assess if the patients cluster according to their original class labels. &lt;/p&gt;\n\n&lt;p&gt;Should I be doing PCA prior to the hierarchical cluster? And how do I compare the clusters made to the original class labels?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15k2hlt", "is_robot_indexable": true, "report_reasons": null, "author": "Fun_Elevator_814", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15k2hlt/pca_before_hierarchical_clustering_for_genomic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15k2hlt/pca_before_hierarchical_clustering_for_genomic/", "subreddit_subscribers": 977470, "created_utc": 1691360501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey fellow data scientists,\n\nI'm grappling with a complex problem related to location data gathered from various apps, and I need your insights!\n\nThe Challenge:\nI'm tasked with counting how many customers are in a specific country's neighborhood on a given day. However, the number of apps providing this data can fluctuate, leading to skewed representations of customer density. For instance, more apps might falsely indicate a neighborhood is receiving more people.\n\nHere's what I've considered so far:\n\nSwitch to Percentages: Abandon absolute values and work with the percentage of visitors relative to data availability. This might involve developing a confidence interval around these percentages. (Suggestions on techniques here would be greatly appreciated!)\n\n\nNormalization Using Historical Data: Normalize the absolute values based on previous months' data. I'm thinking of using the median to adjust the value and analyze how well it fits the prior patterns.\n\n\nI'm eager to learn from your expertise. Have any of you tackled similar challenges? What strategies would you recommend? If you have any insights, papers, or tools that could help, please share!\n\nThank you all in advance. Let's crack this problem together!", "author_fullname": "t2_adagm480", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Help with Normalizing Visitor Counts Based on App-Provided Location Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jsv5d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691336940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow data scientists,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m grappling with a complex problem related to location data gathered from various apps, and I need your insights!&lt;/p&gt;\n\n&lt;p&gt;The Challenge:\nI&amp;#39;m tasked with counting how many customers are in a specific country&amp;#39;s neighborhood on a given day. However, the number of apps providing this data can fluctuate, leading to skewed representations of customer density. For instance, more apps might falsely indicate a neighborhood is receiving more people.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s what I&amp;#39;ve considered so far:&lt;/p&gt;\n\n&lt;p&gt;Switch to Percentages: Abandon absolute values and work with the percentage of visitors relative to data availability. This might involve developing a confidence interval around these percentages. (Suggestions on techniques here would be greatly appreciated!)&lt;/p&gt;\n\n&lt;p&gt;Normalization Using Historical Data: Normalize the absolute values based on previous months&amp;#39; data. I&amp;#39;m thinking of using the median to adjust the value and analyze how well it fits the prior patterns.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m eager to learn from your expertise. Have any of you tackled similar challenges? What strategies would you recommend? If you have any insights, papers, or tools that could help, please share!&lt;/p&gt;\n\n&lt;p&gt;Thank you all in advance. Let&amp;#39;s crack this problem together!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jsv5d", "is_robot_indexable": true, "report_reasons": null, "author": "dmirandaalves", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jsv5d/need_help_with_normalizing_visitor_counts_based/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jsv5d/need_help_with_normalizing_visitor_counts_based/", "subreddit_subscribers": 977470, "created_utc": 1691336940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a use case for which I have to decide the best DB to use.\n\nUse Case:\nMultiple people will read row-wise and update the row they were assigned. For example, I want to label text as either happy, sad or neutral. All the sentences are in a DB as rows. Now 5 people can label at a time. This means 5 people will be reading and updating individual rows.\n\nQuestion:\nWhich in your opinion is the most optimal DB for such operations and why?\n\nI am leaning towards redis, but I don't have a background in software engineering.", "author_fullname": "t2_5bjmm66f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best DB for a problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jlkd8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691314970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a use case for which I have to decide the best DB to use.&lt;/p&gt;\n\n&lt;p&gt;Use Case:\nMultiple people will read row-wise and update the row they were assigned. For example, I want to label text as either happy, sad or neutral. All the sentences are in a DB as rows. Now 5 people can label at a time. This means 5 people will be reading and updating individual rows.&lt;/p&gt;\n\n&lt;p&gt;Question:\nWhich in your opinion is the most optimal DB for such operations and why?&lt;/p&gt;\n\n&lt;p&gt;I am leaning towards redis, but I don&amp;#39;t have a background in software engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jlkd8", "is_robot_indexable": true, "report_reasons": null, "author": "hark_in_tranquillity", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jlkd8/best_db_for_a_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jlkd8/best_db_for_a_problem/", "subreddit_subscribers": 977470, "created_utc": 1691314970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I want to detect an object but only if they are in some specific regions, which are not static so I cannot manually crop the image.\n\nLets say we are detecting phones but we only want phones that are not put securely, ie. they might drop to ground if someone touches them or they might get wet since there is sink etc. So obviously not all phones in all images are labelled. Also image context is enough for the person to label these specific phones.\n\nThe most obvious answer for how to proceed is try and see, \\[train with the labels and observe metrics on region proposal networks\\] but I want to ask for your opinions. Thanks in advance!", "author_fullname": "t2_8dt4hm2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] detecting only specific instances of the object", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jj8n9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691306544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I want to detect an object but only if they are in some specific regions, which are not static so I cannot manually crop the image.&lt;/p&gt;\n\n&lt;p&gt;Lets say we are detecting phones but we only want phones that are not put securely, ie. they might drop to ground if someone touches them or they might get wet since there is sink etc. So obviously not all phones in all images are labelled. Also image context is enough for the person to label these specific phones.&lt;/p&gt;\n\n&lt;p&gt;The most obvious answer for how to proceed is try and see, [train with the labels and observe metrics on region proposal networks] but I want to ask for your opinions. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jj8n9", "is_robot_indexable": true, "report_reasons": null, "author": "Street_Excitement_14", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jj8n9/d_detecting_only_specific_instances_of_the_object/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jj8n9/d_detecting_only_specific_instances_of_the_object/", "subreddit_subscribers": 977470, "created_utc": 1691306544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a project idea that would require scraping the twitter feeds of participants in the study and asking them questions about the \"For you\" tab and \"Following\" tab. \n\nI've read up on the API, but I still have questions about what is possible. Is there a way to pull the tweets a user sees on their timeline? It looked like there might be a way to do this for one user (for example, my own personal account), but I couldn't find anything about doing this for multiple users. \n\nOf course, it might not be possible, but any information or ideas would be helpful. If it's possible on other platforms, that would be helpful to know as well. \n\nThanks! ", "author_fullname": "t2_5cu3a3ep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scraping Twitter Feeds", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k5al3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691367890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a project idea that would require scraping the twitter feeds of participants in the study and asking them questions about the &amp;quot;For you&amp;quot; tab and &amp;quot;Following&amp;quot; tab. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read up on the API, but I still have questions about what is possible. Is there a way to pull the tweets a user sees on their timeline? It looked like there might be a way to do this for one user (for example, my own personal account), but I couldn&amp;#39;t find anything about doing this for multiple users. &lt;/p&gt;\n\n&lt;p&gt;Of course, it might not be possible, but any information or ideas would be helpful. If it&amp;#39;s possible on other platforms, that would be helpful to know as well. &lt;/p&gt;\n\n&lt;p&gt;Thanks! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15k5al3", "is_robot_indexable": true, "report_reasons": null, "author": "MysteriousResource3", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15k5al3/scraping_twitter_feeds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15k5al3/scraping_twitter_feeds/", "subreddit_subscribers": 977470, "created_utc": 1691367890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to learn about data compression and maybe working on building a compression algorithm but I don't have resources to learn can pls recommend?", "author_fullname": "t2_h0hth8dnw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hello friend I need help (data compression)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jysb8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691351488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to learn about data compression and maybe working on building a compression algorithm but I don&amp;#39;t have resources to learn can pls recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jysb8", "is_robot_indexable": true, "report_reasons": null, "author": "OTInternet", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jysb8/hello_friend_i_need_help_data_compression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jysb8/hello_friend_i_need_help_data_compression/", "subreddit_subscribers": 977470, "created_utc": 1691351488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Premise: I have a time series problem where Im trying to predict the completion of a task. Theres a ton of information, and the model predicts reasonably well throughout the lifecycle.\nAs i would expect, the accuracy should get better and better as time goes on, as more information comes in and time gets shorter, but there is one spot where the MAE spikes, and it would have been better to estimate from previous predictions. Whats the best way to resolve this?\n \n[Heres the graph of the Accuracy over time that im trying to resolve](https://imgur.com/hMT4nLh). Days From Completion is my target variable.\n\nWould love your input for approaches to try. This is what im thinking\n\n1. use LSTMs prediction as another predictor, and feed it to a linear regression. What do I need to do here in regards to train/test? I'd really not like to go down this route as i have to deal with multiple models. \n\n2. Change the architecture. Not really sure the best way to accommodate for previous info to smooth out the line.", "author_fullname": "t2_9ei17", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LSTM Time Series Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jrzjf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691334699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Premise: I have a time series problem where Im trying to predict the completion of a task. Theres a ton of information, and the model predicts reasonably well throughout the lifecycle.\nAs i would expect, the accuracy should get better and better as time goes on, as more information comes in and time gets shorter, but there is one spot where the MAE spikes, and it would have been better to estimate from previous predictions. Whats the best way to resolve this?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/hMT4nLh\"&gt;Heres the graph of the Accuracy over time that im trying to resolve&lt;/a&gt;. Days From Completion is my target variable.&lt;/p&gt;\n\n&lt;p&gt;Would love your input for approaches to try. This is what im thinking&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;use LSTMs prediction as another predictor, and feed it to a linear regression. What do I need to do here in regards to train/test? I&amp;#39;d really not like to go down this route as i have to deal with multiple models. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Change the architecture. Not really sure the best way to accommodate for previous info to smooth out the line.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wGoRWMB5xZzsrQjOmG4gTCulsqqVBqhgUpv1VEWpQHU.jpg?auto=webp&amp;s=d40eb85fa57cc746a36e86ba75bc6eb168cb80fc", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/wGoRWMB5xZzsrQjOmG4gTCulsqqVBqhgUpv1VEWpQHU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d8c849fe3a1ebe97bd261bdb294452b4802d85c", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/wGoRWMB5xZzsrQjOmG4gTCulsqqVBqhgUpv1VEWpQHU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=12996c4d2ad06aa77ad13e306ba4953f0e8a7be1", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/wGoRWMB5xZzsrQjOmG4gTCulsqqVBqhgUpv1VEWpQHU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4ffa8e4148f5c58df4f03ae6e6e67aa945fff60e", "width": 320, "height": 168}], "variants": {}, "id": "HOFOfyMWfZ0FuUarIhVEfua1E5WNJ_81bJPDZK7CuC0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jrzjf", "is_robot_indexable": true, "report_reasons": null, "author": "LucidChess", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jrzjf/lstm_time_series_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jrzjf/lstm_time_series_question/", "subreddit_subscribers": 977470, "created_utc": 1691334699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_tep294qj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Logistic Model for finding important factors of divorce", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_15jink5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/lcpx4-eSgR4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Logistic Model for finding important factors of divorce\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Logistic Model for finding important factors of divorce", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/lcpx4-eSgR4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Logistic Model for finding important factors of divorce\"&gt;&lt;/iframe&gt;", "author_name": "Tkk Nuggets", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/lcpx4-eSgR4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@tkprotich1617"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/lcpx4-eSgR4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Logistic Model for finding important factors of divorce\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/15jink5", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_CXYfyi-elK0ZDO2Xi4HiY8PMdrF_Gqt-r9_UaVZeJo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691304484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/lcpx4-eSgR4", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cpHrjRygYWuyOM9YIqeQLwiaCba7Dc44wiTl-mUokuw.jpg?auto=webp&amp;s=09c2fb83e1b3044672a3943d826083a4a620551a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/cpHrjRygYWuyOM9YIqeQLwiaCba7Dc44wiTl-mUokuw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=781ac07904960a1166e6d6e25cf76b26b379e5e8", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/cpHrjRygYWuyOM9YIqeQLwiaCba7Dc44wiTl-mUokuw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1ee91acd2818a76afbec51834fb1bdf1e5e347a3", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/cpHrjRygYWuyOM9YIqeQLwiaCba7Dc44wiTl-mUokuw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=43a12f0dc7bda4ed20045e6c4bcf32d25e314d8e", "width": 320, "height": 240}], "variants": {}, "id": "DSTlkuKkIkeT_Ys9Sc3MbS0DfmcVNqjVFB7VI1Dl5GU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jink5", "is_robot_indexable": true, "report_reasons": null, "author": "TKPROTICH", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jink5/logistic_model_for_finding_important_factors_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/lcpx4-eSgR4", "subreddit_subscribers": 977470, "created_utc": 1691304484.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Logistic Model for finding important factors of divorce", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/lcpx4-eSgR4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Logistic Model for finding important factors of divorce\"&gt;&lt;/iframe&gt;", "author_name": "Tkk Nuggets", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/lcpx4-eSgR4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@tkprotich1617"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all I work as a System Engineer in providing infra support.\n\nI want to transition to Data Science domain in my career. And honestly looking at what courses or free resources to pursue I feel a bit lost\n\nIt would be very helpful if y'all can suggest and advice me on giving a Roadmap and materials/YouTube channels ( paid courses are welcome too )\n\nThanks in advance", "author_fullname": "t2_h31rkak3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help on getting to start in Data Science domain", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k22h0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691359434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all I work as a System Engineer in providing infra support.&lt;/p&gt;\n\n&lt;p&gt;I want to transition to Data Science domain in my career. And honestly looking at what courses or free resources to pursue I feel a bit lost&lt;/p&gt;\n\n&lt;p&gt;It would be very helpful if y&amp;#39;all can suggest and advice me on giving a Roadmap and materials/YouTube channels ( paid courses are welcome too )&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15k22h0", "is_robot_indexable": true, "report_reasons": null, "author": "Strange_Builder6255", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15k22h0/need_help_on_getting_to_start_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15k22h0/need_help_on_getting_to_start_in_data_science/", "subreddit_subscribers": 977470, "created_utc": 1691359434.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}