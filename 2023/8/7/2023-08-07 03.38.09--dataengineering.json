{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a Postgresql server running on AWS ECE2 t2.small instance.\n\none of its tables contains  4,629,588 rows. on average around 50k rows are written on it daily. The data are coming from another application server. The purpose of this database is to serve the BI tools like powerBI. But a simple SELECT  query takes a lot of time, and PowerBI refresh time takes around 40 minutes.\n\nHow can I speed up my query times and reduce the time it takes to refresh the data in PowerBI?\n\nDo I need to scale up the instance configuration or it is something else", "author_fullname": "t2_6wue8mt3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fixing slow queries in Postgresql", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jlrkd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691315727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Postgresql server running on AWS ECE2 t2.small instance.&lt;/p&gt;\n\n&lt;p&gt;one of its tables contains  4,629,588 rows. on average around 50k rows are written on it daily. The data are coming from another application server. The purpose of this database is to serve the BI tools like powerBI. But a simple SELECT  query takes a lot of time, and PowerBI refresh time takes around 40 minutes.&lt;/p&gt;\n\n&lt;p&gt;How can I speed up my query times and reduce the time it takes to refresh the data in PowerBI?&lt;/p&gt;\n\n&lt;p&gt;Do I need to scale up the instance configuration or it is something else&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jlrkd", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPickles736", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jlrkd/fixing_slow_queries_in_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jlrkd/fixing_slow_queries_in_postgresql/", "subreddit_subscribers": 121184, "created_utc": 1691315727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How's the current job market for Senior Data Engineers, especially in Europe? \n\nIs it easy to switch job, are there alot of demand with few competition?", "author_fullname": "t2_8ijlo4rl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Status quo job market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jmpo8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691319195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How&amp;#39;s the current job market for Senior Data Engineers, especially in Europe? &lt;/p&gt;\n\n&lt;p&gt;Is it easy to switch job, are there alot of demand with few competition?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jmpo8", "is_robot_indexable": true, "report_reasons": null, "author": "Noway721", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jmpo8/status_quo_job_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jmpo8/status_quo_job_market/", "subreddit_subscribers": 121184, "created_utc": 1691319195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just wondering if people see all three of these as being necessary. I\u2019m in an organization that has an Azure data warehouse. This gives us access to ADF. But databricks salespeople have started reaching out to us recently. \n\nThe ability to work within python and r in databricks sounds great. But how does it differ from a more sql-based tool like dbt?\n\nFor context, my background is more in data analytics/science. But our organization (from what I\u2019ve seen after being here a couple months) is in desperate need of data engineering skills. They\u2019ve gone out and hired data scientists, but their basic institutional data is a mess and in many cases not existent in the warehouse.", "author_fullname": "t2_9ytsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you need Azure Data Factory and Databricks? What about dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jxfd4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691348215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wondering if people see all three of these as being necessary. I\u2019m in an organization that has an Azure data warehouse. This gives us access to ADF. But databricks salespeople have started reaching out to us recently. &lt;/p&gt;\n\n&lt;p&gt;The ability to work within python and r in databricks sounds great. But how does it differ from a more sql-based tool like dbt?&lt;/p&gt;\n\n&lt;p&gt;For context, my background is more in data analytics/science. But our organization (from what I\u2019ve seen after being here a couple months) is in desperate need of data engineering skills. They\u2019ve gone out and hired data scientists, but their basic institutional data is a mess and in many cases not existent in the warehouse.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jxfd4", "is_robot_indexable": true, "report_reasons": null, "author": "ursamajorm82", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jxfd4/do_you_need_azure_data_factory_and_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jxfd4/do_you_need_azure_data_factory_and_databricks/", "subreddit_subscribers": 121184, "created_utc": 1691348215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "pandas.dataframe is now the standard structural data API in machine learning, but pandas is single node and in-core(in RAM computing), so there have been attempts to port pandas API to parallel and out-of-core environments, such as pandas-on-spark, dask, polars etc.\n\nBesides Spark, is there any SQL RDBMS backend providing the pandas dataframe API?\n\nI mean any python library \"pa\" that provides:\n\n* pa.DataFrame --- every DataFrame object has a database table in a RDBMS, and every computation, including python functions, to be compiled into SQL code that executes on the RDBMS. Data manipulation coded in python can be implemented in foreign functions of the RDBMS.\n* The node running python only generate queries and translate between python and rdbms. The actual data processing is performed by RDBMS (thus parallel, out of core and support partitioning/sharding)", "author_fullname": "t2_igoo081k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a RDBMS-based backend providing the pandas dataframe api?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jpf9b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691327792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;pandas.dataframe is now the standard structural data API in machine learning, but pandas is single node and in-core(in RAM computing), so there have been attempts to port pandas API to parallel and out-of-core environments, such as pandas-on-spark, dask, polars etc.&lt;/p&gt;\n\n&lt;p&gt;Besides Spark, is there any SQL RDBMS backend providing the pandas dataframe API?&lt;/p&gt;\n\n&lt;p&gt;I mean any python library &amp;quot;pa&amp;quot; that provides:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;pa.DataFrame --- every DataFrame object has a database table in a RDBMS, and every computation, including python functions, to be compiled into SQL code that executes on the RDBMS. Data manipulation coded in python can be implemented in foreign functions of the RDBMS.&lt;/li&gt;\n&lt;li&gt;The node running python only generate queries and translate between python and rdbms. The actual data processing is performed by RDBMS (thus parallel, out of core and support partitioning/sharding)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jpf9b", "is_robot_indexable": true, "report_reasons": null, "author": "larryliu7", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jpf9b/is_there_a_rdbmsbased_backend_providing_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jpf9b/is_there_a_rdbmsbased_backend_providing_the/", "subreddit_subscribers": 121184, "created_utc": 1691327792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[edited to clarify I'm asking about what to concentrate on for a DE in context of learning python generally]  \n\nIf a practicing/aspiring DE asks  \"what python do I need for DE?\" below are my thoughts about what to concentrate on/supplement  from a \"general python\" class, would like to get feedback. The core of such classes is about general path of execution control, and using lists, dictionaries, sets and tuple, manipulating strings. All that stuff is crucial, if you have it down cold you'll be better off for both jobs and interviews. \n\nBut when general classes move on to bigger programs I'm interested in thoughts about *what's likely to be most crucial for DEs, or useful and not touched on* by such a class.\n\n\n**likely covered, but less important for a DE than for a general SWE**\n\n   Design to take advantage of OO concepts (any python class will cover instantiating objects and accessing attributes, which you do need)  \n   multi-threading and multi-processing  \n   tkinter or other desktop GUI framework  \n   subprocess control (popen)  \n   Dataclass (given the name, its surprising, but I haven't talked to DEs who use these)  \n\n**likely less/not covered, often important for DEs**\n\n   *comes-with libs*:  \n   datetime -- deltas, arithmetic, date&lt;-&gt;string, timezone handling, pytz &amp; post 3.10(?) built-in  \n   zipfile  \n   csv  \n   pathlib  \n   re, and familiarity with string functions likely alternative (startswith, in) (if you use re and don't need it that might look bad in interview)  \n   Decimal v float (rounding with money)  \n\n   *Additional libs*:\n   pytz (as a predecssor to datetime.timzone (still widely used))  \n   chardet  \n   pandas  (just understanding its filter syntax, like df\\[df\\['poo'\\] &gt; 3\\], puts you ahead of the bottom candidates already)  \n   requests  (and non-python you should take a short course on postman and curl &amp; learn a bit about headers and tokens)  \n   fastapi and/or DRF (read about both) (it's not obviously DE-ish, but 3 \"ETL\" teams I know have put up FASTapi stuff) (anyway DEs should have basic idea of HTTP apps, apis, basic REST theory, and at least know you don't know about SOAP)  \n\n*edit* - Likely not covered at all in a python class but likely to be relevant: jinja2 (used in dbt) and sqlalchemy (used widely but esp. with pandas)\n\nIn my experience SQL is crucial and I think if you can't do \"medium\" leetcode sql you're likely to have problems in any DE interview, whether it's really relevant to that specific job or not.  \n\nGeneral algorithm/data structure knowledge isn't important for most DE practitioners day-to-day, but necessary to clear interviews at some companies (I've never encountered this in about 15 interviews thru my career, all &lt; $150K/yr in today's US$).  If you're looking to enter the DE field, you should be familiar enough with LC to know if you can get up to speed on medium or hard LC if you need to.", "author_fullname": "t2_abfpw4qq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "python specifically for DE positions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k0sbu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691375655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691356283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[edited to clarify I&amp;#39;m asking about what to concentrate on for a DE in context of learning python generally]  &lt;/p&gt;\n\n&lt;p&gt;If a practicing/aspiring DE asks  &amp;quot;what python do I need for DE?&amp;quot; below are my thoughts about what to concentrate on/supplement  from a &amp;quot;general python&amp;quot; class, would like to get feedback. The core of such classes is about general path of execution control, and using lists, dictionaries, sets and tuple, manipulating strings. All that stuff is crucial, if you have it down cold you&amp;#39;ll be better off for both jobs and interviews. &lt;/p&gt;\n\n&lt;p&gt;But when general classes move on to bigger programs I&amp;#39;m interested in thoughts about &lt;em&gt;what&amp;#39;s likely to be most crucial for DEs, or useful and not touched on&lt;/em&gt; by such a class.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;likely covered, but less important for a DE than for a general SWE&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Design to take advantage of OO concepts (any python class will cover instantiating objects and accessing attributes, which you do need)&lt;br/&gt;\n   multi-threading and multi-processing&lt;br/&gt;\n   tkinter or other desktop GUI framework&lt;br/&gt;\n   subprocess control (popen)&lt;br/&gt;\n   Dataclass (given the name, its surprising, but I haven&amp;#39;t talked to DEs who use these)  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;likely less/not covered, often important for DEs&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;comes-with libs&lt;/em&gt;:&lt;br/&gt;\n   datetime -- deltas, arithmetic, date&amp;lt;-&amp;gt;string, timezone handling, pytz &amp;amp; post 3.10(?) built-in&lt;br/&gt;\n   zipfile&lt;br/&gt;\n   csv&lt;br/&gt;\n   pathlib&lt;br/&gt;\n   re, and familiarity with string functions likely alternative (startswith, in) (if you use re and don&amp;#39;t need it that might look bad in interview)&lt;br/&gt;\n   Decimal v float (rounding with money)  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Additional libs&lt;/em&gt;:\n   pytz (as a predecssor to datetime.timzone (still widely used))&lt;br/&gt;\n   chardet&lt;br/&gt;\n   pandas  (just understanding its filter syntax, like df[df[&amp;#39;poo&amp;#39;] &amp;gt; 3], puts you ahead of the bottom candidates already)&lt;br/&gt;\n   requests  (and non-python you should take a short course on postman and curl &amp;amp; learn a bit about headers and tokens)&lt;br/&gt;\n   fastapi and/or DRF (read about both) (it&amp;#39;s not obviously DE-ish, but 3 &amp;quot;ETL&amp;quot; teams I know have put up FASTapi stuff) (anyway DEs should have basic idea of HTTP apps, apis, basic REST theory, and at least know you don&amp;#39;t know about SOAP)  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;edit&lt;/em&gt; - Likely not covered at all in a python class but likely to be relevant: jinja2 (used in dbt) and sqlalchemy (used widely but esp. with pandas)&lt;/p&gt;\n\n&lt;p&gt;In my experience SQL is crucial and I think if you can&amp;#39;t do &amp;quot;medium&amp;quot; leetcode sql you&amp;#39;re likely to have problems in any DE interview, whether it&amp;#39;s really relevant to that specific job or not.  &lt;/p&gt;\n\n&lt;p&gt;General algorithm/data structure knowledge isn&amp;#39;t important for most DE practitioners day-to-day, but necessary to clear interviews at some companies (I&amp;#39;ve never encountered this in about 15 interviews thru my career, all &amp;lt; $150K/yr in today&amp;#39;s US$).  If you&amp;#39;re looking to enter the DE field, you should be familiar enough with LC to know if you can get up to speed on medium or hard LC if you need to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k0sbu", "is_robot_indexable": true, "report_reasons": null, "author": "levintennine", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k0sbu/python_specifically_for_de_positions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k0sbu/python_specifically_for_de_positions/", "subreddit_subscribers": 121184, "created_utc": 1691356283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Figma for Data Products: Novel tech requires enough experimentation and a big playground", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15jntr6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LKVQdyJQAYKiDuaUXQrvh3qwoHP2KS8eJQ0e0YOOR3c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691323022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/figma-for-data-products-novel-tech", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?auto=webp&amp;s=00fe75becd7940bd54c29c8c2a2edbabfdb4f068", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d2de591a2defe24dffb8588eb3458f8e940e19d6", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dd2f9af5562dbbebf11bdc84ceb83400b221347f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f9bed5581f8673e4a5319a878b430911abf75a76", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2db00580b5f6d991d365795383694d2b6b6a8af4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c9e161886c464d256b9425d9d11eb45111e2b8c2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e5d1a5d8dcb27a1b5c61bde3af86077d83783c93", "width": 1080, "height": 540}], "variants": {}, "id": "DjHOPoos8rWBEZLEKOpFCb-GTBmxyeuofzBUipivrKw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15jntr6", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jntr6/figma_for_data_products_novel_tech_requires/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/figma-for-data-products-novel-tech", "subreddit_subscribers": 121184, "created_utc": 1691323022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am doing modeling in python to maintain a next best action python model in that tracks relationships in dynamics. 1. the system is expensive to run 2. the data is ugly / messy. I'm supposed to be supporting our sales org with data insights as a \"data analyst\". I like the notebook approach of synapse. I feel like azure can go infinitely deep. Is anyone else using dynamics and doing analytics with it?", "author_fullname": "t2_8klzm7ui", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dropped into Azure as a newbie 60 days in, using Dynamics / Synapse / PowerBI/ Pyspark (sql). What do I need to learn? WTF is fabric?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15k6vai", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691372297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am doing modeling in python to maintain a next best action python model in that tracks relationships in dynamics. 1. the system is expensive to run 2. the data is ugly / messy. I&amp;#39;m supposed to be supporting our sales org with data insights as a &amp;quot;data analyst&amp;quot;. I like the notebook approach of synapse. I feel like azure can go infinitely deep. Is anyone else using dynamics and doing analytics with it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15k6vai", "is_robot_indexable": true, "report_reasons": null, "author": "LogicalPhallicsy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k6vai/dropped_into_azure_as_a_newbie_60_days_in_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k6vai/dropped_into_azure_as_a_newbie_60_days_in_using/", "subreddit_subscribers": 121184, "created_utc": 1691372297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\n \n\n# Orchestrate SQL Data Pipelines with Airflow | Schedule SQL scripts with Airlfow | ETL with SQL\n\n\ud83d\udcf7[**Blog**](https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;restrict_sr=1)\n\nVlog on how to run and schedule SQL scripts with Airflow? | SQL Data Pipelines | Airflow | \n\n[https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;t](https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;t=15s)\n\nTopics covered:\n\n* SQL Data Pipelines\n* Orchestrate SQL Data Pipelines with Airflow\n* Build ETL Pipelines with SQL and Airlfow\n\nTech Stack: **Airflow, SQL, Postgres**", "author_fullname": "t2_vj0466m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Orchestrate SQL Data Pipelines with Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jr3va", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691332425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Orchestrate SQL Data Pipelines with Airflow | Schedule SQL scripts with Airlfow | ETL with SQL&lt;/h1&gt;\n\n&lt;p&gt;\ud83d\udcf7&lt;a href=\"https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;amp;restrict_sr=1\"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Vlog on how to run and schedule SQL scripts with Airflow? | SQL Data Pipelines | Airflow | &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;amp;t=15s\"&gt;https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;amp;t&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Topics covered:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SQL Data Pipelines&lt;/li&gt;\n&lt;li&gt;Orchestrate SQL Data Pipelines with Airflow&lt;/li&gt;\n&lt;li&gt;Build ETL Pipelines with SQL and Airlfow&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Tech Stack: &lt;strong&gt;Airflow, SQL, Postgres&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?auto=webp&amp;s=03784d9dac9dffcc1166f570436a71e7c718902a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0980d90c5755f83d45488668837f05287f0483bd", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=df7595d0942017850684fa6a05af1cc40dbfeec1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9d668134559a76c33c5122856aff02e27742302", "width": 320, "height": 240}], "variants": {}, "id": "VdeBUiZIsVh-t6deaseFeEHDK_Q0GOVBJM1ja2o45TE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15jr3va", "is_robot_indexable": true, "report_reasons": null, "author": "Either-Adeptness6638", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jr3va/orchestrate_sql_data_pipelines_with_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jr3va/orchestrate_sql_data_pipelines_with_airflow/", "subreddit_subscribers": 121184, "created_utc": 1691332425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are moving from DW to Data lake. We will move from one cloud(Gcp) to another in the next year or so. What we pick will also need to move. \nWe have a lot of code that queries BigQuery. I looked at Omni but it looks like there are a lot of restrictions.", "author_fullname": "t2_s3lpw2dx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you use for your Data Lakehouse architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k2i56", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691360539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are moving from DW to Data lake. We will move from one cloud(Gcp) to another in the next year or so. What we pick will also need to move. \nWe have a lot of code that queries BigQuery. I looked at Omni but it looks like there are a lot of restrictions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k2i56", "is_robot_indexable": true, "report_reasons": null, "author": "nelsonbigetti", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k2i56/what_do_you_use_for_your_data_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k2i56/what_do_you_use_for_your_data_lakehouse/", "subreddit_subscribers": 121184, "created_utc": 1691360539.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\n\nI'd like to ask for some advices about architecting a datalake that's mostly used to train ML algorithms. \n\n\nSo we have at my job, the first silo of a datalake (let's call it C1), containing raw data from IoT devices. The interface is HTTP, you download records/files, then process them locally as you want. Those are organized per category. The user access and roles is handled by an OAuth service, and a web server is serving the data to the user. It is made using an AWS EC2 machine and a Mongo database. \n\nWe are working on a second silo, with data being in a cleaned form, from C1, stored as parquet files. This one will be used more extensively. The \"records\"/data must be versionned. Some users should be able to create datasets from the records (many to many relationship). And the user ACL should be as fine as on C1. Also we want something as in-house as possible, anything Databricks Saas or AWS full-managed/serverless isn't possible. \n\n\nWe are trying to solutions at the moment :\n\nThe first one being using Spark and Iceberg over S3 + a Glue catalog, which is great because the SQL API offers flexibility but I'm quite scared of the datascientists running expensive requests. Also I still don't know how to handle the user access management and roles. Then how would the data scientists do the compute, running Spark on their computer? Ultimately they work on their computers and don't plan on using a saas editor. Which kind of computing platform would allow low TTFB for small requests and high throughput for highly distributed workload? \n\nThe second one being an RDS PostGreSQL database for the meta, which would also do most of the compute when searching for a record, S3, and a web server. Kinda the same architecture as in C1, but the RDBMS allowing for versionning the data and creating datasets.\n\n\nDo you guys know of any solution that would fit our need better? \n\nThanks! \n\nN.B : Sorry if this is very approximate, I'm a SWE but have been doing DE for only 3 months.", "author_fullname": "t2_12102p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice for architecting a datalake.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jvem7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691343296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to ask for some advices about architecting a datalake that&amp;#39;s mostly used to train ML algorithms. &lt;/p&gt;\n\n&lt;p&gt;So we have at my job, the first silo of a datalake (let&amp;#39;s call it C1), containing raw data from IoT devices. The interface is HTTP, you download records/files, then process them locally as you want. Those are organized per category. The user access and roles is handled by an OAuth service, and a web server is serving the data to the user. It is made using an AWS EC2 machine and a Mongo database. &lt;/p&gt;\n\n&lt;p&gt;We are working on a second silo, with data being in a cleaned form, from C1, stored as parquet files. This one will be used more extensively. The &amp;quot;records&amp;quot;/data must be versionned. Some users should be able to create datasets from the records (many to many relationship). And the user ACL should be as fine as on C1. Also we want something as in-house as possible, anything Databricks Saas or AWS full-managed/serverless isn&amp;#39;t possible. &lt;/p&gt;\n\n&lt;p&gt;We are trying to solutions at the moment :&lt;/p&gt;\n\n&lt;p&gt;The first one being using Spark and Iceberg over S3 + a Glue catalog, which is great because the SQL API offers flexibility but I&amp;#39;m quite scared of the datascientists running expensive requests. Also I still don&amp;#39;t know how to handle the user access management and roles. Then how would the data scientists do the compute, running Spark on their computer? Ultimately they work on their computers and don&amp;#39;t plan on using a saas editor. Which kind of computing platform would allow low TTFB for small requests and high throughput for highly distributed workload? &lt;/p&gt;\n\n&lt;p&gt;The second one being an RDS PostGreSQL database for the meta, which would also do most of the compute when searching for a record, S3, and a web server. Kinda the same architecture as in C1, but the RDBMS allowing for versionning the data and creating datasets.&lt;/p&gt;\n\n&lt;p&gt;Do you guys know of any solution that would fit our need better? &lt;/p&gt;\n\n&lt;p&gt;Thanks! &lt;/p&gt;\n\n&lt;p&gt;N.B : Sorry if this is very approximate, I&amp;#39;m a SWE but have been doing DE for only 3 months.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jvem7", "is_robot_indexable": true, "report_reasons": null, "author": "papawish", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jvem7/need_advice_for_architecting_a_datalake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jvem7/need_advice_for_architecting_a_datalake/", "subreddit_subscribers": 121184, "created_utc": 1691343296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How successful are such efforts? Are there any problems or behaviors that keep recurring despite this?\n\n[View Poll](https://www.reddit.com/poll/15joy01)", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(question if you work in a large company with many analysts) How often does your company organize training for Analysts to help them avoid Expensive, Slow queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15joy01", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691326421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How successful are such efforts? Are there any problems or behaviors that keep recurring despite this?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/15joy01\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15joy01", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1691585622043, "options": [{"text": "once every 3 months or less", "id": "24223580"}, {"text": "once every 3 - 6 months", "id": "24223581"}, {"text": "Once every 6 - 12 months", "id": "24223582"}, {"text": "Once every few years, or even more infrequently", "id": "24223583"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 209, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15joy01/question_if_you_work_in_a_large_company_with_many/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/15joy01/question_if_you_work_in_a_large_company_with_many/", "subreddit_subscribers": 121184, "created_utc": 1691326421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am tasked with building a data pipeline/engine that takes in an PDF invoice and spits out a JSON with some extracted information. My problem is that this analyzer must be able to parse different invoice-types from different places, that look and behave differently. Keywords can also change and/or be spelled and abbreviated differently. \n\nDo you people know of any approaches, methods or technologies to do this in a approachable and maintainable way? I am open to any tips and tricks, any technologies and programming languages. Performance should be taken into account, but it is not the top priority. The amount of invoices can be pretty big sometimes. \n\nTL;DR: I have to parse and analyze PDF invoices of differing formats to extract certain data points. What is the best way to analyze this type of unstructured and varying data?", "author_fullname": "t2_3tfn3hrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting info from unstructured varying PDF data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jnvrh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691323216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am tasked with building a data pipeline/engine that takes in an PDF invoice and spits out a JSON with some extracted information. My problem is that this analyzer must be able to parse different invoice-types from different places, that look and behave differently. Keywords can also change and/or be spelled and abbreviated differently. &lt;/p&gt;\n\n&lt;p&gt;Do you people know of any approaches, methods or technologies to do this in a approachable and maintainable way? I am open to any tips and tricks, any technologies and programming languages. Performance should be taken into account, but it is not the top priority. The amount of invoices can be pretty big sometimes. &lt;/p&gt;\n\n&lt;p&gt;TL;DR: I have to parse and analyze PDF invoices of differing formats to extract certain data points. What is the best way to analyze this type of unstructured and varying data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jnvrh", "is_robot_indexable": true, "report_reasons": null, "author": "Bitzer-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jnvrh/extracting_info_from_unstructured_varying_pdf_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jnvrh/extracting_info_from_unstructured_varying_pdf_data/", "subreddit_subscribers": 121184, "created_utc": 1691323216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the disadvantages of using Dremio? Can I move between clouds? Is it costly?", "author_fullname": "t2_s3lpw2dx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use Dremio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k2m5u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691360835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the disadvantages of using Dremio? Can I move between clouds? Is it costly?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k2m5u", "is_robot_indexable": true, "report_reasons": null, "author": "nelsonbigetti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k2m5u/do_you_use_dremio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k2m5u/do_you_use_dremio/", "subreddit_subscribers": 121184, "created_utc": 1691360835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What factors do you consider when deciding to store data in a database vs using object storage such as S3? At my org we use python scripts to store most of our raw JSON data in postgresql JSONB columns. We then build on this data and add to it within other database tables.\n\nThe only thing we store in S3 is PDFs and HTML. I noticed a lot of people here talking about saving raw JSON to S3, so I got me curious about what we may be missing.\n\nSome advantages for object storage that I thought of are:\n\n1. More durable, less likely to be lost\n2. Less stress on database\n3. Can process more data concurrently\n\nThe cons for object storage seem to be:\n\n1. Expense involved with every query\n2. Harder to attach metadata via other columns\n\nCurious to hear what others think about this!", "author_fullname": "t2_1zkaz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storing JSON - database vs object storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k4oyg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691366261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What factors do you consider when deciding to store data in a database vs using object storage such as S3? At my org we use python scripts to store most of our raw JSON data in postgresql JSONB columns. We then build on this data and add to it within other database tables.&lt;/p&gt;\n\n&lt;p&gt;The only thing we store in S3 is PDFs and HTML. I noticed a lot of people here talking about saving raw JSON to S3, so I got me curious about what we may be missing.&lt;/p&gt;\n\n&lt;p&gt;Some advantages for object storage that I thought of are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;More durable, less likely to be lost&lt;/li&gt;\n&lt;li&gt;Less stress on database&lt;/li&gt;\n&lt;li&gt;Can process more data concurrently&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The cons for object storage seem to be:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Expense involved with every query&lt;/li&gt;\n&lt;li&gt;Harder to attach metadata via other columns&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Curious to hear what others think about this!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k4oyg", "is_robot_indexable": true, "report_reasons": null, "author": "caseym", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k4oyg/storing_json_database_vs_object_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k4oyg/storing_json_database_vs_object_storage/", "subreddit_subscribers": 121184, "created_utc": 1691366261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm a junior in college majoring in computer information systems. The way my major is set up is that students can focus towards either programming, web design? I think it's web design either way, programming, web design, and database managment. I'm thinking I should probably focus on programming if I want to be a data engineer right?", "author_fullname": "t2_a24gckgw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need some help.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jweks", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691345887.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691345682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m a junior in college majoring in computer information systems. The way my major is set up is that students can focus towards either programming, web design? I think it&amp;#39;s web design either way, programming, web design, and database managment. I&amp;#39;m thinking I should probably focus on programming if I want to be a data engineer right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jweks", "is_robot_indexable": true, "report_reasons": null, "author": "International_Fig420", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jweks/i_need_some_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jweks/i_need_some_help/", "subreddit_subscribers": 121184, "created_utc": 1691345682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone have experience or evaluated the use of Neo4J vs Neptune for a cloud graph DB. Read a few things online but curious if anyone\u2019s got any pointers here. \n\nSeems like both can easily interact with sagemaker\u2026 don\u2019t think Neptune plays well with redshift. Would be loading data from S3. Looks like they both have some bulk loading functionality. \n\nI\u2019m pretty sure someone read: https://neo4j.com/blog/walmart-neo4j-competitive-advantage/ and now this is the direction we are going \ud83e\udd37\u200d\u2642\ufe0f", "author_fullname": "t2_9bj4s404", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Neptune vs Neo4J", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jvl8l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691343729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have experience or evaluated the use of Neo4J vs Neptune for a cloud graph DB. Read a few things online but curious if anyone\u2019s got any pointers here. &lt;/p&gt;\n\n&lt;p&gt;Seems like both can easily interact with sagemaker\u2026 don\u2019t think Neptune plays well with redshift. Would be loading data from S3. Looks like they both have some bulk loading functionality. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m pretty sure someone read: &lt;a href=\"https://neo4j.com/blog/walmart-neo4j-competitive-advantage/\"&gt;https://neo4j.com/blog/walmart-neo4j-competitive-advantage/&lt;/a&gt; and now this is the direction we are going \ud83e\udd37\u200d\u2642\ufe0f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?auto=webp&amp;s=6461cc17589dd510fedc58ce52e211af7a82e4cf", "width": 900, "height": 224}, "resolutions": [{"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63dc4fce6e270fd5c997b4728a9c1ca6a7460bde", "width": 108, "height": 26}, {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a457717892c3f55d109a2bc173b147b48a77018a", "width": 216, "height": 53}, {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f6bfab6bdff8e9df079960b254cc09f9bafbaf84", "width": 320, "height": 79}, {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=af40ed6c60f803746d4dd8609e8ce5045f0d4f1b", "width": 640, "height": 159}], "variants": {}, "id": "nK4sSdFMcMhjFzyzeJp52E0WY68i_JTltCFahWvYB4o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jvl8l", "is_robot_indexable": true, "report_reasons": null, "author": "Over-Geologist-5760", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jvl8l/neptune_vs_neo4j/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jvl8l/neptune_vs_neo4j/", "subreddit_subscribers": 121184, "created_utc": 1691343729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI/ML Best Practices During a Gold Rush", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": false, "name": "t3_15ju2tf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uL48H9N0DS2GEo6E8gcgH3GJoWggSe4z8bGaLYBgYgc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691339995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.min.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.min.io/ai-ml-best-practices-during-a-gold-rush/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?auto=webp&amp;s=6791496e14e9072b5565cf0bb72bd800f967cf8a", "width": 2000, "height": 598}, "resolutions": [{"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca7901908b612d3e51236eeeb3cfe4b1cf1359f3", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=435eb84902201b6c1b33b8822133d652f04c601f", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c5a88bafa9e1a8e6a4e228cdd155b0a21ce4cd9f", "width": 320, "height": 95}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4d24ecd00d22decec81215802a961e8c05765660", "width": 640, "height": 191}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=60b1c2eeb2c644334379f7225ff166914bb57360", "width": 960, "height": 287}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a60340fe7b4d735f421d201c1632af89ff22da2d", "width": 1080, "height": 322}], "variants": {}, "id": "LR1jOSz4RSQ2PbagOXJkm6885ysOmVuTrnO79a5sXR4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ju2tf", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ju2tf/aiml_best_practices_during_a_gold_rush/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.min.io/ai-ml-best-practices-during-a-gold-rush/", "subreddit_subscribers": 121184, "created_utc": 1691339995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 11 years exp. Recently started working in streaming tech. Mostly worked on big data tech \nMy org and manager forcing to become manager \nI really want to become architect. Need some general guidance for becoming architect", "author_fullname": "t2_8yd9vdzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "senior developer who want transition to architect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jpfij", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691327813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 11 years exp. Recently started working in streaming tech. Mostly worked on big data tech \nMy org and manager forcing to become manager \nI really want to become architect. Need some general guidance for becoming architect&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15jpfij", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious_Role_304", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jpfij/senior_developer_who_want_transition_to_architect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jpfij/senior_developer_who_want_transition_to_architect/", "subreddit_subscribers": 121184, "created_utc": 1691327813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nEnjoy reading all your posts here.\n\nI just want to get your opinion on the smallest scale DE stack that is feasible to roll out for a small to medium enterprise on a pilot basis.\n\nShould I start with AWS ,Google or Alibaba?\n\nHow do I calculate computation costs v storage cost?\n\nKakfa or Hevo ?\n\nWhat about APIs?\n\nEstimated man hours to deploy?\n\nRefactoring?\n\nHow do I cost the whole pilot project?\n\nAny recommended DE stack model that I could have a look at?\n\nCheers and apologies for the range of questions.", "author_fullname": "t2_s2dp5dpg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE stack by new outfit for small to medium business", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k41zm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691364576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;Enjoy reading all your posts here.&lt;/p&gt;\n\n&lt;p&gt;I just want to get your opinion on the smallest scale DE stack that is feasible to roll out for a small to medium enterprise on a pilot basis.&lt;/p&gt;\n\n&lt;p&gt;Should I start with AWS ,Google or Alibaba?&lt;/p&gt;\n\n&lt;p&gt;How do I calculate computation costs v storage cost?&lt;/p&gt;\n\n&lt;p&gt;Kakfa or Hevo ?&lt;/p&gt;\n\n&lt;p&gt;What about APIs?&lt;/p&gt;\n\n&lt;p&gt;Estimated man hours to deploy?&lt;/p&gt;\n\n&lt;p&gt;Refactoring?&lt;/p&gt;\n\n&lt;p&gt;How do I cost the whole pilot project?&lt;/p&gt;\n\n&lt;p&gt;Any recommended DE stack model that I could have a look at?&lt;/p&gt;\n\n&lt;p&gt;Cheers and apologies for the range of questions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k41zm", "is_robot_indexable": true, "report_reasons": null, "author": "saintisstat", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k41zm/de_stack_by_new_outfit_for_small_to_medium/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k41zm/de_stack_by_new_outfit_for_small_to_medium/", "subreddit_subscribers": 121184, "created_utc": 1691364576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I work in a plastic factory and i am making tests of a product with different composition and features. I would like to compare my tests with the product of my competition and between each other in order to determinate which one is the best. Could someone guide me about how to make this type of analysis please?\n\nthe data is in the link.\n\n[Data](https://docs.google.com/spreadsheets/d/1DBaZGUlMK1p-RavfZiyr_8L4npI6hCzz381aNa2Zo5U/edit?usp=sharing)", "author_fullname": "t2_qx2yrcp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to choose the best result?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jufgz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691340897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I work in a plastic factory and i am making tests of a product with different composition and features. I would like to compare my tests with the product of my competition and between each other in order to determinate which one is the best. Could someone guide me about how to make this type of analysis please?&lt;/p&gt;\n\n&lt;p&gt;the data is in the link.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.google.com/spreadsheets/d/1DBaZGUlMK1p-RavfZiyr_8L4npI6hCzz381aNa2Zo5U/edit?usp=sharing\"&gt;Data&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?auto=webp&amp;s=b6ed92112b16068a2303c366865831f26427eafe", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c3787d86902b7d6abc24019ae9c009dee2b2232", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d8af98ced5d5e230b402963ef756923d641df974", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e792353e97cc4866a04fed5002f0e85cd7a1ff8f", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b8c0a014c73d42a52e5bd499c20f589b6b952853", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f23b638b39f7a68792ef486b7311ff8d5794edb0", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0c883ade7bacf66361c01bdbe90b34eea5dc67a4", "width": 1080, "height": 567}], "variants": {}, "id": "XC4uNHGpS51t7eDtzWOidn67MZebTkLycF2OnN3BFVQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jufgz", "is_robot_indexable": true, "report_reasons": null, "author": "ECsantaroz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jufgz/how_to_choose_the_best_result/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jufgz/how_to_choose_the_best_result/", "subreddit_subscribers": 121184, "created_utc": 1691340897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As someone who enjoys all kinds of cs fields, the second thing I should look at when choosing a career is the ease of finding a job and salary. Please be realistic, which one would you choose if you started from scratch?\n\n[View Poll](https://www.reddit.com/poll/15ju56b)", "author_fullname": "t2_be0kmkfc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which one would you choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ju56b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691340161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As someone who enjoys all kinds of cs fields, the second thing I should look at when choosing a career is the ease of finding a job and salary. Please be realistic, which one would you choose if you started from scratch?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/15ju56b\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ju56b", "is_robot_indexable": true, "report_reasons": null, "author": "Due_Salamander_2931", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1691512961705, "options": [{"text": "Data Engineering", "id": "24225937"}, {"text": "Devops Engineering", "id": "24225938"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 330, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ju56b/which_one_would_you_choose/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/15ju56b/which_one_would_you_choose/", "subreddit_subscribers": 121184, "created_utc": 1691340161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Want to be useful with AI\n\nI will  mostly be making data models, and using SSRS to create reports drawn from those analysis. \n\nI've very little experience with SSRS. \n\nHowever I'm fairly comfortable with SQL\nAnd some Python\n\n\n\nBut most importantly I know the landscape is changing. And I want to be useful. People are leveraging AI in many aspects of SQL reporting.\n\nI just don't know how exactly.\n\nMaybe in: \n\n1. Data cleansing\n\n\n2. Automated report capture and send out.\n\n\nHow else?\n\nWhat AI prompting/script creation should I learn that will be useful? Or revolutionizing in general?\n\nWhat should I learn in general for SSRS reporting?", "author_fullname": "t2_18rszvo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want to be useful with AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k09fu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691355037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Want to be useful with AI&lt;/p&gt;\n\n&lt;p&gt;I will  mostly be making data models, and using SSRS to create reports drawn from those analysis. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve very little experience with SSRS. &lt;/p&gt;\n\n&lt;p&gt;However I&amp;#39;m fairly comfortable with SQL\nAnd some Python&lt;/p&gt;\n\n&lt;p&gt;But most importantly I know the landscape is changing. And I want to be useful. People are leveraging AI in many aspects of SQL reporting.&lt;/p&gt;\n\n&lt;p&gt;I just don&amp;#39;t know how exactly.&lt;/p&gt;\n\n&lt;p&gt;Maybe in: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Data cleansing&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Automated report capture and send out.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;How else?&lt;/p&gt;\n\n&lt;p&gt;What AI prompting/script creation should I learn that will be useful? Or revolutionizing in general?&lt;/p&gt;\n\n&lt;p&gt;What should I learn in general for SSRS reporting?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15k09fu", "is_robot_indexable": true, "report_reasons": null, "author": "peyott100", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k09fu/want_to_be_useful_with_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k09fu/want_to_be_useful_with_ai/", "subreddit_subscribers": 121184, "created_utc": 1691355037.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}