{"kind": "Listing", "data": {"after": "t3_15ju56b", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just wondering if people see all three of these as being necessary. I\u2019m in an organization that has an Azure data warehouse. This gives us access to ADF. But databricks salespeople have started reaching out to us recently. \n\nThe ability to work within python and r in databricks sounds great. But how does it differ from a more sql-based tool like dbt?\n\nFor context, my background is more in data analytics/science. But our organization (from what I\u2019ve seen after being here a couple months) is in desperate need of data engineering skills. They\u2019ve gone out and hired data scientists, but their basic institutional data is a mess and in many cases not existent in the warehouse.", "author_fullname": "t2_9ytsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you need Azure Data Factory and Databricks? What about dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jxfd4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691348215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wondering if people see all three of these as being necessary. I\u2019m in an organization that has an Azure data warehouse. This gives us access to ADF. But databricks salespeople have started reaching out to us recently. &lt;/p&gt;\n\n&lt;p&gt;The ability to work within python and r in databricks sounds great. But how does it differ from a more sql-based tool like dbt?&lt;/p&gt;\n\n&lt;p&gt;For context, my background is more in data analytics/science. But our organization (from what I\u2019ve seen after being here a couple months) is in desperate need of data engineering skills. They\u2019ve gone out and hired data scientists, but their basic institutional data is a mess and in many cases not existent in the warehouse.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jxfd4", "is_robot_indexable": true, "report_reasons": null, "author": "ursamajorm82", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jxfd4/do_you_need_azure_data_factory_and_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jxfd4/do_you_need_azure_data_factory_and_databricks/", "subreddit_subscribers": 121235, "created_utc": 1691348215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How's the current job market for Senior Data Engineers, especially in Europe? \n\nIs it easy to switch job, are there alot of demand with few competition?", "author_fullname": "t2_8ijlo4rl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Status quo job market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jmpo8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691319195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How&amp;#39;s the current job market for Senior Data Engineers, especially in Europe? &lt;/p&gt;\n\n&lt;p&gt;Is it easy to switch job, are there alot of demand with few competition?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jmpo8", "is_robot_indexable": true, "report_reasons": null, "author": "Noway721", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jmpo8/status_quo_job_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jmpo8/status_quo_job_market/", "subreddit_subscribers": 121235, "created_utc": 1691319195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am doing modeling in python to maintain a next best action python model in that tracks relationships in dynamics. 1. the system is expensive to run 2. the data is ugly / messy. I'm supposed to be supporting our sales org with data insights as a \"data analyst\". I like the notebook approach of synapse. I feel like azure can go infinitely deep. Is anyone else using dynamics and doing analytics with it?", "author_fullname": "t2_8klzm7ui", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dropped into Azure as a newbie 60 days in, using Dynamics / Synapse / PowerBI/ Pyspark (sql). What do I need to learn? WTF is fabric?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k6vai", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691372297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am doing modeling in python to maintain a next best action python model in that tracks relationships in dynamics. 1. the system is expensive to run 2. the data is ugly / messy. I&amp;#39;m supposed to be supporting our sales org with data insights as a &amp;quot;data analyst&amp;quot;. I like the notebook approach of synapse. I feel like azure can go infinitely deep. Is anyone else using dynamics and doing analytics with it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15k6vai", "is_robot_indexable": true, "report_reasons": null, "author": "LogicalPhallicsy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k6vai/dropped_into_azure_as_a_newbie_60_days_in_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k6vai/dropped_into_azure_as_a_newbie_60_days_in_using/", "subreddit_subscribers": 121235, "created_utc": 1691372297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[edited to clarify I'm asking about what to concentrate on for a DE in context of learning python generally]  \n\nIf a practicing/aspiring DE asks  \"what python do I need for DE?\" below are my thoughts about what to concentrate on/supplement  from a \"general python\" class, would like to get feedback. The core of such classes is about general path of execution control, and using lists, dictionaries, sets and tuple, manipulating strings. All that stuff is crucial, if you have it down cold you'll be better off for both jobs and interviews. \n\nBut when general classes move on to bigger programs I'm interested in thoughts about *what's likely to be most crucial for DEs, or useful and not touched on* by such a class.\n\n\n**likely covered, but less important for a DE than for a general SWE**\n\n   Design to take advantage of OO concepts (any python class will cover instantiating objects and accessing attributes, which you do need)  \n   multi-threading and multi-processing  \n   tkinter or other desktop GUI framework  \n   subprocess control (popen)  \n   Dataclass (given the name, its surprising, but I haven't talked to DEs who use these)  \n\n**likely less/not covered, often important for DEs**\n\n   *comes-with libs*:  \n   datetime -- deltas, arithmetic, date&lt;-&gt;string, timezone handling, pytz &amp; post 3.10(?) built-in  \n   zipfile  \n   csv  \n   pathlib  \n   re, and familiarity with string functions likely alternative (startswith, in) (if you use re and don't need it that might look bad in interview)  \n   Decimal v float (rounding with money)  \n\n   *Additional libs*:\n   pytz (as a predecssor to datetime.timzone (still widely used))  \n   chardet  \n   pandas  (just understanding its filter syntax, like df\\[df\\['poo'\\] &gt; 3\\], puts you ahead of the bottom candidates already)  \n   requests  (and non-python you should take a short course on postman and curl &amp; learn a bit about headers and tokens)  \n   fastapi and/or DRF (read about both) (it's not obviously DE-ish, but 3 \"ETL\" teams I know have put up FASTapi stuff) (anyway DEs should have basic idea of HTTP apps, apis, basic REST theory, and at least know you don't know about SOAP)  \n\n*edit* - Likely not covered at all in a python class but likely to be relevant: jinja2 (used in dbt) and sqlalchemy (used widely but esp. with pandas)\n\nIn my experience SQL is crucial and I think if you can't do \"medium\" leetcode sql you're likely to have problems in any DE interview, whether it's really relevant to that specific job or not.  \n\nGeneral algorithm/data structure knowledge isn't important for most DE practitioners day-to-day, but necessary to clear interviews at some companies (I've never encountered this in about 15 interviews thru my career, all &lt; $150K/yr in today's US$).  If you're looking to enter the DE field, you should be familiar enough with LC to know if you can get up to speed on medium or hard LC if you need to.", "author_fullname": "t2_abfpw4qq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "python specifically for DE positions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k0sbu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691375655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691356283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[edited to clarify I&amp;#39;m asking about what to concentrate on for a DE in context of learning python generally]  &lt;/p&gt;\n\n&lt;p&gt;If a practicing/aspiring DE asks  &amp;quot;what python do I need for DE?&amp;quot; below are my thoughts about what to concentrate on/supplement  from a &amp;quot;general python&amp;quot; class, would like to get feedback. The core of such classes is about general path of execution control, and using lists, dictionaries, sets and tuple, manipulating strings. All that stuff is crucial, if you have it down cold you&amp;#39;ll be better off for both jobs and interviews. &lt;/p&gt;\n\n&lt;p&gt;But when general classes move on to bigger programs I&amp;#39;m interested in thoughts about &lt;em&gt;what&amp;#39;s likely to be most crucial for DEs, or useful and not touched on&lt;/em&gt; by such a class.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;likely covered, but less important for a DE than for a general SWE&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Design to take advantage of OO concepts (any python class will cover instantiating objects and accessing attributes, which you do need)&lt;br/&gt;\n   multi-threading and multi-processing&lt;br/&gt;\n   tkinter or other desktop GUI framework&lt;br/&gt;\n   subprocess control (popen)&lt;br/&gt;\n   Dataclass (given the name, its surprising, but I haven&amp;#39;t talked to DEs who use these)  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;likely less/not covered, often important for DEs&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;comes-with libs&lt;/em&gt;:&lt;br/&gt;\n   datetime -- deltas, arithmetic, date&amp;lt;-&amp;gt;string, timezone handling, pytz &amp;amp; post 3.10(?) built-in&lt;br/&gt;\n   zipfile&lt;br/&gt;\n   csv&lt;br/&gt;\n   pathlib&lt;br/&gt;\n   re, and familiarity with string functions likely alternative (startswith, in) (if you use re and don&amp;#39;t need it that might look bad in interview)&lt;br/&gt;\n   Decimal v float (rounding with money)  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Additional libs&lt;/em&gt;:\n   pytz (as a predecssor to datetime.timzone (still widely used))&lt;br/&gt;\n   chardet&lt;br/&gt;\n   pandas  (just understanding its filter syntax, like df[df[&amp;#39;poo&amp;#39;] &amp;gt; 3], puts you ahead of the bottom candidates already)&lt;br/&gt;\n   requests  (and non-python you should take a short course on postman and curl &amp;amp; learn a bit about headers and tokens)&lt;br/&gt;\n   fastapi and/or DRF (read about both) (it&amp;#39;s not obviously DE-ish, but 3 &amp;quot;ETL&amp;quot; teams I know have put up FASTapi stuff) (anyway DEs should have basic idea of HTTP apps, apis, basic REST theory, and at least know you don&amp;#39;t know about SOAP)  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;edit&lt;/em&gt; - Likely not covered at all in a python class but likely to be relevant: jinja2 (used in dbt) and sqlalchemy (used widely but esp. with pandas)&lt;/p&gt;\n\n&lt;p&gt;In my experience SQL is crucial and I think if you can&amp;#39;t do &amp;quot;medium&amp;quot; leetcode sql you&amp;#39;re likely to have problems in any DE interview, whether it&amp;#39;s really relevant to that specific job or not.  &lt;/p&gt;\n\n&lt;p&gt;General algorithm/data structure knowledge isn&amp;#39;t important for most DE practitioners day-to-day, but necessary to clear interviews at some companies (I&amp;#39;ve never encountered this in about 15 interviews thru my career, all &amp;lt; $150K/yr in today&amp;#39;s US$).  If you&amp;#39;re looking to enter the DE field, you should be familiar enough with LC to know if you can get up to speed on medium or hard LC if you need to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k0sbu", "is_robot_indexable": true, "report_reasons": null, "author": "levintennine", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k0sbu/python_specifically_for_de_positions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k0sbu/python_specifically_for_de_positions/", "subreddit_subscribers": 121235, "created_utc": 1691356283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "pandas.dataframe is now the standard structural data API in machine learning, but pandas is single node and in-core(in RAM computing), so there have been attempts to port pandas API to parallel and out-of-core environments, such as pandas-on-spark, dask, polars etc.\n\nBesides Spark, is there any SQL RDBMS backend providing the pandas dataframe API?\n\nI mean any python library \"pa\" that provides:\n\n* pa.DataFrame --- every DataFrame object has a database table in a RDBMS, and every computation, including python functions, to be compiled into SQL code that executes on the RDBMS. Data manipulation coded in python can be implemented in foreign functions of the RDBMS.\n* The node running python only generate queries and translate between python and rdbms. The actual data processing is performed by RDBMS (thus parallel, out of core and support partitioning/sharding)", "author_fullname": "t2_igoo081k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a RDBMS-based backend providing the pandas dataframe api?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jpf9b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691327792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;pandas.dataframe is now the standard structural data API in machine learning, but pandas is single node and in-core(in RAM computing), so there have been attempts to port pandas API to parallel and out-of-core environments, such as pandas-on-spark, dask, polars etc.&lt;/p&gt;\n\n&lt;p&gt;Besides Spark, is there any SQL RDBMS backend providing the pandas dataframe API?&lt;/p&gt;\n\n&lt;p&gt;I mean any python library &amp;quot;pa&amp;quot; that provides:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;pa.DataFrame --- every DataFrame object has a database table in a RDBMS, and every computation, including python functions, to be compiled into SQL code that executes on the RDBMS. Data manipulation coded in python can be implemented in foreign functions of the RDBMS.&lt;/li&gt;\n&lt;li&gt;The node running python only generate queries and translate between python and rdbms. The actual data processing is performed by RDBMS (thus parallel, out of core and support partitioning/sharding)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jpf9b", "is_robot_indexable": true, "report_reasons": null, "author": "larryliu7", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jpf9b/is_there_a_rdbmsbased_backend_providing_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jpf9b/is_there_a_rdbmsbased_backend_providing_the/", "subreddit_subscribers": 121235, "created_utc": 1691327792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a rising senior in university; I know that DE jobs are relatively harder to come by for new grads so looking for backend-ish software engineering jobs. But I hope to eventually transition into this field.\n\nI was reading [this AMA](https://www.reddit.com/r/dataengineering/comments/udboyq/comment/i6gj0iy/) and one of the commenters asked how the Netflix DE interview goes, and further into the thread, OP is asked how they would deal with an out of memory issue with Spark and answers with several options - each showing that they understand not just how to use this tool, but why certain things work the way they do.\n\nMy question - how would one come to know this? Is it experience? Book / blogs / podcasts? Someone just telling you over the course of time (e.g. me reading this AMA would prolly count)? Feels a but overwhelming. Maybe what I'm doing - reading stuff made by knowledgeable people is part of what gives you this knowledge; but how the hell do you remember it? I can probably bet that if I ran into an OOM error in Spark a year later, I would probably **not** go \"Oh this was mentioned in a random reddit AMA that one can remove duplicates and/or process outliers separately let's try that!\". I'd probably go whine to a mentor and/or hopelessly google and/or if I'm lucky, remember this reddit thread and come back to it.\n\nEven more worrying - a commenter asked \"How much understanding do you need for OOM you either  use more memory or less memory\". Which worried me because that reeks of the Dunning Kruger effect / not knowing what I know. if I do not even know what I don't know, how do I learn? How do I know that a source I'm looking it is a credible one to learn from? How would one get past this at all?", "author_fullname": "t2_1j8v22cd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you get to know all these *stuff* concerning the internals of various tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15kanjk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691383762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a rising senior in university; I know that DE jobs are relatively harder to come by for new grads so looking for backend-ish software engineering jobs. But I hope to eventually transition into this field.&lt;/p&gt;\n\n&lt;p&gt;I was reading &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/udboyq/comment/i6gj0iy/\"&gt;this AMA&lt;/a&gt; and one of the commenters asked how the Netflix DE interview goes, and further into the thread, OP is asked how they would deal with an out of memory issue with Spark and answers with several options - each showing that they understand not just how to use this tool, but why certain things work the way they do.&lt;/p&gt;\n\n&lt;p&gt;My question - how would one come to know this? Is it experience? Book / blogs / podcasts? Someone just telling you over the course of time (e.g. me reading this AMA would prolly count)? Feels a but overwhelming. Maybe what I&amp;#39;m doing - reading stuff made by knowledgeable people is part of what gives you this knowledge; but how the hell do you remember it? I can probably bet that if I ran into an OOM error in Spark a year later, I would probably &lt;strong&gt;not&lt;/strong&gt; go &amp;quot;Oh this was mentioned in a random reddit AMA that one can remove duplicates and/or process outliers separately let&amp;#39;s try that!&amp;quot;. I&amp;#39;d probably go whine to a mentor and/or hopelessly google and/or if I&amp;#39;m lucky, remember this reddit thread and come back to it.&lt;/p&gt;\n\n&lt;p&gt;Even more worrying - a commenter asked &amp;quot;How much understanding do you need for OOM you either  use more memory or less memory&amp;quot;. Which worried me because that reeks of the Dunning Kruger effect / not knowing what I know. if I do not even know what I don&amp;#39;t know, how do I learn? How do I know that a source I&amp;#39;m looking it is a credible one to learn from? How would one get past this at all?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15kanjk", "is_robot_indexable": true, "report_reasons": null, "author": "stuffingmybrain", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15kanjk/how_do_you_get_to_know_all_these_stuff_concerning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15kanjk/how_do_you_get_to_know_all_these_stuff_concerning/", "subreddit_subscribers": 121235, "created_utc": 1691383762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What factors do you consider when deciding to store data in a database vs using object storage such as S3? At my org we use python scripts to store most of our raw JSON data in postgresql JSONB columns. We then build on this data and add to it within other database tables.\n\nThe only thing we store in S3 is PDFs and HTML. I noticed a lot of people here talking about saving raw JSON to S3, so I got me curious about what we may be missing.\n\nSome advantages for object storage that I thought of are:\n\n1. More durable, less likely to be lost\n2. Less stress on database\n3. Can process more data concurrently\n\nThe cons for object storage seem to be:\n\n1. Expense involved with every query\n2. Harder to attach metadata via other columns\n\nCurious to hear what others think about this!", "author_fullname": "t2_1zkaz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storing JSON - database vs object storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k4oyg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691366261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What factors do you consider when deciding to store data in a database vs using object storage such as S3? At my org we use python scripts to store most of our raw JSON data in postgresql JSONB columns. We then build on this data and add to it within other database tables.&lt;/p&gt;\n\n&lt;p&gt;The only thing we store in S3 is PDFs and HTML. I noticed a lot of people here talking about saving raw JSON to S3, so I got me curious about what we may be missing.&lt;/p&gt;\n\n&lt;p&gt;Some advantages for object storage that I thought of are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;More durable, less likely to be lost&lt;/li&gt;\n&lt;li&gt;Less stress on database&lt;/li&gt;\n&lt;li&gt;Can process more data concurrently&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The cons for object storage seem to be:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Expense involved with every query&lt;/li&gt;\n&lt;li&gt;Harder to attach metadata via other columns&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Curious to hear what others think about this!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k4oyg", "is_robot_indexable": true, "report_reasons": null, "author": "caseym", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k4oyg/storing_json_database_vs_object_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k4oyg/storing_json_database_vs_object_storage/", "subreddit_subscribers": 121235, "created_utc": 1691366261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Figma for Data Products: Novel tech requires enough experimentation and a big playground", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15jntr6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LKVQdyJQAYKiDuaUXQrvh3qwoHP2KS8eJQ0e0YOOR3c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691323022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/figma-for-data-products-novel-tech", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?auto=webp&amp;s=00fe75becd7940bd54c29c8c2a2edbabfdb4f068", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d2de591a2defe24dffb8588eb3458f8e940e19d6", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dd2f9af5562dbbebf11bdc84ceb83400b221347f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f9bed5581f8673e4a5319a878b430911abf75a76", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2db00580b5f6d991d365795383694d2b6b6a8af4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c9e161886c464d256b9425d9d11eb45111e2b8c2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e5d1a5d8dcb27a1b5c61bde3af86077d83783c93", "width": 1080, "height": 540}], "variants": {}, "id": "DjHOPoos8rWBEZLEKOpFCb-GTBmxyeuofzBUipivrKw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15jntr6", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jntr6/figma_for_data_products_novel_tech_requires/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/figma-for-data-products-novel-tech", "subreddit_subscribers": 121235, "created_utc": 1691323022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are moving from DW to Data lake. We will move from one cloud(Gcp) to another in the next year or so. What we pick will also need to move. \nWe have a lot of code that queries BigQuery. I looked at Omni but it looks like there are a lot of restrictions.", "author_fullname": "t2_s3lpw2dx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you use for your Data Lakehouse architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k2i56", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691360539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are moving from DW to Data lake. We will move from one cloud(Gcp) to another in the next year or so. What we pick will also need to move. \nWe have a lot of code that queries BigQuery. I looked at Omni but it looks like there are a lot of restrictions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k2i56", "is_robot_indexable": true, "report_reasons": null, "author": "nelsonbigetti", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k2i56/what_do_you_use_for_your_data_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k2i56/what_do_you_use_for_your_data_lakehouse/", "subreddit_subscribers": 121235, "created_utc": 1691360539.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\n\nI'd like to ask for some advices about architecting a datalake that's mostly used to train ML algorithms. \n\n\nSo we have at my job, the first silo of a datalake (let's call it C1), containing raw data from IoT devices. The interface is HTTP, you download records/files, then process them locally as you want. Those are organized per category. The user access and roles is handled by an OAuth service, and a web server is serving the data to the user. It is made using an AWS EC2 machine and a Mongo database. \n\nWe are working on a second silo, with data being in a cleaned from C1, stored as parquet files. This one will be used more extensively. The \"records\"/data must be versionned. Some users should be able to create datasets from the records (many to many relationship). And the user ACL should be as fine as on C1. Also we want something as in-house as possible, anything Databricks Saas or AWS full-managed/serverless isn't possible. \n\n\nWe are trying two solutions at the moment :\n\nThe first one being using Spark and Iceberg over S3 + a Glue catalog, which is great because the SQL API offers flexibility but I'm quite scared of the datascientists running expensive requests. Also I still don't know how to handle the user access management and roles. Then how would the data scientists do the compute, running Spark on their computer? Ultimately they work on their computers and don't plan on using a saas editor. Which kind of computing platform would allow low TTFB for small requests and high throughput for highly distributed workload? \n\nThe second one being an RDS PostGreSQL database for the meta, which would also do most of the compute when searching for a record, S3, and a web server. Kinda the same architecture as in C1, but the RDBMS allowing for versionning the data and creating datasets.\n\n\nDo you guys know of any solution that would fit our need better? \n\nThanks! \n\nN.B : Sorry if this is very approximate, I'm a SWE but have been doing DE for only 3 months.", "author_fullname": "t2_12102p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice for architecting a datalake.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jvem7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691393466.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691343296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to ask for some advices about architecting a datalake that&amp;#39;s mostly used to train ML algorithms. &lt;/p&gt;\n\n&lt;p&gt;So we have at my job, the first silo of a datalake (let&amp;#39;s call it C1), containing raw data from IoT devices. The interface is HTTP, you download records/files, then process them locally as you want. Those are organized per category. The user access and roles is handled by an OAuth service, and a web server is serving the data to the user. It is made using an AWS EC2 machine and a Mongo database. &lt;/p&gt;\n\n&lt;p&gt;We are working on a second silo, with data being in a cleaned from C1, stored as parquet files. This one will be used more extensively. The &amp;quot;records&amp;quot;/data must be versionned. Some users should be able to create datasets from the records (many to many relationship). And the user ACL should be as fine as on C1. Also we want something as in-house as possible, anything Databricks Saas or AWS full-managed/serverless isn&amp;#39;t possible. &lt;/p&gt;\n\n&lt;p&gt;We are trying two solutions at the moment :&lt;/p&gt;\n\n&lt;p&gt;The first one being using Spark and Iceberg over S3 + a Glue catalog, which is great because the SQL API offers flexibility but I&amp;#39;m quite scared of the datascientists running expensive requests. Also I still don&amp;#39;t know how to handle the user access management and roles. Then how would the data scientists do the compute, running Spark on their computer? Ultimately they work on their computers and don&amp;#39;t plan on using a saas editor. Which kind of computing platform would allow low TTFB for small requests and high throughput for highly distributed workload? &lt;/p&gt;\n\n&lt;p&gt;The second one being an RDS PostGreSQL database for the meta, which would also do most of the compute when searching for a record, S3, and a web server. Kinda the same architecture as in C1, but the RDBMS allowing for versionning the data and creating datasets.&lt;/p&gt;\n\n&lt;p&gt;Do you guys know of any solution that would fit our need better? &lt;/p&gt;\n\n&lt;p&gt;Thanks! &lt;/p&gt;\n\n&lt;p&gt;N.B : Sorry if this is very approximate, I&amp;#39;m a SWE but have been doing DE for only 3 months.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jvem7", "is_robot_indexable": true, "report_reasons": null, "author": "papawish", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jvem7/need_advice_for_architecting_a_datalake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jvem7/need_advice_for_architecting_a_datalake/", "subreddit_subscribers": 121235, "created_utc": 1691343296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How successful are such efforts? Are there any problems or behaviors that keep recurring despite this?\n\n[View Poll](https://www.reddit.com/poll/15joy01)", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(question if you work in a large company with many analysts) How often does your company organize training for Analysts to help them avoid Expensive, Slow queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15joy01", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691326421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How successful are such efforts? Are there any problems or behaviors that keep recurring despite this?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/15joy01\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15joy01", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1691585622043, "options": [{"text": "once every 3 months or less", "id": "24223580"}, {"text": "once every 3 - 6 months", "id": "24223581"}, {"text": "Once every 6 - 12 months", "id": "24223582"}, {"text": "Once every few years, or even more infrequently", "id": "24223583"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 232, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15joy01/question_if_you_work_in_a_large_company_with_many/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/15joy01/question_if_you_work_in_a_large_company_with_many/", "subreddit_subscribers": 121235, "created_utc": 1691326421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\n \n\n# Orchestrate SQL Data Pipelines with Airflow | Schedule SQL scripts with Airlfow | ETL with SQL\n\n\ud83d\udcf7[**Blog**](https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;restrict_sr=1)\n\nVlog on how to run and schedule SQL scripts with Airflow? | SQL Data Pipelines | Airflow | \n\n[https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;t](https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;t=15s)\n\nTopics covered:\n\n* SQL Data Pipelines\n* Orchestrate SQL Data Pipelines with Airflow\n* Build ETL Pipelines with SQL and Airlfow\n\nTech Stack: **Airflow, SQL, Postgres**", "author_fullname": "t2_vj0466m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Orchestrate SQL Data Pipelines with Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jr3va", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691332425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Orchestrate SQL Data Pipelines with Airflow | Schedule SQL scripts with Airlfow | ETL with SQL&lt;/h1&gt;\n\n&lt;p&gt;\ud83d\udcf7&lt;a href=\"https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;amp;restrict_sr=1\"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Vlog on how to run and schedule SQL scripts with Airflow? | SQL Data Pipelines | Airflow | &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;amp;t=15s\"&gt;https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;amp;t&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Topics covered:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SQL Data Pipelines&lt;/li&gt;\n&lt;li&gt;Orchestrate SQL Data Pipelines with Airflow&lt;/li&gt;\n&lt;li&gt;Build ETL Pipelines with SQL and Airlfow&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Tech Stack: &lt;strong&gt;Airflow, SQL, Postgres&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?auto=webp&amp;s=03784d9dac9dffcc1166f570436a71e7c718902a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0980d90c5755f83d45488668837f05287f0483bd", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=df7595d0942017850684fa6a05af1cc40dbfeec1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9d668134559a76c33c5122856aff02e27742302", "width": 320, "height": 240}], "variants": {}, "id": "VdeBUiZIsVh-t6deaseFeEHDK_Q0GOVBJM1ja2o45TE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15jr3va", "is_robot_indexable": true, "report_reasons": null, "author": "Either-Adeptness6638", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jr3va/orchestrate_sql_data_pipelines_with_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jr3va/orchestrate_sql_data_pipelines_with_airflow/", "subreddit_subscribers": 121235, "created_utc": 1691332425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am tasked with building a data pipeline/engine that takes in an PDF invoice and spits out a JSON with some extracted information. My problem is that this analyzer must be able to parse different invoice-types from different places, that look and behave differently. Keywords can also change and/or be spelled and abbreviated differently. \n\nDo you people know of any approaches, methods or technologies to do this in a approachable and maintainable way? I am open to any tips and tricks, any technologies and programming languages. Performance should be taken into account, but it is not the top priority. The amount of invoices can be pretty big sometimes. \n\nTL;DR: I have to parse and analyze PDF invoices of differing formats to extract certain data points. What is the best way to analyze this type of unstructured and varying data?", "author_fullname": "t2_3tfn3hrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting info from unstructured varying PDF data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jnvrh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691323216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am tasked with building a data pipeline/engine that takes in an PDF invoice and spits out a JSON with some extracted information. My problem is that this analyzer must be able to parse different invoice-types from different places, that look and behave differently. Keywords can also change and/or be spelled and abbreviated differently. &lt;/p&gt;\n\n&lt;p&gt;Do you people know of any approaches, methods or technologies to do this in a approachable and maintainable way? I am open to any tips and tricks, any technologies and programming languages. Performance should be taken into account, but it is not the top priority. The amount of invoices can be pretty big sometimes. &lt;/p&gt;\n\n&lt;p&gt;TL;DR: I have to parse and analyze PDF invoices of differing formats to extract certain data points. What is the best way to analyze this type of unstructured and varying data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jnvrh", "is_robot_indexable": true, "report_reasons": null, "author": "Bitzer-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jnvrh/extracting_info_from_unstructured_varying_pdf_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jnvrh/extracting_info_from_unstructured_varying_pdf_data/", "subreddit_subscribers": 121235, "created_utc": 1691323216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "  \n\nHey ya'll.\n\nI could use some input regarding \"stream\" ingestion.\n\n**Definition:**  \n I feel the definition of \"stream data\" is super vague. For most tutorials online, the use cases is usually relate to streams of data from e.g. sensors or website actions, that you for some reason need to be **processed** in real-time and thus, call for methods such as Windowing etc.\n\nBut the use cases I work with are usually very traditional, data warehouse use cases, where the further processing of data does not need to be real time. The only real-time component, really, is the ingestion, where, for example, the data from an event lands in a, say, Kafka queue, and we *choose* to act on it immediately. The only processing that is done on the event, *might* be to de-nest a nested structure and parsing say, a JSON format, to input it into a relational database.\n\n**Tooling:**\n\nAll the tooling I read about, all focus on **processing** data in real time, i.e. doing some sort of aggregate functions on them. Fx. Spark Streaming, Apache Beam.\n\n**Pipeline:**\n\nI have previously utilized function services like AWS Lambda or Azure Functions, and have these be triggered from Events, like *new file in S3*, or *new event in queue*. And then ingest the data **one by one**. I have done this approach by myself before, as to me it is the simplest approach that does not introduce any new software dependencies, and works on the basic services offered by the cloud provider.\n\nCould any of you elaborate on why, say, Spark Streaming with Databricks, or Apache Beam would be a better choice in the above use case, where I simply ingest the data through Azure Functions/AWS Lambda through triggers?", "author_fullname": "t2_onmeo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming ingestion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15kdri9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691394061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey ya&amp;#39;ll.&lt;/p&gt;\n\n&lt;p&gt;I could use some input regarding &amp;quot;stream&amp;quot; ingestion.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt;&lt;br/&gt;\n I feel the definition of &amp;quot;stream data&amp;quot; is super vague. For most tutorials online, the use cases is usually relate to streams of data from e.g. sensors or website actions, that you for some reason need to be &lt;strong&gt;processed&lt;/strong&gt; in real-time and thus, call for methods such as Windowing etc.&lt;/p&gt;\n\n&lt;p&gt;But the use cases I work with are usually very traditional, data warehouse use cases, where the further processing of data does not need to be real time. The only real-time component, really, is the ingestion, where, for example, the data from an event lands in a, say, Kafka queue, and we &lt;em&gt;choose&lt;/em&gt; to act on it immediately. The only processing that is done on the event, &lt;em&gt;might&lt;/em&gt; be to de-nest a nested structure and parsing say, a JSON format, to input it into a relational database.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Tooling:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;All the tooling I read about, all focus on &lt;strong&gt;processing&lt;/strong&gt; data in real time, i.e. doing some sort of aggregate functions on them. Fx. Spark Streaming, Apache Beam.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Pipeline:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have previously utilized function services like AWS Lambda or Azure Functions, and have these be triggered from Events, like &lt;em&gt;new file in S3&lt;/em&gt;, or &lt;em&gt;new event in queue&lt;/em&gt;. And then ingest the data &lt;strong&gt;one by one&lt;/strong&gt;. I have done this approach by myself before, as to me it is the simplest approach that does not introduce any new software dependencies, and works on the basic services offered by the cloud provider.&lt;/p&gt;\n\n&lt;p&gt;Could any of you elaborate on why, say, Spark Streaming with Databricks, or Apache Beam would be a better choice in the above use case, where I simply ingest the data through Azure Functions/AWS Lambda through triggers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15kdri9", "is_robot_indexable": true, "report_reasons": null, "author": "Hinkakan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15kdri9/streaming_ingestion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15kdri9/streaming_ingestion/", "subreddit_subscribers": 121235, "created_utc": 1691394061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the disadvantages of using Dremio? Can I move between clouds? Is it costly?", "author_fullname": "t2_s3lpw2dx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use Dremio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k2m5u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691360835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the disadvantages of using Dremio? Can I move between clouds? Is it costly?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k2m5u", "is_robot_indexable": true, "report_reasons": null, "author": "nelsonbigetti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k2m5u/do_you_use_dremio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k2m5u/do_you_use_dremio/", "subreddit_subscribers": 121235, "created_utc": 1691360835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "To becoming a Data Scientist is a backup option for my future career, so i usually pay more attention to the related information. Just the other day, i attended a career planning lecture for doctoral student, and the speaker is a leading data scientist from UK. I want to take the opportunity to share the information with you, and taking some advice from Reddit.", "author_fullname": "t2_f5n99q0y4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Become a Data Scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15kfb0f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691399384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To becoming a Data Scientist is a backup option for my future career, so i usually pay more attention to the related information. Just the other day, i attended a career planning lecture for doctoral student, and the speaker is a leading data scientist from UK. I want to take the opportunity to share the information with you, and taking some advice from Reddit.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15kfb0f", "is_robot_indexable": true, "report_reasons": null, "author": "AggravatingGrab99", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15kfb0f/how_to_become_a_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15kfb0f/how_to_become_a_data_scientist/", "subreddit_subscribers": 121235, "created_utc": 1691399384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My organization is looking to change to a different ETL tool. As a part of this process, I was tasked to test out Google Cloud Data Fusion. These are some of the things, which I came across while working with this tool. Our data warehouse is GBQ and we have a MySQL instance running on AWS. \n\nI tried the following using CDF:\n\n1. Load data from MySQL to GBQ\n2. Load data from GBQ to MySQL\n\n**Loading data from MySQL to GBQ**\n\nThis seems to be working fine. The table gets loaded into GBQ regardless if the table exists in the destination or not. We have the luxury to CHOOSE the write operations like: insert, update or upsert on the UI itself. Data type selecting within the UI is limited. For example, we cannot change LONG into INT.\n\n**Loading data from GBQ to MySQL**\n\n\"MySQL\" sink doesn't seem to work. Using \"MySQL\" sink throws an error saying the URL used for JDBC. This is error I am getting:\n\n    Exception while trying to validate schema of database table 'table' for connection 'jdbc:mysql://host:3306/database' with username does not appear to be a valid URL.\n\nThe table in the destination (MySQL db) should exist. If not the job fails. If the table exists and job succeeded. The data gets appended to the table. We can configure the write operation in this case.   \n\n\nAm I using CDF in a wrong way? Are there any good resources to learn CDF? Is Dataflow overkill for the task I am describing? Do you know any other ETL tools that can be cost-effective? Would writing a custom Python script and hosting be much cheaper than these?   \n\n\nThank you for reading! ", "author_fullname": "t2_auriunhuo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My take on Google Cloud Data Fusion.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15keaam", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "a96f3daa-e787-11ed-bb3c-927138abd1d2", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691395879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My organization is looking to change to a different ETL tool. As a part of this process, I was tasked to test out Google Cloud Data Fusion. These are some of the things, which I came across while working with this tool. Our data warehouse is GBQ and we have a MySQL instance running on AWS. &lt;/p&gt;\n\n&lt;p&gt;I tried the following using CDF:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Load data from MySQL to GBQ&lt;/li&gt;\n&lt;li&gt;Load data from GBQ to MySQL&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Loading data from MySQL to GBQ&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This seems to be working fine. The table gets loaded into GBQ regardless if the table exists in the destination or not. We have the luxury to CHOOSE the write operations like: insert, update or upsert on the UI itself. Data type selecting within the UI is limited. For example, we cannot change LONG into INT.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Loading data from GBQ to MySQL&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;MySQL&amp;quot; sink doesn&amp;#39;t seem to work. Using &amp;quot;MySQL&amp;quot; sink throws an error saying the URL used for JDBC. This is error I am getting:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Exception while trying to validate schema of database table &amp;#39;table&amp;#39; for connection &amp;#39;jdbc:mysql://host:3306/database&amp;#39; with username does not appear to be a valid URL.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The table in the destination (MySQL db) should exist. If not the job fails. If the table exists and job succeeded. The data gets appended to the table. We can configure the write operation in this case.   &lt;/p&gt;\n\n&lt;p&gt;Am I using CDF in a wrong way? Are there any good resources to learn CDF? Is Dataflow overkill for the task I am describing? Do you know any other ETL tools that can be cost-effective? Would writing a custom Python script and hosting be much cheaper than these?   &lt;/p&gt;\n\n&lt;p&gt;Thank you for reading! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Junior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15keaam", "is_robot_indexable": true, "report_reasons": null, "author": "Interesting-Rub-3984", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15keaam/my_take_on_google_cloud_data_fusion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15keaam/my_take_on_google_cloud_data_fusion/", "subreddit_subscribers": 121235, "created_utc": 1691395879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\nI started using the new feature called 'Change data feed,' but there's something I don't understand. When I input the data in Bronze and activate the CDF there, I can use startTimestamp to retrieve the latest data in Silver and thus only read the delta. However, when I write this data in Silver, it retains the CDF information from Bronze. Before saving, I deleted the CDF columns and reactivated the CDF, but unfortunately, it didn't work. What am I doing wrong here?\n\n&amp;#x200B;\n\nLoading data to bronze:\n\n     df.write.mode(\"append\") \\\n        .format(\"delta\") \\\n        .option(\"mergeSchema\", \"true\") \\\n        .option(\"delta.enableChangeDataFeed\",\"true\") \\\n        .save(SINK_PATH+'/'+FOLDER_NAME)\n\nLoading data in silver:\n\n    df = spark.read.option(\"readChangeFeed\", \"true\").option(\"startingTimestamp\", last_version_ts).load(folder.path, format = \"delta\")\n    \n    df = df.drop(\"_change_type\", \"_commit_version\",  \"_commit_timestamp\")\n    \n    df.write.mode(\"append\") \\\n        .format(\"delta\") \\\n        .option(\"mergeSchema\", \"true\") \\\n        .option(\"delta.enableChangeDataFeed\",\"true\") \\\n        .save(SINK_PATH+'/'+FOLDER_NAME)\n\nWithout dropping the columns BUT with enabling ChangeDataFeed I got an error, that the columns are ambiguous or something. I coulnd't read from the Lake because of that.", "author_fullname": "t2_3hjo2xx8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta's Change data feed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ke874", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691395674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;I started using the new feature called &amp;#39;Change data feed,&amp;#39; but there&amp;#39;s something I don&amp;#39;t understand. When I input the data in Bronze and activate the CDF there, I can use startTimestamp to retrieve the latest data in Silver and thus only read the delta. However, when I write this data in Silver, it retains the CDF information from Bronze. Before saving, I deleted the CDF columns and reactivated the CDF, but unfortunately, it didn&amp;#39;t work. What am I doing wrong here?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Loading data to bronze:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt; df.write.mode(&amp;quot;append&amp;quot;) \\\n    .format(&amp;quot;delta&amp;quot;) \\\n    .option(&amp;quot;mergeSchema&amp;quot;, &amp;quot;true&amp;quot;) \\\n    .option(&amp;quot;delta.enableChangeDataFeed&amp;quot;,&amp;quot;true&amp;quot;) \\\n    .save(SINK_PATH+&amp;#39;/&amp;#39;+FOLDER_NAME)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Loading data in silver:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;df = spark.read.option(&amp;quot;readChangeFeed&amp;quot;, &amp;quot;true&amp;quot;).option(&amp;quot;startingTimestamp&amp;quot;, last_version_ts).load(folder.path, format = &amp;quot;delta&amp;quot;)\n\ndf = df.drop(&amp;quot;_change_type&amp;quot;, &amp;quot;_commit_version&amp;quot;,  &amp;quot;_commit_timestamp&amp;quot;)\n\ndf.write.mode(&amp;quot;append&amp;quot;) \\\n    .format(&amp;quot;delta&amp;quot;) \\\n    .option(&amp;quot;mergeSchema&amp;quot;, &amp;quot;true&amp;quot;) \\\n    .option(&amp;quot;delta.enableChangeDataFeed&amp;quot;,&amp;quot;true&amp;quot;) \\\n    .save(SINK_PATH+&amp;#39;/&amp;#39;+FOLDER_NAME)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Without dropping the columns BUT with enabling ChangeDataFeed I got an error, that the columns are ambiguous or something. I coulnd&amp;#39;t read from the Lake because of that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ke874", "is_robot_indexable": true, "report_reasons": null, "author": "alienus333", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ke874/deltas_change_data_feed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ke874/deltas_change_data_feed/", "subreddit_subscribers": 121235, "created_utc": 1691395674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to leverage a messaging service to enable event-driven integration and facilitate near real-time integration for building data pipelines. Which one of these messaging services do you think would be most suitable?\nI am a newbie data engineer thank you\u2026\n\n[View Poll](https://www.reddit.com/poll/15kalqr)", "author_fullname": "t2_u1p9g2g4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MSK or SQS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15kalqr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691383603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to leverage a messaging service to enable event-driven integration and facilitate near real-time integration for building data pipelines. Which one of these messaging services do you think would be most suitable?\nI am a newbie data engineer thank you\u2026&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/15kalqr\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15kalqr", "is_robot_indexable": true, "report_reasons": null, "author": "Active-Ask-3524", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1691642803277, "options": [{"text": "MSK", "id": "24233658"}, {"text": "SQS", "id": "24233659"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 11, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15kalqr/msk_or_sqs/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/15kalqr/msk_or_sqs/", "subreddit_subscribers": 121235, "created_utc": 1691383603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nEnjoy reading all your posts here.\n\nI just want to get your opinion on the smallest scale DE stack that is feasible to roll out for a small to medium enterprise on a pilot basis.\n\nShould I start with AWS ,Google or Alibaba?\n\nHow do I calculate computation costs v storage cost?\n\nKakfa or Hevo ?\n\nWhat about APIs?\n\nEstimated man hours to deploy?\n\nRefactoring?\n\nHow do I cost the whole pilot project?\n\nAny recommended DE stack model that I could have a look at?\n\nCheers and apologies for the range of questions.", "author_fullname": "t2_s2dp5dpg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE stack by new outfit for small to medium business", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15k41zm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691364576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;Enjoy reading all your posts here.&lt;/p&gt;\n\n&lt;p&gt;I just want to get your opinion on the smallest scale DE stack that is feasible to roll out for a small to medium enterprise on a pilot basis.&lt;/p&gt;\n\n&lt;p&gt;Should I start with AWS ,Google or Alibaba?&lt;/p&gt;\n\n&lt;p&gt;How do I calculate computation costs v storage cost?&lt;/p&gt;\n\n&lt;p&gt;Kakfa or Hevo ?&lt;/p&gt;\n\n&lt;p&gt;What about APIs?&lt;/p&gt;\n\n&lt;p&gt;Estimated man hours to deploy?&lt;/p&gt;\n\n&lt;p&gt;Refactoring?&lt;/p&gt;\n\n&lt;p&gt;How do I cost the whole pilot project?&lt;/p&gt;\n\n&lt;p&gt;Any recommended DE stack model that I could have a look at?&lt;/p&gt;\n\n&lt;p&gt;Cheers and apologies for the range of questions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15k41zm", "is_robot_indexable": true, "report_reasons": null, "author": "saintisstat", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15k41zm/de_stack_by_new_outfit_for_small_to_medium/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15k41zm/de_stack_by_new_outfit_for_small_to_medium/", "subreddit_subscribers": 121235, "created_utc": 1691364576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm a junior in college majoring in computer information systems. The way my major is set up is that students can focus towards either programming, web design? I think it's web design either way, programming, web design, and database managment. I'm thinking I should probably focus on programming if I want to be a data engineer right?", "author_fullname": "t2_a24gckgw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need some help.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jweks", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691345887.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691345682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m a junior in college majoring in computer information systems. The way my major is set up is that students can focus towards either programming, web design? I think it&amp;#39;s web design either way, programming, web design, and database managment. I&amp;#39;m thinking I should probably focus on programming if I want to be a data engineer right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jweks", "is_robot_indexable": true, "report_reasons": null, "author": "International_Fig420", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jweks/i_need_some_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jweks/i_need_some_help/", "subreddit_subscribers": 121235, "created_utc": 1691345682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone have experience or evaluated the use of Neo4J vs Neptune for a cloud graph DB. Read a few things online but curious if anyone\u2019s got any pointers here. \n\nSeems like both can easily interact with sagemaker\u2026 don\u2019t think Neptune plays well with redshift. Would be loading data from S3. Looks like they both have some bulk loading functionality. \n\nI\u2019m pretty sure someone read: https://neo4j.com/blog/walmart-neo4j-competitive-advantage/ and now this is the direction we are going \ud83e\udd37\u200d\u2642\ufe0f", "author_fullname": "t2_9bj4s404", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Neptune vs Neo4J", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jvl8l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691343729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have experience or evaluated the use of Neo4J vs Neptune for a cloud graph DB. Read a few things online but curious if anyone\u2019s got any pointers here. &lt;/p&gt;\n\n&lt;p&gt;Seems like both can easily interact with sagemaker\u2026 don\u2019t think Neptune plays well with redshift. Would be loading data from S3. Looks like they both have some bulk loading functionality. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m pretty sure someone read: &lt;a href=\"https://neo4j.com/blog/walmart-neo4j-competitive-advantage/\"&gt;https://neo4j.com/blog/walmart-neo4j-competitive-advantage/&lt;/a&gt; and now this is the direction we are going \ud83e\udd37\u200d\u2642\ufe0f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?auto=webp&amp;s=6461cc17589dd510fedc58ce52e211af7a82e4cf", "width": 900, "height": 224}, "resolutions": [{"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63dc4fce6e270fd5c997b4728a9c1ca6a7460bde", "width": 108, "height": 26}, {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a457717892c3f55d109a2bc173b147b48a77018a", "width": 216, "height": 53}, {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f6bfab6bdff8e9df079960b254cc09f9bafbaf84", "width": 320, "height": 79}, {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=af40ed6c60f803746d4dd8609e8ce5045f0d4f1b", "width": 640, "height": 159}], "variants": {}, "id": "nK4sSdFMcMhjFzyzeJp52E0WY68i_JTltCFahWvYB4o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jvl8l", "is_robot_indexable": true, "report_reasons": null, "author": "Over-Geologist-5760", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jvl8l/neptune_vs_neo4j/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jvl8l/neptune_vs_neo4j/", "subreddit_subscribers": 121235, "created_utc": 1691343729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI/ML Best Practices During a Gold Rush", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": false, "name": "t3_15ju2tf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uL48H9N0DS2GEo6E8gcgH3GJoWggSe4z8bGaLYBgYgc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691339995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.min.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.min.io/ai-ml-best-practices-during-a-gold-rush/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?auto=webp&amp;s=6791496e14e9072b5565cf0bb72bd800f967cf8a", "width": 2000, "height": 598}, "resolutions": [{"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca7901908b612d3e51236eeeb3cfe4b1cf1359f3", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=435eb84902201b6c1b33b8822133d652f04c601f", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c5a88bafa9e1a8e6a4e228cdd155b0a21ce4cd9f", "width": 320, "height": 95}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4d24ecd00d22decec81215802a961e8c05765660", "width": 640, "height": 191}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=60b1c2eeb2c644334379f7225ff166914bb57360", "width": 960, "height": 287}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a60340fe7b4d735f421d201c1632af89ff22da2d", "width": 1080, "height": 322}], "variants": {}, "id": "LR1jOSz4RSQ2PbagOXJkm6885ysOmVuTrnO79a5sXR4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ju2tf", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ju2tf/aiml_best_practices_during_a_gold_rush/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.min.io/ai-ml-best-practices-during-a-gold-rush/", "subreddit_subscribers": 121235, "created_utc": 1691339995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 11 years exp. Recently started working in streaming tech. Mostly worked on big data tech \nMy org and manager forcing to become manager \nI really want to become architect. Need some general guidance for becoming architect", "author_fullname": "t2_8yd9vdzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "senior developer who want transition to architect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jpfij", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691327813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 11 years exp. Recently started working in streaming tech. Mostly worked on big data tech \nMy org and manager forcing to become manager \nI really want to become architect. Need some general guidance for becoming architect&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15jpfij", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious_Role_304", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jpfij/senior_developer_who_want_transition_to_architect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jpfij/senior_developer_who_want_transition_to_architect/", "subreddit_subscribers": 121235, "created_utc": 1691327813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As someone who enjoys all kinds of cs fields, the second thing I should look at when choosing a career is the ease of finding a job and salary. Please be realistic, which one would you choose if you started from scratch?\n\n[View Poll](https://www.reddit.com/poll/15ju56b)", "author_fullname": "t2_be0kmkfc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which one would you choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ju56b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691340161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As someone who enjoys all kinds of cs fields, the second thing I should look at when choosing a career is the ease of finding a job and salary. Please be realistic, which one would you choose if you started from scratch?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/15ju56b\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ju56b", "is_robot_indexable": true, "report_reasons": null, "author": "Due_Salamander_2931", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1691512961705, "options": [{"text": "Data Engineering", "id": "24225937"}, {"text": "Devops Engineering", "id": "24225938"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 372, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ju56b/which_one_would_you_choose/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/15ju56b/which_one_would_you_choose/", "subreddit_subscribers": 121235, "created_utc": 1691340161.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}