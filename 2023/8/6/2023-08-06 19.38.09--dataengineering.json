{"kind": "Listing", "data": {"after": null, "dist": 18, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How's the current job market for Senior Data Engineers, especially in Europe? \n\nIs it easy to switch job, are there alot of demand with few competition?", "author_fullname": "t2_8ijlo4rl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Status quo job market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jmpo8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691319195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How&amp;#39;s the current job market for Senior Data Engineers, especially in Europe? &lt;/p&gt;\n\n&lt;p&gt;Is it easy to switch job, are there alot of demand with few competition?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jmpo8", "is_robot_indexable": true, "report_reasons": null, "author": "Noway721", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jmpo8/status_quo_job_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jmpo8/status_quo_job_market/", "subreddit_subscribers": 121116, "created_utc": 1691319195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a Postgresql server running on AWS ECE2 t2.small instance.\n\none of its tables contains  4,629,588 rows. on average around 50k rows are written on it daily. The data are coming from another application server. The purpose of this database is to serve the BI tools like powerBI. But a simple SELECT  query takes a lot of time, and PowerBI refresh time takes around 40 minutes.\n\nHow can I speed up my query times and reduce the time it takes to refresh the data in PowerBI?\n\nDo I need to scale up the instance configuration or it is something else", "author_fullname": "t2_6wue8mt3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fixing slow queries in Postgresql", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jlrkd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691315727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Postgresql server running on AWS ECE2 t2.small instance.&lt;/p&gt;\n\n&lt;p&gt;one of its tables contains  4,629,588 rows. on average around 50k rows are written on it daily. The data are coming from another application server. The purpose of this database is to serve the BI tools like powerBI. But a simple SELECT  query takes a lot of time, and PowerBI refresh time takes around 40 minutes.&lt;/p&gt;\n\n&lt;p&gt;How can I speed up my query times and reduce the time it takes to refresh the data in PowerBI?&lt;/p&gt;\n\n&lt;p&gt;Do I need to scale up the instance configuration or it is something else&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jlrkd", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPickles736", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jlrkd/fixing_slow_queries_in_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jlrkd/fixing_slow_queries_in_postgresql/", "subreddit_subscribers": 121116, "created_utc": 1691315727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2rku02rf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Iceberg Crash Course for AWS users: Amazon S3, Athena &amp; AWS Glue \u2764\ufe0f Iceberg", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15j7wua", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1691272420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kestra.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://kestra.io/blogs/2023-08-05-iceberg-for-aws-users", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15j7wua", "is_robot_indexable": true, "report_reasons": null, "author": "tchiotludo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15j7wua/apache_iceberg_crash_course_for_aws_users_amazon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://kestra.io/blogs/2023-08-05-iceberg-for-aws-users", "subreddit_subscribers": 121116, "created_utc": 1691272420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "pandas.dataframe is now the standard structural data API in machine learning, but pandas is single node and in-core(in RAM computing), so there have been attempts to port pandas API to parallel and out-of-core environments, such as pandas-on-spark, dask, polars etc.\n\nBesides Spark, is there any SQL RDBMS backend providing the pandas dataframe API?\n\nI mean any python library \"pa\" that provides:\n\n* pa.DataFrame --- every DataFrame object has a database table in a RDBMS, and every computation, including python functions, to be compiled into SQL code that executes on the RDBMS. Data manipulation coded in python can be implemented in foreign functions of the RDBMS.\n* The node running python only generate queries and translate between python and rdbms. The actual data processing is performed by RDBMS (thus parallel, out of core and support partitioning/sharding)", "author_fullname": "t2_igoo081k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a RDBMS-based backend providing the pandas dataframe api?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jpf9b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691327792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;pandas.dataframe is now the standard structural data API in machine learning, but pandas is single node and in-core(in RAM computing), so there have been attempts to port pandas API to parallel and out-of-core environments, such as pandas-on-spark, dask, polars etc.&lt;/p&gt;\n\n&lt;p&gt;Besides Spark, is there any SQL RDBMS backend providing the pandas dataframe API?&lt;/p&gt;\n\n&lt;p&gt;I mean any python library &amp;quot;pa&amp;quot; that provides:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;pa.DataFrame --- every DataFrame object has a database table in a RDBMS, and every computation, including python functions, to be compiled into SQL code that executes on the RDBMS. Data manipulation coded in python can be implemented in foreign functions of the RDBMS.&lt;/li&gt;\n&lt;li&gt;The node running python only generate queries and translate between python and rdbms. The actual data processing is performed by RDBMS (thus parallel, out of core and support partitioning/sharding)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jpf9b", "is_robot_indexable": true, "report_reasons": null, "author": "larryliu7", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jpf9b/is_there_a_rdbmsbased_backend_providing_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jpf9b/is_there_a_rdbmsbased_backend_providing_the/", "subreddit_subscribers": 121116, "created_utc": 1691327792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Figma for Data Products: Novel tech requires enough experimentation and a big playground", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15jntr6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LKVQdyJQAYKiDuaUXQrvh3qwoHP2KS8eJQ0e0YOOR3c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691323022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/figma-for-data-products-novel-tech", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?auto=webp&amp;s=00fe75becd7940bd54c29c8c2a2edbabfdb4f068", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d2de591a2defe24dffb8588eb3458f8e940e19d6", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dd2f9af5562dbbebf11bdc84ceb83400b221347f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f9bed5581f8673e4a5319a878b430911abf75a76", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2db00580b5f6d991d365795383694d2b6b6a8af4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c9e161886c464d256b9425d9d11eb45111e2b8c2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/QmRSmcjqOtMmX71fVqrZLdyP4CyAshAPxxG5-TBOd4A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e5d1a5d8dcb27a1b5c61bde3af86077d83783c93", "width": 1080, "height": 540}], "variants": {}, "id": "DjHOPoos8rWBEZLEKOpFCb-GTBmxyeuofzBUipivrKw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15jntr6", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jntr6/figma_for_data_products_novel_tech_requires/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/figma-for-data-products-novel-tech", "subreddit_subscribers": 121116, "created_utc": 1691323022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone have xp with both alembic and dbt? I know the latter and like it. New team uses alembic for db migrations but it\u2019s morphed into the transformation tool too. \n\nI haven\u2019t used alembic but from light reading it strikes me as a bit outdated for anything other than db migrations. \n\nCan anyone validate that? Would using it for transformation be misuse?", "author_fullname": "t2_2tu8n7l9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alembic vs dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jah1g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691278988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have xp with both alembic and dbt? I know the latter and like it. New team uses alembic for db migrations but it\u2019s morphed into the transformation tool too. &lt;/p&gt;\n\n&lt;p&gt;I haven\u2019t used alembic but from light reading it strikes me as a bit outdated for anything other than db migrations. &lt;/p&gt;\n\n&lt;p&gt;Can anyone validate that? Would using it for transformation be misuse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jah1g", "is_robot_indexable": true, "report_reasons": null, "author": "Firm_Bit", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jah1g/alembic_vs_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jah1g/alembic_vs_dbt/", "subreddit_subscribers": 121116, "created_utc": 1691278988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\n \n\n# Orchestrate SQL Data Pipelines with Airflow | Schedule SQL scripts with Airlfow | ETL with SQL\n\n\ud83d\udcf7[**Blog**](https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;restrict_sr=1)\n\nVlog on how to run and schedule SQL scripts with Airflow? | SQL Data Pipelines | Airflow | \n\n[https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;t](https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;t=15s)\n\nTopics covered:\n\n* SQL Data Pipelines\n* Orchestrate SQL Data Pipelines with Airflow\n* Build ETL Pipelines with SQL and Airlfow\n\nTech Stack: **Airflow, SQL, Postgres**", "author_fullname": "t2_vj0466m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Orchestrate SQL Data Pipelines with Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jr3va", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691332425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Orchestrate SQL Data Pipelines with Airflow | Schedule SQL scripts with Airlfow | ETL with SQL&lt;/h1&gt;\n\n&lt;p&gt;\ud83d\udcf7&lt;a href=\"https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;amp;restrict_sr=1\"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Vlog on how to run and schedule SQL scripts with Airflow? | SQL Data Pipelines | Airflow | &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;amp;t=15s\"&gt;https://www.youtube.com/watch?v=glzj7p7Yrrs&amp;amp;t&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Topics covered:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SQL Data Pipelines&lt;/li&gt;\n&lt;li&gt;Orchestrate SQL Data Pipelines with Airflow&lt;/li&gt;\n&lt;li&gt;Build ETL Pipelines with SQL and Airlfow&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Tech Stack: &lt;strong&gt;Airflow, SQL, Postgres&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?auto=webp&amp;s=03784d9dac9dffcc1166f570436a71e7c718902a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0980d90c5755f83d45488668837f05287f0483bd", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=df7595d0942017850684fa6a05af1cc40dbfeec1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/cWgb4mWxVeGdcsWCAiJbenMQChVTd9RbZmEWZkr541Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9d668134559a76c33c5122856aff02e27742302", "width": 320, "height": 240}], "variants": {}, "id": "VdeBUiZIsVh-t6deaseFeEHDK_Q0GOVBJM1ja2o45TE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15jr3va", "is_robot_indexable": true, "report_reasons": null, "author": "Either-Adeptness6638", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jr3va/orchestrate_sql_data_pipelines_with_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jr3va/orchestrate_sql_data_pipelines_with_airflow/", "subreddit_subscribers": 121116, "created_utc": 1691332425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am tasked with building a data pipeline/engine that takes in an PDF invoice and spits out a JSON with some extracted information. My problem is that this analyzer must be able to parse different invoice-types from different places, that look and behave differently. Keywords can also change and/or be spelled and abbreviated differently. \n\nDo you people know of any approaches, methods or technologies to do this in a approachable and maintainable way? I am open to any tips and tricks, any technologies and programming languages. Performance should be taken into account, but it is not the top priority. The amount of invoices can be pretty big sometimes. \n\nTL;DR: I have to parse and analyze PDF invoices of differing formats to extract certain data points. What is the best way to analyze this type of unstructured and varying data?", "author_fullname": "t2_3tfn3hrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting info from unstructured varying PDF data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jnvrh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691323216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am tasked with building a data pipeline/engine that takes in an PDF invoice and spits out a JSON with some extracted information. My problem is that this analyzer must be able to parse different invoice-types from different places, that look and behave differently. Keywords can also change and/or be spelled and abbreviated differently. &lt;/p&gt;\n\n&lt;p&gt;Do you people know of any approaches, methods or technologies to do this in a approachable and maintainable way? I am open to any tips and tricks, any technologies and programming languages. Performance should be taken into account, but it is not the top priority. The amount of invoices can be pretty big sometimes. &lt;/p&gt;\n\n&lt;p&gt;TL;DR: I have to parse and analyze PDF invoices of differing formats to extract certain data points. What is the best way to analyze this type of unstructured and varying data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jnvrh", "is_robot_indexable": true, "report_reasons": null, "author": "Bitzer-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jnvrh/extracting_info_from_unstructured_varying_pdf_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jnvrh/extracting_info_from_unstructured_varying_pdf_data/", "subreddit_subscribers": 121116, "created_utc": 1691323216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\n\nI'd like to ask for some advices about architecting a datalake that's mostly used to train ML algorithms. \n\n\nSo we have at my job, the first silo of a datalake (let's call it C1), containing raw data from IoT devices. The interface is HTTP, you download records/files, then process them locally as you want. Those are organized per category. The user access and roles is handled by an OAuth service, and a web server is serving the data to the user. It is made using an AWS EC2 machine and a Mongo database. \n\nWe are working on a second silo, with data being in a cleaned form, from C1, stored as parquet files. This one will be used more extensively. The \"records\"/data must be versionned. Some users should be able to create datasets from the records (many to many relationship). And the user ACL should be as fine as on C1. Also we want something as in-house as possible, anything Databricks Saas or AWS full-managed/serverless isn't possible. \n\n\nWe are trying to solutions at the moment :\n\nThe first one being using Spark and Iceberg over S3 + a Glue catalog, which is great because the SQL API offers flexibility but I'm quite scared of the datascientists running expensive requests. Also I still don't know how to handle the user access management and roles. Then how would the data scientists do the compute, running Spark on their computer? Ultimately they work on their computers and don't plan on using a saas editor. Which kind of computing platform would allow low TTFB for small requests and high throughput for highly distributed workload? \n\nThe second one being an RDS PostGreSQL database for the meta, which would also do most of the compute when searching for a record, S3, and a web server. Kinda the same architecture as in C1, but the RDBMS allowing for versionning the data and creating datasets.\n\n\nDo you guys know of any solution that would fit our need better? \n\nThanks! \n\nN.B : Sorry if this is very approximate, I'm a SWE but have been doing DE for only 3 months.", "author_fullname": "t2_12102p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice for architecting a datalake.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jvem7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691343296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to ask for some advices about architecting a datalake that&amp;#39;s mostly used to train ML algorithms. &lt;/p&gt;\n\n&lt;p&gt;So we have at my job, the first silo of a datalake (let&amp;#39;s call it C1), containing raw data from IoT devices. The interface is HTTP, you download records/files, then process them locally as you want. Those are organized per category. The user access and roles is handled by an OAuth service, and a web server is serving the data to the user. It is made using an AWS EC2 machine and a Mongo database. &lt;/p&gt;\n\n&lt;p&gt;We are working on a second silo, with data being in a cleaned form, from C1, stored as parquet files. This one will be used more extensively. The &amp;quot;records&amp;quot;/data must be versionned. Some users should be able to create datasets from the records (many to many relationship). And the user ACL should be as fine as on C1. Also we want something as in-house as possible, anything Databricks Saas or AWS full-managed/serverless isn&amp;#39;t possible. &lt;/p&gt;\n\n&lt;p&gt;We are trying to solutions at the moment :&lt;/p&gt;\n\n&lt;p&gt;The first one being using Spark and Iceberg over S3 + a Glue catalog, which is great because the SQL API offers flexibility but I&amp;#39;m quite scared of the datascientists running expensive requests. Also I still don&amp;#39;t know how to handle the user access management and roles. Then how would the data scientists do the compute, running Spark on their computer? Ultimately they work on their computers and don&amp;#39;t plan on using a saas editor. Which kind of computing platform would allow low TTFB for small requests and high throughput for highly distributed workload? &lt;/p&gt;\n\n&lt;p&gt;The second one being an RDS PostGreSQL database for the meta, which would also do most of the compute when searching for a record, S3, and a web server. Kinda the same architecture as in C1, but the RDBMS allowing for versionning the data and creating datasets.&lt;/p&gt;\n\n&lt;p&gt;Do you guys know of any solution that would fit our need better? &lt;/p&gt;\n\n&lt;p&gt;Thanks! &lt;/p&gt;\n\n&lt;p&gt;N.B : Sorry if this is very approximate, I&amp;#39;m a SWE but have been doing DE for only 3 months.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jvem7", "is_robot_indexable": true, "report_reasons": null, "author": "papawish", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jvem7/need_advice_for_architecting_a_datalake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jvem7/need_advice_for_architecting_a_datalake/", "subreddit_subscribers": 121116, "created_utc": 1691343296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As someone who enjoys all kinds of cs fields, the second thing I should look at when choosing a career is the ease of finding a job and salary. Please be realistic, which one would you choose if you started from scratch?\n\n[View Poll](https://www.reddit.com/poll/15ju56b)", "author_fullname": "t2_be0kmkfc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which one would you choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ju56b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691340161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As someone who enjoys all kinds of cs fields, the second thing I should look at when choosing a career is the ease of finding a job and salary. Please be realistic, which one would you choose if you started from scratch?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/15ju56b\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ju56b", "is_robot_indexable": true, "report_reasons": null, "author": "Due_Salamander_2931", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1691512961705, "options": [{"text": "Data Engineering", "id": "24225937"}, {"text": "Devops Engineering", "id": "24225938"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 155, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ju56b/which_one_would_you_choose/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/15ju56b/which_one_would_you_choose/", "subreddit_subscribers": 121116, "created_utc": 1691340161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How successful are such efforts? Are there any problems or behaviors that keep recurring despite this?\n\n[View Poll](https://www.reddit.com/poll/15joy01)", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(question if you work in a large company with many analysts) How often does your company organize training for Analysts to help them avoid Expensive, Slow queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15joy01", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691326421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How successful are such efforts? Are there any problems or behaviors that keep recurring despite this?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/15joy01\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15joy01", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1691585622043, "options": [{"text": "once every 3 months or less", "id": "24223580"}, {"text": "once every 3 - 6 months", "id": "24223581"}, {"text": "Once every 6 - 12 months", "id": "24223582"}, {"text": "Once every few years, or even more infrequently", "id": "24223583"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 141, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15joy01/question_if_you_work_in_a_large_company_with_many/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/15joy01/question_if_you_work_in_a_large_company_with_many/", "subreddit_subscribers": 121116, "created_utc": 1691326421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm a junior in college majoring in computer information systems. The way my major is set up is that students can focus towards either programming, web design? I think it's web design either way, programming, web design, and database managment. I'm thinking I should probably focus on programming if I want to be a data engineer right?", "author_fullname": "t2_a24gckgw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need some help.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15jweks", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691345887.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691345682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m a junior in college majoring in computer information systems. The way my major is set up is that students can focus towards either programming, web design? I think it&amp;#39;s web design either way, programming, web design, and database managment. I&amp;#39;m thinking I should probably focus on programming if I want to be a data engineer right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jweks", "is_robot_indexable": true, "report_reasons": null, "author": "International_Fig420", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jweks/i_need_some_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jweks/i_need_some_help/", "subreddit_subscribers": 121116, "created_utc": 1691345682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just wondering if people see all three of these as being necessary. I\u2019m in an organization that has an Azure data warehouse. This gives us access to ADF. But databricks salespeople have started reaching out to us recently. \n\nThe ability to work within python and r in databricks sounds great. But how does it differ from a more sql-based tool like dbt?\n\nFor context, my background is more in data analytics/science. But our organization (from what I\u2019ve seen after being here a couple months) is in desperate need of data engineering skills. They\u2019ve gone out and hired data scientists, but their basic institutional data is a mess and in many cases not existent in the warehouse.", "author_fullname": "t2_9ytsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you need Azure Data Factory and Databricks? What about dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15jxfd4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691348215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wondering if people see all three of these as being necessary. I\u2019m in an organization that has an Azure data warehouse. This gives us access to ADF. But databricks salespeople have started reaching out to us recently. &lt;/p&gt;\n\n&lt;p&gt;The ability to work within python and r in databricks sounds great. But how does it differ from a more sql-based tool like dbt?&lt;/p&gt;\n\n&lt;p&gt;For context, my background is more in data analytics/science. But our organization (from what I\u2019ve seen after being here a couple months) is in desperate need of data engineering skills. They\u2019ve gone out and hired data scientists, but their basic institutional data is a mess and in many cases not existent in the warehouse.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jxfd4", "is_robot_indexable": true, "report_reasons": null, "author": "ursamajorm82", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jxfd4/do_you_need_azure_data_factory_and_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jxfd4/do_you_need_azure_data_factory_and_databricks/", "subreddit_subscribers": 121116, "created_utc": 1691348215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone have experience or evaluated the use of Neo4J vs Neptune for a cloud graph DB. Read a few things online but curious if anyone\u2019s got any pointers here. \n\nSeems like both can easily interact with sagemaker\u2026 don\u2019t think Neptune plays well with redshift. Would be loading data from S3. Looks like they both have some bulk loading functionality. \n\nI\u2019m pretty sure someone read: https://neo4j.com/blog/walmart-neo4j-competitive-advantage/ and now this is the direction we are going \ud83e\udd37\u200d\u2642\ufe0f", "author_fullname": "t2_9bj4s404", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Neptune vs Neo4J", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15jvl8l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691343729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have experience or evaluated the use of Neo4J vs Neptune for a cloud graph DB. Read a few things online but curious if anyone\u2019s got any pointers here. &lt;/p&gt;\n\n&lt;p&gt;Seems like both can easily interact with sagemaker\u2026 don\u2019t think Neptune plays well with redshift. Would be loading data from S3. Looks like they both have some bulk loading functionality. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m pretty sure someone read: &lt;a href=\"https://neo4j.com/blog/walmart-neo4j-competitive-advantage/\"&gt;https://neo4j.com/blog/walmart-neo4j-competitive-advantage/&lt;/a&gt; and now this is the direction we are going \ud83e\udd37\u200d\u2642\ufe0f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?auto=webp&amp;s=6461cc17589dd510fedc58ce52e211af7a82e4cf", "width": 900, "height": 224}, "resolutions": [{"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63dc4fce6e270fd5c997b4728a9c1ca6a7460bde", "width": 108, "height": 26}, {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a457717892c3f55d109a2bc173b147b48a77018a", "width": 216, "height": 53}, {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f6bfab6bdff8e9df079960b254cc09f9bafbaf84", "width": 320, "height": 79}, {"url": "https://external-preview.redd.it/fOzr6MGwSdCHTgkN9MLsw5dmZLFUB_07WMClVbE9EBM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=af40ed6c60f803746d4dd8609e8ce5045f0d4f1b", "width": 640, "height": 159}], "variants": {}, "id": "nK4sSdFMcMhjFzyzeJp52E0WY68i_JTltCFahWvYB4o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jvl8l", "is_robot_indexable": true, "report_reasons": null, "author": "Over-Geologist-5760", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jvl8l/neptune_vs_neo4j/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jvl8l/neptune_vs_neo4j/", "subreddit_subscribers": 121116, "created_utc": 1691343729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I work in a plastic factory and i am making tests of a product with different composition and features. I would like to compare my tests with the product of my competition and between each other in order to determinate which one is the best. Could someone guide me about how to make this type of analysis please?\n\nthe data is in the link.\n\n[Data](https://docs.google.com/spreadsheets/d/1DBaZGUlMK1p-RavfZiyr_8L4npI6hCzz381aNa2Zo5U/edit?usp=sharing)", "author_fullname": "t2_qx2yrcp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to choose the best result?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jufgz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691340897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I work in a plastic factory and i am making tests of a product with different composition and features. I would like to compare my tests with the product of my competition and between each other in order to determinate which one is the best. Could someone guide me about how to make this type of analysis please?&lt;/p&gt;\n\n&lt;p&gt;the data is in the link.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.google.com/spreadsheets/d/1DBaZGUlMK1p-RavfZiyr_8L4npI6hCzz381aNa2Zo5U/edit?usp=sharing\"&gt;Data&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?auto=webp&amp;s=b6ed92112b16068a2303c366865831f26427eafe", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c3787d86902b7d6abc24019ae9c009dee2b2232", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d8af98ced5d5e230b402963ef756923d641df974", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e792353e97cc4866a04fed5002f0e85cd7a1ff8f", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b8c0a014c73d42a52e5bd499c20f589b6b952853", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f23b638b39f7a68792ef486b7311ff8d5794edb0", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Lgg7yO5wf5iMxEoj9mvDng4BJNSlu5kjtkqKcpGtcqQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0c883ade7bacf66361c01bdbe90b34eea5dc67a4", "width": 1080, "height": 567}], "variants": {}, "id": "XC4uNHGpS51t7eDtzWOidn67MZebTkLycF2OnN3BFVQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jufgz", "is_robot_indexable": true, "report_reasons": null, "author": "ECsantaroz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jufgz/how_to_choose_the_best_result/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jufgz/how_to_choose_the_best_result/", "subreddit_subscribers": 121116, "created_utc": 1691340897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI/ML Best Practices During a Gold Rush", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": false, "name": "t3_15ju2tf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uL48H9N0DS2GEo6E8gcgH3GJoWggSe4z8bGaLYBgYgc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691339995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.min.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.min.io/ai-ml-best-practices-during-a-gold-rush/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?auto=webp&amp;s=6791496e14e9072b5565cf0bb72bd800f967cf8a", "width": 2000, "height": 598}, "resolutions": [{"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca7901908b612d3e51236eeeb3cfe4b1cf1359f3", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=435eb84902201b6c1b33b8822133d652f04c601f", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c5a88bafa9e1a8e6a4e228cdd155b0a21ce4cd9f", "width": 320, "height": 95}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4d24ecd00d22decec81215802a961e8c05765660", "width": 640, "height": 191}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=60b1c2eeb2c644334379f7225ff166914bb57360", "width": 960, "height": 287}, {"url": "https://external-preview.redd.it/vhf96aAqebV5kXzkcHzLa7DvRfqVYj1vy50dYX_RH9U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a60340fe7b4d735f421d201c1632af89ff22da2d", "width": 1080, "height": 322}], "variants": {}, "id": "LR1jOSz4RSQ2PbagOXJkm6885ysOmVuTrnO79a5sXR4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15ju2tf", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ju2tf/aiml_best_practices_during_a_gold_rush/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.min.io/ai-ml-best-practices-during-a-gold-rush/", "subreddit_subscribers": 121116, "created_utc": 1691339995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 11 years exp. Recently started working in streaming tech. Mostly worked on big data tech \nMy org and manager forcing to become manager \nI really want to become architect. Need some general guidance for becoming architect", "author_fullname": "t2_8yd9vdzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "senior developer who want transition to architect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jpfij", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691327813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 11 years exp. Recently started working in streaming tech. Mostly worked on big data tech \nMy org and manager forcing to become manager \nI really want to become architect. Need some general guidance for becoming architect&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15jpfij", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious_Role_304", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jpfij/senior_developer_who_want_transition_to_architect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jpfij/senior_developer_who_want_transition_to_architect/", "subreddit_subscribers": 121116, "created_utc": 1691327813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey I'm totally new to data and I've just started my first portfolio project creating a python web scraper. Im wondering what is the best way to store the data I'm going to collect. Its a very small amount, something around 50 columns and 1300 rows. Each Row will also have an aprox 3000 word report associated with it.\n\nI'm totally in no-mans-land mystery continent territory right now. Do I write out my data to a csv file and put that into google sheets? How do I query that with python? How do I relate the reports with each row? Should I build my own SQL database for this instead (seems overkill no?)\n\nThanks for your time.", "author_fullname": "t2_381zkha4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "End-to-End Data Analysis Project Guidance: How to store my data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jaa1b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691278455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey I&amp;#39;m totally new to data and I&amp;#39;ve just started my first portfolio project creating a python web scraper. Im wondering what is the best way to store the data I&amp;#39;m going to collect. Its a very small amount, something around 50 columns and 1300 rows. Each Row will also have an aprox 3000 word report associated with it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m totally in no-mans-land mystery continent territory right now. Do I write out my data to a csv file and put that into google sheets? How do I query that with python? How do I relate the reports with each row? Should I build my own SQL database for this instead (seems overkill no?)&lt;/p&gt;\n\n&lt;p&gt;Thanks for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jaa1b", "is_robot_indexable": true, "report_reasons": null, "author": "bigjungus11", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jaa1b/endtoend_data_analysis_project_guidance_how_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jaa1b/endtoend_data_analysis_project_guidance_how_to/", "subreddit_subscribers": 121116, "created_utc": 1691278455.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}