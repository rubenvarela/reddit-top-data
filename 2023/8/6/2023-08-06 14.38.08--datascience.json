{"kind": "Listing", "data": {"after": "t3_15jfok8", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This guy admittedly is running a social media campaign in this sub specifically to get clients. He gives advice based on his own survivorship bias without any data to support it, and parades as if he was a knowledgeable data scientist just because he was somehow promoted to \"senior data scientist\" in like a year or so. \n\nUpon him posting multiple times a day solely to drive engagement for his business I asked him about his methods that he based his advice on, and in reply he blocked me. \n\nYes, I'm probably the salty one, just wanted to point out he's a snake oil salesman whose sole goal is to get leads from this sub.", "author_fullname": "t2_3nsle7kc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dear u/on_the_mark_data, either don't run a social media marketing campaign in the sub, or be ready to answer the criticism", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ix2bi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 439, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 439, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": 1691250404.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691245552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This guy admittedly is running a social media campaign in this sub specifically to get clients. He gives advice based on his own survivorship bias without any data to support it, and parades as if he was a knowledgeable data scientist just because he was somehow promoted to &amp;quot;senior data scientist&amp;quot; in like a year or so. &lt;/p&gt;\n\n&lt;p&gt;Upon him posting multiple times a day solely to drive engagement for his business I asked him about his methods that he based his advice on, and in reply he blocked me. &lt;/p&gt;\n\n&lt;p&gt;Yes, I&amp;#39;m probably the salty one, just wanted to point out he&amp;#39;s a snake oil salesman whose sole goal is to get leads from this sub.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ix2bi", "is_robot_indexable": true, "report_reasons": null, "author": "lifesthateasy", "discussion_type": null, "num_comments": 80, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ix2bi/dear_uon_the_mark_data_either_dont_run_a_social/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ix2bi/dear_uon_the_mark_data_either_dont_run_a_social/", "subreddit_subscribers": 976713, "created_utc": 1691245552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a math enthusiasts, that's why I got attracted to ML. To understand ML theory one needs to have good hold on stats, probability and basic algebra. Deep learning requires extensive knowledge of linear algebra. All of this takes months and months to understand. But in the end all that matters is whether you can implement a model or not. Especially today when we are looking at all per-trained (LLM) models, which is just few lines of code to train. I won't say implementation is not important. But it requires much less effort to master. Why one should (and would) waste his time learning all the maths? Just for fun? (PS: I do it for fun but little frustrated by industry)", "author_fullname": "t2_sipyqz9a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Whats the point of learning ML theory if industry doesn't care (other than interviews)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ji5de", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 107, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 107, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691302673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a math enthusiasts, that&amp;#39;s why I got attracted to ML. To understand ML theory one needs to have good hold on stats, probability and basic algebra. Deep learning requires extensive knowledge of linear algebra. All of this takes months and months to understand. But in the end all that matters is whether you can implement a model or not. Especially today when we are looking at all per-trained (LLM) models, which is just few lines of code to train. I won&amp;#39;t say implementation is not important. But it requires much less effort to master. Why one should (and would) waste his time learning all the maths? Just for fun? (PS: I do it for fun but little frustrated by industry)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ji5de", "is_robot_indexable": true, "report_reasons": null, "author": "Numerous_Syllabub545", "discussion_type": null, "num_comments": 51, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ji5de/whats_the_point_of_learning_ml_theory_if_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ji5de/whats_the_point_of_learning_ml_theory_if_industry/", "subreddit_subscribers": 976713, "created_utc": 1691302673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My aim is to build up the skills of a competent DA, DS and DE over the next few years. If anyone has done this, could you explain if it has made a big difference when it comes to landing jobs?", "author_fullname": "t2_7qvort5t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone skilled in both DS and DE? If so, how much of an advantage did that give you in the job market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jlo1y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691315356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My aim is to build up the skills of a competent DA, DS and DE over the next few years. If anyone has done this, could you explain if it has made a big difference when it comes to landing jobs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jlo1y", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial_Space9001", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jlo1y/is_anyone_skilled_in_both_ds_and_de_if_so_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jlo1y/is_anyone_skilled_in_both_ds_and_de_if_so_how/", "subreddit_subscribers": 976713, "created_utc": 1691315356.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I've been impacted by tech layoffs and I decided to spend some time doing a personal project to scrape some data from the web and then apply an ML model to predict the outcome of some future event(s). Anyway, part of the reason was to stay sharp but the other motivation was to show employers what I've done as I obviously can not show code from the company I worked at. I've never done a portfolio project before so I'm wondering how to showcase it. \n\nI tried making a web application but I have no front end skills so that's not been going great, any ideas? Any suggestions for a method/platform other than just slapping the code on GitHub and linking it? Thanks.", "author_fullname": "t2_7of89rmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Best Showcase Personal Data Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15j4r69", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691264697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been impacted by tech layoffs and I decided to spend some time doing a personal project to scrape some data from the web and then apply an ML model to predict the outcome of some future event(s). Anyway, part of the reason was to stay sharp but the other motivation was to show employers what I&amp;#39;ve done as I obviously can not show code from the company I worked at. I&amp;#39;ve never done a portfolio project before so I&amp;#39;m wondering how to showcase it. &lt;/p&gt;\n\n&lt;p&gt;I tried making a web application but I have no front end skills so that&amp;#39;s not been going great, any ideas? Any suggestions for a method/platform other than just slapping the code on GitHub and linking it? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15j4r69", "is_robot_indexable": true, "report_reasons": null, "author": "RandomlyGeneratedNm", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15j4r69/how_to_best_showcase_personal_data_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15j4r69/how_to_best_showcase_personal_data_project/", "subreddit_subscribers": 976713, "created_utc": 1691264697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "New to Pandas, and although I appreciate it's power  and speed, some parts seem a bit obscure.  In particular, you seen to be able to filter both by df[filter criteria] and df.loc[filter criteria] where the filter criteria are similar: field-nanes, lists of field-nanes and boolean-arrays, and the end result seems almost identical.  What am I missing.  When do you use .loc when filtering?\n\nLooked extensively through the web, and most articles seem to focus on .loc vs .iloc, which is clear (label based indexing vs positional).\n\nAnd help or pointers gratefully accepted.", "author_fullname": "t2_35lv1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pandas loc vs no loc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jo3mf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691323883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New to Pandas, and although I appreciate it&amp;#39;s power  and speed, some parts seem a bit obscure.  In particular, you seen to be able to filter both by df[filter criteria] and df.loc[filter criteria] where the filter criteria are similar: field-nanes, lists of field-nanes and boolean-arrays, and the end result seems almost identical.  What am I missing.  When do you use .loc when filtering?&lt;/p&gt;\n\n&lt;p&gt;Looked extensively through the web, and most articles seem to focus on .loc vs .iloc, which is clear (label based indexing vs positional).&lt;/p&gt;\n\n&lt;p&gt;And help or pointers gratefully accepted.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jo3mf", "is_robot_indexable": true, "report_reasons": null, "author": "llynglas", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jo3mf/pandas_loc_vs_no_loc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jo3mf/pandas_loc_vs_no_loc/", "subreddit_subscribers": 976713, "created_utc": 1691323883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_tep294qj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Logistic Model for finding important factors of divorce", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_15jink5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/lcpx4-eSgR4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Logistic Model for finding important factors of divorce\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Logistic Model for finding important factors of divorce", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/lcpx4-eSgR4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Logistic Model for finding important factors of divorce\"&gt;&lt;/iframe&gt;", "author_name": "Tkk Nuggets", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/lcpx4-eSgR4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@tkprotich1617"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/lcpx4-eSgR4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Logistic Model for finding important factors of divorce\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/15jink5", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_CXYfyi-elK0ZDO2Xi4HiY8PMdrF_Gqt-r9_UaVZeJo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691304484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/lcpx4-eSgR4", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cpHrjRygYWuyOM9YIqeQLwiaCba7Dc44wiTl-mUokuw.jpg?auto=webp&amp;s=09c2fb83e1b3044672a3943d826083a4a620551a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/cpHrjRygYWuyOM9YIqeQLwiaCba7Dc44wiTl-mUokuw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=781ac07904960a1166e6d6e25cf76b26b379e5e8", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/cpHrjRygYWuyOM9YIqeQLwiaCba7Dc44wiTl-mUokuw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1ee91acd2818a76afbec51834fb1bdf1e5e347a3", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/cpHrjRygYWuyOM9YIqeQLwiaCba7Dc44wiTl-mUokuw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=43a12f0dc7bda4ed20045e6c4bcf32d25e314d8e", "width": 320, "height": 240}], "variants": {}, "id": "DSTlkuKkIkeT_Ys9Sc3MbS0DfmcVNqjVFB7VI1Dl5GU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jink5", "is_robot_indexable": true, "report_reasons": null, "author": "TKPROTICH", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jink5/logistic_model_for_finding_important_factors_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/lcpx4-eSgR4", "subreddit_subscribers": 976713, "created_utc": 1691304484.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Logistic Model for finding important factors of divorce", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/lcpx4-eSgR4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Logistic Model for finding important factors of divorce\"&gt;&lt;/iframe&gt;", "author_name": "Tkk Nuggets", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/lcpx4-eSgR4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@tkprotich1617"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anyone have any advice for a first time conference attendee at JSM? I also am looking for jobs too and heard there was a career fair there as well?", "author_fullname": "t2_55qnkwk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Joint Statistical Meetings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jfd40", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691293374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have any advice for a first time conference attendee at JSM? I also am looking for jobs too and heard there was a career fair there as well?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jfd40", "is_robot_indexable": true, "report_reasons": null, "author": "kbabqiqja", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jfd40/joint_statistical_meetings/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jfd40/joint_statistical_meetings/", "subreddit_subscribers": 976713, "created_utc": 1691293374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As the title states, I am curious how the Data Scientists here handle marketing in their companies, as Marketing is one of the more popular use cases for DS.  \n\nLearning about Causal Analysis, I understand the 'Gold Standard' is randomized experimentation.  So, given a group, you'd like to randomly assign who gets a Treatment and who doesn't, then you can compare the difference in outcomes between the 2 groups.\n\nThere are instances where this is not reasonable, like in medical examples.  Greatly simplifying things,  if someone gets sick, you give them treatment.  So everyone who needs it should get treatment, so you use one of the many techniques to see difference in outcomes between groups.\n\nBut how about Marketing Campaigns? If you have a promotions team with the capacity to do A/B testing for example, the analysis returns to the first point.  But what if the campaign is population-wide? Like sent to all users in an app.  Only a few users may respond to this campaign and fulfill conditions.  Others may be purchasing in this time but not participate in the campaign.  So now you have the entire population do/do not make a purchase, a subgroup of users who respond to campaign, and a subgroup who dont.  \n\nWhat are some methods that would be useful in measuring the effects of the treatment here, which is the population wide campaign.\n\n&amp;#x200B;", "author_fullname": "t2_5puimv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to estimate effects of population wide marketing campaign?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jeo5s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691291209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title states, I am curious how the Data Scientists here handle marketing in their companies, as Marketing is one of the more popular use cases for DS.  &lt;/p&gt;\n\n&lt;p&gt;Learning about Causal Analysis, I understand the &amp;#39;Gold Standard&amp;#39; is randomized experimentation.  So, given a group, you&amp;#39;d like to randomly assign who gets a Treatment and who doesn&amp;#39;t, then you can compare the difference in outcomes between the 2 groups.&lt;/p&gt;\n\n&lt;p&gt;There are instances where this is not reasonable, like in medical examples.  Greatly simplifying things,  if someone gets sick, you give them treatment.  So everyone who needs it should get treatment, so you use one of the many techniques to see difference in outcomes between groups.&lt;/p&gt;\n\n&lt;p&gt;But how about Marketing Campaigns? If you have a promotions team with the capacity to do A/B testing for example, the analysis returns to the first point.  But what if the campaign is population-wide? Like sent to all users in an app.  Only a few users may respond to this campaign and fulfill conditions.  Others may be purchasing in this time but not participate in the campaign.  So now you have the entire population do/do not make a purchase, a subgroup of users who respond to campaign, and a subgroup who dont.  &lt;/p&gt;\n\n&lt;p&gt;What are some methods that would be useful in measuring the effects of the treatment here, which is the population wide campaign.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jeo5s", "is_robot_indexable": true, "report_reasons": null, "author": "shaner92", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jeo5s/how_to_estimate_effects_of_population_wide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jeo5s/how_to_estimate_effects_of_population_wide/", "subreddit_subscribers": 976713, "created_utc": 1691291209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a dataset structured like the above. U1L1 has four rows with utilities for one person. \n\nThe goal is to get every unique combination between each category (Ex: u1L1_u2l1_u3l1, u1l1_u2l2_u3l1 etc) sum up each row from the columns in the combination chosen, then get the average from all the sums. That's it; I've drawn an example. \n\nAfter unique combos are created, I need to sum across the row, exp() the sum and then average all the resulting exp(sums). That\u2019s it.\n\nIve thought about exploding the data to get a unique identifier and then group based on that getting the average; I have about 168 billion possible combinations so that gets tricky\u2026. I can break that into 14 different datasets but looking for any guidance!! Thank you.", "author_fullname": "t2_ry4km", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Calculating utility for every combo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15j4t0i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WTK9QV_-QOeV1bCP3OyUNBQ6xpgpHArKTcWQ6R7msCE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691264819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset structured like the above. U1L1 has four rows with utilities for one person. &lt;/p&gt;\n\n&lt;p&gt;The goal is to get every unique combination between each category (Ex: u1L1_u2l1_u3l1, u1l1_u2l2_u3l1 etc) sum up each row from the columns in the combination chosen, then get the average from all the sums. That&amp;#39;s it; I&amp;#39;ve drawn an example. &lt;/p&gt;\n\n&lt;p&gt;After unique combos are created, I need to sum across the row, exp() the sum and then average all the resulting exp(sums). That\u2019s it.&lt;/p&gt;\n\n&lt;p&gt;Ive thought about exploding the data to get a unique identifier and then group based on that getting the average; I have about 168 billion possible combinations so that gets tricky\u2026. I can break that into 14 different datasets but looking for any guidance!! Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/qd6h6cimicgb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/qd6h6cimicgb1.jpg?auto=webp&amp;s=954b43e27323a4d7ff78f6f46440744caca4510b", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/qd6h6cimicgb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=08a0edc4d44480ec0ecf23763b95650060df8c9b", "width": 108, "height": 144}, {"url": "https://preview.redd.it/qd6h6cimicgb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a2444d499faf235e32ec8621c6cc08b77b804586", "width": 216, "height": 288}, {"url": "https://preview.redd.it/qd6h6cimicgb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9324db5dd5afe48245c869c46ae5c16c9fb21314", "width": 320, "height": 426}, {"url": "https://preview.redd.it/qd6h6cimicgb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c11ba641c13d199ec5a1015aa9a695d344bbee72", "width": 640, "height": 853}, {"url": "https://preview.redd.it/qd6h6cimicgb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ceb6722657a60bb3bce434e87b00d7a1d3dbc15f", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/qd6h6cimicgb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e34f571bf3ef6e5c566e2e890931bfbfe04a28bc", "width": 1080, "height": 1440}], "variants": {}, "id": "paUfLi9bGc4lNI7OuKl1dM7NpRQAuTSHT48pGVEmQXM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15j4t0i", "is_robot_indexable": true, "report_reasons": null, "author": "CaptnCassanova", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15j4t0i/calculating_utility_for_every_combo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/qd6h6cimicgb1.jpg", "subreddit_subscribers": 976713, "created_utc": 1691264819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you guys have any recommendations for websites/books which are useful for starting out and exploring in the data science space (not theory/math books, but actual general career guidance)", "author_fullname": "t2_pgihp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Books for navigating career in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15jopfo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691325722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you guys have any recommendations for websites/books which are useful for starting out and exploring in the data science space (not theory/math books, but actual general career guidance)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jopfo", "is_robot_indexable": true, "report_reasons": null, "author": "BadTacticss", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jopfo/books_for_navigating_career_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jopfo/books_for_navigating_career_in_data_science/", "subreddit_subscribers": 976713, "created_utc": 1691325722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So im currently creating a list of statistical terms and information to learn for my R programming knowledge. Of course all of these key terms come with annoying equations which I have no clue what it means. But my thinking is that since R will be doing the working out....the equations are kinda irrelevant ? Maybe ?\n\nEither way my goal is to understand what these terms are and how and when to use it with R. Im hoping I dont have to learn these equations.", "author_fullname": "t2_xt8l4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is knowing Statistical Equations important ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15joix1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691325185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So im currently creating a list of statistical terms and information to learn for my R programming knowledge. Of course all of these key terms come with annoying equations which I have no clue what it means. But my thinking is that since R will be doing the working out....the equations are kinda irrelevant ? Maybe ?&lt;/p&gt;\n\n&lt;p&gt;Either way my goal is to understand what these terms are and how and when to use it with R. Im hoping I dont have to learn these equations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15joix1", "is_robot_indexable": true, "report_reasons": null, "author": "JonStark2016", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15joix1/is_knowing_statistical_equations_important/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15joix1/is_knowing_statistical_equations_important/", "subreddit_subscribers": 976713, "created_utc": 1691325185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I also posted the question [on StackExchange.](https://stats.stackexchange.com/questions/623313/forecasting-a-time-series-model-for-1000s-of-time-series)\n\nI'm currently immersed in a challenging forecasting project centered around predicting the required work hours to complete various tasks within a team setting. My dataset comprises crucial attributes, including team IDs, task IDs, hours, and dates. Specifically, I'm working with a comprehensive dataset that holds distinct time series information for each unique combination of teams and tasks, resulting in approximately 8000 distinct time series. My overarching goal is to construct a robust forecasting model tailored to this intricate scenario.\n\nAmidst this endeavor, I've encountered several complexities. These include the diversity in time series lengths, the presence of both new and well-established teams and tasks, varying from 3 months to 2 years of data, and the potential incompleteness or gaps within the time series.\n\nTo provide deeper insight into the dataset's dynamics, each team is associated with a set of tasks, such as \"call customer\", \"draft email\" and \"follow up with a client\". Individuals within the team record daily time entries for these tasks, collectively contributing to the intricate web of time series data. The primary objective of my forecasting model is to predict future work hours based on historical observations, facilitating informed planning and decision-making by team leads.\n\nIn my pursuit of a scalable approach, I'm exploring the following strategies to enhance forecasting accuracy:\n\nUtilizing a diverse ensemble of time series models (e.g., Prophet, ARIMA) to boost forecasting precision, coupled with time series ensemble techniques for prediction aggregation (as detailed here). The resultant ensemble models would be saved for future predictions.  \nTuning hyperparameters for individual models to optimize their predictive capabilities.  \nConducting rigorous machine learning experiments for each ensemble model to identify the most effective models based on varying hyperparameter configurations.  \nEvaluating model performance using the Mean Absolute Percentage Error (MAPE) as the chosen evaluation metric. However, the presence of tasks with zero hours for certain days poses challenges to accurate MAPE calculation.  \nTo comprehend the data more deeply, I'm considering applying stationarity tests. However, I'm seeking guidance on how to effectively scale this approach to encompass the complexity of 8000 time series.  \nDespite these strategies, the challenge of scalability remains. For instance, the task of training six models (ARIMA, ETS, BATS, TBATS, Prophet, and XGBoost) for each of the 8000 time series equates to a staggering 48,000 iterations, without considering hyperparameter tuning. The practical feasibility of tracking these experiments using open-source MLOps tools like MLFlow is also a concern, given the substantial computation requirements.\n\nI'm reaching out for valuable insights and guidance. I'm keen to learn about best practices, effective approaches, and any available resources that can help me navigate this challenging endeavor.\n\nThank you in advance for your expertise and assistance.", "author_fullname": "t2_1yr4w8az", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Forecasting a Time Series Model for 1000s of Time Series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jna8c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691321190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I also posted the question &lt;a href=\"https://stats.stackexchange.com/questions/623313/forecasting-a-time-series-model-for-1000s-of-time-series\"&gt;on StackExchange.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently immersed in a challenging forecasting project centered around predicting the required work hours to complete various tasks within a team setting. My dataset comprises crucial attributes, including team IDs, task IDs, hours, and dates. Specifically, I&amp;#39;m working with a comprehensive dataset that holds distinct time series information for each unique combination of teams and tasks, resulting in approximately 8000 distinct time series. My overarching goal is to construct a robust forecasting model tailored to this intricate scenario.&lt;/p&gt;\n\n&lt;p&gt;Amidst this endeavor, I&amp;#39;ve encountered several complexities. These include the diversity in time series lengths, the presence of both new and well-established teams and tasks, varying from 3 months to 2 years of data, and the potential incompleteness or gaps within the time series.&lt;/p&gt;\n\n&lt;p&gt;To provide deeper insight into the dataset&amp;#39;s dynamics, each team is associated with a set of tasks, such as &amp;quot;call customer&amp;quot;, &amp;quot;draft email&amp;quot; and &amp;quot;follow up with a client&amp;quot;. Individuals within the team record daily time entries for these tasks, collectively contributing to the intricate web of time series data. The primary objective of my forecasting model is to predict future work hours based on historical observations, facilitating informed planning and decision-making by team leads.&lt;/p&gt;\n\n&lt;p&gt;In my pursuit of a scalable approach, I&amp;#39;m exploring the following strategies to enhance forecasting accuracy:&lt;/p&gt;\n\n&lt;p&gt;Utilizing a diverse ensemble of time series models (e.g., Prophet, ARIMA) to boost forecasting precision, coupled with time series ensemble techniques for prediction aggregation (as detailed here). The resultant ensemble models would be saved for future predictions.&lt;br/&gt;\nTuning hyperparameters for individual models to optimize their predictive capabilities.&lt;br/&gt;\nConducting rigorous machine learning experiments for each ensemble model to identify the most effective models based on varying hyperparameter configurations.&lt;br/&gt;\nEvaluating model performance using the Mean Absolute Percentage Error (MAPE) as the chosen evaluation metric. However, the presence of tasks with zero hours for certain days poses challenges to accurate MAPE calculation.&lt;br/&gt;\nTo comprehend the data more deeply, I&amp;#39;m considering applying stationarity tests. However, I&amp;#39;m seeking guidance on how to effectively scale this approach to encompass the complexity of 8000 time series.&lt;br/&gt;\nDespite these strategies, the challenge of scalability remains. For instance, the task of training six models (ARIMA, ETS, BATS, TBATS, Prophet, and XGBoost) for each of the 8000 time series equates to a staggering 48,000 iterations, without considering hyperparameter tuning. The practical feasibility of tracking these experiments using open-source MLOps tools like MLFlow is also a concern, given the substantial computation requirements.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reaching out for valuable insights and guidance. I&amp;#39;m keen to learn about best practices, effective approaches, and any available resources that can help me navigate this challenging endeavor.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your expertise and assistance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?auto=webp&amp;s=e25be8cb5cf2448d39a7e5ffc877e4d466b776d3", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9645cb9b1f6437724f04c3b63b841cf7766f27d6", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dc7ee570d3611e1ef9314d658423c42908808820", "width": 216, "height": 216}], "variants": {}, "id": "63C1GbYQbI4tHZMkw99e-qlyoYaGnG58yfnmnFUJ34s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jna8c", "is_robot_indexable": true, "report_reasons": null, "author": "Teethss", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jna8c/forecasting_a_time_series_model_for_1000s_of_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jna8c/forecasting_a_time_series_model_for_1000s_of_time/", "subreddit_subscribers": 976713, "created_utc": 1691321190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a use case for which I have to decide the best DB to use.\n\nUse Case:\nMultiple people will read row-wise and update the row they were assigned. For example, I want to label text as either happy, sad or neutral. All the sentences are in a DB as rows. Now 5 people can label at a time. This means 5 people will be reading and updating individual rows.\n\nQuestion:\nWhich in your opinion is the most optimal DB for such operations and why?\n\nI am leaning towards redis, but I don't have a background in software engineering.", "author_fullname": "t2_5bjmm66f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best DB for a problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jlkd8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691314970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a use case for which I have to decide the best DB to use.&lt;/p&gt;\n\n&lt;p&gt;Use Case:\nMultiple people will read row-wise and update the row they were assigned. For example, I want to label text as either happy, sad or neutral. All the sentences are in a DB as rows. Now 5 people can label at a time. This means 5 people will be reading and updating individual rows.&lt;/p&gt;\n\n&lt;p&gt;Question:\nWhich in your opinion is the most optimal DB for such operations and why?&lt;/p&gt;\n\n&lt;p&gt;I am leaning towards redis, but I don&amp;#39;t have a background in software engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jlkd8", "is_robot_indexable": true, "report_reasons": null, "author": "hark_in_tranquillity", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jlkd8/best_db_for_a_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jlkd8/best_db_for_a_problem/", "subreddit_subscribers": 976713, "created_utc": 1691314970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I want to detect an object but only if they are in some specific regions, which are not static so I cannot manually crop the image.\n\nLets say we are detecting phones but we only want phones that are not put securely, ie. they might drop to ground if someone touches them or they might get wet since there is sink etc. So obviously not all phones in all images are labelled. Also image context is enough for the person to label these specific phones.\n\nThe most obvious answer for how to proceed is try and see, \\[train with the labels and observe metrics on region proposal networks\\] but I want to ask for your opinions. Thanks in advance!", "author_fullname": "t2_8dt4hm2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] detecting only specific instances of the object", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jj8n9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691306544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I want to detect an object but only if they are in some specific regions, which are not static so I cannot manually crop the image.&lt;/p&gt;\n\n&lt;p&gt;Lets say we are detecting phones but we only want phones that are not put securely, ie. they might drop to ground if someone touches them or they might get wet since there is sink etc. So obviously not all phones in all images are labelled. Also image context is enough for the person to label these specific phones.&lt;/p&gt;\n\n&lt;p&gt;The most obvious answer for how to proceed is try and see, [train with the labels and observe metrics on region proposal networks] but I want to ask for your opinions. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jj8n9", "is_robot_indexable": true, "report_reasons": null, "author": "Street_Excitement_14", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jj8n9/d_detecting_only_specific_instances_of_the_object/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jj8n9/d_detecting_only_specific_instances_of_the_object/", "subreddit_subscribers": 976713, "created_utc": 1691306544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am learning SQL, and came across a topic where I was creating Schema of a table, and adding constraints to some columns,\n\nhttps://preview.redd.it/l1cwfsvxydgb1.png?width=1186&amp;format=png&amp;auto=webp&amp;s=e736663400ba3bbee2595093ee275b7ebdcb45a2\n\nHere In school\\_ID column, I can add rule of value length=5 while adding that column, but I can also specifically define constraint for that column, for value length=5 ,\n\nBoth works, now I am confused what is difference between both action.\n\nwhere one will work and other won't?\n\nIn a specific condition which one should I use?", "author_fullname": "t2_agvtvokn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PostgreSQL-Adding Constraints", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 48, "top_awarded_type": null, "hide_score": false, "media_metadata": {"l1cwfsvxydgb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 37, "x": 108, "u": "https://preview.redd.it/l1cwfsvxydgb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c53ed10867e10d70671148785b9f237ed86269c"}, {"y": 75, "x": 216, "u": "https://preview.redd.it/l1cwfsvxydgb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=785ce52b4ffc2dfe877b242da38c5c588abdaaff"}, {"y": 111, "x": 320, "u": "https://preview.redd.it/l1cwfsvxydgb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1468bcbaf7fed3f515a0c6b9cd2c6a31b64464d1"}, {"y": 222, "x": 640, "u": "https://preview.redd.it/l1cwfsvxydgb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a4a13eee1200492985de8b4051d8dcad186eceb3"}, {"y": 333, "x": 960, "u": "https://preview.redd.it/l1cwfsvxydgb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=76f36956e08bd0390603434ad8d3ce2448b6be0a"}, {"y": 375, "x": 1080, "u": "https://preview.redd.it/l1cwfsvxydgb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f11e927c0824634c79e38407fcdfbcc649a72a6f"}], "s": {"y": 412, "x": 1186, "u": "https://preview.redd.it/l1cwfsvxydgb1.png?width=1186&amp;format=png&amp;auto=webp&amp;s=e736663400ba3bbee2595093ee275b7ebdcb45a2"}, "id": "l1cwfsvxydgb1"}}, "name": "t3_15jbt5o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rruNs6rXyhY6j7mwwDjMX2AdVq66T3Nxmecgk-pSrhA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691282653.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am learning SQL, and came across a topic where I was creating Schema of a table, and adding constraints to some columns,&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/l1cwfsvxydgb1.png?width=1186&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e736663400ba3bbee2595093ee275b7ebdcb45a2\"&gt;https://preview.redd.it/l1cwfsvxydgb1.png?width=1186&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e736663400ba3bbee2595093ee275b7ebdcb45a2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here In school_ID column, I can add rule of value length=5 while adding that column, but I can also specifically define constraint for that column, for value length=5 ,&lt;/p&gt;\n\n&lt;p&gt;Both works, now I am confused what is difference between both action.&lt;/p&gt;\n\n&lt;p&gt;where one will work and other won&amp;#39;t?&lt;/p&gt;\n\n&lt;p&gt;In a specific condition which one should I use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jbt5o", "is_robot_indexable": true, "report_reasons": null, "author": "chilly_tomato", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jbt5o/postgresqladding_constraints/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jbt5o/postgresqladding_constraints/", "subreddit_subscribers": 976713, "created_utc": 1691282653.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We are a team of data analysts, and now we want to separate the etl, and dashboarding part of the job to give the analysts more focus on the analysis. \n\nI am quite familiar with tableau and python so they chose me to lead this new subteam. \n\nMy personal goal is to be a data scientist. With the creation of BI team, am I going near to my goal or am I going on the other direction?\n\nAlso, any tip on leading a BI team?\n\nThank$!", "author_fullname": "t2_ftzx68gnj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am tasked to create and lead a Business Intelligence Team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ja5t3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691278156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are a team of data analysts, and now we want to separate the etl, and dashboarding part of the job to give the analysts more focus on the analysis. &lt;/p&gt;\n\n&lt;p&gt;I am quite familiar with tableau and python so they chose me to lead this new subteam. &lt;/p&gt;\n\n&lt;p&gt;My personal goal is to be a data scientist. With the creation of BI team, am I going near to my goal or am I going on the other direction?&lt;/p&gt;\n\n&lt;p&gt;Also, any tip on leading a BI team?&lt;/p&gt;\n\n&lt;p&gt;Thank$!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ja5t3", "is_robot_indexable": true, "report_reasons": null, "author": "medyosuper", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ja5t3/i_am_tasked_to_create_and_lead_a_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ja5t3/i_am_tasked_to_create_and_lead_a_business/", "subreddit_subscribers": 976713, "created_utc": 1691278156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "All in one package: Remote Server with RDP Access, Unlimited Worldwide Residential Proxies, and Device Fingerprint Spoofing. (1 Year)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15j6ra0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_arjlo", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AxcUTONrZB02Z1sHW7ghttzhsRncnsnHYhmKvXM6ZUo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "911s5_alternative", "selftext": "**The Professional All in one PackageUnlimited worldwide proxies + full edited Remote Server with RDP and VNC Access + Device fingerprints spoofing. (1 Year)**\n\n**What are the package features?**\n\n**This package is for Professional people only who know and value the benefits**\n\n1. **Edited Virtual Machine (VPS) With RDP and VNC Access**\n2. **All third party report bots redirected to somewhere else (block them is not good)**\n3. **A special tool to create a profile for each proxy so the websites can't identify your RDP fingerprints**\n4. **All Professional people know that websites Identify people by device fingerprints not only IP Address that's why we created this edited VPS with special tools**\n5. **Fingerprints Spoofer for each proxy you create (Auto)**\n6. **GPS Location Spoof (Auto)**\n7. **Timezone Spoof (Auto)**\n8. **Real 20k User Agents Added to all profiles**\n9. **Unlimited Proxies for all countries (Fairly usage applied)**\n10. **Unlimited Traffic / Bandwidth**\n11. **No Blocked Sites**\n12. **All Proxies are residential Proxies**\n13. **Fraud Score 0**\n14. **Additional tools added to the RDP for Professional people**\n15. **The package is for 1 Year only but you can renew it**\n\n&amp;#x200B;\n\n**How does it work?**\n\nFirst, you connect to the remote virtual machine using any RDP client from your phone or computer. After logging in to the remote virtual machine, you'll see a program similar to the screenshots provided. From there, you can choose the residential proxy location (country, state, city) and customize the device fingerprints as desired. As you may know, websites nowadays identify users through device fingerprints, not just IP addresses. This package includes unlimited worldwide residential proxies and is multi-layered (Remote Virtual Machine + Unlimited Residential Proxies + The ability to change device fingerprints).\n\nEvery time you log in to the remote virtual machine through the RDP client, you can change the device fingerprints and residential proxy. You also have the option to create multiple RDP users, each with unique device fingerprints and a residential proxy. The package offers many more features for your convenience.\n\n&amp;#x200B;\n\n**First you login to the remote windows server using Remote Desktop, you can even login to it from a phone using any RDP client,I use it from iPad so I can use windows on iPad.**\n\n[RDP](https://preview.redd.it/qpnhnkrhsd7b1.jpg?width=407&amp;format=pjpg&amp;auto=webp&amp;s=49b2dfa628b3d13a368cf1cd4b2a5deeef19f8c7)\n\n**After you login you see windows remote virtual machine**\n\n&amp;#x200B;\n\n[Liber8Proxy](https://preview.redd.it/yk5e51ylsd7b1.jpg?width=602&amp;format=pjpg&amp;auto=webp&amp;s=30a0c03e21228482df50dd1e021143cbb64f236f)\n\n**Now from start menu on the Remote Server type \u201dliber8\u201d to open the program that spoofs the virtual machine and select a worldwide residential proxy (unlimited).**\n\n**Like this**\n\n&amp;#x200B;\n\n[Device fingerprints spoofing](https://preview.redd.it/ub63catqsd7b1.jpg?width=602&amp;format=pjpg&amp;auto=webp&amp;s=2ce30149963eb6a2df990d90c7ea32fde5620c74)\n\n&amp;#x200B;\n\n**There is no KYC, No verification, no GOV I\u2019d required.**\n\n&amp;#x200B;\n\n**The package link** [**Liber8Proxy Professional Package**](https://liber8proxy.com/unlimited-worldwide-residential-proxy)\n\n&amp;#x200B;\n\n**Please use my referral link** [**https://Liber8Proxy.com/?referral=msdiana**](https://Liber8Proxy.com/)\n\n&amp;#x200B;\n\n**\\*This Package is for one Year but you can renew it\\***\n\n**Read about it on AP NEWS**\n\n[AP NEWS - Liber8 Proxy has created a New undetectable Operating System with Anti Detect and Unlimited Residential Proxy on a VPS](https://apnews.com/article/technology-operating-systems-626ead1115df0dc7d525d0005f5bcecd)", "author_fullname": "t2_7rwj4lb8s", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "All in one package: Remote Server with RDP Access, Unlimited Worldwide Residential Proxies, and Device Fingerprint Spoofing. (1 Year)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/911s5_alternative", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qpnhnkrhsd7b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/qpnhnkrhsd7b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f285106355b42e6ddef7eab50d468acc86e796e4"}, {"y": 133, "x": 216, "u": "https://preview.redd.it/qpnhnkrhsd7b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b21c82b939b8d6c830f926b5f4542d0b3e1446a9"}, {"y": 198, "x": 320, "u": "https://preview.redd.it/qpnhnkrhsd7b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6717679246aac74b5a770874244ce4cd7895cb4b"}], "s": {"y": 252, "x": 407, "u": "https://preview.redd.it/qpnhnkrhsd7b1.jpg?width=407&amp;format=pjpg&amp;auto=webp&amp;s=49b2dfa628b3d13a368cf1cd4b2a5deeef19f8c7"}, "id": "qpnhnkrhsd7b1"}, "ub63catqsd7b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/ub63catqsd7b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=19b9593bebac6f717109b1eeb0ebdbab8b4059b5"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/ub63catqsd7b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=43d94983ed474fca9d6050a7f0aa740490457b14"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/ub63catqsd7b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e9023892dc86487c4620072fb79ef4a0cb8b34de"}], "s": {"y": 1817, "x": 602, "u": "https://preview.redd.it/ub63catqsd7b1.jpg?width=602&amp;format=pjpg&amp;auto=webp&amp;s=2ce30149963eb6a2df990d90c7ea32fde5620c74"}, "id": "ub63catqsd7b1"}, "yk5e51ylsd7b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 172, "x": 108, "u": "https://preview.redd.it/yk5e51ylsd7b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2021a3d5f9d4f66a9c0ed57bf080311242b03163"}, {"y": 345, "x": 216, "u": "https://preview.redd.it/yk5e51ylsd7b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e82e287142f45d5ad4fcaea1ec636a3ffaf0d84c"}, {"y": 511, "x": 320, "u": "https://preview.redd.it/yk5e51ylsd7b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4869350d591c5d9c315049995dc5aedfd96a04ec"}], "s": {"y": 963, "x": 602, "u": "https://preview.redd.it/yk5e51ylsd7b1.jpg?width=602&amp;format=pjpg&amp;auto=webp&amp;s=30a0c03e21228482df50dd1e021143cbb64f236f"}, "id": "yk5e51ylsd7b1"}}, "name": "t3_14f9frf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 829, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 829, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AxcUTONrZB02Z1sHW7ghttzhsRncnsnHYhmKvXM6ZUo.jpg", "edited": 1687624965.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687358187.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.911s5_alternative", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;The Professional All in one PackageUnlimited worldwide proxies + full edited Remote Server with RDP and VNC Access + Device fingerprints spoofing. (1 Year)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What are the package features?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;This package is for Professional people only who know and value the benefits&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Edited Virtual Machine (VPS) With RDP and VNC Access&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;All third party report bots redirected to somewhere else (block them is not good)&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;A special tool to create a profile for each proxy so the websites can&amp;#39;t identify your RDP fingerprints&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;All Professional people know that websites Identify people by device fingerprints not only IP Address that&amp;#39;s why we created this edited VPS with special tools&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Fingerprints Spoofer for each proxy you create (Auto)&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;GPS Location Spoof (Auto)&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Timezone Spoof (Auto)&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Real 20k User Agents Added to all profiles&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Unlimited Proxies for all countries (Fairly usage applied)&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Unlimited Traffic / Bandwidth&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;No Blocked Sites&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;All Proxies are residential Proxies&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Fraud Score 0&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Additional tools added to the RDP for Professional people&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;The package is for 1 Year only but you can renew it&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How does it work?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;First, you connect to the remote virtual machine using any RDP client from your phone or computer. After logging in to the remote virtual machine, you&amp;#39;ll see a program similar to the screenshots provided. From there, you can choose the residential proxy location (country, state, city) and customize the device fingerprints as desired. As you may know, websites nowadays identify users through device fingerprints, not just IP addresses. This package includes unlimited worldwide residential proxies and is multi-layered (Remote Virtual Machine + Unlimited Residential Proxies + The ability to change device fingerprints).&lt;/p&gt;\n\n&lt;p&gt;Every time you log in to the remote virtual machine through the RDP client, you can change the device fingerprints and residential proxy. You also have the option to create multiple RDP users, each with unique device fingerprints and a residential proxy. The package offers many more features for your convenience.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;First you login to the remote windows server using Remote Desktop, you can even login to it from a phone using any RDP client,I use it from iPad so I can use windows on iPad.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qpnhnkrhsd7b1.jpg?width=407&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=49b2dfa628b3d13a368cf1cd4b2a5deeef19f8c7\"&gt;RDP&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;After you login you see windows remote virtual machine&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yk5e51ylsd7b1.jpg?width=602&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=30a0c03e21228482df50dd1e021143cbb64f236f\"&gt;Liber8Proxy&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Now from start menu on the Remote Server type \u201dliber8\u201d to open the program that spoofs the virtual machine and select a worldwide residential proxy (unlimited).&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Like this&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ub63catqsd7b1.jpg?width=602&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=2ce30149963eb6a2df990d90c7ea32fde5620c74\"&gt;Device fingerprints spoofing&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;There is no KYC, No verification, no GOV I\u2019d required.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The package link&lt;/strong&gt; &lt;a href=\"https://liber8proxy.com/unlimited-worldwide-residential-proxy\"&gt;&lt;strong&gt;Liber8Proxy Professional Package&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Please use my referral link&lt;/strong&gt; &lt;a href=\"https://Liber8Proxy.com/\"&gt;&lt;strong&gt;https://Liber8Proxy.com/?referral=msdiana&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;*This Package is for one Year but you can renew it\\&lt;/strong&gt;*&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Read about it on AP NEWS&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://apnews.com/article/technology-operating-systems-626ead1115df0dc7d525d0005f5bcecd\"&gt;AP NEWS - Liber8 Proxy has created a New undetectable Operating System with Anti Detect and Unlimited Residential Proxy on a VPS&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CYubxPl4Vy1s4S9rmK0kkpIuyzb09EbxNgwhXCVr9to.jpg?auto=webp&amp;s=15051692068b3ccb543382c8c3abfd43d1bb9243", "width": 500, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/CYubxPl4Vy1s4S9rmK0kkpIuyzb09EbxNgwhXCVr9to.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=98bddd586941ec0ab6c4c383d8d39544d714d5a8", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/CYubxPl4Vy1s4S9rmK0kkpIuyzb09EbxNgwhXCVr9to.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a63085473379c79e9bcf91e954a157bf0af84987", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/CYubxPl4Vy1s4S9rmK0kkpIuyzb09EbxNgwhXCVr9to.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=88ad01e1a1f49eafd2ca5a5d134c0d37de1dcadb", "width": 320, "height": 320}], "variants": {}, "id": "NLajS7CTgqo7uE-iPZuNiOul9xxr0A4X4E_4DV9_Eb0"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_777ng5", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14f9frf", "is_robot_indexable": true, "report_reasons": null, "author": "MzDiana", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/911s5_alternative/comments/14f9frf/all_in_one_package_remote_server_with_rdp_access/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/911s5_alternative/comments/14f9frf/all_in_one_package_remote_server_with_rdp_access/", "subreddit_subscribers": 2825, "created_utc": 1687358187.0, "num_crossposts": 260, "media": null, "is_video": false}], "created": 1691269628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.911s5_alternative", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/911s5_alternative/comments/14f9frf/all_in_one_package_remote_server_with_rdp_access/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CYubxPl4Vy1s4S9rmK0kkpIuyzb09EbxNgwhXCVr9to.jpg?auto=webp&amp;s=15051692068b3ccb543382c8c3abfd43d1bb9243", "width": 500, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/CYubxPl4Vy1s4S9rmK0kkpIuyzb09EbxNgwhXCVr9to.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=98bddd586941ec0ab6c4c383d8d39544d714d5a8", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/CYubxPl4Vy1s4S9rmK0kkpIuyzb09EbxNgwhXCVr9to.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a63085473379c79e9bcf91e954a157bf0af84987", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/CYubxPl4Vy1s4S9rmK0kkpIuyzb09EbxNgwhXCVr9to.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=88ad01e1a1f49eafd2ca5a5d134c0d37de1dcadb", "width": 320, "height": 320}], "variants": {}, "id": "NLajS7CTgqo7uE-iPZuNiOul9xxr0A4X4E_4DV9_Eb0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15j6ra0", "is_robot_indexable": true, "report_reasons": null, "author": "xshopx", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14f9frf", "author_flair_text_color": null, "permalink": "/r/datascience/comments/15j6ra0/all_in_one_package_remote_server_with_rdp_access/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/911s5_alternative/comments/14f9frf/all_in_one_package_remote_server_with_rdp_access/", "subreddit_subscribers": 976713, "created_utc": 1691269628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What kind of problems you are solving or solved in your current role?\nI am wondering if everyone start to implement generative AI(GPT4, Llama, stable diffusion, etc.) in their company. I know there a lots of startups directly focusing on those models to but besides them how others use it?", "author_fullname": "t2_b0kcvbcq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use cases of Generative AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15j5z45", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691267700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What kind of problems you are solving or solved in your current role?\nI am wondering if everyone start to implement generative AI(GPT4, Llama, stable diffusion, etc.) in their company. I know there a lots of startups directly focusing on those models to but besides them how others use it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15j5z45", "is_robot_indexable": true, "report_reasons": null, "author": "Sure_Fisherman2641", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15j5z45/use_cases_of_generative_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15j5z45/use_cases_of_generative_ai/", "subreddit_subscribers": 976713, "created_utc": 1691267700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know that Midjourney is used for creating the characters, but can it also make them talk or what\u2019s used for that?\n\nhttps://youtu.be/1bqcojPYZKQ", "author_fullname": "t2_9a9z89x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone knows what\u2019s used to make the characters talk in this videos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jftv3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691294817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that Midjourney is used for creating the characters, but can it also make them talk or what\u2019s used for that?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/1bqcojPYZKQ\"&gt;https://youtu.be/1bqcojPYZKQ&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3l0OvDjzcJcXTYOV_UmIcoeHhDSlpIF7EYxC0_q6deM.jpg?auto=webp&amp;s=fca97aaf7b02c4f2dbccde3312c3586c7543c515", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/3l0OvDjzcJcXTYOV_UmIcoeHhDSlpIF7EYxC0_q6deM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a468564fe1f19800e1b34761ac6c7b5eae3377f", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/3l0OvDjzcJcXTYOV_UmIcoeHhDSlpIF7EYxC0_q6deM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4ac2036db4c1b97d46ab17e1f8f1536436877dd7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/3l0OvDjzcJcXTYOV_UmIcoeHhDSlpIF7EYxC0_q6deM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7619a981ee54215c449e8edce5a00c00bf4fbc4e", "width": 320, "height": 240}], "variants": {}, "id": "mHYR2ma_eU4sDe9BWS8cwBNgaEIfN4BnuHzUXdTD7dI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jftv3", "is_robot_indexable": true, "report_reasons": null, "author": "Xteoman", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jftv3/anyone_knows_whats_used_to_make_the_characters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jftv3/anyone_knows_whats_used_to_make_the_characters/", "subreddit_subscribers": 976713, "created_utc": 1691294817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a 3 years advanced diploma in automation and robotics(Electromechanical Eng) from a Canadian college. Working as a CNC machinist from last 2 years, decided to switch career. I\u2019m interested in data science but with no degree and zero experience,  no way getting into the field.Recently heard about WGU(from a Reddit post), researched a bit,but can\u2019t decide if its worth it? Am I going to get a job with an online degree? Do companies/employers even consider an online degree?\n\nI\u2019m a complete beginner and totally lost. Any advice or suggestions will be appreciated :)", "author_fullname": "t2_7aimqa6a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thinking of getting a degree from WGU.Is it worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jde2b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691287279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 3 years advanced diploma in automation and robotics(Electromechanical Eng) from a Canadian college. Working as a CNC machinist from last 2 years, decided to switch career. I\u2019m interested in data science but with no degree and zero experience,  no way getting into the field.Recently heard about WGU(from a Reddit post), researched a bit,but can\u2019t decide if its worth it? Am I going to get a job with an online degree? Do companies/employers even consider an online degree?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a complete beginner and totally lost. Any advice or suggestions will be appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jde2b", "is_robot_indexable": true, "report_reasons": null, "author": "krishasingh", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jde2b/thinking_of_getting_a_degree_from_wguis_it_worth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jde2b/thinking_of_getting_a_degree_from_wguis_it_worth/", "subreddit_subscribers": 976713, "created_utc": 1691287279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is the IBM data science certificate from coursera enough to start a career at data science?\nIf not what else should i study", "author_fullname": "t2_gvzoyi6ob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IBM data science certificate from coursera", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jaofo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691279547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is the IBM data science certificate from coursera enough to start a career at data science?\nIf not what else should i study&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jaofo", "is_robot_indexable": true, "report_reasons": null, "author": "Equivalent_Revenue59", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jaofo/ibm_data_science_certificate_from_coursera/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jaofo/ibm_data_science_certificate_from_coursera/", "subreddit_subscribers": 976713, "created_utc": 1691279547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Looking at a switch to DS. I do database programming now and feel perfectly comfortable most of the time. The thing that I'm struggling with is these concepts. \n\n&amp;#x200B;\n\nIf there were some test and I was asked to use dynamic programming to find the longest shared substring...I think I'd struggle. ", "author_fullname": "t2_5e9xna0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important are concepts like recursion/dynamic programming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15j7k5w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691271569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking at a switch to DS. I do database programming now and feel perfectly comfortable most of the time. The thing that I&amp;#39;m struggling with is these concepts. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If there were some test and I was asked to use dynamic programming to find the longest shared substring...I think I&amp;#39;d struggle. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15j7k5w", "is_robot_indexable": true, "report_reasons": null, "author": "royalconfetti5", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15j7k5w/how_important_are_concepts_like_recursiondynamic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15j7k5w/how_important_are_concepts_like_recursiondynamic/", "subreddit_subscribers": 976713, "created_utc": 1691271569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, \n \nMy friends and i created a app. I can\u2019t really go into detail exactly what it is because it hasn\u2019t officially launched yet. But we need people to do the final testing before launch. We need like 30-50 people. Is there a platform that allows us to get such services. Or any specific place of institution that helps with said things paid or free. Any help would be much appreciated.", "author_fullname": "t2_fe8234i81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Group testing for app 30-50 people needed for testing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15j2waj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691260071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, &lt;/p&gt;\n\n&lt;p&gt;My friends and i created a app. I can\u2019t really go into detail exactly what it is because it hasn\u2019t officially launched yet. But we need people to do the final testing before launch. We need like 30-50 people. Is there a platform that allows us to get such services. Or any specific place of institution that helps with said things paid or free. Any help would be much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15j2waj", "is_robot_indexable": true, "report_reasons": null, "author": "Pesusz", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15j2waj/group_testing_for_app_3050_people_needed_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15j2waj/group_testing_for_app_3050_people_needed_for/", "subreddit_subscribers": 976713, "created_utc": 1691260071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, \n \nMy friend and i created a app that is matching up people. We have tested it with about 3-5 people every time. Is there any platform or service we can hire to do a large group testing or is there other methods.", "author_fullname": "t2_fe8234i81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Group testing for app need around 30-50 people", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15j10ow", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691255359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, &lt;/p&gt;\n\n&lt;p&gt;My friend and i created a app that is matching up people. We have tested it with about 3-5 people every time. Is there any platform or service we can hire to do a large group testing or is there other methods.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15j10ow", "is_robot_indexable": true, "report_reasons": null, "author": "Pesusz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15j10ow/group_testing_for_app_need_around_3050_people/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15j10ow/group_testing_for_app_need_around_3050_people/", "subreddit_subscribers": 976713, "created_utc": 1691255359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I had 2 rounds of technical interviews (involved python, SQL and a take home). The third round is said to be a \u201cconsultant\u201d round. I did ask the recruiter what to expect in this round. The response was \u201cIt will not be technical and more about leadership skills, ability to handle clients, communication etc\u201d. How do I prepare for this (I think there is no prep as such for it as it could be very open) but any insights or suggestions would be greatly appreciated. Thank you.", "author_fullname": "t2_110183", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What can I expect for a consultant round in a Data Scientist interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jfok8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691294380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had 2 rounds of technical interviews (involved python, SQL and a take home). The third round is said to be a \u201cconsultant\u201d round. I did ask the recruiter what to expect in this round. The response was \u201cIt will not be technical and more about leadership skills, ability to handle clients, communication etc\u201d. How do I prepare for this (I think there is no prep as such for it as it could be very open) but any insights or suggestions would be greatly appreciated. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15jfok8", "is_robot_indexable": true, "report_reasons": null, "author": "leomatey", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15jfok8/what_can_i_expect_for_a_consultant_round_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15jfok8/what_can_i_expect_for_a_consultant_round_in_a/", "subreddit_subscribers": 976713, "created_utc": 1691294380.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}