{"kind": "Listing", "data": {"after": null, "dist": 15, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been blocked on the post, but OP is clearly running a sock puppet network as I detailed in (rapidly downvoted) comments in the post.", "author_fullname": "t2_30190", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Don't fall for the \"Data is Beautiful\" post with the mug. It is an ad. Mods, is there anything we can do about shit like this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15iu5ya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 117, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 117, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691237658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been blocked on the post, but OP is clearly running a sock puppet network as I detailed in (rapidly downvoted) comments in the post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15iu5ya", "is_robot_indexable": true, "report_reasons": null, "author": "mojitz", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iu5ya/dont_fall_for_the_data_is_beautiful_post_with_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iu5ya/dont_fall_for_the_data_is_beautiful_post_with_the/", "subreddit_subscribers": 120994, "created_utc": 1691237658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, \n\nI read about DuckDB from this subreddit and decided to give it a spin together with dbt. I think it is a blast and I am amazed at the speed of DuckDB. Currently, I am building a local data warehouse that is grabbing data from the open Danish parliament API, landing it in a folder, and then creating views in DuckDB to query. This could easily be shifted to the cloud but I love the simplicity of running it just in time when I would like to look at the data.\n\nI have so far designed one fact that tracks the process of voting, with dimensions on actors, cases, dates, meetings, and votes.\n\nI have yet to decide on an EL tool, and I would like to implement some delta loading and further build out the dimensional model. Furthermore, I am in doubt about a visualization tool as I use Power BI in my daily job, which is the go-to tool in Denmark for data.\n\nIt is still a work in progress, but I think it's great fun to build something on real-world data that is not company based. The project is open source and available here: [https://github.com/bgarcevic/danish-democracy-data](https://github.com/bgarcevic/danish-democracy-data)\n\nIf I ever go back to work as an analyst instead of data engineering I would start using DuckDB in my daily work. If anyone has feedback on how to improve the project, please feel free to chip in.", "author_fullname": "t2_1j8f19jc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Currently building a local data warehouse with dbt/DuckDB using real data from the danish parliament", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15iq5bk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1691224320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;I read about DuckDB from this subreddit and decided to give it a spin together with dbt. I think it is a blast and I am amazed at the speed of DuckDB. Currently, I am building a local data warehouse that is grabbing data from the open Danish parliament API, landing it in a folder, and then creating views in DuckDB to query. This could easily be shifted to the cloud but I love the simplicity of running it just in time when I would like to look at the data.&lt;/p&gt;\n\n&lt;p&gt;I have so far designed one fact that tracks the process of voting, with dimensions on actors, cases, dates, meetings, and votes.&lt;/p&gt;\n\n&lt;p&gt;I have yet to decide on an EL tool, and I would like to implement some delta loading and further build out the dimensional model. Furthermore, I am in doubt about a visualization tool as I use Power BI in my daily job, which is the go-to tool in Denmark for data.&lt;/p&gt;\n\n&lt;p&gt;It is still a work in progress, but I think it&amp;#39;s great fun to build something on real-world data that is not company based. The project is open source and available here: &lt;a href=\"https://github.com/bgarcevic/danish-democracy-data\"&gt;https://github.com/bgarcevic/danish-democracy-data&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If I ever go back to work as an analyst instead of data engineering I would start using DuckDB in my daily work. If anyone has feedback on how to improve the project, please feel free to chip in.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?auto=webp&amp;s=d440a9b03ad7be4bd8ccbab3eea98961d188954b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c7f75b61b4185c330bde2a091c8da5756fb83e2f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9989ad88c395bfe0f60169409451bf20647bdf2d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=66b2a7ade568849f387186e14a78e2664c25384d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bad7f84339e26933c09eef145d5fbf77e4811e56", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8b6d67b5f7ceb1276bbd892207792c85f11c9c45", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/cDQSNkLTYwyA0HCBjrq-aPG16wvkLpfLJuw4E-w9Aa0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c0bf07519000fee88d7ebee0b0ee08b465ff7a9e", "width": 1080, "height": 540}], "variants": {}, "id": "lKWf3uuaiZX6lRl11i9elQHtnYAFKgHicR3A0_a2wCs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "15iq5bk", "is_robot_indexable": true, "report_reasons": null, "author": "bgarcevic", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iq5bk/currently_building_a_local_data_warehouse_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iq5bk/currently_building_a_local_data_warehouse_with/", "subreddit_subscribers": 120994, "created_utc": 1691224320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a big distinction between data engineers and senior roles? \n\nIs it easier to look for senior roles rather than get promoted in the current company?\n\n&amp;#x200B;", "author_fullname": "t2_av88gzj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between Data engineer and Senior Data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15iqtrz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691226704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a big distinction between data engineers and senior roles? &lt;/p&gt;\n\n&lt;p&gt;Is it easier to look for senior roles rather than get promoted in the current company?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15iqtrz", "is_robot_indexable": true, "report_reasons": null, "author": "rdmcoloring", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iqtrz/difference_between_data_engineer_and_senior_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iqtrz/difference_between_data_engineer_and_senior_data/", "subreddit_subscribers": 120994, "created_utc": 1691226704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I just wanted to come on here to rant/ask for advice.\nI am a recent grad and got a sick job as a data engineer at a pretty large consulting company and I loved it at first, like I want to do this for the rest of my life. My colleagues are awesome, my bosses/managers are awesome. I am pretty good at what I do too, I\u2019ve had a few managers tell me that I\u2019m doing a great job and that I\u2019m a great dev, and I really feel fulfilled and valuable here. However, our client is terrible to us. They give us extremely unreasonable deadlines and are super impatient when it comes to development that would take some time - resulting in most of the backend engineers working up to 60 hrs per week for a few months. \nThis has resulted in a snowball effect where all of us are so burnt out and so our deliverables can\u2019t keep up with their big asks/deadlines, and I\u2019m not sure why the folks that communicate most with the client doesn\u2019t push back at all. I\u2019ve sat in a few of these client meetings and all they do is yell at us and complain about how long it takes to develop a very drastic change that would take a huge LOE.\nLast Friday I got assigned to basically redo a bunch of code that had taken weeks to develop (not by me) initially, and it was supposed to be released on that Thursday and I had no support and NONE of this was in writing or documented until Wednesday. I worked so hard on it, and worked from 8am-4am on Tuesday trying to get it out so we can test it. I got pulled into a big call w all of the managers on Thursday (after it was released) and basically got screamed at by a senior manager that talks to the client a bunch bc I was told to do something different, even though he was the one that confirmed with me that I understood the assignment on Tuesday. So he basically lied to everyone to make me seem incompetent. I started defending myself and he started yelling over me \u201cWHY IS SHE TALKING AND NOT A MANAGER?\u201d Luckily, one of the other senior managers stood up for me, saying that I was the one that developed the code and I should be speaking on this. And so I started crying bc I was so frustrated, sleep deprived, and couldn\u2019t hold back my tears anymore. My leads/managers reached out to me during and after the meeting assuring me it wasn\u2019t my fault and they know I did what I was asked to do. Luckily, we were able to redo it the next day, as I had a lot of support and clearly understood the assignment.\nI want to leave this project so bad, I\u2019m miserable, constantly anxious at work, and I don\u2019t have a life anymore. I also start grad school again in about a month and I have no idea how I am going to balance this with school, and job searching is really difficult when I don\u2019t have the time or the energy to do it, especially with only having under a year of experience. Also I would have to brush up on my Leetcode/data structures if I wanna start job searching again lol, which is possible but man I am just SO burnt out and I need to pay the bills, so I can\u2019t just take a break to job search (I am very much underpaid for a DE so I don\u2019t have a lot of savings). Or maybe I\u2019m just making up excuses and just need a push haha. What should I do?\n\nTLDR; I am underpaid, got yelled at for things that are not my fault, work up to 60 hours a week, and I have to go back to night school in less than a month and can\u2019t balance this like I used to before it got so bad. I just need advice on what I should do or how to find time to look for other jobs.", "author_fullname": "t2_5i0h4l3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Terrible work environment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15iwbtf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691243670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I just wanted to come on here to rant/ask for advice.\nI am a recent grad and got a sick job as a data engineer at a pretty large consulting company and I loved it at first, like I want to do this for the rest of my life. My colleagues are awesome, my bosses/managers are awesome. I am pretty good at what I do too, I\u2019ve had a few managers tell me that I\u2019m doing a great job and that I\u2019m a great dev, and I really feel fulfilled and valuable here. However, our client is terrible to us. They give us extremely unreasonable deadlines and are super impatient when it comes to development that would take some time - resulting in most of the backend engineers working up to 60 hrs per week for a few months. \nThis has resulted in a snowball effect where all of us are so burnt out and so our deliverables can\u2019t keep up with their big asks/deadlines, and I\u2019m not sure why the folks that communicate most with the client doesn\u2019t push back at all. I\u2019ve sat in a few of these client meetings and all they do is yell at us and complain about how long it takes to develop a very drastic change that would take a huge LOE.\nLast Friday I got assigned to basically redo a bunch of code that had taken weeks to develop (not by me) initially, and it was supposed to be released on that Thursday and I had no support and NONE of this was in writing or documented until Wednesday. I worked so hard on it, and worked from 8am-4am on Tuesday trying to get it out so we can test it. I got pulled into a big call w all of the managers on Thursday (after it was released) and basically got screamed at by a senior manager that talks to the client a bunch bc I was told to do something different, even though he was the one that confirmed with me that I understood the assignment on Tuesday. So he basically lied to everyone to make me seem incompetent. I started defending myself and he started yelling over me \u201cWHY IS SHE TALKING AND NOT A MANAGER?\u201d Luckily, one of the other senior managers stood up for me, saying that I was the one that developed the code and I should be speaking on this. And so I started crying bc I was so frustrated, sleep deprived, and couldn\u2019t hold back my tears anymore. My leads/managers reached out to me during and after the meeting assuring me it wasn\u2019t my fault and they know I did what I was asked to do. Luckily, we were able to redo it the next day, as I had a lot of support and clearly understood the assignment.\nI want to leave this project so bad, I\u2019m miserable, constantly anxious at work, and I don\u2019t have a life anymore. I also start grad school again in about a month and I have no idea how I am going to balance this with school, and job searching is really difficult when I don\u2019t have the time or the energy to do it, especially with only having under a year of experience. Also I would have to brush up on my Leetcode/data structures if I wanna start job searching again lol, which is possible but man I am just SO burnt out and I need to pay the bills, so I can\u2019t just take a break to job search (I am very much underpaid for a DE so I don\u2019t have a lot of savings). Or maybe I\u2019m just making up excuses and just need a push haha. What should I do?&lt;/p&gt;\n\n&lt;p&gt;TLDR; I am underpaid, got yelled at for things that are not my fault, work up to 60 hours a week, and I have to go back to night school in less than a month and can\u2019t balance this like I used to before it got so bad. I just need advice on what I should do or how to find time to look for other jobs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15iwbtf", "is_robot_indexable": true, "report_reasons": null, "author": "manwithenormouspeepe", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iwbtf/terrible_work_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iwbtf/terrible_work_environment/", "subreddit_subscribers": 120994, "created_utc": 1691243670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2rku02rf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Iceberg Crash Course for AWS users: Amazon S3, Athena &amp; AWS Glue \u2764\ufe0f Iceberg", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15j7wua", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1691272420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kestra.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://kestra.io/blogs/2023-08-05-iceberg-for-aws-users", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15j7wua", "is_robot_indexable": true, "report_reasons": null, "author": "tchiotludo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15j7wua/apache_iceberg_crash_course_for_aws_users_amazon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://kestra.io/blogs/2023-08-05-iceberg-for-aws-users", "subreddit_subscribers": 120994, "created_utc": 1691272420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All!  \nSince this a long question, I will organize it into topics as follows:\n\nBreathily explaining our architecture:   \nWe have a landing AWS s3 bucket that receives raw files from Airbyte, then using Trino we run some merge statements to promote and treat this data, converting the raw parquet files into iceberg tables (this is our cleansed layer).   \n\n\nMore context:   \nWe run several refreshes throughout the day, meaning we have thousands of small files and We are not using partitioning at the landing layer, so every merge statement from every table fully scans the landing layer before refreshing the cleansed layer.\n\nOur main problem:   \n**Costs!** We are paying around USD 150 every day **only for the get and put requests** on AWS S3.   \n\n\nMy proposed solution:  \nI'm wondering about partitioning our landing layer by the `_airbyte_emitted_at` date key, so that we will have a partition for each day and the merge operations will only scan these files instead of scanning all the old files.  \n\n\nMy question:  \nConsidering that my landing layer relies on a Hive Catalog and we orchestrate everything using Trino.  After Airbyte syncs the incremental data, I would run the following statement to update the Hive table's metadata:\n\n    call landing_catalog.system.sync_partition_metadata(\n        schema_name =&gt; '&lt;my schema&gt;',\n        table_name =&gt; '&lt;my table name&gt;',\n        mode =&gt; 'full'\n    );\n\n\nIs this `sync_partition_metadata` function as expensive as fully scanning the s3 bucket every time?  Considering that it probably scans all the folders and files for each one of the table....  \n\n\nOther comments about the architecture are also welcome!  \nThank you!", "author_fullname": "t2_ijp90vxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to save money with AWS S3 get and put requests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15iwlpd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691244369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All!&lt;br/&gt;\nSince this a long question, I will organize it into topics as follows:&lt;/p&gt;\n\n&lt;p&gt;Breathily explaining our architecture:&lt;br/&gt;\nWe have a landing AWS s3 bucket that receives raw files from Airbyte, then using Trino we run some merge statements to promote and treat this data, converting the raw parquet files into iceberg tables (this is our cleansed layer).   &lt;/p&gt;\n\n&lt;p&gt;More context:&lt;br/&gt;\nWe run several refreshes throughout the day, meaning we have thousands of small files and We are not using partitioning at the landing layer, so every merge statement from every table fully scans the landing layer before refreshing the cleansed layer.&lt;/p&gt;\n\n&lt;p&gt;Our main problem:&lt;br/&gt;\n&lt;strong&gt;Costs!&lt;/strong&gt; We are paying around USD 150 every day &lt;strong&gt;only for the get and put requests&lt;/strong&gt; on AWS S3.   &lt;/p&gt;\n\n&lt;p&gt;My proposed solution:&lt;br/&gt;\nI&amp;#39;m wondering about partitioning our landing layer by the &lt;code&gt;_airbyte_emitted_at&lt;/code&gt; date key, so that we will have a partition for each day and the merge operations will only scan these files instead of scanning all the old files.  &lt;/p&gt;\n\n&lt;p&gt;My question:&lt;br/&gt;\nConsidering that my landing layer relies on a Hive Catalog and we orchestrate everything using Trino.  After Airbyte syncs the incremental data, I would run the following statement to update the Hive table&amp;#39;s metadata:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;call landing_catalog.system.sync_partition_metadata(\n    schema_name =&amp;gt; &amp;#39;&amp;lt;my schema&amp;gt;&amp;#39;,\n    table_name =&amp;gt; &amp;#39;&amp;lt;my table name&amp;gt;&amp;#39;,\n    mode =&amp;gt; &amp;#39;full&amp;#39;\n);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Is this &lt;code&gt;sync_partition_metadata&lt;/code&gt; function as expensive as fully scanning the s3 bucket every time?  Considering that it probably scans all the folders and files for each one of the table....  &lt;/p&gt;\n\n&lt;p&gt;Other comments about the architecture are also welcome!&lt;br/&gt;\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15iwlpd", "is_robot_indexable": true, "report_reasons": null, "author": "CzarSantos98", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iwlpd/trying_to_save_money_with_aws_s3_get_and_put/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iwlpd/trying_to_save_money_with_aws_s3_get_and_put/", "subreddit_subscribers": 120994, "created_utc": 1691244369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need some advice on my use case. I have a table which has the list of assets in the organization and I am working on a project where we are required to compute a security score for all assets. The algorithm and parameters used for various asset types is different and I decided to create a staging table to compute the score and later join to the primary dim table to store the score. However I received push back during a review as this requires a separate pipeline and storage requirements. I wanted some advice on the approach I should use and pros and cons on these approaches. I feel merging these computations to the existing pipeline can make it complex. Can some who has worked on something similar share some advice on what the pro and con is for these approaches and why i should use one versus other.", "author_fullname": "t2_kb23rcjq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on creating a separate staging table versus computing in the same pipeline.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15io4u9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691217251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need some advice on my use case. I have a table which has the list of assets in the organization and I am working on a project where we are required to compute a security score for all assets. The algorithm and parameters used for various asset types is different and I decided to create a staging table to compute the score and later join to the primary dim table to store the score. However I received push back during a review as this requires a separate pipeline and storage requirements. I wanted some advice on the approach I should use and pros and cons on these approaches. I feel merging these computations to the existing pipeline can make it complex. Can some who has worked on something similar share some advice on what the pro and con is for these approaches and why i should use one versus other.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15io4u9", "is_robot_indexable": true, "report_reasons": null, "author": "SweetAbject2153", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15io4u9/advice_on_creating_a_separate_staging_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15io4u9/advice_on_creating_a_separate_staging_table/", "subreddit_subscribers": 120994, "created_utc": 1691217251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "(TLDR at bottom)\n\nA bit ago, I became part of an advanced analytics team within my company. However, I noticed that the team mostly consists of Software Engineers and Application Developers with limited expertise in analytics or data engineering, they didn't even know what Databricks was and are unfamiliar with basic data modelling/warehousing concepts.\n\nThe challenge I face is that the data engineering tasks, such as pipelining and ETL, are approached in a way that feels too much like traditional software engineering. It's like using a hammer to drive in a screw \u2013 it gets the job done, but it doesn't feel like the most appropriate approach. Instead of utilizing \"traditional\" data engineering tools for building and orchestrating pipelines, we rely on a more typical Software Engineering stack. \n\n**Some Background for your Understanding** \n\nWe have a primary ingestion pipeline that scans and retrieves JSON data from the landing area every minute. This pipeline then transforms the data into a parquet file and appends it to our data lake. Everything downstream from this ingestion pipeline are referred to as \"pipeline tasks\", which I am responsible for developing. These tasks are essentially Python-based Dockerized ETL applications. Even the ingestion pipeline is just an application running as a Docker Container with a parameter to execute every minute. Also, all applications are run on a Kubernetes Cluster.\n\nEach task has its own dedicated message queue. These queues receive notifications whenever new parquet files for specific tables are ingested through the primary ingestion pipeline. To facilitate this process, we store the \"routing information\" in an Azure table for each entity we ingest data for. The ingestion pipeline leverages this routing information to notify the respective queues for all downstream pipeline tasks. \n\n**My Issue**\n\nI have concerns about our current approach to developing the pipeline task applications. Currently, the development process involves working locally with the Azure SDK to read sample data from the data lake and develop the entire ETL python application on this sample of data. Once the application is \"developed,\" we build the Dockerfile and then push the code to a \"testing\" GitHub branch. Subsequently, a Docker image is created, and a container is built through a CI/CD pipeline. In the testing phase, we ingest some more sample data into the data lake and verify that the application processes the data correctly. Finally, the code is pushed to the main GitHub branch, and the CI/CD pipeline is used again to build the container for the production environment.\n\nI know it's common to run data engineering services in Docker, like airflow, but is what we are doing evening logical? Message queues, docker/kubernetes, CI/CD, dev/test/prod deployments - It all seems like application development, not data engineering. Therefore, the data engineering stuff I am doing seems very forced to me and I can't seem to get that point across to my manager or team members.\n\n**Secondary Issue?**\n\nAnother issue I have is that these pipeline tasks are independent from other tasks. We are not creating conformed dimensions with fact tables, like you'd see in traditional data modeling. We create independent data models (we call them data marts) that serve the purpose of a given project. These models are just in a \"data mart layer\" of the data lake with an Azure Serverless SQL Pool on top. Each \"mart\" is its own schema in the Serverless SQL Pool, and the schemas are completely independent from each other.\n\n**TLDR**\n\nI joined an analytics team with mostly Software Engineers and Application Developers, lacking knowledge in data engineering concepts. Our data engineering tasks are approached like traditional software development using a non-traditional stack. We have a primary ingestion pipeline and downstream tasks with dedicated message queues. However, I'm worried this setup isn't ideal for data engineering. The development process feels forced, requiring local development, Docker, CI/CD, and GitHub branching for staging, etc... I'm struggling to convince my manager and team that we should consider more appropriate data engineering practices. ", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL Pipelines as Software Applications?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jdao9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691286996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(TLDR at bottom)&lt;/p&gt;\n\n&lt;p&gt;A bit ago, I became part of an advanced analytics team within my company. However, I noticed that the team mostly consists of Software Engineers and Application Developers with limited expertise in analytics or data engineering, they didn&amp;#39;t even know what Databricks was and are unfamiliar with basic data modelling/warehousing concepts.&lt;/p&gt;\n\n&lt;p&gt;The challenge I face is that the data engineering tasks, such as pipelining and ETL, are approached in a way that feels too much like traditional software engineering. It&amp;#39;s like using a hammer to drive in a screw \u2013 it gets the job done, but it doesn&amp;#39;t feel like the most appropriate approach. Instead of utilizing &amp;quot;traditional&amp;quot; data engineering tools for building and orchestrating pipelines, we rely on a more typical Software Engineering stack. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Some Background for your Understanding&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;We have a primary ingestion pipeline that scans and retrieves JSON data from the landing area every minute. This pipeline then transforms the data into a parquet file and appends it to our data lake. Everything downstream from this ingestion pipeline are referred to as &amp;quot;pipeline tasks&amp;quot;, which I am responsible for developing. These tasks are essentially Python-based Dockerized ETL applications. Even the ingestion pipeline is just an application running as a Docker Container with a parameter to execute every minute. Also, all applications are run on a Kubernetes Cluster.&lt;/p&gt;\n\n&lt;p&gt;Each task has its own dedicated message queue. These queues receive notifications whenever new parquet files for specific tables are ingested through the primary ingestion pipeline. To facilitate this process, we store the &amp;quot;routing information&amp;quot; in an Azure table for each entity we ingest data for. The ingestion pipeline leverages this routing information to notify the respective queues for all downstream pipeline tasks. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My Issue&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have concerns about our current approach to developing the pipeline task applications. Currently, the development process involves working locally with the Azure SDK to read sample data from the data lake and develop the entire ETL python application on this sample of data. Once the application is &amp;quot;developed,&amp;quot; we build the Dockerfile and then push the code to a &amp;quot;testing&amp;quot; GitHub branch. Subsequently, a Docker image is created, and a container is built through a CI/CD pipeline. In the testing phase, we ingest some more sample data into the data lake and verify that the application processes the data correctly. Finally, the code is pushed to the main GitHub branch, and the CI/CD pipeline is used again to build the container for the production environment.&lt;/p&gt;\n\n&lt;p&gt;I know it&amp;#39;s common to run data engineering services in Docker, like airflow, but is what we are doing evening logical? Message queues, docker/kubernetes, CI/CD, dev/test/prod deployments - It all seems like application development, not data engineering. Therefore, the data engineering stuff I am doing seems very forced to me and I can&amp;#39;t seem to get that point across to my manager or team members.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Secondary Issue?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Another issue I have is that these pipeline tasks are independent from other tasks. We are not creating conformed dimensions with fact tables, like you&amp;#39;d see in traditional data modeling. We create independent data models (we call them data marts) that serve the purpose of a given project. These models are just in a &amp;quot;data mart layer&amp;quot; of the data lake with an Azure Serverless SQL Pool on top. Each &amp;quot;mart&amp;quot; is its own schema in the Serverless SQL Pool, and the schemas are completely independent from each other.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I joined an analytics team with mostly Software Engineers and Application Developers, lacking knowledge in data engineering concepts. Our data engineering tasks are approached like traditional software development using a non-traditional stack. We have a primary ingestion pipeline and downstream tasks with dedicated message queues. However, I&amp;#39;m worried this setup isn&amp;#39;t ideal for data engineering. The development process feels forced, requiring local development, Docker, CI/CD, and GitHub branching for staging, etc... I&amp;#39;m struggling to convince my manager and team that we should consider more appropriate data engineering practices. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jdao9", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jdao9/etl_pipelines_as_software_applications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jdao9/etl_pipelines_as_software_applications/", "subreddit_subscribers": 120994, "created_utc": 1691286996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone have xp with both alembic and dbt? I know the latter and like it. New team uses alembic for db migrations but it\u2019s morphed into the transformation tool too. \n\nI haven\u2019t used alembic but from light reading it strikes me as a bit outdated for anything other than db migrations. \n\nCan anyone validate that? Would using it for transformation be misuse?", "author_fullname": "t2_2tu8n7l9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alembic vs dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jah1g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691278988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have xp with both alembic and dbt? I know the latter and like it. New team uses alembic for db migrations but it\u2019s morphed into the transformation tool too. &lt;/p&gt;\n\n&lt;p&gt;I haven\u2019t used alembic but from light reading it strikes me as a bit outdated for anything other than db migrations. &lt;/p&gt;\n\n&lt;p&gt;Can anyone validate that? Would using it for transformation be misuse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15jah1g", "is_robot_indexable": true, "report_reasons": null, "author": "Firm_Bit", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jah1g/alembic_vs_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jah1g/alembic_vs_dbt/", "subreddit_subscribers": 120994, "created_utc": 1691278988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wanted to ask some experienced people here about what gave them the best return on investment. Will investing in my data engineering/interviewing skills be more fruitful or will  some freelancing/consulting on the side would be better?\n\nAnd if doing some freelancing/consulting for extra cash is better, what platforms do you guys use to find such opportunities?", "author_fullname": "t2_l35gwhuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Invest More in Day Job and Skills VS Investing In a Side Hustle?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15iz9jc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691251022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanted to ask some experienced people here about what gave them the best return on investment. Will investing in my data engineering/interviewing skills be more fruitful or will  some freelancing/consulting on the side would be better?&lt;/p&gt;\n\n&lt;p&gt;And if doing some freelancing/consulting for extra cash is better, what platforms do you guys use to find such opportunities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15iz9jc", "is_robot_indexable": true, "report_reasons": null, "author": "Senior_Anteater4688", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iz9jc/invest_more_in_day_job_and_skills_vs_investing_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iz9jc/invest_more_in_day_job_and_skills_vs_investing_in/", "subreddit_subscribers": 120994, "created_utc": 1691251022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey I'm totally new to data and I've just started my first portfolio project creating a python web scraper. Im wondering what is the best way to store the data I'm going to collect. Its a very small amount, something around 50 columns and 1300 rows. Each Row will also have an aprox 3000 word report associated with it.\n\nI'm totally in no-mans-land mystery continent territory right now. Do I write out my data to a csv file and put that into google sheets? How do I query that with python? How do I relate the reports with each row? Should I build my own SQL database for this instead (seems overkill no?)\n\nThanks for your time.", "author_fullname": "t2_381zkha4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "End-to-End Data Analysis Project Guidance: How to store my data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15jaa1b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691278455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey I&amp;#39;m totally new to data and I&amp;#39;ve just started my first portfolio project creating a python web scraper. Im wondering what is the best way to store the data I&amp;#39;m going to collect. Its a very small amount, something around 50 columns and 1300 rows. Each Row will also have an aprox 3000 word report associated with it.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m totally in no-mans-land mystery continent territory right now. Do I write out my data to a csv file and put that into google sheets? How do I query that with python? How do I relate the reports with each row? Should I build my own SQL database for this instead (seems overkill no?)&lt;/p&gt;\n\n&lt;p&gt;Thanks for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15jaa1b", "is_robot_indexable": true, "report_reasons": null, "author": "bigjungus11", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15jaa1b/endtoend_data_analysis_project_guidance_how_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15jaa1b/endtoend_data_analysis_project_guidance_how_to/", "subreddit_subscribers": 120994, "created_utc": 1691278455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, i'm currently following this [course](https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/), and i'm wondering if Pig is still used in industry because in jobs offer (at least in France) they never mention Pig only Hive\n\nTy", "author_fullname": "t2_w54e628x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Apache Pig used in industry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15iyfjx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691248953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, i&amp;#39;m currently following this &lt;a href=\"https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/\"&gt;course&lt;/a&gt;, and i&amp;#39;m wondering if Pig is still used in industry because in jobs offer (at least in France) they never mention Pig only Hive&lt;/p&gt;\n\n&lt;p&gt;Ty&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15iyfjx", "is_robot_indexable": true, "report_reasons": null, "author": "rxmi_bkd_", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15iyfjx/is_apache_pig_used_in_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15iyfjx/is_apache_pig_used_in_industry/", "subreddit_subscribers": 120994, "created_utc": 1691248953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I posted to this reddit a week ago and it got removed (not sure why as it was a genuine \"where to start\" kind of post. Hopefully this one does not get removed.)\n\n&amp;#x200B;\n\nI have been self teaching myself SQL (via SQLBOLT, brain is currently mush trying to understand LEFT JOIN clause) for the last week with zero coding skills prior (Economics major and have worked in Finance Analyst for last 7 years) and wanted to know how I can use SQL in my current position to get me ready for becoming a Data Analyst in 2 years (end goal is to become a Data Engineer but I understand I would need some experience in data in order to make that big of a jump, hence DA first then DE in my roadmap)\n\nI work in excel a sh\\*t ton so maybe I can start there if possible to use SQL in excel? Just wanted some input from those on the \"inside\" on what I can do in order to become proficient in SQL in my current function before attempting to jump over to a DA role. Studying SQL on the side is obviously going to help, but I want to also try and use what I am studying in my current role to further solidify what I am learning. \n\n&amp;#x200B;\n\nSELECT How To\n\nFROM Help", "author_fullname": "t2_22q9pua0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How To utilize SQL in current job to get ready for next step? (pls dont remove this post)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ix0ey", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691245638.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691245408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I posted to this reddit a week ago and it got removed (not sure why as it was a genuine &amp;quot;where to start&amp;quot; kind of post. Hopefully this one does not get removed.)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have been self teaching myself SQL (via SQLBOLT, brain is currently mush trying to understand LEFT JOIN clause) for the last week with zero coding skills prior (Economics major and have worked in Finance Analyst for last 7 years) and wanted to know how I can use SQL in my current position to get me ready for becoming a Data Analyst in 2 years (end goal is to become a Data Engineer but I understand I would need some experience in data in order to make that big of a jump, hence DA first then DE in my roadmap)&lt;/p&gt;\n\n&lt;p&gt;I work in excel a sh*t ton so maybe I can start there if possible to use SQL in excel? Just wanted some input from those on the &amp;quot;inside&amp;quot; on what I can do in order to become proficient in SQL in my current function before attempting to jump over to a DA role. Studying SQL on the side is obviously going to help, but I want to also try and use what I am studying in my current role to further solidify what I am learning. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;SELECT How To&lt;/p&gt;\n\n&lt;p&gt;FROM Help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ix0ey", "is_robot_indexable": true, "report_reasons": null, "author": "PoloParachutes", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ix0ey/how_to_utilize_sql_in_current_job_to_get_ready/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ix0ey/how_to_utilize_sql_in_current_job_to_get_ready/", "subreddit_subscribers": 120994, "created_utc": 1691245408.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data engineer with 6+ years of experience. We have built pipelines to bring data into our warehouse. Now my manager says \"now that we have brought in a lot of data, lets analyze it to find if we can provide the company with some insights on the data.\" Shouldn't this be the other way round where we know what we are looking for?\nShould i start transitioning into a data analyst? If yes, what are the ways to get started?", "author_fullname": "t2_eobyj34v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Conundrum", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ioiih", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691218620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data engineer with 6+ years of experience. We have built pipelines to bring data into our warehouse. Now my manager says &amp;quot;now that we have brought in a lot of data, lets analyze it to find if we can provide the company with some insights on the data.&amp;quot; Shouldn&amp;#39;t this be the other way round where we know what we are looking for?\nShould i start transitioning into a data analyst? If yes, what are the ways to get started?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ioiih", "is_robot_indexable": true, "report_reasons": null, "author": "Stoic_Akshay", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ioiih/conundrum/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ioiih/conundrum/", "subreddit_subscribers": 120994, "created_utc": 1691218620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\\-deleted-", "author_fullname": "t2_a9ij7ckc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BI engineer interview question - Feedback please", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15imc1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691292321.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691211255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;-deleted-&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15imc1q", "is_robot_indexable": true, "report_reasons": null, "author": "thriftyberry", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15imc1q/bi_engineer_interview_question_feedback_please/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15imc1q/bi_engineer_interview_question_feedback_please/", "subreddit_subscribers": 120994, "created_utc": 1691211255.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}