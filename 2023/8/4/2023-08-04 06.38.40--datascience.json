{"kind": "Listing", "data": {"after": "t3_15hg8s3", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_81zrh19oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you think of this book", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15hc04a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 238, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 238, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YLmGb9LQ26of7dcS23OMo8H3H_qce1hNuL0Bb7zgXGY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691087613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/kni8xfcpvxfb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/kni8xfcpvxfb1.jpg?auto=webp&amp;s=c78b50a496a1f63f4fe6fb4a9cd9f076fada8145", "width": 483, "height": 634}, "resolutions": [{"url": "https://preview.redd.it/kni8xfcpvxfb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=256e5450e46ff8d6146a3be40b8f497f041c6080", "width": 108, "height": 141}, {"url": "https://preview.redd.it/kni8xfcpvxfb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=47191a099b47efe0a9489a3a98558d7006c6e121", "width": 216, "height": 283}, {"url": "https://preview.redd.it/kni8xfcpvxfb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=673a4268975dc8a86fcd02097f6d2fd5dccc68b3", "width": 320, "height": 420}], "variants": {}, "id": "Kk5_umePsmsZoA0JdfpOxctUMJv7Z-r0gVQahq6CsFA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15hc04a", "is_robot_indexable": true, "report_reasons": null, "author": "Careful_Engineer_700", "discussion_type": null, "num_comments": 109, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15hc04a/what_do_you_think_of_this_book/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/kni8xfcpvxfb1.jpg", "subreddit_subscribers": 973786, "created_utc": 1691087613.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi people of reddit,\n\nI have been looking for a job as a Data Scientist for the last year or so. In the meantime, I have been taking up some freelance work and classes on the side (dataquest, datacamp) to improve my skills.\n\nFor context, I am a Mathematician, and graduated from my Ph.D. a few years back. I finished my post-doc last August. I know how to write code in R, SQL and Python, and I am confident (most of the time) in my ability to learn. I am very familiar with statistical concepts (although I did not specialise in it) and I have exposure to ML algorithms. Over the last year or so, I have applied for over 500 roles, getting into \\~50 interviews. In the end, I got exactly 2 offers, one of which I accepted a few days ago.\n\nI have to say that this last year has been crappy (to say the least). Every company boasts about its inclusivity plan, which (don't get me wrong) is very much needed. However, my point here is that people with a background in academia are generally, and from my own experience, not included at all.\n\nSome doctorate programmes have seminars that aim to ease the hypothetical transition to the industry, while, in truth it should be the other way around. As a former academic, I do not seek favourable treatment, not at all (and if I come off as such, it is a mistake that is solely on me). I do not expect people to rely on the fact that I have degrees and hire me immediately. I understand that it's a \"tough market\" and a \"numbers' game\". I just have to say that it feels that all the weight is put on work experience, while in truth it is perhaps an overrated characteristic.\n\nI should not have to prove my ability to learn, adapt and apply. I should not have to prove my ability to mentally keep up with all kidns of hardship, from day one, all the way to graduation. I should not have to prove how adaptable and resilient people from academia are. I should not have to prove my ability to juggle dozens of responsibilities, all at once; nor my capacity to manage time, under a constant schedule made of deadlines. Are those not important anymore? Are those not crucial elements, honed through years of work experience?\n\nEmployers seem to care more about people using software A, rather software B and that's all it takes to get your application rejected. And here I am, thinking that they'd care about problem-solving (the big picture).\n\nIMHO, I should not get rejected because I do not have 3 years of experience for a junior data analyst position (true story).\n\nTo finish up, I was lucky, finding a job, even after 1 year of search. Excuse the emotional take; I am genuinely curious to see if more people see my point of view.\n\nCheers.\n\nEDIT: Wow! I never expected to have 100 comments to read/reply to. Hence, I feel obliged to provide a few clarification points:\n\n* I read quite a few valuable comments, and, to the people that took time to write them, thanks!\n* I want to say that, sincerely, I do not think that my PhD alone makes me better than other candidates. I even highlighted that take in my post. Naturally, I do feel I need to prove my worth, I know that. It is something that traditionally comes after 1-2 interviews, maybe in the form of a take-home task, or live coding session. What is the main point of my rant, is that my \"success rate\", defining \"success\" as \"invited for an interview\" is \\~1%, which, to me, is absurd.\n* Kudos to u/dfphd for expressing myself better than I did:  \"*why is it that hiring managers assume that someone with regular work experience has these attributes, while not giving someone in academia the same credit?*\" is the main question I have.", "author_fullname": "t2_3ldy6dkw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job offer (mini rant)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15h58oo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691106385.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691071613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi people of reddit,&lt;/p&gt;\n\n&lt;p&gt;I have been looking for a job as a Data Scientist for the last year or so. In the meantime, I have been taking up some freelance work and classes on the side (dataquest, datacamp) to improve my skills.&lt;/p&gt;\n\n&lt;p&gt;For context, I am a Mathematician, and graduated from my Ph.D. a few years back. I finished my post-doc last August. I know how to write code in R, SQL and Python, and I am confident (most of the time) in my ability to learn. I am very familiar with statistical concepts (although I did not specialise in it) and I have exposure to ML algorithms. Over the last year or so, I have applied for over 500 roles, getting into ~50 interviews. In the end, I got exactly 2 offers, one of which I accepted a few days ago.&lt;/p&gt;\n\n&lt;p&gt;I have to say that this last year has been crappy (to say the least). Every company boasts about its inclusivity plan, which (don&amp;#39;t get me wrong) is very much needed. However, my point here is that people with a background in academia are generally, and from my own experience, not included at all.&lt;/p&gt;\n\n&lt;p&gt;Some doctorate programmes have seminars that aim to ease the hypothetical transition to the industry, while, in truth it should be the other way around. As a former academic, I do not seek favourable treatment, not at all (and if I come off as such, it is a mistake that is solely on me). I do not expect people to rely on the fact that I have degrees and hire me immediately. I understand that it&amp;#39;s a &amp;quot;tough market&amp;quot; and a &amp;quot;numbers&amp;#39; game&amp;quot;. I just have to say that it feels that all the weight is put on work experience, while in truth it is perhaps an overrated characteristic.&lt;/p&gt;\n\n&lt;p&gt;I should not have to prove my ability to learn, adapt and apply. I should not have to prove my ability to mentally keep up with all kidns of hardship, from day one, all the way to graduation. I should not have to prove how adaptable and resilient people from academia are. I should not have to prove my ability to juggle dozens of responsibilities, all at once; nor my capacity to manage time, under a constant schedule made of deadlines. Are those not important anymore? Are those not crucial elements, honed through years of work experience?&lt;/p&gt;\n\n&lt;p&gt;Employers seem to care more about people using software A, rather software B and that&amp;#39;s all it takes to get your application rejected. And here I am, thinking that they&amp;#39;d care about problem-solving (the big picture).&lt;/p&gt;\n\n&lt;p&gt;IMHO, I should not get rejected because I do not have 3 years of experience for a junior data analyst position (true story).&lt;/p&gt;\n\n&lt;p&gt;To finish up, I was lucky, finding a job, even after 1 year of search. Excuse the emotional take; I am genuinely curious to see if more people see my point of view.&lt;/p&gt;\n\n&lt;p&gt;Cheers.&lt;/p&gt;\n\n&lt;p&gt;EDIT: Wow! I never expected to have 100 comments to read/reply to. Hence, I feel obliged to provide a few clarification points:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I read quite a few valuable comments, and, to the people that took time to write them, thanks!&lt;/li&gt;\n&lt;li&gt;I want to say that, sincerely, I do not think that my PhD alone makes me better than other candidates. I even highlighted that take in my post. Naturally, I do feel I need to prove my worth, I know that. It is something that traditionally comes after 1-2 interviews, maybe in the form of a take-home task, or live coding session. What is the main point of my rant, is that my &amp;quot;success rate&amp;quot;, defining &amp;quot;success&amp;quot; as &amp;quot;invited for an interview&amp;quot; is ~1%, which, to me, is absurd.&lt;/li&gt;\n&lt;li&gt;Kudos to &lt;a href=\"/u/dfphd\"&gt;u/dfphd&lt;/a&gt; for expressing myself better than I did:  &amp;quot;&lt;em&gt;why is it that hiring managers assume that someone with regular work experience has these attributes, while not giving someone in academia the same credit?&lt;/em&gt;&amp;quot; is the main question I have.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15h58oo", "is_robot_indexable": true, "report_reasons": null, "author": "Drahmaputras", "discussion_type": null, "num_comments": 111, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15h58oo/job_offer_mini_rant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15h58oo/job_offer_mini_rant/", "subreddit_subscribers": 973786, "created_utc": 1691071613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Meta recently released an open-source library that can produce realistic audio and music from text descriptions. Did anyone try running this? Would love to hear about the experience.\n\nIs there any other library you used for audio gen?   \nLink to the GitHub: [https://github.com/facebookresearch/audiocraft](https://github.com/facebookresearch/audiocraft)  \nLink to the Paper: [https://arxiv.org/abs/2209.15352](https://arxiv.org/abs/2209.15352)", "author_fullname": "t2_4y306umt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meta released AudioCraft: generative AI for audio/music generation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15h8b1u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691078716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Meta recently released an open-source library that can produce realistic audio and music from text descriptions. Did anyone try running this? Would love to hear about the experience.&lt;/p&gt;\n\n&lt;p&gt;Is there any other library you used for audio gen?&lt;br/&gt;\nLink to the GitHub: &lt;a href=\"https://github.com/facebookresearch/audiocraft\"&gt;https://github.com/facebookresearch/audiocraft&lt;/a&gt;&lt;br/&gt;\nLink to the Paper: &lt;a href=\"https://arxiv.org/abs/2209.15352\"&gt;https://arxiv.org/abs/2209.15352&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15h8b1u", "is_robot_indexable": true, "report_reasons": null, "author": "AsDivyansh", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15h8b1u/meta_released_audiocraft_generative_ai_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15h8b1u/meta_released_audiocraft_generative_ai_for/", "subreddit_subscribers": 973786, "created_utc": 1691078716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_120afq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyzing Coffee with Data Science + ChatGPT Code Interpreter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15h41ka", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jrw3fuupSpEdi7cXk_b46ekR3ZDG2IxrfkIKFbCmDwE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691068689.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "briansunter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://briansunter.com/pages/newsletter/issue-13", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HtWEfwL_7mIrlVy-bIN2PzJX4VOTIsqKEi6IaUBLUw8.jpg?auto=webp&amp;s=310070e43a19048060a7f4d2cc094d2fe2f1a070", "width": 800, "height": 1228}, "resolutions": [{"url": "https://external-preview.redd.it/HtWEfwL_7mIrlVy-bIN2PzJX4VOTIsqKEi6IaUBLUw8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1963211c11f2d0fa63960dc202f9f61016e99e02", "width": 108, "height": 165}, {"url": "https://external-preview.redd.it/HtWEfwL_7mIrlVy-bIN2PzJX4VOTIsqKEi6IaUBLUw8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c1f2915bc4fce6fb4bab118902ed3b5dec01a9ae", "width": 216, "height": 331}, {"url": "https://external-preview.redd.it/HtWEfwL_7mIrlVy-bIN2PzJX4VOTIsqKEi6IaUBLUw8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e36d2ddbdf5f8ac2959ecc74af1107dc407d4924", "width": 320, "height": 491}, {"url": "https://external-preview.redd.it/HtWEfwL_7mIrlVy-bIN2PzJX4VOTIsqKEi6IaUBLUw8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9a51a60dd5c27dd594952efa91a2f3fddbb1c0b0", "width": 640, "height": 982}], "variants": {}, "id": "NYP_7m1XEYWLIbMU91vgewdLXaU3gJHGAeYA1psGzAc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15h41ka", "is_robot_indexable": true, "report_reasons": null, "author": "debordian", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15h41ka/analyzing_coffee_with_data_science_chatgpt_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://briansunter.com/pages/newsletter/issue-13", "subreddit_subscribers": 973786, "created_utc": 1691068689.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am one of those who is not thrilled by the regular trite questions on the sub that has either already been answered or is better suited to be posted on the pinned thread.\n\nHowever, it's got me thinking , how many of us regulars actually get involved in the weekly pinned threads ? \n\nIt might be helpful if we kept them slightly more engaging so that more people are encouraged to participate in the more happening thread.", "author_fullname": "t2_mloui", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meta - pinned post and regular participants", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15hhbkq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691099731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am one of those who is not thrilled by the regular trite questions on the sub that has either already been answered or is better suited to be posted on the pinned thread.&lt;/p&gt;\n\n&lt;p&gt;However, it&amp;#39;s got me thinking , how many of us regulars actually get involved in the weekly pinned threads ? &lt;/p&gt;\n\n&lt;p&gt;It might be helpful if we kept them slightly more engaging so that more people are encouraged to participate in the more happening thread.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15hhbkq", "is_robot_indexable": true, "report_reasons": null, "author": "Asshaisin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15hhbkq/meta_pinned_post_and_regular_participants/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15hhbkq/meta_pinned_post_and_regular_participants/", "subreddit_subscribers": 973786, "created_utc": 1691099731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[Mito](https://github.com/mito-ds/mito) is a spreadsheet drop-in replacement for `st.dataframe` or `st.data_editor`. Mito allows you to view and edit dataframes with spreadsheet formulas, pivot tables, graphs, and much more. For every edit you make, Mito generates Python code that corresponds to the edit.\n\nAdd Mito to your Streamlit app with these [steps](https://docs.trymito.io/mito-for-streamlit/getting-started) :)\n\nHere is a sample [app](https://mito-data-cleaning-demo.streamlit.app/) with the spreadsheet inside.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/s8z4isomcyfb1.jpg?width=2718&amp;format=pjpg&amp;auto=webp&amp;s=d5c51dee90fb156135810cd7fe7dde5b441f304d", "author_fullname": "t2_7vpi3es9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interactive Spreadsheets inside Streamlit Apps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "media_metadata": {"s8z4isomcyfb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/s8z4isomcyfb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dd3520a35d06ce8a7bbc9f1bae74a71db1a133f0"}, {"y": 117, "x": 216, "u": "https://preview.redd.it/s8z4isomcyfb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=18fee8c09cbad8805818cd8ebd0a88580751e725"}, {"y": 174, "x": 320, "u": "https://preview.redd.it/s8z4isomcyfb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cdc0208941ae320c82fad4ad961b492911c79dc9"}, {"y": 349, "x": 640, "u": "https://preview.redd.it/s8z4isomcyfb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f598e06ad25e012ff891d2ac9e85e2417daf5228"}, {"y": 524, "x": 960, "u": "https://preview.redd.it/s8z4isomcyfb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=df1a900a4fb09067416cb826f0a97a773f2b5c5f"}, {"y": 589, "x": 1080, "u": "https://preview.redd.it/s8z4isomcyfb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=58bb4ba351cc3653c3e3634298fdc208af025767"}], "s": {"y": 1484, "x": 2718, "u": "https://preview.redd.it/s8z4isomcyfb1.jpg?width=2718&amp;format=pjpg&amp;auto=webp&amp;s=d5c51dee90fb156135810cd7fe7dde5b441f304d"}, "id": "s8z4isomcyfb1"}}, "name": "t3_15hehoq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Ts7vmpRjDCnSC2bFxJlXtfNeFG-MoERLsCmZkQ6k0GI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691093324.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/mito-ds/mito\"&gt;Mito&lt;/a&gt; is a spreadsheet drop-in replacement for &lt;code&gt;st.dataframe&lt;/code&gt; or &lt;code&gt;st.data_editor&lt;/code&gt;. Mito allows you to view and edit dataframes with spreadsheet formulas, pivot tables, graphs, and much more. For every edit you make, Mito generates Python code that corresponds to the edit.&lt;/p&gt;\n\n&lt;p&gt;Add Mito to your Streamlit app with these &lt;a href=\"https://docs.trymito.io/mito-for-streamlit/getting-started\"&gt;steps&lt;/a&gt; :)&lt;/p&gt;\n\n&lt;p&gt;Here is a sample &lt;a href=\"https://mito-data-cleaning-demo.streamlit.app/\"&gt;app&lt;/a&gt; with the spreadsheet inside.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/s8z4isomcyfb1.jpg?width=2718&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d5c51dee90fb156135810cd7fe7dde5b441f304d\"&gt;https://preview.redd.it/s8z4isomcyfb1.jpg?width=2718&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d5c51dee90fb156135810cd7fe7dde5b441f304d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15hehoq", "is_robot_indexable": true, "report_reasons": null, "author": "Jake_Stack808", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15hehoq/interactive_spreadsheets_inside_streamlit_apps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15hehoq/interactive_spreadsheets_inside_streamlit_apps/", "subreddit_subscribers": 973786, "created_utc": 1691093324.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Why it matters to data science:**\nData cleaning is an integral part to data science workflows and data scientists/analysts are often the \"consumers\" this article is talking about (even if the title didn't exist back then). Learning how to talk about data quality can empower you to make better requests from upstream sources that impact your work.\n\n-----\n\nI recently had to define data quality for a chapter in the book I'm writing. A big piece of writing this content is understanding where these terms came from and the context they sit in. One of the pioneers of this space is Dr.Richard Wang and his work based out in MIT.\n\nUpon talking to other data quality experts, it was highly recommended I read his most cited article *Beyond Accuracy: What Data Quality Means to Data Consumers* where Dr. Diane Strong was the co-author.\n\nAttached is a PDF link to the document from MIT. I found it super interesting and played a huge part in the section I'm writing.", "author_fullname": "t2_v7fvlqc8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm co-authoring a book on data quality. This paper came up multiple times in my research.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15hd59r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1691090226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mitiq.mit.edu", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Why it matters to data science:&lt;/strong&gt;\nData cleaning is an integral part to data science workflows and data scientists/analysts are often the &amp;quot;consumers&amp;quot; this article is talking about (even if the title didn&amp;#39;t exist back then). Learning how to talk about data quality can empower you to make better requests from upstream sources that impact your work.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;I recently had to define data quality for a chapter in the book I&amp;#39;m writing. A big piece of writing this content is understanding where these terms came from and the context they sit in. One of the pioneers of this space is Dr.Richard Wang and his work based out in MIT.&lt;/p&gt;\n\n&lt;p&gt;Upon talking to other data quality experts, it was highly recommended I read his most cited article &lt;em&gt;Beyond Accuracy: What Data Quality Means to Data Consumers&lt;/em&gt; where Dr. Diane Strong was the co-author.&lt;/p&gt;\n\n&lt;p&gt;Attached is a PDF link to the document from MIT. I found it super interesting and played a huge part in the section I&amp;#39;m writing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "http://mitiq.mit.edu/documents/publications/tdqmpub/14_beyond_accuracy.pdf", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15hd59r", "is_robot_indexable": true, "report_reasons": null, "author": "on_the_mark_data", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15hd59r/im_coauthoring_a_book_on_data_quality_this_paper/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "http://mitiq.mit.edu/documents/publications/tdqmpub/14_beyond_accuracy.pdf", "subreddit_subscribers": 973786, "created_utc": 1691090226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Seeing the number of applicants on a job posting is a pretty big factor in whether or not I apply for a job, at least for me. If a job already has hundreds or over 1k applicants, I won't bother crafting my resume and cover letter. I usually assume that a recruiter already has the number of applications they're looking for at that point. But it's extremely confusing when LinkedIn says that there could be **9** or **634** people applying. Does anyone know what's actually accurate here? Has anyone been seeing this kind of thing on LinkedIn?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/kx846m3t9yfb1.png?width=489&amp;format=png&amp;auto=webp&amp;s=eb48f16806165d0e9a3e8bffc2520de2797d581f", "author_fullname": "t2_f9vvf5nan", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is up with LinkedIn's applicant counting system? How can there be such a massive discrepancy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"kx846m3t9yfb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/kx846m3t9yfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fef525c5b8ee4fdaa33e63bb38fa7de13e8ddaea"}, {"y": 108, "x": 216, "u": "https://preview.redd.it/kx846m3t9yfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7475f902a0cd1fb937f800f09a3f6087e6647cdf"}, {"y": 160, "x": 320, "u": "https://preview.redd.it/kx846m3t9yfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=09373896afa068e86867b63be730cf66cb8aa81f"}], "s": {"y": 245, "x": 489, "u": "https://preview.redd.it/kx846m3t9yfb1.png?width=489&amp;format=png&amp;auto=webp&amp;s=eb48f16806165d0e9a3e8bffc2520de2797d581f"}, "id": "kx846m3t9yfb1"}}, "name": "t3_15he532", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/19hbBOl3LK7b_S2-Vp7WOrQp6E_SjJwN0ktBSNLkAc8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691092530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seeing the number of applicants on a job posting is a pretty big factor in whether or not I apply for a job, at least for me. If a job already has hundreds or over 1k applicants, I won&amp;#39;t bother crafting my resume and cover letter. I usually assume that a recruiter already has the number of applications they&amp;#39;re looking for at that point. But it&amp;#39;s extremely confusing when LinkedIn says that there could be &lt;strong&gt;9&lt;/strong&gt; or &lt;strong&gt;634&lt;/strong&gt; people applying. Does anyone know what&amp;#39;s actually accurate here? Has anyone been seeing this kind of thing on LinkedIn?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/kx846m3t9yfb1.png?width=489&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eb48f16806165d0e9a3e8bffc2520de2797d581f\"&gt;https://preview.redd.it/kx846m3t9yfb1.png?width=489&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eb48f16806165d0e9a3e8bffc2520de2797d581f&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15he532", "is_robot_indexable": true, "report_reasons": null, "author": "MoonBug-5013", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15he532/what_is_up_with_linkedins_applicant_counting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15he532/what_is_up_with_linkedins_applicant_counting/", "subreddit_subscribers": 973786, "created_utc": 1691092530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\ni\u2019m about to finish college (studying stats) and have been thinking about careers. Basically i was talking to some people recently that worked in nonprofits and government. I just was wondering if there were jobs that I could help people and use data for social causes etc. Is this idea completely unrealistic/jobs don\u2019t exist / not gonna be able to afford to live w shit income. I just wanna hear the reality and understand if these types of opportunities exist.", "author_fullname": "t2_87dbo3n7v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jobs that have a social impact", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gyug5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691053533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\ni\u2019m about to finish college (studying stats) and have been thinking about careers. Basically i was talking to some people recently that worked in nonprofits and government. I just was wondering if there were jobs that I could help people and use data for social causes etc. Is this idea completely unrealistic/jobs don\u2019t exist / not gonna be able to afford to live w shit income. I just wanna hear the reality and understand if these types of opportunities exist.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15gyug5", "is_robot_indexable": true, "report_reasons": null, "author": "conscious_tiger04", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15gyug5/jobs_that_have_a_social_impact/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15gyug5/jobs_that_have_a_social_impact/", "subreddit_subscribers": 973786, "created_utc": 1691053533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently pursuing a MS in Data Science, I graduated in winter 2021 with a Bachelors in economics. I've had three years of experience as a broker in the financial services industry while also doing part time data analyst work for a family consulting business. I've done countless courses and am pretty comfortable with most of the data science stack, and a fair bit of projects from course work I have on github that I share when I apply. But literally what the hell does it take to get an entry level job in this field, I've applied to hundreds of jobs with either auto rejections or no replies, I've tried messaging recruiters directly via LinkedIn/email with even less success, the rare times I'm contacted by recruiters I get ghost ed after a week, usually before I'm even asked to do any kind of assessment. Where am I going wrong or what could I do better? I'm at the point where I'm asking myself if it's even worth finishing this MS if I have so little opportunity.", "author_fullname": "t2_9ftvf6z8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difficulty getting entry level jobs in the field", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15h9thc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691082491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently pursuing a MS in Data Science, I graduated in winter 2021 with a Bachelors in economics. I&amp;#39;ve had three years of experience as a broker in the financial services industry while also doing part time data analyst work for a family consulting business. I&amp;#39;ve done countless courses and am pretty comfortable with most of the data science stack, and a fair bit of projects from course work I have on github that I share when I apply. But literally what the hell does it take to get an entry level job in this field, I&amp;#39;ve applied to hundreds of jobs with either auto rejections or no replies, I&amp;#39;ve tried messaging recruiters directly via LinkedIn/email with even less success, the rare times I&amp;#39;m contacted by recruiters I get ghost ed after a week, usually before I&amp;#39;m even asked to do any kind of assessment. Where am I going wrong or what could I do better? I&amp;#39;m at the point where I&amp;#39;m asking myself if it&amp;#39;s even worth finishing this MS if I have so little opportunity.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15h9thc", "is_robot_indexable": true, "report_reasons": null, "author": "Minute_Scientist2780", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15h9thc/difficulty_getting_entry_level_jobs_in_the_field/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15h9thc/difficulty_getting_entry_level_jobs_in_the_field/", "subreddit_subscribers": 973786, "created_utc": 1691082491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a large data set (12,388,912 by  84). Say each row represents an individual customer, with location info (state, and county) and an important associated dollar amount. For part of my project, I need to know, for one specific state, how many customers there are below a certain dollar amount threshold for each location (.  It is important that this number is as accurate as possible as it will be used in some other calculations later. \n\nThe problem is I am missing a lot of location data. Initially, I had about **26% of rows** missing county data. I was able to get that down to about 6%, using some other variables to figure out the needed location data. For the **remaining 6%**, I'm debating what I should do. \n\n&amp;#x200B;\n\nI have considered **just dropping them**, but comparing summary stats for the missing group to the complete group, I see that they have very different Means and STD for the important $ amount (which, I believe, suggests that the data are not randomly missing, so dropping them may introduce bias). \n\nI also considered trying to do a **weighted imputation**. Each row has a weight associated with it, representing the number of other people this row theoretically represents. I thought I could try weighting location data by this person-weight and then imputing location values according to this.\n\nAny advice? How would you more seasoned DS people proceed. I am on a time crunch (I need to present this tomorrow morning) and I am doing this on my personal laptop, so computation speed is an issue.\n\n&amp;#x200B;\n\n(Don't hate. I know this is a fairly simple problem but I am still learning the ropes in my new job. ). \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_a7hjy38v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you deal with these missing values??? (under time crunch)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15h6mk6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691074860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a large data set (12,388,912 by  84). Say each row represents an individual customer, with location info (state, and county) and an important associated dollar amount. For part of my project, I need to know, for one specific state, how many customers there are below a certain dollar amount threshold for each location (.  It is important that this number is as accurate as possible as it will be used in some other calculations later. &lt;/p&gt;\n\n&lt;p&gt;The problem is I am missing a lot of location data. Initially, I had about &lt;strong&gt;26% of rows&lt;/strong&gt; missing county data. I was able to get that down to about 6%, using some other variables to figure out the needed location data. For the &lt;strong&gt;remaining 6%&lt;/strong&gt;, I&amp;#39;m debating what I should do. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have considered &lt;strong&gt;just dropping them&lt;/strong&gt;, but comparing summary stats for the missing group to the complete group, I see that they have very different Means and STD for the important $ amount (which, I believe, suggests that the data are not randomly missing, so dropping them may introduce bias). &lt;/p&gt;\n\n&lt;p&gt;I also considered trying to do a &lt;strong&gt;weighted imputation&lt;/strong&gt;. Each row has a weight associated with it, representing the number of other people this row theoretically represents. I thought I could try weighting location data by this person-weight and then imputing location values according to this.&lt;/p&gt;\n\n&lt;p&gt;Any advice? How would you more seasoned DS people proceed. I am on a time crunch (I need to present this tomorrow morning) and I am doing this on my personal laptop, so computation speed is an issue.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(Don&amp;#39;t hate. I know this is a fairly simple problem but I am still learning the ropes in my new job. ). &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15h6mk6", "is_robot_indexable": true, "report_reasons": null, "author": "Local_Order6899", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15h6mk6/how_would_you_deal_with_these_missing_values/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15h6mk6/how_would_you_deal_with_these_missing_values/", "subreddit_subscribers": 973786, "created_utc": 1691074860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I had an idea for a project tracking and comparing trends in savings account yield rates. Does anyone know where I might be able to source this data from? I can't seem to find rate history info directly on a bank website", "author_fullname": "t2_4k72lgwz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data for Savings Account yield rates by bank", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15hawqn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691085066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had an idea for a project tracking and comparing trends in savings account yield rates. Does anyone know where I might be able to source this data from? I can&amp;#39;t seem to find rate history info directly on a bank website&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15hawqn", "is_robot_indexable": true, "report_reasons": null, "author": "Thoughtful_Giraffe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15hawqn/data_for_savings_account_yield_rates_by_bank/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15hawqn/data_for_savings_account_yield_rates_by_bank/", "subreddit_subscribers": 973786, "created_utc": 1691085066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I transitioned recently from being Dentist(10yrs) to Data Science space! It\u2019s been 7months as a Data Scientist in a good health care based company. As of now, apart from building the tables, stats, and some regressions, I\u2019ve not got into real ML intricacies. But which is in line in coming months. Could you all experienced and no so experienced Data Scientists or in Data Space, advise me on what fronts I need to better myself. I aspire to be an ML engineer in the next year or so. I\u2019ve not had any exposure on NLP side. However, fair bit experience on Deep Learning(neural Networks)? Also, as a Data Scientist, what soft engineering skills I should master. Thank you.", "author_fullname": "t2_5twywu79s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Growing as Data Scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15h8ury", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691080209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I transitioned recently from being Dentist(10yrs) to Data Science space! It\u2019s been 7months as a Data Scientist in a good health care based company. As of now, apart from building the tables, stats, and some regressions, I\u2019ve not got into real ML intricacies. But which is in line in coming months. Could you all experienced and no so experienced Data Scientists or in Data Space, advise me on what fronts I need to better myself. I aspire to be an ML engineer in the next year or so. I\u2019ve not had any exposure on NLP side. However, fair bit experience on Deep Learning(neural Networks)? Also, as a Data Scientist, what soft engineering skills I should master. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15h8ury", "is_robot_indexable": true, "report_reasons": null, "author": "Ornery_Tumbleweed_98", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15h8ury/growing_as_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15h8ury/growing_as_data_scientist/", "subreddit_subscribers": 973786, "created_utc": 1691080209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Perhaps not belonging here, but I'll still try. \n\nFor my undergrad dissertation I'm conducting a small research which ended up becoming a data science(ish) project in the field of psychology. The bulk of the research is to predict some user's characteristics through classification methods.\n\nResults ended up being a little bit too unrealistic (e.g. AUC = 0.99, avg f-1 score = 0.96), leading me to think that I must've done something wrong.\n\nNow, assuming results are correct, how would you communicate such findings ? How much should I raise skeptical concerns ? It's kind of difficult to me to communicate this without either sounding like \"that's completely meaningless\" or \"this research is fire \ud83d\ude0e\ud83d\ude0e\"\n\nAlso, what would you suggest me to check that could potentially lead to such metrics erroneously ? \n\n&amp;#x200B;", "author_fullname": "t2_4r49gk33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to communicate unrealistic results ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15h0jua", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691059114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Perhaps not belonging here, but I&amp;#39;ll still try. &lt;/p&gt;\n\n&lt;p&gt;For my undergrad dissertation I&amp;#39;m conducting a small research which ended up becoming a data science(ish) project in the field of psychology. The bulk of the research is to predict some user&amp;#39;s characteristics through classification methods.&lt;/p&gt;\n\n&lt;p&gt;Results ended up being a little bit too unrealistic (e.g. AUC = 0.99, avg f-1 score = 0.96), leading me to think that I must&amp;#39;ve done something wrong.&lt;/p&gt;\n\n&lt;p&gt;Now, assuming results are correct, how would you communicate such findings ? How much should I raise skeptical concerns ? It&amp;#39;s kind of difficult to me to communicate this without either sounding like &amp;quot;that&amp;#39;s completely meaningless&amp;quot; or &amp;quot;this research is fire \ud83d\ude0e\ud83d\ude0e&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Also, what would you suggest me to check that could potentially lead to such metrics erroneously ? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15h0jua", "is_robot_indexable": true, "report_reasons": null, "author": "assassinatoSC2", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15h0jua/how_to_communicate_unrealistic_results/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15h0jua/how_to_communicate_unrealistic_results/", "subreddit_subscribers": 973786, "created_utc": 1691059114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a very primitive question: applying data augmentation on fmri preprocessed data (functional connectivity features), how would I designate the labels if I apply random cropping for example, knowing that I will be dropping out some important connectivity info through cropping it doesnt seem right to label it the same as the original.", "author_fullname": "t2_7x03dc86", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Augmentation on Neuroimages", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gw41e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691044051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a very primitive question: applying data augmentation on fmri preprocessed data (functional connectivity features), how would I designate the labels if I apply random cropping for example, knowing that I will be dropping out some important connectivity info through cropping it doesnt seem right to label it the same as the original.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15gw41e", "is_robot_indexable": true, "report_reasons": null, "author": "adamrayan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15gw41e/data_augmentation_on_neuroimages/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15gw41e/data_augmentation_on_neuroimages/", "subreddit_subscribers": 973786, "created_utc": 1691044051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is creating anki cards from hands-on machine learning by aurelien geron as I read it a waste of time? Or would doing the book alone better?", "author_fullname": "t2_5lys2h23", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Create Anki cards from this book", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15hnn3w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dY5Tzg46pwNVz1hxjpn281XH6TyVFAaLD1GMuAR0hZc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691116277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is creating anki cards from hands-on machine learning by aurelien geron as I read it a waste of time? Or would doing the book alone better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/qc863eqx80gb1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/qc863eqx80gb1.png?auto=webp&amp;s=dd6d36bc447f270c7a0232bae34c52300ef737b8", "width": 483, "height": 684}, "resolutions": [{"url": "https://preview.redd.it/qc863eqx80gb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=95ad09a7d86a9b61808865f29723e6b24a7014ec", "width": 108, "height": 152}, {"url": "https://preview.redd.it/qc863eqx80gb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0f46e760d14089a4b5bcc7280b9f6f4d4526b9fa", "width": 216, "height": 305}, {"url": "https://preview.redd.it/qc863eqx80gb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f2031d7741750e664d94465b9cee59496ece1cd", "width": 320, "height": 453}], "variants": {}, "id": "3c9XTwecG5os39armOLfiCkmWIWTEkavUh1cX0lp-YE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15hnn3w", "is_robot_indexable": true, "report_reasons": null, "author": "nthnlmo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15hnn3w/create_anki_cards_from_this_book/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/qc863eqx80gb1.png", "subreddit_subscribers": 973786, "created_utc": 1691116277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working on trying to learn the basics and maybe intermediate in forecasting with power bi, excel, or anything else that's free. I see there's a book in the resources of this sub, but are there any courses, guides, or blog recommendations that I can also utilize?", "author_fullname": "t2_us2ir6c8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips on learning forecasting tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15hh9h2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691099592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on trying to learn the basics and maybe intermediate in forecasting with power bi, excel, or anything else that&amp;#39;s free. I see there&amp;#39;s a book in the resources of this sub, but are there any courses, guides, or blog recommendations that I can also utilize?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15hh9h2", "is_robot_indexable": true, "report_reasons": null, "author": "ChasingPacing2022", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15hh9h2/tips_on_learning_forecasting_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15hh9h2/tips_on_learning_forecasting_tools/", "subreddit_subscribers": 973786, "created_utc": 1691099592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All, \n\nI am currently looking for a dataset or a place to obtain this dataset. I seek:\n\n\\- Data on football/soccer teams at the midway point of their seasons. \n\n\\- As much team statistics at this midpoint of their season for the last 20+ seasons. \n\n\\- I would also like this data on as many leagues as is possible \n\nAny help on how to find this data would be amazing. Thanks.", "author_fullname": "t2_dq3lw0bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "*** Data Search ***", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15hcprr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691089275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, &lt;/p&gt;\n\n&lt;p&gt;I am currently looking for a dataset or a place to obtain this dataset. I seek:&lt;/p&gt;\n\n&lt;p&gt;- Data on football/soccer teams at the midway point of their seasons. &lt;/p&gt;\n\n&lt;p&gt;- As much team statistics at this midpoint of their season for the last 20+ seasons. &lt;/p&gt;\n\n&lt;p&gt;- I would also like this data on as many leagues as is possible &lt;/p&gt;\n\n&lt;p&gt;Any help on how to find this data would be amazing. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15hcprr", "is_robot_indexable": true, "report_reasons": null, "author": "Omorelo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15hcprr/data_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15hcprr/data_search/", "subreddit_subscribers": 973786, "created_utc": 1691089275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My work has tasked me to work on excel files to be moved to a modern storage system where they can be accessed, worked on, and exported in excel format when needed. to give a quick background, the files we have are in XLSX format in local drive and they are all linked with each other with calculations.\n\nI have read through some articles earlier and Azure Data Factory seems to be that option for me, but I am not aware if it\u2019s possible to input the new data manually into the existent data sheet on ADF. The final stage is to do visualization with Tableau after the data is processed.\n\nDo you guys think Azure Data Factory is the right approach for this or is there anything else I could do resolve this?\n\n ", "author_fullname": "t2_3cpobabd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data migration from legacy systems - help me before I get the axe.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15h82uy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691078210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My work has tasked me to work on excel files to be moved to a modern storage system where they can be accessed, worked on, and exported in excel format when needed. to give a quick background, the files we have are in XLSX format in local drive and they are all linked with each other with calculations.&lt;/p&gt;\n\n&lt;p&gt;I have read through some articles earlier and Azure Data Factory seems to be that option for me, but I am not aware if it\u2019s possible to input the new data manually into the existent data sheet on ADF. The final stage is to do visualization with Tableau after the data is processed.&lt;/p&gt;\n\n&lt;p&gt;Do you guys think Azure Data Factory is the right approach for this or is there anything else I could do resolve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15h82uy", "is_robot_indexable": true, "report_reasons": null, "author": "shanke_y8", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15h82uy/data_migration_from_legacy_systems_help_me_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15h82uy/data_migration_from_legacy_systems_help_me_before/", "subreddit_subscribers": 973786, "created_utc": 1691078210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm an internal strategy consultant at a large conglomerate that recently launched a B2C FMCG. We've had a massive B2B food products business for many years. \n\nI have transaction level data in excel format for every transaction done YTD (7 months worth of data with about 100k rows). This dataset tells us customer by outlet and company, quantities, gross and net sales value, unit prices, location, returns, salesman, etc. \n\nUsing this data I've created a PBI dashboard that shows some key KPIs and othe descriptive analytics (e.g. OTIF, MTD sales vs target, etc.) \n\nI have now been requested by Senior Management to Incorporate predictive analytics for 2 key areas: 1) Sales Forecasting and 2) Demand planning\n\nI'm not sure where to begin or what tools to use.\n\nFor 1), I know we can do simple regression but this won't be accurate. I've looked at multivariable regression that Incorporates SARIMA (for seasonality) but not sure if this would be accurate and how if even do this. \n\nFor 2) I was wondering if predictive models exist that we can run our data through and they can output expected demand. \n\nWould appreciate any guidance or help on this!", "author_fullname": "t2_r3v90a8g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predictive Analytics for CPG?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15h63zz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691073669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an internal strategy consultant at a large conglomerate that recently launched a B2C FMCG. We&amp;#39;ve had a massive B2B food products business for many years. &lt;/p&gt;\n\n&lt;p&gt;I have transaction level data in excel format for every transaction done YTD (7 months worth of data with about 100k rows). This dataset tells us customer by outlet and company, quantities, gross and net sales value, unit prices, location, returns, salesman, etc. &lt;/p&gt;\n\n&lt;p&gt;Using this data I&amp;#39;ve created a PBI dashboard that shows some key KPIs and othe descriptive analytics (e.g. OTIF, MTD sales vs target, etc.) &lt;/p&gt;\n\n&lt;p&gt;I have now been requested by Senior Management to Incorporate predictive analytics for 2 key areas: 1) Sales Forecasting and 2) Demand planning&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure where to begin or what tools to use.&lt;/p&gt;\n\n&lt;p&gt;For 1), I know we can do simple regression but this won&amp;#39;t be accurate. I&amp;#39;ve looked at multivariable regression that Incorporates SARIMA (for seasonality) but not sure if this would be accurate and how if even do this. &lt;/p&gt;\n\n&lt;p&gt;For 2) I was wondering if predictive models exist that we can run our data through and they can output expected demand. &lt;/p&gt;\n\n&lt;p&gt;Would appreciate any guidance or help on this!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15h63zz", "is_robot_indexable": true, "report_reasons": null, "author": "throaway5401", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15h63zz/predictive_analytics_for_cpg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15h63zz/predictive_analytics_for_cpg/", "subreddit_subscribers": 973786, "created_utc": 1691073669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI\u2019m currently a master\u2019s degree student in Business Analytics and Big Data, and I\u2019m doing an internship in IIoT consulting.\n\nI\u2019m looking to transition into Data Analysis or even better, Data Science, as that is my area of specialization in my studies. Although I have no prior experience in the field, I do have 8 months of sales experience and a 3-month project management internship. Currently, I'm involved in a 6-month IIoT consulting internship.\n\nAs part of my portfolio, I'm working on a project related to the real estate market in my home country's city. I'm scraping data from web pages (currently 5, so 5 spiders) and performing all the ETL (Extract, Transform, Load) processes to use the data for creating visualizations and generating insights. My ultimate goal is to develop a web app that allows people to determine home prices based on their location within the city. However, since I don't have enough data at the moment, I'll be focusing on presenting the available data.\n\nWhile on vacation, I plan to utilize AWS Lambda to run my scripts and store everything in AWS S3, automating the entire data pipeline.\n\nI plan to put on my web page a general \u201chow\u201d I did the project and the technologies used in it\n\nMy question is, would this project alone be sufficient to present on my web page, or should I also include some smaller Kaggle projects?\n\nI understand that this project covers a variety of areas, including Data Engineering, Data Science, and Data Analysis, but I'm unsure if having only one project in my portfolio is enough.", "author_fullname": "t2_bzkl24up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Portfolio suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15h5hmg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691072208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently a master\u2019s degree student in Business Analytics and Big Data, and I\u2019m doing an internship in IIoT consulting.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking to transition into Data Analysis or even better, Data Science, as that is my area of specialization in my studies. Although I have no prior experience in the field, I do have 8 months of sales experience and a 3-month project management internship. Currently, I&amp;#39;m involved in a 6-month IIoT consulting internship.&lt;/p&gt;\n\n&lt;p&gt;As part of my portfolio, I&amp;#39;m working on a project related to the real estate market in my home country&amp;#39;s city. I&amp;#39;m scraping data from web pages (currently 5, so 5 spiders) and performing all the ETL (Extract, Transform, Load) processes to use the data for creating visualizations and generating insights. My ultimate goal is to develop a web app that allows people to determine home prices based on their location within the city. However, since I don&amp;#39;t have enough data at the moment, I&amp;#39;ll be focusing on presenting the available data.&lt;/p&gt;\n\n&lt;p&gt;While on vacation, I plan to utilize AWS Lambda to run my scripts and store everything in AWS S3, automating the entire data pipeline.&lt;/p&gt;\n\n&lt;p&gt;I plan to put on my web page a general \u201chow\u201d I did the project and the technologies used in it&lt;/p&gt;\n\n&lt;p&gt;My question is, would this project alone be sufficient to present on my web page, or should I also include some smaller Kaggle projects?&lt;/p&gt;\n\n&lt;p&gt;I understand that this project covers a variety of areas, including Data Engineering, Data Science, and Data Analysis, but I&amp;#39;m unsure if having only one project in my portfolio is enough.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15h5hmg", "is_robot_indexable": true, "report_reasons": null, "author": "_CT-5555_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15h5hmg/portfolio_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15h5hmg/portfolio_suggestions/", "subreddit_subscribers": 973786, "created_utc": 1691072208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_3mo78b0r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "3D Rendering of Population Spike Troubleshooting (pic1): Image Texture (pic2) washed out? Not sure how else to visualize population density using color", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"84bcdgw6jvfb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/84bcdgw6jvfb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=706f2d2ab6f534eaa6174c255dede2944eecbf78"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/84bcdgw6jvfb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=34c58317333b662e4808d53186190e61f26773d9"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/84bcdgw6jvfb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=10ba1360d4400a6f88b5730a14b844b9bfbe6d1d"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/84bcdgw6jvfb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5a45e65331352b9499d48a9fd7af0cb9c752249"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/84bcdgw6jvfb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cf4044237ce541c209fc3b76f5fde4bb41c1847c"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/84bcdgw6jvfb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=241dd54d0cf88f04ee73049231340d1486664ab7"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/84bcdgw6jvfb1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=482b709d0c1db5d6022998c3238861ed7f44bf6b"}, "id": "84bcdgw6jvfb1"}, "xmgfo1njjvfb1": {"status": "failed"}}, "name": "t3_15h0uju", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "84bcdgw6jvfb1", "id": 310405881}, {"media_id": "xmgfo1njjvfb1", "id": 310405882}]}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/V1qduHRwib_ppVs9VcSZrgnmVYq6TZmsqXFN9tl3qhc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691060038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/15h0uju", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "15h0uju", "is_robot_indexable": true, "report_reasons": null, "author": "j___8", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15h0uju/3d_rendering_of_population_spike_troubleshooting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/15h0uju", "subreddit_subscribers": 973786, "created_utc": 1691060038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Reddit. I'm working on a daily, short-term forecast which already works reasonably well using simple methods like ETS. My problem is that I need to incorporate some strong effects with yearly seasonality but daily precision. Think about sales of a product that start to rise some weeks before Christmas and then suddenly drop to nearly zero at the holiday. I need to model that sudden drop which can vary significantly from one time series to the next (ed.: forgot to mention: there is a large number of similar ts to forecast). Next problem: I may only have a single previous year of historical data.\n\nMy only idea so far is to use a maximum likelihood fit to fit shapes like my \"Christmas sawtooth\" to the previous year and use that as a component in the forecast. For the case the behaviour in the new year is different, I could continuously update the estimated strength of the effect when new data comes in.\n\nHowever, that's very homebrew and I wonder if anyone has a better idea. Yearly seasonalities with daily data seem to be problematic anyway but all methods I found so far assume at least data from several seasons.\n\nThanks", "author_fullname": "t2_kguv0t9a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series: \"One shot learning\" of seasonal effects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gyopv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1691053620.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691052991.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Reddit. I&amp;#39;m working on a daily, short-term forecast which already works reasonably well using simple methods like ETS. My problem is that I need to incorporate some strong effects with yearly seasonality but daily precision. Think about sales of a product that start to rise some weeks before Christmas and then suddenly drop to nearly zero at the holiday. I need to model that sudden drop which can vary significantly from one time series to the next (ed.: forgot to mention: there is a large number of similar ts to forecast). Next problem: I may only have a single previous year of historical data.&lt;/p&gt;\n\n&lt;p&gt;My only idea so far is to use a maximum likelihood fit to fit shapes like my &amp;quot;Christmas sawtooth&amp;quot; to the previous year and use that as a component in the forecast. For the case the behaviour in the new year is different, I could continuously update the estimated strength of the effect when new data comes in.&lt;/p&gt;\n\n&lt;p&gt;However, that&amp;#39;s very homebrew and I wonder if anyone has a better idea. Yearly seasonalities with daily data seem to be problematic anyway but all methods I found so far assume at least data from several seasons.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15gyopv", "is_robot_indexable": true, "report_reasons": null, "author": "JPyoris", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15gyopv/time_series_one_shot_learning_of_seasonal_effects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15gyopv/time_series_one_shot_learning_of_seasonal_effects/", "subreddit_subscribers": 973786, "created_utc": 1691052991.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So i was exploring a dataset of wages with different variables and on plotting its pairs plot I got some plots which I am unable to understand can someone explain what these plots are and how does one interpret them?\n\nhttps://preview.redd.it/hk9xsblcnufb1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=ec695f01142e36b1beee9b320232202885c0f0e2", "author_fullname": "t2_vt5r7wi2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what type of plot is this and how to interpret it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hk9xsblcnufb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/hk9xsblcnufb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8944a9047a68cdd9a1717376ad02a096f1a33037"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/hk9xsblcnufb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=efa01c57c8d93dabc14883e8af94503706ac2871"}, {"y": 196, "x": 320, "u": "https://preview.redd.it/hk9xsblcnufb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c7114d0e2e473278800ddf8472c9e4d1d97c87bf"}, {"y": 393, "x": 640, "u": "https://preview.redd.it/hk9xsblcnufb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f4238707cb05cbe6c6abcdc7da68a1a66f173cd5"}, {"y": 590, "x": 960, "u": "https://preview.redd.it/hk9xsblcnufb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a549dbf647816cd372e78b3709ad0f7219fc6d9"}], "s": {"y": 615, "x": 1000, "u": "https://preview.redd.it/hk9xsblcnufb1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=ec695f01142e36b1beee9b320232202885c0f0e2"}, "id": "hk9xsblcnufb1"}}, "name": "t3_15gxffq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/9hnYYhblRezzAnpnPnRtmm7QRZ-AVDGtFYcomR7sBX4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691048629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i was exploring a dataset of wages with different variables and on plotting its pairs plot I got some plots which I am unable to understand can someone explain what these plots are and how does one interpret them?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hk9xsblcnufb1.png?width=1000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec695f01142e36b1beee9b320232202885c0f0e2\"&gt;https://preview.redd.it/hk9xsblcnufb1.png?width=1000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec695f01142e36b1beee9b320232202885c0f0e2&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15gxffq", "is_robot_indexable": true, "report_reasons": null, "author": "Additional_Guide5439", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15gxffq/what_type_of_plot_is_this_and_how_to_interpret_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15gxffq/what_type_of_plot_is_this_and_how_to_interpret_it/", "subreddit_subscribers": 973786, "created_utc": 1691048629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As a SPSS- and Statistics-Newbie I have following question which I couldn't find in any book or website:\nTo analyze different influences on survival times, I calculated the factors both univariately and multivariately by Cox regression analysis. One factor, for example, factor A, had a non-significant value in the univariate analysis, but a highly significant value in the multivariate analysis. Is this plausible? Can this occur in this way? Factor B was significant in the univariate analysis, but not in the multivariate analysis.\nIn general, how can I understand multivariate Cox regression analysis?\nThank you so much for your support!", "author_fullname": "t2_bmbaptws1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question to Cox-Regression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15hg8s3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691097267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a SPSS- and Statistics-Newbie I have following question which I couldn&amp;#39;t find in any book or website:\nTo analyze different influences on survival times, I calculated the factors both univariately and multivariately by Cox regression analysis. One factor, for example, factor A, had a non-significant value in the univariate analysis, but a highly significant value in the multivariate analysis. Is this plausible? Can this occur in this way? Factor B was significant in the univariate analysis, but not in the multivariate analysis.\nIn general, how can I understand multivariate Cox regression analysis?\nThank you so much for your support!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15hg8s3", "is_robot_indexable": true, "report_reasons": null, "author": "MajorPractical6256", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15hg8s3/question_to_coxregression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15hg8s3/question_to_coxregression/", "subreddit_subscribers": 973786, "created_utc": 1691097267.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}