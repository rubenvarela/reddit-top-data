{"kind": "Listing", "data": {"after": "t3_164jr1i", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It is so incredibly frustrating and disrespectful to ghost candidates after multiple rounds and especially when the on-site interviews are 4-5 hours long. I lost an entire day to this, and they can't even be bothered to call or email me to let you know yes or no?  I am at a loss for words how just incredibly inconsiderate it is to treat people like this.", "author_fullname": "t2_bf28c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ghosted after On-Site Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_163rtk4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 203, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 203, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693242691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It is so incredibly frustrating and disrespectful to ghost candidates after multiple rounds and especially when the on-site interviews are 4-5 hours long. I lost an entire day to this, and they can&amp;#39;t even be bothered to call or email me to let you know yes or no?  I am at a loss for words how just incredibly inconsiderate it is to treat people like this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "163rtk4", "is_robot_indexable": true, "report_reasons": null, "author": "aleph-w", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/163rtk4/ghosted_after_onsite_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/163rtk4/ghosted_after_onsite_interview/", "subreddit_subscribers": 1020298, "created_utc": 1693242691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I completed school back in May for datasci at a top 20 university, projects and internships. I've been having a hard time finding a role. \n\nMy parents see news about chatgpt, expect that AI/ML &amp; DS are booming, and are dumbfounded that I can't get companies to be clambering for my so-called in-demand skills. I wish I could get them to understand its not that simple. They guilt me as an idiot who wasted money to go to school.\n\n I sometimes wish this upsurge about AI news never went mainstream (or rather, a year later) if it could mean the hype would be weaponized to guilt me.", "author_fullname": "t2_abnu12cen", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parents annoyed that I'm not hyping myself enough", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1649elx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 131, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 131, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693288153.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693286651.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I completed school back in May for datasci at a top 20 university, projects and internships. I&amp;#39;ve been having a hard time finding a role. &lt;/p&gt;\n\n&lt;p&gt;My parents see news about chatgpt, expect that AI/ML &amp;amp; DS are booming, and are dumbfounded that I can&amp;#39;t get companies to be clambering for my so-called in-demand skills. I wish I could get them to understand its not that simple. They guilt me as an idiot who wasted money to go to school.&lt;/p&gt;\n\n&lt;p&gt;I sometimes wish this upsurge about AI news never went mainstream (or rather, a year later) if it could mean the hype would be weaponized to guilt me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1649elx", "is_robot_indexable": true, "report_reasons": null, "author": "newauthry", "discussion_type": null, "num_comments": 79, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1649elx/parents_annoyed_that_im_not_hyping_myself_enough/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1649elx/parents_annoyed_that_im_not_hyping_myself_enough/", "subreddit_subscribers": 1020298, "created_utc": 1693286651.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everybody, I came here in the search for wisdom. This is my situation \nI\u2019ve been working as a data scientist for the past 3 years for two different consulting companies, while I can\u2019t say that I hate it, I am definitely not passionate about it.\nI think a good data scientist should find pleasure in finding answers for business questions as well as learning about the most recent models and their applications. Honestly, I can\u2019t be bother to do any of those things, I just don\u2019t have that much interest to be better at my job. Call me lazy or mediocre but it is what it is.\nOn the other hand I do find creating data pipelines, managing data bases,\u2026\u2026. Fairly cool. Needless to say I am planning on switching career paths and become a Data Engineer. \nHow would you approach HR on this matter without sending the message that you would just be an OK data engineer. I want to tell them that I could be a good DE, that it suits me better.\n\nAnyway thanks for any advice or experience that you guys have for sharing.", "author_fullname": "t2_mnei30rr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switching to Data Engineering because I don\u2019t like DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_163rkk0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 67, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 67, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693244227.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693242131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody, I came here in the search for wisdom. This is my situation \nI\u2019ve been working as a data scientist for the past 3 years for two different consulting companies, while I can\u2019t say that I hate it, I am definitely not passionate about it.\nI think a good data scientist should find pleasure in finding answers for business questions as well as learning about the most recent models and their applications. Honestly, I can\u2019t be bother to do any of those things, I just don\u2019t have that much interest to be better at my job. Call me lazy or mediocre but it is what it is.\nOn the other hand I do find creating data pipelines, managing data bases,\u2026\u2026. Fairly cool. Needless to say I am planning on switching career paths and become a Data Engineer. \nHow would you approach HR on this matter without sending the message that you would just be an OK data engineer. I want to tell them that I could be a good DE, that it suits me better.&lt;/p&gt;\n\n&lt;p&gt;Anyway thanks for any advice or experience that you guys have for sharing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "163rkk0", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Scratch3295", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/163rkk0/switching_to_data_engineering_because_i_dont_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/163rkk0/switching_to_data_engineering_because_i_dont_like/", "subreddit_subscribers": 1020298, "created_utc": 1693242131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What must someone work on in data science, ml and ai to make the most wealth in next 10 years? And yes I am not talking about job roles or something, I am talking about specific niche or some kind of project!", "author_fullname": "t2_ceg3slvl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does the most wealth in Data Science or AI lie in?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164aib9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693291539.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693290375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What must someone work on in data science, ml and ai to make the most wealth in next 10 years? And yes I am not talking about job roles or something, I am talking about specific niche or some kind of project!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "164aib9", "is_robot_indexable": true, "report_reasons": null, "author": "Dogemuskelon", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/164aib9/where_does_the_most_wealth_in_data_science_or_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/164aib9/where_does_the_most_wealth_in_data_science_or_ai/", "subreddit_subscribers": 1020298, "created_utc": 1693290375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I have been working in Analytics since close to 3 years for now. There was this company which I was targeting since quite some time and I applied to a relevant position and fortunately I landed an interview (after applying to numerous other positions).\n\nTechnical test went well, technical interview went well too. Was asked questions on multiple things and I got most of them right and few close.\n\nAfter a long time, interview felt like a discussion than an interrogation. It was all good but then couple of days later they say I have been rejected......\n\nI know this happens most of the times to almost everyone and no big deal, but it's becoming difficult to let this rejection go and start preparing again as both position and company looked like a perfect fit for my career. \n\nAny thoughts/feedback/suggestions are all welcome!", "author_fullname": "t2_6j283ev3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview went really well, still rejected", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164dsoa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693301920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have been working in Analytics since close to 3 years for now. There was this company which I was targeting since quite some time and I applied to a relevant position and fortunately I landed an interview (after applying to numerous other positions).&lt;/p&gt;\n\n&lt;p&gt;Technical test went well, technical interview went well too. Was asked questions on multiple things and I got most of them right and few close.&lt;/p&gt;\n\n&lt;p&gt;After a long time, interview felt like a discussion than an interrogation. It was all good but then couple of days later they say I have been rejected......&lt;/p&gt;\n\n&lt;p&gt;I know this happens most of the times to almost everyone and no big deal, but it&amp;#39;s becoming difficult to let this rejection go and start preparing again as both position and company looked like a perfect fit for my career. &lt;/p&gt;\n\n&lt;p&gt;Any thoughts/feedback/suggestions are all welcome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "164dsoa", "is_robot_indexable": true, "report_reasons": null, "author": "GuardObjective9018", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/164dsoa/interview_went_really_well_still_rejected/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/164dsoa/interview_went_really_well_still_rejected/", "subreddit_subscribers": 1020298, "created_utc": 1693301920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to run a LR to check the relationship between those 3 independent variables on a dependent variable(Not a time series), can i include the third variable from the start of the period? Or I should start from the date the variable is not null ?\n\nhttps://preview.redd.it/4crz0asf4xkb1.png?width=407&amp;format=png&amp;auto=webp&amp;s=2fff1c005fa9a84d88f6b21acff3c5754efe481f", "author_fullname": "t2_27k9kc92", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with missing variables in a Linear Regression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4crz0asf4xkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 188, "x": 108, "u": "https://preview.redd.it/4crz0asf4xkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=25a79e55544cdfbc7e4d1d015f8781c5971c5dfc"}, {"y": 376, "x": 216, "u": "https://preview.redd.it/4crz0asf4xkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b447d0214c046a3d7e991c803d7f3af1c3c1df19"}, {"y": 558, "x": 320, "u": "https://preview.redd.it/4crz0asf4xkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=04ba09e5606b9368ef56934cf5192bac3258385e"}], "s": {"y": 710, "x": 407, "u": "https://preview.redd.it/4crz0asf4xkb1.png?width=407&amp;format=png&amp;auto=webp&amp;s=2fff1c005fa9a84d88f6b21acff3c5754efe481f"}, "id": "4crz0asf4xkb1"}}, "name": "t3_163yixq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/xZzEYIDQYJkMYRXNfFbcOJQTvlc5CQ1z50vW7pi_jC0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693257790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to run a LR to check the relationship between those 3 independent variables on a dependent variable(Not a time series), can i include the third variable from the start of the period? Or I should start from the date the variable is not null ?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4crz0asf4xkb1.png?width=407&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2fff1c005fa9a84d88f6b21acff3c5754efe481f\"&gt;https://preview.redd.it/4crz0asf4xkb1.png?width=407&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2fff1c005fa9a84d88f6b21acff3c5754efe481f&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "163yixq", "is_robot_indexable": true, "report_reasons": null, "author": "Avedis77", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/163yixq/how_to_deal_with_missing_variables_in_a_linear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/163yixq/how_to_deal_with_missing_variables_in_a_linear/", "subreddit_subscribers": 1020298, "created_utc": 1693257790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi Guys! Successfully got  an test assessment for DA position in Finance an Australian base company. Usually how many days should I wait for the result. Its been 4days now, and still waiting. Recruiter said if I pass the test they will  call me for another interview Should I wait for 1 week to email them what's the status of my test result or they want me or not. Thank you in advance. ", "author_fullname": "t2_d02vi21j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For How long, waiting for my Data Analyst Test result.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1642pga", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693267725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys! Successfully got  an test assessment for DA position in Finance an Australian base company. Usually how many days should I wait for the result. Its been 4days now, and still waiting. Recruiter said if I pass the test they will  call me for another interview Should I wait for 1 week to email them what&amp;#39;s the status of my test result or they want me or not. Thank you in advance. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1642pga", "is_robot_indexable": true, "report_reasons": null, "author": "hot_cat22", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1642pga/for_how_long_waiting_for_my_data_analyst_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1642pga/for_how_long_waiting_for_my_data_analyst_test/", "subreddit_subscribers": 1020298, "created_utc": 1693267725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The interview is about Statistics Knowledge, Visualization, and Analysis. What can be some of the potential topics I should cover no matter what? Bit tense\n\nThe interview is for an entry-level position.", "author_fullname": "t2_in5rr0gd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have a stats interview coming up and need suggestions on how to best prepare for it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1649uf8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693288094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The interview is about Statistics Knowledge, Visualization, and Analysis. What can be some of the potential topics I should cover no matter what? Bit tense&lt;/p&gt;\n\n&lt;p&gt;The interview is for an entry-level position.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1649uf8", "is_robot_indexable": true, "report_reasons": null, "author": "Consistent_Angle4366", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1649uf8/i_have_a_stats_interview_coming_up_and_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1649uf8/i_have_a_stats_interview_coming_up_and_need/", "subreddit_subscribers": 1020298, "created_utc": 1693288094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI was wondering if it was possible to extract the intent of a short sentence using unsupervised methods. Dataset consists of unlabeled tweets written to a customer support twitter handle. \n\nI have looked at zero-shot classification using an LLM and using a dataset that covers various customer service intents. The problem statement is specific about using the tweets dataset and not inputting custom labels (such as the ones I provided during zero shot classification)\n\nI have been racking my brain for days now and I am open to any ideas on how I could tackle this problem\n\nThanks!", "author_fullname": "t2_6ezkabqp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intent Classification Using Unlabeled Data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_163rpy7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693242465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I was wondering if it was possible to extract the intent of a short sentence using unsupervised methods. Dataset consists of unlabeled tweets written to a customer support twitter handle. &lt;/p&gt;\n\n&lt;p&gt;I have looked at zero-shot classification using an LLM and using a dataset that covers various customer service intents. The problem statement is specific about using the tweets dataset and not inputting custom labels (such as the ones I provided during zero shot classification)&lt;/p&gt;\n\n&lt;p&gt;I have been racking my brain for days now and I am open to any ideas on how I could tackle this problem&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "163rpy7", "is_robot_indexable": true, "report_reasons": null, "author": "fullHierarchy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/163rpy7/intent_classification_using_unlabeled_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/163rpy7/intent_classification_using_unlabeled_data/", "subreddit_subscribers": 1020298, "created_utc": 1693242465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_rvf1q32t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pond (paper reading/sharing platform) is now in Open Beta, with its own Chrome extension.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_163qsm3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aOz74tnxTVixg5kiYW0_L6WgpQjw0v3UCZp6tYMZh9E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693240325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/wavynjetovkb1.gif", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/wavynjetovkb1.gif?format=png8&amp;s=4170cd651d56bcd31bf1882de50f56cdaa9e229a", "width": 1152, "height": 648}, "resolutions": [{"url": "https://preview.redd.it/wavynjetovkb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=11396cb64384321d77734b3a027968b073d07892", "width": 108, "height": 60}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=0ced2268e96db07f2bf95adbe0ff357a8cc001e7", "width": 216, "height": 121}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=ec864320a32d20e4563caee31b37d0b7519393f4", "width": 320, "height": 180}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=3fdd6e5ade93aa0f5c73f77e63df5163ded27519", "width": 640, "height": 360}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=ed20535826922db9ed6cfcdaffaeb977788d3378", "width": 960, "height": 540}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=6d26e98d5199935d714c1a467418f5eb548266e2", "width": 1080, "height": 607}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/wavynjetovkb1.gif?s=23716554b13479858b2172bcb840e7542f735734", "width": 1152, "height": 648}, "resolutions": [{"url": "https://preview.redd.it/wavynjetovkb1.gif?width=108&amp;crop=smart&amp;s=20ccbc031301e2bd1672899271ca8f641721dc7e", "width": 108, "height": 60}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=216&amp;crop=smart&amp;s=3ae4c054b9c169f452beee922f19336dc5855d8c", "width": 216, "height": 121}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=320&amp;crop=smart&amp;s=99033f305d406e5b29bfdd88defe3a54c15f4272", "width": 320, "height": 180}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=640&amp;crop=smart&amp;s=cf3e1187361994a506eb08f74d65e91b085e7202", "width": 640, "height": 360}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=960&amp;crop=smart&amp;s=496aa33595b17039c63bb165487ab968e0382162", "width": 960, "height": 540}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=1080&amp;crop=smart&amp;s=65f50587e6d28f205088691eb6b58b7b985801d9", "width": 1080, "height": 607}]}, "mp4": {"source": {"url": "https://preview.redd.it/wavynjetovkb1.gif?format=mp4&amp;s=bc42269d15911001c897fcbae7072f105490e9f6", "width": 1152, "height": 648}, "resolutions": [{"url": "https://preview.redd.it/wavynjetovkb1.gif?width=108&amp;format=mp4&amp;s=fcfdd364349965bdf3449dec3b2300e9763eb54a", "width": 108, "height": 60}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=216&amp;format=mp4&amp;s=19a6fb7a6666c2c950d2538a566abeaa0db4f116", "width": 216, "height": 121}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=320&amp;format=mp4&amp;s=2e93a5f701f31f2885d10b283aacdb0173d666ec", "width": 320, "height": 180}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=640&amp;format=mp4&amp;s=ef63385a45b1eab9a17dda6844845468fe190724", "width": 640, "height": 360}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=960&amp;format=mp4&amp;s=f8b3c45587bb5fb8fb63564859eccbbb669a4967", "width": 960, "height": 540}, {"url": "https://preview.redd.it/wavynjetovkb1.gif?width=1080&amp;format=mp4&amp;s=371f52854ecb09bfcbc226f552b4790ef658f7b8", "width": 1080, "height": 607}]}}, "id": "eJAiZC3HvOQEShSpWZLHMJspfBOWai2Hh67UD9Yl19Q"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "163qsm3", "is_robot_indexable": true, "report_reasons": null, "author": "dockerun", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/163qsm3/pond_paper_readingsharing_platform_is_now_in_open/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/wavynjetovkb1.gif", "subreddit_subscribers": 1020298, "created_utc": 1693240325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_dy7ojby3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When Can I Ride? Using ML to Predict Mountain Bike Trail Status", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_164l1o1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1693321769.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "offroadanalyst.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://offroadanalyst.com/2023/08/25/cincinnati-mtb-trail-status-predictor/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "164l1o1", "is_robot_indexable": true, "report_reasons": null, "author": "malcom_bored_well", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/164l1o1/when_can_i_ride_using_ml_to_predict_mountain_bike/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://offroadanalyst.com/2023/08/25/cincinnati-mtb-trail-status-predictor/", "subreddit_subscribers": 1020298, "created_utc": 1693321769.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Here's the handwavy article. https://www.computerworld.com/article/3705550/microsoft-amazon-go-head-to-head-on-genai-in-the-cloud-heres-wholl-win.html\n\nMarkov might give us a long term winner prediction.  \n\nIt needs transition probabilities of users, which I don't know where to get yet.  \n\nAnd Markov analysis needs stable transition probabilities, which we would use a couple years of historical data to check.\n\nAnd would we be able to say \"stable transition probability\" if we choose the mean of whatever distribution is found?  I guess ARIMA or linear regression or other autoregressive analysis can spot a trend for long term that would suggest it's not suitable use-case for Markov.  But even if Markov is not applicable here then this finding would still help us answer the question if it looks like one vendor's long term trend is UP but others are DOWN.\n\nWhere would data be found as to user transitions among clouds? Google or chatgpt4 are what I got for now... TBD", "author_fullname": "t2_katn8jcr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Markov chain analysis for answering at a level better than handwaving: Which vendor cloud will win (long run)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164k5q0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693319705.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here&amp;#39;s the handwavy article. &lt;a href=\"https://www.computerworld.com/article/3705550/microsoft-amazon-go-head-to-head-on-genai-in-the-cloud-heres-wholl-win.html\"&gt;https://www.computerworld.com/article/3705550/microsoft-amazon-go-head-to-head-on-genai-in-the-cloud-heres-wholl-win.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Markov might give us a long term winner prediction.  &lt;/p&gt;\n\n&lt;p&gt;It needs transition probabilities of users, which I don&amp;#39;t know where to get yet.  &lt;/p&gt;\n\n&lt;p&gt;And Markov analysis needs stable transition probabilities, which we would use a couple years of historical data to check.&lt;/p&gt;\n\n&lt;p&gt;And would we be able to say &amp;quot;stable transition probability&amp;quot; if we choose the mean of whatever distribution is found?  I guess ARIMA or linear regression or other autoregressive analysis can spot a trend for long term that would suggest it&amp;#39;s not suitable use-case for Markov.  But even if Markov is not applicable here then this finding would still help us answer the question if it looks like one vendor&amp;#39;s long term trend is UP but others are DOWN.&lt;/p&gt;\n\n&lt;p&gt;Where would data be found as to user transitions among clouds? Google or chatgpt4 are what I got for now... TBD&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tRfOcFOLXta7ZzFnD0SMYvs_hQxRMXeB7gg8P0ESPLk.jpg?auto=webp&amp;s=1d6391534ab4d1d6cabc2fab704df82caad2c8fc", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/tRfOcFOLXta7ZzFnD0SMYvs_hQxRMXeB7gg8P0ESPLk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=92bcd44b4a27204102cdfb61e2fab7201cabe258", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/tRfOcFOLXta7ZzFnD0SMYvs_hQxRMXeB7gg8P0ESPLk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=11905d17065c990e306d75f88f158f9cb36cb754", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/tRfOcFOLXta7ZzFnD0SMYvs_hQxRMXeB7gg8P0ESPLk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c873c8ec7124104bea6853ae778a97bc81028d02", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/tRfOcFOLXta7ZzFnD0SMYvs_hQxRMXeB7gg8P0ESPLk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b003f6c271ad951444687f07f5dd1852dd275290", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/tRfOcFOLXta7ZzFnD0SMYvs_hQxRMXeB7gg8P0ESPLk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d066c4a6afaddfe7d79aff314b8b86297b134c0a", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/tRfOcFOLXta7ZzFnD0SMYvs_hQxRMXeB7gg8P0ESPLk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f8ae83ab827bb6d0287cc38d3c7cd565ad24820a", "width": 1080, "height": 720}], "variants": {}, "id": "sRyu2wZCPyhVD0VqMrfw_yxGywG6QpWI75N5xw_4qD4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "164k5q0", "is_robot_indexable": true, "report_reasons": null, "author": "foofriender", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/164k5q0/markov_chain_analysis_for_answering_at_a_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/164k5q0/markov_chain_analysis_for_answering_at_a_level/", "subreddit_subscribers": 1020298, "created_utc": 1693319705.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI'm currently thinking about how to implement the \"similar keywords\" feature. I've prepared a table with keywords that are extracted from several hundred other tables. It includes basic information such as \"keyword,\" \"type,\" \"words\" (indicating the number of words in a keyword, e.g., \"first name\" will have \"words\" = 2), as well as some technical fields (such as database, table, etc.).\n\nIn our data product, after entering a specific keyword, we have various pieces of information (which I'm not currently focusing on), and among them, we have \"SIMILAR KEYWORDS.\" The results are displayed based on simple SQL queries, for instance:  \n\n\n    SELECT word, \n    \tSUM(CASE WHEN type IN ('N', 'T') THEN 1 ELSE 0 END) AS count,\n    \tCOUNT(*) * CASE WHEN (word + '%') LIKE u/word + '%' THEN 1.5 ELSE 1 END AS score\n    FROM object_keywords\n    WHERE ('% ' + word + '%') LIKE '%' + u/word + '%'\n    AND (database_id = u/database_id OR u/database_id IS NULL)\n    AND (\n    .... more technical information here.\n    \n\n \n\nI'm wondering how to improve this process. Would it be worth considering some AI solutions, or should I focus on enhancing the current SQL scripts (e.g., think about a more advanced scoring system)?\n\nWhat are your thoughts on this? Has anyone worked on something similar?\n\n&amp;#x200B;", "author_fullname": "t2_7yv0lkcd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing Keyword Search: Balancing SQL Script Enhancements and AI Solutions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164hx9j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693314192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently thinking about how to implement the &amp;quot;similar keywords&amp;quot; feature. I&amp;#39;ve prepared a table with keywords that are extracted from several hundred other tables. It includes basic information such as &amp;quot;keyword,&amp;quot; &amp;quot;type,&amp;quot; &amp;quot;words&amp;quot; (indicating the number of words in a keyword, e.g., &amp;quot;first name&amp;quot; will have &amp;quot;words&amp;quot; = 2), as well as some technical fields (such as database, table, etc.).&lt;/p&gt;\n\n&lt;p&gt;In our data product, after entering a specific keyword, we have various pieces of information (which I&amp;#39;m not currently focusing on), and among them, we have &amp;quot;SIMILAR KEYWORDS.&amp;quot; The results are displayed based on simple SQL queries, for instance:  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT word, \n    SUM(CASE WHEN type IN (&amp;#39;N&amp;#39;, &amp;#39;T&amp;#39;) THEN 1 ELSE 0 END) AS count,\n    COUNT(*) * CASE WHEN (word + &amp;#39;%&amp;#39;) LIKE u/word + &amp;#39;%&amp;#39; THEN 1.5 ELSE 1 END AS score\nFROM object_keywords\nWHERE (&amp;#39;% &amp;#39; + word + &amp;#39;%&amp;#39;) LIKE &amp;#39;%&amp;#39; + u/word + &amp;#39;%&amp;#39;\nAND (database_id = u/database_id OR u/database_id IS NULL)\nAND (\n.... more technical information here.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;m wondering how to improve this process. Would it be worth considering some AI solutions, or should I focus on enhancing the current SQL scripts (e.g., think about a more advanced scoring system)?&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on this? Has anyone worked on something similar?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "164hx9j", "is_robot_indexable": true, "report_reasons": null, "author": "International-Shirt5", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/164hx9j/optimizing_keyword_search_balancing_sql_script/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/164hx9j/optimizing_keyword_search_balancing_sql_script/", "subreddit_subscribers": 1020298, "created_utc": 1693314192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone!\n\nI  wanted to create a \"Flood prediction system\" using LSTM or Random  Forest. I'm just a beginner in this field and have no proper idea of  which one's the best at this situation. I recently bought some data from  the government which consists:\n\n1. Amount of rainfall(mm)\n2. Water discharge(in m3/sec)\n3. temperature(min/max)\n4. river water level\n\nIs  there \"the best\" algorithm to use in my case or is it just the matter  of testing it all? Please help me. I'm just stuck with this diemma and  it's sort of choking me at the moment.\n\nAlso,  if you've some time I'd have loved to hear how I should go about  processing the data to get it ready for the model that I'm willing to  prepare. Just your personal experience would really mean a lot to me in  showing what exactly I should be doing.", "author_fullname": "t2_8norio4g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Selecting \"the best\" model for a project.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164feqs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693307159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I  wanted to create a &amp;quot;Flood prediction system&amp;quot; using LSTM or Random  Forest. I&amp;#39;m just a beginner in this field and have no proper idea of  which one&amp;#39;s the best at this situation. I recently bought some data from  the government which consists:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Amount of rainfall(mm)&lt;/li&gt;\n&lt;li&gt;Water discharge(in m3/sec)&lt;/li&gt;\n&lt;li&gt;temperature(min/max)&lt;/li&gt;\n&lt;li&gt;river water level&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Is  there &amp;quot;the best&amp;quot; algorithm to use in my case or is it just the matter  of testing it all? Please help me. I&amp;#39;m just stuck with this diemma and  it&amp;#39;s sort of choking me at the moment.&lt;/p&gt;\n\n&lt;p&gt;Also,  if you&amp;#39;ve some time I&amp;#39;d have loved to hear how I should go about  processing the data to get it ready for the model that I&amp;#39;m willing to  prepare. Just your personal experience would really mean a lot to me in  showing what exactly I should be doing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "164feqs", "is_robot_indexable": true, "report_reasons": null, "author": "SudipShrestha369", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/164feqs/selecting_the_best_model_for_a_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/164feqs/selecting_the_best_model_for_a_project/", "subreddit_subscribers": 1020298, "created_utc": 1693307159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_7k6lx11e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a csv file to store image path and class neccessary for image classification?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164dd8i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693300410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "164dd8i", "is_robot_indexable": true, "report_reasons": null, "author": "Itthi125", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/164dd8i/is_a_csv_file_to_store_image_path_and_class/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/164dd8i/is_a_csv_file_to_store_image_path_and_class/", "subreddit_subscribers": 1020298, "created_utc": 1693300410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**TLDR;** We're open-sourcing our CodeLlama server. It handles streaming, caching, model fallbacks, and tracks prompts + token usage - [https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server](https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server)\n\n\\~\\~\n\nHello r/datascience,\n\nI\u2019m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, TogetherAI, Cohere, Anthropic, Baseten, Hugging face API Endpoints: [https://github.com/BerriAI/litellm/](https://github.com/BerriAI/litellm/)\n\nWe're open sourcing our CodeLlama server:\n\nWhat can our server do? - It uses Together AI's CodeLlama to answer coding questions, with GPT-4 + Claude-2 as backups (you can easily switch this to any model from Huggingface, Replicate, Cohere, AI21, Azure, OpenAI, etc.)\n\nConsistent Input/Output Format - Call all models using the OpenAI format: completion(model, messages) - Text responses will always be available at \\['choices'\\]\\[0\\]\\['message'\\]\\['content'\\]\n\n* Streaming &amp; Async Support - Return generators to stream text responses\n* Error Handling Using Model Fallbacks (if Phind-CodeLlama fails, use Claude-2, fine-tuned GPT-3.5 etc.)\n* Logging - It's integrated with promptlayer, so you can automatically track your prompt + model changes there.\n* Token Usage &amp; Spend - Track Input + Completion tokens used + Spend/model\n* Caching - In-memory + Redis Cache solutions provided (works for streaming too!).\n\nYou can deploy liteLLM to your own infrastructure using Railway, GCP, AWS, Azure\n\nHappy completion() !", "author_fullname": "t2_b5qc2w9r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open-Source CodeLlama Server: Streaming, Caching, Model Fallbacks (OpenAI + Anthropic), Prompt-tracking", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1647or7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693281179.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TLDR;&lt;/strong&gt; We&amp;#39;re open-sourcing our CodeLlama server. It handles streaming, caching, model fallbacks, and tracks prompts + token usage - &lt;a href=\"https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server\"&gt;https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;~~&lt;/p&gt;\n\n&lt;p&gt;Hello &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, TogetherAI, Cohere, Anthropic, Baseten, Hugging face API Endpoints: &lt;a href=\"https://github.com/BerriAI/litellm/\"&gt;https://github.com/BerriAI/litellm/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re open sourcing our CodeLlama server:&lt;/p&gt;\n\n&lt;p&gt;What can our server do? - It uses Together AI&amp;#39;s CodeLlama to answer coding questions, with GPT-4 + Claude-2 as backups (you can easily switch this to any model from Huggingface, Replicate, Cohere, AI21, Azure, OpenAI, etc.)&lt;/p&gt;\n\n&lt;p&gt;Consistent Input/Output Format - Call all models using the OpenAI format: completion(model, messages) - Text responses will always be available at [&amp;#39;choices&amp;#39;][0][&amp;#39;message&amp;#39;][&amp;#39;content&amp;#39;]&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Streaming &amp;amp; Async Support - Return generators to stream text responses&lt;/li&gt;\n&lt;li&gt;Error Handling Using Model Fallbacks (if Phind-CodeLlama fails, use Claude-2, fine-tuned GPT-3.5 etc.)&lt;/li&gt;\n&lt;li&gt;Logging - It&amp;#39;s integrated with promptlayer, so you can automatically track your prompt + model changes there.&lt;/li&gt;\n&lt;li&gt;Token Usage &amp;amp; Spend - Track Input + Completion tokens used + Spend/model&lt;/li&gt;\n&lt;li&gt;Caching - In-memory + Redis Cache solutions provided (works for streaming too!).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You can deploy liteLLM to your own infrastructure using Railway, GCP, AWS, Azure&lt;/p&gt;\n\n&lt;p&gt;Happy completion() !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Q_LZ3GNpmZvmbO4QJPw4Tdz26wRiSEjpPJJbYgkR0xc.jpg?auto=webp&amp;s=55519c2e574678f16543188d2727ba798a622992", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Q_LZ3GNpmZvmbO4QJPw4Tdz26wRiSEjpPJJbYgkR0xc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9377cae8b98809dd9237def65c3a53a7c1bf5c40", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Q_LZ3GNpmZvmbO4QJPw4Tdz26wRiSEjpPJJbYgkR0xc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7964ce3ab0e60d457ed03e07e00cb78ffd8811c5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Q_LZ3GNpmZvmbO4QJPw4Tdz26wRiSEjpPJJbYgkR0xc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f92d3a9ebb34836cb273f35b0a2bbb610f6df944", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Q_LZ3GNpmZvmbO4QJPw4Tdz26wRiSEjpPJJbYgkR0xc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d068f28238e39a9b417a4a335201cef36572b6d1", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Q_LZ3GNpmZvmbO4QJPw4Tdz26wRiSEjpPJJbYgkR0xc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=46d3c8bbf6f06cb4d75dfeb4dff1df3133f1175e", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Q_LZ3GNpmZvmbO4QJPw4Tdz26wRiSEjpPJJbYgkR0xc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ce5b78a00fc8bd8fb6b7a377018d9b7f1530932d", "width": 1080, "height": 540}], "variants": {}, "id": "MCWVlp1nxdlv6eTSOB67ElRG9IFpJXwG1AFr1PAyd_s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1647or7", "is_robot_indexable": true, "report_reasons": null, "author": "VideoTo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1647or7/opensource_codellama_server_streaming_caching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1647or7/opensource_codellama_server_streaming_caching/", "subreddit_subscribers": 1020298, "created_utc": 1693281179.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I have trained an XGB, an RF and an LGBM model for a 12-class classification task with 10-fold stratified CV. Randomized search was performed for 200 iterations for all models. 20% of all the data was holdout for test and at best XGB could achieve an F1 macro score of 0.87 on this separate data set.\n\nTraining set has 20753 samples and 40 features, where the class with the most samples has 16323 samples, and the least 33, followed by 40,62 and 92.\n\nI tried using an oversampling method, SMOTE, to see if it improved the performance, then trained without the weights. It performed at most as well as if the models were trained with sample/ class weights and no oversampling.\n\nFurthermore, based on feature importance extracted from models after the training, reducing \\~20% of the less important features did not improve performance either.\n\nWhat are some ways that I can improve the models and analyze them further? Thank you.", "author_fullname": "t2_3fdp0rn9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Performance improvement of tree based models for imbalanced multi-class classification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_163zk1h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693260131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have trained an XGB, an RF and an LGBM model for a 12-class classification task with 10-fold stratified CV. Randomized search was performed for 200 iterations for all models. 20% of all the data was holdout for test and at best XGB could achieve an F1 macro score of 0.87 on this separate data set.&lt;/p&gt;\n\n&lt;p&gt;Training set has 20753 samples and 40 features, where the class with the most samples has 16323 samples, and the least 33, followed by 40,62 and 92.&lt;/p&gt;\n\n&lt;p&gt;I tried using an oversampling method, SMOTE, to see if it improved the performance, then trained without the weights. It performed at most as well as if the models were trained with sample/ class weights and no oversampling.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, based on feature importance extracted from models after the training, reducing ~20% of the less important features did not improve performance either.&lt;/p&gt;\n\n&lt;p&gt;What are some ways that I can improve the models and analyze them further? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "163zk1h", "is_robot_indexable": true, "report_reasons": null, "author": "returnname35", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/163zk1h/performance_improvement_of_tree_based_models_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/163zk1h/performance_improvement_of_tree_based_models_for/", "subreddit_subscribers": 1020298, "created_utc": 1693260131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I have the option to choose between the Business Analytics, Econometrics, and Statistics track and the Machine Learning and Artificial Intelligence for my university courses. Which one do you think is more important and will help me land a job after graduating? Thank you very much!", "author_fullname": "t2_i8z3toes", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Business Analytics, Econometrics, and Statistics vs Machine Learning and Artificial Intelligence", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_163rf7f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693241795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have the option to choose between the Business Analytics, Econometrics, and Statistics track and the Machine Learning and Artificial Intelligence for my university courses. Which one do you think is more important and will help me land a job after graduating? Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "163rf7f", "is_robot_indexable": true, "report_reasons": null, "author": "ApprehensiveWay2282", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/163rf7f/business_analytics_econometrics_and_statistics_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/163rf7f/business_analytics_econometrics_and_statistics_vs/", "subreddit_subscribers": 1020298, "created_utc": 1693241795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a GTX1080 in a Windows 10 PC\n\nI've currently spent 4 hours trying to get  tensorflow working with my GPU.\n\nI've installed and reinstalled CUDA and CUDNN multiple times with no luck.\n\nIs there an easier way to get tensorflow working with Nvidia GPUs?", "author_fullname": "t2_p5mn5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a better way to get setup using tensorflow with a Nvidia GPU?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_163qd5m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693239325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a GTX1080 in a Windows 10 PC&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve currently spent 4 hours trying to get  tensorflow working with my GPU.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve installed and reinstalled CUDA and CUDNN multiple times with no luck.&lt;/p&gt;\n\n&lt;p&gt;Is there an easier way to get tensorflow working with Nvidia GPUs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "163qd5m", "is_robot_indexable": true, "report_reasons": null, "author": "balackdynamite", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/163qd5m/is_there_a_better_way_to_get_setup_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/163qd5m/is_there_a_better_way_to_get_setup_using/", "subreddit_subscribers": 1020298, "created_utc": 1693239325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " The world of data science is constantly evolving, with Python emerging as a premier tool for researchers due to its robust libraries for data manipulation, analysis, and visualization.\n\nIn this ever-changing landscape, the \u201cPython Data Science Handbook: Essential Tools for Working with Data\u201d by Jake VanderPlas stands as a comprehensive resource that brings together essential tools and techniques under one roof.\n\nWhether you\u2019re a seasoned [data scientist or a beginner looking to dive into the realm of data analysis](https://thecontentfarm.net/hands-on-data-analysis-with-pandas-stefanie-molin/), this book offers a wealth of insights and practical guidance.\n\nHere is the book review on the book    \n[https://thecontentfarm.net/python-data-science-handbook-jake-vanderplas/](https://thecontentfarm.net/python-data-science-handbook-jake-vanderplas/)", "author_fullname": "t2_gcy2cxlqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Data Science Handbook by Jake VanderPlas (Book Review)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_164m8zy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693324556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The world of data science is constantly evolving, with Python emerging as a premier tool for researchers due to its robust libraries for data manipulation, analysis, and visualization.&lt;/p&gt;\n\n&lt;p&gt;In this ever-changing landscape, the \u201cPython Data Science Handbook: Essential Tools for Working with Data\u201d by Jake VanderPlas stands as a comprehensive resource that brings together essential tools and techniques under one roof.&lt;/p&gt;\n\n&lt;p&gt;Whether you\u2019re a seasoned &lt;a href=\"https://thecontentfarm.net/hands-on-data-analysis-with-pandas-stefanie-molin/\"&gt;data scientist or a beginner looking to dive into the realm of data analysis&lt;/a&gt;, this book offers a wealth of insights and practical guidance.&lt;/p&gt;\n\n&lt;p&gt;Here is the book review on the book&lt;br/&gt;\n&lt;a href=\"https://thecontentfarm.net/python-data-science-handbook-jake-vanderplas/\"&gt;https://thecontentfarm.net/python-data-science-handbook-jake-vanderplas/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fo3vS5Qd85hWyA6RIupaZgwNx9uIcFlUWlnUtF0eecM.jpg?auto=webp&amp;s=55a40d3250b40f37eabf59d133e919a62f8aea98", "width": 1000, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/fo3vS5Qd85hWyA6RIupaZgwNx9uIcFlUWlnUtF0eecM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c22e1125cb7788a806fd1e13dbc01ac704f21e36", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/fo3vS5Qd85hWyA6RIupaZgwNx9uIcFlUWlnUtF0eecM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=721279096e34bd6abea998c2bacfff81ecd062ec", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/fo3vS5Qd85hWyA6RIupaZgwNx9uIcFlUWlnUtF0eecM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8b44c6ae3ad568a703408d571fdb696c5afc4e20", "width": 320, "height": 192}, {"url": "https://external-preview.redd.it/fo3vS5Qd85hWyA6RIupaZgwNx9uIcFlUWlnUtF0eecM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=723ff6cdb65735af3265059c891726321975c21b", "width": 640, "height": 384}, {"url": "https://external-preview.redd.it/fo3vS5Qd85hWyA6RIupaZgwNx9uIcFlUWlnUtF0eecM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c9183efc98cf98ea14f6515430203d9f84c6fa6b", "width": 960, "height": 576}], "variants": {}, "id": "aTDLR8e6aw6qGVQuQtDy18TMzo9vV9zQ0flvY7ZzYxg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "164m8zy", "is_robot_indexable": true, "report_reasons": null, "author": "Content-farm_net", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/164m8zy/python_data_science_handbook_by_jake_vanderplas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/164m8zy/python_data_science_handbook_by_jake_vanderplas/", "subreddit_subscribers": 1020298, "created_utc": 1693324556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I am offered an interview with a company that manages several marinas, and I am preparing for the interview, this is what they say:\n\n*X company develops innovative tools and services for the entire yachting sector, from navigation to port management. The data collected by the group comes from various integrated software or developed internally (accounting management software, CRM, etc.). A data center was recently created with the mission of collecting its data, process it, analyze it and model it for the various businesses (finance, operations, marketing...).*\n\n***MISSION***\n\n*Within a small team, you will contribute to the following activities without being exhaustive:*\n\n*- Understanding and reformulation of business issues*\n\n*- Understanding, cleaning and enrichment of data*\n\n*- Treatment*\n\n*- Modelization*\n\n*- Analysis*\n\n*You will work with SQL Server Management Studio and Power BI.*\n\n***PROFILE***\n\n*Knowledge of SQL Server is required.*\n\n*Autonomy.*\n\n*You like to take initiatives.*\n\n*You have writing and communication skills (English).*\n\n*You know how to make your code and complex concepts intelligible.*\n\nMy question: what to include and say in the presentation on the day of the interview? Any ideas how I can be useful to this business? Anything really that can help on the day of the interview... (Thanks!!)\n\n&amp;#x200B;\n\n(I have two bachelors, one in computer science and the other in data science).", "author_fullname": "t2_arr9ev59", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How data science might help data gathered by a port company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_164lnql", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693323189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am offered an interview with a company that manages several marinas, and I am preparing for the interview, this is what they say:&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;X company develops innovative tools and services for the entire yachting sector, from navigation to port management. The data collected by the group comes from various integrated software or developed internally (accounting management software, CRM, etc.). A data center was recently created with the mission of collecting its data, process it, analyze it and model it for the various businesses (finance, operations, marketing...).&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;MISSION&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Within a small team, you will contribute to the following activities without being exhaustive:&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;- Understanding and reformulation of business issues&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;- Understanding, cleaning and enrichment of data&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;- Treatment&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;- Modelization&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;- Analysis&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;You will work with SQL Server Management Studio and Power BI.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;PROFILE&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Knowledge of SQL Server is required.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Autonomy.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;You like to take initiatives.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;You have writing and communication skills (English).&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;You know how to make your code and complex concepts intelligible.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;My question: what to include and say in the presentation on the day of the interview? Any ideas how I can be useful to this business? Anything really that can help on the day of the interview... (Thanks!!)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(I have two bachelors, one in computer science and the other in data science).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "164lnql", "is_robot_indexable": true, "report_reasons": null, "author": "jiii95", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/164lnql/how_data_science_might_help_data_gathered_by_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/164lnql/how_data_science_might_help_data_gathered_by_a/", "subreddit_subscribers": 1020298, "created_utc": 1693323189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m having an issue where I have a notebook in SageMaker. My team copies the notebook when they want to use it across the environment. At the beginning it was fine but as I have made some changes and it\u2019s become a popular tool, I need properly move this and maintain it appropriately. \n\nWhat are good solutions to like properly scale up this into a usable solution?\n\nDo I make it a library in a mono-repo for my team to use?", "author_fullname": "t2_jqznxjjy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jupyter Notebooks into Production", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_164lmj6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693323109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m having an issue where I have a notebook in SageMaker. My team copies the notebook when they want to use it across the environment. At the beginning it was fine but as I have made some changes and it\u2019s become a popular tool, I need properly move this and maintain it appropriately. &lt;/p&gt;\n\n&lt;p&gt;What are good solutions to like properly scale up this into a usable solution?&lt;/p&gt;\n\n&lt;p&gt;Do I make it a library in a mono-repo for my team to use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "164lmj6", "is_robot_indexable": true, "report_reasons": null, "author": "D1N4D4N1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/164lmj6/jupyter_notebooks_into_production/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/164lmj6/jupyter_notebooks_into_production/", "subreddit_subscribers": 1020298, "created_utc": 1693323109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let\u2019s say you gotta find the amount of vanilla flavoured ice cream eaten in a day in Brazil. How would the data be efficiently collected, and the step by step calculation be conducted?", "author_fullname": "t2_bjx7vyfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you find the amount of a specific food eaten in a day", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_164l3pg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693321901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s say you gotta find the amount of vanilla flavoured ice cream eaten in a day in Brazil. How would the data be efficiently collected, and the step by step calculation be conducted?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "164l3pg", "is_robot_indexable": true, "report_reasons": null, "author": "OkWinter75", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/164l3pg/how_would_you_find_the_amount_of_a_specific_food/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/164l3pg/how_would_you_find_the_amount_of_a_specific_food/", "subreddit_subscribers": 1020298, "created_utc": 1693321901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work in a team that has been working on a data pipeline product for ~2 years. We are now being asked to share our code base with other teams  in different countries.\n\nHow can we ensure that these teams don't use our code to become our competitors by implementing our solution?\n\nWhat is a sensible business approach to this? Collaboration is undoubtedly good but it seems unreasonable that to hand out two years of hard work?", "author_fullname": "t2_3qhbsob6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to protect teams IP (code)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164k288", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693319478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in a team that has been working on a data pipeline product for ~2 years. We are now being asked to share our code base with other teams  in different countries.&lt;/p&gt;\n\n&lt;p&gt;How can we ensure that these teams don&amp;#39;t use our code to become our competitors by implementing our solution?&lt;/p&gt;\n\n&lt;p&gt;What is a sensible business approach to this? Collaboration is undoubtedly good but it seems unreasonable that to hand out two years of hard work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "164k288", "is_robot_indexable": true, "report_reasons": null, "author": "1throwawayacc999", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/164k288/how_to_protect_teams_ip_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/164k288/how_to_protect_teams_ip_code/", "subreddit_subscribers": 1020298, "created_utc": 1693319478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am interested in a job that requires me to be familiar with common methods in the field of big data, automated data validation, and artificial intelligence. Along with setting up an automated data evaluation of multi-sensor systems for the detection and prediction of safety-critical events. The job description is for a junior data scientist for a start-up in the EU that works in Aeronautics and Aerospace.\n\nIf anyone can shed some info about these topics, in case there are some significantly different practices than standard EDA (and I am guessing it is different) that will really be helpful.\n\n&amp;#x200B;", "author_fullname": "t2_7lqv45ds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the common methods in the field of big data, automated data validation and artificial intelligence?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164jr1i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693318715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am interested in a job that requires me to be familiar with common methods in the field of big data, automated data validation, and artificial intelligence. Along with setting up an automated data evaluation of multi-sensor systems for the detection and prediction of safety-critical events. The job description is for a junior data scientist for a start-up in the EU that works in Aeronautics and Aerospace.&lt;/p&gt;\n\n&lt;p&gt;If anyone can shed some info about these topics, in case there are some significantly different practices than standard EDA (and I am guessing it is different) that will really be helpful.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "164jr1i", "is_robot_indexable": true, "report_reasons": null, "author": "SmartPuppyy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/164jr1i/what_are_the_common_methods_in_the_field_of_big/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/164jr1i/what_are_the_common_methods_in_the_field_of_big/", "subreddit_subscribers": 1020298, "created_utc": 1693318715.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}