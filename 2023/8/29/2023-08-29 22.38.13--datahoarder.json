{"kind": "Listing", "data": {"after": "t3_164aysg", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_h6kxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft quietly ends unlimited cloud storage option on OneDrive [business plans]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_164bxnn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 393, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 393, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qsZKjG62IYdMo2LOpHqjPX2JsmSfViXP5KEbg5jBaBk.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693295373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "techradar.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.techradar.com/pro/exclusive-microsoft-quietly-ends-unlimited-cloud-storage-option-on-onedrive", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mawAjS6m8O-wtump8pibt5rSyfDg68d7uyziYyvu4XA.jpg?auto=webp&amp;s=8f0bce728502ff2794f2abe160b5e43d821f817d", "width": 1200, "height": 799}, "resolutions": [{"url": "https://external-preview.redd.it/mawAjS6m8O-wtump8pibt5rSyfDg68d7uyziYyvu4XA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c524c4034625e14952da7029a7bed7674341abfd", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/mawAjS6m8O-wtump8pibt5rSyfDg68d7uyziYyvu4XA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=55070ea84af1531328ecf1b9c9b0f8bd18f67496", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/mawAjS6m8O-wtump8pibt5rSyfDg68d7uyziYyvu4XA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6f42ae78c0a2875c7907960ce7678c983b091226", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/mawAjS6m8O-wtump8pibt5rSyfDg68d7uyziYyvu4XA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e62033ee43d5e8c455c088a089ea28fe0ff64a2c", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/mawAjS6m8O-wtump8pibt5rSyfDg68d7uyziYyvu4XA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5b16d5a627abfe94cda7ba07c92c5f80cf92ec3a", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/mawAjS6m8O-wtump8pibt5rSyfDg68d7uyziYyvu4XA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=71496d7b0a565a26020ed04c18e7e57da051d63a", "width": 1080, "height": 719}], "variants": {}, "id": "07k0jfNLeSFDs0wK0HvO2LDPlpZMOEZOQBn-LqWlUGg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": true, "author_flair_text": "400TB raw", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164bxnn", "is_robot_indexable": true, "report_reasons": null, "author": "It_Is1-24PM", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/164bxnn/microsoft_quietly_ends_unlimited_cloud_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.techradar.com/pro/exclusive-microsoft-quietly-ends-unlimited-cloud-storage-option-on-onedrive", "subreddit_subscribers": 700634, "created_utc": 1693295373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to digatize some old home recordings, and I am wondering if my current workflow and tools are good enough or if you can recomend better.\n\nCapture Card: Haupage PVR 2\n\nVHS: Zenith DVD-R VCR combo\n\nConnection: Component? the three cable plus the audio\n\nSoftware: OBS\n\nSetting:\n\nOuput scaled to Input\n\n720 x 520\n\nno filters\n\nno deinterlacing\n\ndefault KBS\n\nFile quality is medium to lossless, haven't decided\n\nContainer format is MKV\n\nAny ideas where I can improve things,\n\nNot only do I want to future proof myself for clean up but I hear a whine on the audio and I'm not sure I am actually recording at best quality and what have you. I also don't know if I need to get a time base corrector, I have seen dvd-rs that have one built in on ebay and I have an old Sony camcorder that might have a similar function but I have no idea how I would pass it thru.\n\nDon't suppose there are an AI tools that could help with the clean up as well?\n\n&amp;#x200B;\n\nEdit:\n\nI thought I should mention this:\n\nMy current workflow follows,\n\nUnimportant tapes get basic settings care, mostly just getting them done so I know whats on the tape and can discard if unneeded.\n\nImportant tapes get kept for future digitizing at higher quality.\n\nThough given that there doesn't seem to be that much space lost in using Indistinguishable /lossless I am inclined for that any way.\n\n&amp;#x200B;", "author_fullname": "t2_fk8e08x1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to digatize some old VHS tapes what would you recomend as far as tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1644io3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693285328.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693272394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to digatize some old home recordings, and I am wondering if my current workflow and tools are good enough or if you can recomend better.&lt;/p&gt;\n\n&lt;p&gt;Capture Card: Haupage PVR 2&lt;/p&gt;\n\n&lt;p&gt;VHS: Zenith DVD-R VCR combo&lt;/p&gt;\n\n&lt;p&gt;Connection: Component? the three cable plus the audio&lt;/p&gt;\n\n&lt;p&gt;Software: OBS&lt;/p&gt;\n\n&lt;p&gt;Setting:&lt;/p&gt;\n\n&lt;p&gt;Ouput scaled to Input&lt;/p&gt;\n\n&lt;p&gt;720 x 520&lt;/p&gt;\n\n&lt;p&gt;no filters&lt;/p&gt;\n\n&lt;p&gt;no deinterlacing&lt;/p&gt;\n\n&lt;p&gt;default KBS&lt;/p&gt;\n\n&lt;p&gt;File quality is medium to lossless, haven&amp;#39;t decided&lt;/p&gt;\n\n&lt;p&gt;Container format is MKV&lt;/p&gt;\n\n&lt;p&gt;Any ideas where I can improve things,&lt;/p&gt;\n\n&lt;p&gt;Not only do I want to future proof myself for clean up but I hear a whine on the audio and I&amp;#39;m not sure I am actually recording at best quality and what have you. I also don&amp;#39;t know if I need to get a time base corrector, I have seen dvd-rs that have one built in on ebay and I have an old Sony camcorder that might have a similar function but I have no idea how I would pass it thru.&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t suppose there are an AI tools that could help with the clean up as well?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit:&lt;/p&gt;\n\n&lt;p&gt;I thought I should mention this:&lt;/p&gt;\n\n&lt;p&gt;My current workflow follows,&lt;/p&gt;\n\n&lt;p&gt;Unimportant tapes get basic settings care, mostly just getting them done so I know whats on the tape and can discard if unneeded.&lt;/p&gt;\n\n&lt;p&gt;Important tapes get kept for future digitizing at higher quality.&lt;/p&gt;\n\n&lt;p&gt;Though given that there doesn&amp;#39;t seem to be that much space lost in using Indistinguishable /lossless I am inclined for that any way.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1644io3", "is_robot_indexable": true, "report_reasons": null, "author": "KWalthersArt", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1644io3/trying_to_digatize_some_old_vhs_tapes_what_would/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1644io3/trying_to_digatize_some_old_vhs_tapes_what_would/", "subreddit_subscribers": 700634, "created_utc": 1693272394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Heya!\n\nI'm trying to send a buddy of mine Terabytes of data (old Twitch VODs of his) I had laying around for years and now need a bit more space.\n\nI tried to set up Tailscale VPN on my TrueNAS and giving him access to it, it did work via SMB and SCP/SFTP but we only got like \\~10MBit/s max. I'm not entirely sure tho if we used Tailscale's servers or a direct connection, never really used it before.\n\nIs there any other, easier way to move multiple Terabytes in one go? So far I've uploaded \\~900GB batches onto Google Drive and then telling him to download them again via rclone, but this is a bit annoying...\n\nThanks already for suggestions!", "author_fullname": "t2_ebu8n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best/Fastest way to transfer Terabytes of data to a buddy overseas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164gfgq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693310167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heya!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to send a buddy of mine Terabytes of data (old Twitch VODs of his) I had laying around for years and now need a bit more space.&lt;/p&gt;\n\n&lt;p&gt;I tried to set up Tailscale VPN on my TrueNAS and giving him access to it, it did work via SMB and SCP/SFTP but we only got like ~10MBit/s max. I&amp;#39;m not entirely sure tho if we used Tailscale&amp;#39;s servers or a direct connection, never really used it before.&lt;/p&gt;\n\n&lt;p&gt;Is there any other, easier way to move multiple Terabytes in one go? So far I&amp;#39;ve uploaded ~900GB batches onto Google Drive and then telling him to download them again via rclone, but this is a bit annoying...&lt;/p&gt;\n\n&lt;p&gt;Thanks already for suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164gfgq", "is_robot_indexable": true, "report_reasons": null, "author": "EpicLPer", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164gfgq/bestfastest_way_to_transfer_terabytes_of_data_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164gfgq/bestfastest_way_to_transfer_terabytes_of_data_to/", "subreddit_subscribers": 700634, "created_utc": 1693310167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need new 4-10TB drive since my old WD Black 1TB is dying, desktop PC usage with images, videos and other files in same drive so not just pure archiving drive but datahoarding with usage, it's a sickness.\n\nGames are on different SSD, but the drive needs to be able to playback 4K HDR - I noticed playback started stuttering lately with my WD Black and it started making noise so time to replace, served me good 6 years 60 days.\n\nWhich one would you go for, any pros/cons? They're all fairly similarly priced.\n\nWD Red Plus 4TB 108\u20ac\n\nWD Red Pro 8TB 234\u20ac\n\nToshiba X300 10TB 209\u20ac\n\nThanks in advance!", "author_fullname": "t2_10s9c5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD Red Plus, Pro or Toshiba X300", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164j3tp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693317133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need new 4-10TB drive since my old WD Black 1TB is dying, desktop PC usage with images, videos and other files in same drive so not just pure archiving drive but datahoarding with usage, it&amp;#39;s a sickness.&lt;/p&gt;\n\n&lt;p&gt;Games are on different SSD, but the drive needs to be able to playback 4K HDR - I noticed playback started stuttering lately with my WD Black and it started making noise so time to replace, served me good 6 years 60 days.&lt;/p&gt;\n\n&lt;p&gt;Which one would you go for, any pros/cons? They&amp;#39;re all fairly similarly priced.&lt;/p&gt;\n\n&lt;p&gt;WD Red Plus 4TB 108\u20ac&lt;/p&gt;\n\n&lt;p&gt;WD Red Pro 8TB 234\u20ac&lt;/p&gt;\n\n&lt;p&gt;Toshiba X300 10TB 209\u20ac&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164j3tp", "is_robot_indexable": true, "report_reasons": null, "author": "gotanytips", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164j3tp/wd_red_plus_pro_or_toshiba_x300/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164j3tp/wd_red_plus_pro_or_toshiba_x300/", "subreddit_subscribers": 700634, "created_utc": 1693317133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently pack important data with WinRAR (Blake checksum, 5% recovery record) and then create PAR2 (5%) of that archive. I have two identical copies (checked by SHA3-512) of important data stored locally and in cloud. My question is whether anyone has deeper knowledge of PAR and  give us more insight into that technology and maybe give us hints how to use it properly.\nI have situations where recovery record was broken, I read about situation(s) where PAR2 was unable to detect data corruption.", "author_fullname": "t2_u2h4zflt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for making data redundancy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164hee6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693312812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently pack important data with WinRAR (Blake checksum, 5% recovery record) and then create PAR2 (5%) of that archive. I have two identical copies (checked by SHA3-512) of important data stored locally and in cloud. My question is whether anyone has deeper knowledge of PAR and  give us more insight into that technology and maybe give us hints how to use it properly.\nI have situations where recovery record was broken, I read about situation(s) where PAR2 was unable to detect data corruption.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164hee6", "is_robot_indexable": true, "report_reasons": null, "author": "mrmh1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164hee6/best_practices_for_making_data_redundancy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164hee6/best_practices_for_making_data_redundancy/", "subreddit_subscribers": 700634, "created_utc": 1693312812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anybody if we can and especially HOW to undo a deletion on Czkawka?\n\nI thought it was going to delete only the selected files but it seemed to have deleted everything cause I selected \"delete all\"", "author_fullname": "t2_rkszq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to undo on Czkawka?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164sjn7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693338967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anybody if we can and especially HOW to undo a deletion on Czkawka?&lt;/p&gt;\n\n&lt;p&gt;I thought it was going to delete only the selected files but it seemed to have deleted everything cause I selected &amp;quot;delete all&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164sjn7", "is_robot_indexable": true, "report_reasons": null, "author": "rediteux", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164sjn7/how_to_undo_on_czkawka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164sjn7/how_to_undo_on_czkawka/", "subreddit_subscribers": 700634, "created_utc": 1693338967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a mergerFS with snapraid setup running on OpenMediaVault with a bunch of different drives (none of them SMR, AFIAK). The drives are running on a  SuperMicro server with a Xeon E3-1240v6, 32 GB RAM and a LSI 9211 LBA card.\n\nHowever, my setup originated on an old HP Microserver Gen7 with an AMD Turion  N40L (that synced with only 20 MB/s)  that I have moved first to a Gen 8 microserver (sync speeds 90-110 MB/s) and now to the Supermicro. Across all three setup my Snapraid speeds felt rather slow, but lacking any base for comparison i thought its OK. However in this thread here someone was compaining that his sync is running only 130 MB/s  [https://www.reddit.com/r/DataHoarder/comments/15ujyz2/snapraid\\_long\\_sync\\_times\\_is\\_it\\_just\\_not\\_suitable/](https://www.reddit.com/r/DataHoarder/comments/15ujyz2/snapraid_long_sync_times_is_it_just_not_suitable/)\n\nCurrently I have a sync job running at around 130 MB/s  and 120 stripes pre sec, running for more than 6 hours and  22 more to go. CPU utilization is around 2-3%.\n\nThe disk contain mostly movies and music, so it should be rather big files.\n\nThe drives used are the following:\n\n\\- WDC WD40EFRX\n\n\\- WDC WD30EFRX\n\n\\- WDC WD60EFRX\n\n\\- WDC WD80EZAZ\n\n\\- HGST HUS728T8TALE6L4 (this is the parity drive)\n\nIt seems my speeds are too slow. What can i do  to improve them?\n\n&amp;#x200B;", "author_fullname": "t2_gww3b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to improve Snapraid sync speed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164p6sv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693331306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a mergerFS with snapraid setup running on OpenMediaVault with a bunch of different drives (none of them SMR, AFIAK). The drives are running on a  SuperMicro server with a Xeon E3-1240v6, 32 GB RAM and a LSI 9211 LBA card.&lt;/p&gt;\n\n&lt;p&gt;However, my setup originated on an old HP Microserver Gen7 with an AMD Turion  N40L (that synced with only 20 MB/s)  that I have moved first to a Gen 8 microserver (sync speeds 90-110 MB/s) and now to the Supermicro. Across all three setup my Snapraid speeds felt rather slow, but lacking any base for comparison i thought its OK. However in this thread here someone was compaining that his sync is running only 130 MB/s  &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/15ujyz2/snapraid_long_sync_times_is_it_just_not_suitable/\"&gt;https://www.reddit.com/r/DataHoarder/comments/15ujyz2/snapraid_long_sync_times_is_it_just_not_suitable/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Currently I have a sync job running at around 130 MB/s  and 120 stripes pre sec, running for more than 6 hours and  22 more to go. CPU utilization is around 2-3%.&lt;/p&gt;\n\n&lt;p&gt;The disk contain mostly movies and music, so it should be rather big files.&lt;/p&gt;\n\n&lt;p&gt;The drives used are the following:&lt;/p&gt;\n\n&lt;p&gt;- WDC WD40EFRX&lt;/p&gt;\n\n&lt;p&gt;- WDC WD30EFRX&lt;/p&gt;\n\n&lt;p&gt;- WDC WD60EFRX&lt;/p&gt;\n\n&lt;p&gt;- WDC WD80EZAZ&lt;/p&gt;\n\n&lt;p&gt;- HGST HUS728T8TALE6L4 (this is the parity drive)&lt;/p&gt;\n\n&lt;p&gt;It seems my speeds are too slow. What can i do  to improve them?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164p6sv", "is_robot_indexable": true, "report_reasons": null, "author": "rudeer_poke", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164p6sv/how_to_improve_snapraid_sync_speed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164p6sv/how_to_improve_snapraid_sync_speed/", "subreddit_subscribers": 700634, "created_utc": 1693331306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\n1. I applied chkdsk x: /r command on the drive.\n\n&amp;#x200B;\n\n2. Then did a extended health check with GSmartControl. The drive has no problem.\n\n&amp;#x200B;\n\nAlthough those I can not neither rename nor copy some files.\n\n&amp;#x200B;\n\n**Question 1)** What\u2019s the problem?\n\n&amp;#x200B;\n\n**Question 2)** How can I fix this problem?\n\n&amp;#x200B;\n\n**EDIT :** I had a long test with both A) Seagate Seatools and B) WD Diagnotstics App. The Drive is ALRIGHT.\n\n&amp;#x200B;", "author_fullname": "t2_vzb13yh5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I Can Not Rename Or Copy Some Files Into Another Place On The SSD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164i63e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693343009.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693314811.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I applied chkdsk x: /r command on the drive.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Then did a extended health check with GSmartControl. The drive has no problem.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Although those I can not neither rename nor copy some files.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question 1)&lt;/strong&gt; What\u2019s the problem?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question 2)&lt;/strong&gt; How can I fix this problem?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT :&lt;/strong&gt; I had a long test with both A) Seagate Seatools and B) WD Diagnotstics App. The Drive is ALRIGHT.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164i63e", "is_robot_indexable": true, "report_reasons": null, "author": "EarthShaker23", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164i63e/i_can_not_rename_or_copy_some_files_into_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164i63e/i_can_not_rename_or_copy_some_files_into_another/", "subreddit_subscribers": 700634, "created_utc": 1693314811.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I use Acronis Trueimage to backup my files, in my case family photos and videos. Among other things, working with a single .tib file is easier than moving around thousands of individual .jpgs.\n\nHowever I started thinking that this may be introducing a vulnerability - if the .tib file becomes corrupt then I'll likely lose all the files contained within. Whereas a corrupt.jpg is only a single file.\n\nI'd be interested to know what others are doing. Should I use smaller archive files? Some kind of checksum to prove integrity?\n\nThese aren't my only backups, I have the files duplicated in their original format so it's not a pressing issue but before I invest any more time in this I thought it would be useful to get an outside opinion. I suppose this is the same for other formats such as tar and zip.", "author_fullname": "t2_vdieh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I introducing risk to my backup procedure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164cxoi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693298900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use Acronis Trueimage to backup my files, in my case family photos and videos. Among other things, working with a single .tib file is easier than moving around thousands of individual .jpgs.&lt;/p&gt;\n\n&lt;p&gt;However I started thinking that this may be introducing a vulnerability - if the .tib file becomes corrupt then I&amp;#39;ll likely lose all the files contained within. Whereas a corrupt.jpg is only a single file.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d be interested to know what others are doing. Should I use smaller archive files? Some kind of checksum to prove integrity?&lt;/p&gt;\n\n&lt;p&gt;These aren&amp;#39;t my only backups, I have the files duplicated in their original format so it&amp;#39;s not a pressing issue but before I invest any more time in this I thought it would be useful to get an outside opinion. I suppose this is the same for other formats such as tar and zip.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164cxoi", "is_robot_indexable": true, "report_reasons": null, "author": "pennanbeach", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164cxoi/am_i_introducing_risk_to_my_backup_procedure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164cxoi/am_i_introducing_risk_to_my_backup_procedure/", "subreddit_subscribers": 700634, "created_utc": 1693298900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an issue where if I use both ports of an LSI3008i (IT) HBA to connect to a BPN-SAS3-216EL1-N4 backplane, I get errors. However, if I only connect 1 port, regardless of which port it is, or cable, there are no errors. Only when using both ports are there errors.\n\n&amp;#x200B;\n\nAny ideas of what could be causing this?\n\n&amp;#x200B;\n\nThe case is a Supermicro SC216 filled with 24 MX500 disks that had firmware updated in windows before installing TrueNAS Scale.\n\n&amp;#x200B;\n\nAll drives are recognized and appear to work normally. I used a known good cpu/board/ecc RAM so these are not a factor.\n\n&amp;#x200B;\n\nThe first test with both cables attached gave errors.\n\nI disconnected one cable and it tested fine with no errors.\n\nI disconnected that cable and reconnected the first one, also fine with no errors.\n\nI changed ports on the backplane/HBA with each cable, and as long as only one port is connected, there are no errors.\n\nAs soon as both ports are connected, errors.\n\n&amp;#x200B;\n\nIt is a little perplexing since each individual cable/port seems to be fine. The manual for the backplane shows connecting two cables to an HBA for 8 SAS links, so that seems to be how it is intended to function. \n\n&amp;#x200B;\n\nMy assumption is that the problem lies with the HBA (because I really don't want it to be the backplane), but I don't have a spare SAS3 HBA to test with and I'd like to rule out any other potential possibilities before I buy another one. \n\n&amp;#x200B;\n\nI currently only have one cable connected and have only been using it as a secondary backup since I don't fully trust it. It's been about two months now with no errors, but it bothers me that I can't use both connections and that there may be something else wrong with the card.\n\n&amp;#x200B;", "author_fullname": "t2_16xzp7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Errors when using both SAS Ports on HBA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1641z6c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693265949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an issue where if I use both ports of an LSI3008i (IT) HBA to connect to a BPN-SAS3-216EL1-N4 backplane, I get errors. However, if I only connect 1 port, regardless of which port it is, or cable, there are no errors. Only when using both ports are there errors.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any ideas of what could be causing this?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The case is a Supermicro SC216 filled with 24 MX500 disks that had firmware updated in windows before installing TrueNAS Scale.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;All drives are recognized and appear to work normally. I used a known good cpu/board/ecc RAM so these are not a factor.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The first test with both cables attached gave errors.&lt;/p&gt;\n\n&lt;p&gt;I disconnected one cable and it tested fine with no errors.&lt;/p&gt;\n\n&lt;p&gt;I disconnected that cable and reconnected the first one, also fine with no errors.&lt;/p&gt;\n\n&lt;p&gt;I changed ports on the backplane/HBA with each cable, and as long as only one port is connected, there are no errors.&lt;/p&gt;\n\n&lt;p&gt;As soon as both ports are connected, errors.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It is a little perplexing since each individual cable/port seems to be fine. The manual for the backplane shows connecting two cables to an HBA for 8 SAS links, so that seems to be how it is intended to function. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My assumption is that the problem lies with the HBA (because I really don&amp;#39;t want it to be the backplane), but I don&amp;#39;t have a spare SAS3 HBA to test with and I&amp;#39;d like to rule out any other potential possibilities before I buy another one. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I currently only have one cable connected and have only been using it as a secondary backup since I don&amp;#39;t fully trust it. It&amp;#39;s been about two months now with no errors, but it bothers me that I can&amp;#39;t use both connections and that there may be something else wrong with the card.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1641z6c", "is_robot_indexable": true, "report_reasons": null, "author": "IsomorphicProjection", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1641z6c/data_errors_when_using_both_sas_ports_on_hba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1641z6c/data_errors_when_using_both_sas_ports_on_hba/", "subreddit_subscribers": 700634, "created_utc": 1693265949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm considering buying an LSI MegaRaid 9361-8i card.\n\nI see that it's a 2012 model (maybe pcie 2.0?) which was replaced by 9480-8i released in 2020, but a lot more expensive.\n\nIs the newer one worth the cost? Or should i perhaps go for some HBA card, losing the hw raid support? Which model? Linux support required, 12G/s really appreciated.\n\nThankyou", "author_fullname": "t2_c712xrd9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for SAS controller card", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1641pcp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693265283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m considering buying an LSI MegaRaid 9361-8i card.&lt;/p&gt;\n\n&lt;p&gt;I see that it&amp;#39;s a 2012 model (maybe pcie 2.0?) which was replaced by 9480-8i released in 2020, but a lot more expensive.&lt;/p&gt;\n\n&lt;p&gt;Is the newer one worth the cost? Or should i perhaps go for some HBA card, losing the hw raid support? Which model? Linux support required, 12G/s really appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thankyou&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1641pcp", "is_robot_indexable": true, "report_reasons": null, "author": "turtle1470", "discussion_type": null, "num_comments": 11, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1641pcp/advice_for_sas_controller_card/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1641pcp/advice_for_sas_controller_card/", "subreddit_subscribers": 700634, "created_utc": 1693265283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an UnRaid server that I primarily use for Plex, storing photos and backups of my PC, Laptop, and Phone. Currently it uses three dives, an 120GB M.2 cache disk, 6TB Storage HDD, and a 6 TB Parity HDD. It's nearing full and I'd like to future-proof it, so my plan is to buy another 6TB drive and an 18TB drive. Then, run the three 6TB drives as an array, with the 18TB to serve as a parity drive. Is this an efficient setup? Is it dangerous to put all my eggs in one basket with a single parity drive?", "author_fullname": "t2_12ekn1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most Efficient UnRaid Setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_164u378", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693342430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an UnRaid server that I primarily use for Plex, storing photos and backups of my PC, Laptop, and Phone. Currently it uses three dives, an 120GB M.2 cache disk, 6TB Storage HDD, and a 6 TB Parity HDD. It&amp;#39;s nearing full and I&amp;#39;d like to future-proof it, so my plan is to buy another 6TB drive and an 18TB drive. Then, run the three 6TB drives as an array, with the 18TB to serve as a parity drive. Is this an efficient setup? Is it dangerous to put all my eggs in one basket with a single parity drive?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164u378", "is_robot_indexable": true, "report_reasons": null, "author": "senpizzle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164u378/most_efficient_unraid_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164u378/most_efficient_unraid_setup/", "subreddit_subscribers": 700634, "created_utc": 1693342430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[This site](https://fl511.com/cctv) hosts florida DOT cameras. There's 2 specific ones that I want keep on storage. Inspecting, I can't seem to figure out the feed to add to blue iris. Any assistance would be appreciated", "author_fullname": "t2_speo3xmt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help storing Florida road cameras", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164slyu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693339117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://fl511.com/cctv\"&gt;This site&lt;/a&gt; hosts florida DOT cameras. There&amp;#39;s 2 specific ones that I want keep on storage. Inspecting, I can&amp;#39;t seem to figure out the feed to add to blue iris. Any assistance would be appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/J0R887_liIdumYByc8hss2drLu1Q4sG2Rz4EnWhhHQg.jpg?auto=webp&amp;s=0798308c3c0e60d5185348aaae85b75659737d40", "width": 310, "height": 310}, "resolutions": [{"url": "https://external-preview.redd.it/J0R887_liIdumYByc8hss2drLu1Q4sG2Rz4EnWhhHQg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2c8661a696f284a1bd339db998620a65e6dd3111", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/J0R887_liIdumYByc8hss2drLu1Q4sG2Rz4EnWhhHQg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=15ecd7b8fa2a14827bf80bc4c0ef06f691992c13", "width": 216, "height": 216}], "variants": {}, "id": "mR6vooTnizkeN8A6SemUD8_4WfiA2ZtDvOSAA5ciz2U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164slyu", "is_robot_indexable": true, "report_reasons": null, "author": "Vile-X", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164slyu/help_storing_florida_road_cameras/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164slyu/help_storing_florida_road_cameras/", "subreddit_subscribers": 700634, "created_utc": 1693339117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI really like how syncthing automatically connects to your remote peers over the internet.\n\nIs there an open-source backup program that can do the same thing?  (Knowing that syncthing is for file synchronization and not really a backup solution.)\n\nIntended usage would be running docker containers at my and an offsite location (friend's home).\n\nThank you.", "author_fullname": "t2_2k54e5qp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "automatically-discovering open-source backup solution like syncthing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164q5mc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693333549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I really like how syncthing automatically connects to your remote peers over the internet.&lt;/p&gt;\n\n&lt;p&gt;Is there an open-source backup program that can do the same thing?  (Knowing that syncthing is for file synchronization and not really a backup solution.)&lt;/p&gt;\n\n&lt;p&gt;Intended usage would be running docker containers at my and an offsite location (friend&amp;#39;s home).&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164q5mc", "is_robot_indexable": true, "report_reasons": null, "author": "da4niu2", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164q5mc/automaticallydiscovering_opensource_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164q5mc/automaticallydiscovering_opensource_backup/", "subreddit_subscribers": 700634, "created_utc": 1693333549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have a decently high number of Blu-ray discs I need to rip and I'm unsure which drive would work best for my needs. I've seen a lot of conflicting information about drives and thought this would be the best place to ask.\n\n1. The discs are from both North America and Japan so region A would be needed. \n2. I don't think any of them are 4k discs, but I wouldnt be against a drive with 4k support.\n3. I really only need a reader so I can rip them, but once again I wouldnt be against write support. \n4. I have 2 computers I could connect the drive to. The lower end one from like 10 years ago could use either an internal or external drive. But if I need to hook it up to my main Ryzen-based machine then it has to be external.", "author_fullname": "t2_blk7dc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Could use some help picking the right drive for my needs.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164kz8p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693321607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a decently high number of Blu-ray discs I need to rip and I&amp;#39;m unsure which drive would work best for my needs. I&amp;#39;ve seen a lot of conflicting information about drives and thought this would be the best place to ask.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The discs are from both North America and Japan so region A would be needed. &lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t think any of them are 4k discs, but I wouldnt be against a drive with 4k support.&lt;/li&gt;\n&lt;li&gt;I really only need a reader so I can rip them, but once again I wouldnt be against write support. &lt;/li&gt;\n&lt;li&gt;I have 2 computers I could connect the drive to. The lower end one from like 10 years ago could use either an internal or external drive. But if I need to hook it up to my main Ryzen-based machine then it has to be external.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164kz8p", "is_robot_indexable": true, "report_reasons": null, "author": "Zyvyn", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164kz8p/could_use_some_help_picking_the_right_drive_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164kz8p/could_use_some_help_picking_the_right_drive_for/", "subreddit_subscribers": 700634, "created_utc": 1693321607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "One of the drives in my unRAID is reporting \"[error](https://imgur.com/a/io2oJQ0).\"\n\n[Here is the SMART report](https://pastebin.com/H6FCnzEW).\n\nI've ordered [a replacement](https://www.amazon.com/Seagate-IronWolf-Enterprise-Internal-Drive/dp/B0B94KSFTH), arriving tomorrow.\n\nBut for future reference, how serious is this error and is failure imminent?\n\nThanks.\n\n&amp;#x200B;", "author_fullname": "t2_dxdvg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why does SMART status say \"error\" in my array? How serious is this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164joh2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693318546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One of the drives in my unRAID is reporting &amp;quot;&lt;a href=\"https://imgur.com/a/io2oJQ0\"&gt;error&lt;/a&gt;.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pastebin.com/H6FCnzEW\"&gt;Here is the SMART report&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve ordered &lt;a href=\"https://www.amazon.com/Seagate-IronWolf-Enterprise-Internal-Drive/dp/B0B94KSFTH\"&gt;a replacement&lt;/a&gt;, arriving tomorrow.&lt;/p&gt;\n\n&lt;p&gt;But for future reference, how serious is this error and is failure imminent?&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yrLKEHLedzWx3OhSG3vsWLlC6ZC3Hq_TDiKpIaYM520.jpg?auto=webp&amp;s=eb341089b1268a76b8aa0f5972077f982eb4dcd3", "width": 1286, "height": 702}, "resolutions": [{"url": "https://external-preview.redd.it/yrLKEHLedzWx3OhSG3vsWLlC6ZC3Hq_TDiKpIaYM520.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4c3e728b07729037783a81449f73218a1b967490", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/yrLKEHLedzWx3OhSG3vsWLlC6ZC3Hq_TDiKpIaYM520.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e0d81b7ebc1e8d8d25e8652aa7ee1e683ee0d57", "width": 216, "height": 117}, {"url": "https://external-preview.redd.it/yrLKEHLedzWx3OhSG3vsWLlC6ZC3Hq_TDiKpIaYM520.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=da640567e6e8203be36a9569fcab412c58e66008", "width": 320, "height": 174}, {"url": "https://external-preview.redd.it/yrLKEHLedzWx3OhSG3vsWLlC6ZC3Hq_TDiKpIaYM520.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0b26fd501dbbada4cb8e164f12898a00689ef63e", "width": 640, "height": 349}, {"url": "https://external-preview.redd.it/yrLKEHLedzWx3OhSG3vsWLlC6ZC3Hq_TDiKpIaYM520.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ef094c4e7553b1973eeff9197ef6eb36fe45f379", "width": 960, "height": 524}, {"url": "https://external-preview.redd.it/yrLKEHLedzWx3OhSG3vsWLlC6ZC3Hq_TDiKpIaYM520.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d0a259cfb1614b5a7130025ce6fc0dbc677fba90", "width": 1080, "height": 589}], "variants": {}, "id": "dgpUNpRQY5ZjiIYkCK73ojSC9GwmLaeqnT_v2hJGcPI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164joh2", "is_robot_indexable": true, "report_reasons": null, "author": "volcs0", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164joh2/why_does_smart_status_say_error_in_my_array_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164joh2/why_does_smart_status_say_error_in_my_array_how/", "subreddit_subscribers": 700634, "created_utc": 1693318546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm a simple man with simple needs.  I'm on a 5 bay Drobo S (yes its like 15 years old) and I really just want a file storage system with redundancy similar to Drobo's with 2 disk failure backup and the ability to upgrade drives without fuss.  Oh, and network capability which the Drobo didn't have.\n\nLiterally just the ability to access a drive path and add/remove files is my baseline, with no additional needs.\n\nDoes this exist?  Plug and pray minimalism is ideal.", "author_fullname": "t2_3zyfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating from Drobo, best no-fuss NAS solution with redundancy and easy drive upgrade?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1649ef5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693286633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a simple man with simple needs.  I&amp;#39;m on a 5 bay Drobo S (yes its like 15 years old) and I really just want a file storage system with redundancy similar to Drobo&amp;#39;s with 2 disk failure backup and the ability to upgrade drives without fuss.  Oh, and network capability which the Drobo didn&amp;#39;t have.&lt;/p&gt;\n\n&lt;p&gt;Literally just the ability to access a drive path and add/remove files is my baseline, with no additional needs.&lt;/p&gt;\n\n&lt;p&gt;Does this exist?  Plug and pray minimalism is ideal.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1649ef5", "is_robot_indexable": true, "report_reasons": null, "author": "pencock", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1649ef5/migrating_from_drobo_best_nofuss_nas_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1649ef5/migrating_from_drobo_best_nofuss_nas_solution/", "subreddit_subscribers": 700634, "created_utc": 1693286633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been thinking of building a Nas recently, and I have been wondering if it would make sense to have paired drives be 1SSD + 1HDD instead of 2HDD. The reasoning being that different storage mediums won't ever fail at the same time. Does this makes sense or should I just di HDDs?", "author_fullname": "t2_10rjio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about paired drives in a server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_164txq0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693342079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking of building a Nas recently, and I have been wondering if it would make sense to have paired drives be 1SSD + 1HDD instead of 2HDD. The reasoning being that different storage mediums won&amp;#39;t ever fail at the same time. Does this makes sense or should I just di HDDs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164txq0", "is_robot_indexable": true, "report_reasons": null, "author": "CirnoIzumi", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164txq0/question_about_paired_drives_in_a_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164txq0/question_about_paired_drives_in_a_server/", "subreddit_subscribers": 700634, "created_utc": 1693342079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I am creating an application on Plant Analysis and disease detection. Is there any specific dataset that is available where I can get ALL Plant Identification, ALL Disease Detection and ALL Plant Description (after identification)? \n\nI have found multiple datasets online but they are all in portions, resulting in me having to do data cleaning which is quite time consuming. \n\nIt would be of great help if anyone knows or has a source for an all in one type dataset.", "author_fullname": "t2_75dck8dj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataset on Plant Identification, Disease Detection &amp; Plant Description", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164rgsj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693336547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am creating an application on Plant Analysis and disease detection. Is there any specific dataset that is available where I can get ALL Plant Identification, ALL Disease Detection and ALL Plant Description (after identification)? &lt;/p&gt;\n\n&lt;p&gt;I have found multiple datasets online but they are all in portions, resulting in me having to do data cleaning which is quite time consuming. &lt;/p&gt;\n\n&lt;p&gt;It would be of great help if anyone knows or has a source for an all in one type dataset.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164rgsj", "is_robot_indexable": true, "report_reasons": null, "author": "aka1432", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164rgsj/dataset_on_plant_identification_disease_detection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164rgsj/dataset_on_plant_identification_disease_detection/", "subreddit_subscribers": 700634, "created_utc": 1693336547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello :)\n\nI have 6 WD Elements 14tb drives plugged on my Nuc i7 , my OS is Windows 10.\n\n&amp;#x200B;\n\nMy drives never go to sleep, and I can't find anyway to make them so.\n\nWD Utilities doesn't recognise them so I can't change any settings, time to sleep or led blinking....\n\n&amp;#x200B;\n\nAny help would be much appreciated :)", "author_fullname": "t2_1481h9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to make WD Elements 14tb drives to sleep?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164gitw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693310438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello :)&lt;/p&gt;\n\n&lt;p&gt;I have 6 WD Elements 14tb drives plugged on my Nuc i7 , my OS is Windows 10.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My drives never go to sleep, and I can&amp;#39;t find anyway to make them so.&lt;/p&gt;\n\n&lt;p&gt;WD Utilities doesn&amp;#39;t recognise them so I can&amp;#39;t change any settings, time to sleep or led blinking....&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any help would be much appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164gitw", "is_robot_indexable": true, "report_reasons": null, "author": "tangsgod", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164gitw/how_to_make_wd_elements_14tb_drives_to_sleep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164gitw/how_to_make_wd_elements_14tb_drives_to_sleep/", "subreddit_subscribers": 700634, "created_utc": 1693310438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone !\n\nI am thinking about building a NAS with quite some storage.\n\nLooking around here, I couldn't find a megathread or updated information about good practices when it comes to buying hard drives.\n\nI was wondering if there was a megathred somewhere, comparison webistes, etc. I heard about a few of them, but if they could be referenced in a central place (for example a pinned post), it could be seen by many and contributions/verifications could be easily done !\n\nLet me know what you think", "author_fullname": "t2_h6pb6ppc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Updated prices, comparison, megathread", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164cr60", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693298253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone !&lt;/p&gt;\n\n&lt;p&gt;I am thinking about building a NAS with quite some storage.&lt;/p&gt;\n\n&lt;p&gt;Looking around here, I couldn&amp;#39;t find a megathread or updated information about good practices when it comes to buying hard drives.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if there was a megathred somewhere, comparison webistes, etc. I heard about a few of them, but if they could be referenced in a central place (for example a pinned post), it could be seen by many and contributions/verifications could be easily done !&lt;/p&gt;\n\n&lt;p&gt;Let me know what you think&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "164cr60", "is_robot_indexable": true, "report_reasons": null, "author": "AntonioKarot", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164cr60/updated_prices_comparison_megathread/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164cr60/updated_prices_comparison_megathread/", "subreddit_subscribers": 700634, "created_utc": 1693298253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello friends of data hoarder! I come with a question that I was looking to get some opinions on:\nI am currently a film student, and often have to take projects home to edit them. I use my windows laptop to do so, and constantly need to go use my schools Apple Mac lab to export since my laptop isn\u2019t strong enough. \nThe issue with this, is that I need to have files on my hard drive, which is formatted for my windows laptop, and have an issue with being unable to use that hard drive on the Mac computers.\nShould i get a hard drive that is formatted for just macs and try to use both of them? Is there a hard drive out there that can do both data formats for me? I\u2019m looking for any advice or opinions I can get- as long as they aren\u2019t \u2018conform and buy a Mac laptop\u2019 because Im broke ;) \n\nThanks in advance! \n\nTL;DR: I have a hard drive formatted for windows and often need to use macs to edit footage, and am looking for advice of a solution to bridge this gap", "author_fullname": "t2_5ckxqxe8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for hard drive advice!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16407hg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693261633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello friends of data hoarder! I come with a question that I was looking to get some opinions on:\nI am currently a film student, and often have to take projects home to edit them. I use my windows laptop to do so, and constantly need to go use my schools Apple Mac lab to export since my laptop isn\u2019t strong enough. \nThe issue with this, is that I need to have files on my hard drive, which is formatted for my windows laptop, and have an issue with being unable to use that hard drive on the Mac computers.\nShould i get a hard drive that is formatted for just macs and try to use both of them? Is there a hard drive out there that can do both data formats for me? I\u2019m looking for any advice or opinions I can get- as long as they aren\u2019t \u2018conform and buy a Mac laptop\u2019 because Im broke ;) &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance! &lt;/p&gt;\n\n&lt;p&gt;TL;DR: I have a hard drive formatted for windows and often need to use macs to edit footage, and am looking for advice of a solution to bridge this gap&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16407hg", "is_robot_indexable": true, "report_reasons": null, "author": "miraclemileee", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16407hg/looking_for_hard_drive_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16407hg/looking_for_hard_drive_advice/", "subreddit_subscribers": 700634, "created_utc": 1693261633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I got a random BSOD and my HDD got somewhat corrupted ?, opening the drive a window popup appeared shows my drive is \"corrupted\", but after a quick scan with easeUS, it show that my files are still there, and i can even preview them, recover them to another drive. \n\nThe easy option is to have an extra 4TB drive to \"recover\" all the \"existing files\" to but i dont have that right now, is there anyway to rebuild and re-index these files, as they are already there and untouched? not even corrupted or anything. The BSOD did something that i cant seems to find any solution on the Google it only show bot-written articles, any help guys ?", "author_fullname": "t2_14ng5jfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HELP! HDD corrupted but files are still there.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164knoa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693320888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got a random BSOD and my HDD got somewhat corrupted ?, opening the drive a window popup appeared shows my drive is &amp;quot;corrupted&amp;quot;, but after a quick scan with easeUS, it show that my files are still there, and i can even preview them, recover them to another drive. &lt;/p&gt;\n\n&lt;p&gt;The easy option is to have an extra 4TB drive to &amp;quot;recover&amp;quot; all the &amp;quot;existing files&amp;quot; to but i dont have that right now, is there anyway to rebuild and re-index these files, as they are already there and untouched? not even corrupted or anything. The BSOD did something that i cant seems to find any solution on the Google it only show bot-written articles, any help guys ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164knoa", "is_robot_indexable": true, "report_reasons": null, "author": "chickifat", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164knoa/help_hdd_corrupted_but_files_are_still_there/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164knoa/help_hdd_corrupted_but_files_are_still_there/", "subreddit_subscribers": 700634, "created_utc": 1693320888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Howdy folks. My storage needs (wants I guess, technically...) on my gaming machine are growing. I record a lot of footage from my gaming (DCS, flight sim, mostly so it takes a lot of footage to get the little pieces I actually want to edit/share). Currently only recording in 2k but eventually it'll be 4k when I either get super resolution to work properly or I upgrade to a 4k monitor. With the amount of stuff I record, I have to clear it out more often than I want to, in order to avoid filling up my backup drive. My backup scheme is maybe a little aggressive or inefficient, I can go into detail on that if needed.\n\nGaming machine storage:\n\n3 2TB 980 Pros (I have checked/updated the firmware!)\n\n1 4TB Teamgroup PCIE 3.0 (to be added soon)\n\n1 8TB SATA HDD. Can't remember the brand. Write performance and noise are okay. But not enough space to do backups and have versioning.\n\nSo my question is - what drive in the 12-20TB capacity range would you guys recommend? My gaming machine sits on top of my desk, right next to where I am sitting. So something with lower noise would be nice. The drives in my NAS are definitely not quiet (so it's hidden away in the back room), so I probably will want to avoid NAS/Enterprise drives if at all possible. My case only has room for 1 3.5\" drive at a time, so I would have to go with a single drive, or do an external enclosure.\n\nMy other thought is - buy a number of SATA SSD's since my case has the room and set them up in a RAID (even if it's RAID 0). Is it wise/okay to use SSD's as a backup destination? Bearing in mind that they would not be my only backup, the backups are synced to my NAS and off site as well. And everything important to me is in cloud storage as well (Nextcloud or GDrive).\n\nSide note - once I get another server to move some virtualization over to, I am going to have a central Veeam community instance. Is it possible for me to have a local backup job on my computer, and also have those backups go to the central repo? Or would I need to keep my current setup of local backup + Syncthing?\n\nSummary: I record more gaming footage than is reasonable. I want to make sure I have enough backups. Is there a reasonably quiet 12-20TB hard drive?", "author_fullname": "t2_66k5u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hard drive advice - backup drive for my gaming PC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164k5uo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693319712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Howdy folks. My storage needs (wants I guess, technically...) on my gaming machine are growing. I record a lot of footage from my gaming (DCS, flight sim, mostly so it takes a lot of footage to get the little pieces I actually want to edit/share). Currently only recording in 2k but eventually it&amp;#39;ll be 4k when I either get super resolution to work properly or I upgrade to a 4k monitor. With the amount of stuff I record, I have to clear it out more often than I want to, in order to avoid filling up my backup drive. My backup scheme is maybe a little aggressive or inefficient, I can go into detail on that if needed.&lt;/p&gt;\n\n&lt;p&gt;Gaming machine storage:&lt;/p&gt;\n\n&lt;p&gt;3 2TB 980 Pros (I have checked/updated the firmware!)&lt;/p&gt;\n\n&lt;p&gt;1 4TB Teamgroup PCIE 3.0 (to be added soon)&lt;/p&gt;\n\n&lt;p&gt;1 8TB SATA HDD. Can&amp;#39;t remember the brand. Write performance and noise are okay. But not enough space to do backups and have versioning.&lt;/p&gt;\n\n&lt;p&gt;So my question is - what drive in the 12-20TB capacity range would you guys recommend? My gaming machine sits on top of my desk, right next to where I am sitting. So something with lower noise would be nice. The drives in my NAS are definitely not quiet (so it&amp;#39;s hidden away in the back room), so I probably will want to avoid NAS/Enterprise drives if at all possible. My case only has room for 1 3.5&amp;quot; drive at a time, so I would have to go with a single drive, or do an external enclosure.&lt;/p&gt;\n\n&lt;p&gt;My other thought is - buy a number of SATA SSD&amp;#39;s since my case has the room and set them up in a RAID (even if it&amp;#39;s RAID 0). Is it wise/okay to use SSD&amp;#39;s as a backup destination? Bearing in mind that they would not be my only backup, the backups are synced to my NAS and off site as well. And everything important to me is in cloud storage as well (Nextcloud or GDrive).&lt;/p&gt;\n\n&lt;p&gt;Side note - once I get another server to move some virtualization over to, I am going to have a central Veeam community instance. Is it possible for me to have a local backup job on my computer, and also have those backups go to the central repo? Or would I need to keep my current setup of local backup + Syncthing?&lt;/p&gt;\n\n&lt;p&gt;Summary: I record more gaming footage than is reasonable. I want to make sure I have enough backups. Is there a reasonably quiet 12-20TB hard drive?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164k5uo", "is_robot_indexable": true, "report_reasons": null, "author": "Bagellord", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164k5uo/hard_drive_advice_backup_drive_for_my_gaming_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164k5uo/hard_drive_advice_backup_drive_for_my_gaming_pc/", "subreddit_subscribers": 700634, "created_utc": 1693319712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm really short on storage recently, i wanted to install one more ssd but found out that i have no SATA cables left, only SATA power cables. What do i do? My psu isnt modular (Be quiet system power 10). It says it has 6 SATA cables but i see only 2, rest are power cables.", "author_fullname": "t2_dfwa0gxf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ran out of SSD SATA cables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164aysg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.13, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693291951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m really short on storage recently, i wanted to install one more ssd but found out that i have no SATA cables left, only SATA power cables. What do i do? My psu isnt modular (Be quiet system power 10). It says it has 6 SATA cables but i see only 2, rest are power cables.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164aysg", "is_robot_indexable": true, "report_reasons": null, "author": "CartographerGold934", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164aysg/ran_out_of_ssd_sata_cables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164aysg/ran_out_of_ssd_sata_cables/", "subreddit_subscribers": 700634, "created_utc": 1693291951.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}