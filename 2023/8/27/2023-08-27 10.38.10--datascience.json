{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve had dozens of interviews over the past 6 months and nobody has asked a single tech question or done a technical assessment. I think I\u2019ve got to the final round 6 times without any offers.\n\nWhat was the point of learning data science if employers are just going to judge me based on what spirit animal I would be or where I see myself in 10 years?\n\nIs it just who I\u2019ve been interviewing with or is this an overall theme?", "author_fullname": "t2_4q04yojj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why does nobody ask technical questions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1627l75", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 82, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 82, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693086078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve had dozens of interviews over the past 6 months and nobody has asked a single tech question or done a technical assessment. I think I\u2019ve got to the final round 6 times without any offers.&lt;/p&gt;\n\n&lt;p&gt;What was the point of learning data science if employers are just going to judge me based on what spirit animal I would be or where I see myself in 10 years?&lt;/p&gt;\n\n&lt;p&gt;Is it just who I\u2019ve been interviewing with or is this an overall theme?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1627l75", "is_robot_indexable": true, "report_reasons": null, "author": "CyHawkNerd", "discussion_type": null, "num_comments": 73, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1627l75/why_does_nobody_ask_technical_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1627l75/why_does_nobody_ask_technical_questions/", "subreddit_subscribers": 1016419, "created_utc": 1693086078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are the worst questions you\u2019ve ever been asked in an interview? \n\nI had the worst interview of my life this week. So bad that I removed myself from consideration. It was with the CEO and the first three rounds of interviews went very well. These three questions were asked in this order:\n\n1. \u201cWhat is the hardest thing you\u2019ve ever had to do?\u201d\n2. \u201cI\u2019m not searching for a specific answer, but what is the second hardest thing you\u2019ve ever had to do?\u201d\n3. Put yourself in your manager\u2019s shoes and give me three reasons why you don\u2019t deserve a promotion. \n\nMan, what a weird set of questions.", "author_fullname": "t2_g7gx7tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Worst Interview Questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162ckok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 65, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 65, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693098785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the worst questions you\u2019ve ever been asked in an interview? &lt;/p&gt;\n\n&lt;p&gt;I had the worst interview of my life this week. So bad that I removed myself from consideration. It was with the CEO and the first three rounds of interviews went very well. These three questions were asked in this order:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;\u201cWhat is the hardest thing you\u2019ve ever had to do?\u201d&lt;/li&gt;\n&lt;li&gt;\u201cI\u2019m not searching for a specific answer, but what is the second hardest thing you\u2019ve ever had to do?\u201d&lt;/li&gt;\n&lt;li&gt;Put yourself in your manager\u2019s shoes and give me three reasons why you don\u2019t deserve a promotion. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Man, what a weird set of questions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162ckok", "is_robot_indexable": true, "report_reasons": null, "author": "jt97suu", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162ckok/worst_interview_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162ckok/worst_interview_questions/", "subreddit_subscribers": 1016419, "created_utc": 1693098785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I inherited a large model code base that basically forecasts the contact volume across many languages-regions. It basically creates unique RidgeCV regression models for each market trained on the last 2-3 years of data and spits out a predicted contact volume at different time horizons. The stakeholders then use the outputs of the model as a baseline upon which they apply business logic, e.g. new product launches, predicted customer growth etc, to come up with a final contact volume upon which business decisions are made.\n\nSome of my stakeholders who consume the data from this model have said that the accuracy is low (MAPE \\~20-30% with larger markets being more accurate), and that the model swings unexpectedly and they have no insight as to why it does.\n\nUnfortunately, we will not be rebuilding the model as we calculated the opportunity size for improving the accuracy to be not worth the time it would take, and there are more impactful projects in other departments that I am going to be focussing on.\n\nI don't want to leave them completely hanging, as it is a major pain point for them, so one thing I am thinking about doing to make their lives easier is to create a dashboard that can list out something along the lines of feature importances at the per-model level. This would allow them to see the drivers for when each model predicts a large variation in contact volume. I was thinking either listing out the feature weights since it is a linear model, or using Shapley values. But I would love some feedback from people who have built these kinds of things before on what would actually be useful on a dashboard like this?\n\nNote: I am NOT an MLE, my DS career has had a heavier emphasis on the DE, Experimentation, and Analytics with limited modeling work.\n\nedit: Error was incorrect, it's \\~20-30% not 70-80%. I had mixed it up with the stakeholders use of \"70-80% accuracy\"", "author_fullname": "t2_fhys02p7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for Model Explainability for End Consumers of a Demand Forecasting Model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1620x1a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693086199.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693070294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I inherited a large model code base that basically forecasts the contact volume across many languages-regions. It basically creates unique RidgeCV regression models for each market trained on the last 2-3 years of data and spits out a predicted contact volume at different time horizons. The stakeholders then use the outputs of the model as a baseline upon which they apply business logic, e.g. new product launches, predicted customer growth etc, to come up with a final contact volume upon which business decisions are made.&lt;/p&gt;\n\n&lt;p&gt;Some of my stakeholders who consume the data from this model have said that the accuracy is low (MAPE ~20-30% with larger markets being more accurate), and that the model swings unexpectedly and they have no insight as to why it does.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, we will not be rebuilding the model as we calculated the opportunity size for improving the accuracy to be not worth the time it would take, and there are more impactful projects in other departments that I am going to be focussing on.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to leave them completely hanging, as it is a major pain point for them, so one thing I am thinking about doing to make their lives easier is to create a dashboard that can list out something along the lines of feature importances at the per-model level. This would allow them to see the drivers for when each model predicts a large variation in contact volume. I was thinking either listing out the feature weights since it is a linear model, or using Shapley values. But I would love some feedback from people who have built these kinds of things before on what would actually be useful on a dashboard like this?&lt;/p&gt;\n\n&lt;p&gt;Note: I am NOT an MLE, my DS career has had a heavier emphasis on the DE, Experimentation, and Analytics with limited modeling work.&lt;/p&gt;\n\n&lt;p&gt;edit: Error was incorrect, it&amp;#39;s ~20-30% not 70-80%. I had mixed it up with the stakeholders use of &amp;quot;70-80% accuracy&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1620x1a", "is_robot_indexable": true, "report_reasons": null, "author": "Moldy-Tangelo", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1620x1a/ideas_for_model_explainability_for_end_consumers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1620x1a/ideas_for_model_explainability_for_end_consumers/", "subreddit_subscribers": 1016419, "created_utc": 1693070294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\\[Not sure if this breaking any rule or not, if it is, my apologies in advance\\]\n\nI am preparing for entry level position or internship position for Data Science/Machine Learning in the industry, is there a collection for such questions to prepare beforehand? Especially keeping with the fast changing industry standard?", "author_fullname": "t2_7lqv45ds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview questions for preparation for entry level position for Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1628bpa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693087824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[Not sure if this breaking any rule or not, if it is, my apologies in advance]&lt;/p&gt;\n\n&lt;p&gt;I am preparing for entry level position or internship position for Data Science/Machine Learning in the industry, is there a collection for such questions to prepare beforehand? Especially keeping with the fast changing industry standard?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1628bpa", "is_robot_indexable": true, "report_reasons": null, "author": "SmartPuppyy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1628bpa/interview_questions_for_preparation_for_entry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1628bpa/interview_questions_for_preparation_for_entry/", "subreddit_subscribers": 1016419, "created_utc": 1693087824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I often find myself in conversation with people with little-to-no understanding of IT in general, and less of data science.\n\nI work as a data scientist that mostly have to do a lot of BA bullshit like speaking with stakeholders. I probably spend 75 percent of my time in meetings with internal stakeholders. \n\nMy trouble is that I sort of start out explaining what machine learning is and how we use statistical models to do X and Y for the company then explaining how I actually not do that for most of my time, seeing the life actually leaving the persons body so I just end up saying something along the lines of \u201cI press buttons and the computer goes brrr.\u201d\n\nHow do you guys handle these situations?\nKind regards\nSocially awkward data scientist", "author_fullname": "t2_g381bacdm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you tell people you do for a living?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162ioz4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693117621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I often find myself in conversation with people with little-to-no understanding of IT in general, and less of data science.&lt;/p&gt;\n\n&lt;p&gt;I work as a data scientist that mostly have to do a lot of BA bullshit like speaking with stakeholders. I probably spend 75 percent of my time in meetings with internal stakeholders. &lt;/p&gt;\n\n&lt;p&gt;My trouble is that I sort of start out explaining what machine learning is and how we use statistical models to do X and Y for the company then explaining how I actually not do that for most of my time, seeing the life actually leaving the persons body so I just end up saying something along the lines of \u201cI press buttons and the computer goes brrr.\u201d&lt;/p&gt;\n\n&lt;p&gt;How do you guys handle these situations?\nKind regards\nSocially awkward data scientist&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162ioz4", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_Belaja", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162ioz4/what_do_you_tell_people_you_do_for_a_living/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162ioz4/what_do_you_tell_people_you_do_for_a_living/", "subreddit_subscribers": 1016419, "created_utc": 1693117621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Streamlining your data visualization journey with Python's popular library\n\n[ Photo Credit: Created by Author, Canva  ](https://preview.redd.it/7mc9f945zfkb1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=e2cfe38d1ddea91e3d551b74b0d6964cac90d4a1)\n\nThis article aims to introduce the objects interface feature in [Seaborn 0.12](https://seaborn.pydata.org/whatsnew/index.html?ref=dataleadsfuture.com#v0-12), including the concept of declarative graphic syntax, and a practical visualization project to showcase the usage of the objects interface.\n\nBy the end of this article, you'll have a clear understanding of the advantages and limitations of [Seaborn's objects interface API](https://seaborn.pydata.org/tutorial/objects_interface.html?ref=dataleadsfuture.com). And you will be able to use Seaborn for data analysis projects more easily.\n\n## Introduction\n\nRemember that joke about a programmer?\n\nHe was heading to the grocery store, and his wife told him, \"Buy a bottle of milk, and if they have eggs, buy 12.\"\n\nSo, he came home with 12 bottles of milk because they had eggs.\n\nThis is the problem with imperative programming\u2014it executes your instructions to the letter, without understanding your intent.\n\nNow, imagine you're creating a data visualization chart using Python.\n\nYou have to instruct the computer every step of the way: select a dataset, create a figure, set the color, add labels, adjust the size, etc...\n\nThen you realize your code is getting longer and more complex, and all you wanted was to quickly visualize your data.\n\nIt's like going to the grocery store and having to specify every item's location, color, size, and shape, instead of just telling the shop assistant what you need.\n\nNot only is this time-consuming, but it can also feel tiring.\n\nHowever, Seaborn 0.12's new feature\u2014the objects interface\u2014and its use of declarative graphic syntax is like having a shop assistant who understands you. You just need to tell it what you need to do, and it will find everything for you.\n\nYou no longer need to instruct it every step of the way. You just need to tell it what kind of result you want.\n\nIn this article, I'll guide you through using the objects interface, this new feature that makes your data visualization process more effortless, flexible, and enjoyable. Let's get started!\n\n## Why Declarative Graphic Syntax?\n\nLet's consider the salad-making process to illustrate the difference between traditional and declarative graphic syntax.\n\nIn the traditional approach, you're providing a detailed recipe, telling the chef each step, for example:\n\n1. Get a bowl.\n2. Put lettuce in it.\n3. Cut some cherry tomatoes and add them.\n4. Add some cucumber slices.\n5. Sprinkle some sesame seeds.\n6. Finally, drizzle with your favorite dressing.\n\nEven for a simple salad, you must specify each step in detail.\n\nIn contrast, declarative graphic syntax is more like telling the chef what kind of salad you want, rather than how to make it.\n\nFor instance, you might say, \"I want a salad with lettuce, tomatoes, cucumber, and sesame seeds.\"\n\nThe chef knows how to handle each ingredient without requiring step-by-step instructions.\n\nSimilarly, when using Seaborn's objects interface with its declarative syntax to create a visualization, we specify what we want (a histogram showing a variable's distribution in a given dataset), not how to get there.\n\nThis approach makes the code more concise and easier to understand, enhancing programming flexibility and efficiency.\n\n## Seaborn API: Then and Now\n\nBefore diving into the objects interface API, let's systematically look at the differences between the Seaborn API of earlier versions and the 0.12 version.\n\n## The original API\n\nMany readers might have been intimidated by Matplotlib's complex API documentation when learning Python data visualization.\n\nSeaborn simplifies this by wrapping and streamlining Matplotlib's API, making the learning curve gentler.\n\nSeaborn doesn't just offer high-level encapsulation of Matplotlib; it also categorizes all charts into relational, distributional, and categorical scenarios.\n\n[ Overview of Seaborn's original API design. Image by Author ](https://preview.redd.it/ajcy9e99zfkb1.png?width=741&amp;format=png&amp;auto=webp&amp;s=e0a6794876d4e4a7febdb987226a359f1c3a5e20)\n\nYou should comprehensively understand Seaborn's API through this diagram and know when to use which chart.\n\nFor example, a histplot representing data distribution would fall under the distribution chart category.\n\nIn contrast, a violinplot representing data features by category would be classified as a categorical chart.\n\nAside from vertical categorization, Seaborn also performs horizontal categorization: Figure-level and axes-level.\n\nAccording to the [official website](https://seaborn.pydata.org/tutorial/function_overview.html?ref=dataleadsfuture.com#figure-level-vs-axes-level-functions), axes-level charts are drawn on matplotlib.pyplot.axes and can only draw one figure.\n\nIn contrast, Figure-level charts use Matplotlib's FacetGrid to draw multiple charts in one figure, facilitating easy comparison of similar data dimensions.\n\nHowever, even though Seaborn's API significantly simplifies chart drawing through encapsulating Matplotlib, creating an individual-specific chart still requires complex configurations.\n\nFor example, if I use Seaborn's built-in penguins dataset to draw a histplot, the code is as follows:\n\n    sns.histplot(penguins, x=\"flipper_length_mm\", hue=\"species\");\n\n[ The original way of drawing a histplot. Image by Author ](https://preview.redd.it/z3ubpaufzfkb1.png?width=566&amp;format=png&amp;auto=webp&amp;s=a33bf9df8e83b18cb35ab90822858ebb95bd95c2)\n\nAnd when I use the same dataset to draw a kdeplot, the code is as follows:\n\n    sns.kdeplot(penguins, x=\"flipper_length_mm\", fill=True, hue=\"species\");\n\n[ The original way of drawing a kdeplot. Image by Author ](https://preview.redd.it/ufs151akzfkb1.png?width=588&amp;format=png&amp;auto=webp&amp;s=f8f93006ad7fcf7534e81ac88cfe3d470f8c20dd)\n\nExcept for the chart API, the rest of the configurations are identical.\n\nThis is like telling the chef I want to use lamb chops and onions to make a lamb soup and specifying the cooking steps. When I want to use these ingredients to make a roasted lamb chop, I have to tell the chef about the ingredients and the cooking steps all over again.\n\nNot only is it inefficient, but it also needs more flexibility.\n\nThat's why Seaborn introduced the objects interface API in its 0.12 version. This declarative graphic syntax dramatically improves the process of creating a chart.\n\n## The objects Interface API\n\nBefore we start with the objects interface API, let's take a high-level look at it to better understand the drawing process.\n\nUnlike the original Seaborn API, which organizes the drawing API by classification, the objects interface API collects the API by a drawing pipeline.\n\nThe objects interface API divides the drawing into multiple stages, such as data binding, layout, presentation, customization, etc.\n\n[ Overview of Seaborn's objects interface API design. Image by Author ](https://preview.redd.it/jdkazetmzfkb1.png?width=899&amp;format=png&amp;auto=webp&amp;s=21b59c646f0365f5ccffb40b7bb0015a1975c23e)\n\nThe data binding and presentation stages are necessary, while other stages are optional.\n\nAlso, since the stages are independent, each stage can be reused. Following the previous example of the hist and kde plots:\n\nTo use the objects interface to draw, we first need to bind the data:\n\n    p = so.Plot(penguins, x=\"flipper_length_mm\", color=\"species\")\n\nFrom this line of code, we can see that the objects interface uses the so.Plot class for data binding.\n\nAlso, compared to the original API that uses the incomprehensible hue parameter, it uses the color parameter to bind the species dimension directly to the chart color, making the configuration more intuitive.\n\nFinally, this line of code returns a p instance that can be reused to draw a chart.\n\nNext, let's draw a histplot:\n\n    p.add(so.Bars(), so.Hist())\n\n[ Use objects interface API to draw a histplot. Image by Author ](https://preview.redd.it/otseb0utzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=0d19226419a136f1042faa6bd67754a891ae7b6a)\n\nThis line of code shows that the drawing stage does not need to rebind the data. We just need to tell the addmethod what to draw: so.Bars(), and how to calculate it: so.Hist().\n\nThe add method also returns a copy of the Plot instance, so any adjustments in the add method will not affect the original data binding. The p instance can still be reused.\n\nTherefore, we continue to call the p.add() method to draw a kdeplot:\n\n    p.add(so.Area(), so.KDE())\n\n[ Use objects interface API to draw a kdeplot. Image by Author ](https://preview.redd.it/tjaegaiyzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=8d35e9fd209c9a2004c5496f45c489aa67202e89)\n\nSince KDE is a way of statistic, so.KDE() is called on the stat parameter here. And since the kdeplot itself is an area plot, so.Area() is used for drawing.\n\nWe reused the p instance bound to the data, so there is no need to tell the chef how to cook each dish, but to directly say what we want. Isn't it much more concise and flexible?\n\nThis article was originally published on my personal blog [Data Leads Future](https://www.dataleadsfuture.com/seaborn-0-12-an-insightful-guide-to-the-objects-interface-and-declarative-graphics/).", "author_fullname": "t2_9r8ft2a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seaborn 0.12: An Insightful Guide to the Objects Interface and Declarative Graphics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jdkazetmzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 34, "x": 108, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8a1c79aaa8209286897009af6b8fe6d6023a94ba"}, {"y": 68, "x": 216, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=036f43099ad78132ba3bbbdbd2eab2d3d571e650"}, {"y": 102, "x": 320, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b400a489bf1caa71e186b76d8abab5d22a22822d"}, {"y": 204, "x": 640, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=63255828bab9bdd13bc317a9d9882676388af0a8"}], "s": {"y": 287, "x": 899, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=899&amp;format=png&amp;auto=webp&amp;s=21b59c646f0365f5ccffb40b7bb0015a1975c23e"}, "id": "jdkazetmzfkb1"}, "7mc9f945zfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=70ba39e64584a7a4f8a9d7fe01787e7f41ff214e"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3681ced759d7b2cac2379d8aa0f3ba859ea227c"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=49edb457688deff44b86bc4064427b2005382aec"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e1e2115ab9aab2c42217dda0f4b65aeefc18fdec"}, {"y": 639, "x": 960, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5883a021a3863c01d5bf06352e3f39c244601492"}, {"y": 719, "x": 1080, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fa2d349e5289a02100631eff932dc09d7b03af8e"}], "s": {"y": 959, "x": 1440, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=e2cfe38d1ddea91e3d551b74b0d6964cac90d4a1"}, "id": "7mc9f945zfkb1"}, "ufs151akzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=47aa5cc59119e12d70dd8082aa77b3f9b613649b"}, {"y": 160, "x": 216, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b329c29a2969bb8d4ea74e6c234cf56a8071f424"}, {"y": 237, "x": 320, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1d742ff677c4e9eb3d364e3ac69c533d136d9a8"}], "s": {"y": 437, "x": 588, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=588&amp;format=png&amp;auto=webp&amp;s=f8f93006ad7fcf7534e81ac88cfe3d470f8c20dd"}, "id": "ufs151akzfkb1"}, "z3ubpaufzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 83, "x": 108, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fd655c9ef8b03e51256976cc2115c4eaad57c6e3"}, {"y": 166, "x": 216, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1ab3edfaa3283b1117d0ae3d10bfbc68ac64c22"}, {"y": 247, "x": 320, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3ac3fee91bdca1fbf6a919ca817995501b781774"}], "s": {"y": 437, "x": 566, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=566&amp;format=png&amp;auto=webp&amp;s=a33bf9df8e83b18cb35ab90822858ebb95bd95c2"}, "id": "z3ubpaufzfkb1"}, "otseb0utzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ff67695c30da82344330de221f8b6d1c02e416c"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8b4135abb4f0fb34b799b303b0c991fe62ae21d1"}, {"y": 196, "x": 320, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e3ab322b3be6edd12b92c27484ffea35336e1d32"}, {"y": 392, "x": 640, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2b62c3ad6ca6bd36db936b0f571848cff05e5849"}, {"y": 588, "x": 960, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6527a4224acd02a5e11a5850d49b400c5bc4860"}, {"y": 661, "x": 1080, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=981a36ab971d06f701cdb8dff853676a3afa6c92"}], "s": {"y": 890, "x": 1453, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=0d19226419a136f1042faa6bd67754a891ae7b6a"}, "id": "otseb0utzfkb1"}, "tjaegaiyzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=402545adec6758cd1ecedb0cd6e9e2c2d95d1901"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=66959f2ca43e2b3faaa511d12e028fc17887fb8b"}, {"y": 196, "x": 320, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d55b3c4ca08d4d16c2ff93a41d1b004f1a214cd5"}, {"y": 392, "x": 640, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d0d2e477c3139ade726d2666842e0e569ecf2272"}, {"y": 588, "x": 960, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=edfc63ad503512d6b81c7a99c80c592684a1bbce"}, {"y": 661, "x": 1080, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=224e924131ef5654821ea8191d11ac42c494b64c"}], "s": {"y": 890, "x": 1453, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=8d35e9fd209c9a2004c5496f45c489aa67202e89"}, "id": "tjaegaiyzfkb1"}, "ajcy9e99zfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 70, "x": 108, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3bdd77020d14a0736156a9f930124b73c1f1bf4a"}, {"y": 141, "x": 216, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fdb95df8bcebb767c507c6e0e36ac459b510fb45"}, {"y": 210, "x": 320, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5094fd4de54cee0e2b6b58aa1de353e59865a1b6"}, {"y": 420, "x": 640, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b55bab4eeb2005bd9381423915d5edb6969d0f5c"}], "s": {"y": 487, "x": 741, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=741&amp;format=png&amp;auto=webp&amp;s=e0a6794876d4e4a7febdb987226a359f1c3a5e20"}, "id": "ajcy9e99zfkb1"}}, "name": "t3_161t22b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mD7sAGXVRAtCoqB5yQQShnqAKM4diaNaW9hrfwSjqIs.jpg", "edited": 1693055052.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693050410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Streamlining your data visualization journey with Python&amp;#39;s popular library&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7mc9f945zfkb1.png?width=1440&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e2cfe38d1ddea91e3d551b74b0d6964cac90d4a1\"&gt; Photo Credit: Created by Author, Canva  &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This article aims to introduce the objects interface feature in &lt;a href=\"https://seaborn.pydata.org/whatsnew/index.html?ref=dataleadsfuture.com#v0-12\"&gt;Seaborn 0.12&lt;/a&gt;, including the concept of declarative graphic syntax, and a practical visualization project to showcase the usage of the objects interface.&lt;/p&gt;\n\n&lt;p&gt;By the end of this article, you&amp;#39;ll have a clear understanding of the advantages and limitations of &lt;a href=\"https://seaborn.pydata.org/tutorial/objects_interface.html?ref=dataleadsfuture.com\"&gt;Seaborn&amp;#39;s objects interface API&lt;/a&gt;. And you will be able to use Seaborn for data analysis projects more easily.&lt;/p&gt;\n\n&lt;h2&gt;Introduction&lt;/h2&gt;\n\n&lt;p&gt;Remember that joke about a programmer?&lt;/p&gt;\n\n&lt;p&gt;He was heading to the grocery store, and his wife told him, &amp;quot;Buy a bottle of milk, and if they have eggs, buy 12.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;So, he came home with 12 bottles of milk because they had eggs.&lt;/p&gt;\n\n&lt;p&gt;This is the problem with imperative programming\u2014it executes your instructions to the letter, without understanding your intent.&lt;/p&gt;\n\n&lt;p&gt;Now, imagine you&amp;#39;re creating a data visualization chart using Python.&lt;/p&gt;\n\n&lt;p&gt;You have to instruct the computer every step of the way: select a dataset, create a figure, set the color, add labels, adjust the size, etc...&lt;/p&gt;\n\n&lt;p&gt;Then you realize your code is getting longer and more complex, and all you wanted was to quickly visualize your data.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s like going to the grocery store and having to specify every item&amp;#39;s location, color, size, and shape, instead of just telling the shop assistant what you need.&lt;/p&gt;\n\n&lt;p&gt;Not only is this time-consuming, but it can also feel tiring.&lt;/p&gt;\n\n&lt;p&gt;However, Seaborn 0.12&amp;#39;s new feature\u2014the objects interface\u2014and its use of declarative graphic syntax is like having a shop assistant who understands you. You just need to tell it what you need to do, and it will find everything for you.&lt;/p&gt;\n\n&lt;p&gt;You no longer need to instruct it every step of the way. You just need to tell it what kind of result you want.&lt;/p&gt;\n\n&lt;p&gt;In this article, I&amp;#39;ll guide you through using the objects interface, this new feature that makes your data visualization process more effortless, flexible, and enjoyable. Let&amp;#39;s get started!&lt;/p&gt;\n\n&lt;h2&gt;Why Declarative Graphic Syntax?&lt;/h2&gt;\n\n&lt;p&gt;Let&amp;#39;s consider the salad-making process to illustrate the difference between traditional and declarative graphic syntax.&lt;/p&gt;\n\n&lt;p&gt;In the traditional approach, you&amp;#39;re providing a detailed recipe, telling the chef each step, for example:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Get a bowl.&lt;/li&gt;\n&lt;li&gt;Put lettuce in it.&lt;/li&gt;\n&lt;li&gt;Cut some cherry tomatoes and add them.&lt;/li&gt;\n&lt;li&gt;Add some cucumber slices.&lt;/li&gt;\n&lt;li&gt;Sprinkle some sesame seeds.&lt;/li&gt;\n&lt;li&gt;Finally, drizzle with your favorite dressing.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Even for a simple salad, you must specify each step in detail.&lt;/p&gt;\n\n&lt;p&gt;In contrast, declarative graphic syntax is more like telling the chef what kind of salad you want, rather than how to make it.&lt;/p&gt;\n\n&lt;p&gt;For instance, you might say, &amp;quot;I want a salad with lettuce, tomatoes, cucumber, and sesame seeds.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The chef knows how to handle each ingredient without requiring step-by-step instructions.&lt;/p&gt;\n\n&lt;p&gt;Similarly, when using Seaborn&amp;#39;s objects interface with its declarative syntax to create a visualization, we specify what we want (a histogram showing a variable&amp;#39;s distribution in a given dataset), not how to get there.&lt;/p&gt;\n\n&lt;p&gt;This approach makes the code more concise and easier to understand, enhancing programming flexibility and efficiency.&lt;/p&gt;\n\n&lt;h2&gt;Seaborn API: Then and Now&lt;/h2&gt;\n\n&lt;p&gt;Before diving into the objects interface API, let&amp;#39;s systematically look at the differences between the Seaborn API of earlier versions and the 0.12 version.&lt;/p&gt;\n\n&lt;h2&gt;The original API&lt;/h2&gt;\n\n&lt;p&gt;Many readers might have been intimidated by Matplotlib&amp;#39;s complex API documentation when learning Python data visualization.&lt;/p&gt;\n\n&lt;p&gt;Seaborn simplifies this by wrapping and streamlining Matplotlib&amp;#39;s API, making the learning curve gentler.&lt;/p&gt;\n\n&lt;p&gt;Seaborn doesn&amp;#39;t just offer high-level encapsulation of Matplotlib; it also categorizes all charts into relational, distributional, and categorical scenarios.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ajcy9e99zfkb1.png?width=741&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e0a6794876d4e4a7febdb987226a359f1c3a5e20\"&gt; Overview of Seaborn&amp;#39;s original API design. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You should comprehensively understand Seaborn&amp;#39;s API through this diagram and know when to use which chart.&lt;/p&gt;\n\n&lt;p&gt;For example, a histplot representing data distribution would fall under the distribution chart category.&lt;/p&gt;\n\n&lt;p&gt;In contrast, a violinplot representing data features by category would be classified as a categorical chart.&lt;/p&gt;\n\n&lt;p&gt;Aside from vertical categorization, Seaborn also performs horizontal categorization: Figure-level and axes-level.&lt;/p&gt;\n\n&lt;p&gt;According to the &lt;a href=\"https://seaborn.pydata.org/tutorial/function_overview.html?ref=dataleadsfuture.com#figure-level-vs-axes-level-functions\"&gt;official website&lt;/a&gt;, axes-level charts are drawn on matplotlib.pyplot.axes and can only draw one figure.&lt;/p&gt;\n\n&lt;p&gt;In contrast, Figure-level charts use Matplotlib&amp;#39;s FacetGrid to draw multiple charts in one figure, facilitating easy comparison of similar data dimensions.&lt;/p&gt;\n\n&lt;p&gt;However, even though Seaborn&amp;#39;s API significantly simplifies chart drawing through encapsulating Matplotlib, creating an individual-specific chart still requires complex configurations.&lt;/p&gt;\n\n&lt;p&gt;For example, if I use Seaborn&amp;#39;s built-in penguins dataset to draw a histplot, the code is as follows:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;sns.histplot(penguins, x=&amp;quot;flipper_length_mm&amp;quot;, hue=&amp;quot;species&amp;quot;);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/z3ubpaufzfkb1.png?width=566&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a33bf9df8e83b18cb35ab90822858ebb95bd95c2\"&gt; The original way of drawing a histplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And when I use the same dataset to draw a kdeplot, the code is as follows:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;sns.kdeplot(penguins, x=&amp;quot;flipper_length_mm&amp;quot;, fill=True, hue=&amp;quot;species&amp;quot;);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ufs151akzfkb1.png?width=588&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f8f93006ad7fcf7534e81ac88cfe3d470f8c20dd\"&gt; The original way of drawing a kdeplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Except for the chart API, the rest of the configurations are identical.&lt;/p&gt;\n\n&lt;p&gt;This is like telling the chef I want to use lamb chops and onions to make a lamb soup and specifying the cooking steps. When I want to use these ingredients to make a roasted lamb chop, I have to tell the chef about the ingredients and the cooking steps all over again.&lt;/p&gt;\n\n&lt;p&gt;Not only is it inefficient, but it also needs more flexibility.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s why Seaborn introduced the objects interface API in its 0.12 version. This declarative graphic syntax dramatically improves the process of creating a chart.&lt;/p&gt;\n\n&lt;h2&gt;The objects Interface API&lt;/h2&gt;\n\n&lt;p&gt;Before we start with the objects interface API, let&amp;#39;s take a high-level look at it to better understand the drawing process.&lt;/p&gt;\n\n&lt;p&gt;Unlike the original Seaborn API, which organizes the drawing API by classification, the objects interface API collects the API by a drawing pipeline.&lt;/p&gt;\n\n&lt;p&gt;The objects interface API divides the drawing into multiple stages, such as data binding, layout, presentation, customization, etc.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jdkazetmzfkb1.png?width=899&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=21b59c646f0365f5ccffb40b7bb0015a1975c23e\"&gt; Overview of Seaborn&amp;#39;s objects interface API design. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The data binding and presentation stages are necessary, while other stages are optional.&lt;/p&gt;\n\n&lt;p&gt;Also, since the stages are independent, each stage can be reused. Following the previous example of the hist and kde plots:&lt;/p&gt;\n\n&lt;p&gt;To use the objects interface to draw, we first need to bind the data:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;p = so.Plot(penguins, x=&amp;quot;flipper_length_mm&amp;quot;, color=&amp;quot;species&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;From this line of code, we can see that the objects interface uses the so.Plot class for data binding.&lt;/p&gt;\n\n&lt;p&gt;Also, compared to the original API that uses the incomprehensible hue parameter, it uses the color parameter to bind the species dimension directly to the chart color, making the configuration more intuitive.&lt;/p&gt;\n\n&lt;p&gt;Finally, this line of code returns a p instance that can be reused to draw a chart.&lt;/p&gt;\n\n&lt;p&gt;Next, let&amp;#39;s draw a histplot:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;p.add(so.Bars(), so.Hist())\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/otseb0utzfkb1.png?width=1453&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0d19226419a136f1042faa6bd67754a891ae7b6a\"&gt; Use objects interface API to draw a histplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This line of code shows that the drawing stage does not need to rebind the data. We just need to tell the addmethod what to draw: so.Bars(), and how to calculate it: so.Hist().&lt;/p&gt;\n\n&lt;p&gt;The add method also returns a copy of the Plot instance, so any adjustments in the add method will not affect the original data binding. The p instance can still be reused.&lt;/p&gt;\n\n&lt;p&gt;Therefore, we continue to call the p.add() method to draw a kdeplot:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;p.add(so.Area(), so.KDE())\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tjaegaiyzfkb1.png?width=1453&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8d35e9fd209c9a2004c5496f45c489aa67202e89\"&gt; Use objects interface API to draw a kdeplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Since KDE is a way of statistic, so.KDE() is called on the stat parameter here. And since the kdeplot itself is an area plot, so.Area() is used for drawing.&lt;/p&gt;\n\n&lt;p&gt;We reused the p instance bound to the data, so there is no need to tell the chef how to cook each dish, but to directly say what we want. Isn&amp;#39;t it much more concise and flexible?&lt;/p&gt;\n\n&lt;p&gt;This article was originally published on my personal blog &lt;a href=\"https://www.dataleadsfuture.com/seaborn-0-12-an-insightful-guide-to-the-objects-interface-and-declarative-graphics/\"&gt;Data Leads Future&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161t22b", "is_robot_indexable": true, "report_reasons": null, "author": "qtalen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161t22b/seaborn_012_an_insightful_guide_to_the_objects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161t22b/seaborn_012_an_insightful_guide_to_the_objects/", "subreddit_subscribers": 1016419, "created_utc": 1693050410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Data Scientists or Data Analysts that work for shipping companies/ transportation companies. \n\nI know it's weirdly specific but I just want to ask. \n\nFor Data Scientists and Data Analysts who work for the above companies, what exactly do you do in your day to day job. \n\nHow often do you use SQL, Python, visualization tools etc? \n\nHow do often do you talk with colleagues from different departments and upper management.", "author_fullname": "t2_5hcl0uoj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientists and Data Analysts that work for shipping companies or transportation companies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162jmi9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693120879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Scientists or Data Analysts that work for shipping companies/ transportation companies. &lt;/p&gt;\n\n&lt;p&gt;I know it&amp;#39;s weirdly specific but I just want to ask. &lt;/p&gt;\n\n&lt;p&gt;For Data Scientists and Data Analysts who work for the above companies, what exactly do you do in your day to day job. &lt;/p&gt;\n\n&lt;p&gt;How often do you use SQL, Python, visualization tools etc? &lt;/p&gt;\n\n&lt;p&gt;How do often do you talk with colleagues from different departments and upper management.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162jmi9", "is_robot_indexable": true, "report_reasons": null, "author": "Large-Relationship37", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162jmi9/data_scientists_and_data_analysts_that_work_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162jmi9/data_scientists_and_data_analysts_that_work_for/", "subreddit_subscribers": 1016419, "created_utc": 1693120879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "With the advent of more and more dedicated advanced Data Science degrees, will PhD holders in \"general\" (non DS/ML/CS) areas stop being hired as DSs in the next few years?\n\nGiven the list of requirements I've seen on job listings, it appears that the times in which PhDs were hired due to their skills to learn and think analytically outside the box (if this ever was really a thing), are far in the past. It looks to me that, currently, even for entry-level jobs, the market favors people with the full stack of specific technical skills plus experience already under their arms. Put another way, freshly graduated PhDs are just not adecquate for entry-level jobs.\n\nApologies if the question isn't very well formulated. For context, I've noticed that some friends who recently finished their PhD (say math or physics) and are currently looking for DS roles, are pretty much being ignored by recruiters. What I'd like to understand is if this responds to global factors where everyone is being treated \"equally\" in difficult times, or if having a generalist PhD by itself is never gonna cut it again (if ever). Could online courses (not an online DS master!) still be relevant for these PhDs to get a job, or would PhD holders have to go back to school and do a DS master's should they decide to pursue this career for a lack of a better option?", "author_fullname": "t2_gajawaxj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will Data Science stop being a plan-B for generalist PhD holders?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162h8yh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693112668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the advent of more and more dedicated advanced Data Science degrees, will PhD holders in &amp;quot;general&amp;quot; (non DS/ML/CS) areas stop being hired as DSs in the next few years?&lt;/p&gt;\n\n&lt;p&gt;Given the list of requirements I&amp;#39;ve seen on job listings, it appears that the times in which PhDs were hired due to their skills to learn and think analytically outside the box (if this ever was really a thing), are far in the past. It looks to me that, currently, even for entry-level jobs, the market favors people with the full stack of specific technical skills plus experience already under their arms. Put another way, freshly graduated PhDs are just not adecquate for entry-level jobs.&lt;/p&gt;\n\n&lt;p&gt;Apologies if the question isn&amp;#39;t very well formulated. For context, I&amp;#39;ve noticed that some friends who recently finished their PhD (say math or physics) and are currently looking for DS roles, are pretty much being ignored by recruiters. What I&amp;#39;d like to understand is if this responds to global factors where everyone is being treated &amp;quot;equally&amp;quot; in difficult times, or if having a generalist PhD by itself is never gonna cut it again (if ever). Could online courses (not an online DS master!) still be relevant for these PhDs to get a job, or would PhD holders have to go back to school and do a DS master&amp;#39;s should they decide to pursue this career for a lack of a better option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162h8yh", "is_robot_indexable": true, "report_reasons": null, "author": "SincopaDisonante", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162h8yh/will_data_science_stop_being_a_planb_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162h8yh/will_data_science_stop_being_a_planb_for/", "subreddit_subscribers": 1016419, "created_utc": 1693112668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,  \nI'm recentrly working on a project about \"Functional Data Analysis\"  in the part of time series especially forecasting i found out that there's no package that deals with functional observations, the usual ARIMA models apply to univariate data only. \n\nAny ideas to help please ?", "author_fullname": "t2_7y59qi3hn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FAR and FARIMA model in python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161x071", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693060867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;br/&gt;\nI&amp;#39;m recentrly working on a project about &amp;quot;Functional Data Analysis&amp;quot;  in the part of time series especially forecasting i found out that there&amp;#39;s no package that deals with functional observations, the usual ARIMA models apply to univariate data only. &lt;/p&gt;\n\n&lt;p&gt;Any ideas to help please ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161x071", "is_robot_indexable": true, "report_reasons": null, "author": "Worth_Truth_8010", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161x071/far_and_farima_model_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161x071/far_and_farima_model_in_python/", "subreddit_subscribers": 1016419, "created_utc": 1693060867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So i am working as a junior data scientist in a financial company and i have been given a project to predict customers if they will invest in our bank or not. I have around 73 variables. These include demographic and their history on our banking app. I am currently using logistic and random forest but my model is giving very bad results on test data. Precision is 1 and recall is 0.\n\nThe train data is highly imbalanced so i am performing an undersampling technique where i take only those rows where the missing value count is less. According to my manager, i should have a higher recall and because this is my first project, i am kind of stuck in what more i can do. I have performed hyperparameter tuning but still the results on test data is very bad. \n\nTrain data: 97k for majority class and 25k for Minority\n\nTest data: 36M for majority class and 30k for Minority\n\nPlease let me know if you need more information in what i am doing or what i can do, any help is appreciated. ", "author_fullname": "t2_aohlpzsv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cant get my model right", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_162lxcw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693128995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i am working as a junior data scientist in a financial company and i have been given a project to predict customers if they will invest in our bank or not. I have around 73 variables. These include demographic and their history on our banking app. I am currently using logistic and random forest but my model is giving very bad results on test data. Precision is 1 and recall is 0.&lt;/p&gt;\n\n&lt;p&gt;The train data is highly imbalanced so i am performing an undersampling technique where i take only those rows where the missing value count is less. According to my manager, i should have a higher recall and because this is my first project, i am kind of stuck in what more i can do. I have performed hyperparameter tuning but still the results on test data is very bad. &lt;/p&gt;\n\n&lt;p&gt;Train data: 97k for majority class and 25k for Minority&lt;/p&gt;\n\n&lt;p&gt;Test data: 36M for majority class and 30k for Minority&lt;/p&gt;\n\n&lt;p&gt;Please let me know if you need more information in what i am doing or what i can do, any help is appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162lxcw", "is_robot_indexable": true, "report_reasons": null, "author": "LieTechnical1662", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162lxcw/cant_get_my_model_right/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162lxcw/cant_get_my_model_right/", "subreddit_subscribers": 1016419, "created_utc": 1693128995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data analysis: DAX vs Python (pandas,numby,mathplotlib)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162dlpb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_qdgsb1r1", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "learnpython", "selftext": "Hi! \nI\u2019m recently learning and introducing into data analysis. I\u2019m actually practicing DAX expressions with my data. I\u2019m mainly using power query in excel for ETL process and then aggregations and iterating functions combining filter context with some basic expressions (CALCULATE, FILTER) in power pivot for excel. However now I\u2019m learning python basics and I\u2019d realized coding using python with some libraries (pandas, numbys, mathplotlib) could do the same or better job, besides the fact that also python allows automate some tasks. I\u2019m working with health data getting info from CSV files. The question is: should I move into python using some libs for data analysis or should I get deep into DAX and power query (M)?", "author_fullname": "t2_qdgsb1r1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data analysis: DAX vs Python (pandas,numby,mathplotlib)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/learnpython", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162crnz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693099339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnpython", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! \nI\u2019m recently learning and introducing into data analysis. I\u2019m actually practicing DAX expressions with my data. I\u2019m mainly using power query in excel for ETL process and then aggregations and iterating functions combining filter context with some basic expressions (CALCULATE, FILTER) in power pivot for excel. However now I\u2019m learning python basics and I\u2019d realized coding using python with some libraries (pandas, numbys, mathplotlib) could do the same or better job, besides the fact that also python allows automate some tasks. I\u2019m working with health data getting info from CSV files. The question is: should I move into python using some libs for data analysis or should I get deep into DAX and power query (M)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8ot", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162crnz", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate_Sea_3254", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/learnpython/comments/162crnz/data_analysis_dax_vs_python_pandasnumbymathplotlib/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/learnpython/comments/162crnz/data_analysis_dax_vs_python_pandasnumbymathplotlib/", "subreddit_subscribers": 736896, "created_utc": 1693099339.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1693101779.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnpython", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/learnpython/comments/162crnz/data_analysis_dax_vs_python_pandasnumbymathplotlib/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162dlpb", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate_Sea_3254", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_162crnz", "author_flair_text_color": null, "permalink": "/r/datascience/comments/162dlpb/data_analysis_dax_vs_python_pandasnumbymathplotlib/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/learnpython/comments/162crnz/data_analysis_dax_vs_python_pandasnumbymathplotlib/", "subreddit_subscribers": 1016419, "created_utc": 1693101779.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am in a team of 10 people, a mix of data scientists, analysts and software engineers. \n\nSome of our side quests involve building tools for our entire small team to use \u2014 think a standardized debugging tool to handle common error messages when interacting with company-wide APIs. The thing is, despite it can bring a lot of value to the team, our manager doesn\u2019t really appreciate this kind of work too much and so when a team member build such a tool, it would usually be quick and dirty without any unit tests written to support any logic changes.\n\nThere are some problems with these tools sometimes \u2014 happening due to untested code updates mostly \u2014 but nothing severe and because we are small, it is easily solved by just sending a message to the software owner. But can you see these problems compounding in the long run? I\u2019m trying to see whether there is a need to shift this culture and encourage unit tests everywhere in our side quests.", "author_fullname": "t2_1bodd6y3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does unit testing make sense for a small team software package?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1621e71", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693071436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in a team of 10 people, a mix of data scientists, analysts and software engineers. &lt;/p&gt;\n\n&lt;p&gt;Some of our side quests involve building tools for our entire small team to use \u2014 think a standardized debugging tool to handle common error messages when interacting with company-wide APIs. The thing is, despite it can bring a lot of value to the team, our manager doesn\u2019t really appreciate this kind of work too much and so when a team member build such a tool, it would usually be quick and dirty without any unit tests written to support any logic changes.&lt;/p&gt;\n\n&lt;p&gt;There are some problems with these tools sometimes \u2014 happening due to untested code updates mostly \u2014 but nothing severe and because we are small, it is easily solved by just sending a message to the software owner. But can you see these problems compounding in the long run? I\u2019m trying to see whether there is a need to shift this culture and encourage unit tests everywhere in our side quests.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1621e71", "is_robot_indexable": true, "report_reasons": null, "author": "iamdeviance", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1621e71/does_unit_testing_make_sense_for_a_small_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1621e71/does_unit_testing_make_sense_for_a_small_team/", "subreddit_subscribers": 1016419, "created_utc": 1693071436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I need a Data Science Project idea for my final year Project idea. I don't find any unique idea can you please suggest an idea or where  I get guidance  ", "author_fullname": "t2_uewgxld9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Project idea?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1620myq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693069598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I need a Data Science Project idea for my final year Project idea. I don&amp;#39;t find any unique idea can you please suggest an idea or where  I get guidance  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1620myq", "is_robot_indexable": true, "report_reasons": null, "author": "atharva_nimbalkar", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1620myq/data_science_project_idea/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1620myq/data_science_project_idea/", "subreddit_subscribers": 1016419, "created_utc": 1693069598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys\n\n* Before the Elon era of Twitter(X) I was running some large twitter scrapes grabbing 1000's of tweets per every X hours and doing some cool trend analysis on topics over a time series with that.\n* Since Elon era and the lockdown of scrapers and additional volume limitations through the API's I've had to drastically reduce the volume of data I obtain.\n* Because this is time series data and not wanting to waste the previous large sets of data I collected I want to combine the 2020-2022 data I collected and tack it onto the 2023 'Elon era' reduced data I now collect.\n\n**Problem**: If I just bolt the two sets together I'll it'll show massive volumes over the 2020-2022 periods then massively reduced volumes on the data sets when you reach 2023\n\n* Because I present this data in charted format with time series running left to right over the X axis it'll look like to the end user \"Lots of volume then not a lot of volume.\"\n* Is there a known technique or method for being able to 'normalise' this pre Elon era data which will help me in bringing the two sets together without the volume disparity affecting too much the end user perception of said data? Volume is as important as the time format in analysing this data.\n\nI'm completely self taught on data aspects so no doubt have some severe gaps in my fundamental knowledge on this type of thing so your insight is valuable and appreciated.\n\nThanks in advance.", "author_fullname": "t2_6mnzdcoh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to combine two data sets with big disparities in volume?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_162l97a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693126713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Before the Elon era of Twitter(X) I was running some large twitter scrapes grabbing 1000&amp;#39;s of tweets per every X hours and doing some cool trend analysis on topics over a time series with that.&lt;/li&gt;\n&lt;li&gt;Since Elon era and the lockdown of scrapers and additional volume limitations through the API&amp;#39;s I&amp;#39;ve had to drastically reduce the volume of data I obtain.&lt;/li&gt;\n&lt;li&gt;Because this is time series data and not wanting to waste the previous large sets of data I collected I want to combine the 2020-2022 data I collected and tack it onto the 2023 &amp;#39;Elon era&amp;#39; reduced data I now collect.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: If I just bolt the two sets together I&amp;#39;ll it&amp;#39;ll show massive volumes over the 2020-2022 periods then massively reduced volumes on the data sets when you reach 2023&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Because I present this data in charted format with time series running left to right over the X axis it&amp;#39;ll look like to the end user &amp;quot;Lots of volume then not a lot of volume.&amp;quot;&lt;/li&gt;\n&lt;li&gt;Is there a known technique or method for being able to &amp;#39;normalise&amp;#39; this pre Elon era data which will help me in bringing the two sets together without the volume disparity affecting too much the end user perception of said data? Volume is as important as the time format in analysing this data.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m completely self taught on data aspects so no doubt have some severe gaps in my fundamental knowledge on this type of thing so your insight is valuable and appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162l97a", "is_robot_indexable": true, "report_reasons": null, "author": "_DESTRUCTION", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162l97a/how_to_combine_two_data_sets_with_big_disparities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162l97a/how_to_combine_two_data_sets_with_big_disparities/", "subreddit_subscribers": 1016419, "created_utc": 1693126713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I'm a recent (5months ago) international graduate student and been actively looking for a job.\n\nI've been applying almost 1000+ position since last year and got about 10+ interviews and coding tests.\n\nI found this channel that's really active and helpful (before I didn't know about reddit enough).\n\nI'm looking for software engineer (not web dev position) / Data Science / ML position. However, I sometimes feel like my resume can't get even near hiring manager. (very few response rate)\n\nThus, I'm here to ask for help desperately. What I can improve, what to fix, etc.\n\nAny honest feedback (good &amp; bad) would be helpful for me! Thank you\n\nhttps://preview.redd.it/pi8swhy8zlkb1.png?width=657&amp;format=png&amp;auto=webp&amp;s=5d5ccc78bc8f834f5ba70907d37e3e24ce4d680d", "author_fullname": "t2_jkiaz6mq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "May I ask you guys for honest, professional feedback?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"pi8swhy8zlkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 147, "x": 108, "u": "https://preview.redd.it/pi8swhy8zlkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0fcf63cc322c9b1ab495d4f2a0dfa64991aa8b02"}, {"y": 294, "x": 216, "u": "https://preview.redd.it/pi8swhy8zlkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f8560e20c1cc2e0ae0591c810dea638e0dc10c2"}, {"y": 435, "x": 320, "u": "https://preview.redd.it/pi8swhy8zlkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3da95347867f14fa119202b590ca4eff9eedf023"}, {"y": 871, "x": 640, "u": "https://preview.redd.it/pi8swhy8zlkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e2184642d1118b6d0ff9d4411274418756552446"}], "s": {"y": 895, "x": 657, "u": "https://preview.redd.it/pi8swhy8zlkb1.png?width=657&amp;format=png&amp;auto=webp&amp;s=5d5ccc78bc8f834f5ba70907d37e3e24ce4d680d"}, "id": "pi8swhy8zlkb1"}}, "name": "t3_162k0jj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/JzmeLYOGKzAXrEbnIKaw7uN6Ra96D2ariTOEsTY1p64.jpg", "edited": 1693122763.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693122276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m a recent (5months ago) international graduate student and been actively looking for a job.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been applying almost 1000+ position since last year and got about 10+ interviews and coding tests.&lt;/p&gt;\n\n&lt;p&gt;I found this channel that&amp;#39;s really active and helpful (before I didn&amp;#39;t know about reddit enough).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for software engineer (not web dev position) / Data Science / ML position. However, I sometimes feel like my resume can&amp;#39;t get even near hiring manager. (very few response rate)&lt;/p&gt;\n\n&lt;p&gt;Thus, I&amp;#39;m here to ask for help desperately. What I can improve, what to fix, etc.&lt;/p&gt;\n\n&lt;p&gt;Any honest feedback (good &amp;amp; bad) would be helpful for me! Thank you&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pi8swhy8zlkb1.png?width=657&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5d5ccc78bc8f834f5ba70907d37e3e24ce4d680d\"&gt;https://preview.redd.it/pi8swhy8zlkb1.png?width=657&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5d5ccc78bc8f834f5ba70907d37e3e24ce4d680d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162k0jj", "is_robot_indexable": true, "report_reasons": null, "author": "Minimum_Ad_1634", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162k0jj/may_i_ask_you_guys_for_honest_professional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162k0jj/may_i_ask_you_guys_for_honest_professional/", "subreddit_subscribers": 1016419, "created_utc": 1693122276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I really have been looking into applying for a Data Science online program to expand my skillset, and I was wondering how intensive of a math background must I have to succeed in the program?\n\nI was really good at trig and stats, but I was horrible the closer I got to calc. I never took linear algebra but am scared crapless about it. Note: I am on the spectrum so it sometimes affects my thinking in certain kinds of math.", "author_fullname": "t2_tk625m9j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I need a math intensive background to succeed in a Data Science graduate program? I currently work in mid-level IT and it's been 11 years since I graduated undergrad.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162e7g5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693103526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really have been looking into applying for a Data Science online program to expand my skillset, and I was wondering how intensive of a math background must I have to succeed in the program?&lt;/p&gt;\n\n&lt;p&gt;I was really good at trig and stats, but I was horrible the closer I got to calc. I never took linear algebra but am scared crapless about it. Note: I am on the spectrum so it sometimes affects my thinking in certain kinds of math.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162e7g5", "is_robot_indexable": true, "report_reasons": null, "author": "YepperyYepstein", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162e7g5/do_i_need_a_math_intensive_background_to_succeed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162e7g5/do_i_need_a_math_intensive_background_to_succeed/", "subreddit_subscribers": 1016419, "created_utc": 1693103526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! We are a group of 4th year students from Singapore Management University, majoring in Information Systems. We are collecting survey responses as part of our final year project, which aims to investigate a child's influence on their parents' diet choices. Ultimately, we wish to leverage these insights to suggest ways to better promote healthy eating within families l.\n\nThe survey should take less than 15 minutes and we would greatly appreciate your responses. \n\nBelow is the link for your reference: https://smusg.asia.qualtrics.com/jfe/form/SV_bEnU3Ffvy74k0ey", "author_fullname": "t2_6ei5kt8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Health Analytics Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_162l0dl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693125823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! We are a group of 4th year students from Singapore Management University, majoring in Information Systems. We are collecting survey responses as part of our final year project, which aims to investigate a child&amp;#39;s influence on their parents&amp;#39; diet choices. Ultimately, we wish to leverage these insights to suggest ways to better promote healthy eating within families l.&lt;/p&gt;\n\n&lt;p&gt;The survey should take less than 15 minutes and we would greatly appreciate your responses. &lt;/p&gt;\n\n&lt;p&gt;Below is the link for your reference: &lt;a href=\"https://smusg.asia.qualtrics.com/jfe/form/SV_bEnU3Ffvy74k0ey\"&gt;https://smusg.asia.qualtrics.com/jfe/form/SV_bEnU3Ffvy74k0ey&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162l0dl", "is_robot_indexable": true, "report_reasons": null, "author": "jinnnramen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162l0dl/health_analytics_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162l0dl/health_analytics_project/", "subreddit_subscribers": 1016419, "created_utc": 1693125823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI have PDFs consisting of images of forms. I want to apply OCR and OMR on this images to extract the required data. I want to detect ticked checkboxes and extract the associated data to those checkboxes from these images. However, the current code is not able to detect the contours of the ticked checkbox.\n\nI am using `findcontours` to find contours and make bounding boxes around the checkboxes. This code is inspired from this [post](https://stackoverflow.com/questions/55763858/how-to-detect-and-find-checkboxes-in-a-form-using-python-opencv).  However, it is not able to detect the contours of the checkbox that is ticked. Here is the code and the image of the area in the form where I am applying the code. \n\n&amp;#x200B;\n\n[ Image of the region of the form with checkboxes and associated data ](https://preview.redd.it/zezn47w91jkb1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=70c517e0eb2b745b711639cfe3f4ff5ecd621232)\n\n    gray = x_gray.copy() # Copy of the Grayscale image shared in this post \n    blur = cv2.GaussianBlur(gray, (3,3), 0)\n    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n    \n    # Find contours and filter using contour area filtering to remove noise\n    cnts, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n    AREA_THRESHOLD = 100\n    for c in cnts:\n        area = cv2.contourArea(c)\n        if area &lt; AREA_THRESHOLD:\n            cv2.drawContours(thresh, [c], -1, 0, -1)\n    \n    # Repair checkbox horizontal and vertical walls\n    repair_kernel1 = cv2.getStructuringElement(cv2.MORPH_RECT, (5,1))\n    repair = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, repair_kernel1, iterations=1)\n    repair_kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (1,5))\n    repair = cv2.morphologyEx(repair, cv2.MORPH_CLOSE, repair_kernel2, iterations=1)\n    \n    # Detect checkboxes using shape approximation and aspect ratio filtering\n    checkbox_contours = []\n    cnts, _ = cv2.findContours(repair, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n    for c in cnts:\n        peri = cv2.arcLength(c, True)\n        approx = cv2.approxPolyDP(c, 0.035 * peri, True)\n        x,y,w,h = cv2.boundingRect(approx)\n        aspect_ratio = w / float(h)\n        if len(approx) == 4 and (aspect_ratio &gt;= 0.8 and aspect_ratio &lt;= 1.2):\n            cv2.rectangle(gray, (x, y), (x + w, y + h), (36,255,12), 3) #original\n            checkbox_contours.append(c)\n    \n    print('Checkboxes:', len(checkbox_contours))\n\n \n\nI have tried various values of the parameter `AREA_THRESHOLD` ranging from 10 - 200. However, I'm still not getting the expected result.\n\nIt would be really helpful if someone can help me with this problem.", "author_fullname": "t2_sq7rhmzy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to detect a ticked checkbox and extract the text associated to it from an image?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zezn47w91jkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 39, "x": 108, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=df46dbcacbb87736e528e3dbdb6bfc5d126d1c45"}, {"y": 78, "x": 216, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4fe58afaa4c9ced4c55e60006eb8e18735452685"}, {"y": 116, "x": 320, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=818915627b0f8ac9a8fb9555c551e88184ff0b22"}, {"y": 233, "x": 640, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=281c44cb846692a1c020de84103ddf2d61f1307b"}, {"y": 350, "x": 960, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=02248f63cbadf1b53ccced790e40fc7722c222ed"}, {"y": 394, "x": 1080, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d56060f6f2a87097038599f429ce9c5465792c64"}], "s": {"y": 565, "x": 1546, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=70c517e0eb2b745b711639cfe3f4ff5ecd621232"}, "id": "zezn47w91jkb1"}}, "name": "t3_16283ok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BR9NB6Fvr_8UUHe0n9NcXWLt2z0-vaZBHk3y27t0Vmo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1693087298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have PDFs consisting of images of forms. I want to apply OCR and OMR on this images to extract the required data. I want to detect ticked checkboxes and extract the associated data to those checkboxes from these images. However, the current code is not able to detect the contours of the ticked checkbox.&lt;/p&gt;\n\n&lt;p&gt;I am using &lt;code&gt;findcontours&lt;/code&gt; to find contours and make bounding boxes around the checkboxes. This code is inspired from this &lt;a href=\"https://stackoverflow.com/questions/55763858/how-to-detect-and-find-checkboxes-in-a-form-using-python-opencv\"&gt;post&lt;/a&gt;.  However, it is not able to detect the contours of the checkbox that is ticked. Here is the code and the image of the area in the form where I am applying the code. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zezn47w91jkb1.png?width=1546&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=70c517e0eb2b745b711639cfe3f4ff5ecd621232\"&gt; Image of the region of the form with checkboxes and associated data &lt;/a&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;gray = x_gray.copy() # Copy of the Grayscale image shared in this post \nblur = cv2.GaussianBlur(gray, (3,3), 0)\nthresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n\n# Find contours and filter using contour area filtering to remove noise\ncnts, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\nAREA_THRESHOLD = 100\nfor c in cnts:\n    area = cv2.contourArea(c)\n    if area &amp;lt; AREA_THRESHOLD:\n        cv2.drawContours(thresh, [c], -1, 0, -1)\n\n# Repair checkbox horizontal and vertical walls\nrepair_kernel1 = cv2.getStructuringElement(cv2.MORPH_RECT, (5,1))\nrepair = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, repair_kernel1, iterations=1)\nrepair_kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (1,5))\nrepair = cv2.morphologyEx(repair, cv2.MORPH_CLOSE, repair_kernel2, iterations=1)\n\n# Detect checkboxes using shape approximation and aspect ratio filtering\ncheckbox_contours = []\ncnts, _ = cv2.findContours(repair, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\nfor c in cnts:\n    peri = cv2.arcLength(c, True)\n    approx = cv2.approxPolyDP(c, 0.035 * peri, True)\n    x,y,w,h = cv2.boundingRect(approx)\n    aspect_ratio = w / float(h)\n    if len(approx) == 4 and (aspect_ratio &amp;gt;= 0.8 and aspect_ratio &amp;lt;= 1.2):\n        cv2.rectangle(gray, (x, y), (x + w, y + h), (36,255,12), 3) #original\n        checkbox_contours.append(c)\n\nprint(&amp;#39;Checkboxes:&amp;#39;, len(checkbox_contours))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I have tried various values of the parameter &lt;code&gt;AREA_THRESHOLD&lt;/code&gt; ranging from 10 - 200. However, I&amp;#39;m still not getting the expected result.&lt;/p&gt;\n\n&lt;p&gt;It would be really helpful if someone can help me with this problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "16283ok", "is_robot_indexable": true, "report_reasons": null, "author": "yishu17", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16283ok/how_to_detect_a_ticked_checkbox_and_extract_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16283ok/how_to_detect_a_ticked_checkbox_and_extract_the/", "subreddit_subscribers": 1016419, "created_utc": 1693087298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sorry if this isn\u2019t written particularly well, but currently I\u2019m very overwhelmed with the job search process and need to figure out how to optimize my time. Also I\u2019m probably catastrophizing, but I don\u2019t want to live in my parents\u2019 basement forever.\n\nSo I\u2019ve been looking for work in the US after leaving a position I had in the UK for 1.5 years mostly because I would not be allowed to keep it due to visa restrictions. I\u2019m concerned because I was getting a few calls back for interviews in the 2 months I was actively looking for work in the UK but I\u2019ve gotten complete silence since I\u2019ve moved back. This is especially bad because I\u2019m a US citizen so things should be easier for me here than they were there.\n\nI\u2019m concerned that my old job isn\u2019t doing me any favors in terms of experience because while my job title was \u201cData Scientist,\u201d I did very little in terms of actual analysis and absolutely no machine learning. I was mostly helping maintain and build data applications to host on AWS, but i don\u2019t think we did much in terms of ETL to the quality most companies who want a Data Engineer would want.\n\nI think my best bet at this point is to learn Power BI and Tableau to get an analyst position, but again, I never did any analysis in my previous position and I think I\u2019d lose to anybody who has actual work experience with these things. I have some projects from my master\u2019s program that plug some of the holes but in my hubris, I didn\u2019t manage to create anything new for the portfolio while I still had a job. I have several web tools that I managed to get working on GCP (just barely) but I can\u2019t get working anymore without refactoring a ton of stuff. Which is a problem because I need to decide if it\u2019s worth redeploying everything at all.\n\nI also also don\u2019t know how to explain the ever increasing gap in my employment. Do I just need to get on Fivver and start selling some cheap data analysis service there just to prove I\u2019m doing something productive? What if I mess up handling my customers and my ratings suffer so I can\u2019t put that work on my resume? I could also take some part time work tutoring again but wouldn\u2019t that make me look bad anyways because it\u2019s a step back?", "author_fullname": "t2_3o4ak2xl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wondering if my experience is inadequate for US job market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1624yex", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693079851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this isn\u2019t written particularly well, but currently I\u2019m very overwhelmed with the job search process and need to figure out how to optimize my time. Also I\u2019m probably catastrophizing, but I don\u2019t want to live in my parents\u2019 basement forever.&lt;/p&gt;\n\n&lt;p&gt;So I\u2019ve been looking for work in the US after leaving a position I had in the UK for 1.5 years mostly because I would not be allowed to keep it due to visa restrictions. I\u2019m concerned because I was getting a few calls back for interviews in the 2 months I was actively looking for work in the UK but I\u2019ve gotten complete silence since I\u2019ve moved back. This is especially bad because I\u2019m a US citizen so things should be easier for me here than they were there.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m concerned that my old job isn\u2019t doing me any favors in terms of experience because while my job title was \u201cData Scientist,\u201d I did very little in terms of actual analysis and absolutely no machine learning. I was mostly helping maintain and build data applications to host on AWS, but i don\u2019t think we did much in terms of ETL to the quality most companies who want a Data Engineer would want.&lt;/p&gt;\n\n&lt;p&gt;I think my best bet at this point is to learn Power BI and Tableau to get an analyst position, but again, I never did any analysis in my previous position and I think I\u2019d lose to anybody who has actual work experience with these things. I have some projects from my master\u2019s program that plug some of the holes but in my hubris, I didn\u2019t manage to create anything new for the portfolio while I still had a job. I have several web tools that I managed to get working on GCP (just barely) but I can\u2019t get working anymore without refactoring a ton of stuff. Which is a problem because I need to decide if it\u2019s worth redeploying everything at all.&lt;/p&gt;\n\n&lt;p&gt;I also also don\u2019t know how to explain the ever increasing gap in my employment. Do I just need to get on Fivver and start selling some cheap data analysis service there just to prove I\u2019m doing something productive? What if I mess up handling my customers and my ratings suffer so I can\u2019t put that work on my resume? I could also take some part time work tutoring again but wouldn\u2019t that make me look bad anyways because it\u2019s a step back?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1624yex", "is_robot_indexable": true, "report_reasons": null, "author": "GGPiggie", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1624yex/wondering_if_my_experience_is_inadequate_for_us/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1624yex/wondering_if_my_experience_is_inadequate_for_us/", "subreddit_subscribers": 1016419, "created_utc": 1693079851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m thinking of applying to this:\n\n[https://faculty.ai/fellowship-fellows/?utm\\_campaign=Fellowship%2026%20-%20Applications&amp;utm\\_source=email&amp;utm\\_medium=Interest%20list&amp;utm\\_term=Hubspot&amp;utm\\_content=Applications%20open%20%28May%202023%29](https://faculty.ai/fellowship-fellows/?utm_campaign=Fellowship%2026%20-%20Applications&amp;utm_source=email&amp;utm_medium=Interest%20list&amp;utm_term=Hubspot&amp;utm_content=Applications%20open%20%28May%202023%29)\n\nJust wondering how hard it\u2019ll be for me to get in. I\u2019ve got a masters in data science from Careerera which isn\u2019t the best masters but Im hoping it qualifies. Just wondering if anyone\u2019s done it before.", "author_fullname": "t2_4lmpcc3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone heard of faculty.ai?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16216r0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693070936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m thinking of applying to this:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://faculty.ai/fellowship-fellows/?utm_campaign=Fellowship%2026%20-%20Applications&amp;amp;utm_source=email&amp;amp;utm_medium=Interest%20list&amp;amp;utm_term=Hubspot&amp;amp;utm_content=Applications%20open%20%28May%202023%29\"&gt;https://faculty.ai/fellowship-fellows/?utm_campaign=Fellowship%2026%20-%20Applications&amp;amp;utm_source=email&amp;amp;utm_medium=Interest%20list&amp;amp;utm_term=Hubspot&amp;amp;utm_content=Applications%20open%20%28May%202023%29&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Just wondering how hard it\u2019ll be for me to get in. I\u2019ve got a masters in data science from Careerera which isn\u2019t the best masters but Im hoping it qualifies. Just wondering if anyone\u2019s done it before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?auto=webp&amp;s=ee6b11645868310e9239e7fa475c04d7a5afa4d4", "width": 2000, "height": 1333}, "resolutions": [{"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=410ac9dafb9bf4b59bf747e2d75ff9c2fda6a2fd", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8999b58a6ffd1031f3e4a839ea41062baa97003e", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5b2a3b4af378168ba31515efa037a8389602cacb", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=84d38cdcf7d096e929abdd37d4e2f78f5436d389", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a41f7a3e9d3603dcc4d34f05bf5bc303e92a6ec9", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=648798c090bbb8897b8d4326ff8cabb94b401b6b", "width": 1080, "height": 719}], "variants": {}, "id": "ecHk9ZLP1I54kTm81PtOd9flzglN73iU1bmbBvWKh0A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16216r0", "is_robot_indexable": true, "report_reasons": null, "author": "redtoothroll", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16216r0/anyone_heard_of_facultyai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16216r0/anyone_heard_of_facultyai/", "subreddit_subscribers": 1016419, "created_utc": 1693070936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9v2ffwqay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Twitter Community / Machine Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161rqa5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1693046299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/i/communities/1695363277289562618", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161rqa5", "is_robot_indexable": true, "report_reasons": null, "author": "x9182", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161rqa5/twitter_community_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/i/communities/1695363277289562618", "subreddit_subscribers": 1016419, "created_utc": 1693046299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I think the question says it all. I am considering doing masters in data science in uk and wondering what are the job opportunities there like after the degree. How easy it is to land a job in data science as a fresher being an international student and is it even possible?", "author_fullname": "t2_f31m67lx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How easy is to land a job in data science get a job as a fresher in the uk being an international student?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1626t17", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693084255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think the question says it all. I am considering doing masters in data science in uk and wondering what are the job opportunities there like after the degree. How easy it is to land a job in data science as a fresher being an international student and is it even possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1626t17", "is_robot_indexable": true, "report_reasons": null, "author": "ProfessionalOne272", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1626t17/how_easy_is_to_land_a_job_in_data_science_get_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1626t17/how_easy_is_to_land_a_job_in_data_science_get_a/", "subreddit_subscribers": 1016419, "created_utc": 1693084255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_h8jjaslyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Get Hired as Junior Data Analyst - Remote | FullTime", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161zaol", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1693066315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theswedishtimes.se", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://theswedishtimes.se/jobs/8", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161zaol", "is_robot_indexable": true, "report_reasons": null, "author": "Finance_mechanism", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161zaol/get_hired_as_junior_data_analyst_remote_fulltime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://theswedishtimes.se/jobs/8", "subreddit_subscribers": 1016419, "created_utc": 1693066315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "https://youtube.com/shorts/rLoecC__oL4?si=aaiCATF2VQVdRuUs\n\nAnd here\n\nhttps://youtu.be/DHlkr2C03x4?si=deLRkY9W-OufIfFJ", "author_fullname": "t2_i69qgpqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data scientists gets owned", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162h6r1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693112475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://youtube.com/shorts/rLoecC__oL4?si=aaiCATF2VQVdRuUs\"&gt;https://youtube.com/shorts/rLoecC__oL4?si=aaiCATF2VQVdRuUs&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And here&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/DHlkr2C03x4?si=deLRkY9W-OufIfFJ\"&gt;https://youtu.be/DHlkr2C03x4?si=deLRkY9W-OufIfFJ&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bqCWyZKKhhn7NKMexZq-AuTMD7rQGm-u53AaKu10-XE.jpg?auto=webp&amp;s=a1d9f6f14b3e1fea341e37a8077ae4a3fd0ccb35", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/bqCWyZKKhhn7NKMexZq-AuTMD7rQGm-u53AaKu10-XE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1ee275129b61fbeeece375492317f7f88bafedc", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/bqCWyZKKhhn7NKMexZq-AuTMD7rQGm-u53AaKu10-XE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=898ed17be0555e1fa70f9acebdd55f334f9ff20c", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/bqCWyZKKhhn7NKMexZq-AuTMD7rQGm-u53AaKu10-XE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3ad14cfb125be27356e3857a0f81c2f3f13c1583", "width": 320, "height": 240}], "variants": {}, "id": "L9hulc6L93EFaXv2ZzFFjd7ALeZvginnXCPQ7uHq2uc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162h6r1", "is_robot_indexable": true, "report_reasons": null, "author": "AdFew4357", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162h6r1/data_scientists_gets_owned/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162h6r1/data_scientists_gets_owned/", "subreddit_subscribers": 1016419, "created_utc": 1693112475.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}